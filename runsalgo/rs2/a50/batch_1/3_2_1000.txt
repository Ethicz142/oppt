Run # 1
Initial state: 0 0.584183 0.814878 0.16185 0.940648 0.607462 0.882425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53256 episodes
GETTING ACTION FROM:
action 3, numVisits=53230, meanQ=4.837144, numObservations: 4
action 0, numVisits=18, meanQ=3.293214, numObservations: 1
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.584183 0.814878 0.16185 0.940648 0.607462 0.882425 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.797463 0.906179 0.523556 0.833645 0.615086 0.895801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55143 episodes
GETTING ACTION FROM:
action 2, numVisits=55026, meanQ=4.967448, numObservations: 4
action -1, numVisits=77, meanQ=4.190591, numObservations: 1
action 0, numVisits=38, meanQ=3.886135, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.797463 0.906179 0.523556 0.833645 0.615086 0.895801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 3
Initial state: 0 0.526012 0.878613 0.533219 0.582518 0.610518 0.808119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51499 episodes
GETTING ACTION FROM:
action 3, numVisits=46066, meanQ=4.950869, numObservations: 3
action 0, numVisits=5365, meanQ=2.851601, numObservations: 1
action 2, numVisits=46, meanQ=1.900437, numObservations: 4
action 1, numVisits=20, meanQ=1.498505, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.526012 0.878613 0.533219 0.582518 0.610518 0.808119 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 4
Initial state: 0 0.501702 0.839369 0.623296 0.859163 0.46552 0.0758975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31489 episodes
GETTING ACTION FROM:
action 0, numVisits=31470, meanQ=2.739627, numObservations: 1
action 3, numVisits=11, meanQ=0.270000, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 0
Next state: 0 0.501702 0.839369 0.623296 0.859163 0.46552 0.0758975 w: 1
Observation: 0 0 0.892464 0 0.847003 0 0.0170266 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31440, meanQ=4.809457, numObservations: 5
action -1, numVisits=25, meanQ=3.555159, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 52249 episodes
GETTING ACTION FROM:
action 1, numVisits=83606, meanQ=4.872721, numObservations: 5
action 2, numVisits=83, meanQ=3.977510, numObservations: 4
action -1, numVisits=26, meanQ=3.464321, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.501702 0.839369 0.623296 0.859163 0.46552 0.0758975 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 5
Initial state: 0 0.523945 0.831156 0.692387 0.835427 0.704302 0.0987189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55523 episodes
GETTING ACTION FROM:
action 3, numVisits=55492, meanQ=4.999374, numObservations: 5
action -1, numVisits=25, meanQ=3.626576, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.523945 0.831156 0.692387 0.835427 0.704302 0.0987189 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 6
Initial state: 0 0.686934 0.899753 0.0451366 0.0615365 0.610243 0.834625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54834 episodes
GETTING ACTION FROM:
action 2, numVisits=54776, meanQ=4.901083, numObservations: 4
action 3, numVisits=53, meanQ=3.584447, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.686934 0.899753 0.0451366 0.0615365 0.610243 0.834625 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8304, meanQ=8.280496, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 41321 episodes
GETTING ACTION FROM:
action 3, numVisits=49601, meanQ=6.404247, numObservations: 4
action 1, numVisits=22, meanQ=3.449550, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.686934 0.899753 0.0451366 0.0615365 0.610243 0.834625 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 7
Initial state: 0 0.547104 0.00584024 0.585852 0.818668 0.619804 0.827944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55574 episodes
GETTING ACTION FROM:
action 2, numVisits=55526, meanQ=4.967628, numObservations: 4
action -1, numVisits=41, meanQ=3.942939, numObservations: 1
action 1, numVisits=3, meanQ=-0.329967, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.547104 0.00584024 0.585852 0.818668 0.619804 0.827944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3967, meanQ=5.702594, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 63569 episodes
GETTING ACTION FROM:
action 1, numVisits=22409, meanQ=5.865016, numObservations: 4
action 2, numVisits=45126, meanQ=5.073746, numObservations: 5
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 0 0.547104 0.00584024 0.585852 0.818668 0.619804 0.827944 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=128, meanQ=7.994064, numObservations: 4
action 2, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 66470 episodes
GETTING ACTION FROM:
action 3, numVisits=66243, meanQ=5.897083, numObservations: 4
action 2, numVisits=354, meanQ=5.542316, numObservations: 5
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.547104 0.00584024 0.585852 0.818668 0.619804 0.827944 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 8
Initial state: 0 0.619773 0.809242 0.736653 0.569761 0.664325 0.876402 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54945 episodes
GETTING ACTION FROM:
action 1, numVisits=54938, meanQ=4.931914, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.619773 0.809242 0.736653 0.569761 0.664325 0.876402 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 9
Initial state: 0 0.675522 0.875851 0.976084 0.232937 0.686346 0.808031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47677 episodes
GETTING ACTION FROM:
action 1, numVisits=36230, meanQ=5.045483, numObservations: 4
action 0, numVisits=11438, meanQ=3.046931, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.675522 0.875851 0.976084 0.232937 0.686346 0.808031 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 10
Initial state: 0 0.668968 0.888365 0.808905 0.747994 0.575716 0.857952 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54291 episodes
GETTING ACTION FROM:
action 3, numVisits=53596, meanQ=4.993016, numObservations: 5
action -1, numVisits=687, meanQ=3.557560, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.668968 0.888365 0.808905 0.747994 0.575716 0.857952 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 11
Initial state: 0 0.665922 0.695179 0.579339 0.880606 0.602859 0.847705 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54683 episodes
GETTING ACTION FROM:
action 2, numVisits=54676, meanQ=4.942272, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.665922 0.695179 0.579339 0.880606 0.602859 0.847705 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 12
Initial state: 0 0.529729 0.818564 0.807387 0.370115 0.608872 0.812928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55244 episodes
GETTING ACTION FROM:
action 3, numVisits=55238, meanQ=4.991858, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.529729 0.818564 0.807387 0.370115 0.608872 0.812928 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 13
Initial state: 0 0.571474 0.80481 0.684982 0.837 0.14847 0.00182103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55122 episodes
GETTING ACTION FROM:
action 3, numVisits=55020, meanQ=4.924788, numObservations: 4
action -1, numVisits=83, meanQ=2.747189, numObservations: 1
action 1, numVisits=16, meanQ=1.987500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.571474 0.80481 0.684982 0.837 0.14847 0.00182103 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8350, meanQ=8.296717, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 47555 episodes
GETTING ACTION FROM:
action 2, numVisits=55900, meanQ=6.540914, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 2
Next state: 1 0.571474 0.80481 0.684982 0.837 0.14847 0.00182103 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 14
Initial state: 0 0.769635 0.169287 0.629926 0.884894 0.642988 0.836059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54810 episodes
GETTING ACTION FROM:
action 1, numVisits=54788, meanQ=4.790257, numObservations: 5
action 2, numVisits=16, meanQ=1.487513, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.769635 0.169287 0.629926 0.884894 0.642988 0.836059 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.676418 0.87004 0.525484 0.825334 0.754091 0.60628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52950 episodes
GETTING ACTION FROM:
action 2, numVisits=52900, meanQ=4.756550, numObservations: 4
action -1, numVisits=43, meanQ=3.738779, numObservations: 1
action 3, numVisits=4, meanQ=-0.504975, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.676418 0.87004 0.525484 0.825334 0.754091 0.60628 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 16
Initial state: 0 0.073328 0.313845 0.684869 0.806235 0.509323 0.846347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 36759 episodes
GETTING ACTION FROM:
action 0, numVisits=29730, meanQ=5.799342, numObservations: 3
action 1, numVisits=6990, meanQ=4.868944, numObservations: 4
action -1, numVisits=37, meanQ=3.958497, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.073328 0.313845 0.684869 0.806235 0.509323 0.846347 w: 1
Observation: 0 0 0.349736 0 0.76274 0 0.929041 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8991, meanQ=8.130791, numObservations: 5
action 2, numVisits=17, meanQ=6.410588, numObservations: 3
action 1, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 54894 episodes
GETTING ACTION FROM:
action 3, numVisits=63857, meanQ=5.492110, numObservations: 5
action 2, numVisits=30, meanQ=3.798673, numObservations: 4
action 1, numVisits=18, meanQ=3.771117, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.073328 0.313845 0.684869 0.806235 0.509323 0.846347 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 17
Initial state: 0 0.346094 0.974432 0.516104 0.86079 0.698655 0.825563 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32246 episodes
GETTING ACTION FROM:
action -1, numVisits=32224, meanQ=2.913722, numObservations: 1
action 1, numVisits=18, meanQ=1.111683, numObservations: 5
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.346094 0.974432 0.516104 0.86079 0.698655 0.825563 w: 1
Observation: 0 0.435473 0 0.577356 0 0.689147 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32123, meanQ=4.953012, numObservations: 4
action -1, numVisits=95, meanQ=4.306299, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55349 episodes
GETTING ACTION FROM:
action 2, numVisits=87461, meanQ=4.812940, numObservations: 4
action -1, numVisits=106, meanQ=4.178545, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.346094 0.974432 0.516104 0.86079 0.698655 0.825563 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 18
Initial state: 0 0.228799 0.83008 0.555937 0.878909 0.543546 0.894303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52707 episodes
GETTING ACTION FROM:
action 1, numVisits=52676, meanQ=4.798272, numObservations: 5
action -1, numVisits=27, meanQ=3.545809, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.228799 0.83008 0.555937 0.878909 0.543546 0.894303 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2851, meanQ=7.771925, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46704 episodes
GETTING ACTION FROM:
action 2, numVisits=21765, meanQ=6.034626, numObservations: 4
action 3, numVisits=27781, meanQ=5.893465, numObservations: 4
action 1, numVisits=8, meanQ=3.497500, numObservations: 2
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 2
Next state: 0 0.228799 0.83008 0.555937 0.878909 0.543546 0.894303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=429, meanQ=8.265542, numObservations: 3
action -1, numVisits=182, meanQ=5.097387, numObservations: 1
action 3, numVisits=6, meanQ=3.665000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 66130 episodes
GETTING ACTION FROM:
action 3, numVisits=57376, meanQ=5.944879, numObservations: 4
action 2, numVisits=9059, meanQ=5.771169, numObservations: 3
action -1, numVisits=307, meanQ=2.251661, numObservations: 1
action 0, numVisits=6, meanQ=-0.350000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.228799 0.83008 0.555937 0.878909 0.543546 0.894303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 19
Initial state: 0 0.619091 0.805231 0.278879 0.564183 0.580094 0.896019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55423 episodes
GETTING ACTION FROM:
action 2, numVisits=55412, meanQ=4.932082, numObservations: 4
action 1, numVisits=6, meanQ=1.331683, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.619091 0.805231 0.278879 0.564183 0.580094 0.896019 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2989, meanQ=7.858663, numObservations: 4
action 3, numVisits=29, meanQ=6.516559, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 41805 episodes
GETTING ACTION FROM:
action 1, numVisits=44732, meanQ=6.145845, numObservations: 4
action 3, numVisits=75, meanQ=4.679603, numObservations: 3
action 2, numVisits=13, meanQ=4.075385, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 1
Next state: 1 0.619091 0.805231 0.278879 0.564183 0.580094 0.896019 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 20
Initial state: 0 0.595449 0.819227 0.591058 0.250565 0.51549 0.885812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52301 episodes
GETTING ACTION FROM:
action 3, numVisits=52265, meanQ=4.862928, numObservations: 3
action 2, numVisits=25, meanQ=0.920812, numObservations: 4
action 1, numVisits=7, meanQ=0.144314, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.595449 0.819227 0.591058 0.250565 0.51549 0.885812 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=3790, meanQ=4.410420, numObservations: 2
action 3, numVisits=7, meanQ=-0.429986, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 60909 episodes
GETTING ACTION FROM:
action 3, numVisits=55784, meanQ=5.051394, numObservations: 3
action 0, numVisits=8916, meanQ=1.785762, numObservations: 2
action -1, numVisits=7, meanQ=-0.728557, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.595449 0.819227 0.591058 0.250565 0.51549 0.885812 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 21
Initial state: 0 0.567384 0.855477 0.24984 0.625199 0.658413 0.84735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54973 episodes
GETTING ACTION FROM:
action 1, numVisits=54869, meanQ=4.918665, numObservations: 5
action 3, numVisits=99, meanQ=4.241621, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.567384 0.855477 0.24984 0.625199 0.658413 0.84735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3442, meanQ=5.853369, numObservations: 3
action 2, numVisits=9, meanQ=2.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 60400 episodes
GETTING ACTION FROM:
action 1, numVisits=63829, meanQ=5.206612, numObservations: 3
action 3, numVisits=12, meanQ=2.658333, numObservations: 2
action 2, numVisits=9, meanQ=2.333333, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.567384 0.855477 0.24984 0.625199 0.658413 0.84735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 22
Initial state: 0 0.337573 0.375462 0.547729 0.84971 0.525685 0.898853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32466 episodes
GETTING ACTION FROM:
action -1, numVisits=32436, meanQ=3.054900, numObservations: 1
action 3, numVisits=18, meanQ=1.222222, numObservations: 3
action 1, numVisits=9, meanQ=-0.123322, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.337573 0.375462 0.547729 0.84971 0.525685 0.898853 w: 1
Observation: 0 0.380689 0 0.550044 0 0.50191 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32413, meanQ=5.039722, numObservations: 3
action 1, numVisits=14, meanQ=2.856436, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 55767 episodes
GETTING ACTION FROM:
action 3, numVisits=88179, meanQ=4.872650, numObservations: 3
action 1, numVisits=15, meanQ=2.993340, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.337573 0.375462 0.547729 0.84971 0.525685 0.898853 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 23
Initial state: 0 0.61129 0.865055 0.490744 0.911057 0.594841 0.838983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53361 episodes
GETTING ACTION FROM:
action 1, numVisits=53302, meanQ=4.878437, numObservations: 5
action 0, numVisits=51, meanQ=3.929273, numObservations: 1
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.61129 0.865055 0.490744 0.911057 0.594841 0.838983 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 24
Initial state: 0 0.67003 0.824487 0.634294 0.888472 0.193381 0.556522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55125 episodes
GETTING ACTION FROM:
action 1, numVisits=55076, meanQ=4.914700, numObservations: 4
action 3, numVisits=44, meanQ=3.673184, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.67003 0.824487 0.634294 0.888472 0.193381 0.556522 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 25
Initial state: 0 0.846341 0.873379 0.526307 0.883068 0.656063 0.849554 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55510 episodes
GETTING ACTION FROM:
action 1, numVisits=55405, meanQ=5.047107, numObservations: 3
action 2, numVisits=85, meanQ=4.234635, numObservations: 3
action -1, numVisits=17, meanQ=3.333873, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.846341 0.873379 0.526307 0.883068 0.656063 0.849554 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 26
Initial state: 0 0.675401 0.864468 0.0938044 0.899667 0.673801 0.880875 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54677 episodes
GETTING ACTION FROM:
action 1, numVisits=54620, meanQ=4.928874, numObservations: 4
action -1, numVisits=42, meanQ=3.884963, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action 3, numVisits=6, meanQ=1.331683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.675401 0.864468 0.0938044 0.899667 0.673801 0.880875 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 27
Initial state: 0 0.665569 0.857057 0.0792537 0.520788 0.523543 0.827164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55042 episodes
GETTING ACTION FROM:
action 3, numVisits=54999, meanQ=4.922792, numObservations: 4
action -1, numVisits=21, meanQ=3.454269, numObservations: 1
action 2, numVisits=19, meanQ=3.310000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.665569 0.857057 0.0792537 0.520788 0.523543 0.827164 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 28
Initial state: 0 0.406776 0.929276 0.616312 0.884751 0.615703 0.831062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54131 episodes
GETTING ACTION FROM:
action 1, numVisits=54124, meanQ=4.901575, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.406776 0.929276 0.616312 0.884751 0.615703 0.831062 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2725, meanQ=5.632287, numObservations: 3
action -1, numVisits=1274, meanQ=2.632642, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 66607 episodes
GETTING ACTION FROM:
action 3, numVisits=65874, meanQ=5.608560, numObservations: 3
action 1, numVisits=3457, meanQ=5.508486, numObservations: 3
action -1, numVisits=1274, meanQ=2.632642, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.406776 0.929276 0.616312 0.884751 0.615703 0.831062 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 29
Initial state: 0 0.673347 0.899736 0.488352 0.7832 0.537096 0.811324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55316 episodes
GETTING ACTION FROM:
action 3, numVisits=55263, meanQ=4.968725, numObservations: 4
action -1, numVisits=42, meanQ=3.940733, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.673347 0.899736 0.488352 0.7832 0.537096 0.811324 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 30
Initial state: 0 0.889855 0.755061 0.620702 0.88831 0.581969 0.86362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55004 episodes
GETTING ACTION FROM:
action 1, numVisits=54996, meanQ=4.906797, numObservations: 4
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.889855 0.755061 0.620702 0.88831 0.581969 0.86362 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 31
Initial state: 0 0.528092 0.517513 0.51834 0.881176 0.547581 0.848537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50577 episodes
GETTING ACTION FROM:
action 1, numVisits=47832, meanQ=4.802553, numObservations: 5
action 0, numVisits=2649, meanQ=2.870101, numObservations: 1
action -1, numVisits=90, meanQ=2.384483, numObservations: 1
action 3, numVisits=5, meanQ=0.196000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.528092 0.517513 0.51834 0.881176 0.547581 0.848537 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2688, meanQ=7.786827, numObservations: 4
action 3, numVisits=11, meanQ=5.724545, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46361 episodes
GETTING ACTION FROM:
action 2, numVisits=27837, meanQ=5.986741, numObservations: 4
action 3, numVisits=21216, meanQ=5.852023, numObservations: 3
action -1, numVisits=6, meanQ=-0.350000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.528092 0.517513 0.51834 0.881176 0.547581 0.848537 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 32
Initial state: 0 0.512293 0.895845 0.485857 0.20034 0.690364 0.873169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50167 episodes
GETTING ACTION FROM:
action 2, numVisits=44897, meanQ=4.853691, numObservations: 5
action -1, numVisits=5241, meanQ=3.017583, numObservations: 1
action 3, numVisits=26, meanQ=1.845396, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.512293 0.895845 0.485857 0.20034 0.690364 0.873169 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5587, meanQ=8.384799, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 48936 episodes
GETTING ACTION FROM:
action 3, numVisits=53251, meanQ=6.082360, numObservations: 5
action 1, numVisits=1269, meanQ=5.596675, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.512293 0.895845 0.485857 0.20034 0.690364 0.873169 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 33
Initial state: 0 0.565714 0.800348 0.624161 0.888541 0.0901469 0.108118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54928 episodes
GETTING ACTION FROM:
action 1, numVisits=54913, meanQ=5.010341, numObservations: 3
action -1, numVisits=11, meanQ=2.890000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.565714 0.800348 0.624161 0.888541 0.0901469 0.108118 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 34
Initial state: 0 0.503162 0.847481 0.502733 0.810981 0.287855 0.918037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55627 episodes
GETTING ACTION FROM:
action 2, numVisits=55550, meanQ=4.995671, numObservations: 5
action -1, numVisits=34, meanQ=3.873203, numObservations: 1
action 3, numVisits=19, meanQ=3.094737, numObservations: 4
action 0, numVisits=13, meanQ=2.842027, numObservations: 1
action 1, numVisits=11, meanQ=2.272745, numObservations: 2
action: 2
Next state: 1 0.503162 0.847481 0.502733 0.810981 0.287855 0.918037 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 35
Initial state: 0 0.534163 0.829199 0.560765 0.859001 0.618316 0.857797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55616 episodes
GETTING ACTION FROM:
action 1, numVisits=55514, meanQ=5.105344, numObservations: 4
action -1, numVisits=84, meanQ=4.384609, numObservations: 1
action 0, numVisits=16, meanQ=3.459969, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.534163 0.829199 0.560765 0.859001 0.618316 0.857797 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 36
Initial state: 0 0.692484 0.893106 0.678041 0.86089 0.601013 0.151524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55472 episodes
GETTING ACTION FROM:
action 3, numVisits=55445, meanQ=5.018876, numObservations: 5
action 0, numVisits=21, meanQ=3.481082, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=3, meanQ=-2.966667, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.692484 0.893106 0.678041 0.86089 0.601013 0.151524 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.471313 0.0264213 0.675123 0.859761 0.520733 0.874919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55385 episodes
GETTING ACTION FROM:
action 1, numVisits=48289, meanQ=4.968791, numObservations: 4
action 3, numVisits=6931, meanQ=4.846002, numObservations: 5
action 0, numVisits=143, meanQ=4.413357, numObservations: 1
action 2, numVisits=20, meanQ=3.498505, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.471313 0.0264213 0.675123 0.859761 0.520733 0.874919 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7367, meanQ=8.263779, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 44482 episodes
GETTING ACTION FROM:
action 3, numVisits=51828, meanQ=6.185093, numObservations: 4
action 2, numVisits=19, meanQ=3.104737, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.471313 0.0264213 0.675123 0.859761 0.520733 0.874919 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 38
Initial state: 0 0.68743 0.803962 0.648599 0.242457 0.507311 0.840709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55012 episodes
GETTING ACTION FROM:
action 3, numVisits=54895, meanQ=4.923872, numObservations: 5
action 0, numVisits=113, meanQ=4.315411, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.68743 0.803962 0.648599 0.242457 0.507311 0.840709 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 39
Initial state: 0 0.624348 0.546647 0.657378 0.817776 0.624148 0.812604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33467 episodes
GETTING ACTION FROM:
action 0, numVisits=33462, meanQ=4.810416, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.624348 0.546647 0.657378 0.817776 0.624148 0.812604 w: 1
Observation: 0 0 0.481295 0 0.769156 0 0.841674 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9428, meanQ=8.201441, numObservations: 3
action 2, numVisits=46, meanQ=5.125872, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55573 episodes
GETTING ACTION FROM:
action 3, numVisits=64902, meanQ=5.373593, numObservations: 3
action 2, numVisits=143, meanQ=4.834932, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.624348 0.546647 0.657378 0.817776 0.624148 0.812604 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 40
Initial state: 0 0.670534 0.806518 0.552372 0.824561 0.608239 0.0455832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55321 episodes
GETTING ACTION FROM:
action 2, numVisits=55315, meanQ=5.012045, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.670534 0.806518 0.552372 0.824561 0.608239 0.0455832 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4131, meanQ=5.835115, numObservations: 4
action 1, numVisits=18, meanQ=2.776678, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 61725 episodes
GETTING ACTION FROM:
action 2, numVisits=65849, meanQ=5.061657, numObservations: 4
action 1, numVisits=18, meanQ=2.776678, numObservations: 3
action 0, numVisits=7, meanQ=1.960000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.670534 0.806518 0.552372 0.824561 0.608239 0.0455832 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 41
Initial state: 0 0.540219 0.882214 0.5083 0.805219 0.673687 0.162505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55240 episodes
GETTING ACTION FROM:
action 3, numVisits=55234, meanQ=4.970898, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.540219 0.882214 0.5083 0.805219 0.673687 0.162505 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 42
Initial state: 0 0.559226 0.215041 0.6828 0.890365 0.557388 0.842012 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55227 episodes
GETTING ACTION FROM:
action 3, numVisits=55221, meanQ=4.976581, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.559226 0.215041 0.6828 0.890365 0.557388 0.842012 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 43
Initial state: 0 0.525209 0.874881 0.609033 0.810571 0.401311 0.515571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33809 episodes
GETTING ACTION FROM:
action 0, numVisits=33797, meanQ=5.712503, numObservations: 2
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.525209 0.874881 0.609033 0.810571 0.401311 0.515571 w: 1
Observation: 0 0 0.81783 0 0.862355 0 0.42176 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=15302, meanQ=7.882137, numObservations: 5
action 3, numVisits=6, meanQ=1.663333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 55572 episodes
GETTING ACTION FROM:
action 2, numVisits=70866, meanQ=6.051899, numObservations: 5
action -1, numVisits=9, meanQ=3.388719, numObservations: 1
action 3, numVisits=6, meanQ=1.663333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.525209 0.874881 0.609033 0.810571 0.401311 0.515571 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 44
Initial state: 0 0.622671 0.808305 0.706991 0.00630202 0.653797 0.806844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55422 episodes
GETTING ACTION FROM:
action 2, numVisits=55394, meanQ=4.977579, numObservations: 4
action 0, numVisits=13, meanQ=3.037577, numObservations: 2
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.622671 0.808305 0.706991 0.00630202 0.653797 0.806844 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 45
Initial state: 0 0.537343 0.845687 0.603687 0.846788 0.678139 0.72715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55180 episodes
GETTING ACTION FROM:
action 3, numVisits=55164, meanQ=5.008423, numObservations: 4
action 1, numVisits=11, meanQ=-0.456364, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.537343 0.845687 0.603687 0.846788 0.678139 0.72715 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 46
Initial state: 0 0.59101 0.805336 0.485824 0.9795 0.563582 0.818478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52844 episodes
GETTING ACTION FROM:
action 1, numVisits=52836, meanQ=4.803994, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.59101 0.805336 0.485824 0.9795 0.563582 0.818478 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 47
Initial state: 0 0.180735 0.743131 0.547563 0.859547 0.526862 0.85832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55519 episodes
GETTING ACTION FROM:
action 1, numVisits=55508, meanQ=4.937235, numObservations: 5
action 2, numVisits=6, meanQ=1.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.180735 0.743131 0.547563 0.859547 0.526862 0.85832 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3128, meanQ=7.882257, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 45364 episodes
GETTING ACTION FROM:
action 2, numVisits=39327, meanQ=6.028223, numObservations: 3
action 3, numVisits=9157, meanQ=5.886901, numObservations: 4
action 1, numVisits=6, meanQ=4.665017, numObservations: 2
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 2
Next state: 1 0.180735 0.743131 0.547563 0.859547 0.526862 0.85832 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 48
Initial state: 0 0.546049 0.838787 0.628971 0.832168 0.397096 0.00256321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54527 episodes
GETTING ACTION FROM:
action 1, numVisits=54463, meanQ=5.078186, numObservations: 4
action 0, numVisits=32, meanQ=3.897541, numObservations: 1
action 3, numVisits=27, meanQ=3.066674, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.546049 0.838787 0.628971 0.832168 0.397096 0.00256321 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 49
Initial state: 0 0.602681 0.855961 0.587705 0.874939 0.764402 0.290669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54772 episodes
GETTING ACTION FROM:
action 2, numVisits=54760, meanQ=5.082772, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.602681 0.855961 0.587705 0.874939 0.764402 0.290669 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 50
Initial state: 0 0.653958 0.853925 0.593685 0.832154 0.199296 0.731958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55278 episodes
GETTING ACTION FROM:
action 2, numVisits=53858, meanQ=4.961705, numObservations: 5
action 1, numVisits=1315, meanQ=4.793188, numObservations: 3
action 0, numVisits=53, meanQ=4.040602, numObservations: 1
action -1, numVisits=43, meanQ=3.917541, numObservations: 1
action 3, numVisits=9, meanQ=2.312222, numObservations: 2
action: 2
Next state: 1 0.653958 0.853925 0.593685 0.832154 0.199296 0.731958 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 51
Initial state: 0 0.652269 0.786956 0.558981 0.879788 0.547078 0.824574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55141 episodes
GETTING ACTION FROM:
action 2, numVisits=55133, meanQ=4.906058, numObservations: 4
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 2
Next state: 1 0.652269 0.786956 0.558981 0.879788 0.547078 0.824574 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 52
Initial state: 0 0.657853 0.891553 0.89387 0.239138 0.617114 0.813248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55217 episodes
GETTING ACTION FROM:
action 1, numVisits=55175, meanQ=5.010408, numObservations: 5
action -1, numVisits=37, meanQ=3.790760, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.657853 0.891553 0.89387 0.239138 0.617114 0.813248 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 53
Initial state: 0 0.55888 0.889112 0.408385 0.168023 0.640057 0.80426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51664 episodes
GETTING ACTION FROM:
action 2, numVisits=51654, meanQ=4.826467, numObservations: 5
action 1, numVisits=5, meanQ=0.196000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.55888 0.889112 0.408385 0.168023 0.640057 0.80426 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6652, meanQ=8.322352, numObservations: 5
action 3, numVisits=9, meanQ=5.876667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46499 episodes
GETTING ACTION FROM:
action 1, numVisits=52931, meanQ=6.139411, numObservations: 5
action 3, numVisits=218, meanQ=5.493257, numObservations: 3
action 2, numVisits=8, meanQ=4.512500, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 1
Next state: 1 0.55888 0.889112 0.408385 0.168023 0.640057 0.80426 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 54
Initial state: 0 0.593205 0.813781 0.337604 0.187641 0.615154 0.865106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54703 episodes
GETTING ACTION FROM:
action 1, numVisits=53766, meanQ=4.905142, numObservations: 4
action -1, numVisits=869, meanQ=3.166510, numObservations: 1
action 0, numVisits=62, meanQ=2.664831, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.593205 0.813781 0.337604 0.187641 0.615154 0.865106 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 55
Initial state: 0 0.623689 0.892728 0.553928 0.845734 0.850727 0.760892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54864 episodes
GETTING ACTION FROM:
action 3, numVisits=54858, meanQ=4.919426, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.623689 0.892728 0.553928 0.845734 0.850727 0.760892 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 56
Initial state: 0 0.540865 0.822025 0.558342 0.833608 0.867441 0.678646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32474 episodes
GETTING ACTION FROM:
action 0, numVisits=32465, meanQ=2.918150, numObservations: 1
action 2, numVisits=4, meanQ=-1.047500, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.540865 0.822025 0.558342 0.833608 0.867441 0.678646 w: 1
Observation: 0 0 0.814612 0 0.912201 0 0.695698 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32437, meanQ=5.021042, numObservations: 4
action 3, numVisits=22, meanQ=3.272277, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55390 episodes
GETTING ACTION FROM:
action 1, numVisits=87824, meanQ=5.121792, numObservations: 4
action 3, numVisits=23, meanQ=2.912617, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.540865 0.822025 0.558342 0.833608 0.867441 0.678646 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 57
Initial state: 0 0.527668 0.815247 0.651919 0.828315 0.445594 0.700925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54905 episodes
GETTING ACTION FROM:
action 3, numVisits=54899, meanQ=4.908909, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.527668 0.815247 0.651919 0.828315 0.445594 0.700925 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6965, meanQ=8.377624, numObservations: 4
action 1, numVisits=23, meanQ=6.916957, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 49206 episodes
GETTING ACTION FROM:
action 2, numVisits=38690, meanQ=6.181287, numObservations: 4
action 1, numVisits=17500, meanQ=6.127196, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.527668 0.815247 0.651919 0.828315 0.445594 0.700925 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 58
Initial state: 0 0.585846 0.802646 0.588955 0.865391 0.789307 0.414625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54923 episodes
GETTING ACTION FROM:
action 1, numVisits=54916, meanQ=4.894549, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.585846 0.802646 0.588955 0.865391 0.789307 0.414625 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 59
Initial state: 0 0.537521 0.892311 0.999159 0.710131 0.681224 0.856074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55289 episodes
GETTING ACTION FROM:
action 2, numVisits=42826, meanQ=4.993920, numObservations: 3
action 1, numVisits=12454, meanQ=4.903237, numObservations: 4
action 3, numVisits=5, meanQ=1.780000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.537521 0.892311 0.999159 0.710131 0.681224 0.856074 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 60
Initial state: 0 0.603634 0.803096 0.518734 0.832809 0.881649 0.93511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55168 episodes
GETTING ACTION FROM:
action 2, numVisits=55058, meanQ=5.020787, numObservations: 5
action -1, numVisits=53, meanQ=4.085884, numObservations: 1
action 0, numVisits=37, meanQ=3.945697, numObservations: 1
action 3, numVisits=9, meanQ=2.553344, numObservations: 3
action 1, numVisits=11, meanQ=2.100000, numObservations: 4
action: 2
Next state: 1 0.603634 0.803096 0.518734 0.832809 0.881649 0.93511 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 61
Initial state: 0 0.875028 0.915417 0.532125 0.809474 0.597882 0.866895 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48864 episodes
GETTING ACTION FROM:
action 1, numVisits=39711, meanQ=4.934770, numObservations: 4
action -1, numVisits=9140, meanQ=2.949625, numObservations: 1
action 2, numVisits=8, meanQ=-0.001250, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.875028 0.915417 0.532125 0.809474 0.597882 0.866895 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 62
Initial state: 0 0.967917 0.361307 0.6756 0.855582 0.637232 0.861568 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50549 episodes
GETTING ACTION FROM:
action 1, numVisits=50514, meanQ=4.721113, numObservations: 4
action 2, numVisits=24, meanQ=3.249171, numObservations: 3
action 3, numVisits=7, meanQ=2.155714, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.967917 0.361307 0.6756 0.855582 0.637232 0.861568 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 63
Initial state: 0 0.569538 0.818133 0.510065 0.866835 0.542252 0.143747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55215 episodes
GETTING ACTION FROM:
action 2, numVisits=55204, meanQ=4.921313, numObservations: 4
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.569538 0.818133 0.510065 0.866835 0.542252 0.143747 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 64
Initial state: 0 0.572171 0.878522 0.583744 0.809017 0.406199 0.169108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55256 episodes
GETTING ACTION FROM:
action 2, numVisits=55249, meanQ=4.980551, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.572171 0.878522 0.583744 0.809017 0.406199 0.169108 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 65
Initial state: 0 0.505181 0.815872 0.635212 0.852096 0.376504 0.300537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55088 episodes
GETTING ACTION FROM:
action 3, numVisits=52219, meanQ=4.917191, numObservations: 4
action 2, numVisits=2838, meanQ=4.802860, numObservations: 3
action 1, numVisits=27, meanQ=3.665930, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.505181 0.815872 0.635212 0.852096 0.376504 0.300537 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 66
Initial state: 0 0.604217 0.830949 0.253525 0.632609 0.668016 0.812342 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55497 episodes
GETTING ACTION FROM:
action 3, numVisits=55484, meanQ=4.970398, numObservations: 4
action 1, numVisits=8, meanQ=1.500000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.604217 0.830949 0.253525 0.632609 0.668016 0.812342 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8426, meanQ=8.288956, numObservations: 5
action 1, numVisits=40, meanQ=7.145255, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 47722 episodes
GETTING ACTION FROM:
action 2, numVisits=28725, meanQ=6.583010, numObservations: 5
action 1, numVisits=27450, meanQ=6.320419, numObservations: 4
action 0, numVisits=13, meanQ=0.817692, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.604217 0.830949 0.253525 0.632609 0.668016 0.812342 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=166, meanQ=8.378314, numObservations: 3
action 3, numVisits=47, meanQ=7.168306, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 65625 episodes
GETTING ACTION FROM:
action 1, numVisits=65675, meanQ=6.452862, numObservations: 4
action 3, numVisits=163, meanQ=6.385953, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.604217 0.830949 0.253525 0.632609 0.668016 0.812342 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 67
Initial state: 0 0.522315 0.884723 0.543536 0.875938 0.0559793 0.296507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55021 episodes
GETTING ACTION FROM:
action 3, numVisits=55000, meanQ=4.877083, numObservations: 4
action 2, numVisits=11, meanQ=2.801827, numObservations: 2
action 1, numVisits=6, meanQ=1.331683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.522315 0.884723 0.543536 0.875938 0.0559793 0.296507 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7112, meanQ=8.410702, numObservations: 3
action 1, numVisits=3, meanQ=4.996667, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 48021 episodes
GETTING ACTION FROM:
action 2, numVisits=43170, meanQ=6.209802, numObservations: 3
action 1, numVisits=11955, meanQ=5.952492, numObservations: 3
action -1, numVisits=11, meanQ=0.520000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.522315 0.884723 0.543536 0.875938 0.0559793 0.296507 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 68
Initial state: 0 0.887766 0.555425 0.546681 0.892997 0.593989 0.887226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54948 episodes
GETTING ACTION FROM:
action 1, numVisits=54936, meanQ=4.882073, numObservations: 4
action 2, numVisits=6, meanQ=-1.670000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.887766 0.555425 0.546681 0.892997 0.593989 0.887226 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 69
Initial state: 0 0.523744 0.845531 0.647236 0.868542 0.0883423 0.299308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54981 episodes
GETTING ACTION FROM:
action 3, numVisits=54966, meanQ=4.990541, numObservations: 5
action 1, numVisits=10, meanQ=2.189000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.523744 0.845531 0.647236 0.868542 0.0883423 0.299308 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6855, meanQ=8.360179, numObservations: 3
action 2, numVisits=187, meanQ=7.973230, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46545 episodes
GETTING ACTION FROM:
action 1, numVisits=45791, meanQ=6.268072, numObservations: 3
action 2, numVisits=7794, meanQ=5.943903, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.523744 0.845531 0.647236 0.868542 0.0883423 0.299308 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 70
Initial state: 0 0.550317 0.88866 0.621024 0.838282 0.718589 0.909485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55135 episodes
GETTING ACTION FROM:
action 2, numVisits=55129, meanQ=4.910957, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.550317 0.88866 0.621024 0.838282 0.718589 0.909485 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3982, meanQ=4.842589, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 66823 episodes
GETTING ACTION FROM:
action 1, numVisits=70803, meanQ=5.654259, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.550317 0.88866 0.621024 0.838282 0.718589 0.909485 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 71
Initial state: 0 0.554504 0.807215 0.658486 0.884903 0.691962 0.648455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55251 episodes
GETTING ACTION FROM:
action 3, numVisits=55111, meanQ=5.034083, numObservations: 3
action 0, numVisits=127, meanQ=4.472376, numObservations: 2
action 2, numVisits=10, meanQ=2.598000, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.554504 0.807215 0.658486 0.884903 0.691962 0.648455 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 72
Initial state: 0 0.549979 0.882372 0.603093 0.856215 0.0110953 0.0603633 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55237 episodes
GETTING ACTION FROM:
action 2, numVisits=55187, meanQ=4.868866, numObservations: 5
action 0, numVisits=31, meanQ=3.647591, numObservations: 1
action 1, numVisits=16, meanQ=2.498750, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.549979 0.882372 0.603093 0.856215 0.0110953 0.0603633 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 73
Initial state: 0 0.59649 0.882293 0.573967 0.84923 0.708082 0.862521 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55167 episodes
GETTING ACTION FROM:
action 1, numVisits=55086, meanQ=4.945727, numObservations: 5
action -1, numVisits=52, meanQ=4.030748, numObservations: 1
action 3, numVisits=18, meanQ=2.678344, numObservations: 4
action 2, numVisits=9, meanQ=2.333344, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.59649 0.882293 0.573967 0.84923 0.708082 0.862521 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 74
Initial state: 0 0.678404 0.759354 0.535625 0.801382 0.522673 0.860354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54873 episodes
GETTING ACTION FROM:
action 3, numVisits=54861, meanQ=4.899697, numObservations: 4
action 1, numVisits=6, meanQ=0.981667, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.678404 0.759354 0.535625 0.801382 0.522673 0.860354 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 75
Initial state: 0 0.681584 0.872146 0.547468 0.842966 0.865043 0.968576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55198 episodes
GETTING ACTION FROM:
action 3, numVisits=55188, meanQ=4.983048, numObservations: 4
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.681584 0.872146 0.547468 0.842966 0.865043 0.968576 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 76
Initial state: 0 0.571214 0.881522 0.663063 0.837382 0.810955 0.337615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55370 episodes
GETTING ACTION FROM:
action 1, numVisits=55356, meanQ=4.943481, numObservations: 3
action 2, numVisits=9, meanQ=2.553344, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.571214 0.881522 0.663063 0.837382 0.810955 0.337615 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 77
Initial state: 0 0.696725 0.851731 0.544662 0.920925 0.600279 0.878286 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55231 episodes
GETTING ACTION FROM:
action 1, numVisits=55216, meanQ=5.103664, numObservations: 4
action 2, numVisits=9, meanQ=1.664478, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.696725 0.851731 0.544662 0.920925 0.600279 0.878286 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 78
Initial state: 0 0.62089 0.812255 0.664162 0.88492 0.891676 0.97933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53279 episodes
GETTING ACTION FROM:
action 3, numVisits=53253, meanQ=4.852446, numObservations: 5
action 1, numVisits=21, meanQ=3.094286, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.62089 0.812255 0.664162 0.88492 0.891676 0.97933 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 79
Initial state: 0 0.296958 0.380158 0.664264 0.846258 0.555983 0.807886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55486 episodes
GETTING ACTION FROM:
action 1, numVisits=55459, meanQ=4.958473, numObservations: 4
action -1, numVisits=19, meanQ=3.337386, numObservations: 1
action 2, numVisits=5, meanQ=1.000020, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.296958 0.380158 0.664264 0.846258 0.555983 0.807886 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5880, meanQ=8.294376, numObservations: 4
action 2, numVisits=2638, meanQ=8.242604, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 50679 episodes
GETTING ACTION FROM:
action 2, numVisits=18215, meanQ=6.296087, numObservations: 3
action 3, numVisits=40969, meanQ=5.946390, numObservations: 4
action 0, numVisits=13, meanQ=0.817692, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.296958 0.380158 0.664264 0.846258 0.555983 0.807886 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 80
Initial state: 0 0.631876 0.810488 0.956911 0.180767 0.694816 0.842354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55289 episodes
GETTING ACTION FROM:
action 3, numVisits=55238, meanQ=4.968661, numObservations: 4
action 0, numVisits=45, meanQ=3.996220, numObservations: 1
action 2, numVisits=3, meanQ=0.330033, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.631876 0.810488 0.956911 0.180767 0.694816 0.842354 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 81
Initial state: 0 0.501802 0.959662 0.596615 0.82543 0.51225 0.854224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53989 episodes
GETTING ACTION FROM:
action 1, numVisits=52677, meanQ=5.002201, numObservations: 4
action 0, numVisits=1294, meanQ=2.829257, numObservations: 1
action 3, numVisits=9, meanQ=0.998900, numObservations: 4
action 2, numVisits=7, meanQ=-0.145714, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.501802 0.959662 0.596615 0.82543 0.51225 0.854224 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 82
Initial state: 0 0.552564 0.831294 0.900753 0.463266 0.662167 0.884735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55300 episodes
GETTING ACTION FROM:
action 2, numVisits=55229, meanQ=4.887965, numObservations: 3
action 0, numVisits=60, meanQ=4.012118, numObservations: 1
action 1, numVisits=8, meanQ=2.498750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.552564 0.831294 0.900753 0.463266 0.662167 0.884735 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 83
Initial state: 0 0.576689 0.879908 0.646017 0.805427 0.97961 0.675098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54936 episodes
GETTING ACTION FROM:
action 1, numVisits=54870, meanQ=4.952318, numObservations: 4
action 0, numVisits=61, meanQ=4.115288, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.576689 0.879908 0.646017 0.805427 0.97961 0.675098 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 84
Initial state: 0 0.703608 0.920887 0.649863 0.810723 0.594233 0.816551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55029 episodes
GETTING ACTION FROM:
action 3, numVisits=55008, meanQ=4.850436, numObservations: 4
action 1, numVisits=16, meanQ=3.006250, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.703608 0.920887 0.649863 0.810723 0.594233 0.816551 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 85
Initial state: 0 0.543849 0.899355 0.643761 0.852417 0.885794 0.54879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55363 episodes
GETTING ACTION FROM:
action 3, numVisits=55336, meanQ=4.980528, numObservations: 4
action -1, numVisits=16, meanQ=3.077679, numObservations: 1
action 2, numVisits=8, meanQ=2.498750, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.543849 0.899355 0.643761 0.852417 0.885794 0.54879 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 86
Initial state: 0 0.629028 0.826559 0.493388 0.0217461 0.53628 0.887752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55109 episodes
GETTING ACTION FROM:
action 2, numVisits=55043, meanQ=4.863353, numObservations: 3
action 0, numVisits=24, meanQ=3.515919, numObservations: 1
action 3, numVisits=38, meanQ=3.255276, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.629028 0.826559 0.493388 0.0217461 0.53628 0.887752 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 87
Initial state: 0 0.490166 0.909021 0.606649 0.812123 0.510508 0.881812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48539 episodes
GETTING ACTION FROM:
action 3, numVisits=41587, meanQ=4.887399, numObservations: 4
action -1, numVisits=6942, meanQ=2.867356, numObservations: 1
action 2, numVisits=7, meanQ=-1.004271, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.490166 0.909021 0.606649 0.812123 0.510508 0.881812 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 88
Initial state: 0 0.668325 0.837629 0.634398 0.833079 0.990785 0.00860821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52514 episodes
GETTING ACTION FROM:
action 1, numVisits=52506, meanQ=4.737049, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.668325 0.837629 0.634398 0.833079 0.990785 0.00860821 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 89
Initial state: 0 0.606339 0.890096 0.521562 0.884229 0.119096 0.694119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32357 episodes
GETTING ACTION FROM:
action -1, numVisits=32336, meanQ=3.008577, numObservations: 1
action 2, numVisits=16, meanQ=1.123769, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.606339 0.890096 0.521562 0.884229 0.119096 0.694119 w: 1
Observation: 0 0.670796 0 0.601531 0 0.0498181 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32326, meanQ=5.041276, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55803 episodes
GETTING ACTION FROM:
action 2, numVisits=88111, meanQ=5.075739, numObservations: 4
action 1, numVisits=19, meanQ=3.286316, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.606339 0.890096 0.521562 0.884229 0.119096 0.694119 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 90
Initial state: 0 0.610616 0.813421 0.777079 0.407107 0.691179 0.862675 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55372 episodes
GETTING ACTION FROM:
action 3, numVisits=55366, meanQ=4.890788, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.610616 0.813421 0.777079 0.407107 0.691179 0.862675 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 91
Initial state: 0 0.535538 0.858818 0.619811 0.825595 0.0443422 0.988014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55366 episodes
GETTING ACTION FROM:
action 2, numVisits=55357, meanQ=5.002602, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.535538 0.858818 0.619811 0.825595 0.0443422 0.988014 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 92
Initial state: 0 0.501829 0.898468 0.432449 0.734687 0.678179 0.852616 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55421 episodes
GETTING ACTION FROM:
action 1, numVisits=55219, meanQ=4.914533, numObservations: 4
action 3, numVisits=194, meanQ=4.126111, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.501829 0.898468 0.432449 0.734687 0.678179 0.852616 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 93
Initial state: 0 0.503808 0.877197 0.631263 0.836277 0.767932 0.977954 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33091 episodes
GETTING ACTION FROM:
action 0, numVisits=33084, meanQ=5.278063, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.503808 0.877197 0.631263 0.836277 0.767932 0.977954 w: 1
Observation: 0 0 0.940286 0 0.910842 0 0.893234 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23000, meanQ=7.285806, numObservations: 4
action 3, numVisits=15, meanQ=3.134007, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 52481 episodes
GETTING ACTION FROM:
action 2, numVisits=75480, meanQ=5.849914, numObservations: 4
action 3, numVisits=15, meanQ=3.134007, numObservations: 4
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.503808 0.877197 0.631263 0.836277 0.767932 0.977954 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 94
Initial state: 0 0.596355 0.870345 0.603504 0.837375 0.27041 0.436412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54903 episodes
GETTING ACTION FROM:
action 2, numVisits=54896, meanQ=5.088556, numObservations: 4
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.596355 0.870345 0.603504 0.837375 0.27041 0.436412 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 95
Initial state: 0 0.0915802 0.156947 0.622187 0.8718 0.692218 0.815221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50827 episodes
GETTING ACTION FROM:
action 2, numVisits=48105, meanQ=4.790087, numObservations: 4
action -1, numVisits=2718, meanQ=2.869480, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0915802 0.156947 0.622187 0.8718 0.692218 0.815221 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 96
Initial state: 0 0.520454 0.82669 0.676252 0.867978 0.527706 0.881749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54795 episodes
GETTING ACTION FROM:
action 2, numVisits=54750, meanQ=4.915192, numObservations: 5
action -1, numVisits=28, meanQ=3.619242, numObservations: 1
action 3, numVisits=14, meanQ=2.980007, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.520454 0.82669 0.676252 0.867978 0.527706 0.881749 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 97
Initial state: 0 0.627634 0.8498 0.67929 0.894894 0.52949 0.822633 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54743 episodes
GETTING ACTION FROM:
action 2, numVisits=54701, meanQ=4.893404, numObservations: 4
action 1, numVisits=37, meanQ=3.805141, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.627634 0.8498 0.67929 0.894894 0.52949 0.822633 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 98
Initial state: 0 0.519239 0.896918 0.676365 0.858286 0.193835 0.836711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52624 episodes
GETTING ACTION FROM:
action 1, numVisits=52613, meanQ=4.804716, numObservations: 4
action 3, numVisits=6, meanQ=-0.669983, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.519239 0.896918 0.676365 0.858286 0.193835 0.836711 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 99
Initial state: 0 0.547851 0.821625 0.281806 0.190979 0.63327 0.862378 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55080 episodes
GETTING ACTION FROM:
action 2, numVisits=55028, meanQ=4.872628, numObservations: 4
action -1, numVisits=41, meanQ=3.796134, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=5, meanQ=-0.582000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.547851 0.821625 0.281806 0.190979 0.63327 0.862378 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5066, meanQ=8.548536, numObservations: 3
action 3, numVisits=349, meanQ=8.310541, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 48381 episodes
GETTING ACTION FROM:
action 1, numVisits=47310, meanQ=6.158712, numObservations: 5
action 3, numVisits=6482, meanQ=5.978967, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.547851 0.821625 0.281806 0.190979 0.63327 0.862378 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 100
Initial state: 0 0.685804 0.292873 0.691841 0.844365 0.539567 0.82381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55271 episodes
GETTING ACTION FROM:
action 1, numVisits=55255, meanQ=4.959669, numObservations: 4
action 2, numVisits=9, meanQ=1.886667, numObservations: 3
action 3, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.685804 0.292873 0.691841 0.844365 0.539567 0.82381 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3956, meanQ=5.496375, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67512 episodes
GETTING ACTION FROM:
action 3, numVisits=67510, meanQ=5.658990, numObservations: 4
action 1, numVisits=3956, meanQ=5.496375, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 0 0.685804 0.292873 0.691841 0.844365 0.539567 0.82381 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1222, meanQ=6.810413, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 69528 episodes
GETTING ACTION FROM:
action 2, numVisits=70746, meanQ=5.960900, numObservations: 5
action 1, numVisits=2, meanQ=0.950000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 2
Next state: 1 0.685804 0.292873 0.691841 0.844365 0.539567 0.82381 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 101
Initial state: 0 0.500739 0.840764 0.506438 0.884173 0.520925 0.85038 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51713 episodes
GETTING ACTION FROM:
action 3, numVisits=47783, meanQ=4.957157, numObservations: 5
action 0, numVisits=3924, meanQ=2.976692, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 3
Next state: 1 0.500739 0.840764 0.506438 0.884173 0.520925 0.85038 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 102
Initial state: 0 0.660414 0.84243 0.63778 0.823583 0.537246 0.609647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55723 episodes
GETTING ACTION FROM:
action 2, numVisits=55682, meanQ=5.160084, numObservations: 5
action 0, numVisits=32, meanQ=3.967404, numObservations: 1
action 1, numVisits=5, meanQ=0.196000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.660414 0.84243 0.63778 0.823583 0.537246 0.609647 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 103
Initial state: 0 0.550804 0.854105 0.577177 0.811081 0.0812485 0.0184003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55185 episodes
GETTING ACTION FROM:
action 2, numVisits=55176, meanQ=4.960318, numObservations: 4
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.550804 0.854105 0.577177 0.811081 0.0812485 0.0184003 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 104
Initial state: 0 0.656083 0.853612 0.587779 0.894775 0.71703 0.986623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55472 episodes
GETTING ACTION FROM:
action 2, numVisits=55411, meanQ=5.131973, numObservations: 4
action 0, numVisits=26, meanQ=3.854448, numObservations: 1
action -1, numVisits=23, meanQ=3.738257, numObservations: 1
action 1, numVisits=11, meanQ=1.361818, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.656083 0.853612 0.587779 0.894775 0.71703 0.986623 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2626, meanQ=7.921754, numObservations: 4
action 1, numVisits=793, meanQ=7.787433, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 47594 episodes
GETTING ACTION FROM:
action 1, numVisits=14732, meanQ=6.007671, numObservations: 4
action 3, numVisits=36278, meanQ=5.916790, numObservations: 4
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.656083 0.853612 0.587779 0.894775 0.71703 0.986623 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 105
Initial state: 0 0.187227 0.203322 0.622366 0.833202 0.667272 0.834681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54761 episodes
GETTING ACTION FROM:
action 1, numVisits=54693, meanQ=4.829667, numObservations: 4
action 2, numVisits=34, meanQ=3.467065, numObservations: 5
action 0, numVisits=24, meanQ=3.415267, numObservations: 1
action 3, numVisits=8, meanQ=2.498750, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.187227 0.203322 0.622366 0.833202 0.667272 0.834681 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1418, meanQ=7.818484, numObservations: 4
action 3, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 44803 episodes
GETTING ACTION FROM:
action 2, numVisits=46030, meanQ=5.838769, numObservations: 4
action 3, numVisits=190, meanQ=5.189317, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-2.003300, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.187227 0.203322 0.622366 0.833202 0.667272 0.834681 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 106
Initial state: 0 0.911891 0.818738 0.654609 0.821531 0.691209 0.897925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52435 episodes
GETTING ACTION FROM:
action 2, numVisits=52323, meanQ=4.836466, numObservations: 4
action -1, numVisits=108, meanQ=1.809359, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.911891 0.818738 0.654609 0.821531 0.691209 0.897925 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 107
Initial state: 0 0.300751 0.000982839 0.647269 0.881621 0.500557 0.817846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55602 episodes
GETTING ACTION FROM:
action 3, numVisits=55496, meanQ=5.000517, numObservations: 4
action -1, numVisits=97, meanQ=4.330936, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.300751 0.000982839 0.647269 0.881621 0.500557 0.817846 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 108
Initial state: 0 0.661249 0.8005 0.535548 0.816571 0.809643 0.954544 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55066 episodes
GETTING ACTION FROM:
action 3, numVisits=55037, meanQ=4.893112, numObservations: 4
action -1, numVisits=24, meanQ=3.501567, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.661249 0.8005 0.535548 0.816571 0.809643 0.954544 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 109
Initial state: 0 0.774762 0.67686 0.557175 0.879787 0.511547 0.833867 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52589 episodes
GETTING ACTION FROM:
action 2, numVisits=52582, meanQ=4.796777, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.774762 0.67686 0.557175 0.879787 0.511547 0.833867 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 110
Initial state: 0 0.558833 0.875709 0.421015 0.0665509 0.690395 0.873415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54891 episodes
GETTING ACTION FROM:
action 3, numVisits=54885, meanQ=4.883463, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.558833 0.875709 0.421015 0.0665509 0.690395 0.873415 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 111
Initial state: 0 0.519759 0.845981 0.64219 0.0889176 0.659829 0.840756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32355 episodes
GETTING ACTION FROM:
action 0, numVisits=32345, meanQ=2.841351, numObservations: 1
action 1, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.519759 0.845981 0.64219 0.0889176 0.659829 0.840756 w: 1
Observation: 0 0 0.812958 0 0.0714447 0 0.912296 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32328, meanQ=4.875270, numObservations: 4
action -1, numVisits=12, meanQ=2.933362, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55628 episodes
GETTING ACTION FROM:
action 1, numVisits=87955, meanQ=4.946613, numObservations: 4
action -1, numVisits=12, meanQ=2.933362, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 1
Next state: 1 0.519759 0.845981 0.64219 0.0889176 0.659829 0.840756 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 112
Initial state: 0 0.595377 0.838737 0.650879 0.856544 0.697317 0.513402 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55542 episodes
GETTING ACTION FROM:
action 1, numVisits=55396, meanQ=5.007461, numObservations: 5
action 2, numVisits=88, meanQ=4.260347, numObservations: 4
action -1, numVisits=55, meanQ=4.073743, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.595377 0.838737 0.650879 0.856544 0.697317 0.513402 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 113
Initial state: 0 0.664515 0.820215 0.227541 0.640494 0.596383 0.834066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55187 episodes
GETTING ACTION FROM:
action 2, numVisits=55118, meanQ=4.935338, numObservations: 5
action 0, numVisits=51, meanQ=3.993101, numObservations: 1
action 1, numVisits=12, meanQ=2.999167, numObservations: 4
action 3, numVisits=4, meanQ=-0.025000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.664515 0.820215 0.227541 0.640494 0.596383 0.834066 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5413, meanQ=8.530973, numObservations: 3
action 3, numVisits=7, meanQ=5.284300, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 44910 episodes
GETTING ACTION FROM:
action 1, numVisits=49952, meanQ=6.316638, numObservations: 3
action 3, numVisits=374, meanQ=5.743291, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.664515 0.820215 0.227541 0.640494 0.596383 0.834066 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 114
Initial state: 0 0.473592 0.000350866 0.580647 0.884803 0.578768 0.850167 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55485 episodes
GETTING ACTION FROM:
action 3, numVisits=55479, meanQ=4.944024, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.473592 0.000350866 0.580647 0.884803 0.578768 0.850167 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 115
Initial state: 0 0.534028 0.870458 0.566057 0.809093 0.185591 0.0918998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52882 episodes
GETTING ACTION FROM:
action 1, numVisits=52101, meanQ=4.824303, numObservations: 3
action 3, numVisits=771, meanQ=4.561932, numObservations: 4
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.534028 0.870458 0.566057 0.809093 0.185591 0.0918998 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 116
Initial state: 0 0.687794 0.814036 0.359692 0.355712 0.57818 0.863885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32263 episodes
GETTING ACTION FROM:
action 0, numVisits=30589, meanQ=2.925473, numObservations: 1
action -1, numVisits=1658, meanQ=2.804009, numObservations: 1
action 3, numVisits=5, meanQ=-0.201980, numObservations: 1
action 2, numVisits=8, meanQ=-0.273737, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 0
Next state: 0 0.687794 0.814036 0.359692 0.355712 0.57818 0.863885 w: 1
Observation: 0 0 0.756707 0 0.369902 0 0.93342 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=29931, meanQ=4.898364, numObservations: 4
action 1, numVisits=650, meanQ=4.659163, numObservations: 4
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 55063 episodes
GETTING ACTION FROM:
action 2, numVisits=84987, meanQ=4.915077, numObservations: 4
action 1, numVisits=650, meanQ=4.659163, numObservations: 4
action 3, numVisits=10, meanQ=1.798020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.687794 0.814036 0.359692 0.355712 0.57818 0.863885 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=13016, meanQ=8.286195, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 47131 episodes
GETTING ACTION FROM:
action 3, numVisits=60132, meanQ=6.321666, numObservations: 4
action 1, numVisits=9, meanQ=0.998889, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-2.003300, numObservations: 1
action: 3
Next state: 1 0.687794 0.814036 0.359692 0.355712 0.57818 0.863885 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 117
Initial state: 0 0.171879 0.590226 0.563073 0.841185 0.584746 0.818149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32392 episodes
GETTING ACTION FROM:
action -1, numVisits=32368, meanQ=2.902636, numObservations: 1
action 2, numVisits=16, meanQ=1.244381, numObservations: 3
action 3, numVisits=5, meanQ=-1.402000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.171879 0.590226 0.563073 0.841185 0.584746 0.818149 w: 1
Observation: 0 0.110376 0 0.584707 0 0.51757 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32305, meanQ=4.956287, numObservations: 4
action -1, numVisits=56, meanQ=4.080343, numObservations: 1
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55140 episodes
GETTING ACTION FROM:
action 2, numVisits=87444, meanQ=5.040142, numObservations: 4
action -1, numVisits=57, meanQ=4.042449, numObservations: 1
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.171879 0.590226 0.563073 0.841185 0.584746 0.818149 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 118
Initial state: 0 0.675532 0.827019 0.87372 0.580773 0.548259 0.800947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55494 episodes
GETTING ACTION FROM:
action 2, numVisits=55464, meanQ=4.953554, numObservations: 5
action -1, numVisits=21, meanQ=3.451419, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.675532 0.827019 0.87372 0.580773 0.548259 0.800947 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 119
Initial state: 0 0.630367 0.835572 0.629146 0.824511 0.133056 0.615152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55175 episodes
GETTING ACTION FROM:
action 1, numVisits=55167, meanQ=4.988528, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.630367 0.835572 0.629146 0.824511 0.133056 0.615152 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 120
Initial state: 0 0.568213 0.864683 0.607479 0.639629 0.548233 0.899927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55071 episodes
GETTING ACTION FROM:
action 3, numVisits=55063, meanQ=4.942379, numObservations: 4
action 1, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.568213 0.864683 0.607479 0.639629 0.548233 0.899927 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 121
Initial state: 0 0.52457 0.840901 0.00704567 0.373526 0.532067 0.897002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54850 episodes
GETTING ACTION FROM:
action 2, numVisits=54773, meanQ=5.016425, numObservations: 5
action 0, numVisits=68, meanQ=4.190095, numObservations: 1
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.52457 0.840901 0.00704567 0.373526 0.532067 0.897002 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5478, meanQ=8.548716, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 50030 episodes
GETTING ACTION FROM:
action 1, numVisits=55443, meanQ=5.990157, numObservations: 4
action 3, numVisits=36, meanQ=3.385836, numObservations: 3
action 0, numVisits=29, meanQ=1.413793, numObservations: 1
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.52457 0.840901 0.00704567 0.373526 0.532067 0.897002 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 122
Initial state: 0 0.654382 0.875852 0.635226 0.831411 0.285338 0.862093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55597 episodes
GETTING ACTION FROM:
action 1, numVisits=55585, meanQ=4.991696, numObservations: 4
action 0, numVisits=4, meanQ=-2.502425, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=4, meanQ=-4.002500, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 1
Next state: 1 0.654382 0.875852 0.635226 0.831411 0.285338 0.862093 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 123
Initial state: 0 0.601846 0.810069 0.56793 0.817228 0.262721 0.420908 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52739 episodes
GETTING ACTION FROM:
action 3, numVisits=52679, meanQ=4.831266, numObservations: 4
action 2, numVisits=54, meanQ=3.952969, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.601846 0.810069 0.56793 0.817228 0.262721 0.420908 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8084, meanQ=8.244915, numObservations: 3
action 1, numVisits=28, meanQ=6.987146, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 43726 episodes
GETTING ACTION FROM:
action 2, numVisits=51440, meanQ=6.147350, numObservations: 3
action 1, numVisits=395, meanQ=5.523139, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.601846 0.810069 0.56793 0.817228 0.262721 0.420908 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=165, meanQ=7.854425, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55329 episodes
GETTING ACTION FROM:
action 2, numVisits=176, meanQ=7.789149, numObservations: 3
action 1, numVisits=55315, meanQ=6.226465, numObservations: 5
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.601846 0.810069 0.56793 0.817228 0.262721 0.420908 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 124
Initial state: 0 0.944051 0.272054 0.680819 0.857086 0.528574 0.842782 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55131 episodes
GETTING ACTION FROM:
action 2, numVisits=55024, meanQ=4.930391, numObservations: 4
action 0, numVisits=101, meanQ=1.673672, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.944051 0.272054 0.680819 0.857086 0.528574 0.842782 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 125
Initial state: 0 0.560064 0.860933 0.578139 0.846164 0.0847091 0.610881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34151 episodes
GETTING ACTION FROM:
action 0, numVisits=34042, meanQ=5.818411, numObservations: 3
action -1, numVisits=96, meanQ=2.883322, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 3
action 1, numVisits=7, meanQ=0.144314, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.560064 0.860933 0.578139 0.846164 0.0847091 0.610881 w: 1
Observation: 0 0 0.936728 0 0.795522 0 0.549438 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11001, meanQ=8.015522, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 56145 episodes
GETTING ACTION FROM:
action 2, numVisits=67143, meanQ=5.249317, numObservations: 4
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.560064 0.860933 0.578139 0.846164 0.0847091 0.610881 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 126
Initial state: 0 0.706426 0.681108 0.524273 0.801726 0.5296 0.897306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54911 episodes
GETTING ACTION FROM:
action 1, numVisits=54589, meanQ=4.949146, numObservations: 5
action 0, numVisits=212, meanQ=4.510213, numObservations: 1
action -1, numVisits=108, meanQ=4.325956, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.706426 0.681108 0.524273 0.801726 0.5296 0.897306 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 127
Initial state: 0 0.580085 0.89869 0.646255 0.82611 0.257986 0.314786 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 45402 episodes
GETTING ACTION FROM:
action 1, numVisits=31322, meanQ=4.866610, numObservations: 3
action 0, numVisits=14069, meanQ=3.064878, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.580085 0.89869 0.646255 0.82611 0.257986 0.314786 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 128
Initial state: 0 0.525608 0.879288 0.403998 0.160108 0.696759 0.882093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55023 episodes
GETTING ACTION FROM:
action 2, numVisits=54979, meanQ=4.948471, numObservations: 5
action 0, numVisits=37, meanQ=3.850747, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.525608 0.879288 0.403998 0.160108 0.696759 0.882093 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6937, meanQ=8.340296, numObservations: 4
action 1, numVisits=9, meanQ=6.331111, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 47652 episodes
GETTING ACTION FROM:
action 3, numVisits=54201, meanQ=6.164676, numObservations: 4
action 1, numVisits=387, meanQ=5.711603, numObservations: 4
action 0, numVisits=10, meanQ=0.772000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.525608 0.879288 0.403998 0.160108 0.696759 0.882093 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 129
Initial state: 0 0.0776582 0.359567 0.641969 0.857536 0.522892 0.866687 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55370 episodes
GETTING ACTION FROM:
action 2, numVisits=55287, meanQ=4.969811, numObservations: 4
action -1, numVisits=72, meanQ=4.156412, numObservations: 1
action 0, numVisits=9, meanQ=2.730000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0776582 0.359567 0.641969 0.857536 0.522892 0.866687 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 130
Initial state: 0 0.622694 0.805248 0.0277257 0.231151 0.562378 0.873909 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53331 episodes
GETTING ACTION FROM:
action 3, numVisits=53316, meanQ=4.936896, numObservations: 5
action 1, numVisits=7, meanQ=-1.287129, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.622694 0.805248 0.0277257 0.231151 0.562378 0.873909 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 131
Initial state: 0 0.546057 0.815166 0.652335 0.805869 0.677237 0.826199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55267 episodes
GETTING ACTION FROM:
action 2, numVisits=42195, meanQ=4.936649, numObservations: 4
action 1, numVisits=12874, meanQ=4.886184, numObservations: 5
action 3, numVisits=194, meanQ=4.433974, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.546057 0.815166 0.652335 0.805869 0.677237 0.826199 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 132
Initial state: 0 0.0977376 0.808105 0.652557 0.892588 0.571562 0.80902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55423 episodes
GETTING ACTION FROM:
action 3, numVisits=55416, meanQ=5.042589, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.0977376 0.808105 0.652557 0.892588 0.571562 0.80902 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=855, meanQ=6.804433, numObservations: 4
action 2, numVisits=133, meanQ=5.970484, numObservations: 3
action 3, numVisits=39, meanQ=5.352209, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 51460 episodes
GETTING ACTION FROM:
action 2, numVisits=1336, meanQ=5.816383, numObservations: 4
action 1, numVisits=51108, meanQ=5.815754, numObservations: 4
action 3, numVisits=39, meanQ=5.352209, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 2
Next state: 0 0.0977376 0.808105 0.652557 0.892588 0.571562 0.80902 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=25, meanQ=7.400000, numObservations: 3
action 1, numVisits=9, meanQ=4.775567, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 59888 episodes
GETTING ACTION FROM:
action 3, numVisits=147, meanQ=5.951633, numObservations: 4
action 2, numVisits=59590, meanQ=5.600531, numObservations: 4
action 1, numVisits=179, meanQ=4.318325, numObservations: 5
action 0, numVisits=6, meanQ=-0.350000, numObservations: 1
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 3
Next state: 1 0.0977376 0.808105 0.652557 0.892588 0.571562 0.80902 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 133
Initial state: 0 0.688562 0.874677 0.548487 0.858711 0.508498 0.407027 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54923 episodes
GETTING ACTION FROM:
action 2, numVisits=54890, meanQ=4.911140, numObservations: 5
action -1, numVisits=20, meanQ=3.305132, numObservations: 1
action 1, numVisits=10, meanQ=2.598000, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.688562 0.874677 0.548487 0.858711 0.508498 0.407027 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 134
Initial state: 0 0.133966 0.944581 0.544768 0.816182 0.510164 0.832811 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55268 episodes
GETTING ACTION FROM:
action 1, numVisits=55260, meanQ=4.864814, numObservations: 5
action 2, numVisits=3, meanQ=-0.329967, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.133966 0.944581 0.544768 0.816182 0.510164 0.832811 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3959, meanQ=4.611766, numObservations: 4
action -1, numVisits=45, meanQ=3.591133, numObservations: 1
action 1, numVisits=6, meanQ=1.001683, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 65938 episodes
GETTING ACTION FROM:
action 3, numVisits=69883, meanQ=5.604992, numObservations: 4
action -1, numVisits=52, meanQ=2.925152, numObservations: 1
action 2, numVisits=8, meanQ=2.498750, numObservations: 4
action 1, numVisits=6, meanQ=1.001683, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.133966 0.944581 0.544768 0.816182 0.510164 0.832811 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 135
Initial state: 0 0.676443 0.823112 0.563981 0.887124 0.917496 0.203458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54990 episodes
GETTING ACTION FROM:
action 3, numVisits=54967, meanQ=4.883480, numObservations: 5
action -1, numVisits=19, meanQ=3.372686, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.676443 0.823112 0.563981 0.887124 0.917496 0.203458 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 136
Initial state: 0 0.574363 0.848202 0.515928 0.88556 0.238707 0.155178 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32426 episodes
GETTING ACTION FROM:
action -1, numVisits=32414, meanQ=2.911586, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=5, meanQ=-3.001960, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action: -1
Next state: 0 0.574363 0.848202 0.515928 0.88556 0.238707 0.155178 w: 1
Observation: 0 0.661614 0 0.448316 0 0.280454 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32375, meanQ=4.985241, numObservations: 3
action 0, numVisits=20, meanQ=3.469298, numObservations: 1
action 2, numVisits=15, meanQ=1.660013, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 54621 episodes
GETTING ACTION FROM:
action 3, numVisits=86995, meanQ=5.009021, numObservations: 3
action 0, numVisits=21, meanQ=3.425618, numObservations: 1
action 2, numVisits=15, meanQ=1.660013, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.574363 0.848202 0.515928 0.88556 0.238707 0.155178 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=13493, meanQ=8.299399, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 48115 episodes
GETTING ACTION FROM:
action 2, numVisits=61509, meanQ=6.453879, numObservations: 4
action 1, numVisits=91, meanQ=5.197803, numObservations: 3
action -1, numVisits=10, meanQ=0.772000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.574363 0.848202 0.515928 0.88556 0.238707 0.155178 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 137
Initial state: 0 0.679523 0.89182 0.583666 0.840775 0.342632 0.233396 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55616 episodes
GETTING ACTION FROM:
action 1, numVisits=55571, meanQ=4.994837, numObservations: 5
action -1, numVisits=31, meanQ=3.749337, numObservations: 1
action 3, numVisits=11, meanQ=2.081827, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.679523 0.89182 0.583666 0.840775 0.342632 0.233396 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 138
Initial state: 0 0.574714 0.136427 0.595006 0.87756 0.500071 0.863556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55390 episodes
GETTING ACTION FROM:
action 1, numVisits=55383, meanQ=4.968445, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.574714 0.136427 0.595006 0.87756 0.500071 0.863556 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 139
Initial state: 0 0.594168 0.806685 0.550106 0.854052 0.673959 0.219488 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34061 episodes
GETTING ACTION FROM:
action 0, numVisits=34052, meanQ=5.437183, numObservations: 3
action 3, numVisits=4, meanQ=-0.504975, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.594168 0.806685 0.550106 0.854052 0.673959 0.219488 w: 1
Observation: 0 0 0.743537 0 0.946146 0 0.119792 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9373, meanQ=8.198601, numObservations: 3
action 2, numVisits=18, meanQ=6.110011, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55907 episodes
GETTING ACTION FROM:
action 1, numVisits=65256, meanQ=5.838315, numObservations: 3
action -1, numVisits=20, meanQ=4.325997, numObservations: 1
action 2, numVisits=23, meanQ=4.129574, numObservations: 4
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.594168 0.806685 0.550106 0.854052 0.673959 0.219488 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 140
Initial state: 0 0.622726 0.878118 0.79995 0.797904 0.618622 0.827356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55234 episodes
GETTING ACTION FROM:
action 3, numVisits=55107, meanQ=4.890822, numObservations: 5
action 0, numVisits=123, meanQ=4.317208, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.622726 0.878118 0.79995 0.797904 0.618622 0.827356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 141
Initial state: 0 0.570724 0.88249 0.00111316 0.161792 0.540303 0.838821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55415 episodes
GETTING ACTION FROM:
action 3, numVisits=55353, meanQ=4.978252, numObservations: 5
action -1, numVisits=58, meanQ=4.089687, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.570724 0.88249 0.00111316 0.161792 0.540303 0.838821 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 142
Initial state: 0 0.560494 0.880031 0.526509 0.85618 0.986187 0.139577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55130 episodes
GETTING ACTION FROM:
action 3, numVisits=55053, meanQ=4.914527, numObservations: 4
action 0, numVisits=49, meanQ=3.967320, numObservations: 1
action 2, numVisits=24, meanQ=3.075842, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.560494 0.880031 0.526509 0.85618 0.986187 0.139577 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 143
Initial state: 0 0.583408 0.802423 0.286078 0.533954 0.538602 0.807247 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54771 episodes
GETTING ACTION FROM:
action 3, numVisits=54542, meanQ=4.939133, numObservations: 5
action 2, numVisits=188, meanQ=4.441033, numObservations: 5
action -1, numVisits=38, meanQ=3.810555, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.583408 0.802423 0.286078 0.533954 0.538602 0.807247 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 144
Initial state: 0 0.68014 0.819884 0.653967 0.827342 0.687179 0.617746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55372 episodes
GETTING ACTION FROM:
action 2, numVisits=55366, meanQ=4.946916, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.68014 0.819884 0.653967 0.827342 0.687179 0.617746 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 145
Initial state: 0 0.681788 0.80718 0.603132 0.818932 0.570269 0.832776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52510 episodes
GETTING ACTION FROM:
action 3, numVisits=52494, meanQ=4.728850, numObservations: 4
action -1, numVisits=12, meanQ=2.565000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.681788 0.80718 0.603132 0.818932 0.570269 0.832776 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 146
Initial state: 0 0.151813 0.612606 0.504642 0.801368 0.555541 0.884961 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54900 episodes
GETTING ACTION FROM:
action 2, numVisits=54872, meanQ=4.886201, numObservations: 4
action 3, numVisits=23, meanQ=3.173922, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.151813 0.612606 0.504642 0.801368 0.555541 0.884961 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 147
Initial state: 0 0.620313 0.857452 0.884475 0.184733 0.606925 0.809767 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55237 episodes
GETTING ACTION FROM:
action 1, numVisits=55194, meanQ=5.017040, numObservations: 4
action -1, numVisits=38, meanQ=3.937103, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.620313 0.857452 0.884475 0.184733 0.606925 0.809767 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=491, meanQ=4.092115, numObservations: 4
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 45171 episodes
GETTING ACTION FROM:
action 2, numVisits=45658, meanQ=5.923736, numObservations: 4
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.620313 0.857452 0.884475 0.184733 0.606925 0.809767 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=25, meanQ=6.593200, numObservations: 1
action 2, numVisits=16, meanQ=3.748750, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 62087 episodes
GETTING ACTION FROM:
action 3, numVisits=39697, meanQ=5.880577, numObservations: 3
action 2, numVisits=22283, meanQ=5.543914, numObservations: 5
action 1, numVisits=11, meanQ=1.727273, numObservations: 3
action -1, numVisits=133, meanQ=-0.089507, numObservations: 1
action 0, numVisits=8, meanQ=-1.876250, numObservations: 1
action: 3
Next state: 1 0.620313 0.857452 0.884475 0.184733 0.606925 0.809767 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 148
Initial state: 0 0.128819 0.518888 0.535264 0.865386 0.579337 0.81966 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33950 episodes
GETTING ACTION FROM:
action 0, numVisits=33944, meanQ=5.037057, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.128819 0.518888 0.535264 0.865386 0.579337 0.81966 w: 1
Observation: 0 0 0.50364 0 0.912755 0 0.791174 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13133, meanQ=6.901703, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55213 episodes
GETTING ACTION FROM:
action 3, numVisits=68323, meanQ=5.335208, numObservations: 5
action -1, numVisits=23, meanQ=3.886293, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.128819 0.518888 0.535264 0.865386 0.579337 0.81966 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 149
Initial state: 0 0.636453 0.81586 0.594503 0.823189 0.200133 0.535337 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55218 episodes
GETTING ACTION FROM:
action 3, numVisits=55174, meanQ=4.974710, numObservations: 4
action -1, numVisits=27, meanQ=3.672411, numObservations: 1
action 1, numVisits=14, meanQ=2.569293, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.636453 0.81586 0.594503 0.823189 0.200133 0.535337 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8393, meanQ=8.308462, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 52122 episodes
GETTING ACTION FROM:
action 2, numVisits=60474, meanQ=6.250879, numObservations: 4
action 1, numVisits=39, meanQ=4.484872, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.636453 0.81586 0.594503 0.823189 0.200133 0.535337 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 150
Initial state: 0 0.538858 0.882843 0.553731 0.846166 0.382879 0.647839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55041 episodes
GETTING ACTION FROM:
action 2, numVisits=54987, meanQ=4.857894, numObservations: 5
action 0, numVisits=50, meanQ=3.940943, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.538858 0.882843 0.553731 0.846166 0.382879 0.647839 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 151
Initial state: 0 0.507412 0.835276 0.0552776 0.447341 0.662434 0.818207 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55561 episodes
GETTING ACTION FROM:
action 1, numVisits=55499, meanQ=4.999240, numObservations: 3
action -1, numVisits=21, meanQ=3.560263, numObservations: 1
action 0, numVisits=20, meanQ=3.456325, numObservations: 1
action 2, numVisits=16, meanQ=3.006250, numObservations: 3
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action: 1
Next state: 1 0.507412 0.835276 0.0552776 0.447341 0.662434 0.818207 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 152
Initial state: 0 0.147859 0.295712 0.59274 0.865215 0.637357 0.87522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55599 episodes
GETTING ACTION FROM:
action 3, numVisits=55593, meanQ=5.062957, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.147859 0.295712 0.59274 0.865215 0.637357 0.87522 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 153
Initial state: 0 0.769499 0.384493 0.630173 0.84843 0.613052 0.801213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 36704 episodes
GETTING ACTION FROM:
action 0, numVisits=30179, meanQ=5.637357, numObservations: 3
action 2, numVisits=6469, meanQ=4.841412, numObservations: 5
action -1, numVisits=45, meanQ=4.004347, numObservations: 1
action 3, numVisits=8, meanQ=2.498750, numObservations: 3
action 1, numVisits=3, meanQ=0.330033, numObservations: 1
action: 0
Next state: 0 0.769499 0.384493 0.630173 0.84843 0.613052 0.801213 w: 1
Observation: 0 0 0.332002 0 0.85609 0 0.886454 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7301, meanQ=8.307212, numObservations: 4
action 2, numVisits=6, meanQ=4.665017, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55521 episodes
GETTING ACTION FROM:
action 3, numVisits=62351, meanQ=5.252376, numObservations: 4
action 2, numVisits=439, meanQ=4.931809, numObservations: 4
action 0, numVisits=38, meanQ=4.128227, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.769499 0.384493 0.630173 0.84843 0.613052 0.801213 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 154
Initial state: 0 0.384666 0.604189 0.623177 0.897813 0.680233 0.829876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55144 episodes
GETTING ACTION FROM:
action 2, numVisits=55127, meanQ=4.939071, numObservations: 5
action 1, numVisits=8, meanQ=-0.001250, numObservations: 4
action 3, numVisits=5, meanQ=-0.582000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.384666 0.604189 0.623177 0.897813 0.680233 0.829876 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 155
Initial state: 0 0.562279 0.842996 0.41316 0.846248 0.534475 0.832728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55406 episodes
GETTING ACTION FROM:
action 3, numVisits=55351, meanQ=5.023726, numObservations: 4
action 2, numVisits=49, meanQ=3.767763, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.562279 0.842996 0.41316 0.846248 0.534475 0.832728 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3985, meanQ=5.662826, numObservations: 4
action 1, numVisits=23, meanQ=2.999135, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67124 episodes
GETTING ACTION FROM:
action 2, numVisits=67123, meanQ=6.073678, numObservations: 4
action 3, numVisits=3985, meanQ=5.662826, numObservations: 4
action 1, numVisits=23, meanQ=2.999135, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 2 0.562279 0.842996 0.41316 0.846248 0.534475 0.832728 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 156
Initial state: 0 0.525874 0.871341 0.680587 0.811436 0.544486 0.95326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55125 episodes
GETTING ACTION FROM:
action 3, numVisits=55112, meanQ=4.844238, numObservations: 4
action 1, numVisits=8, meanQ=-0.752487, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.525874 0.871341 0.680587 0.811436 0.544486 0.95326 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 157
Initial state: 0 0.441736 0.694008 0.619854 0.809946 0.587391 0.848672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52582 episodes
GETTING ACTION FROM:
action 1, numVisits=52513, meanQ=4.840748, numObservations: 4
action 2, numVisits=63, meanQ=3.664925, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.441736 0.694008 0.619854 0.809946 0.587391 0.848672 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6586, meanQ=8.337646, numObservations: 5
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 50892 episodes
GETTING ACTION FROM:
action 3, numVisits=33799, meanQ=6.137948, numObservations: 5
action 2, numVisits=23674, meanQ=6.103192, numObservations: 3
action -1, numVisits=6, meanQ=-0.350000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.441736 0.694008 0.619854 0.809946 0.587391 0.848672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 158
Initial state: 0 0.882393 0.749585 0.624765 0.853095 0.609457 0.870637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55629 episodes
GETTING ACTION FROM:
action 3, numVisits=55579, meanQ=4.964978, numObservations: 4
action -1, numVisits=29, meanQ=3.747213, numObservations: 1
action 0, numVisits=18, meanQ=3.316419, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.882393 0.749585 0.624765 0.853095 0.609457 0.870637 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6900, meanQ=8.367978, numObservations: 4
action 1, numVisits=10, meanQ=6.189000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 47612 episodes
GETTING ACTION FROM:
action 2, numVisits=54438, meanQ=6.143462, numObservations: 4
action 1, numVisits=77, meanQ=4.683247, numObservations: 4
action -1, numVisits=6, meanQ=-0.350000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.882393 0.749585 0.624765 0.853095 0.609457 0.870637 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 159
Initial state: 0 0.525287 0.808288 0.64148 0.844058 0.912927 0.522982 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55055 episodes
GETTING ACTION FROM:
action 2, numVisits=55045, meanQ=4.855346, numObservations: 5
action 3, numVisits=4, meanQ=-0.504975, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.525287 0.808288 0.64148 0.844058 0.912927 0.522982 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 160
Initial state: 0 0.639055 0.846373 0.682594 0.554125 0.59296 0.83967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55306 episodes
GETTING ACTION FROM:
action 2, numVisits=55178, meanQ=4.909308, numObservations: 4
action 0, numVisits=124, meanQ=4.302882, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.639055 0.846373 0.682594 0.554125 0.59296 0.83967 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 161
Initial state: 0 0.512513 0.880087 0.529154 0.802694 0.440385 0.828299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52720 episodes
GETTING ACTION FROM:
action 3, numVisits=52714, meanQ=4.819509, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.512513 0.880087 0.529154 0.802694 0.440385 0.828299 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 162
Initial state: 0 0.673817 0.829896 0.667469 0.85394 0.522427 0.853065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55274 episodes
GETTING ACTION FROM:
action 1, numVisits=55215, meanQ=4.971113, numObservations: 5
action -1, numVisits=45, meanQ=3.984212, numObservations: 1
action 2, numVisits=11, meanQ=2.453636, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.673817 0.829896 0.667469 0.85394 0.522427 0.853065 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 163
Initial state: 0 0.577146 0.894934 0.838334 0.544227 0.52674 0.818102 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52657 episodes
GETTING ACTION FROM:
action 2, numVisits=48227, meanQ=4.972760, numObservations: 5
action -1, numVisits=4426, meanQ=2.853151, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.577146 0.894934 0.838334 0.544227 0.52674 0.818102 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 164
Initial state: 0 0.842559 0.314468 0.524024 0.815245 0.500816 0.815586 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31786 episodes
GETTING ACTION FROM:
action -1, numVisits=31777, meanQ=2.745229, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.842559 0.314468 0.524024 0.815245 0.500816 0.815586 w: 1
Observation: 0 0.829459 0 0.597488 0 0.452361 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31666, meanQ=4.867370, numObservations: 5
action -1, numVisits=105, meanQ=4.162495, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54083 episodes
GETTING ACTION FROM:
action 1, numVisits=85748, meanQ=4.846535, numObservations: 5
action -1, numVisits=105, meanQ=4.162495, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 1
Next state: 2 0.842559 0.314468 0.524024 0.815245 0.500816 0.815586 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 165
Initial state: 0 0.328982 0.434095 0.555646 0.860204 0.600344 0.849836 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55030 episodes
GETTING ACTION FROM:
action 1, numVisits=55010, meanQ=4.994714, numObservations: 4
action 3, numVisits=9, meanQ=1.218900, numObservations: 3
action 2, numVisits=7, meanQ=-0.145714, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.328982 0.434095 0.555646 0.860204 0.600344 0.849836 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8352, meanQ=8.249869, numObservations: 3
action 3, numVisits=54, meanQ=7.481489, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 48129 episodes
GETTING ACTION FROM:
action 2, numVisits=37555, meanQ=6.383712, numObservations: 3
action 3, numVisits=18977, meanQ=6.047408, numObservations: 5
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.328982 0.434095 0.555646 0.860204 0.600344 0.849836 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 166
Initial state: 0 0.436038 0.505787 0.638527 0.8712 0.682884 0.806723 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55382 episodes
GETTING ACTION FROM:
action 2, numVisits=55368, meanQ=5.133787, numObservations: 4
action 3, numVisits=9, meanQ=1.665567, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.436038 0.505787 0.638527 0.8712 0.682884 0.806723 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 167
Initial state: 0 0.517429 0.818988 0.589575 0.840549 0.517454 0.764056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55345 episodes
GETTING ACTION FROM:
action 3, numVisits=54723, meanQ=5.096079, numObservations: 5
action 2, numVisits=617, meanQ=4.842294, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.517429 0.818988 0.589575 0.840549 0.517454 0.764056 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 168
Initial state: 0 0.562577 0.321484 0.583274 0.858237 0.676558 0.812855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55561 episodes
GETTING ACTION FROM:
action 2, numVisits=55549, meanQ=5.004301, numObservations: 5
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 1, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.562577 0.321484 0.583274 0.858237 0.676558 0.812855 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 169
Initial state: 0 0.644967 0.858523 0.670483 0.806673 0.593124 0.0532234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55366 episodes
GETTING ACTION FROM:
action 2, numVisits=55284, meanQ=4.879543, numObservations: 4
action 0, numVisits=56, meanQ=3.868468, numObservations: 1
action 1, numVisits=23, meanQ=3.082183, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.644967 0.858523 0.670483 0.806673 0.593124 0.0532234 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 170
Initial state: 0 0.691768 0.898229 0.691203 0.876533 0.322507 0.817324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54912 episodes
GETTING ACTION FROM:
action 2, numVisits=54863, meanQ=4.906295, numObservations: 5
action -1, numVisits=44, meanQ=3.912987, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.691768 0.898229 0.691203 0.876533 0.322507 0.817324 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 171
Initial state: 0 0.6268 0.0460471 0.6164 0.899997 0.552022 0.845824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55194 episodes
GETTING ACTION FROM:
action 1, numVisits=55187, meanQ=4.863602, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.6268 0.0460471 0.6164 0.899997 0.552022 0.845824 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 172
Initial state: 0 0.326231 0.484611 0.634457 0.8325 0.672373 0.813513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55491 episodes
GETTING ACTION FROM:
action 3, numVisits=55417, meanQ=4.962331, numObservations: 5
action 0, numVisits=53, meanQ=4.067757, numObservations: 1
action -1, numVisits=17, meanQ=3.370939, numObservations: 1
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.326231 0.484611 0.634457 0.8325 0.672373 0.813513 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 173
Initial state: 0 0.674038 0.866535 0.511979 0.802128 0.845544 0.907274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32397 episodes
GETTING ACTION FROM:
action 0, numVisits=32386, meanQ=2.914974, numObservations: 1
action 2, numVisits=6, meanQ=-1.670000, numObservations: 2
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.674038 0.866535 0.511979 0.802128 0.845544 0.907274 w: 1
Observation: 0 0 0.909518 0 0.782745 0 0.865476 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32370, meanQ=4.934887, numObservations: 4
action 3, numVisits=10, meanQ=2.789010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55924 episodes
GETTING ACTION FROM:
action 1, numVisits=88286, meanQ=4.939535, numObservations: 4
action 3, numVisits=17, meanQ=1.580594, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.674038 0.866535 0.511979 0.802128 0.845544 0.907274 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 174
Initial state: 0 0.614038 0.839133 0.671546 0.872779 0.758155 0.0274557 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55245 episodes
GETTING ACTION FROM:
action 1, numVisits=55185, meanQ=4.993838, numObservations: 4
action 0, numVisits=48, meanQ=4.047264, numObservations: 1
action 2, numVisits=9, meanQ=1.878900, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.614038 0.839133 0.671546 0.872779 0.758155 0.0274557 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 175
Initial state: 0 0.667947 0.891 0.513391 0.82619 0.415019 0.297555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55135 episodes
GETTING ACTION FROM:
action 2, numVisits=55082, meanQ=4.884284, numObservations: 5
action 0, numVisits=36, meanQ=3.790772, numObservations: 1
action -1, numVisits=15, meanQ=3.041729, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.667947 0.891 0.513391 0.82619 0.415019 0.297555 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 176
Initial state: 0 0.494152 0.227659 0.592585 0.87977 0.610557 0.855707 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55275 episodes
GETTING ACTION FROM:
action 3, numVisits=55242, meanQ=4.923903, numObservations: 5
action -1, numVisits=26, meanQ=3.610860, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.494152 0.227659 0.592585 0.87977 0.610557 0.855707 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 177
Initial state: 0 0.640316 0.815533 0.234598 0.763685 0.651624 0.82581 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55318 episodes
GETTING ACTION FROM:
action 1, numVisits=55303, meanQ=4.867736, numObservations: 3
action 2, numVisits=9, meanQ=1.665567, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.640316 0.815533 0.234598 0.763685 0.651624 0.82581 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 178
Initial state: 0 0.486736 0.157216 0.670172 0.815614 0.534568 0.86157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52942 episodes
GETTING ACTION FROM:
action 3, numVisits=52931, meanQ=4.909992, numObservations: 5
action 1, numVisits=5, meanQ=-0.201980, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.486736 0.157216 0.670172 0.815614 0.534568 0.86157 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 179
Initial state: 0 0.639745 0.839414 0.55496 0.820018 0.0206444 0.110663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55316 episodes
GETTING ACTION FROM:
action 1, numVisits=55284, meanQ=4.904301, numObservations: 5
action -1, numVisits=28, meanQ=3.640774, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.639745 0.839414 0.55496 0.820018 0.0206444 0.110663 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 180
Initial state: 0 0.616847 0.83514 0.570305 0.856297 0.199178 0.93116 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55388 episodes
GETTING ACTION FROM:
action 1, numVisits=55375, meanQ=4.968988, numObservations: 5
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.616847 0.83514 0.570305 0.856297 0.199178 0.93116 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 181
Initial state: 0 0.678744 0.875479 0.551136 0.87966 0.599425 0.7506 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54787 episodes
GETTING ACTION FROM:
action 1, numVisits=54749, meanQ=5.134502, numObservations: 4
action -1, numVisits=26, meanQ=3.786622, numObservations: 1
action 3, numVisits=9, meanQ=1.454444, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.678744 0.875479 0.551136 0.87966 0.599425 0.7506 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3541, meanQ=7.283035, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 61402 episodes
GETTING ACTION FROM:
action 1, numVisits=64941, meanQ=5.035235, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.678744 0.875479 0.551136 0.87966 0.599425 0.7506 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 182
Initial state: 0 0.288479 0.693162 0.552835 0.846638 0.627579 0.863172 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52225 episodes
GETTING ACTION FROM:
action 3, numVisits=52174, meanQ=4.804212, numObservations: 5
action -1, numVisits=46, meanQ=3.819133, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.288479 0.693162 0.552835 0.846638 0.627579 0.863172 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.306553 0.774179 0.669993 0.843473 0.642784 0.823046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55047 episodes
GETTING ACTION FROM:
action 1, numVisits=55004, meanQ=4.986126, numObservations: 4
action -1, numVisits=34, meanQ=3.845829, numObservations: 1
action 3, numVisits=6, meanQ=1.331683, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.306553 0.774179 0.669993 0.843473 0.642784 0.823046 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 184
Initial state: 0 0.540767 0.8905 0.646276 0.0394829 0.575709 0.876656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32352 episodes
GETTING ACTION FROM:
action 0, numVisits=32344, meanQ=3.091595, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.540767 0.8905 0.646276 0.0394829 0.575709 0.876656 w: 1
Observation: 0 0 0.967495 0 0.0622913 0 0.805465 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32297, meanQ=5.104165, numObservations: 5
action 0, numVisits=16, meanQ=3.451692, numObservations: 1
action 1, numVisits=20, meanQ=2.891010, numObservations: 3
action 2, numVisits=8, meanQ=2.498763, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 54882 episodes
GETTING ACTION FROM:
action 3, numVisits=87178, meanQ=5.256096, numObservations: 5
action 0, numVisits=17, meanQ=3.189240, numObservations: 1
action 1, numVisits=20, meanQ=2.891010, numObservations: 3
action 2, numVisits=8, meanQ=2.498763, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.540767 0.8905 0.646276 0.0394829 0.575709 0.876656 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 185
Initial state: 0 0.909029 0.03693 0.569571 0.895316 0.695966 0.879363 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55405 episodes
GETTING ACTION FROM:
action 3, numVisits=47363, meanQ=5.049246, numObservations: 5
action 1, numVisits=8037, meanQ=4.992398, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.909029 0.03693 0.569571 0.895316 0.695966 0.879363 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3392, meanQ=5.743770, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67693 episodes
GETTING ACTION FROM:
action 2, numVisits=67336, meanQ=5.990680, numObservations: 5
action 3, numVisits=3727, meanQ=5.663109, numObservations: 3
action 1, numVisits=22, meanQ=3.908636, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.909029 0.03693 0.569571 0.895316 0.695966 0.879363 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 186
Initial state: 0 0.677907 0.807914 0.672334 0.894592 0.0981544 0.572281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33612 episodes
GETTING ACTION FROM:
action 0, numVisits=33599, meanQ=4.731301, numObservations: 2
action 2, numVisits=9, meanQ=0.997800, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.677907 0.807914 0.672334 0.894592 0.0981544 0.572281 w: 1
Observation: 0 0 0.720028 0 0.902017 0 0.560458 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25725, meanQ=6.985498, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 54582 episodes
GETTING ACTION FROM:
action 2, numVisits=80305, meanQ=5.457223, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.677907 0.807914 0.672334 0.894592 0.0981544 0.572281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=6289, meanQ=4.850082, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67113 episodes
GETTING ACTION FROM:
action 1, numVisits=67112, meanQ=6.027600, numObservations: 5
action 3, numVisits=6289, meanQ=4.850082, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.677907 0.807914 0.672334 0.894592 0.0981544 0.572281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 187
Initial state: 0 0.671002 0.81015 0.125284 0.50324 0.66725 0.834369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55135 episodes
GETTING ACTION FROM:
action 2, numVisits=55129, meanQ=4.945751, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.671002 0.81015 0.125284 0.50324 0.66725 0.834369 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4805, meanQ=8.536328, numObservations: 3
action 1, numVisits=710, meanQ=8.399731, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 48164 episodes
GETTING ACTION FROM:
action 1, numVisits=1591, meanQ=6.787505, numObservations: 4
action 3, numVisits=52079, meanQ=6.355273, numObservations: 4
action -1, numVisits=8, meanQ=0.351250, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.671002 0.81015 0.125284 0.50324 0.66725 0.834369 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 188
Initial state: 0 0.565184 0.889979 0.661269 0.83808 0.227824 0.888145 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31476 episodes
GETTING ACTION FROM:
action 0, numVisits=31471, meanQ=2.799217, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.565184 0.889979 0.661269 0.83808 0.227824 0.888145 w: 1
Observation: 0 0 0.853907 0 0.766954 0 0.925865 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31464, meanQ=4.809206, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 52857 episodes
GETTING ACTION FROM:
action 1, numVisits=84318, meanQ=4.701820, numObservations: 3
action 3, numVisits=4, meanQ=-0.504975, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.565184 0.889979 0.661269 0.83808 0.227824 0.888145 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 189
Initial state: 0 0.691556 0.889868 0.128895 0.951253 0.507245 0.862271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 45931 episodes
GETTING ACTION FROM:
action 1, numVisits=32448, meanQ=4.943765, numObservations: 5
action 0, numVisits=13474, meanQ=2.901057, numObservations: 1
action 3, numVisits=4, meanQ=-0.504975, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 1
Next state: 1 0.691556 0.889868 0.128895 0.951253 0.507245 0.862271 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 190
Initial state: 0 0.564622 0.852996 0.593753 0.854578 0.238823 0.900731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55136 episodes
GETTING ACTION FROM:
action 2, numVisits=54885, meanQ=4.957891, numObservations: 5
action -1, numVisits=247, meanQ=3.726834, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.564622 0.852996 0.593753 0.854578 0.238823 0.900731 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 191
Initial state: 0 0.539371 0.870297 0.280968 0.0755372 0.680552 0.845682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54905 episodes
GETTING ACTION FROM:
action 2, numVisits=54899, meanQ=4.876738, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.539371 0.870297 0.280968 0.0755372 0.680552 0.845682 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3035, meanQ=7.842469, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 39533 episodes
GETTING ACTION FROM:
action 3, numVisits=42553, meanQ=6.029486, numObservations: 4
action 1, numVisits=12, meanQ=1.667508, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.539371 0.870297 0.280968 0.0755372 0.680552 0.845682 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 192
Initial state: 0 0.639444 0.828785 0.64413 0.80929 0.377594 0.783695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55222 episodes
GETTING ACTION FROM:
action 1, numVisits=55207, meanQ=4.932381, numObservations: 4
action 3, numVisits=10, meanQ=2.010010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.639444 0.828785 0.64413 0.80929 0.377594 0.783695 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 193
Initial state: 0 0.594658 0.855064 0.62269 0.825389 0.289466 0.184563 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55105 episodes
GETTING ACTION FROM:
action 3, numVisits=55085, meanQ=4.996846, numObservations: 4
action 2, numVisits=15, meanQ=0.872673, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.594658 0.855064 0.62269 0.825389 0.289466 0.184563 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8321, meanQ=8.244844, numObservations: 4
action 2, numVisits=32, meanQ=7.124694, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 50284 episodes
GETTING ACTION FROM:
action 1, numVisits=57605, meanQ=6.264774, numObservations: 4
action 2, numVisits=1018, meanQ=5.966046, numObservations: 5
action 3, numVisits=11, meanQ=4.817282, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 1
Next state: 1 0.594658 0.855064 0.62269 0.825389 0.289466 0.184563 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 194
Initial state: 0 0.509409 0.827877 0.533249 0.849703 0.316439 0.963625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55246 episodes
GETTING ACTION FROM:
action 1, numVisits=55165, meanQ=4.964690, numObservations: 4
action -1, numVisits=42, meanQ=3.943520, numObservations: 1
action 0, numVisits=37, meanQ=3.806639, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.509409 0.827877 0.533249 0.849703 0.316439 0.963625 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 195
Initial state: 0 0.584663 0.837508 0.336419 0.923943 0.612906 0.822356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54912 episodes
GETTING ACTION FROM:
action 1, numVisits=54891, meanQ=4.913415, numObservations: 4
action 3, numVisits=14, meanQ=2.714307, numObservations: 3
action 2, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.584663 0.837508 0.336419 0.923943 0.612906 0.822356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 196
Initial state: 0 0.605102 0.860301 0.691799 0.814029 0.584606 0.850933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32218 episodes
GETTING ACTION FROM:
action -1, numVisits=32196, meanQ=2.783435, numObservations: 1
action 3, numVisits=13, meanQ=0.992323, numObservations: 2
action 2, numVisits=6, meanQ=-0.669983, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.605102 0.860301 0.691799 0.814029 0.584606 0.850933 w: 1
Observation: 0 0.615987 0 0.737071 0 0.569378 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32168, meanQ=4.912701, numObservations: 3
action 0, numVisits=23, meanQ=3.533934, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55283 episodes
GETTING ACTION FROM:
action 2, numVisits=87450, meanQ=4.927664, numObservations: 3
action 0, numVisits=24, meanQ=3.513971, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.605102 0.860301 0.691799 0.814029 0.584606 0.850933 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 197
Initial state: 0 0.282988 0.0625331 0.679803 0.872758 0.631768 0.876307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54920 episodes
GETTING ACTION FROM:
action 3, numVisits=54886, meanQ=4.967667, numObservations: 4
action -1, numVisits=16, meanQ=3.277600, numObservations: 1
action 1, numVisits=15, meanQ=2.606667, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.282988 0.0625331 0.679803 0.872758 0.631768 0.876307 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 198
Initial state: 0 0.657423 0.853705 0.535556 0.887232 0.45713 0.925381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52528 episodes
GETTING ACTION FROM:
action 3, numVisits=52513, meanQ=4.808122, numObservations: 5
action 2, numVisits=8, meanQ=1.747513, numObservations: 4
action 1, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.657423 0.853705 0.535556 0.887232 0.45713 0.925381 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 199
Initial state: 0 0.00973837 0.237287 0.602278 0.840917 0.504883 0.813744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55281 episodes
GETTING ACTION FROM:
action 1, numVisits=55223, meanQ=4.873044, numObservations: 4
action 3, numVisits=30, meanQ=3.528340, numObservations: 4
action -1, numVisits=25, meanQ=3.528329, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.00973837 0.237287 0.602278 0.840917 0.504883 0.813744 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7088, meanQ=8.399951, numObservations: 4
action 2, numVisits=9, meanQ=5.890011, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 40188 episodes
GETTING ACTION FROM:
action 3, numVisits=47268, meanQ=6.257954, numObservations: 4
action 2, numVisits=12, meanQ=1.667508, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.00973837 0.237287 0.602278 0.840917 0.504883 0.813744 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 200
Initial state: 0 0.541059 0.818674 0.595044 0.81951 0.601929 0.924495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52808 episodes
GETTING ACTION FROM:
action 1, numVisits=52716, meanQ=4.769813, numObservations: 4
action -1, numVisits=83, meanQ=4.071189, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.541059 0.818674 0.595044 0.81951 0.601929 0.924495 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 201
Initial state: 0 0.658124 0.473732 0.611266 0.89297 0.686475 0.814402 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52636 episodes
GETTING ACTION FROM:
action 1, numVisits=52567, meanQ=4.902832, numObservations: 4
action 0, numVisits=54, meanQ=4.030642, numObservations: 1
action 3, numVisits=9, meanQ=2.312222, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.658124 0.473732 0.611266 0.89297 0.686475 0.814402 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6230, meanQ=8.347138, numObservations: 4
action 3, numVisits=402, meanQ=8.120062, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 43458 episodes
GETTING ACTION FROM:
action 2, numVisits=46710, meanQ=6.338291, numObservations: 4
action 3, numVisits=3378, meanQ=6.063075, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.658124 0.473732 0.611266 0.89297 0.686475 0.814402 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 202
Initial state: 0 0.582217 0.844301 0.913454 0.485095 0.640085 0.813355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52459 episodes
GETTING ACTION FROM:
action 2, numVisits=52448, meanQ=4.895793, numObservations: 4
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.582217 0.844301 0.913454 0.485095 0.640085 0.813355 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 203
Initial state: 0 0.545415 0.812741 0.631068 0.832165 0.916014 0.282532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55359 episodes
GETTING ACTION FROM:
action 1, numVisits=55346, meanQ=4.947821, numObservations: 4
action 2, numVisits=8, meanQ=1.747513, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.545415 0.812741 0.631068 0.832165 0.916014 0.282532 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 204
Initial state: 0 0.640996 0.809811 0.711895 0.491464 0.544667 0.807926 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53513 episodes
GETTING ACTION FROM:
action 2, numVisits=53392, meanQ=4.866848, numObservations: 4
action 3, numVisits=116, meanQ=4.122724, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.640996 0.809811 0.711895 0.491464 0.544667 0.807926 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1014, meanQ=4.511689, numObservations: 4
action 0, numVisits=2497, meanQ=2.877038, numObservations: 1
action -1, numVisits=363, meanQ=2.693087, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 44528 episodes
GETTING ACTION FROM:
action 1, numVisits=44902, meanQ=5.796379, numObservations: 4
action 2, numVisits=15, meanQ=2.866000, numObservations: 3
action 0, numVisits=3049, meanQ=2.238777, numObservations: 1
action -1, numVisits=437, meanQ=2.067294, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.640996 0.809811 0.711895 0.491464 0.544667 0.807926 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 205
Initial state: 0 0.500119 0.63815 0.538456 0.801007 0.647196 0.866991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54955 episodes
GETTING ACTION FROM:
action 2, numVisits=54948, meanQ=4.892963, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.500119 0.63815 0.538456 0.801007 0.647196 0.866991 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 206
Initial state: 0 0.99153 0.136711 0.654393 0.826913 0.517762 0.89689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55374 episodes
GETTING ACTION FROM:
action 1, numVisits=55277, meanQ=4.931785, numObservations: 5
action -1, numVisits=49, meanQ=3.900307, numObservations: 1
action 2, numVisits=39, meanQ=3.607951, numObservations: 3
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.99153 0.136711 0.654393 0.826913 0.517762 0.89689 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 207
Initial state: 0 0.576529 0.841999 0.341345 0.639101 0.627475 0.857742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55322 episodes
GETTING ACTION FROM:
action 2, numVisits=55190, meanQ=5.018711, numObservations: 3
action -1, numVisits=92, meanQ=4.355147, numObservations: 1
action 1, numVisits=37, meanQ=3.806768, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.576529 0.841999 0.341345 0.639101 0.627475 0.857742 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8491, meanQ=8.322040, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 36303 episodes
GETTING ACTION FROM:
action 3, numVisits=44472, meanQ=6.374308, numObservations: 3
action 1, numVisits=320, meanQ=5.317722, numObservations: 5
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.576529 0.841999 0.341345 0.639101 0.627475 0.857742 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 208
Initial state: 0 0.528383 0.893397 0.167141 0.874929 0.504037 0.855789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55419 episodes
GETTING ACTION FROM:
action 2, numVisits=55394, meanQ=4.955561, numObservations: 5
action -1, numVisits=21, meanQ=3.450736, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.528383 0.893397 0.167141 0.874929 0.504037 0.855789 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3920, meanQ=5.438222, numObservations: 4
action 3, numVisits=7, meanQ=2.127143, numObservations: 3
action 1, numVisits=4, meanQ=-0.025000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 67589 episodes
GETTING ACTION FROM:
action 3, numVisits=66340, meanQ=5.638091, numObservations: 4
action 2, numVisits=5174, meanQ=5.323910, numObservations: 5
action 1, numVisits=4, meanQ=-0.025000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.528383 0.893397 0.167141 0.874929 0.504037 0.855789 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 209
Initial state: 0 0.603744 0.823017 0.889617 0.0737292 0.666489 0.819667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32363 episodes
GETTING ACTION FROM:
action -1, numVisits=32342, meanQ=2.869960, numObservations: 1
action 1, numVisits=16, meanQ=-0.500619, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.603744 0.823017 0.889617 0.0737292 0.666489 0.819667 w: 1
Observation: 0 0.581288 0 0.849997 0 0.765322 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32255, meanQ=4.902542, numObservations: 4
action 0, numVisits=81, meanQ=1.845664, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 54813 episodes
GETTING ACTION FROM:
action 1, numVisits=87063, meanQ=5.062836, numObservations: 4
action 0, numVisits=81, meanQ=1.845664, numObservations: 1
action 2, numVisits=7, meanQ=0.985714, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.603744 0.823017 0.889617 0.0737292 0.666489 0.819667 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 210
Initial state: 0 0.157869 0.0860715 0.576394 0.845183 0.523409 0.893945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47777 episodes
GETTING ACTION FROM:
action 1, numVisits=36357, meanQ=5.138808, numObservations: 5
action -1, numVisits=11416, meanQ=3.046105, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.157869 0.0860715 0.576394 0.845183 0.523409 0.893945 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3567, meanQ=8.508331, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 50844 episodes
GETTING ACTION FROM:
action 3, numVisits=54401, meanQ=5.999840, numObservations: 5
action 2, numVisits=8, meanQ=-0.001250, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.157869 0.0860715 0.576394 0.845183 0.523409 0.893945 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 211
Initial state: 0 0.632976 0.89578 0.690731 0.834295 0.534478 0.931077 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55660 episodes
GETTING ACTION FROM:
action 1, numVisits=55652, meanQ=5.158886, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.632976 0.89578 0.690731 0.834295 0.534478 0.931077 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 212
Initial state: 0 0.565968 0.875385 0.331737 0.0054239 0.627169 0.841184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52251 episodes
GETTING ACTION FROM:
action 3, numVisits=51743, meanQ=4.878487, numObservations: 5
action 0, numVisits=500, meanQ=2.554722, numObservations: 1
action 1, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.565968 0.875385 0.331737 0.0054239 0.627169 0.841184 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 213
Initial state: 0 0.695317 0.852114 0.351121 0.611683 0.584811 0.886082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54971 episodes
GETTING ACTION FROM:
action 3, numVisits=54962, meanQ=4.930918, numObservations: 5
action 1, numVisits=3, meanQ=0.993333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.695317 0.852114 0.351121 0.611683 0.584811 0.886082 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 214
Initial state: 0 0.514339 0.850369 0.526549 0.643463 0.527281 0.82733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54822 episodes
GETTING ACTION FROM:
action 3, numVisits=54810, meanQ=4.978818, numObservations: 5
action 2, numVisits=7, meanQ=0.711443, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.514339 0.850369 0.526549 0.643463 0.527281 0.82733 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 215
Initial state: 0 0.520263 0.838228 0.426703 0.234556 0.546972 0.865606 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55153 episodes
GETTING ACTION FROM:
action 3, numVisits=55014, meanQ=5.041812, numObservations: 4
action 0, numVisits=69, meanQ=4.217787, numObservations: 1
action -1, numVisits=66, meanQ=4.213493, numObservations: 1
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.520263 0.838228 0.426703 0.234556 0.546972 0.865606 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3617, meanQ=7.330231, numObservations: 4
action 1, numVisits=4, meanQ=4.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 66410 episodes
GETTING ACTION FROM:
action 2, numVisits=59044, meanQ=5.647068, numObservations: 3
action 3, numVisits=10981, meanQ=5.513635, numObservations: 4
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 0 0.520263 0.838228 0.426703 0.234556 0.546972 0.865606 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1061, meanQ=7.775017, numObservations: 4
action 1, numVisits=94, meanQ=7.352980, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 62725 episodes
GETTING ACTION FROM:
action 1, numVisits=4062, meanQ=5.965737, numObservations: 5
action 3, numVisits=59814, meanQ=5.908195, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.520263 0.838228 0.426703 0.234556 0.546972 0.865606 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 216
Initial state: 0 0.589162 0.89154 0.585015 0.318056 0.657101 0.844985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55204 episodes
GETTING ACTION FROM:
action 1, numVisits=55190, meanQ=4.919099, numObservations: 4
action 2, numVisits=7, meanQ=2.144300, numObservations: 3
action 3, numVisits=3, meanQ=0.993333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.589162 0.89154 0.585015 0.318056 0.657101 0.844985 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 217
Initial state: 0 0.502697 0.82211 0.173258 0.377095 0.585586 0.824741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51883 episodes
GETTING ACTION FROM:
action 2, numVisits=51877, meanQ=4.829961, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.502697 0.82211 0.173258 0.377095 0.585586 0.824741 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8043, meanQ=8.248835, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 47748 episodes
GETTING ACTION FROM:
action 3, numVisits=55777, meanQ=6.397759, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action 0, numVisits=6, meanQ=-0.350000, numObservations: 1
action -1, numVisits=3, meanQ=-5.300000, numObservations: 1
action: 3
Next state: 1 0.502697 0.82211 0.173258 0.377095 0.585586 0.824741 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 218
Initial state: 0 0.50608 0.816359 0.645202 0.85088 0.46301 0.992244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55444 episodes
GETTING ACTION FROM:
action 2, numVisits=55417, meanQ=4.994262, numObservations: 4
action -1, numVisits=16, meanQ=3.272674, numObservations: 1
action 0, numVisits=9, meanQ=2.730000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.50608 0.816359 0.645202 0.85088 0.46301 0.992244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4024, meanQ=5.814966, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67245 episodes
GETTING ACTION FROM:
action 1, numVisits=66485, meanQ=5.879996, numObservations: 3
action 2, numVisits=4781, meanQ=5.650707, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.50608 0.816359 0.645202 0.85088 0.46301 0.992244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 219
Initial state: 0 0.598817 0.830309 0.0093811 0.184712 0.688608 0.801656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55103 episodes
GETTING ACTION FROM:
action 3, numVisits=55093, meanQ=4.893112, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.598817 0.830309 0.0093811 0.184712 0.688608 0.801656 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 220
Initial state: 0 0.661878 0.848394 0.625018 0.8742 0.0300575 0.255234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55113 episodes
GETTING ACTION FROM:
action 3, numVisits=55041, meanQ=4.896060, numObservations: 5
action 0, numVisits=68, meanQ=4.093100, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.661878 0.848394 0.625018 0.8742 0.0300575 0.255234 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5404, meanQ=8.486923, numObservations: 3
action 1, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 51499 episodes
GETTING ACTION FROM:
action 2, numVisits=56770, meanQ=6.237760, numObservations: 3
action 3, numVisits=17, meanQ=6.177065, numObservations: 3
action 1, numVisits=116, meanQ=5.118191, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-2.003300, numObservations: 1
action: 2
Next state: 1 0.661878 0.848394 0.625018 0.8742 0.0300575 0.255234 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 221
Initial state: 0 0.516013 0.820368 0.555891 0.802117 0.28813 0.0627349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55056 episodes
GETTING ACTION FROM:
action 2, numVisits=42595, meanQ=4.915755, numObservations: 3
action 1, numVisits=12456, meanQ=4.860119, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.516013 0.820368 0.555891 0.802117 0.28813 0.0627349 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 222
Initial state: 0 0.549901 0.868619 0.862708 0.402042 0.574283 0.899447 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54793 episodes
GETTING ACTION FROM:
action 3, numVisits=54595, meanQ=4.936117, numObservations: 5
action 2, numVisits=181, meanQ=4.255725, numObservations: 5
action 0, numVisits=14, meanQ=2.967243, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.549901 0.868619 0.862708 0.402042 0.574283 0.899447 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 223
Initial state: 0 0.547414 0.871483 0.292928 0.507181 0.675011 0.824527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55183 episodes
GETTING ACTION FROM:
action 1, numVisits=55176, meanQ=4.923502, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.547414 0.871483 0.292928 0.507181 0.675011 0.824527 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 224
Initial state: 0 0.68699 0.565769 0.642251 0.861228 0.605377 0.83569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55462 episodes
GETTING ACTION FROM:
action 1, numVisits=55433, meanQ=4.912566, numObservations: 4
action 2, numVisits=24, meanQ=2.833758, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.68699 0.565769 0.642251 0.861228 0.605377 0.83569 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2995, meanQ=7.935197, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 44227 episodes
GETTING ACTION FROM:
action 2, numVisits=42030, meanQ=6.017569, numObservations: 4
action 3, numVisits=5188, meanQ=5.728520, numObservations: 5
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 2
Next state: 1 0.68699 0.565769 0.642251 0.861228 0.605377 0.83569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 225
Initial state: 0 0.522392 0.872365 0.610877 0.686829 0.523032 0.854991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55483 episodes
GETTING ACTION FROM:
action 2, numVisits=55448, meanQ=4.967640, numObservations: 3
action 0, numVisits=23, meanQ=3.491709, numObservations: 1
action -1, numVisits=10, meanQ=2.485195, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.522392 0.872365 0.610877 0.686829 0.523032 0.854991 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 226
Initial state: 0 0.623745 0.891066 0.360796 0.291364 0.596726 0.860067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55377 episodes
GETTING ACTION FROM:
action 1, numVisits=55369, meanQ=4.987877, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.623745 0.891066 0.360796 0.291364 0.596726 0.860067 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 227
Initial state: 0 0.536421 0.896693 0.981606 0.610744 0.507393 0.84268 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55224 episodes
GETTING ACTION FROM:
action 3, numVisits=55210, meanQ=4.945985, numObservations: 5
action 1, numVisits=9, meanQ=1.440000, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.536421 0.896693 0.981606 0.610744 0.507393 0.84268 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 228
Initial state: 0 0.653793 0.852745 0.719616 0.321743 0.674835 0.880638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54630 episodes
GETTING ACTION FROM:
action 2, numVisits=54562, meanQ=4.847068, numObservations: 4
action 0, numVisits=40, meanQ=3.778088, numObservations: 1
action 1, numVisits=25, meanQ=2.431600, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.653793 0.852745 0.719616 0.321743 0.674835 0.880638 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 229
Initial state: 0 0.571066 0.815725 0.711708 0.820869 0.62449 0.829908 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55255 episodes
GETTING ACTION FROM:
action 3, numVisits=55179, meanQ=4.907994, numObservations: 4
action -1, numVisits=56, meanQ=4.048842, numObservations: 1
action 2, numVisits=17, meanQ=2.625294, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.571066 0.815725 0.711708 0.820869 0.62449 0.829908 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 230
Initial state: 0 0.595667 0.803394 0.557016 0.841154 0.675723 0.209103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52537 episodes
GETTING ACTION FROM:
action 2, numVisits=52528, meanQ=4.750784, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 2
Next state: 1 0.595667 0.803394 0.557016 0.841154 0.675723 0.209103 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 231
Initial state: 0 0.50341 0.840741 0.672388 0.86629 0.412619 0.845022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54699 episodes
GETTING ACTION FROM:
action 3, numVisits=54571, meanQ=4.880619, numObservations: 4
action 0, numVisits=59, meanQ=4.013373, numObservations: 1
action 1, numVisits=64, meanQ=3.991094, numObservations: 3
action 2, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.50341 0.840741 0.672388 0.86629 0.412619 0.845022 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1351, meanQ=7.883028, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 49332 episodes
GETTING ACTION FROM:
action 2, numVisits=12259, meanQ=6.039968, numObservations: 4
action 1, numVisits=38422, meanQ=5.818533, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.50341 0.840741 0.672388 0.86629 0.412619 0.845022 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 232
Initial state: 0 0.616166 0.814513 0.647114 0.80191 0.771256 0.243347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50800 episodes
GETTING ACTION FROM:
action 1, numVisits=44895, meanQ=4.895490, numObservations: 4
action 0, numVisits=5901, meanQ=2.898075, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.616166 0.814513 0.647114 0.80191 0.771256 0.243347 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 233
Initial state: 0 0.817277 0.282379 0.505507 0.867511 0.660767 0.823496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55033 episodes
GETTING ACTION FROM:
action 1, numVisits=54868, meanQ=4.904517, numObservations: 5
action -1, numVisits=95, meanQ=4.238367, numObservations: 1
action 0, numVisits=66, meanQ=4.110882, numObservations: 1
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.817277 0.282379 0.505507 0.867511 0.660767 0.823496 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 234
Initial state: 0 0.787902 0.463665 0.673957 0.854862 0.54053 0.827575 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54962 episodes
GETTING ACTION FROM:
action 1, numVisits=54956, meanQ=4.905003, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.787902 0.463665 0.673957 0.854862 0.54053 0.827575 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 235
Initial state: 0 0.545787 0.801712 0.517083 0.0153679 0.645406 0.892131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55497 episodes
GETTING ACTION FROM:
action 3, numVisits=55488, meanQ=5.081207, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.545787 0.801712 0.517083 0.0153679 0.645406 0.892131 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 236
Initial state: 0 0.508956 0.196477 0.68446 0.806802 0.513589 0.854876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54539 episodes
GETTING ACTION FROM:
action 3, numVisits=54531, meanQ=4.923492, numObservations: 5
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.508956 0.196477 0.68446 0.806802 0.513589 0.854876 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 237
Initial state: 0 0.512955 0.840507 0.130124 0.203004 0.56588 0.870356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54737 episodes
GETTING ACTION FROM:
action 3, numVisits=54722, meanQ=4.844792, numObservations: 3
action 1, numVisits=10, meanQ=2.598000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.512955 0.840507 0.130124 0.203004 0.56588 0.870356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 238
Initial state: 0 0.545507 0.880722 0.689944 0.83645 0.605117 0.688847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54846 episodes
GETTING ACTION FROM:
action 2, numVisits=54808, meanQ=4.905093, numObservations: 4
action 0, numVisits=25, meanQ=3.571751, numObservations: 1
action 1, numVisits=10, meanQ=1.799000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.545507 0.880722 0.689944 0.83645 0.605117 0.688847 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3918, meanQ=4.717156, numObservations: 5
action 1, numVisits=25, meanQ=3.392400, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67348 episodes
GETTING ACTION FROM:
action 1, numVisits=67369, meanQ=5.605949, numObservations: 3
action 3, numVisits=3918, meanQ=4.717156, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 1
Next state: 0 0.545507 0.880722 0.689944 0.83645 0.605117 0.688847 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1171, meanQ=7.004839, numObservations: 4
action 2, numVisits=6, meanQ=2.301667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 68820 episodes
GETTING ACTION FROM:
action 1, numVisits=69985, meanQ=5.507743, numObservations: 4
action 2, numVisits=6, meanQ=2.301667, numObservations: 3
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.545507 0.880722 0.689944 0.83645 0.605117 0.688847 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 239
Initial state: 0 0.309422 0.141484 0.566348 0.844415 0.68064 0.859626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55067 episodes
GETTING ACTION FROM:
action 2, numVisits=55060, meanQ=4.895511, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.309422 0.141484 0.566348 0.844415 0.68064 0.859626 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 240
Initial state: 0 0.658114 0.815686 0.629611 0.888177 0.677813 0.312456 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50649 episodes
GETTING ACTION FROM:
action 2, numVisits=50574, meanQ=4.582322, numObservations: 4
action 0, numVisits=42, meanQ=3.580194, numObservations: 1
action -1, numVisits=28, meanQ=3.350663, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.658114 0.815686 0.629611 0.888177 0.677813 0.312456 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 241
Initial state: 0 0.575392 0.822381 0.60554 0.523504 0.584363 0.828945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55263 episodes
GETTING ACTION FROM:
action 3, numVisits=55220, meanQ=4.939485, numObservations: 4
action -1, numVisits=37, meanQ=3.810444, numObservations: 1
action 1, numVisits=3, meanQ=-2.966667, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.575392 0.822381 0.60554 0.523504 0.584363 0.828945 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4013, meanQ=5.399473, numObservations: 3
action 2, numVisits=40, meanQ=4.192760, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 68029 episodes
GETTING ACTION FROM:
action 2, numVisits=67628, meanQ=5.821135, numObservations: 4
action 3, numVisits=4452, meanQ=5.286490, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.575392 0.822381 0.60554 0.523504 0.584363 0.828945 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 242
Initial state: 0 0.800972 0.543491 0.67218 0.859554 0.521769 0.820146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55458 episodes
GETTING ACTION FROM:
action 1, numVisits=55451, meanQ=4.965141, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.800972 0.543491 0.67218 0.859554 0.521769 0.820146 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 243
Initial state: 0 0.571648 0.888607 0.586389 0.866839 0.782945 0.769692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54894 episodes
GETTING ACTION FROM:
action 1, numVisits=54869, meanQ=4.888104, numObservations: 4
action 2, numVisits=19, meanQ=1.735795, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.571648 0.888607 0.586389 0.866839 0.782945 0.769692 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 244
Initial state: 0 0.508068 0.851458 0.607437 0.843708 0.931359 0.730242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54680 episodes
GETTING ACTION FROM:
action 1, numVisits=54664, meanQ=5.070524, numObservations: 4
action 2, numVisits=10, meanQ=2.598000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.508068 0.851458 0.607437 0.843708 0.931359 0.730242 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 245
Initial state: 0 0.556798 0.849523 0.780758 0.168705 0.692756 0.833885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54824 episodes
GETTING ACTION FROM:
action 3, numVisits=54817, meanQ=4.844071, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.556798 0.849523 0.780758 0.168705 0.692756 0.833885 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 246
Initial state: 0 0.683302 0.832176 0.553429 0.818395 0.945823 0.73005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55017 episodes
GETTING ACTION FROM:
action 1, numVisits=54987, meanQ=4.932935, numObservations: 5
action 2, numVisits=25, meanQ=3.304812, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.683302 0.832176 0.553429 0.818395 0.945823 0.73005 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 247
Initial state: 0 0.624224 0.894674 0.679171 0.855719 0.84521 0.666435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55175 episodes
GETTING ACTION FROM:
action 2, numVisits=55130, meanQ=4.922775, numObservations: 3
action 0, numVisits=41, meanQ=3.865969, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.624224 0.894674 0.679171 0.855719 0.84521 0.666435 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 248
Initial state: 0 0.686609 0.817682 0.894254 0.065882 0.594443 0.804766 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54583 episodes
GETTING ACTION FROM:
action 2, numVisits=54524, meanQ=4.981284, numObservations: 5
action -1, numVisits=37, meanQ=3.905308, numObservations: 1
action 1, numVisits=17, meanQ=2.411765, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.686609 0.817682 0.894254 0.065882 0.594443 0.804766 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 249
Initial state: 0 0.693401 0.805778 0.305266 0.857719 0.584534 0.880367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54547 episodes
GETTING ACTION FROM:
action 3, numVisits=54518, meanQ=4.948307, numObservations: 5
action -1, numVisits=23, meanQ=3.561751, numObservations: 1
action 2, numVisits=3, meanQ=0.993333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.693401 0.805778 0.305266 0.857719 0.584534 0.880367 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 250
Initial state: 0 0.60106 0.834024 0.597295 0.813381 0.372738 0.26047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55538 episodes
GETTING ACTION FROM:
action 2, numVisits=55503, meanQ=4.910304, numObservations: 5
action 0, numVisits=28, meanQ=3.648012, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.60106 0.834024 0.597295 0.813381 0.372738 0.26047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 251
Initial state: 0 0.503063 0.619063 0.601068 0.852921 0.579768 0.85246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32319 episodes
GETTING ACTION FROM:
action -1, numVisits=32310, meanQ=2.928278, numObservations: 1
action 2, numVisits=4, meanQ=-2.005000, numObservations: 2
action 0, numVisits=3, meanQ=-2.333300, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.503063 0.619063 0.601068 0.852921 0.579768 0.85246 w: 1
Observation: 0 0.532068 0 0.585194 0 0.610375 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32270, meanQ=4.965377, numObservations: 5
action 0, numVisits=32, meanQ=3.756552, numObservations: 1
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 54751 episodes
GETTING ACTION FROM:
action 1, numVisits=87020, meanQ=5.024915, numObservations: 5
action 0, numVisits=33, meanQ=3.689741, numObservations: 1
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.503063 0.619063 0.601068 0.852921 0.579768 0.85246 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 252
Initial state: 0 0.503081 0.827749 0.598833 0.618391 0.660782 0.820283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55501 episodes
GETTING ACTION FROM:
action 3, numVisits=55459, meanQ=5.020807, numObservations: 3
action 2, numVisits=30, meanQ=3.796340, numObservations: 3
action 1, numVisits=8, meanQ=2.012500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.503081 0.827749 0.598833 0.618391 0.660782 0.820283 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 253
Initial state: 0 0.577833 0.879525 0.66152 0.845452 0.387991 0.699976 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52636 episodes
GETTING ACTION FROM:
action 3, numVisits=52479, meanQ=4.852804, numObservations: 4
action -1, numVisits=49, meanQ=3.925425, numObservations: 1
action 1, numVisits=57, meanQ=3.838951, numObservations: 4
action 2, numVisits=49, meanQ=3.773069, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.577833 0.879525 0.66152 0.845452 0.387991 0.699976 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 254
Initial state: 0 0.56927 0.872923 0.534065 0.855679 0.257027 0.054357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55043 episodes
GETTING ACTION FROM:
action 1, numVisits=54828, meanQ=5.149588, numObservations: 4
action 0, numVisits=209, meanQ=1.303884, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.56927 0.872923 0.534065 0.855679 0.257027 0.054357 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3839, meanQ=7.084803, numObservations: 4
action 2, numVisits=20, meanQ=4.185500, numObservations: 3
action 3, numVisits=10, meanQ=3.198010, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 65938 episodes
GETTING ACTION FROM:
action 2, numVisits=46431, meanQ=5.575939, numObservations: 4
action 1, numVisits=23364, meanQ=5.279132, numObservations: 4
action 3, numVisits=10, meanQ=3.198010, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.56927 0.872923 0.534065 0.855679 0.257027 0.054357 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 255
Initial state: 0 0.589364 0.818053 0.155921 0.423393 0.685401 0.8531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54606 episodes
GETTING ACTION FROM:
action 3, numVisits=54600, meanQ=4.854791, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.589364 0.818053 0.155921 0.423393 0.685401 0.8531 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 256
Initial state: 0 0.543881 0.806722 0.574977 0.805271 0.277052 0.591067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55254 episodes
GETTING ACTION FROM:
action 2, numVisits=55218, meanQ=4.881411, numObservations: 4
action 0, numVisits=32, meanQ=3.696606, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.543881 0.806722 0.574977 0.805271 0.277052 0.591067 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 257
Initial state: 0 0.552849 0.824058 0.838554 0.522372 0.553861 0.851139 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55261 episodes
GETTING ACTION FROM:
action 1, numVisits=55212, meanQ=5.092018, numObservations: 4
action 0, numVisits=27, meanQ=3.809337, numObservations: 1
action 3, numVisits=18, meanQ=3.221111, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.552849 0.824058 0.838554 0.522372 0.553861 0.851139 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 258
Initial state: 0 0.516936 0.851964 0.309597 0.720979 0.631212 0.826495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34168 episodes
GETTING ACTION FROM:
action 0, numVisits=34162, meanQ=5.830148, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.516936 0.851964 0.309597 0.720979 0.631212 0.826495 w: 1
Observation: 0 0 0.897233 0 0.689583 0 0.822301 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9375, meanQ=7.994176, numObservations: 4
action 3, numVisits=1563, meanQ=7.877802, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 55334 episodes
GETTING ACTION FROM:
action 1, numVisits=58659, meanQ=5.726787, numObservations: 4
action 3, numVisits=7576, meanQ=5.676601, numObservations: 4
action -1, numVisits=38, meanQ=4.624182, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.516936 0.851964 0.309597 0.720979 0.631212 0.826495 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 259
Initial state: 0 0.635454 0.823497 0.251208 0.895074 0.553794 0.859704 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55185 episodes
GETTING ACTION FROM:
action 1, numVisits=55028, meanQ=4.867443, numObservations: 3
action 3, numVisits=110, meanQ=4.211985, numObservations: 5
action -1, numVisits=36, meanQ=3.733528, numObservations: 1
action 2, numVisits=9, meanQ=2.333344, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.635454 0.823497 0.251208 0.895074 0.553794 0.859704 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 260
Initial state: 0 0.664255 0.890233 0.596886 0.759016 0.56307 0.848845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55594 episodes
GETTING ACTION FROM:
action 1, numVisits=55546, meanQ=4.960268, numObservations: 5
action -1, numVisits=42, meanQ=3.860294, numObservations: 1
action 3, numVisits=3, meanQ=0.993333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.664255 0.890233 0.596886 0.759016 0.56307 0.848845 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 261
Initial state: 0 0.548612 0.877737 0.549243 0.550359 0.649317 0.824889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 46947 episodes
GETTING ACTION FROM:
action 1, numVisits=35905, meanQ=4.923074, numObservations: 5
action 0, numVisits=11020, meanQ=2.764840, numObservations: 1
action 3, numVisits=13, meanQ=0.993085, numObservations: 2
action 2, numVisits=7, meanQ=-0.429986, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.548612 0.877737 0.549243 0.550359 0.649317 0.824889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 262
Initial state: 0 0.513957 0.837733 0.606048 0.88553 0.428301 0.82477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55172 episodes
GETTING ACTION FROM:
action 3, numVisits=55061, meanQ=4.955021, numObservations: 4
action -1, numVisits=67, meanQ=4.151480, numObservations: 1
action 0, numVisits=42, meanQ=3.939802, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.513957 0.837733 0.606048 0.88553 0.428301 0.82477 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 263
Initial state: 0 0.686917 0.868894 0.405759 0.234025 0.642081 0.882206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54878 episodes
GETTING ACTION FROM:
action 3, numVisits=54856, meanQ=4.998881, numObservations: 5
action 1, numVisits=17, meanQ=3.222947, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.686917 0.868894 0.405759 0.234025 0.642081 0.882206 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.637953 0.892734 0.0770277 0.936037 0.56593 0.832428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52852 episodes
GETTING ACTION FROM:
action 2, numVisits=52838, meanQ=4.810583, numObservations: 5
action 3, numVisits=9, meanQ=2.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.637953 0.892734 0.0770277 0.936037 0.56593 0.832428 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 265
Initial state: 0 0.889849 0.0341796 0.606682 0.870485 0.614954 0.897772 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54858 episodes
GETTING ACTION FROM:
action 3, numVisits=54852, meanQ=4.961150, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.889849 0.0341796 0.606682 0.870485 0.614954 0.897772 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 266
Initial state: 0 0.238715 0.795919 0.662701 0.896002 0.573776 0.848256 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54791 episodes
GETTING ACTION FROM:
action 3, numVisits=54672, meanQ=4.996038, numObservations: 3
action 2, numVisits=88, meanQ=3.967163, numObservations: 3
action -1, numVisits=26, meanQ=3.596854, numObservations: 1
action 1, numVisits=3, meanQ=0.993333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.238715 0.795919 0.662701 0.896002 0.573776 0.848256 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 267
Initial state: 0 0.618592 0.89556 0.785942 0.637782 0.611272 0.870331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55893 episodes
GETTING ACTION FROM:
action 2, numVisits=43084, meanQ=4.987672, numObservations: 3
action 1, numVisits=12801, meanQ=4.839864, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.618592 0.89556 0.785942 0.637782 0.611272 0.870331 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 268
Initial state: 0 0.601512 0.851214 0.334806 0.736495 0.619319 0.891698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55340 episodes
GETTING ACTION FROM:
action 2, numVisits=55313, meanQ=4.897112, numObservations: 5
action -1, numVisits=18, meanQ=3.338613, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.601512 0.851214 0.334806 0.736495 0.619319 0.891698 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5572, meanQ=8.359258, numObservations: 3
action 3, numVisits=1329, meanQ=8.272572, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 50043 episodes
GETTING ACTION FROM:
action 1, numVisits=25191, meanQ=6.557518, numObservations: 3
action 3, numVisits=31749, meanQ=6.181540, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.601512 0.851214 0.334806 0.736495 0.619319 0.891698 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 269
Initial state: 0 0.633777 0.836192 0.587661 0.836969 0.340638 0.261748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52726 episodes
GETTING ACTION FROM:
action 2, numVisits=52654, meanQ=4.809654, numObservations: 4
action 3, numVisits=67, meanQ=3.517794, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.633777 0.836192 0.587661 0.836969 0.340638 0.261748 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 270
Initial state: 0 0.673535 0.146091 0.542485 0.849801 0.539396 0.837233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55033 episodes
GETTING ACTION FROM:
action 2, numVisits=55027, meanQ=4.903662, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.673535 0.146091 0.542485 0.849801 0.539396 0.837233 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 271
Initial state: 0 0.529515 0.827095 0.66907 0.884907 0.565439 0.891684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52285 episodes
GETTING ACTION FROM:
action 1, numVisits=52096, meanQ=4.823183, numObservations: 3
action -1, numVisits=149, meanQ=4.285699, numObservations: 1
action 3, numVisits=36, meanQ=3.653892, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.529515 0.827095 0.66907 0.884907 0.565439 0.891684 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 272
Initial state: 0 0.245947 0.598516 0.58668 0.871026 0.502006 0.895626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54915 episodes
GETTING ACTION FROM:
action 2, numVisits=54899, meanQ=4.842672, numObservations: 5
action 0, numVisits=12, meanQ=2.399312, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.245947 0.598516 0.58668 0.871026 0.502006 0.895626 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 273
Initial state: 0 0.379808 0.779003 0.595276 0.807474 0.527792 0.875332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55006 episodes
GETTING ACTION FROM:
action 3, numVisits=54999, meanQ=4.905264, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.379808 0.779003 0.595276 0.807474 0.527792 0.875332 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 274
Initial state: 0 0.624433 0.879113 0.501303 0.471794 0.514361 0.800362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32060 episodes
GETTING ACTION FROM:
action -1, numVisits=32052, meanQ=2.822324, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.624433 0.879113 0.501303 0.471794 0.514361 0.800362 w: 1
Observation: 0 0.540545 0 0.567497 0 0.452606 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32043, meanQ=4.981140, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 54862 episodes
GETTING ACTION FROM:
action 3, numVisits=51031, meanQ=5.074477, numObservations: 4
action 1, numVisits=35875, meanQ=4.957964, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 3
Next state: 1 0.624433 0.879113 0.501303 0.471794 0.514361 0.800362 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 275
Initial state: 0 0.0916523 0.444258 0.515432 0.823556 0.641548 0.81889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55236 episodes
GETTING ACTION FROM:
action 3, numVisits=55230, meanQ=4.812551, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0916523 0.444258 0.515432 0.823556 0.641548 0.81889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 276
Initial state: 0 0.350348 0.257302 0.516995 0.838142 0.539431 0.8185 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55041 episodes
GETTING ACTION FROM:
action 1, numVisits=54712, meanQ=4.946823, numObservations: 4
action -1, numVisits=325, meanQ=1.948978, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.350348 0.257302 0.516995 0.838142 0.539431 0.8185 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7016, meanQ=8.318653, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 50866 episodes
GETTING ACTION FROM:
action 2, numVisits=53964, meanQ=6.194763, numObservations: 3
action 3, numVisits=3915, meanQ=5.898251, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.350348 0.257302 0.516995 0.838142 0.539431 0.8185 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 277
Initial state: 0 0.686612 0.194047 0.520515 0.877636 0.641696 0.834712 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55095 episodes
GETTING ACTION FROM:
action 3, numVisits=55071, meanQ=4.952018, numObservations: 4
action 2, numVisits=19, meanQ=2.051589, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.686612 0.194047 0.520515 0.877636 0.641696 0.834712 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.299133 0.399523 0.697818 0.821095 0.604828 0.864266 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55373 episodes
GETTING ACTION FROM:
action 3, numVisits=55367, meanQ=5.016753, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.299133 0.399523 0.697818 0.821095 0.604828 0.864266 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 279
Initial state: 0 0.378522 0.944376 0.622184 0.879131 0.506754 0.835373 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51873 episodes
GETTING ACTION FROM:
action 3, numVisits=46784, meanQ=4.988842, numObservations: 5
action -1, numVisits=5082, meanQ=2.750767, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=4, meanQ=-2.502475, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.378522 0.944376 0.622184 0.879131 0.506754 0.835373 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 280
Initial state: 0 0.409322 0.332433 0.667105 0.890851 0.515754 0.83846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55335 episodes
GETTING ACTION FROM:
action 3, numVisits=55276, meanQ=5.034366, numObservations: 5
action 0, numVisits=32, meanQ=3.846051, numObservations: 1
action 2, numVisits=23, meanQ=3.521743, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.409322 0.332433 0.667105 0.890851 0.515754 0.83846 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 281
Initial state: 0 0.326354 0.659286 0.660877 0.860791 0.526464 0.847967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55310 episodes
GETTING ACTION FROM:
action 1, numVisits=55298, meanQ=4.948264, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=6, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.326354 0.659286 0.660877 0.860791 0.526464 0.847967 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6986, meanQ=8.279082, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46497 episodes
GETTING ACTION FROM:
action 2, numVisits=53475, meanQ=6.093289, numObservations: 4
action -1, numVisits=6, meanQ=-0.350000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.326354 0.659286 0.660877 0.860791 0.526464 0.847967 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 282
Initial state: 0 0.594432 0.832824 0.606874 0.730321 0.679375 0.87546 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54839 episodes
GETTING ACTION FROM:
action 3, numVisits=54833, meanQ=4.862067, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.594432 0.832824 0.606874 0.730321 0.679375 0.87546 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3867, meanQ=4.460486, numObservations: 3
action 0, numVisits=26, meanQ=3.319461, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 66406 episodes
GETTING ACTION FROM:
action 2, numVisits=70272, meanQ=5.500960, numObservations: 3
action 0, numVisits=27, meanQ=3.327411, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.594432 0.832824 0.606874 0.730321 0.679375 0.87546 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 283
Initial state: 0 0.551824 0.893768 0.53547 0.89578 0.813302 0.371094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 45293 episodes
GETTING ACTION FROM:
action 1, numVisits=30568, meanQ=4.953248, numObservations: 4
action 0, numVisits=14719, meanQ=3.134853, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.551824 0.893768 0.53547 0.89578 0.813302 0.371094 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 284
Initial state: 0 0.563554 0.805582 0.672633 0.829682 0.970759 0.35306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55309 episodes
GETTING ACTION FROM:
action 2, numVisits=55303, meanQ=4.931341, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.563554 0.805582 0.672633 0.829682 0.970759 0.35306 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 285
Initial state: 0 0.0871435 0.783629 0.595288 0.82473 0.680139 0.866305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54279 episodes
GETTING ACTION FROM:
action 3, numVisits=52950, meanQ=4.950238, numObservations: 5
action -1, numVisits=1323, meanQ=2.645551, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0871435 0.783629 0.595288 0.82473 0.680139 0.866305 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 286
Initial state: 0 0.598133 0.837775 0.689984 0.567866 0.630571 0.817726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55354 episodes
GETTING ACTION FROM:
action 2, numVisits=55322, meanQ=4.995769, numObservations: 5
action -1, numVisits=22, meanQ=3.547470, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.598133 0.837775 0.689984 0.567866 0.630571 0.817726 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 287
Initial state: 0 0.590183 0.511721 0.6589 0.848012 0.604995 0.857548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52143 episodes
GETTING ACTION FROM:
action 1, numVisits=52136, meanQ=4.359851, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.590183 0.511721 0.6589 0.848012 0.604995 0.857548 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 288
Initial state: 0 0.102304 0.899553 0.548608 0.815066 0.560321 0.845299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55232 episodes
GETTING ACTION FROM:
action 3, numVisits=55226, meanQ=5.035919, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.102304 0.899553 0.548608 0.815066 0.560321 0.845299 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 289
Initial state: 0 0.863684 0.735964 0.54452 0.817817 0.607481 0.853423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55071 episodes
GETTING ACTION FROM:
action 2, numVisits=55061, meanQ=4.907494, numObservations: 4
action 3, numVisits=5, meanQ=-1.402000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.863684 0.735964 0.54452 0.817817 0.607481 0.853423 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 290
Initial state: 0 0.681753 0.880644 0.337459 0.544044 0.510033 0.899349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55398 episodes
GETTING ACTION FROM:
action 2, numVisits=55378, meanQ=4.979394, numObservations: 5
action 1, numVisits=14, meanQ=1.570000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.681753 0.880644 0.337459 0.544044 0.510033 0.899349 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 291
Initial state: 0 0.851459 0.0635963 0.53453 0.885376 0.554852 0.814474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55505 episodes
GETTING ACTION FROM:
action 1, numVisits=54984, meanQ=5.113846, numObservations: 5
action 2, numVisits=497, meanQ=4.689180, numObservations: 3
action 0, numVisits=21, meanQ=3.542478, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.851459 0.0635963 0.53453 0.885376 0.554852 0.814474 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 292
Initial state: 0 0.544579 0.829029 0.686807 0.899089 0.596274 0.831027 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55222 episodes
GETTING ACTION FROM:
action 2, numVisits=55185, meanQ=4.948300, numObservations: 4
action 0, numVisits=33, meanQ=1.592881, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.544579 0.829029 0.686807 0.899089 0.596274 0.831027 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 293
Initial state: 0 0.0878712 0.858227 0.567664 0.873411 0.546463 0.8603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55413 episodes
GETTING ACTION FROM:
action 1, numVisits=54969, meanQ=4.922882, numObservations: 4
action 2, numVisits=424, meanQ=4.346444, numObservations: 3
action 3, numVisits=16, meanQ=2.750000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0878712 0.858227 0.567664 0.873411 0.546463 0.8603 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1340, meanQ=7.852857, numObservations: 5
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 49798 episodes
GETTING ACTION FROM:
action 2, numVisits=39834, meanQ=5.948605, numObservations: 5
action 3, numVisits=11302, meanQ=5.780400, numObservations: 5
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0878712 0.858227 0.567664 0.873411 0.546463 0.8603 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 294
Initial state: 0 0.342595 0.642839 0.585382 0.80382 0.678848 0.847628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55020 episodes
GETTING ACTION FROM:
action 2, numVisits=54806, meanQ=5.149730, numObservations: 5
action 1, numVisits=133, meanQ=4.530675, numObservations: 3
action -1, numVisits=78, meanQ=4.417464, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.342595 0.642839 0.585382 0.80382 0.678848 0.847628 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 295
Initial state: 0 0.584884 0.800752 0.59055 0.892379 0.432294 0.308924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32342 episodes
GETTING ACTION FROM:
action 0, numVisits=32332, meanQ=2.939972, numObservations: 1
action 2, numVisits=5, meanQ=-0.201980, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.584884 0.800752 0.59055 0.892379 0.432294 0.308924 w: 1
Observation: 0 0 0.892837 0 0.915949 0 0.246416 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32303, meanQ=5.004256, numObservations: 4
action 0, numVisits=23, meanQ=3.634599, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55336 episodes
GETTING ACTION FROM:
action 2, numVisits=87638, meanQ=4.943114, numObservations: 4
action 0, numVisits=24, meanQ=3.451580, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.584884 0.800752 0.59055 0.892379 0.432294 0.308924 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 296
Initial state: 0 0.230375 0.214447 0.589256 0.871136 0.545641 0.821554 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55791 episodes
GETTING ACTION FROM:
action 1, numVisits=55762, meanQ=4.990489, numObservations: 4
action -1, numVisits=21, meanQ=3.553420, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.230375 0.214447 0.589256 0.871136 0.545641 0.821554 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8069, meanQ=8.243403, numObservations: 4
action 3, numVisits=199, meanQ=7.804825, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 52031 episodes
GETTING ACTION FROM:
action 2, numVisits=28008, meanQ=6.511008, numObservations: 4
action 3, numVisits=32284, meanQ=6.181005, numObservations: 5
action 1, numVisits=5, meanQ=5.780000, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=3, meanQ=-2.003300, numObservations: 1
action: 2
Next state: 1 0.230375 0.214447 0.589256 0.871136 0.545641 0.821554 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 297
Initial state: 0 0.510931 0.826056 0.67127 0.85404 0.349958 0.146175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 36778 episodes
GETTING ACTION FROM:
action 0, numVisits=29846, meanQ=5.798774, numObservations: 3
action 1, numVisits=6900, meanQ=4.864434, numObservations: 4
action -1, numVisits=21, meanQ=3.560701, numObservations: 1
action 2, numVisits=10, meanQ=3.000010, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.510931 0.826056 0.67127 0.85404 0.349958 0.146175 w: 1
Observation: 0 0 0.83457 0 0.923322 0 0.0726137 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10142, meanQ=7.863664, numObservations: 3
action 2, numVisits=17, meanQ=5.940012, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 56134 episodes
GETTING ACTION FROM:
action 1, numVisits=66230, meanQ=5.314777, numObservations: 3
action -1, numVisits=35, meanQ=4.210583, numObservations: 1
action 2, numVisits=28, meanQ=4.070368, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.510931 0.826056 0.67127 0.85404 0.349958 0.146175 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 298
Initial state: 0 0.79454 0.735466 0.519804 0.875885 0.524903 0.870695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51973 episodes
GETTING ACTION FROM:
action 2, numVisits=47258, meanQ=4.839858, numObservations: 4
action -1, numVisits=4711, meanQ=2.938482, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.79454 0.735466 0.519804 0.875885 0.524903 0.870695 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 299
Initial state: 0 0.630903 0.843231 0.657018 0.815656 0.572994 0.996381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55359 episodes
GETTING ACTION FROM:
action 1, numVisits=30275, meanQ=5.008896, numObservations: 4
action 2, numVisits=25006, meanQ=4.891792, numObservations: 4
action -1, numVisits=37, meanQ=3.867147, numObservations: 1
action 0, numVisits=35, meanQ=3.770959, numObservations: 1
action 3, numVisits=6, meanQ=2.333333, numObservations: 2
action: 1
Next state: 0 0.630903 0.843231 0.657018 0.815656 0.572994 0.996381 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=260, meanQ=6.247090, numObservations: 3
action 3, numVisits=10, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 50661 episodes
GETTING ACTION FROM:
action 1, numVisits=264, meanQ=6.273308, numObservations: 3
action 3, numVisits=50641, meanQ=5.899084, numObservations: 4
action 0, numVisits=18, meanQ=1.025000, numObservations: 1
action -1, numVisits=6, meanQ=-0.350000, numObservations: 1
action 2, numVisits=5, meanQ=-1.402000, numObservations: 2
action: 1
Next state: 1 0.630903 0.843231 0.657018 0.815656 0.572994 0.996381 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 300
Initial state: 0 0.569719 0.835635 0.62892 0.815075 0.174674 0.638624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55073 episodes
GETTING ACTION FROM:
action 1, numVisits=55061, meanQ=4.977778, numObservations: 4
action 2, numVisits=7, meanQ=2.427157, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.569719 0.835635 0.62892 0.815075 0.174674 0.638624 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 301
Initial state: 0 0.68582 0.897589 0.690539 0.892251 0.66331 0.771108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55082 episodes
GETTING ACTION FROM:
action 1, numVisits=55076, meanQ=4.885716, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.68582 0.897589 0.690539 0.892251 0.66331 0.771108 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 302
Initial state: 0 0.718616 0.837778 0.611471 0.868706 0.691866 0.810331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53801 episodes
GETTING ACTION FROM:
action 2, numVisits=51825, meanQ=4.857344, numObservations: 5
action -1, numVisits=1964, meanQ=3.187815, numObservations: 1
action 1, numVisits=9, meanQ=1.445567, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.718616 0.837778 0.611471 0.868706 0.691866 0.810331 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 303
Initial state: 0 0.975355 0.477376 0.646178 0.857634 0.669447 0.83623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52595 episodes
GETTING ACTION FROM:
action 1, numVisits=52524, meanQ=4.882721, numObservations: 4
action 2, numVisits=42, meanQ=3.752857, numObservations: 3
action 0, numVisits=26, meanQ=3.592284, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.975355 0.477376 0.646178 0.857634 0.669447 0.83623 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=3815, meanQ=3.460777, numObservations: 1
action -1, numVisits=76, meanQ=2.685255, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 35132 episodes
GETTING ACTION FROM:
action 3, numVisits=29889, meanQ=5.766277, numObservations: 4
action 1, numVisits=23, meanQ=4.652174, numObservations: 3
action 0, numVisits=8956, meanQ=1.196972, numObservations: 1
action -1, numVisits=157, meanQ=0.773178, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.975355 0.477376 0.646178 0.857634 0.669447 0.83623 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 304
Initial state: 0 0.88573 0.204053 0.649688 0.849223 0.599064 0.88229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54966 episodes
GETTING ACTION FROM:
action 2, numVisits=54911, meanQ=4.936373, numObservations: 4
action 0, numVisits=34, meanQ=3.734549, numObservations: 1
action 1, numVisits=12, meanQ=2.658333, numObservations: 3
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.88573 0.204053 0.649688 0.849223 0.599064 0.88229 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 305
Initial state: 0 0.54469 0.884358 0.770431 0.623849 0.539294 0.809482 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53579 episodes
GETTING ACTION FROM:
action 3, numVisits=53453, meanQ=5.040753, numObservations: 5
action -1, numVisits=87, meanQ=4.318129, numObservations: 1
action 1, numVisits=25, meanQ=3.720000, numObservations: 4
action 2, numVisits=12, meanQ=2.999167, numObservations: 5
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.54469 0.884358 0.770431 0.623849 0.539294 0.809482 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 306
Initial state: 0 0.699265 0.892506 0.385209 0.626938 0.561998 0.895876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55692 episodes
GETTING ACTION FROM:
action 1, numVisits=50602, meanQ=4.975358, numObservations: 5
action 3, numVisits=5085, meanQ=4.905556, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.699265 0.892506 0.385209 0.626938 0.561998 0.895876 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3703, meanQ=5.622847, numObservations: 4
action 2, numVisits=17, meanQ=3.117653, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 62707 episodes
GETTING ACTION FROM:
action 1, numVisits=66408, meanQ=5.426801, numObservations: 4
action 2, numVisits=17, meanQ=3.117653, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.699265 0.892506 0.385209 0.626938 0.561998 0.895876 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 307
Initial state: 0 0.466797 0.9174 0.691053 0.847534 0.688979 0.870197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53675 episodes
GETTING ACTION FROM:
action 2, numVisits=53669, meanQ=4.835686, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.466797 0.9174 0.691053 0.847534 0.688979 0.870197 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1734, meanQ=5.463788, numObservations: 4
action -1, numVisits=2252, meanQ=2.430351, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 60536 episodes
GETTING ACTION FROM:
action 2, numVisits=62268, meanQ=4.782589, numObservations: 4
action -1, numVisits=2252, meanQ=2.430351, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.466797 0.9174 0.691053 0.847534 0.688979 0.870197 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=6841, meanQ=8.542877, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 57578 episodes
GETTING ACTION FROM:
action 1, numVisits=64254, meanQ=6.476314, numObservations: 5
action 3, numVisits=159, meanQ=5.553208, numObservations: 5
action 2, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 1
Next state: 1 0.466797 0.9174 0.691053 0.847534 0.688979 0.870197 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 308
Initial state: 0 0.655642 0.826236 0.569931 0.816236 0.688972 0.596623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32244 episodes
GETTING ACTION FROM:
action 0, numVisits=32217, meanQ=2.903339, numObservations: 1
action 3, numVisits=13, meanQ=0.698477, numObservations: 3
action 2, numVisits=9, meanQ=0.111122, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.655642 0.826236 0.569931 0.816236 0.688972 0.596623 w: 1
Observation: 0 0 0.795979 0 0.8002 0 0.538717 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32152, meanQ=4.949214, numObservations: 4
action -1, numVisits=36, meanQ=3.861309, numObservations: 1
action 3, numVisits=25, meanQ=3.392008, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55425 episodes
GETTING ACTION FROM:
action 1, numVisits=87576, meanQ=4.957354, numObservations: 4
action -1, numVisits=37, meanQ=3.808822, numObservations: 1
action 3, numVisits=25, meanQ=3.392008, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.655642 0.826236 0.569931 0.816236 0.688972 0.596623 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 309
Initial state: 0 0.16339 0.298649 0.57929 0.86831 0.622519 0.887658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54971 episodes
GETTING ACTION FROM:
action 1, numVisits=54895, meanQ=5.005186, numObservations: 4
action -1, numVisits=51, meanQ=4.080374, numObservations: 1
action 3, numVisits=14, meanQ=2.414286, numObservations: 3
action 2, numVisits=9, meanQ=2.332244, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.16339 0.298649 0.57929 0.86831 0.622519 0.887658 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8342, meanQ=8.265037, numObservations: 4
action 3, numVisits=4, meanQ=2.497525, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 43505 episodes
GETTING ACTION FROM:
action 2, numVisits=51421, meanQ=6.363713, numObservations: 4
action 3, numVisits=424, meanQ=5.623581, numObservations: 5
action 1, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 2
Next state: 1 0.16339 0.298649 0.57929 0.86831 0.622519 0.887658 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 310
Initial state: 0 0.62108 0.881225 0.680809 0.849671 0.75545 0.558612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55060 episodes
GETTING ACTION FROM:
action 3, numVisits=54955, meanQ=4.984169, numObservations: 4
action -1, numVisits=63, meanQ=4.112151, numObservations: 1
action 0, numVisits=38, meanQ=3.863630, numObservations: 1
action 1, numVisits=3, meanQ=0.330033, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.62108 0.881225 0.680809 0.849671 0.75545 0.558612 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2973, meanQ=7.908031, numObservations: 5
action 2, numVisits=6, meanQ=4.335017, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46582 episodes
GETTING ACTION FROM:
action 1, numVisits=49422, meanQ=6.249505, numObservations: 5
action 2, numVisits=136, meanQ=5.395811, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.62108 0.881225 0.680809 0.849671 0.75545 0.558612 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 311
Initial state: 0 0.571725 0.826603 0.544853 0.872524 0.103812 0.618296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54989 episodes
GETTING ACTION FROM:
action 3, numVisits=54973, meanQ=4.914664, numObservations: 4
action 1, numVisits=11, meanQ=0.453664, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.571725 0.826603 0.544853 0.872524 0.103812 0.618296 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1355, meanQ=7.841682, numObservations: 4
action 1, numVisits=13, meanQ=5.923085, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 45315 episodes
GETTING ACTION FROM:
action 2, numVisits=46635, meanQ=6.078656, numObservations: 4
action 1, numVisits=45, meanQ=4.464669, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.571725 0.826603 0.544853 0.872524 0.103812 0.618296 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 312
Initial state: 0 0.532474 0.824513 0.636954 0.334233 0.583941 0.854391 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52173 episodes
GETTING ACTION FROM:
action 3, numVisits=47667, meanQ=4.944917, numObservations: 5
action -1, numVisits=4471, meanQ=3.149897, numObservations: 1
action 1, numVisits=32, meanQ=1.937194, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.532474 0.824513 0.636954 0.334233 0.583941 0.854391 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 313
Initial state: 0 0.717483 0.676033 0.629617 0.852507 0.614558 0.858888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52641 episodes
GETTING ACTION FROM:
action 2, numVisits=52633, meanQ=4.905212, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.717483 0.676033 0.629617 0.852507 0.614558 0.858888 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 314
Initial state: 0 0.536402 0.835353 0.28681 0.76002 0.621465 0.849412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32243 episodes
GETTING ACTION FROM:
action -1, numVisits=32231, meanQ=3.085282, numObservations: 1
action 1, numVisits=5, meanQ=-0.597980, numObservations: 2
action 3, numVisits=4, meanQ=-2.005000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.536402 0.835353 0.28681 0.76002 0.621465 0.849412 w: 1
Observation: 0 0.619866 0 0.232273 0 0.662849 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31887, meanQ=5.123179, numObservations: 4
action 3, numVisits=313, meanQ=4.770307, numObservations: 3
action -1, numVisits=27, meanQ=3.882515, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 54409 episodes
GETTING ACTION FROM:
action 1, numVisits=86295, meanQ=5.175819, numObservations: 4
action 3, numVisits=313, meanQ=4.770307, numObservations: 3
action -1, numVisits=28, meanQ=3.833497, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.536402 0.835353 0.28681 0.76002 0.621465 0.849412 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=5670, meanQ=6.957998, numObservations: 4
action 2, numVisits=9, meanQ=3.887789, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 61260 episodes
GETTING ACTION FROM:
action 2, numVisits=17903, meanQ=5.947191, numObservations: 3
action 1, numVisits=49033, meanQ=4.951154, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 0 0.536402 0.835353 0.28681 0.76002 0.621465 0.849412 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=392, meanQ=8.349733, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 66999 episodes
GETTING ACTION FROM:
action 3, numVisits=67235, meanQ=6.769407, numObservations: 3
action 1, numVisits=154, meanQ=5.661559, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.536402 0.835353 0.28681 0.76002 0.621465 0.849412 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -1.14771
Run # 315
Initial state: 0 0.693887 0.886465 0.612512 0.807961 0.131458 0.938757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55342 episodes
GETTING ACTION FROM:
action 1, numVisits=55293, meanQ=4.943987, numObservations: 4
action 0, numVisits=45, meanQ=3.970341, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.693887 0.886465 0.612512 0.807961 0.131458 0.938757 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 316
Initial state: 0 0.589733 0.857617 0.353651 0.497373 0.65324 0.874315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54834 episodes
GETTING ACTION FROM:
action 1, numVisits=54791, meanQ=4.904409, numObservations: 5
action 2, numVisits=33, meanQ=3.723639, numObservations: 4
action 3, numVisits=6, meanQ=1.015000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.589733 0.857617 0.353651 0.497373 0.65324 0.874315 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 317
Initial state: 0 0.323411 0.0880958 0.537824 0.871159 0.519759 0.86902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55518 episodes
GETTING ACTION FROM:
action 1, numVisits=55455, meanQ=5.016860, numObservations: 3
action 3, numVisits=58, meanQ=3.753966, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.323411 0.0880958 0.537824 0.871159 0.519759 0.86902 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7823, meanQ=8.313931, numObservations: 4
action 2, numVisits=691, meanQ=8.141491, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 50898 episodes
GETTING ACTION FROM:
action 3, numVisits=35357, meanQ=6.375954, numObservations: 4
action 2, numVisits=24034, meanQ=6.058950, numObservations: 4
action 1, numVisits=10, meanQ=3.799000, numObservations: 3
action 0, numVisits=11, meanQ=0.520000, numObservations: 1
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 3
Next state: 1 0.323411 0.0880958 0.537824 0.871159 0.519759 0.86902 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 318
Initial state: 0 0.4139 0.353038 0.57583 0.859835 0.623861 0.895421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55158 episodes
GETTING ACTION FROM:
action 3, numVisits=55152, meanQ=4.869488, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.4139 0.353038 0.57583 0.859835 0.623861 0.895421 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 319
Initial state: 0 0.791062 0.525104 0.668712 0.812423 0.543317 0.845177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54660 episodes
GETTING ACTION FROM:
action 2, numVisits=54649, meanQ=4.920537, numObservations: 3
action 1, numVisits=6, meanQ=1.015000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.791062 0.525104 0.668712 0.812423 0.543317 0.845177 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 320
Initial state: 0 0.0967139 0.760715 0.667516 0.826487 0.50145 0.839508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54870 episodes
GETTING ACTION FROM:
action 2, numVisits=54609, meanQ=4.894809, numObservations: 4
action 3, numVisits=218, meanQ=4.366170, numObservations: 4
action 1, numVisits=39, meanQ=3.805905, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.0967139 0.760715 0.667516 0.826487 0.50145 0.839508 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 321
Initial state: 0 0.25164 0.366124 0.547392 0.857633 0.508367 0.892188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54465 episodes
GETTING ACTION FROM:
action 1, numVisits=54458, meanQ=4.953540, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.25164 0.366124 0.547392 0.857633 0.508367 0.892188 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2010, meanQ=8.542223, numObservations: 3
action 3, numVisits=3301, meanQ=8.494097, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 51073 episodes
GETTING ACTION FROM:
action 3, numVisits=47736, meanQ=6.410058, numObservations: 4
action 2, numVisits=8645, meanQ=6.395408, numObservations: 4
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.25164 0.366124 0.547392 0.857633 0.508367 0.892188 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 322
Initial state: 0 0.60174 0.884756 0.860741 0.89075 0.563 0.851574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54950 episodes
GETTING ACTION FROM:
action 2, numVisits=54937, meanQ=4.897223, numObservations: 4
action 1, numVisits=8, meanQ=1.996250, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.60174 0.884756 0.860741 0.89075 0.563 0.851574 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 323
Initial state: 0 0.564843 0.812137 0.532962 0.897006 0.0850258 0.672935 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53191 episodes
GETTING ACTION FROM:
action 3, numVisits=52869, meanQ=4.836246, numObservations: 5
action 2, numVisits=195, meanQ=4.294310, numObservations: 4
action 0, numVisits=50, meanQ=3.913180, numObservations: 1
action 1, numVisits=58, meanQ=3.891897, numObservations: 4
action -1, numVisits=19, meanQ=3.318728, numObservations: 1
action: 3
Next state: 0 0.564843 0.812137 0.532962 0.897006 0.0850258 0.672935 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2964, meanQ=8.542820, numObservations: 3
action 2, numVisits=2297, meanQ=8.528970, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46399 episodes
GETTING ACTION FROM:
action 1, numVisits=24862, meanQ=6.233188, numObservations: 4
action 2, numVisits=26789, meanQ=6.138240, numObservations: 5
action 0, numVisits=8, meanQ=0.351250, numObservations: 1
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.564843 0.812137 0.532962 0.897006 0.0850258 0.672935 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 324
Initial state: 0 0.683693 0.811505 0.106339 0.0996731 0.652671 0.879766 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55239 episodes
GETTING ACTION FROM:
action 2, numVisits=55154, meanQ=4.948378, numObservations: 3
action 3, numVisits=65, meanQ=3.935385, numObservations: 4
action -1, numVisits=17, meanQ=3.354767, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.683693 0.811505 0.106339 0.0996731 0.652671 0.879766 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8484, meanQ=8.215997, numObservations: 5
action 3, numVisits=45, meanQ=7.216447, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 45610 episodes
GETTING ACTION FROM:
action 1, numVisits=54000, meanQ=6.359108, numObservations: 5
action 3, numVisits=126, meanQ=5.504366, numObservations: 4
action 2, numVisits=10, meanQ=5.390000, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 1
Next state: 1 0.683693 0.811505 0.106339 0.0996731 0.652671 0.879766 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 325
Initial state: 0 0.606132 0.898625 0.627805 0.888417 0.649511 0.436503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55059 episodes
GETTING ACTION FROM:
action 2, numVisits=55032, meanQ=4.928519, numObservations: 4
action 1, numVisits=22, meanQ=0.817291, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.606132 0.898625 0.627805 0.888417 0.649511 0.436503 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3970, meanQ=4.580211, numObservations: 4
action 1, numVisits=9, meanQ=-0.335556, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 66326 episodes
GETTING ACTION FROM:
action 3, numVisits=70294, meanQ=5.891141, numObservations: 4
action 1, numVisits=9, meanQ=-0.335556, numObservations: 2
action 2, numVisits=3, meanQ=-0.370000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.606132 0.898625 0.627805 0.888417 0.649511 0.436503 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 326
Initial state: 0 0.504143 0.620138 0.66724 0.818036 0.592032 0.871561 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55587 episodes
GETTING ACTION FROM:
action 3, numVisits=55516, meanQ=5.084771, numObservations: 4
action -1, numVisits=56, meanQ=4.209111, numObservations: 1
action 2, numVisits=12, meanQ=2.675000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.504143 0.620138 0.66724 0.818036 0.592032 0.871561 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 327
Initial state: 0 0.493113 0.328656 0.530257 0.842914 0.691228 0.897338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55311 episodes
GETTING ACTION FROM:
action 1, numVisits=55302, meanQ=4.935152, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.493113 0.328656 0.530257 0.842914 0.691228 0.897338 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 328
Initial state: 0 0.648735 0.861776 0.44418 0.804106 0.553451 0.850977 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54372 episodes
GETTING ACTION FROM:
action 3, numVisits=54366, meanQ=4.805742, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.648735 0.861776 0.44418 0.804106 0.553451 0.850977 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 329
Initial state: 0 0.776913 0.373635 0.605179 0.803442 0.514147 0.830548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54992 episodes
GETTING ACTION FROM:
action 1, numVisits=54973, meanQ=4.933875, numObservations: 5
action 3, numVisits=14, meanQ=1.998579, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.776913 0.373635 0.605179 0.803442 0.514147 0.830548 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 330
Initial state: 0 0.59035 0.88645 0.427627 0.595464 0.606605 0.813824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54647 episodes
GETTING ACTION FROM:
action 1, numVisits=54639, meanQ=4.898153, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.59035 0.88645 0.427627 0.595464 0.606605 0.813824 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 331
Initial state: 0 0.508296 0.886808 0.235386 0.737541 0.667679 0.840488 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55129 episodes
GETTING ACTION FROM:
action 1, numVisits=54855, meanQ=4.937822, numObservations: 3
action 2, numVisits=254, meanQ=4.491746, numObservations: 4
action 0, numVisits=17, meanQ=3.280008, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.508296 0.886808 0.235386 0.737541 0.667679 0.840488 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 332
Initial state: 0 0.847248 0.326742 0.564332 0.880485 0.600628 0.802725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55324 episodes
GETTING ACTION FROM:
action 1, numVisits=55318, meanQ=4.970542, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.847248 0.326742 0.564332 0.880485 0.600628 0.802725 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 333
Initial state: 0 0.680675 0.247354 0.603638 0.867543 0.64281 0.883996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54946 episodes
GETTING ACTION FROM:
action 3, numVisits=54879, meanQ=4.941192, numObservations: 3
action 0, numVisits=63, meanQ=4.105712, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.680675 0.247354 0.603638 0.867543 0.64281 0.883996 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4043, meanQ=4.732884, numObservations: 4
action 3, numVisits=8, meanQ=1.747513, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 67107 episodes
GETTING ACTION FROM:
action 2, numVisits=71142, meanQ=5.826172, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 3, numVisits=9, meanQ=0.331122, numObservations: 2
action 1, numVisits=6, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.680675 0.247354 0.603638 0.867543 0.64281 0.883996 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 334
Initial state: 0 0.360105 0.51575 0.52645 0.841005 0.51212 0.869803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55537 episodes
GETTING ACTION FROM:
action 1, numVisits=55524, meanQ=5.010928, numObservations: 4
action 2, numVisits=8, meanQ=2.498763, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.360105 0.51575 0.52645 0.841005 0.51212 0.869803 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 335
Initial state: 0 0.714445 0.497351 0.526084 0.884324 0.503539 0.862974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55348 episodes
GETTING ACTION FROM:
action 3, numVisits=55323, meanQ=4.947616, numObservations: 5
action 1, numVisits=12, meanQ=2.498342, numObservations: 2
action 2, numVisits=9, meanQ=2.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.714445 0.497351 0.526084 0.884324 0.503539 0.862974 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 336
Initial state: 0 0.691929 0.896777 0.506722 0.940049 0.615945 0.813268 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54620 episodes
GETTING ACTION FROM:
action 1, numVisits=54436, meanQ=4.942795, numObservations: 4
action 2, numVisits=179, meanQ=4.392237, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.691929 0.896777 0.506722 0.940049 0.615945 0.813268 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 337
Initial state: 0 0.544321 0.230818 0.544975 0.893473 0.543134 0.804995 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55328 episodes
GETTING ACTION FROM:
action 1, numVisits=55135, meanQ=5.060525, numObservations: 4
action 0, numVisits=189, meanQ=4.562356, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.544321 0.230818 0.544975 0.893473 0.543134 0.804995 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3391, meanQ=7.948290, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 50150 episodes
GETTING ACTION FROM:
action 3, numVisits=53475, meanQ=5.909423, numObservations: 4
action 2, numVisits=63, meanQ=4.142700, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.544321 0.230818 0.544975 0.893473 0.543134 0.804995 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 338
Initial state: 0 0.677265 0.833798 0.671707 0.890023 0.727535 0.304857 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54738 episodes
GETTING ACTION FROM:
action 3, numVisits=54730, meanQ=4.924015, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.677265 0.833798 0.671707 0.890023 0.727535 0.304857 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 339
Initial state: 0 0.571028 0.811156 0.31247 0.0675776 0.58 0.884318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54940 episodes
GETTING ACTION FROM:
action 3, numVisits=54924, meanQ=4.898740, numObservations: 5
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 2, numVisits=9, meanQ=0.991122, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.571028 0.811156 0.31247 0.0675776 0.58 0.884318 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 340
Initial state: 0 0.121047 0.914545 0.62219 0.854965 0.559515 0.812841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54848 episodes
GETTING ACTION FROM:
action 2, numVisits=54838, meanQ=4.951763, numObservations: 4
action 3, numVisits=5, meanQ=-0.201980, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.121047 0.914545 0.62219 0.854965 0.559515 0.812841 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 341
Initial state: 0 0.536809 0.886184 0.730048 0.348504 0.596176 0.84395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 43126 episodes
GETTING ACTION FROM:
action 2, numVisits=27120, meanQ=4.893822, numObservations: 5
action 0, numVisits=15954, meanQ=2.822881, numObservations: 1
action -1, numVisits=44, meanQ=1.850169, numObservations: 1
action 3, numVisits=6, meanQ=-1.670000, numObservations: 3
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 2 0.536809 0.886184 0.730048 0.348504 0.596176 0.84395 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 342
Initial state: 0 0.518047 0.897721 0.636458 0.818996 0.638831 0.983251 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31492 episodes
GETTING ACTION FROM:
action -1, numVisits=31486, meanQ=2.571157, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.518047 0.897721 0.636458 0.818996 0.638831 0.983251 w: 1
Observation: 0 0.586286 0 0.691286 0 0.626142 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31458, meanQ=4.637101, numObservations: 4
action -1, numVisits=13, meanQ=2.746923, numObservations: 1
action 2, numVisits=8, meanQ=2.012500, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 53085 episodes
GETTING ACTION FROM:
action 1, numVisits=84542, meanQ=4.786816, numObservations: 4
action -1, numVisits=14, meanQ=2.478571, numObservations: 1
action 2, numVisits=8, meanQ=2.012500, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.518047 0.897721 0.636458 0.818996 0.638831 0.983251 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 343
Initial state: 0 0.0634446 0.838522 0.556168 0.890314 0.520921 0.855734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55535 episodes
GETTING ACTION FROM:
action 3, numVisits=55528, meanQ=4.963261, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0634446 0.838522 0.556168 0.890314 0.520921 0.855734 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 344
Initial state: 0 0.48235 0.22835 0.68455 0.837901 0.694213 0.887725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55086 episodes
GETTING ACTION FROM:
action 2, numVisits=47148, meanQ=4.922187, numObservations: 5
action 3, numVisits=7931, meanQ=4.857123, numObservations: 5
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.48235 0.22835 0.68455 0.837901 0.694213 0.887725 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 345
Initial state: 0 0.503723 0.802525 0.491987 0.654405 0.601332 0.838554 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53279 episodes
GETTING ACTION FROM:
action 2, numVisits=53273, meanQ=4.817563, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.503723 0.802525 0.491987 0.654405 0.601332 0.838554 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7936, meanQ=8.251930, numObservations: 4
action 1, numVisits=171, meanQ=7.820235, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 51658 episodes
GETTING ACTION FROM:
action 1, numVisits=1948, meanQ=6.056268, numObservations: 3
action 3, numVisits=57813, meanQ=5.968787, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.503723 0.802525 0.491987 0.654405 0.601332 0.838554 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 346
Initial state: 0 0.16709 0.0652368 0.683021 0.836786 0.606088 0.888774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55365 episodes
GETTING ACTION FROM:
action 3, numVisits=55297, meanQ=4.994533, numObservations: 4
action 0, numVisits=52, meanQ=4.098471, numObservations: 1
action 2, numVisits=12, meanQ=2.498342, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.16709 0.0652368 0.683021 0.836786 0.606088 0.888774 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 347
Initial state: 0 0.501424 0.864345 0.626159 0.863359 0.022717 0.918113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55085 episodes
GETTING ACTION FROM:
action 2, numVisits=38393, meanQ=4.881082, numObservations: 3
action 3, numVisits=16653, meanQ=4.851733, numObservations: 5
action -1, numVisits=35, meanQ=3.785106, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.501424 0.864345 0.626159 0.863359 0.022717 0.918113 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 348
Initial state: 0 0.51596 0.838188 0.674607 0.80826 0.440118 0.307669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55640 episodes
GETTING ACTION FROM:
action 3, numVisits=55629, meanQ=5.002991, numObservations: 4
action 1, numVisits=6, meanQ=1.671700, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.51596 0.838188 0.674607 0.80826 0.440118 0.307669 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7468, meanQ=8.326935, numObservations: 5
action 2, numVisits=1005, meanQ=8.225987, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 43636 episodes
GETTING ACTION FROM:
action 1, numVisits=45528, meanQ=6.408559, numObservations: 5
action 2, numVisits=6575, meanQ=6.348462, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=3, meanQ=-2.003300, numObservations: 1
action: 1
Next state: 1 0.51596 0.838188 0.674607 0.80826 0.440118 0.307669 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 349
Initial state: 0 0.540972 0.80127 0.094567 0.628446 0.666697 0.847724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55158 episodes
GETTING ACTION FROM:
action 1, numVisits=55001, meanQ=4.887627, numObservations: 5
action -1, numVisits=129, meanQ=4.325128, numObservations: 1
action 0, numVisits=11, meanQ=2.890000, numObservations: 1
action 3, numVisits=12, meanQ=1.832508, numObservations: 3
action 2, numVisits=5, meanQ=1.794000, numObservations: 3
action: 1
Next state: 1 0.540972 0.80127 0.094567 0.628446 0.666697 0.847724 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 350
Initial state: 0 0.543533 0.893573 0.641241 0.893651 0.131392 0.879178 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55411 episodes
GETTING ACTION FROM:
action 3, numVisits=55371, meanQ=5.005561, numObservations: 5
action -1, numVisits=35, meanQ=3.855341, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.543533 0.893573 0.641241 0.893651 0.131392 0.879178 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1005, meanQ=6.694089, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67381 episodes
GETTING ACTION FROM:
action 1, numVisits=68384, meanQ=5.923746, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.543533 0.893573 0.641241 0.893651 0.131392 0.879178 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 351
Initial state: 0 0.681487 0.820654 0.252141 0.857091 0.549299 0.8008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54784 episodes
GETTING ACTION FROM:
action 1, numVisits=54757, meanQ=4.880208, numObservations: 4
action 2, numVisits=14, meanQ=1.857150, numObservations: 2
action 3, numVisits=9, meanQ=1.432222, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.681487 0.820654 0.252141 0.857091 0.549299 0.8008 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 352
Initial state: 0 0.241007 0.668226 0.598865 0.851958 0.56326 0.836482 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54931 episodes
GETTING ACTION FROM:
action 3, numVisits=54923, meanQ=4.903320, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.241007 0.668226 0.598865 0.851958 0.56326 0.836482 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 353
Initial state: 0 0.550842 0.830005 0.587013 0.848406 0.926049 0.266886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55506 episodes
GETTING ACTION FROM:
action 2, numVisits=55473, meanQ=4.973027, numObservations: 5
action -1, numVisits=24, meanQ=3.619448, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.550842 0.830005 0.587013 0.848406 0.926049 0.266886 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 354
Initial state: 0 0.617014 0.836593 0.457132 0.0323962 0.685877 0.84849 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32217 episodes
GETTING ACTION FROM:
action 0, numVisits=32206, meanQ=2.832871, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=4, meanQ=-2.997475, numObservations: 2
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 0
Next state: 0 0.617014 0.836593 0.457132 0.0323962 0.685877 0.84849 w: 1
Observation: 0 0 0.76763 0 0.109693 0 0.821366 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32180, meanQ=4.954810, numObservations: 4
action 0, numVisits=18, meanQ=3.351658, numObservations: 2
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 55906 episodes
GETTING ACTION FROM:
action 2, numVisits=88084, meanQ=5.270676, numObservations: 4
action 0, numVisits=19, meanQ=3.311050, numObservations: 2
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.617014 0.836593 0.457132 0.0323962 0.685877 0.84849 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=12823, meanQ=8.302859, numObservations: 5
action 1, numVisits=4, meanQ=4.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 50533 episodes
GETTING ACTION FROM:
action 3, numVisits=63326, meanQ=6.494080, numObservations: 5
action 1, numVisits=26, meanQ=3.615385, numObservations: 3
action 2, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-2.003300, numObservations: 1
action: 3
Next state: 0 0.617014 0.836593 0.457132 0.0323962 0.685877 0.84849 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=1822, meanQ=7.692472, numObservations: 4
action 1, numVisits=52, meanQ=6.344238, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 65257 episodes
GETTING ACTION FROM:
action 2, numVisits=77, meanQ=6.506364, numObservations: 5
action 1, numVisits=54191, meanQ=6.086206, numObservations: 5
action 3, numVisits=12864, meanQ=5.891595, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.617014 0.836593 0.457132 0.0323962 0.685877 0.84849 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 72297 episodes
GETTING ACTION FROM:
action 3, numVisits=5408, meanQ=5.994863, numObservations: 3
action 1, numVisits=66884, meanQ=5.961647, numObservations: 4
action -1, numVisits=2, meanQ=-2.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.617014 0.836593 0.457132 0.0323962 0.685877 0.84849 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -5.11623
Run # 355
Initial state: 0 0.350713 0.249322 0.644035 0.865569 0.639952 0.81905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55926 episodes
GETTING ACTION FROM:
action 3, numVisits=55887, meanQ=5.000722, numObservations: 5
action 0, numVisits=30, meanQ=3.765375, numObservations: 1
action 1, numVisits=6, meanQ=1.331683, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.350713 0.249322 0.644035 0.865569 0.639952 0.81905 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 356
Initial state: 0 0.650122 0.814626 0.529131 0.856702 0.708176 0.7131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55484 episodes
GETTING ACTION FROM:
action 2, numVisits=55392, meanQ=4.955416, numObservations: 5
action -1, numVisits=83, meanQ=4.234207, numObservations: 1
action 1, numVisits=5, meanQ=1.794000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.650122 0.814626 0.529131 0.856702 0.708176 0.7131 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 357
Initial state: 0 0.554622 0.870652 0.573305 0.847489 0.131631 0.0322636 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49052 episodes
GETTING ACTION FROM:
action 3, numVisits=40736, meanQ=4.881291, numObservations: 4
action -1, numVisits=8292, meanQ=2.930903, numObservations: 1
action 1, numVisits=21, meanQ=1.566200, numObservations: 4
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.554622 0.870652 0.573305 0.847489 0.131631 0.0322636 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4022, meanQ=8.449631, numObservations: 3
action 1, numVisits=8, meanQ=5.997500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 42725 episodes
GETTING ACTION FROM:
action 2, numVisits=46051, meanQ=6.163092, numObservations: 4
action 1, numVisits=700, meanQ=5.798733, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.554622 0.870652 0.573305 0.847489 0.131631 0.0322636 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 358
Initial state: 0 0.548676 0.856259 0.593661 0.828132 0.810525 0.452996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55134 episodes
GETTING ACTION FROM:
action 3, numVisits=55110, meanQ=4.959769, numObservations: 4
action 2, numVisits=19, meanQ=3.195268, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.548676 0.856259 0.593661 0.828132 0.810525 0.452996 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 359
Initial state: 0 0.514696 0.837474 0.846167 0.084489 0.622077 0.811895 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55083 episodes
GETTING ACTION FROM:
action 2, numVisits=55074, meanQ=5.018836, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.514696 0.837474 0.846167 0.084489 0.622077 0.811895 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 360
Initial state: 0 0.697946 0.890545 0.586846 0.854395 0.805348 0.698012 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55113 episodes
GETTING ACTION FROM:
action 2, numVisits=55062, meanQ=4.883357, numObservations: 4
action -1, numVisits=46, meanQ=3.914434, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.697946 0.890545 0.586846 0.854395 0.805348 0.698012 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 361
Initial state: 0 0.676339 0.808439 0.650545 0.816015 0.604284 0.808672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51273 episodes
GETTING ACTION FROM:
action 1, numVisits=45947, meanQ=4.957211, numObservations: 4
action 0, numVisits=5315, meanQ=2.768070, numObservations: 1
action 3, numVisits=6, meanQ=-0.338333, numObservations: 4
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.676339 0.808439 0.650545 0.816015 0.604284 0.808672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 362
Initial state: 0 0.69112 0.876898 0.698792 0.847477 0.903296 0.848903 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55538 episodes
GETTING ACTION FROM:
action 2, numVisits=55506, meanQ=4.954057, numObservations: 4
action 3, numVisits=20, meanQ=3.495010, numObservations: 4
action 1, numVisits=8, meanQ=2.498750, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.69112 0.876898 0.698792 0.847477 0.903296 0.848903 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 363
Initial state: 0 0.636916 0.810885 0.408456 0.243528 0.680472 0.869025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55520 episodes
GETTING ACTION FROM:
action 3, numVisits=55502, meanQ=5.002838, numObservations: 5
action 1, numVisits=13, meanQ=2.998469, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.636916 0.810885 0.408456 0.243528 0.680472 0.869025 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 364
Initial state: 0 0.62289 0.854691 0.107542 0.113479 0.587112 0.875721 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55275 episodes
GETTING ACTION FROM:
action 1, numVisits=55208, meanQ=4.911033, numObservations: 5
action 0, numVisits=57, meanQ=4.050890, numObservations: 1
action 2, numVisits=7, meanQ=1.570014, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.62289 0.854691 0.107542 0.113479 0.587112 0.875721 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 365
Initial state: 0 0.613404 0.882156 0.591281 0.816767 0.687337 0.102038 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33820 episodes
GETTING ACTION FROM:
action 0, numVisits=33701, meanQ=5.756385, numObservations: 3
action -1, numVisits=110, meanQ=2.945018, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.613404 0.882156 0.591281 0.816767 0.687337 0.102038 w: 1
Observation: 0 0 0.876561 0 0.728141 0 0.0784051 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10945, meanQ=7.993512, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55694 episodes
GETTING ACTION FROM:
action 2, numVisits=66637, meanQ=5.533201, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.613404 0.882156 0.591281 0.816767 0.687337 0.102038 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 366
Initial state: 0 0.379371 0.914431 0.513411 0.836962 0.683603 0.816619 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55619 episodes
GETTING ACTION FROM:
action 2, numVisits=55612, meanQ=4.996618, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.379371 0.914431 0.513411 0.836962 0.683603 0.816619 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 367
Initial state: 0 0.472323 0.665799 0.624619 0.863938 0.521841 0.844145 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55085 episodes
GETTING ACTION FROM:
action 1, numVisits=55044, meanQ=4.892323, numObservations: 4
action -1, numVisits=32, meanQ=3.675802, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.472323 0.665799 0.624619 0.863938 0.521841 0.844145 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 368
Initial state: 0 0.520907 0.815097 0.550121 0.815275 0.0505473 0.920145 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33914 episodes
GETTING ACTION FROM:
action 0, numVisits=33871, meanQ=5.277801, numObservations: 2
action 2, numVisits=39, meanQ=1.602821, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.520907 0.815097 0.550121 0.815275 0.0505473 0.920145 w: 1
Observation: 0 0 0.850917 0 0.719397 0 0.921758 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=25716, meanQ=7.228620, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55836 episodes
GETTING ACTION FROM:
action 3, numVisits=81533, meanQ=5.818226, numObservations: 4
action -1, numVisits=20, meanQ=4.179057, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.520907 0.815097 0.550121 0.815275 0.0505473 0.920145 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=9672, meanQ=8.139837, numObservations: 5
action 2, numVisits=38, meanQ=6.792371, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 45064 episodes
GETTING ACTION FROM:
action 1, numVisits=54661, meanQ=6.206111, numObservations: 5
action 2, numVisits=106, meanQ=5.132928, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 1
Next state: 1 0.520907 0.815097 0.550121 0.815275 0.0505473 0.920145 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 369
Initial state: 0 0.829909 0.317983 0.593604 0.85595 0.65346 0.819009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55284 episodes
GETTING ACTION FROM:
action 1, numVisits=55234, meanQ=4.974985, numObservations: 5
action -1, numVisits=45, meanQ=3.974191, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.829909 0.317983 0.593604 0.85595 0.65346 0.819009 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 370
Initial state: 0 0.615424 0.849543 0.295898 0.59519 0.65341 0.859972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53711 episodes
GETTING ACTION FROM:
action 3, numVisits=53665, meanQ=4.911249, numObservations: 4
action 0, numVisits=24, meanQ=3.407206, numObservations: 1
action 1, numVisits=19, meanQ=3.115789, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.615424 0.849543 0.295898 0.59519 0.65341 0.859972 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 371
Initial state: 0 0.0660692 0.597031 0.691653 0.845861 0.556756 0.846673 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55292 episodes
GETTING ACTION FROM:
action 1, numVisits=55240, meanQ=4.983305, numObservations: 4
action 0, numVisits=37, meanQ=3.899192, numObservations: 1
action 3, numVisits=9, meanQ=2.553344, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0660692 0.597031 0.691653 0.845861 0.556756 0.846673 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8570, meanQ=8.297112, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46049 episodes
GETTING ACTION FROM:
action 3, numVisits=54601, meanQ=5.963691, numObservations: 4
action 1, numVisits=10, meanQ=4.598000, numObservations: 4
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=3, meanQ=-2.003300, numObservations: 1
action: 3
Next state: 1 0.0660692 0.597031 0.691653 0.845861 0.556756 0.846673 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 372
Initial state: 0 0.501583 0.210527 0.69067 0.826911 0.646556 0.891662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54609 episodes
GETTING ACTION FROM:
action 2, numVisits=54416, meanQ=4.923531, numObservations: 4
action -1, numVisits=167, meanQ=4.433817, numObservations: 1
action 1, numVisits=19, meanQ=3.000011, numObservations: 3
action 3, numVisits=5, meanQ=-0.201980, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.501583 0.210527 0.69067 0.826911 0.646556 0.891662 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 373
Initial state: 0 0.506043 0.862951 0.891119 0.00120875 0.694884 0.887787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55038 episodes
GETTING ACTION FROM:
action 2, numVisits=54960, meanQ=4.974650, numObservations: 4
action 0, numVisits=47, meanQ=4.009580, numObservations: 1
action -1, numVisits=21, meanQ=3.557172, numObservations: 1
action 3, numVisits=9, meanQ=1.454444, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.506043 0.862951 0.891119 0.00120875 0.694884 0.887787 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 374
Initial state: 0 0.969298 0.0334695 0.670073 0.883572 0.547662 0.808671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54738 episodes
GETTING ACTION FROM:
action 1, numVisits=54599, meanQ=4.987732, numObservations: 5
action 0, numVisits=113, meanQ=4.380724, numObservations: 1
action -1, numVisits=17, meanQ=3.309482, numObservations: 1
action 2, numVisits=8, meanQ=1.747513, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.969298 0.0334695 0.670073 0.883572 0.547662 0.808671 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 375
Initial state: 0 0.670419 0.805892 0.689705 0.824409 0.8461 0.726924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55328 episodes
GETTING ACTION FROM:
action 2, numVisits=55271, meanQ=5.141184, numObservations: 4
action 1, numVisits=52, meanQ=3.764044, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.670419 0.805892 0.689705 0.824409 0.8461 0.726924 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 376
Initial state: 0 0.778547 0.327146 0.549658 0.887167 0.556201 0.872972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55314 episodes
GETTING ACTION FROM:
action 1, numVisits=55274, meanQ=4.999110, numObservations: 3
action 0, numVisits=36, meanQ=3.880151, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.778547 0.327146 0.549658 0.887167 0.556201 0.872972 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 377
Initial state: 0 0.679819 0.895784 0.649508 0.847688 0.485668 0.00431194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55265 episodes
GETTING ACTION FROM:
action 3, numVisits=55225, meanQ=4.978359, numObservations: 4
action -1, numVisits=33, meanQ=3.819373, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.679819 0.895784 0.649508 0.847688 0.485668 0.00431194 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 378
Initial state: 0 0.396553 0.680765 0.619715 0.878887 0.505116 0.87708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52740 episodes
GETTING ACTION FROM:
action 3, numVisits=52691, meanQ=4.792534, numObservations: 5
action -1, numVisits=44, meanQ=3.699444, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.396553 0.680765 0.619715 0.878887 0.505116 0.87708 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 379
Initial state: 0 0.655834 0.805569 0.997768 0.213919 0.51219 0.893665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54899 episodes
GETTING ACTION FROM:
action 3, numVisits=54825, meanQ=4.986408, numObservations: 4
action 0, numVisits=70, meanQ=4.205262, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.655834 0.805569 0.997768 0.213919 0.51219 0.893665 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 380
Initial state: 0 0.697425 0.813003 0.245418 0.376485 0.695448 0.842936 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55193 episodes
GETTING ACTION FROM:
action 1, numVisits=55185, meanQ=4.977306, numObservations: 4
action 2, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.697425 0.813003 0.245418 0.376485 0.695448 0.842936 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 381
Initial state: 0 0.648462 0.804724 0.642986 0.603258 0.699033 0.803466 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32310 episodes
GETTING ACTION FROM:
action -1, numVisits=32295, meanQ=3.074006, numObservations: 1
action 1, numVisits=7, meanQ=-1.287143, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: -1
Next state: 0 0.648462 0.804724 0.642986 0.603258 0.699033 0.803466 w: 1
Observation: 0 0.716991 0 0.719326 0 0.63443 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32129, meanQ=5.043270, numObservations: 4
action 2, numVisits=160, meanQ=4.545954, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55399 episodes
GETTING ACTION FROM:
action 1, numVisits=87522, meanQ=5.068211, numObservations: 4
action 2, numVisits=166, meanQ=4.561823, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.648462 0.804724 0.642986 0.603258 0.699033 0.803466 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 382
Initial state: 0 0.698219 0.839548 0.398079 0.369242 0.586486 0.867252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55109 episodes
GETTING ACTION FROM:
action 1, numVisits=55102, meanQ=4.964135, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.698219 0.839548 0.398079 0.369242 0.586486 0.867252 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 383
Initial state: 0 0.619034 0.805037 0.33247 0.410638 0.687675 0.808585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54864 episodes
GETTING ACTION FROM:
action 3, numVisits=54773, meanQ=4.865039, numObservations: 5
action -1, numVisits=87, meanQ=4.092677, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.619034 0.805037 0.33247 0.410638 0.687675 0.808585 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 384
Initial state: 0 0.415923 0.247381 0.60728 0.855479 0.520461 0.828112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55355 episodes
GETTING ACTION FROM:
action 1, numVisits=55321, meanQ=4.927528, numObservations: 5
action -1, numVisits=21, meanQ=3.441725, numObservations: 1
action 3, numVisits=9, meanQ=2.333344, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.415923 0.247381 0.60728 0.855479 0.520461 0.828112 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7013, meanQ=8.362534, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 48715 episodes
GETTING ACTION FROM:
action 3, numVisits=54134, meanQ=6.173730, numObservations: 4
action 2, numVisits=1580, meanQ=5.819781, numObservations: 5
action 1, numVisits=12, meanQ=4.665833, numObservations: 3
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=3, meanQ=-2.663300, numObservations: 1
action: 3
Next state: 1 0.415923 0.247381 0.60728 0.855479 0.520461 0.828112 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 385
Initial state: 0 0.693241 0.832959 0.0502417 0.32904 0.686878 0.836027 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55730 episodes
GETTING ACTION FROM:
action 1, numVisits=33800, meanQ=4.982103, numObservations: 5
action 2, numVisits=21922, meanQ=4.956157, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.693241 0.832959 0.0502417 0.32904 0.686878 0.836027 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 386
Initial state: 0 0.44489 0.941972 0.609264 0.889013 0.506678 0.844284 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54325 episodes
GETTING ACTION FROM:
action 2, numVisits=53242, meanQ=4.871558, numObservations: 4
action -1, numVisits=1078, meanQ=3.310659, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.44489 0.941972 0.609264 0.889013 0.506678 0.844284 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 387
Initial state: 0 0.643983 0.878816 0.392061 0.856266 0.600138 0.813355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55333 episodes
GETTING ACTION FROM:
action 3, numVisits=55294, meanQ=4.945397, numObservations: 5
action 0, numVisits=32, meanQ=3.787587, numObservations: 1
action 1, numVisits=4, meanQ=-2.005000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.643983 0.878816 0.392061 0.856266 0.600138 0.813355 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 388
Initial state: 0 0.584924 0.888662 0.573479 0.86734 0.0298437 0.836715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55680 episodes
GETTING ACTION FROM:
action 1, numVisits=55636, meanQ=4.951009, numObservations: 4
action -1, numVisits=35, meanQ=3.790040, numObservations: 1
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.584924 0.888662 0.573479 0.86734 0.0298437 0.836715 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3925, meanQ=5.509753, numObservations: 3
action 3, numVisits=9, meanQ=3.221111, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67408 episodes
GETTING ACTION FROM:
action 2, numVisits=67405, meanQ=5.764150, numObservations: 5
action 1, numVisits=3925, meanQ=5.509753, numObservations: 3
action 3, numVisits=11, meanQ=2.453636, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.584924 0.888662 0.573479 0.86734 0.0298437 0.836715 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 389
Initial state: 0 0.673575 0.837104 0.56374 0.861922 0.708331 0.387517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55342 episodes
GETTING ACTION FROM:
action 3, numVisits=55182, meanQ=4.982041, numObservations: 3
action -1, numVisits=83, meanQ=4.268100, numObservations: 1
action 0, numVisits=66, meanQ=4.183076, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action: 3
Next state: 2 0.673575 0.837104 0.56374 0.861922 0.708331 0.387517 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 390
Initial state: 0 0.580041 0.846749 0.255022 0.417848 0.689487 0.840402 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54830 episodes
GETTING ACTION FROM:
action 2, numVisits=50457, meanQ=4.859970, numObservations: 4
action 1, numVisits=4303, meanQ=4.584843, numObservations: 5
action 3, numVisits=39, meanQ=3.662313, numObservations: 3
action 0, numVisits=29, meanQ=3.562604, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.580041 0.846749 0.255022 0.417848 0.689487 0.840402 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 391
Initial state: 0 0.596288 0.821883 0.633761 0.876069 0.743213 0.491591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55552 episodes
GETTING ACTION FROM:
action 2, numVisits=55475, meanQ=4.925408, numObservations: 4
action 0, numVisits=52, meanQ=4.003858, numObservations: 1
action -1, numVisits=23, meanQ=3.553227, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.596288 0.821883 0.633761 0.876069 0.743213 0.491591 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 392
Initial state: 0 0.930068 0.909405 0.599008 0.897365 0.693837 0.893181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55585 episodes
GETTING ACTION FROM:
action 1, numVisits=55567, meanQ=5.031385, numObservations: 4
action 3, numVisits=13, meanQ=3.131538, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.930068 0.909405 0.599008 0.897365 0.693837 0.893181 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 393
Initial state: 0 0.975741 0.615996 0.649076 0.803476 0.637898 0.861513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54439 episodes
GETTING ACTION FROM:
action 1, numVisits=54403, meanQ=4.965709, numObservations: 4
action 0, numVisits=32, meanQ=3.764146, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.975741 0.615996 0.649076 0.803476 0.637898 0.861513 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3719, meanQ=5.663369, numObservations: 4
action 2, numVisits=194, meanQ=4.871598, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 47188 episodes
GETTING ACTION FROM:
action 2, numVisits=47336, meanQ=5.730944, numObservations: 4
action 1, numVisits=3719, meanQ=5.663369, numObservations: 4
action -1, numVisits=23, meanQ=1.038783, numObservations: 1
action 0, numVisits=24, meanQ=1.011250, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.975741 0.615996 0.649076 0.803476 0.637898 0.861513 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 394
Initial state: 0 0.611736 0.835792 0.478145 0.798464 0.655084 0.878907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55350 episodes
GETTING ACTION FROM:
action 2, numVisits=55336, meanQ=4.927964, numObservations: 4
action 3, numVisits=9, meanQ=2.553344, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.611736 0.835792 0.478145 0.798464 0.655084 0.878907 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1427, meanQ=7.858405, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 42596 episodes
GETTING ACTION FROM:
action 1, numVisits=44014, meanQ=5.930595, numObservations: 3
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.611736 0.835792 0.478145 0.798464 0.655084 0.878907 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 395
Initial state: 0 0.571014 0.820889 0.574528 0.847317 0.0181192 0.779218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54808 episodes
GETTING ACTION FROM:
action 3, numVisits=54645, meanQ=5.056554, numObservations: 4
action 2, numVisits=131, meanQ=4.494245, numObservations: 5
action 0, numVisits=27, meanQ=3.710642, numObservations: 1
action 1, numVisits=3, meanQ=0.330033, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.571014 0.820889 0.574528 0.847317 0.0181192 0.779218 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8292, meanQ=8.068974, numObservations: 4
action 2, numVisits=38, meanQ=7.110526, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 43838 episodes
GETTING ACTION FROM:
action 1, numVisits=21209, meanQ=6.706419, numObservations: 4
action 2, numVisits=30952, meanQ=6.091499, numObservations: 5
action -1, numVisits=6, meanQ=-0.350000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.571014 0.820889 0.574528 0.847317 0.0181192 0.779218 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 396
Initial state: 0 0.576001 0.849399 0.663679 0.82106 0.384984 0.519753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31455 episodes
GETTING ACTION FROM:
action -1, numVisits=21442, meanQ=2.938875, numObservations: 1
action 0, numVisits=10004, meanQ=2.918479, numObservations: 1
action 3, numVisits=6, meanQ=-2.318333, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.576001 0.849399 0.663679 0.82106 0.384984 0.519753 w: 1
Observation: 0 0.517241 0 0.742781 0 0.331104 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=21410, meanQ=4.941860, numObservations: 4
action -1, numVisits=27, meanQ=3.726996, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 52429 episodes
GETTING ACTION FROM:
action 3, numVisits=73836, meanQ=4.760756, numObservations: 4
action -1, numVisits=30, meanQ=3.485273, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.576001 0.849399 0.663679 0.82106 0.384984 0.519753 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 397
Initial state: 0 0.128943 0.745521 0.567197 0.887341 0.507991 0.827011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55210 episodes
GETTING ACTION FROM:
action 3, numVisits=55136, meanQ=4.888574, numObservations: 3
action -1, numVisits=70, meanQ=3.907780, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.128943 0.745521 0.567197 0.887341 0.507991 0.827011 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 398
Initial state: 0 0.622342 0.820511 0.837405 0.191197 0.574075 0.856028 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52938 episodes
GETTING ACTION FROM:
action 1, numVisits=52891, meanQ=4.808074, numObservations: 3
action -1, numVisits=23, meanQ=3.383314, numObservations: 1
action 2, numVisits=16, meanQ=2.981875, numObservations: 3
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.622342 0.820511 0.837405 0.191197 0.574075 0.856028 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 399
Initial state: 0 0.644814 0.857217 0.550452 0.846951 0.691109 0.749155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52388 episodes
GETTING ACTION FROM:
action 2, numVisits=52333, meanQ=4.812035, numObservations: 4
action -1, numVisits=29, meanQ=3.530778, numObservations: 1
action 3, numVisits=23, meanQ=3.085652, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.644814 0.857217 0.550452 0.846951 0.691109 0.749155 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 400
Initial state: 0 0.339234 0.607742 0.550806 0.817066 0.526107 0.892642 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32448 episodes
GETTING ACTION FROM:
action -1, numVisits=32407, meanQ=2.972394, numObservations: 1
action 1, numVisits=22, meanQ=1.454100, numObservations: 3
action 3, numVisits=13, meanQ=0.992323, numObservations: 3
action 2, numVisits=4, meanQ=-0.504975, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: -1
Next state: 0 0.339234 0.607742 0.550806 0.817066 0.526107 0.892642 w: 1
Observation: 0 0.249477 0 0.631321 0 0.585955 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32395, meanQ=4.968451, numObservations: 4
action 2, numVisits=6, meanQ=-0.316667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55058 episodes
GETTING ACTION FROM:
action 1, numVisits=87450, meanQ=4.936855, numObservations: 4
action 2, numVisits=6, meanQ=-0.316667, numObservations: 2
action 3, numVisits=4, meanQ=-0.504975, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.339234 0.607742 0.550806 0.817066 0.526107 0.892642 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 401
Initial state: 0 0.607845 0.873228 0.241908 0.261694 0.656844 0.876604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55180 episodes
GETTING ACTION FROM:
action 1, numVisits=55066, meanQ=4.898189, numObservations: 5
action -1, numVisits=73, meanQ=4.127311, numObservations: 1
action 0, numVisits=28, meanQ=3.580160, numObservations: 1
action 2, numVisits=12, meanQ=1.998333, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.607845 0.873228 0.241908 0.261694 0.656844 0.876604 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 402
Initial state: 0 0.650761 0.879935 0.864495 0.679682 0.539819 0.802294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54911 episodes
GETTING ACTION FROM:
action 3, numVisits=54855, meanQ=4.975328, numObservations: 5
action 0, numVisits=21, meanQ=3.510158, numObservations: 1
action 1, numVisits=24, meanQ=3.166671, numObservations: 3
action 2, numVisits=9, meanQ=2.332244, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.650761 0.879935 0.864495 0.679682 0.539819 0.802294 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 403
Initial state: 0 0.515604 0.831376 0.626069 0.852482 0.660448 0.779402 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55137 episodes
GETTING ACTION FROM:
action 2, numVisits=54966, meanQ=4.864187, numObservations: 5
action 0, numVisits=145, meanQ=4.280725, numObservations: 1
action 1, numVisits=23, meanQ=3.346526, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.515604 0.831376 0.626069 0.852482 0.660448 0.779402 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3949, meanQ=4.585075, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 67210 episodes
GETTING ACTION FROM:
action 1, numVisits=71158, meanQ=5.825508, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=4, meanQ=-0.504975, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.515604 0.831376 0.626069 0.852482 0.660448 0.779402 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 404
Initial state: 0 0.603116 0.847975 0.546818 0.86957 0.882774 0.264109 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55232 episodes
GETTING ACTION FROM:
action 2, numVisits=55185, meanQ=5.008688, numObservations: 4
action -1, numVisits=24, meanQ=3.657434, numObservations: 1
action 0, numVisits=19, meanQ=3.488185, numObservations: 1
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.603116 0.847975 0.546818 0.86957 0.882774 0.264109 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 405
Initial state: 0 0.0702193 0.930904 0.525445 0.804054 0.593306 0.812675 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55674 episodes
GETTING ACTION FROM:
action 3, numVisits=55660, meanQ=5.006631, numObservations: 4
action 1, numVisits=8, meanQ=0.725013, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.0702193 0.930904 0.525445 0.804054 0.593306 0.812675 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 406
Initial state: 0 0.573568 0.865447 0.516943 0.803844 0.437744 0.290123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55322 episodes
GETTING ACTION FROM:
action 1, numVisits=55315, meanQ=4.983364, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.573568 0.865447 0.516943 0.803844 0.437744 0.290123 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 407
Initial state: 0 0.607953 0.888869 0.0697728 0.735775 0.649013 0.838887 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55205 episodes
GETTING ACTION FROM:
action 1, numVisits=55198, meanQ=4.922625, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.607953 0.888869 0.0697728 0.735775 0.649013 0.838887 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 408
Initial state: 0 0.67714 0.896388 0.520834 0.887417 0.73251 0.392019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54722 episodes
GETTING ACTION FROM:
action 3, numVisits=54618, meanQ=4.904850, numObservations: 3
action 0, numVisits=74, meanQ=4.163505, numObservations: 1
action -1, numVisits=28, meanQ=3.644557, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.67714 0.896388 0.520834 0.887417 0.73251 0.392019 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 409
Initial state: 0 0.525392 0.837808 0.857856 0.812753 0.533452 0.886927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55282 episodes
GETTING ACTION FROM:
action 1, numVisits=55236, meanQ=4.928208, numObservations: 4
action 0, numVisits=41, meanQ=3.901090, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.525392 0.837808 0.857856 0.812753 0.533452 0.886927 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 410
Initial state: 0 0.624262 0.821872 0.0434214 0.669649 0.618881 0.805993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55098 episodes
GETTING ACTION FROM:
action 2, numVisits=54987, meanQ=5.027959, numObservations: 5
action 0, numVisits=107, meanQ=4.349352, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.624262 0.821872 0.0434214 0.669649 0.618881 0.805993 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7052, meanQ=8.373513, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 45696 episodes
GETTING ACTION FROM:
action 3, numVisits=52741, meanQ=6.087884, numObservations: 5
action 2, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 0 0.624262 0.821872 0.0434214 0.669649 0.618881 0.805993 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=176, meanQ=7.230605, numObservations: 4
action 3, numVisits=5, meanQ=3.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 60236 episodes
GETTING ACTION FROM:
action 1, numVisits=60405, meanQ=5.746388, numObservations: 4
action 3, numVisits=7, meanQ=2.427157, numObservations: 2
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 1
Next state: 0 0.624262 0.821872 0.0434214 0.669649 0.618881 0.805993 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=10, meanQ=5.799000, numObservations: 4
action 0, numVisits=169, meanQ=5.396471, numObservations: 1
action 1, numVisits=3, meanQ=-0.329967, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 72969 episodes
GETTING ACTION FROM:
action 3, numVisits=7902, meanQ=6.213614, numObservations: 4
action 1, numVisits=64824, meanQ=5.291847, numObservations: 4
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action 0, numVisits=417, meanQ=0.997610, numObservations: 1
action -1, numVisits=4, meanQ=-2.002475, numObservations: 1
action: 3
Next state: 1 0.624262 0.821872 0.0434214 0.669649 0.618881 0.805993 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 411
Initial state: 0 0.681232 0.866928 0.232511 0.164213 0.554557 0.88435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54901 episodes
GETTING ACTION FROM:
action 1, numVisits=54872, meanQ=4.878150, numObservations: 5
action 2, numVisits=24, meanQ=2.817508, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.681232 0.866928 0.232511 0.164213 0.554557 0.88435 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 412
Initial state: 0 0.562776 0.839607 0.314273 0.191952 0.664373 0.870689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55153 episodes
GETTING ACTION FROM:
action 3, numVisits=55145, meanQ=5.022866, numObservations: 4
action 2, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.562776 0.839607 0.314273 0.191952 0.664373 0.870689 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 413
Initial state: 0 0.684894 0.807177 0.692 0.260721 0.553927 0.877503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55403 episodes
GETTING ACTION FROM:
action 3, numVisits=55397, meanQ=4.867500, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.684894 0.807177 0.692 0.260721 0.553927 0.877503 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 414
Initial state: 0 0.890051 0.695745 0.503108 0.83837 0.629337 0.829846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54604 episodes
GETTING ACTION FROM:
action 3, numVisits=54571, meanQ=4.845100, numObservations: 5
action -1, numVisits=29, meanQ=3.236666, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.890051 0.695745 0.503108 0.83837 0.629337 0.829846 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 415
Initial state: 0 0.30188 0.396833 0.509484 0.802292 0.540271 0.806586 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55014 episodes
GETTING ACTION FROM:
action 3, numVisits=54988, meanQ=4.922212, numObservations: 5
action 0, numVisits=22, meanQ=1.387084, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.30188 0.396833 0.509484 0.802292 0.540271 0.806586 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3678, meanQ=4.561189, numObservations: 4
action 1, numVisits=216, meanQ=3.914259, numObservations: 5
action -1, numVisits=81, meanQ=3.911115, numObservations: 1
action 0, numVisits=31, meanQ=3.462233, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67492 episodes
GETTING ACTION FROM:
action 2, numVisits=71165, meanQ=5.427189, numObservations: 4
action 1, numVisits=216, meanQ=3.914259, numObservations: 5
action -1, numVisits=85, meanQ=3.685840, numObservations: 1
action 0, numVisits=32, meanQ=3.291538, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.30188 0.396833 0.509484 0.802292 0.540271 0.806586 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 416
Initial state: 0 0.652585 0.363524 0.550837 0.847355 0.613496 0.880686 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55331 episodes
GETTING ACTION FROM:
action 3, numVisits=55166, meanQ=4.929004, numObservations: 3
action 2, numVisits=126, meanQ=4.287145, numObservations: 5
action 0, numVisits=36, meanQ=3.829402, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.652585 0.363524 0.550837 0.847355 0.613496 0.880686 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 417
Initial state: 0 0.212698 0.153253 0.625882 0.808861 0.683067 0.882478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33988 episodes
GETTING ACTION FROM:
action 0, numVisits=33479, meanQ=5.778978, numObservations: 3
action -1, numVisits=504, meanQ=3.439221, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.212698 0.153253 0.625882 0.808861 0.683067 0.882478 w: 1
Observation: 0 0 0.132219 0 0.803279 0 0.828921 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10290, meanQ=8.009010, numObservations: 4
action 1, numVisits=550, meanQ=2.153154, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 56539 episodes
GETTING ACTION FROM:
action 2, numVisits=66829, meanQ=5.616203, numObservations: 4
action 1, numVisits=550, meanQ=2.153154, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.212698 0.153253 0.625882 0.808861 0.683067 0.882478 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 418
Initial state: 0 0.649721 0.848663 0.976249 0.582131 0.56117 0.874796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55297 episodes
GETTING ACTION FROM:
action 2, numVisits=55229, meanQ=4.847328, numObservations: 4
action -1, numVisits=35, meanQ=3.739493, numObservations: 1
action 0, numVisits=24, meanQ=3.513460, numObservations: 1
action 1, numVisits=3, meanQ=0.993333, numObservations: 3
action 3, numVisits=6, meanQ=0.331667, numObservations: 1
action: 2
Next state: 2 0.649721 0.848663 0.976249 0.582131 0.56117 0.874796 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 419
Initial state: 0 0.66716 0.898768 0.645067 0.149108 0.683875 0.857564 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32370 episodes
GETTING ACTION FROM:
action -1, numVisits=32326, meanQ=2.849533, numObservations: 1
action 3, numVisits=33, meanQ=1.649700, numObservations: 3
action 1, numVisits=5, meanQ=-0.201980, numObservations: 2
action 2, numVisits=4, meanQ=-0.504975, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: -1
Next state: 0 0.66716 0.898768 0.645067 0.149108 0.683875 0.857564 w: 1
Observation: 0 0.691548 0 0.632063 0 0.6381 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32299, meanQ=4.957164, numObservations: 4
action 3, numVisits=21, meanQ=2.713810, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55657 episodes
GETTING ACTION FROM:
action 2, numVisits=87947, meanQ=4.995302, numObservations: 4
action 1, numVisits=10, meanQ=2.801020, numObservations: 3
action 3, numVisits=21, meanQ=2.713810, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.66716 0.898768 0.645067 0.149108 0.683875 0.857564 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 420
Initial state: 0 0.517658 0.862397 0.637268 0.819337 0.375784 0.342968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55389 episodes
GETTING ACTION FROM:
action 2, numVisits=55206, meanQ=4.895758, numObservations: 3
action 0, numVisits=162, meanQ=4.296065, numObservations: 1
action 1, numVisits=18, meanQ=3.338339, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.517658 0.862397 0.637268 0.819337 0.375784 0.342968 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 421
Initial state: 0 0.600809 0.84834 0.148956 0.533786 0.55614 0.875091 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52382 episodes
GETTING ACTION FROM:
action 1, numVisits=52371, meanQ=4.755559, numObservations: 5
action 2, numVisits=6, meanQ=0.331683, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.600809 0.84834 0.148956 0.533786 0.55614 0.875091 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 422
Initial state: 0 0.690518 0.0353655 0.581809 0.853492 0.629045 0.869768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55355 episodes
GETTING ACTION FROM:
action 2, numVisits=55346, meanQ=4.913018, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.690518 0.0353655 0.581809 0.853492 0.629045 0.869768 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 423
Initial state: 0 0.531017 0.817394 0.643079 0.821107 0.825001 0.984908 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54730 episodes
GETTING ACTION FROM:
action 1, numVisits=54635, meanQ=4.928617, numObservations: 5
action -1, numVisits=91, meanQ=2.490977, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.531017 0.817394 0.643079 0.821107 0.825001 0.984908 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 424
Initial state: 0 0.509857 0.865135 0.440872 0.642798 0.549519 0.83722 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54775 episodes
GETTING ACTION FROM:
action 3, numVisits=54764, meanQ=4.902831, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.509857 0.865135 0.440872 0.642798 0.549519 0.83722 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 425
Initial state: 0 0.624193 0.855977 0.323506 0.839795 0.603681 0.877923 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55159 episodes
GETTING ACTION FROM:
action 2, numVisits=55150, meanQ=4.960986, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.624193 0.855977 0.323506 0.839795 0.603681 0.877923 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1385, meanQ=7.766938, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 52641 episodes
GETTING ACTION FROM:
action 1, numVisits=54020, meanQ=5.843308, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.624193 0.855977 0.323506 0.839795 0.603681 0.877923 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 426
Initial state: 0 0.608942 0.809642 0.57529 0.829818 0.684694 0.96423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55342 episodes
GETTING ACTION FROM:
action 2, numVisits=55234, meanQ=4.943509, numObservations: 4
action -1, numVisits=91, meanQ=4.273276, numObservations: 1
action 1, numVisits=9, meanQ=1.440000, numObservations: 4
action 3, numVisits=6, meanQ=1.331683, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.608942 0.809642 0.57529 0.829818 0.684694 0.96423 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3958, meanQ=5.446490, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 61508 episodes
GETTING ACTION FROM:
action 2, numVisits=65464, meanQ=4.684511, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.608942 0.809642 0.57529 0.829818 0.684694 0.96423 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 427
Initial state: 0 0.484879 0.65167 0.643264 0.896118 0.636116 0.828263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55112 episodes
GETTING ACTION FROM:
action 3, numVisits=55106, meanQ=4.929498, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.484879 0.65167 0.643264 0.896118 0.636116 0.828263 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 428
Initial state: 0 0.66927 0.894624 0.585056 0.871436 0.0568007 0.062524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54172 episodes
GETTING ACTION FROM:
action 2, numVisits=52320, meanQ=4.849674, numObservations: 4
action -1, numVisits=1843, meanQ=3.062229, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.66927 0.894624 0.585056 0.871436 0.0568007 0.062524 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 429
Initial state: 0 0.566702 0.876907 0.529079 0.824666 0.246381 0.429053 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54498 episodes
GETTING ACTION FROM:
action 1, numVisits=52999, meanQ=4.959802, numObservations: 4
action -1, numVisits=1471, meanQ=2.979752, numObservations: 1
action 3, numVisits=25, meanQ=1.723212, numObservations: 5
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.566702 0.876907 0.529079 0.824666 0.246381 0.429053 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 430
Initial state: 0 0.594262 0.822874 0.682528 0.824461 0.434879 0.650831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55376 episodes
GETTING ACTION FROM:
action 2, numVisits=55301, meanQ=4.920291, numObservations: 4
action 0, numVisits=40, meanQ=3.890802, numObservations: 1
action -1, numVisits=15, meanQ=3.081846, numObservations: 1
action 1, numVisits=16, meanQ=2.873756, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action: 2
Next state: 1 0.594262 0.822874 0.682528 0.824461 0.434879 0.650831 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 431
Initial state: 0 0.662784 0.842362 0.510183 0.873039 0.775942 0.645228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55146 episodes
GETTING ACTION FROM:
action 2, numVisits=55100, meanQ=4.954134, numObservations: 4
action 3, numVisits=35, meanQ=3.846286, numObservations: 4
action 1, numVisits=7, meanQ=2.144300, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.662784 0.842362 0.510183 0.873039 0.775942 0.645228 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 432
Initial state: 0 0.534739 0.886147 0.675456 0.854661 0.039461 0.119111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55404 episodes
GETTING ACTION FROM:
action 1, numVisits=55390, meanQ=4.980889, numObservations: 5
action 2, numVisits=9, meanQ=1.886667, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.534739 0.886147 0.675456 0.854661 0.039461 0.119111 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 433
Initial state: 0 0.539832 0.834731 0.537991 0.888305 0.700711 0.941543 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32265 episodes
GETTING ACTION FROM:
action -1, numVisits=32253, meanQ=2.812721, numObservations: 1
action 1, numVisits=5, meanQ=-1.402000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action: -1
Next state: 0 0.539832 0.834731 0.537991 0.888305 0.700711 0.941543 w: 1
Observation: 0 0.604086 0 0.636824 0 0.680407 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32215, meanQ=4.892121, numObservations: 5
action 0, numVisits=33, meanQ=3.759333, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 54947 episodes
GETTING ACTION FROM:
action 3, numVisits=87161, meanQ=4.987916, numObservations: 5
action 0, numVisits=34, meanQ=3.713982, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.539832 0.834731 0.537991 0.888305 0.700711 0.941543 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 434
Initial state: 0 0.0747975 0.371835 0.552668 0.823016 0.636832 0.896817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55456 episodes
GETTING ACTION FROM:
action 2, numVisits=55447, meanQ=5.111492, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.0747975 0.371835 0.552668 0.823016 0.636832 0.896817 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3563, meanQ=7.377164, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 65068 episodes
GETTING ACTION FROM:
action 1, numVisits=39176, meanQ=5.984929, numObservations: 4
action 2, numVisits=29451, meanQ=5.322005, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 0 0.0747975 0.371835 0.552668 0.823016 0.636832 0.896817 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=245, meanQ=8.389634, numObservations: 3
action 3, numVisits=4, meanQ=5.997500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 57628 episodes
GETTING ACTION FROM:
action 2, numVisits=57326, meanQ=6.268779, numObservations: 5
action 3, numVisits=547, meanQ=5.749159, numObservations: 5
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-2.003300, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0747975 0.371835 0.552668 0.823016 0.636832 0.896817 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 435
Initial state: 0 0.535971 0.866723 0.621496 0.851434 0.549965 0.813989 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54917 episodes
GETTING ACTION FROM:
action 3, numVisits=54911, meanQ=4.928366, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.535971 0.866723 0.621496 0.851434 0.549965 0.813989 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 436
Initial state: 0 0.582467 0.800049 0.121641 0.98069 0.570546 0.860957 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33881 episodes
GETTING ACTION FROM:
action 0, numVisits=33872, meanQ=5.819627, numObservations: 3
action 2, numVisits=5, meanQ=0.196000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.582467 0.800049 0.121641 0.98069 0.570546 0.860957 w: 1
Observation: 0 0 0.740884 0 1 0 0.768189 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9416, meanQ=8.109800, numObservations: 4
action 3, numVisits=105, meanQ=7.394573, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55443 episodes
GETTING ACTION FROM:
action 2, numVisits=63281, meanQ=5.584118, numObservations: 4
action 3, numVisits=1646, meanQ=5.438446, numObservations: 5
action 0, numVisits=37, meanQ=4.490253, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.582467 0.800049 0.121641 0.98069 0.570546 0.860957 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=4644, meanQ=6.180263, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 60345 episodes
GETTING ACTION FROM:
action 2, numVisits=64987, meanQ=4.693983, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.582467 0.800049 0.121641 0.98069 0.570546 0.860957 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 437
Initial state: 0 0.545663 0.872642 0.41475 0.774514 0.68622 0.898605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55105 episodes
GETTING ACTION FROM:
action 1, numVisits=55099, meanQ=4.893188, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.545663 0.872642 0.41475 0.774514 0.68622 0.898605 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 438
Initial state: 0 0.48637 0.36208 0.524689 0.821089 0.585796 0.818749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 45988 episodes
GETTING ACTION FROM:
action 1, numVisits=34840, meanQ=4.812975, numObservations: 4
action 0, numVisits=6707, meanQ=3.081608, numObservations: 1
action -1, numVisits=4436, meanQ=3.064443, numObservations: 1
action 3, numVisits=4, meanQ=-0.504975, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.48637 0.36208 0.524689 0.821089 0.585796 0.818749 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4362, meanQ=8.363543, numObservations: 4
action 3, numVisits=10, meanQ=6.399010, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 45743 episodes
GETTING ACTION FROM:
action 2, numVisits=50090, meanQ=6.077128, numObservations: 4
action 3, numVisits=23, meanQ=3.521309, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.48637 0.36208 0.524689 0.821089 0.585796 0.818749 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 439
Initial state: 0 0.60324 0.864395 0.0234059 0.446479 0.696314 0.85708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55388 episodes
GETTING ACTION FROM:
action 2, numVisits=55335, meanQ=5.011333, numObservations: 4
action -1, numVisits=34, meanQ=3.798470, numObservations: 1
action 3, numVisits=16, meanQ=2.126269, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.60324 0.864395 0.0234059 0.446479 0.696314 0.85708 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2872, meanQ=8.552680, numObservations: 3
action 1, numVisits=2510, meanQ=8.501999, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 52216 episodes
GETTING ACTION FROM:
action 3, numVisits=8613, meanQ=6.793037, numObservations: 3
action 1, numVisits=48981, meanQ=6.091896, numObservations: 5
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.60324 0.864395 0.0234059 0.446479 0.696314 0.85708 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 440
Initial state: 0 0.925361 0.44016 0.652073 0.888137 0.670451 0.876544 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55548 episodes
GETTING ACTION FROM:
action 2, numVisits=55500, meanQ=5.016031, numObservations: 3
action 0, numVisits=41, meanQ=3.988261, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.925361 0.44016 0.652073 0.888137 0.670451 0.876544 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 441
Initial state: 0 0.547677 0.838372 0.862332 0.923089 0.562848 0.809377 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54183 episodes
GETTING ACTION FROM:
action 3, numVisits=54125, meanQ=4.845399, numObservations: 5
action -1, numVisits=54, meanQ=3.947181, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.547677 0.838372 0.862332 0.923089 0.562848 0.809377 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 442
Initial state: 0 0.520968 0.00200392 0.695152 0.894956 0.658143 0.809919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54975 episodes
GETTING ACTION FROM:
action 3, numVisits=54950, meanQ=4.950326, numObservations: 3
action 1, numVisits=20, meanQ=3.299515, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.520968 0.00200392 0.695152 0.894956 0.658143 0.809919 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 443
Initial state: 0 0.950808 0.00581415 0.515466 0.884724 0.555703 0.822479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55267 episodes
GETTING ACTION FROM:
action 2, numVisits=55261, meanQ=4.995911, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.950808 0.00581415 0.515466 0.884724 0.555703 0.822479 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 444
Initial state: 0 0.0813835 0.53161 0.552009 0.844139 0.680959 0.873875 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52310 episodes
GETTING ACTION FROM:
action 2, numVisits=52304, meanQ=4.828627, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.0813835 0.53161 0.552009 0.844139 0.680959 0.873875 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3787, meanQ=4.642977, numObservations: 5
action 3, numVisits=14, meanQ=2.569293, numObservations: 4
action 2, numVisits=5, meanQ=1.794000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 62181 episodes
GETTING ACTION FROM:
action 2, numVisits=62186, meanQ=4.939666, numObservations: 4
action 1, numVisits=3787, meanQ=4.642977, numObservations: 5
action 3, numVisits=14, meanQ=2.569293, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.0813835 0.53161 0.552009 0.844139 0.680959 0.873875 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 445
Initial state: 0 0.576168 0.569218 0.629179 0.840747 0.542902 0.876374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54861 episodes
GETTING ACTION FROM:
action 3, numVisits=54855, meanQ=4.927066, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.576168 0.569218 0.629179 0.840747 0.542902 0.876374 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4005, meanQ=4.727875, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67770 episodes
GETTING ACTION FROM:
action 2, numVisits=71751, meanQ=5.654612, numObservations: 4
action 3, numVisits=22, meanQ=3.452732, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 2
Next state: 1 0.576168 0.569218 0.629179 0.840747 0.542902 0.876374 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 446
Initial state: 0 0.572155 0.854895 0.606023 0.820474 0.816471 0.583441 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54876 episodes
GETTING ACTION FROM:
action 3, numVisits=54870, meanQ=4.949250, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.572155 0.854895 0.606023 0.820474 0.816471 0.583441 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 447
Initial state: 0 0.537573 0.834057 0.794031 0.573166 0.698248 0.819914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54925 episodes
GETTING ACTION FROM:
action 3, numVisits=54898, meanQ=4.849331, numObservations: 5
action -1, numVisits=12, meanQ=2.812500, numObservations: 1
action 2, numVisits=8, meanQ=1.996250, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.537573 0.834057 0.794031 0.573166 0.698248 0.819914 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 448
Initial state: 0 0.602141 0.834803 0.510184 0.895972 0.148488 0.0801632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55543 episodes
GETTING ACTION FROM:
action 2, numVisits=55528, meanQ=4.987367, numObservations: 4
action 3, numVisits=10, meanQ=2.598000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.602141 0.834803 0.510184 0.895972 0.148488 0.0801632 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 449
Initial state: 0 0.282679 0.710914 0.532351 0.833456 0.534605 0.870941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55043 episodes
GETTING ACTION FROM:
action 3, numVisits=54950, meanQ=4.983593, numObservations: 4
action 0, numVisits=72, meanQ=4.207832, numObservations: 1
action -1, numVisits=18, meanQ=3.269648, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.282679 0.710914 0.532351 0.833456 0.534605 0.870941 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 450
Initial state: 0 0.621138 0.848086 0.362452 0.376337 0.648389 0.860014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55245 episodes
GETTING ACTION FROM:
action 3, numVisits=55209, meanQ=4.960635, numObservations: 4
action 0, numVisits=26, meanQ=3.651423, numObservations: 1
action 2, numVisits=7, meanQ=2.427157, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.621138 0.848086 0.362452 0.376337 0.648389 0.860014 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 451
Initial state: 0 0.646293 0.869515 0.466803 0.827846 0.662123 0.859173 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55296 episodes
GETTING ACTION FROM:
action 2, numVisits=55226, meanQ=5.061684, numObservations: 5
action 0, numVisits=61, meanQ=4.203449, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.646293 0.869515 0.466803 0.827846 0.662123 0.859173 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 452
Initial state: 0 0.608953 0.823779 0.71866 0.963624 0.671534 0.881371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52901 episodes
GETTING ACTION FROM:
action 2, numVisits=52548, meanQ=4.801960, numObservations: 3
action 3, numVisits=345, meanQ=4.430593, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.608953 0.823779 0.71866 0.963624 0.671534 0.881371 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 453
Initial state: 0 0.60767 0.834807 0.0223417 0.269209 0.683967 0.834873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54924 episodes
GETTING ACTION FROM:
action 2, numVisits=54781, meanQ=5.074491, numObservations: 4
action 0, numVisits=42, meanQ=4.061676, numObservations: 1
action 1, numVisits=98, meanQ=3.513166, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.60767 0.834807 0.0223417 0.269209 0.683967 0.834873 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 454
Initial state: 0 0.518842 0.827907 0.955115 0.1458 0.524034 0.863966 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55732 episodes
GETTING ACTION FROM:
action 2, numVisits=55726, meanQ=5.089354, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.518842 0.827907 0.955115 0.1458 0.524034 0.863966 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 455
Initial state: 0 0.631786 0.895339 0.627165 0.821919 0.936412 0.183547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54883 episodes
GETTING ACTION FROM:
action 1, numVisits=54866, meanQ=4.887041, numObservations: 4
action 2, numVisits=12, meanQ=2.823342, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.631786 0.895339 0.627165 0.821919 0.936412 0.183547 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 456
Initial state: 0 0.605937 0.882647 0.17053 0.681226 0.515212 0.808804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55327 episodes
GETTING ACTION FROM:
action 2, numVisits=54056, meanQ=4.892144, numObservations: 4
action 3, numVisits=1200, meanQ=4.690905, numObservations: 3
action -1, numVisits=54, meanQ=3.985942, numObservations: 1
action 1, numVisits=15, meanQ=2.866000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.605937 0.882647 0.17053 0.681226 0.515212 0.808804 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8247, meanQ=8.282081, numObservations: 4
action 1, numVisits=4, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 41686 episodes
GETTING ACTION FROM:
action 3, numVisits=49915, meanQ=6.242043, numObservations: 4
action 1, numVisits=16, meanQ=2.498750, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 3
Next state: 1 0.605937 0.882647 0.17053 0.681226 0.515212 0.808804 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 457
Initial state: 0 0.670182 0.832103 0.647092 0.892076 0.165633 0.890514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55166 episodes
GETTING ACTION FROM:
action 3, numVisits=55111, meanQ=4.876774, numObservations: 4
action -1, numVisits=38, meanQ=3.813583, numObservations: 1
action 1, numVisits=13, meanQ=2.998469, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.670182 0.832103 0.647092 0.892076 0.165633 0.890514 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3899, meanQ=4.582741, numObservations: 4
action -1, numVisits=66, meanQ=3.946853, numObservations: 1
action 0, numVisits=34, meanQ=3.668173, numObservations: 1
action 2, numVisits=26, meanQ=2.526923, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
Sampled 66455 episodes
GETTING ACTION FROM:
action 1, numVisits=70349, meanQ=6.064955, numObservations: 4
action -1, numVisits=69, meanQ=3.755241, numObservations: 1
action 0, numVisits=36, meanQ=3.353274, numObservations: 1
action 2, numVisits=26, meanQ=2.526923, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 1 0.670182 0.832103 0.647092 0.892076 0.165633 0.890514 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 458
Initial state: 0 0.582638 0.892031 0.688018 0.845722 0.0344665 0.176204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55445 episodes
GETTING ACTION FROM:
action 3, numVisits=48305, meanQ=5.166199, numObservations: 4
action 2, numVisits=7063, meanQ=4.885612, numObservations: 4
action 0, numVisits=49, meanQ=4.239352, numObservations: 1
action -1, numVisits=22, meanQ=3.723594, numObservations: 1
action 1, numVisits=6, meanQ=1.015000, numObservations: 2
action: 3
Next state: 0 0.582638 0.892031 0.688018 0.845722 0.0344665 0.176204 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7186, meanQ=8.325216, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 47473 episodes
GETTING ACTION FROM:
action 2, numVisits=54608, meanQ=6.162160, numObservations: 3
action 1, numVisits=21, meanQ=3.285714, numObservations: 3
action -1, numVisits=31, meanQ=1.480968, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.582638 0.892031 0.688018 0.845722 0.0344665 0.176204 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 459
Initial state: 0 0.684382 0.829551 0.189725 0.952444 0.517738 0.812681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55221 episodes
GETTING ACTION FROM:
action 2, numVisits=55207, meanQ=4.984253, numObservations: 4
action 1, numVisits=8, meanQ=0.997500, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.684382 0.829551 0.189725 0.952444 0.517738 0.812681 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4015, meanQ=5.743440, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 61173 episodes
GETTING ACTION FROM:
action 2, numVisits=65186, meanQ=5.223903, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.684382 0.829551 0.189725 0.952444 0.517738 0.812681 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=122, meanQ=5.642604, numObservations: 3
action 1, numVisits=15, meanQ=3.666013, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 59896 episodes
GETTING ACTION FROM:
action 1, numVisits=59835, meanQ=5.708861, numObservations: 4
action 2, numVisits=141, meanQ=5.470977, numObservations: 4
action 3, numVisits=54, meanQ=3.740370, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 1
Next state: 1 0.684382 0.829551 0.189725 0.952444 0.517738 0.812681 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 460
Initial state: 0 0.502895 0.855206 0.607534 0.873553 0.829436 0.433832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50809 episodes
GETTING ACTION FROM:
action 1, numVisits=50734, meanQ=4.728811, numObservations: 4
action -1, numVisits=62, meanQ=3.917298, numObservations: 1
action 2, numVisits=10, meanQ=1.191020, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.502895 0.855206 0.607534 0.873553 0.829436 0.433832 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 461
Initial state: 0 0.616133 0.873456 0.371055 0.801164 0.691877 0.85503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55439 episodes
GETTING ACTION FROM:
action 1, numVisits=55391, meanQ=4.993742, numObservations: 5
action -1, numVisits=38, meanQ=3.930840, numObservations: 1
action 2, numVisits=5, meanQ=-0.201980, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.616133 0.873456 0.371055 0.801164 0.691877 0.85503 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 462
Initial state: 0 0.618863 0.823034 0.608944 0.87182 0.43963 0.335231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54870 episodes
GETTING ACTION FROM:
action 1, numVisits=54806, meanQ=5.004454, numObservations: 5
action 0, numVisits=56, meanQ=4.133908, numObservations: 1
action 3, numVisits=5, meanQ=1.780000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.618863 0.823034 0.608944 0.87182 0.43963 0.335231 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 463
Initial state: 0 0.506471 0.869761 0.206998 0.337247 0.651031 0.862611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54992 episodes
GETTING ACTION FROM:
action 2, numVisits=54943, meanQ=4.946316, numObservations: 3
action 0, numVisits=38, meanQ=3.827868, numObservations: 1
action 3, numVisits=8, meanQ=1.996250, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.506471 0.869761 0.206998 0.337247 0.651031 0.862611 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8430, meanQ=8.208184, numObservations: 5
action 1, numVisits=6, meanQ=3.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 43020 episodes
GETTING ACTION FROM:
action 3, numVisits=51331, meanQ=6.048875, numObservations: 5
action 1, numVisits=120, meanQ=5.215668, numObservations: 5
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 3
Next state: 1 0.506471 0.869761 0.206998 0.337247 0.651031 0.862611 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 464
Initial state: 0 0.673283 0.890443 0.66869 0.841716 0.827474 0.636289 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55591 episodes
GETTING ACTION FROM:
action 3, numVisits=55539, meanQ=4.999962, numObservations: 4
action 0, numVisits=45, meanQ=3.985009, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.673283 0.890443 0.66869 0.841716 0.827474 0.636289 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 465
Initial state: 0 0.523869 0.0237057 0.536332 0.864615 0.577536 0.809191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54366 episodes
GETTING ACTION FROM:
action 3, numVisits=54344, meanQ=4.968444, numObservations: 5
action -1, numVisits=17, meanQ=3.309954, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.523869 0.0237057 0.536332 0.864615 0.577536 0.809191 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 466
Initial state: 0 0.465254 0.673761 0.682568 0.817657 0.595998 0.836634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54972 episodes
GETTING ACTION FROM:
action 2, numVisits=54965, meanQ=4.895720, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.465254 0.673761 0.682568 0.817657 0.595998 0.836634 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 467
Initial state: 0 0.969078 0.881744 0.664258 0.835729 0.65296 0.888982 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55427 episodes
GETTING ACTION FROM:
action 2, numVisits=55345, meanQ=4.953609, numObservations: 4
action 3, numVisits=54, meanQ=3.656298, numObservations: 5
action 0, numVisits=25, meanQ=3.644769, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.969078 0.881744 0.664258 0.835729 0.65296 0.888982 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4014, meanQ=5.561346, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 66922 episodes
GETTING ACTION FROM:
action 1, numVisits=66921, meanQ=5.742461, numObservations: 4
action 2, numVisits=4014, meanQ=5.561346, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.969078 0.881744 0.664258 0.835729 0.65296 0.888982 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 468
Initial state: 0 0.687922 0.897453 0.905551 0.681298 0.592321 0.861555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52881 episodes
GETTING ACTION FROM:
action 3, numVisits=52764, meanQ=4.869846, numObservations: 3
action -1, numVisits=84, meanQ=4.157525, numObservations: 1
action 0, numVisits=25, meanQ=3.508605, numObservations: 1
action 1, numVisits=6, meanQ=1.331683, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 1 0.687922 0.897453 0.905551 0.681298 0.592321 0.861555 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 469
Initial state: 0 0.122921 0.0141673 0.639242 0.831036 0.617683 0.890267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51020 episodes
GETTING ACTION FROM:
action 2, numVisits=44818, meanQ=4.996897, numObservations: 5
action -1, numVisits=6192, meanQ=3.104066, numObservations: 1
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.122921 0.0141673 0.639242 0.831036 0.617683 0.890267 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 470
Initial state: 0 0.61637 0.851781 0.163979 0.98466 0.69604 0.816542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52401 episodes
GETTING ACTION FROM:
action 2, numVisits=52342, meanQ=4.860487, numObservations: 4
action 0, numVisits=41, meanQ=3.800959, numObservations: 1
action 3, numVisits=15, meanQ=2.465340, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.61637 0.851781 0.163979 0.98466 0.69604 0.816542 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7933, meanQ=8.281838, numObservations: 3
action 3, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 46715 episodes
GETTING ACTION FROM:
action 1, numVisits=54629, meanQ=6.237230, numObservations: 3
action 3, numVisits=18, meanQ=2.333339, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-2.003300, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.61637 0.851781 0.163979 0.98466 0.69604 0.816542 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 471
Initial state: 0 0.335717 0.141845 0.548216 0.86009 0.548587 0.842755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53190 episodes
GETTING ACTION FROM:
action 1, numVisits=50558, meanQ=4.931052, numObservations: 4
action 0, numVisits=2626, meanQ=2.859334, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.335717 0.141845 0.548216 0.86009 0.548587 0.842755 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6271, meanQ=8.372666, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 56024 episodes
GETTING ACTION FROM:
action 3, numVisits=62291, meanQ=6.183755, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.335717 0.141845 0.548216 0.86009 0.548587 0.842755 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 472
Initial state: 0 0.659262 0.881834 0.64268 0.860538 0.610082 0.772653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55075 episodes
GETTING ACTION FROM:
action 2, numVisits=55069, meanQ=5.084613, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.659262 0.881834 0.64268 0.860538 0.610082 0.772653 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 473
Initial state: 0 0.0312552 0.679352 0.617074 0.880506 0.654353 0.851322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55444 episodes
GETTING ACTION FROM:
action 1, numVisits=55243, meanQ=4.917159, numObservations: 5
action 3, numVisits=164, meanQ=4.261959, numObservations: 5
action 0, numVisits=33, meanQ=3.692104, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0312552 0.679352 0.617074 0.880506 0.654353 0.851322 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5465, meanQ=8.521244, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 43843 episodes
GETTING ACTION FROM:
action 2, numVisits=49255, meanQ=6.075029, numObservations: 4
action 3, numVisits=50, meanQ=4.201600, numObservations: 4
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=3, meanQ=-2.003300, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0312552 0.679352 0.617074 0.880506 0.654353 0.851322 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 474
Initial state: 0 0.0834353 0.0437178 0.515162 0.882159 0.527605 0.828955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55409 episodes
GETTING ACTION FROM:
action 2, numVisits=55311, meanQ=4.992040, numObservations: 5
action -1, numVisits=58, meanQ=4.138881, numObservations: 1
action 3, numVisits=21, meanQ=3.285719, numObservations: 4
action 1, numVisits=17, meanQ=3.234124, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.0834353 0.0437178 0.515162 0.882159 0.527605 0.828955 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 475
Initial state: 0 0.549408 0.859547 0.599704 0.828808 0.950154 0.389324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55069 episodes
GETTING ACTION FROM:
action 1, numVisits=55044, meanQ=4.916449, numObservations: 4
action 0, numVisits=19, meanQ=3.363725, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.549408 0.859547 0.599704 0.828808 0.950154 0.389324 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 476
Initial state: 0 0.554337 0.872502 0.524764 0.837953 0.473342 0.0336622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54928 episodes
GETTING ACTION FROM:
action 2, numVisits=54704, meanQ=5.004032, numObservations: 4
action 1, numVisits=219, meanQ=4.377566, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.554337 0.872502 0.524764 0.837953 0.473342 0.0336622 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 477
Initial state: 0 0.639164 0.837368 0.863314 0.0284432 0.683895 0.821801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54943 episodes
GETTING ACTION FROM:
action 3, numVisits=54900, meanQ=4.943858, numObservations: 4
action -1, numVisits=39, meanQ=3.902374, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.639164 0.837368 0.863314 0.0284432 0.683895 0.821801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.62806 0.882649 0.377007 0.725971 0.500256 0.826455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32177 episodes
GETTING ACTION FROM:
action 0, numVisits=32163, meanQ=2.910271, numObservations: 1
action 2, numVisits=9, meanQ=0.331122, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.62806 0.882649 0.377007 0.725971 0.500256 0.826455 w: 1
Observation: 0 0 0.981575 0 0.723143 0 0.784517 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32152, meanQ=4.905455, numObservations: 4
action 3, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55386 episodes
GETTING ACTION FROM:
action 2, numVisits=87536, meanQ=4.793720, numObservations: 4
action 3, numVisits=6, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.62806 0.882649 0.377007 0.725971 0.500256 0.826455 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2310, meanQ=7.922686, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 44264 episodes
GETTING ACTION FROM:
action 3, numVisits=46310, meanQ=6.119178, numObservations: 5
action 1, numVisits=262, meanQ=5.402902, numObservations: 3
action -1, numVisits=3, meanQ=-2.663300, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.62806 0.882649 0.377007 0.725971 0.500256 0.826455 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 479
Initial state: 0 0.516025 0.803081 0.383375 0.745126 0.656356 0.866961 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55232 episodes
GETTING ACTION FROM:
action 1, numVisits=55221, meanQ=5.028093, numObservations: 5
action 2, numVisits=6, meanQ=2.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.516025 0.803081 0.383375 0.745126 0.656356 0.866961 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 480
Initial state: 0 0.526137 0.861515 0.603296 0.867388 0.819595 0.951097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54392 episodes
GETTING ACTION FROM:
action 2, numVisits=54352, meanQ=4.877851, numObservations: 4
action 0, numVisits=16, meanQ=3.246834, numObservations: 1
action 1, numVisits=20, meanQ=3.176000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.526137 0.861515 0.603296 0.867388 0.819595 0.951097 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 481
Initial state: 0 0.568846 0.821772 0.778355 0.82359 0.641496 0.874379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52575 episodes
GETTING ACTION FROM:
action 2, numVisits=52490, meanQ=4.838976, numObservations: 4
action 3, numVisits=80, meanQ=3.385864, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.568846 0.821772 0.778355 0.82359 0.641496 0.874379 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 482
Initial state: 0 0.0505046 0.434252 0.538527 0.839489 0.685142 0.841743 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32600 episodes
GETTING ACTION FROM:
action 0, numVisits=32592, meanQ=2.976938, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0505046 0.434252 0.538527 0.839489 0.685142 0.841743 w: 1
Observation: 0 0 0.387101 0 0.794349 0 0.917951 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32573, meanQ=5.054226, numObservations: 4
action 3, numVisits=13, meanQ=3.161538, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 55641 episodes
GETTING ACTION FROM:
action 2, numVisits=88194, meanQ=4.783261, numObservations: 4
action 3, numVisits=32, meanQ=3.375009, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.0505046 0.434252 0.538527 0.839489 0.685142 0.841743 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 483
Initial state: 0 0.792765 0.698702 0.55058 0.825544 0.608684 0.89404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55479 episodes
GETTING ACTION FROM:
action 2, numVisits=55472, meanQ=4.921464, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.792765 0.698702 0.55058 0.825544 0.608684 0.89404 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 484
Initial state: 0 0.0711243 0.749006 0.64156 0.843694 0.615844 0.891314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55265 episodes
GETTING ACTION FROM:
action 1, numVisits=55168, meanQ=4.983798, numObservations: 3
action 0, numVisits=68, meanQ=4.195624, numObservations: 1
action -1, numVisits=27, meanQ=3.718077, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0711243 0.749006 0.64156 0.843694 0.615844 0.891314 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8384, meanQ=8.203087, numObservations: 5
action 2, numVisits=57, meanQ=7.414740, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 43940 episodes
GETTING ACTION FROM:
action 3, numVisits=52200, meanQ=6.338696, numObservations: 5
action 2, numVisits=160, meanQ=5.309064, numObservations: 3
action 0, numVisits=20, meanQ=1.296065, numObservations: 1
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0711243 0.749006 0.64156 0.843694 0.615844 0.891314 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 485
Initial state: 0 0.569004 0.0359105 0.538979 0.879664 0.633587 0.879416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32289 episodes
GETTING ACTION FROM:
action -1, numVisits=32276, meanQ=2.981274, numObservations: 1
action 1, numVisits=9, meanQ=-1.670000, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.569004 0.0359105 0.538979 0.879664 0.633587 0.879416 w: 1
Observation: 0 0.605025 0 0.521347 0 0.569808 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32220, meanQ=5.024983, numObservations: 4
action 0, numVisits=42, meanQ=4.029040, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 55653 episodes
GETTING ACTION FROM:
action 3, numVisits=87872, meanQ=5.017687, numObservations: 4
action 0, numVisits=43, meanQ=3.987847, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.569004 0.0359105 0.538979 0.879664 0.633587 0.879416 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 486
Initial state: 0 0.344008 0.0804168 0.511509 0.897272 0.513854 0.882708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52102 episodes
GETTING ACTION FROM:
action 1, numVisits=47660, meanQ=4.932760, numObservations: 4
action -1, numVisits=4436, meanQ=2.699182, numObservations: 1
action 2, numVisits=3, meanQ=-2.966667, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.344008 0.0804168 0.511509 0.897272 0.513854 0.882708 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5983, meanQ=8.339760, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 49647 episodes
GETTING ACTION FROM:
action 3, numVisits=53540, meanQ=6.329340, numObservations: 5
action 2, numVisits=2088, meanQ=5.691042, numObservations: 4
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.344008 0.0804168 0.511509 0.897272 0.513854 0.882708 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 487
Initial state: 0 0.503994 0.873002 0.515173 0.886915 0.432244 0.0606377 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31092 episodes
GETTING ACTION FROM:
action -1, numVisits=31084, meanQ=2.671404, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.503994 0.873002 0.515173 0.886915 0.432244 0.0606377 w: 1
Observation: 0 0.577655 0 0.46446 0 0.376753 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31072, meanQ=4.733224, numObservations: 4
action 1, numVisits=6, meanQ=0.331683, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 52308 episodes
GETTING ACTION FROM:
action 2, numVisits=83374, meanQ=4.795963, numObservations: 4
action 3, numVisits=7, meanQ=0.411429, numObservations: 3
action 1, numVisits=6, meanQ=0.331683, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.503994 0.873002 0.515173 0.886915 0.432244 0.0606377 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 488
Initial state: 0 0.105627 0.924643 0.566811 0.822494 0.509284 0.869828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55533 episodes
GETTING ACTION FROM:
action 3, numVisits=55470, meanQ=4.984334, numObservations: 4
action 0, numVisits=22, meanQ=3.588116, numObservations: 1
action -1, numVisits=23, meanQ=3.582257, numObservations: 1
action 1, numVisits=17, meanQ=2.411176, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.105627 0.924643 0.566811 0.822494 0.509284 0.869828 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 489
Initial state: 0 0.680606 0.844398 0.936353 0.45665 0.53474 0.824524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55373 episodes
GETTING ACTION FROM:
action 1, numVisits=55320, meanQ=4.941390, numObservations: 4
action -1, numVisits=39, meanQ=3.881649, numObservations: 1
action 3, numVisits=11, meanQ=2.633645, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.680606 0.844398 0.936353 0.45665 0.53474 0.824524 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 490
Initial state: 0 0.659212 0.868711 0.0698753 0.413718 0.693352 0.800278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55337 episodes
GETTING ACTION FROM:
action 1, numVisits=55196, meanQ=5.021652, numObservations: 5
action 0, numVisits=129, meanQ=4.453930, numObservations: 1
action 2, numVisits=9, meanQ=2.553344, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.659212 0.868711 0.0698753 0.413718 0.693352 0.800278 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 491
Initial state: 0 0.695066 0.820149 0.545182 0.85735 0.650673 0.827884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54952 episodes
GETTING ACTION FROM:
action 3, numVisits=54914, meanQ=4.917833, numObservations: 4
action -1, numVisits=27, meanQ=3.665589, numObservations: 1
action 1, numVisits=7, meanQ=2.144300, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.695066 0.820149 0.545182 0.85735 0.650673 0.827884 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 492
Initial state: 0 0.682709 0.832948 0.324972 0.319893 0.691257 0.879109 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55692 episodes
GETTING ACTION FROM:
action 2, numVisits=55683, meanQ=5.014096, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.682709 0.832948 0.324972 0.319893 0.691257 0.879109 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 493
Initial state: 0 0.0217791 0.836597 0.552811 0.894814 0.546186 0.80899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55153 episodes
GETTING ACTION FROM:
action 1, numVisits=55125, meanQ=5.128932, numObservations: 5
action 0, numVisits=23, meanQ=3.706024, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0217791 0.836597 0.552811 0.894814 0.546186 0.80899 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3617, meanQ=7.275522, numObservations: 4
action 3, numVisits=4, meanQ=2.995000, numObservations: 2
action 2, numVisits=4, meanQ=2.002525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 66271 episodes
GETTING ACTION FROM:
action 2, numVisits=47493, meanQ=6.066682, numObservations: 3
action 1, numVisits=22390, meanQ=5.125016, numObservations: 5
action 3, numVisits=11, meanQ=3.180000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.0217791 0.836597 0.552811 0.894814 0.546186 0.80899 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=568, meanQ=7.450621, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 61534 episodes
GETTING ACTION FROM:
action 1, numVisits=59467, meanQ=5.710276, numObservations: 4
action 3, numVisits=2633, meanQ=5.479776, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0217791 0.836597 0.552811 0.894814 0.546186 0.80899 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=192, meanQ=8.411876, numObservations: 3
action 2, numVisits=5, meanQ=6.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 69949 episodes
GETTING ACTION FROM:
action 3, numVisits=69360, meanQ=5.664765, numObservations: 3
action 2, numVisits=713, meanQ=5.617097, numObservations: 4
action 1, numVisits=70, meanQ=4.656857, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 3
Next state: 1 0.0217791 0.836597 0.552811 0.894814 0.546186 0.80899 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 494
Initial state: 0 0.260462 0.128613 0.559596 0.849186 0.512581 0.81452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52243 episodes
GETTING ACTION FROM:
action 3, numVisits=47735, meanQ=5.004957, numObservations: 4
action 0, numVisits=4504, meanQ=2.704814, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.260462 0.128613 0.559596 0.849186 0.512581 0.81452 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 495
Initial state: 0 0.123683 0.0974254 0.628267 0.870848 0.560301 0.807338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55215 episodes
GETTING ACTION FROM:
action 3, numVisits=54973, meanQ=4.939099, numObservations: 5
action 1, numVisits=164, meanQ=4.398239, numObservations: 4
action -1, numVisits=42, meanQ=3.915941, numObservations: 1
action 0, numVisits=35, meanQ=3.796871, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.123683 0.0974254 0.628267 0.870848 0.560301 0.807338 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 496
Initial state: 0 0.546391 0.868653 0.656452 0.84988 0.0500792 0.694844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55136 episodes
GETTING ACTION FROM:
action 3, numVisits=55072, meanQ=4.988451, numObservations: 4
action 0, numVisits=60, meanQ=4.148123, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.546391 0.868653 0.656452 0.84988 0.0500792 0.694844 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8416, meanQ=8.297409, numObservations: 4
action 1, numVisits=8, meanQ=5.501263, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 45743 episodes
GETTING ACTION FROM:
action 2, numVisits=54149, meanQ=6.460705, numObservations: 4
action 1, numVisits=10, meanQ=2.201010, numObservations: 3
action -1, numVisits=5, meanQ=-0.020000, numObservations: 1
action 3, numVisits=3, meanQ=-0.329967, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 2
Next state: 1 0.546391 0.868653 0.656452 0.84988 0.0500792 0.694844 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 497
Initial state: 0 0.543905 0.838372 0.688193 0.92467 0.599965 0.897999 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55418 episodes
GETTING ACTION FROM:
action 2, numVisits=55411, meanQ=4.979798, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.543905 0.838372 0.688193 0.92467 0.599965 0.897999 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 498
Initial state: 0 0.606073 0.878448 0.630365 0.411849 0.508208 0.897104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54951 episodes
GETTING ACTION FROM:
action 1, numVisits=54904, meanQ=5.007133, numObservations: 4
action -1, numVisits=43, meanQ=3.985060, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.606073 0.878448 0.630365 0.411849 0.508208 0.897104 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 499
Initial state: 0 0.54816 0.828403 0.527092 0.888379 0.926527 0.602243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55111 episodes
GETTING ACTION FROM:
action 2, numVisits=55105, meanQ=4.983064, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.54816 0.828403 0.527092 0.888379 0.926527 0.602243 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 500
Initial state: 0 0.705581 0.17477 0.533831 0.863732 0.521701 0.861678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54981 episodes
GETTING ACTION FROM:
action 3, numVisits=54804, meanQ=4.949273, numObservations: 4
action 0, numVisits=132, meanQ=4.347271, numObservations: 1
action 2, numVisits=42, meanQ=3.566676, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.705581 0.17477 0.533831 0.863732 0.521701 0.861678 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
