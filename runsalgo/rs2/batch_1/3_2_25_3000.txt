Run # 1
Initial state: 0 0.600914 0.854824 0.437076 0.428716 0.520629 0.894026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159679 episodes
GETTING ACTION FROM:
action 3, numVisits=159655, meanQ=5.003107, numObservations: 4
action 0, numVisits=17, meanQ=3.329803, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 3
Next state: 1 0.600914 0.854824 0.437076 0.428716 0.520629 0.894026 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.645857 0.163892 0.630375 0.878359 0.55557 0.82875 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162535 episodes
GETTING ACTION FROM:
action 2, numVisits=162513, meanQ=4.977942, numObservations: 4
action 3, numVisits=10, meanQ=2.300010, numObservations: 3
action 1, numVisits=8, meanQ=1.877537, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.645857 0.163892 0.630375 0.878359 0.55557 0.82875 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12103, meanQ=4.635776, numObservations: 5
action 3, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 201700 episodes
GETTING ACTION FROM:
action 1, numVisits=213783, meanQ=5.757832, numObservations: 5
action 2, numVisits=21, meanQ=3.282390, numObservations: 4
action 3, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.645857 0.163892 0.630375 0.878359 0.55557 0.82875 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 3
Initial state: 0 0.875927 0.493876 0.507145 0.842207 0.674904 0.819966 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95615 episodes
GETTING ACTION FROM:
action 0, numVisits=95609, meanQ=3.086295, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-4.499950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.875927 0.493876 0.507145 0.842207 0.674904 0.819966 w: 1
Observation: 0 0 0.558941 0 0.87284 0 0.794186 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=95448, meanQ=5.132056, numObservations: 4
action 0, numVisits=65, meanQ=4.292802, numObservations: 1
action -1, numVisits=63, meanQ=4.291095, numObservations: 1
action 3, numVisits=19, meanQ=2.980005, numObservations: 3
action 2, numVisits=13, meanQ=2.536923, numObservations: 4
Sampled 162741 episodes
GETTING ACTION FROM:
action 1, numVisits=258188, meanQ=5.194624, numObservations: 4
action 0, numVisits=65, meanQ=4.292802, numObservations: 1
action -1, numVisits=64, meanQ=4.280574, numObservations: 1
action 3, numVisits=19, meanQ=2.980005, numObservations: 3
action 2, numVisits=13, meanQ=2.536923, numObservations: 4
action: 1
Next state: 2 0.875927 0.493876 0.507145 0.842207 0.674904 0.819966 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 4
Initial state: 0 0.684158 0.845666 0.93084 0.332172 0.665491 0.80059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94843 episodes
GETTING ACTION FROM:
action -1, numVisits=94817, meanQ=2.985486, numObservations: 1
action 2, numVisits=17, meanQ=1.058265, numObservations: 3
action 1, numVisits=6, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.684158 0.845666 0.93084 0.332172 0.665491 0.80059 w: 1
Observation: 0 0.748214 0 0.835585 0 0.590915 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=94794, meanQ=5.001176, numObservations: 5
action 0, numVisits=18, meanQ=3.331583, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 160862 episodes
GETTING ACTION FROM:
action 1, numVisits=255654, meanQ=5.060243, numObservations: 5
action 0, numVisits=19, meanQ=3.272658, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.684158 0.845666 0.93084 0.332172 0.665491 0.80059 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 5
Initial state: 0 0.534436 0.857945 0.570051 0.868088 0.322546 0.925033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159523 episodes
GETTING ACTION FROM:
action 2, numVisits=159516, meanQ=4.966881, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.534436 0.857945 0.570051 0.868088 0.322546 0.925033 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 6
Initial state: 0 0.885739 0.698962 0.540243 0.85524 0.696051 0.809429 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95856 episodes
GETTING ACTION FROM:
action 0, numVisits=95711, meanQ=2.952549, numObservations: 1
action -1, numVisits=133, meanQ=2.385043, numObservations: 1
action 2, numVisits=7, meanQ=0.287157, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 0
Next state: 0 0.885739 0.698962 0.540243 0.85524 0.696051 0.809429 w: 1
Observation: 0 0 0.790925 0 0.858484 0 0.850885 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=83311, meanQ=5.002044, numObservations: 4
action 3, numVisits=12394, meanQ=4.917839, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 166057 episodes
GETTING ACTION FROM:
action 2, numVisits=249360, meanQ=5.102514, numObservations: 4
action 3, numVisits=12394, meanQ=4.917839, numObservations: 3
action 1, numVisits=9, meanQ=2.333344, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.885739 0.698962 0.540243 0.85524 0.696051 0.809429 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 7
Initial state: 0 0.901185 0.199997 0.500694 0.848676 0.638837 0.864577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164072 episodes
GETTING ACTION FROM:
action 3, numVisits=164046, meanQ=5.061942, numObservations: 4
action 1, numVisits=14, meanQ=3.215007, numObservations: 4
action 2, numVisits=8, meanQ=2.498750, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.901185 0.199997 0.500694 0.848676 0.638837 0.864577 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 8
Initial state: 0 0.542003 0.855383 0.905132 0.208736 0.557287 0.826177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153955 episodes
GETTING ACTION FROM:
action 3, numVisits=152558, meanQ=4.861494, numObservations: 5
action 0, numVisits=1386, meanQ=3.296173, numObservations: 1
action 2, numVisits=7, meanQ=1.002886, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.542003 0.855383 0.905132 0.208736 0.557287 0.826177 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 9
Initial state: 0 0.532668 0.841301 0.0423562 0.79025 0.516743 0.851471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162244 episodes
GETTING ACTION FROM:
action 1, numVisits=162237, meanQ=4.948332, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.532668 0.841301 0.0423562 0.79025 0.516743 0.851471 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 10
Initial state: 0 0.342485 0.726491 0.60774 0.859412 0.663962 0.838125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162335 episodes
GETTING ACTION FROM:
action 3, numVisits=162148, meanQ=4.980404, numObservations: 3
action 2, numVisits=138, meanQ=4.175998, numObservations: 4
action -1, numVisits=36, meanQ=3.834685, numObservations: 1
action 1, numVisits=11, meanQ=2.453636, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.342485 0.726491 0.60774 0.859412 0.663962 0.838125 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 11
Initial state: 0 0.642998 0.826307 0.601822 0.88683 0.665378 0.176215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158771 episodes
GETTING ACTION FROM:
action 2, numVisits=154006, meanQ=4.981089, numObservations: 5
action -1, numVisits=4760, meanQ=3.031301, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.642998 0.826307 0.601822 0.88683 0.665378 0.176215 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 12
Initial state: 0 0.567005 0.876713 0.207287 0.493421 0.593573 0.887883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162101 episodes
GETTING ACTION FROM:
action 2, numVisits=162094, meanQ=4.965339, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.567005 0.876713 0.207287 0.493421 0.593573 0.887883 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=18257, meanQ=8.534256, numObservations: 3
action 1, numVisits=26, meanQ=7.304235, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9419 episodes
GETTING ACTION FROM:
action 3, numVisits=20591, meanQ=8.267281, numObservations: 5
action 1, numVisits=54, meanQ=5.590928, numObservations: 4
action 2, numVisits=12, meanQ=5.165842, numObservations: 3
action -1, numVisits=7041, meanQ=0.145070, numObservations: 1
action 0, numVisits=7, meanQ=-56.485915, numObservations: 1
action: 3
Next state: 1 0.567005 0.876713 0.207287 0.493421 0.593573 0.887883 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 13
Initial state: 0 0.598391 0.806795 0.136687 0.0414929 0.518968 0.883852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159131 episodes
GETTING ACTION FROM:
action 2, numVisits=153342, meanQ=5.000309, numObservations: 4
action -1, numVisits=5683, meanQ=3.000876, numObservations: 1
action 0, numVisits=102, meanQ=2.492200, numObservations: 1
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 2
Next state: 0 0.598391 0.806795 0.136687 0.0414929 0.518968 0.883852 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=25192, meanQ=8.323016, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13556 episodes
GETTING ACTION FROM:
action 1, numVisits=25192, meanQ=8.323016, numObservations: 4
action 3, numVisits=18, meanQ=3.166111, numObservations: 3
action -1, numVisits=13526, meanQ=0.256228, numObservations: 1
action 2, numVisits=10, meanQ=0.090563, numObservations: 3
action 0, numVisits=7, meanQ=-2.287100, numObservations: 1
action: 1
Next state: 1 0.598391 0.806795 0.136687 0.0414929 0.518968 0.883852 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 14
Initial state: 0 0.801834 0.592019 0.578451 0.858777 0.588875 0.811003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95589 episodes
GETTING ACTION FROM:
action 0, numVisits=95567, meanQ=2.948404, numObservations: 1
action 1, numVisits=12, meanQ=0.331667, numObservations: 3
action 3, numVisits=6, meanQ=0.166667, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 0
Next state: 0 0.801834 0.592019 0.578451 0.858777 0.588875 0.811003 w: 1
Observation: 0 0 0.650419 0 0.834893 0 0.781123 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=95559, meanQ=4.992636, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 162590 episodes
GETTING ACTION FROM:
action 1, numVisits=258131, meanQ=5.002276, numObservations: 4
action 2, numVisits=17, meanQ=2.465300, numObservations: 3
action 3, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.801834 0.592019 0.578451 0.858777 0.588875 0.811003 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 15
Initial state: 0 0.0899632 0.725878 0.625715 0.806523 0.574095 0.8016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157503 episodes
GETTING ACTION FROM:
action 2, numVisits=157417, meanQ=4.896699, numObservations: 4
action -1, numVisits=60, meanQ=4.004816, numObservations: 1
action 3, numVisits=23, meanQ=2.514352, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0899632 0.725878 0.625715 0.806523 0.574095 0.8016 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 16
Initial state: 0 0.60662 0.863245 0.542516 0.836929 0.786211 0.422273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161746 episodes
GETTING ACTION FROM:
action 1, numVisits=161739, meanQ=5.021735, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.60662 0.863245 0.542516 0.836929 0.786211 0.422273 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 17
Initial state: 0 0.529731 0.863297 0.697713 0.891451 0.467252 0.0269466 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163118 episodes
GETTING ACTION FROM:
action 3, numVisits=163108, meanQ=5.016133, numObservations: 4
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.529731 0.863297 0.697713 0.891451 0.467252 0.0269466 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7990, meanQ=7.821136, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 18894 episodes
GETTING ACTION FROM:
action 1, numVisits=7990, meanQ=7.821136, numObservations: 4
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=18884, meanQ=0.299217, numObservations: 1
action 3, numVisits=5, meanQ=-0.002000, numObservations: 3
action 0, numVisits=3, meanQ=-130.346688, numObservations: 1
action: 1
Next state: 1 0.529731 0.863297 0.697713 0.891451 0.467252 0.0269466 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 18
Initial state: 0 0.688653 0.852058 0.699109 0.750711 0.67932 0.803123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154042 episodes
GETTING ACTION FROM:
action 3, numVisits=154034, meanQ=4.868583, numObservations: 5
action 2, numVisits=3, meanQ=0.000033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.688653 0.852058 0.699109 0.750711 0.67932 0.803123 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 19
Initial state: 0 0.623363 0.847574 0.392031 0.123966 0.538129 0.828382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162005 episodes
GETTING ACTION FROM:
action 3, numVisits=161250, meanQ=4.972515, numObservations: 3
action -1, numVisits=751, meanQ=3.136529, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.623363 0.847574 0.392031 0.123966 0.538129 0.828382 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 20
Initial state: 0 0.0447071 0.303629 0.507845 0.811858 0.586074 0.838707 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163757 episodes
GETTING ACTION FROM:
action 1, numVisits=163689, meanQ=5.175770, numObservations: 5
action 3, numVisits=50, meanQ=4.189608, numObservations: 4
action -1, numVisits=15, meanQ=3.345517, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.0447071 0.303629 0.507845 0.811858 0.586074 0.838707 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=18760, meanQ=8.542003, numObservations: 3
action 2, numVisits=21, meanQ=7.095243, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7517 episodes
GETTING ACTION FROM:
action 3, numVisits=18760, meanQ=8.542003, numObservations: 3
action 2, numVisits=59, meanQ=4.302461, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action 0, numVisits=7475, meanQ=0.428973, numObservations: 1
action -1, numVisits=5, meanQ=-3.633556, numObservations: 1
action: 3
Next state: 1 0.0447071 0.303629 0.507845 0.811858 0.586074 0.838707 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 21
Initial state: 0 0.969332 0.397358 0.58782 0.837127 0.601419 0.801625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162476 episodes
GETTING ACTION FROM:
action 1, numVisits=109252, meanQ=5.157380, numObservations: 4
action 2, numVisits=53188, meanQ=5.016287, numObservations: 5
action 3, numVisits=32, meanQ=3.837500, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.969332 0.397358 0.58782 0.837127 0.601419 0.801625 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.546693 0.820038 0.0633622 0.68772 0.544768 0.821953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162404 episodes
GETTING ACTION FROM:
action 3, numVisits=162396, meanQ=4.968461, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.546693 0.820038 0.0633622 0.68772 0.544768 0.821953 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 23
Initial state: 0 0.577431 0.896767 0.5237 0.852374 0.692484 0.46641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154611 episodes
GETTING ACTION FROM:
action 2, numVisits=154596, meanQ=4.885073, numObservations: 3
action 3, numVisits=8, meanQ=1.500012, numObservations: 2
action 1, numVisits=3, meanQ=0.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.577431 0.896767 0.5237 0.852374 0.692484 0.46641 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 24
Initial state: 0 0.689409 0.831935 0.595123 0.806202 0.980388 0.923577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163187 episodes
GETTING ACTION FROM:
action 1, numVisits=163100, meanQ=5.041909, numObservations: 5
action 2, numVisits=42, meanQ=3.945721, numObservations: 4
action 3, numVisits=26, meanQ=3.374238, numObservations: 4
action 0, numVisits=17, meanQ=3.259874, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.689409 0.831935 0.595123 0.806202 0.980388 0.923577 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 25
Initial state: 0 0.560153 0.818571 0.180419 0.969191 0.63901 0.830753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156627 episodes
GETTING ACTION FROM:
action 2, numVisits=156620, meanQ=5.020058, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.560153 0.818571 0.180419 0.969191 0.63901 0.830753 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=9436, meanQ=5.295311, numObservations: 1
action 3, numVisits=781, meanQ=3.966487, numObservations: 5
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 200383 episodes
GETTING ACTION FROM:
action 3, numVisits=198286, meanQ=6.143870, numObservations: 5
action -1, numVisits=12305, meanQ=4.032732, numObservations: 1
action 0, numVisits=10, meanQ=1.663000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.560153 0.818571 0.180419 0.969191 0.63901 0.830753 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 26
Initial state: 0 0.961706 0.626819 0.508832 0.883607 0.524309 0.873537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162439 episodes
GETTING ACTION FROM:
action 2, numVisits=162421, meanQ=5.015868, numObservations: 5
action 1, numVisits=13, meanQ=2.540031, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.961706 0.626819 0.508832 0.883607 0.524309 0.873537 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 27
Initial state: 0 0.4057 0.156854 0.637063 0.841969 0.593245 0.861278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162154 episodes
GETTING ACTION FROM:
action 3, numVisits=162131, meanQ=4.968626, numObservations: 5
action 1, numVisits=9, meanQ=2.333333, numObservations: 3
action 2, numVisits=10, meanQ=1.991000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.4057 0.156854 0.637063 0.841969 0.593245 0.861278 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 28
Initial state: 0 0.636867 0.661078 0.680316 0.851748 0.507306 0.882808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162723 episodes
GETTING ACTION FROM:
action 1, numVisits=162649, meanQ=4.994592, numObservations: 4
action 0, numVisits=56, meanQ=4.082326, numObservations: 1
action -1, numVisits=13, meanQ=2.976024, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-3.296667, numObservations: 1
action: 1
Next state: 2 0.636867 0.661078 0.680316 0.851748 0.507306 0.882808 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 29
Initial state: 0 0.545686 0.806519 0.549823 0.890017 0.0883418 0.262891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156829 episodes
GETTING ACTION FROM:
action 1, numVisits=149762, meanQ=4.979233, numObservations: 5
action 0, numVisits=7059, meanQ=2.812185, numObservations: 1
action 2, numVisits=5, meanQ=-0.795980, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.545686 0.806519 0.549823 0.890017 0.0883418 0.262891 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 30
Initial state: 0 0.519922 0.613731 0.506604 0.868007 0.55543 0.867203 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162022 episodes
GETTING ACTION FROM:
action 2, numVisits=160887, meanQ=4.973928, numObservations: 5
action 3, numVisits=1127, meanQ=4.765729, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.519922 0.613731 0.506604 0.868007 0.55543 0.867203 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 31
Initial state: 0 0.500081 0.891407 0.622438 0.82645 0.802763 0.283488 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162616 episodes
GETTING ACTION FROM:
action 3, numVisits=162546, meanQ=4.941455, numObservations: 5
action -1, numVisits=64, meanQ=4.065596, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.500081 0.891407 0.622438 0.82645 0.802763 0.283488 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 32
Initial state: 0 0.651464 0.834792 0.43654 0.508353 0.549489 0.895874 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162781 episodes
GETTING ACTION FROM:
action 1, numVisits=162746, meanQ=5.016019, numObservations: 3
action 0, numVisits=28, meanQ=3.688423, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.651464 0.834792 0.43654 0.508353 0.549489 0.895874 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 33
Initial state: 0 0.519298 0.80422 0.0793239 0.0284373 0.504671 0.814695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163123 episodes
GETTING ACTION FROM:
action 2, numVisits=163071, meanQ=5.158864, numObservations: 4
action 1, numVisits=39, meanQ=3.231549, numObservations: 4
action 3, numVisits=9, meanQ=1.886667, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.519298 0.80422 0.0793239 0.0284373 0.504671 0.814695 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22614, meanQ=8.426504, numObservations: 3
action 1, numVisits=7, meanQ=5.284300, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10338 episodes
GETTING ACTION FROM:
action 3, numVisits=22614, meanQ=8.426504, numObservations: 3
action 1, numVisits=28, meanQ=5.213932, numObservations: 3
action 2, numVisits=9, meanQ=3.887789, numObservations: 2
action -1, numVisits=10307, meanQ=0.242508, numObservations: 1
action 0, numVisits=4, meanQ=-98.122867, numObservations: 1
action: 3
Next state: 1 0.519298 0.80422 0.0793239 0.0284373 0.504671 0.814695 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 34
Initial state: 0 0.0476413 0.0436337 0.647989 0.863793 0.538376 0.80886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160846 episodes
GETTING ACTION FROM:
action 1, numVisits=160773, meanQ=4.978430, numObservations: 3
action -1, numVisits=66, meanQ=4.139099, numObservations: 1
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.0476413 0.0436337 0.647989 0.863793 0.538376 0.80886 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.567416 0.863366 0.675709 0.896236 0.282795 0.55491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163839 episodes
GETTING ACTION FROM:
action 2, numVisits=161669, meanQ=5.045128, numObservations: 4
action 1, numVisits=2137, meanQ=4.680608, numObservations: 4
action -1, numVisits=29, meanQ=3.733602, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.567416 0.863366 0.675709 0.896236 0.282795 0.55491 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 36
Initial state: 0 0.530021 0.834 0.609935 0.81877 0.283625 0.148147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160840 episodes
GETTING ACTION FROM:
action 3, numVisits=160783, meanQ=4.942552, numObservations: 3
action -1, numVisits=32, meanQ=3.717095, numObservations: 1
action 1, numVisits=21, meanQ=3.047143, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.530021 0.834 0.609935 0.81877 0.283625 0.148147 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26264, meanQ=8.294208, numObservations: 5
action 1, numVisits=299, meanQ=7.907090, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 14723 episodes
GETTING ACTION FROM:
action 2, numVisits=26264, meanQ=8.294208, numObservations: 5
action 1, numVisits=299, meanQ=7.907090, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action 0, numVisits=14720, meanQ=-0.141555, numObservations: 1
action -1, numVisits=4, meanQ=-98.152041, numObservations: 1
action: 2
Next state: 1 0.530021 0.834 0.609935 0.81877 0.283625 0.148147 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 37
Initial state: 0 0.430002 0.93147 0.684634 0.826335 0.562877 0.853375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158456 episodes
GETTING ACTION FROM:
action 2, numVisits=158447, meanQ=4.929052, numObservations: 5
action 3, numVisits=3, meanQ=0.000033, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.430002 0.93147 0.684634 0.826335 0.562877 0.853375 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 38
Initial state: 0 0.575151 0.805951 0.504165 0.808747 0.170707 0.725097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161473 episodes
GETTING ACTION FROM:
action 2, numVisits=161427, meanQ=4.905769, numObservations: 5
action 0, numVisits=29, meanQ=3.602205, numObservations: 1
action 1, numVisits=12, meanQ=2.250025, numObservations: 3
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.575151 0.805951 0.504165 0.808747 0.170707 0.725097 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 39
Initial state: 0 0.590621 0.870897 0.506622 0.116376 0.684928 0.852641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161890 episodes
GETTING ACTION FROM:
action 2, numVisits=161868, meanQ=4.979035, numObservations: 5
action 0, numVisits=15, meanQ=2.947250, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-5.489950, numObservations: 1
action: 2
Next state: 2 0.590621 0.870897 0.506622 0.116376 0.684928 0.852641 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.645382 0.890332 0.930282 0.736514 0.681503 0.863331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162111 episodes
GETTING ACTION FROM:
action 2, numVisits=161533, meanQ=4.956956, numObservations: 4
action 1, numVisits=542, meanQ=4.654407, numObservations: 4
action 0, numVisits=33, meanQ=3.750107, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.645382 0.890332 0.930282 0.736514 0.681503 0.863331 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12062, meanQ=4.891970, numObservations: 4
action 3, numVisits=11, meanQ=2.261827, numObservations: 4
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 32358 episodes
GETTING ACTION FROM:
action 1, numVisits=12062, meanQ=4.891970, numObservations: 4
action 3, numVisits=11, meanQ=2.261827, numObservations: 4
action -1, numVisits=32309, meanQ=-0.124733, numObservations: 1
action 0, numVisits=41, meanQ=-1.130973, numObservations: 1
action 2, numVisits=19, meanQ=-15.609695, numObservations: 3
action: 1
Next state: 1 0.645382 0.890332 0.930282 0.736514 0.681503 0.863331 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 41
Initial state: 0 0.574563 0.811229 0.551755 0.817606 0.248686 0.107232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161054 episodes
GETTING ACTION FROM:
action 3, numVisits=161048, meanQ=4.977856, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.574563 0.811229 0.551755 0.817606 0.248686 0.107232 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7987, meanQ=7.743255, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 16898 episodes
GETTING ACTION FROM:
action 1, numVisits=7987, meanQ=7.743255, numObservations: 4
action 3, numVisits=10, meanQ=0.300010, numObservations: 2
action 0, numVisits=16858, meanQ=0.241565, numObservations: 1
action 2, numVisits=7, meanQ=-0.287143, numObservations: 3
action -1, numVisits=27, meanQ=-0.973333, numObservations: 1
action: 1
Next state: 1 0.574563 0.811229 0.551755 0.817606 0.248686 0.107232 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 42
Initial state: 0 0.570307 0.859902 0.981891 0.0966917 0.623424 0.875685 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162066 episodes
GETTING ACTION FROM:
action 1, numVisits=162060, meanQ=4.991029, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.570307 0.859902 0.981891 0.0966917 0.623424 0.875685 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 43
Initial state: 0 0.639939 0.899226 0.52138 0.882542 0.820474 0.0316607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157428 episodes
GETTING ACTION FROM:
action 2, numVisits=157419, meanQ=5.013438, numObservations: 5
action 3, numVisits=4, meanQ=-0.272500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.639939 0.899226 0.52138 0.882542 0.820474 0.0316607 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 44
Initial state: 0 0.354669 0.215623 0.559847 0.878502 0.640337 0.870414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162276 episodes
GETTING ACTION FROM:
action 3, numVisits=162237, meanQ=4.979319, numObservations: 4
action 1, numVisits=34, meanQ=3.162941, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.354669 0.215623 0.559847 0.878502 0.640337 0.870414 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 45
Initial state: 0 0.600737 0.845137 0.606286 0.898118 0.104587 0.592358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161964 episodes
GETTING ACTION FROM:
action 2, numVisits=161854, meanQ=4.931724, numObservations: 5
action -1, numVisits=92, meanQ=4.206442, numObservations: 1
action 1, numVisits=15, meanQ=2.800667, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.600737 0.845137 0.606286 0.898118 0.104587 0.592358 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 46
Initial state: 0 0.584898 0.890354 0.0859386 0.739097 0.681874 0.845039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161941 episodes
GETTING ACTION FROM:
action 1, numVisits=161885, meanQ=4.933779, numObservations: 4
action 0, numVisits=48, meanQ=3.932469, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.584898 0.890354 0.0859386 0.739097 0.681874 0.845039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 47
Initial state: 0 0.807606 0.706885 0.637195 0.860137 0.634889 0.883572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162890 episodes
GETTING ACTION FROM:
action 2, numVisits=162878, meanQ=5.004065, numObservations: 4
action 1, numVisits=7, meanQ=1.428571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.807606 0.706885 0.637195 0.860137 0.634889 0.883572 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 48
Initial state: 0 0.51882 0.800641 0.67636 0.806676 0.857534 0.298278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161468 episodes
GETTING ACTION FROM:
action 2, numVisits=161454, meanQ=4.953860, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 3, numVisits=6, meanQ=0.651667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.51882 0.800641 0.67636 0.806676 0.857534 0.298278 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 49
Initial state: 0 0.111958 0.249193 0.576261 0.830342 0.66647 0.846305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162469 episodes
GETTING ACTION FROM:
action 3, numVisits=162017, meanQ=5.021485, numObservations: 4
action -1, numVisits=277, meanQ=3.248199, numObservations: 1
action 0, numVisits=149, meanQ=3.141016, numObservations: 1
action 2, numVisits=18, meanQ=1.943906, numObservations: 3
action 1, numVisits=8, meanQ=0.873750, numObservations: 4
action: 3
Next state: 1 0.111958 0.249193 0.576261 0.830342 0.66647 0.846305 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 50
Initial state: 0 0.674489 0.855765 0.940658 0.300982 0.550539 0.805177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155166 episodes
GETTING ACTION FROM:
action 1, numVisits=155160, meanQ=4.865063, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.674489 0.855765 0.940658 0.300982 0.550539 0.805177 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 51
Initial state: 0 0.563552 0.895809 0.601952 0.864053 0.0110495 0.235766 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163049 episodes
GETTING ACTION FROM:
action 2, numVisits=154092, meanQ=5.004315, numObservations: 4
action 1, numVisits=8952, meanQ=4.914756, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.563552 0.895809 0.601952 0.864053 0.0110495 0.235766 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 52
Initial state: 0 0.503538 0.854028 0.517174 0.889759 0.132123 0.139179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163264 episodes
GETTING ACTION FROM:
action 1, numVisits=163169, meanQ=5.040189, numObservations: 4
action -1, numVisits=84, meanQ=4.294135, numObservations: 1
action 2, numVisits=7, meanQ=1.428571, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-4.499950, numObservations: 1
action: 1
Next state: 1 0.503538 0.854028 0.517174 0.889759 0.132123 0.139179 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 53
Initial state: 0 0.660272 0.82011 0.626778 0.867102 0.820753 0.386562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162385 episodes
GETTING ACTION FROM:
action 3, numVisits=162313, meanQ=4.964805, numObservations: 3
action -1, numVisits=58, meanQ=4.061938, numObservations: 1
action 1, numVisits=9, meanQ=2.664444, numObservations: 4
action 2, numVisits=3, meanQ=0.000033, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.660272 0.82011 0.626778 0.867102 0.820753 0.386562 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 54
Initial state: 0 0.647943 0.853303 0.293721 0.156169 0.652319 0.828759 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95794 episodes
GETTING ACTION FROM:
action -1, numVisits=95771, meanQ=2.892715, numObservations: 1
action 1, numVisits=14, meanQ=0.278571, numObservations: 4
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 2, numVisits=4, meanQ=-2.500000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: -1
Next state: 0 0.647943 0.853303 0.293721 0.156169 0.652319 0.828759 w: 1
Observation: 0 0.68033 0 0.23415 0 0.602905 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=95758, meanQ=4.944843, numObservations: 5
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 164005 episodes
GETTING ACTION FROM:
action 1, numVisits=259757, meanQ=4.770802, numObservations: 5
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action 2, numVisits=7, meanQ=1.144314, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.647943 0.853303 0.293721 0.156169 0.652319 0.828759 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 55
Initial state: 0 0.588788 0.880862 0.21374 0.910979 0.627814 0.824441 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162011 episodes
GETTING ACTION FROM:
action 1, numVisits=161955, meanQ=5.007426, numObservations: 5
action 0, numVisits=22, meanQ=3.446058, numObservations: 1
action -1, numVisits=22, meanQ=3.431680, numObservations: 1
action 3, numVisits=11, meanQ=2.909109, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.588788 0.880862 0.21374 0.910979 0.627814 0.824441 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 56
Initial state: 0 0.985044 0.864079 0.622142 0.886156 0.662368 0.858028 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162258 episodes
GETTING ACTION FROM:
action 2, numVisits=162177, meanQ=4.971102, numObservations: 4
action -1, numVisits=42, meanQ=3.906551, numObservations: 1
action 3, numVisits=36, meanQ=3.665844, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.985044 0.864079 0.622142 0.886156 0.662368 0.858028 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 57
Initial state: 0 0.586917 0.850756 0.715057 0.919135 0.6974 0.80259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162059 episodes
GETTING ACTION FROM:
action 1, numVisits=162027, meanQ=5.001243, numObservations: 4
action 0, numVisits=19, meanQ=3.417432, numObservations: 1
action 2, numVisits=9, meanQ=1.886667, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.586917 0.850756 0.715057 0.919135 0.6974 0.80259 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 58
Initial state: 0 0.630197 0.889046 0.535088 0.888727 0.207021 0.019848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162312 episodes
GETTING ACTION FROM:
action 2, numVisits=162277, meanQ=4.939133, numObservations: 4
action -1, numVisits=26, meanQ=3.337702, numObservations: 1
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.630197 0.889046 0.535088 0.888727 0.207021 0.019848 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 59
Initial state: 0 0.659419 0.877536 0.620955 0.914699 0.675422 0.891963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162203 episodes
GETTING ACTION FROM:
action 3, numVisits=161718, meanQ=5.005217, numObservations: 5
action 0, numVisits=476, meanQ=2.977088, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.659419 0.877536 0.620955 0.914699 0.675422 0.891963 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 60
Initial state: 0 0.0869617 0.0544296 0.536533 0.877786 0.621643 0.890492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161116 episodes
GETTING ACTION FROM:
action 1, numVisits=161043, meanQ=4.961620, numObservations: 4
action -1, numVisits=67, meanQ=4.055125, numObservations: 1
action 2, numVisits=3, meanQ=-0.659967, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0869617 0.0544296 0.536533 0.877786 0.621643 0.890492 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=26304, meanQ=8.290523, numObservations: 4
action 2, numVisits=22, meanQ=6.900005, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12632 episodes
GETTING ACTION FROM:
action 3, numVisits=26304, meanQ=8.290523, numObservations: 4
action 2, numVisits=58, meanQ=6.753622, numObservations: 4
action 1, numVisits=4, meanQ=2.497525, numObservations: 2
action 0, numVisits=12584, meanQ=0.193593, numObservations: 1
action -1, numVisits=11, meanQ=-2.000900, numObservations: 1
action: 3
Next state: 0 0.0869617 0.0544296 0.536533 0.877786 0.621643 0.890492 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=2119, meanQ=8.274817, numObservations: 5
action 3, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 23475 episodes
GETTING ACTION FROM:
action 2, numVisits=2119, meanQ=8.274817, numObservations: 5
action 1, numVisits=35, meanQ=5.971146, numObservations: 3
action 3, numVisits=38, meanQ=5.526053, numObservations: 4
action -1, numVisits=23210, meanQ=-1.692167, numObservations: 1
action 0, numVisits=198, meanQ=-2.110828, numObservations: 1
action: 2
Next state: 1 0.0869617 0.0544296 0.536533 0.877786 0.621643 0.890492 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 61
Initial state: 0 0.653063 0.862977 0.138642 0.628901 0.54914 0.859723 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95889 episodes
GETTING ACTION FROM:
action -1, numVisits=95881, meanQ=2.909589, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=4, meanQ=-2.749975, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.653063 0.862977 0.138642 0.628901 0.54914 0.859723 w: 1
Observation: 0 0.575223 0 0.175411 0 0.484324 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=95829, meanQ=4.952794, numObservations: 4
action 0, numVisits=40, meanQ=3.863233, numObservations: 1
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 162360 episodes
GETTING ACTION FROM:
action 3, numVisits=258185, meanQ=4.843143, numObservations: 4
action 0, numVisits=44, meanQ=3.773177, numObservations: 1
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.653063 0.862977 0.138642 0.628901 0.54914 0.859723 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 62
Initial state: 0 0.675293 0.815967 0.429446 0.741288 0.511176 0.821263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162450 episodes
GETTING ACTION FROM:
action 2, numVisits=162136, meanQ=5.001072, numObservations: 4
action 3, numVisits=168, meanQ=4.478800, numObservations: 3
action 0, numVisits=118, meanQ=4.370818, numObservations: 1
action 1, numVisits=26, meanQ=3.650777, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.675293 0.815967 0.429446 0.741288 0.511176 0.821263 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=26525, meanQ=8.325908, numObservations: 4
action 1, numVisits=97, meanQ=7.700727, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8155 episodes
GETTING ACTION FROM:
action 3, numVisits=26525, meanQ=8.325908, numObservations: 4
action 1, numVisits=205, meanQ=6.921807, numObservations: 4
action -1, numVisits=8042, meanQ=0.290097, numObservations: 1
action 0, numVisits=7, meanQ=-2.144257, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.675293 0.815967 0.429446 0.741288 0.511176 0.821263 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 63
Initial state: 0 0.111114 0.89657 0.660609 0.805327 0.699705 0.88842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154960 episodes
GETTING ACTION FROM:
action 2, numVisits=154928, meanQ=4.841561, numObservations: 5
action 0, numVisits=28, meanQ=3.412128, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.111114 0.89657 0.660609 0.805327 0.699705 0.88842 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 64
Initial state: 0 0.457189 0.235778 0.549912 0.844546 0.664502 0.889392 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95762 episodes
GETTING ACTION FROM:
action -1, numVisits=95754, meanQ=2.890741, numObservations: 1
action 2, numVisits=4, meanQ=-1.249950, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.457189 0.235778 0.549912 0.844546 0.664502 0.889392 w: 1
Observation: 0 0.41039 0 0.611935 0 0.661595 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=95604, meanQ=4.926335, numObservations: 3
action -1, numVisits=95, meanQ=4.240930, numObservations: 1
action 0, numVisits=39, meanQ=3.853719, numObservations: 1
action 3, numVisits=8, meanQ=2.498750, numObservations: 3
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
Sampled 162146 episodes
GETTING ACTION FROM:
action 2, numVisits=257730, meanQ=4.826068, numObservations: 3
action -1, numVisits=110, meanQ=4.162091, numObservations: 1
action 0, numVisits=41, meanQ=3.730867, numObservations: 1
action 3, numVisits=11, meanQ=2.453636, numObservations: 3
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action: 2
Next state: 1 0.457189 0.235778 0.549912 0.844546 0.664502 0.889392 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 65
Initial state: 0 0.0491546 0.0495818 0.615233 0.811626 0.656417 0.807709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161274 episodes
GETTING ACTION FROM:
action 3, numVisits=161093, meanQ=4.990041, numObservations: 5
action 2, numVisits=143, meanQ=4.285717, numObservations: 4
action 0, numVisits=17, meanQ=3.240497, numObservations: 1
action 1, numVisits=19, meanQ=3.205274, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.0491546 0.0495818 0.615233 0.811626 0.656417 0.807709 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 66
Initial state: 0 0.68026 0.811274 0.631046 0.800884 0.797465 0.712723 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162300 episodes
GETTING ACTION FROM:
action 2, numVisits=162263, meanQ=4.911746, numObservations: 4
action 3, numVisits=24, meanQ=1.863342, numObservations: 4
action 1, numVisits=9, meanQ=0.998889, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.68026 0.811274 0.631046 0.800884 0.797465 0.712723 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=13884, meanQ=5.054332, numObservations: 3
action -1, numVisits=47, meanQ=4.139755, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 202233 episodes
GETTING ACTION FROM:
action 1, numVisits=216114, meanQ=5.967982, numObservations: 3
action -1, numVisits=48, meanQ=4.112163, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.68026 0.811274 0.631046 0.800884 0.797465 0.712723 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=4788, meanQ=6.816946, numObservations: 4
action 2, numVisits=8, meanQ=1.251275, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 207899 episodes
GETTING ACTION FROM:
action 1, numVisits=212684, meanQ=5.433874, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action 2, numVisits=8, meanQ=1.251275, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.68026 0.811274 0.631046 0.800884 0.797465 0.712723 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 67
Initial state: 0 0.630401 0.815193 0.617627 0.545722 0.667157 0.899792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162195 episodes
GETTING ACTION FROM:
action 2, numVisits=162115, meanQ=4.940933, numObservations: 4
action -1, numVisits=23, meanQ=3.494537, numObservations: 1
action 1, numVisits=25, meanQ=3.432004, numObservations: 4
action 0, numVisits=21, meanQ=3.424649, numObservations: 1
action 3, numVisits=11, meanQ=2.537282, numObservations: 2
action: 2
Next state: 2 0.630401 0.815193 0.617627 0.545722 0.667157 0.899792 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 68
Initial state: 0 0.694735 0.843158 0.584436 0.81362 0.383386 0.281287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162892 episodes
GETTING ACTION FROM:
action 2, numVisits=162885, meanQ=4.975443, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.694735 0.843158 0.584436 0.81362 0.383386 0.281287 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9998, meanQ=4.086901, numObservations: 5
action 0, numVisits=110, meanQ=3.513730, numObservations: 1
action 3, numVisits=19, meanQ=2.472632, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 201146 episodes
GETTING ACTION FROM:
action 1, numVisits=211133, meanQ=5.982007, numObservations: 5
action 0, numVisits=121, meanQ=3.052090, numObservations: 1
action 3, numVisits=19, meanQ=2.472632, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.694735 0.843158 0.584436 0.81362 0.383386 0.281287 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 69
Initial state: 0 0.694798 0.87442 0.0587314 0.874502 0.608647 0.864613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162141 episodes
GETTING ACTION FROM:
action 1, numVisits=162106, meanQ=5.048639, numObservations: 4
action 0, numVisits=31, meanQ=3.788395, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.694798 0.87442 0.0587314 0.874502 0.608647 0.864613 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 70
Initial state: 0 0.256469 0.689536 0.529602 0.851545 0.515981 0.834545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162279 episodes
GETTING ACTION FROM:
action 3, numVisits=162269, meanQ=5.018596, numObservations: 4
action 1, numVisits=5, meanQ=1.000020, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.256469 0.689536 0.529602 0.851545 0.515981 0.834545 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 71
Initial state: 0 0.612419 0.872865 0.517498 0.818698 0.796976 0.843673 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162614 episodes
GETTING ACTION FROM:
action 1, numVisits=162602, meanQ=4.995208, numObservations: 4
action 2, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 1
Next state: 1 0.612419 0.872865 0.517498 0.818698 0.796976 0.843673 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 72
Initial state: 0 0.522349 0.505001 0.561962 0.860675 0.521889 0.899578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163170 episodes
GETTING ACTION FROM:
action 1, numVisits=163083, meanQ=5.048504, numObservations: 4
action 0, numVisits=39, meanQ=3.925902, numObservations: 1
action 2, numVisits=26, meanQ=3.615012, numObservations: 5
action -1, numVisits=19, meanQ=3.400256, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action: 1
Next state: 0 0.522349 0.505001 0.561962 0.860675 0.521889 0.899578 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=22143, meanQ=8.413710, numObservations: 3
action 3, numVisits=875, meanQ=8.239055, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 16267 episodes
GETTING ACTION FROM:
action 2, numVisits=31953, meanQ=7.586350, numObservations: 3
action 3, numVisits=1480, meanQ=7.146451, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=5851, meanQ=-0.014591, numObservations: 1
action 0, numVisits=2, meanQ=-195.573586, numObservations: 1
action: 2
Next state: 1 0.522349 0.505001 0.561962 0.860675 0.521889 0.899578 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 73
Initial state: 0 0.684609 0.868523 0.191417 0.453094 0.693929 0.878536 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92597 episodes
GETTING ACTION FROM:
action -1, numVisits=92588, meanQ=2.726102, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 1
action: -1
Next state: 0 0.684609 0.868523 0.191417 0.453094 0.693929 0.878536 w: 1
Observation: 0 0.596248 0 0.290002 0 0.638526 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=92551, meanQ=4.767676, numObservations: 4
action -1, numVisits=32, meanQ=3.591326, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 155428 episodes
GETTING ACTION FROM:
action 2, numVisits=247977, meanQ=4.835647, numObservations: 4
action -1, numVisits=33, meanQ=3.558000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action: 2
Next state: 0 0.684609 0.868523 0.191417 0.453094 0.693929 0.878536 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=33861, meanQ=8.411492, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8196 episodes
GETTING ACTION FROM:
action 1, numVisits=33861, meanQ=8.411492, numObservations: 3
action 3, numVisits=53, meanQ=6.187400, numObservations: 3
action -1, numVisits=8141, meanQ=-0.006140, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 0, numVisits=3, meanQ=-4.653139, numObservations: 1
action: 1
Next state: 0 0.684609 0.868523 0.191417 0.453094 0.693929 0.878536 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=2721, meanQ=8.375103, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 18224 episodes
GETTING ACTION FROM:
action 1, numVisits=2721, meanQ=8.375103, numObservations: 3
action 3, numVisits=1382, meanQ=6.438227, numObservations: 3
action 2, numVisits=40, meanQ=5.602500, numObservations: 4
action -1, numVisits=16666, meanQ=-1.653073, numObservations: 1
action 0, numVisits=141, meanQ=-2.266552, numObservations: 1
action: 1
Next state: 1 0.684609 0.868523 0.191417 0.453094 0.693929 0.878536 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -1.14771
Run # 74
Initial state: 0 0.677273 0.885397 0.0144925 0.725854 0.617657 0.881586 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162334 episodes
GETTING ACTION FROM:
action 3, numVisits=162327, meanQ=5.017130, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.677273 0.885397 0.0144925 0.725854 0.617657 0.881586 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 75
Initial state: 0 0.516311 0.801332 0.53463 0.83091 0.483992 0.0827681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162973 episodes
GETTING ACTION FROM:
action 1, numVisits=162918, meanQ=5.052007, numObservations: 3
action 0, numVisits=33, meanQ=3.814762, numObservations: 1
action -1, numVisits=17, meanQ=3.117698, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.516311 0.801332 0.53463 0.83091 0.483992 0.0827681 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 76
Initial state: 0 0.750004 0.838527 0.653877 0.803265 0.682492 0.876283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162634 episodes
GETTING ACTION FROM:
action 1, numVisits=162625, meanQ=5.015943, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.750004 0.838527 0.653877 0.803265 0.682492 0.876283 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 77
Initial state: 0 0.899902 0.979602 0.668874 0.80662 0.647454 0.842474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159218 episodes
GETTING ACTION FROM:
action 3, numVisits=159135, meanQ=4.914191, numObservations: 4
action 0, numVisits=70, meanQ=3.998084, numObservations: 1
action 1, numVisits=9, meanQ=1.555567, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.899902 0.979602 0.668874 0.80662 0.647454 0.842474 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 78
Initial state: 0 0.990894 0.397501 0.590614 0.803727 0.569521 0.814976 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161997 episodes
GETTING ACTION FROM:
action 3, numVisits=161917, meanQ=5.035074, numObservations: 5
action 2, numVisits=51, meanQ=3.982161, numObservations: 5
action 0, numVisits=25, meanQ=3.578835, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 3
Next state: 1 0.990894 0.397501 0.590614 0.803727 0.569521 0.814976 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 79
Initial state: 0 0.521997 0.858516 0.637217 0.127807 0.569358 0.850621 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163438 episodes
GETTING ACTION FROM:
action 1, numVisits=163368, meanQ=5.047496, numObservations: 3
action -1, numVisits=45, meanQ=3.998959, numObservations: 1
action 0, numVisits=22, meanQ=3.532349, numObservations: 1
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.521997 0.858516 0.637217 0.127807 0.569358 0.850621 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 80
Initial state: 0 0.621176 0.834743 0.891824 0.106975 0.691762 0.822607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162601 episodes
GETTING ACTION FROM:
action 3, numVisits=162556, meanQ=5.008648, numObservations: 4
action 1, numVisits=37, meanQ=2.434873, numObservations: 4
action 2, numVisits=4, meanQ=-0.272500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.621176 0.834743 0.891824 0.106975 0.691762 0.822607 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 81
Initial state: 0 0.515324 0.855266 0.653032 0.823619 0.175425 0.573004 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162663 episodes
GETTING ACTION FROM:
action 1, numVisits=162392, meanQ=4.954725, numObservations: 4
action 0, numVisits=85, meanQ=4.209259, numObservations: 1
action -1, numVisits=180, meanQ=3.560717, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.515324 0.855266 0.653032 0.823619 0.175425 0.573004 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 82
Initial state: 0 0.039293 0.33939 0.537855 0.895441 0.627057 0.871037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162782 episodes
GETTING ACTION FROM:
action 1, numVisits=162763, meanQ=4.916549, numObservations: 4
action 3, numVisits=13, meanQ=1.922308, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 1
Next state: 0 0.039293 0.33939 0.537855 0.895441 0.627057 0.871037 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11687, meanQ=8.548257, numObservations: 3
action 3, numVisits=6944, meanQ=8.527949, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 4252 episodes
GETTING ACTION FROM:
action 2, numVisits=11687, meanQ=8.548257, numObservations: 3
action 3, numVisits=6944, meanQ=8.527949, numObservations: 3
action 1, numVisits=13, meanQ=3.922315, numObservations: 2
action -1, numVisits=4224, meanQ=0.138667, numObservations: 1
action 0, numVisits=18, meanQ=-2.056100, numObservations: 1
action: 2
Next state: 1 0.039293 0.33939 0.537855 0.895441 0.627057 0.871037 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 83
Initial state: 0 0.600681 0.846067 0.531581 0.829593 0.238381 0.814399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161702 episodes
GETTING ACTION FROM:
action 1, numVisits=161694, meanQ=5.116586, numObservations: 4
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.600681 0.846067 0.531581 0.829593 0.238381 0.814399 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 84
Initial state: 0 0.486335 0.782357 0.504695 0.810428 0.653317 0.836103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161867 episodes
GETTING ACTION FROM:
action 3, numVisits=161779, meanQ=5.022081, numObservations: 4
action 0, numVisits=84, meanQ=4.267320, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.486335 0.782357 0.504695 0.810428 0.653317 0.836103 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 85
Initial state: 0 0.574916 0.888484 0.514249 0.822642 0.438622 0.206936 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162600 episodes
GETTING ACTION FROM:
action 1, numVisits=162572, meanQ=4.938453, numObservations: 3
action -1, numVisits=22, meanQ=3.405374, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.574916 0.888484 0.514249 0.822642 0.438622 0.206936 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12004, meanQ=4.664042, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 183492 episodes
GETTING ACTION FROM:
action 1, numVisits=183484, meanQ=5.104159, numObservations: 4
action 2, numVisits=12004, meanQ=4.664042, numObservations: 4
action 3, numVisits=11, meanQ=2.363636, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.574916 0.888484 0.514249 0.822642 0.438622 0.206936 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2784, meanQ=7.116868, numObservations: 5
action 2, numVisits=49, meanQ=4.993682, numObservations: 4
action 1, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 207075 episodes
GETTING ACTION FROM:
action 2, numVisits=150701, meanQ=6.391103, numObservations: 4
action 3, numVisits=59203, meanQ=5.913465, numObservations: 5
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.574916 0.888484 0.514249 0.822642 0.438622 0.206936 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 86
Initial state: 0 0.751245 0.465504 0.579872 0.807048 0.509234 0.841774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161267 episodes
GETTING ACTION FROM:
action 2, numVisits=161228, meanQ=5.022072, numObservations: 5
action 0, numVisits=22, meanQ=3.386824, numObservations: 1
action 1, numVisits=11, meanQ=2.543645, numObservations: 3
action 3, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.751245 0.465504 0.579872 0.807048 0.509234 0.841774 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 87
Initial state: 0 0.519368 0.875481 0.966512 0.602626 0.667411 0.816356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162871 episodes
GETTING ACTION FROM:
action 1, numVisits=162842, meanQ=4.971878, numObservations: 4
action -1, numVisits=13, meanQ=2.816388, numObservations: 1
action 3, numVisits=13, meanQ=2.536923, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.519368 0.875481 0.966512 0.602626 0.667411 0.816356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 88
Initial state: 0 0.65115 0.847782 0.698166 0.874209 0.283822 0.138248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161007 episodes
GETTING ACTION FROM:
action 3, numVisits=159722, meanQ=4.949354, numObservations: 5
action 0, numVisits=1278, meanQ=2.634094, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 3
Next state: 0 0.65115 0.847782 0.698166 0.874209 0.283822 0.138248 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=18403, meanQ=8.515491, numObservations: 3
action 2, numVisits=27, meanQ=7.225556, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11384 episodes
GETTING ACTION FROM:
action 1, numVisits=18403, meanQ=8.515491, numObservations: 3
action 2, numVisits=58, meanQ=6.553278, numObservations: 4
action 3, numVisits=22, meanQ=4.545000, numObservations: 4
action -1, numVisits=11296, meanQ=0.203136, numObservations: 1
action 0, numVisits=38, meanQ=-0.801579, numObservations: 1
action: 1
Next state: 1 0.65115 0.847782 0.698166 0.874209 0.283822 0.138248 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 89
Initial state: 0 0.463491 0.762504 0.513237 0.860844 0.604801 0.897323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162937 episodes
GETTING ACTION FROM:
action 2, numVisits=162831, meanQ=4.983226, numObservations: 3
action 0, numVisits=58, meanQ=4.082252, numObservations: 1
action -1, numVisits=27, meanQ=2.928316, numObservations: 1
action 3, numVisits=15, meanQ=2.601347, numObservations: 3
action 1, numVisits=6, meanQ=1.333333, numObservations: 3
action: 2
Next state: 1 0.463491 0.762504 0.513237 0.860844 0.604801 0.897323 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 90
Initial state: 0 0.574996 0.88407 0.621861 0.850295 0.209887 0.634596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162638 episodes
GETTING ACTION FROM:
action 2, numVisits=162601, meanQ=5.161591, numObservations: 4
action 3, numVisits=23, meanQ=3.560887, numObservations: 3
action 1, numVisits=10, meanQ=2.598000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.574996 0.88407 0.621861 0.850295 0.209887 0.634596 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 91
Initial state: 0 0.590567 0.801307 0.520276 0.882399 0.501464 0.220815 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162327 episodes
GETTING ACTION FROM:
action 2, numVisits=162285, meanQ=4.954734, numObservations: 4
action 1, numVisits=36, meanQ=3.666119, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 2
Next state: 1 0.590567 0.801307 0.520276 0.882399 0.501464 0.220815 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 92
Initial state: 0 0.528292 0.817543 0.13572 0.0314044 0.599766 0.859975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159935 episodes
GETTING ACTION FROM:
action 3, numVisits=159726, meanQ=4.939828, numObservations: 5
action 2, numVisits=152, meanQ=4.268686, numObservations: 5
action 0, numVisits=52, meanQ=3.956041, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.528292 0.817543 0.13572 0.0314044 0.599766 0.859975 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 93
Initial state: 0 0.745066 0.628362 0.530645 0.877394 0.648742 0.884151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160970 episodes
GETTING ACTION FROM:
action 2, numVisits=160961, meanQ=4.936434, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=3, meanQ=-3.296667, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.745066 0.628362 0.530645 0.877394 0.648742 0.884151 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 94
Initial state: 0 0.500571 0.784765 0.688511 0.845153 0.616667 0.841546 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162945 episodes
GETTING ACTION FROM:
action 3, numVisits=162922, meanQ=5.013555, numObservations: 4
action 1, numVisits=17, meanQ=2.235894, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.500571 0.784765 0.688511 0.845153 0.616667 0.841546 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 95
Initial state: 0 0.681885 0.942987 0.5492 0.850065 0.637215 0.826127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163142 episodes
GETTING ACTION FROM:
action 1, numVisits=162935, meanQ=5.031605, numObservations: 4
action 0, numVisits=47, meanQ=4.035076, numObservations: 1
action -1, numVisits=129, meanQ=3.482393, numObservations: 1
action 2, numVisits=26, meanQ=2.919246, numObservations: 4
action 3, numVisits=5, meanQ=1.000000, numObservations: 3
action: 1
Next state: 1 0.681885 0.942987 0.5492 0.850065 0.637215 0.826127 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 96
Initial state: 0 0.433414 0.88196 0.673626 0.846261 0.507536 0.870637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161568 episodes
GETTING ACTION FROM:
action 3, numVisits=161513, meanQ=4.963270, numObservations: 4
action 1, numVisits=50, meanQ=3.630614, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.433414 0.88196 0.673626 0.846261 0.507536 0.870637 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 97
Initial state: 0 0.286925 0.850417 0.639484 0.880318 0.648824 0.825649 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161959 episodes
GETTING ACTION FROM:
action 1, numVisits=161891, meanQ=5.039467, numObservations: 5
action 2, numVisits=58, meanQ=2.887593, numObservations: 4
action 3, numVisits=6, meanQ=1.333333, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.286925 0.850417 0.639484 0.880318 0.648824 0.825649 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4003, meanQ=7.723396, numObservations: 3
action 3, numVisits=3, meanQ=2.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 17973 episodes
GETTING ACTION FROM:
action 2, numVisits=4003, meanQ=7.723396, numObservations: 3
action 3, numVisits=17, meanQ=5.882353, numObservations: 3
action 1, numVisits=6, meanQ=1.331683, numObservations: 2
action 0, numVisits=17948, meanQ=0.123304, numObservations: 1
action -1, numVisits=8, meanQ=-2.126225, numObservations: 1
action: 2
Next state: 1 0.286925 0.850417 0.639484 0.880318 0.648824 0.825649 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 98
Initial state: 0 0.65933 0.838629 0.609642 0.800612 0.267744 0.195931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159214 episodes
GETTING ACTION FROM:
action 3, numVisits=157008, meanQ=4.950637, numObservations: 5
action 0, numVisits=2201, meanQ=1.161724, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.65933 0.838629 0.609642 0.800612 0.267744 0.195931 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 99
Initial state: 0 0.0713081 0.0814739 0.575821 0.817139 0.542101 0.815477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93945 episodes
GETTING ACTION FROM:
action 0, numVisits=89301, meanQ=2.901768, numObservations: 1
action -1, numVisits=4638, meanQ=1.029074, numObservations: 1
action 1, numVisits=4, meanQ=-2.500000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0713081 0.0814739 0.575821 0.817139 0.542101 0.815477 w: 1
Observation: 0 0 0.0874372 0 0.815906 0 0.891917 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=89269, meanQ=4.931142, numObservations: 5
action -1, numVisits=21, meanQ=3.412363, numObservations: 1
action 3, numVisits=7, meanQ=2.127143, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 163574 episodes
GETTING ACTION FROM:
action 1, numVisits=252842, meanQ=5.075563, numObservations: 5
action -1, numVisits=21, meanQ=3.412363, numObservations: 1
action 3, numVisits=7, meanQ=2.127143, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.994950, numObservations: 1
action: 1
Next state: 0 0.0713081 0.0814739 0.575821 0.817139 0.542101 0.815477 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=35288, meanQ=8.406933, numObservations: 3
action 2, numVisits=19, meanQ=6.683158, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6024 episodes
GETTING ACTION FROM:
action 3, numVisits=35288, meanQ=8.406933, numObservations: 3
action 2, numVisits=19, meanQ=6.683158, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=6017, meanQ=0.301335, numObservations: 1
action 0, numVisits=8, meanQ=-2.001238, numObservations: 1
action: 3
Next state: 1 0.0713081 0.0814739 0.575821 0.817139 0.542101 0.815477 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 100
Initial state: 0 0.638856 0.858528 0.688908 0.845439 0.57413 0.565881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161818 episodes
GETTING ACTION FROM:
action 3, numVisits=161809, meanQ=5.032134, numObservations: 4
action 1, numVisits=3, meanQ=-0.659967, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.638856 0.858528 0.688908 0.845439 0.57413 0.565881 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 101
Initial state: 0 0.623944 0.836566 0.554739 0.2189 0.668706 0.864688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162454 episodes
GETTING ACTION FROM:
action 1, numVisits=162384, meanQ=4.999381, numObservations: 4
action 0, numVisits=65, meanQ=4.133677, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.623944 0.836566 0.554739 0.2189 0.668706 0.864688 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 102
Initial state: 0 0.51146 0.896897 0.0803875 0.888999 0.689376 0.895152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96080 episodes
GETTING ACTION FROM:
action -1, numVisits=95839, meanQ=2.968468, numObservations: 1
action 0, numVisits=202, meanQ=2.495149, numObservations: 1
action 2, numVisits=31, meanQ=1.733548, numObservations: 4
action 1, numVisits=5, meanQ=-1.402000, numObservations: 2
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action: -1
Next state: 0 0.51146 0.896897 0.0803875 0.888999 0.689376 0.895152 w: 1
Observation: 0 0.547463 0 0.137084 0 0.597019 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=95801, meanQ=5.034339, numObservations: 3
action 0, numVisits=20, meanQ=3.526554, numObservations: 1
action 2, numVisits=12, meanQ=2.833350, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 162662 episodes
GETTING ACTION FROM:
action 1, numVisits=258462, meanQ=5.010927, numObservations: 3
action 0, numVisits=21, meanQ=3.379608, numObservations: 1
action 2, numVisits=12, meanQ=2.833350, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.51146 0.896897 0.0803875 0.888999 0.689376 0.895152 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 103
Initial state: 0 0.620461 0.856208 0.397826 0.455541 0.564033 0.884932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162820 episodes
GETTING ACTION FROM:
action 1, numVisits=162748, meanQ=5.020019, numObservations: 4
action -1, numVisits=67, meanQ=4.177242, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=2, meanQ=-5.489950, numObservations: 1
action: 1
Next state: 1 0.620461 0.856208 0.397826 0.455541 0.564033 0.884932 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 104
Initial state: 0 0.749643 0.218962 0.692271 0.88913 0.688722 0.813905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157496 episodes
GETTING ACTION FROM:
action 2, numVisits=150220, meanQ=4.946228, numObservations: 4
action 0, numVisits=6297, meanQ=3.142001, numObservations: 2
action -1, numVisits=971, meanQ=2.805372, numObservations: 1
action 3, numVisits=5, meanQ=-0.978000, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action: 2
Next state: 1 0.749643 0.218962 0.692271 0.88913 0.688722 0.813905 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 105
Initial state: 0 0.50409 0.878713 0.632192 0.884574 0.338657 0.81706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163621 episodes
GETTING ACTION FROM:
action 1, numVisits=163609, meanQ=5.014230, numObservations: 3
action 3, numVisits=7, meanQ=2.002871, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.50409 0.878713 0.632192 0.884574 0.338657 0.81706 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 106
Initial state: 0 0.634721 0.85523 0.140125 0.292958 0.532335 0.853699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162471 episodes
GETTING ACTION FROM:
action 1, numVisits=162365, meanQ=5.003080, numObservations: 4
action 0, numVisits=61, meanQ=4.117415, numObservations: 1
action -1, numVisits=41, meanQ=3.918404, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.634721 0.85523 0.140125 0.292958 0.532335 0.853699 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 107
Initial state: 0 0.607123 0.886704 0.651575 0.858358 0.278592 0.00835281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163374 episodes
GETTING ACTION FROM:
action 1, numVisits=163367, meanQ=5.163641, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.607123 0.886704 0.651575 0.858358 0.278592 0.00835281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10805, meanQ=7.712621, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 178980 episodes
GETTING ACTION FROM:
action 1, numVisits=189782, meanQ=5.188800, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 1
Next state: 1 0.607123 0.886704 0.651575 0.858358 0.278592 0.00835281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 108
Initial state: 0 0.578685 0.862595 0.543733 0.821987 0.725087 0.680306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162412 episodes
GETTING ACTION FROM:
action 3, numVisits=162373, meanQ=4.996845, numObservations: 3
action -1, numVisits=34, meanQ=1.832263, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.578685 0.862595 0.543733 0.821987 0.725087 0.680306 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 109
Initial state: 0 0.51339 0.805119 0.605723 0.800352 0.22123 0.511877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 130520 episodes
GETTING ACTION FROM:
action 2, numVisits=84544, meanQ=4.959855, numObservations: 3
action 0, numVisits=45971, meanQ=2.885896, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.51339 0.805119 0.605723 0.800352 0.22123 0.511877 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 110
Initial state: 0 0.61804 0.855847 0.620174 0.837273 0.290871 0.443521 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162590 episodes
GETTING ACTION FROM:
action 3, numVisits=162570, meanQ=4.947494, numObservations: 3
action 0, numVisits=12, meanQ=2.877812, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.61804 0.855847 0.620174 0.837273 0.290871 0.443521 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25249, meanQ=8.310066, numObservations: 3
action 1, numVisits=1467, meanQ=8.183140, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7166 episodes
GETTING ACTION FROM:
action 2, numVisits=25249, meanQ=8.310066, numObservations: 3
action 1, numVisits=1467, meanQ=8.183140, numObservations: 4
action 0, numVisits=6722, meanQ=0.064096, numObservations: 2
action -1, numVisits=441, meanQ=-0.170211, numObservations: 1
action 3, numVisits=6, meanQ=-63.738163, numObservations: 2
action: 2
Next state: 1 0.61804 0.855847 0.620174 0.837273 0.290871 0.443521 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 111
Initial state: 0 0.292154 0.374379 0.654389 0.837119 0.559807 0.813262 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160694 episodes
GETTING ACTION FROM:
action 2, numVisits=160665, meanQ=4.834631, numObservations: 4
action 3, numVisits=24, meanQ=3.332083, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.292154 0.374379 0.654389 0.837119 0.559807 0.813262 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 112
Initial state: 0 0.496466 0.233776 0.580873 0.89203 0.521417 0.869553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162406 episodes
GETTING ACTION FROM:
action 3, numVisits=162248, meanQ=4.935429, numObservations: 4
action 0, numVisits=150, meanQ=4.377856, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.496466 0.233776 0.580873 0.89203 0.521417 0.869553 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 113
Initial state: 0 0.646441 0.840614 0.839563 0.670742 0.56277 0.819257 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162371 episodes
GETTING ACTION FROM:
action 2, numVisits=162305, meanQ=4.964461, numObservations: 4
action -1, numVisits=38, meanQ=3.840814, numObservations: 1
action 0, numVisits=23, meanQ=3.453577, numObservations: 1
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.646441 0.840614 0.839563 0.670742 0.56277 0.819257 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 114
Initial state: 0 0.464595 0.562575 0.64195 0.840802 0.625373 0.850096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161818 episodes
GETTING ACTION FROM:
action 3, numVisits=161811, meanQ=4.947581, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.464595 0.562575 0.64195 0.840802 0.625373 0.850096 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 115
Initial state: 0 0.641786 0.828037 0.918468 0.6187 0.687157 0.849432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154896 episodes
GETTING ACTION FROM:
action 3, numVisits=150607, meanQ=4.849982, numObservations: 5
action 2, numVisits=4242, meanQ=4.739544, numObservations: 5
action -1, numVisits=44, meanQ=3.806389, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.641786 0.828037 0.918468 0.6187 0.687157 0.849432 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 116
Initial state: 0 0.503298 0.879299 0.761286 0.111178 0.516489 0.868025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162976 episodes
GETTING ACTION FROM:
action 1, numVisits=162945, meanQ=5.024640, numObservations: 4
action -1, numVisits=27, meanQ=2.586585, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.503298 0.879299 0.761286 0.111178 0.516489 0.868025 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 117
Initial state: 0 0.624988 0.880551 0.516042 0.817292 0.211956 0.135711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161996 episodes
GETTING ACTION FROM:
action 1, numVisits=161952, meanQ=5.026701, numObservations: 4
action 0, numVisits=34, meanQ=3.767913, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.624988 0.880551 0.516042 0.817292 0.211956 0.135711 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 118
Initial state: 0 0.661618 0.877599 0.729593 0.156066 0.634275 0.851875 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158893 episodes
GETTING ACTION FROM:
action 3, numVisits=158860, meanQ=4.961649, numObservations: 4
action -1, numVisits=10, meanQ=2.488000, numObservations: 1
action 2, numVisits=20, meanQ=1.399015, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.661618 0.877599 0.729593 0.156066 0.634275 0.851875 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 119
Initial state: 0 0.548939 0.842573 0.874546 0.771619 0.690888 0.801813 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162479 episodes
GETTING ACTION FROM:
action 2, numVisits=162398, meanQ=4.979726, numObservations: 4
action -1, numVisits=66, meanQ=4.041377, numObservations: 1
action 3, numVisits=9, meanQ=1.767800, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.548939 0.842573 0.874546 0.771619 0.690888 0.801813 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 120
Initial state: 0 0.659826 0.81064 0.0863283 0.202368 0.605986 0.827086 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162624 episodes
GETTING ACTION FROM:
action 1, numVisits=162576, meanQ=5.194125, numObservations: 4
action 3, numVisits=25, meanQ=3.661608, numObservations: 3
action 2, numVisits=19, meanQ=3.202111, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.659826 0.81064 0.0863283 0.202368 0.605986 0.827086 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=11423, meanQ=7.547081, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 199961 episodes
GETTING ACTION FROM:
action 2, numVisits=186239, meanQ=6.042855, numObservations: 4
action 1, numVisits=25140, meanQ=5.877925, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=5, meanQ=-1.600000, numObservations: 3
action -1, numVisits=3, meanQ=-2.003300, numObservations: 1
action: 2
Next state: 0 0.659826 0.81064 0.0863283 0.202368 0.605986 0.827086 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2784, meanQ=8.357013, numObservations: 4
action 1, numVisits=29, meanQ=6.931038, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 25083 episodes
GETTING ACTION FROM:
action 3, numVisits=3052, meanQ=8.202019, numObservations: 4
action 1, numVisits=676, meanQ=5.163551, numObservations: 3
action -1, numVisits=12231, meanQ=-1.575299, numObservations: 1
action 0, numVisits=11937, meanQ=-1.579935, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 3
Next state: 1 0.659826 0.81064 0.0863283 0.202368 0.605986 0.827086 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 121
Initial state: 0 0.778557 0.92004 0.546342 0.834222 0.592555 0.842415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154704 episodes
GETTING ACTION FROM:
action 3, numVisits=154678, meanQ=4.837387, numObservations: 3
action 1, numVisits=16, meanQ=2.498750, numObservations: 4
action 2, numVisits=6, meanQ=0.836683, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.778557 0.92004 0.546342 0.834222 0.592555 0.842415 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=11517, meanQ=3.413915, numObservations: 1
action 1, numVisits=4, meanQ=-0.025000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 201172 episodes
GETTING ACTION FROM:
action 2, numVisits=201171, meanQ=5.910923, numObservations: 4
action -1, numVisits=11518, meanQ=3.413916, numObservations: 1
action 1, numVisits=4, meanQ=-0.025000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action: 2
Next state: 1 0.778557 0.92004 0.546342 0.834222 0.592555 0.842415 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 122
Initial state: 0 0.909272 0.0292021 0.686242 0.808911 0.535479 0.876304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162781 episodes
GETTING ACTION FROM:
action 1, numVisits=162720, meanQ=5.212427, numObservations: 5
action 0, numVisits=35, meanQ=4.039829, numObservations: 1
action 2, numVisits=23, meanQ=2.783487, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.909272 0.0292021 0.686242 0.808911 0.535479 0.876304 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 123
Initial state: 0 0.931646 0.592666 0.523956 0.895528 0.554839 0.878158 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158710 episodes
GETTING ACTION FROM:
action 2, numVisits=156851, meanQ=5.190994, numObservations: 5
action 0, numVisits=1853, meanQ=1.616441, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.931646 0.592666 0.523956 0.895528 0.554839 0.878158 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 124
Initial state: 0 0.289191 0.71466 0.666884 0.849016 0.559706 0.863861 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163212 episodes
GETTING ACTION FROM:
action 3, numVisits=163205, meanQ=5.019373, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.289191 0.71466 0.666884 0.849016 0.559706 0.863861 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 125
Initial state: 0 0.502274 0.897152 0.645001 0.858095 0.055167 0.195205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162859 episodes
GETTING ACTION FROM:
action 1, numVisits=162853, meanQ=4.978622, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.502274 0.897152 0.645001 0.858095 0.055167 0.195205 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 126
Initial state: 0 0.222661 0.443343 0.557666 0.806627 0.667464 0.872351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162126 episodes
GETTING ACTION FROM:
action 3, numVisits=162113, meanQ=5.007327, numObservations: 3
action 1, numVisits=8, meanQ=2.375000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.222661 0.443343 0.557666 0.806627 0.667464 0.872351 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 127
Initial state: 0 0.564739 0.80911 0.570437 0.894814 0.887118 0.683919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154780 episodes
GETTING ACTION FROM:
action 3, numVisits=154665, meanQ=4.832059, numObservations: 4
action 0, numVisits=64, meanQ=3.970277, numObservations: 1
action -1, numVisits=29, meanQ=3.563251, numObservations: 1
action 2, numVisits=14, meanQ=1.635721, numObservations: 3
action 1, numVisits=8, meanQ=0.997500, numObservations: 3
action: 3
Next state: 2 0.564739 0.80911 0.570437 0.894814 0.887118 0.683919 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 128
Initial state: 0 0.116941 0.787242 0.565534 0.892449 0.675625 0.831483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163097 episodes
GETTING ACTION FROM:
action 2, numVisits=162984, meanQ=5.022946, numObservations: 4
action 0, numVisits=57, meanQ=4.089106, numObservations: 1
action -1, numVisits=47, meanQ=4.003369, numObservations: 1
action 3, numVisits=8, meanQ=1.500012, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.116941 0.787242 0.565534 0.892449 0.675625 0.831483 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 129
Initial state: 0 0.603609 0.815709 0.694922 0.85724 0.975665 0.230305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160703 episodes
GETTING ACTION FROM:
action 3, numVisits=159868, meanQ=4.971062, numObservations: 5
action -1, numVisits=566, meanQ=3.452263, numObservations: 1
action 0, numVisits=264, meanQ=3.350225, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 1, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 3
Next state: 2 0.603609 0.815709 0.694922 0.85724 0.975665 0.230305 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 130
Initial state: 0 0.606324 0.852018 0.488366 0.324892 0.608873 0.877267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162656 episodes
GETTING ACTION FROM:
action 1, numVisits=162650, meanQ=5.008659, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.606324 0.852018 0.488366 0.324892 0.608873 0.877267 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 131
Initial state: 0 0.430919 0.290382 0.647606 0.874327 0.533811 0.876318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158165 episodes
GETTING ACTION FROM:
action 2, numVisits=158043, meanQ=4.913402, numObservations: 5
action -1, numVisits=113, meanQ=3.493053, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.430919 0.290382 0.647606 0.874327 0.533811 0.876318 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 132
Initial state: 0 0.680254 0.807049 0.695087 0.828643 0.0146255 0.218626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154946 episodes
GETTING ACTION FROM:
action 1, numVisits=154885, meanQ=4.854002, numObservations: 4
action 0, numVisits=56, meanQ=3.910647, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=2, meanQ=-4.499950, numObservations: 1
action: 1
Next state: 1 0.680254 0.807049 0.695087 0.828643 0.0146255 0.218626 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 133
Initial state: 0 0.626903 0.840028 0.660947 0.848421 0.228828 0.424571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162447 episodes
GETTING ACTION FROM:
action 3, numVisits=162439, meanQ=4.959973, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 3
Next state: 0 0.626903 0.840028 0.660947 0.848421 0.228828 0.424571 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=22694, meanQ=8.427254, numObservations: 3
action 2, numVisits=7, meanQ=4.427143, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6032 episodes
GETTING ACTION FROM:
action 1, numVisits=22694, meanQ=8.427254, numObservations: 3
action 2, numVisits=41, meanQ=5.926588, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=5996, meanQ=0.348030, numObservations: 1
action 0, numVisits=3, meanQ=-3.337872, numObservations: 1
action: 1
Next state: 1 0.626903 0.840028 0.660947 0.848421 0.228828 0.424571 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 134
Initial state: 0 0.560816 0.807206 0.514415 0.811015 0.760922 0.464434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 104868 episodes
GETTING ACTION FROM:
action 0, numVisits=96691, meanQ=5.958679, numObservations: 3
action 2, numVisits=8163, meanQ=4.926220, numObservations: 4
action -1, numVisits=9, meanQ=2.730000, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.560816 0.807206 0.514415 0.811015 0.760922 0.464434 w: 1
Observation: 0 0 0.732289 0 0.734543 0 0.555957 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=36198, meanQ=7.896172, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 164931 episodes
GETTING ACTION FROM:
action 1, numVisits=201108, meanQ=5.661710, numObservations: 5
action 0, numVisits=16, meanQ=3.914518, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.560816 0.807206 0.514415 0.811015 0.760922 0.464434 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 135
Initial state: 0 0.625995 0.877388 0.509332 0.473492 0.677117 0.813994 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96322 episodes
GETTING ACTION FROM:
action -1, numVisits=96250, meanQ=2.927583, numObservations: 1
action 1, numVisits=62, meanQ=1.953555, numObservations: 4
action 3, numVisits=7, meanQ=0.287157, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.625995 0.877388 0.509332 0.473492 0.677117 0.813994 w: 1
Observation: 0 0.559243 0 0.471048 0 0.699273 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=96132, meanQ=4.990108, numObservations: 5
action 0, numVisits=99, meanQ=4.315011, numObservations: 1
action -1, numVisits=13, meanQ=3.107334, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
Sampled 159944 episodes
GETTING ACTION FROM:
action 1, numVisits=256065, meanQ=4.907879, numObservations: 5
action 0, numVisits=105, meanQ=4.228562, numObservations: 1
action -1, numVisits=18, meanQ=3.209983, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 1
Next state: 1 0.625995 0.877388 0.509332 0.473492 0.677117 0.813994 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 136
Initial state: 0 0.695426 0.852959 0.572701 0.814522 0.107346 0.310783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161884 episodes
GETTING ACTION FROM:
action 2, numVisits=160912, meanQ=4.922067, numObservations: 4
action 3, numVisits=848, meanQ=4.691605, numObservations: 4
action -1, numVisits=107, meanQ=4.263951, numObservations: 1
action 1, numVisits=15, meanQ=2.267340, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.695426 0.852959 0.572701 0.814522 0.107346 0.310783 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 137
Initial state: 0 0.620875 0.829645 0.543015 0.898277 0.341933 0.655801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161938 episodes
GETTING ACTION FROM:
action 1, numVisits=161928, meanQ=4.958842, numObservations: 5
action 3, numVisits=3, meanQ=0.000033, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.620875 0.829645 0.543015 0.898277 0.341933 0.655801 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 138
Initial state: 0 0.659113 0.806014 0.691255 0.879258 0.0143748 0.640242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163141 episodes
GETTING ACTION FROM:
action 2, numVisits=163115, meanQ=5.028876, numObservations: 3
action 1, numVisits=20, meanQ=2.136000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.659113 0.806014 0.691255 0.879258 0.0143748 0.640242 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 139
Initial state: 0 0.918252 0.484941 0.542588 0.804999 0.670728 0.862923 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161075 episodes
GETTING ACTION FROM:
action 3, numVisits=160787, meanQ=4.943508, numObservations: 4
action -1, numVisits=126, meanQ=4.326887, numObservations: 1
action 2, numVisits=156, meanQ=4.326885, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.918252 0.484941 0.542588 0.804999 0.670728 0.862923 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11905, meanQ=4.582886, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 200143 episodes
GETTING ACTION FROM:
action 1, numVisits=200138, meanQ=6.179758, numObservations: 5
action 2, numVisits=11905, meanQ=4.582886, numObservations: 5
action 3, numVisits=7, meanQ=3.427157, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.918252 0.484941 0.542588 0.804999 0.670728 0.862923 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 140
Initial state: 0 0.243065 0.179541 0.561659 0.878577 0.63356 0.878032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163046 episodes
GETTING ACTION FROM:
action 3, numVisits=163038, meanQ=5.014359, numObservations: 4
action 1, numVisits=3, meanQ=0.000033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.243065 0.179541 0.561659 0.878577 0.63356 0.878032 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 141
Initial state: 0 0.516378 0.870558 0.826557 0.383446 0.663026 0.802151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95671 episodes
GETTING ACTION FROM:
action -1, numVisits=95662, meanQ=2.874396, numObservations: 1
action 1, numVisits=5, meanQ=-0.399980, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.516378 0.870558 0.826557 0.383446 0.663026 0.802151 w: 1
Observation: 0 0.424843 0 0.852317 0 0.627396 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=95595, meanQ=4.961395, numObservations: 4
action 0, numVisits=58, meanQ=4.044092, numObservations: 1
action 3, numVisits=5, meanQ=1.780000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 163757 episodes
GETTING ACTION FROM:
action 1, numVisits=259350, meanQ=5.071885, numObservations: 4
action 0, numVisits=59, meanQ=4.032987, numObservations: 1
action 3, numVisits=5, meanQ=1.780000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 1
Next state: 1 0.516378 0.870558 0.826557 0.383446 0.663026 0.802151 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 142
Initial state: 0 0.184094 0.0829325 0.63036 0.805236 0.693028 0.870735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162526 episodes
GETTING ACTION FROM:
action 1, numVisits=162496, meanQ=5.000379, numObservations: 4
action -1, numVisits=24, meanQ=3.563313, numObservations: 1
action 3, numVisits=3, meanQ=0.000033, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.184094 0.0829325 0.63036 0.805236 0.693028 0.870735 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=22462, meanQ=8.403938, numObservations: 3
action 3, numVisits=154, meanQ=7.919250, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 5679 episodes
GETTING ACTION FROM:
action 2, numVisits=22462, meanQ=8.403938, numObservations: 3
action 3, numVisits=177, meanQ=7.720703, numObservations: 4
action 1, numVisits=19, meanQ=6.578426, numObservations: 3
action -1, numVisits=4917, meanQ=0.174291, numObservations: 1
action 0, numVisits=723, meanQ=-0.157599, numObservations: 1
action: 2
Next state: 1 0.184094 0.0829325 0.63036 0.805236 0.693028 0.870735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 143
Initial state: 0 0.159953 0.510666 0.582234 0.814878 0.511742 0.800799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156595 episodes
GETTING ACTION FROM:
action 3, numVisits=156560, meanQ=5.044579, numObservations: 4
action 0, numVisits=31, meanQ=3.786741, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.159953 0.510666 0.582234 0.814878 0.511742 0.800799 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 144
Initial state: 0 0.6426 0.822954 0.519461 0.105841 0.608647 0.890764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95615 episodes
GETTING ACTION FROM:
action -1, numVisits=95493, meanQ=3.066229, numObservations: 1
action 0, numVisits=54, meanQ=2.164202, numObservations: 1
action 1, numVisits=42, meanQ=2.017155, numObservations: 4
action 3, numVisits=22, meanQ=1.040459, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action: -1
Next state: 0 0.6426 0.822954 0.519461 0.105841 0.608647 0.890764 w: 1
Observation: 0 0.614615 0 0.581684 0 0.625063 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=95483, meanQ=5.162472, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 162745 episodes
GETTING ACTION FROM:
action 3, numVisits=258227, meanQ=5.259253, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action: 3
Next state: 1 0.6426 0.822954 0.519461 0.105841 0.608647 0.890764 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 145
Initial state: 0 0.83956 0.320131 0.586464 0.843216 0.580665 0.890334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94220 episodes
GETTING ACTION FROM:
action 0, numVisits=84280, meanQ=5.365954, numObservations: 3
action 2, numVisits=9933, meanQ=4.996194, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.83956 0.320131 0.586464 0.843216 0.580665 0.890334 w: 1
Observation: 0 0 0.380277 0 0.779705 0 0.932414 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=28040, meanQ=8.103316, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 157612 episodes
GETTING ACTION FROM:
action 2, numVisits=185533, meanQ=5.578991, numObservations: 5
action 0, numVisits=88, meanQ=4.851005, numObservations: 1
action 1, numVisits=18, meanQ=3.852778, numObservations: 4
action -1, numVisits=15, meanQ=3.530910, numObservations: 1
action 3, numVisits=3, meanQ=0.993333, numObservations: 3
action: 2
Next state: 1 0.83956 0.320131 0.586464 0.843216 0.580665 0.890334 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 146
Initial state: 0 0.15039 0.338267 0.683933 0.802862 0.548369 0.822952 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163119 episodes
GETTING ACTION FROM:
action 3, numVisits=163038, meanQ=4.986068, numObservations: 3
action -1, numVisits=73, meanQ=4.162577, numObservations: 1
action 2, numVisits=5, meanQ=-0.200000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.15039 0.338267 0.683933 0.802862 0.548369 0.822952 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 147
Initial state: 0 0.67587 0.889813 0.509489 0.873403 0.83591 0.412127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160538 episodes
GETTING ACTION FROM:
action 1, numVisits=160449, meanQ=4.955533, numObservations: 4
action -1, numVisits=51, meanQ=3.869725, numObservations: 1
action 0, numVisits=36, meanQ=3.697474, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.67587 0.889813 0.509489 0.873403 0.83591 0.412127 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 148
Initial state: 0 0.736528 0.695532 0.576082 0.855903 0.633503 0.898447 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162916 episodes
GETTING ACTION FROM:
action 1, numVisits=162896, meanQ=5.175242, numObservations: 4
action 2, numVisits=15, meanQ=1.194007, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.736528 0.695532 0.576082 0.855903 0.633503 0.898447 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 149
Initial state: 0 0.538165 0.820454 0.540913 0.819 0.704538 0.448973 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153471 episodes
GETTING ACTION FROM:
action 2, numVisits=153377, meanQ=4.796307, numObservations: 5
action -1, numVisits=43, meanQ=3.749553, numObservations: 1
action 0, numVisits=44, meanQ=3.744657, numObservations: 2
action 1, numVisits=6, meanQ=1.498333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.538165 0.820454 0.540913 0.819 0.704538 0.448973 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 150
Initial state: 0 0.500505 0.854638 0.688295 0.845605 0.490419 0.454324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161626 episodes
GETTING ACTION FROM:
action 2, numVisits=161620, meanQ=5.158878, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.500505 0.854638 0.688295 0.845605 0.490419 0.454324 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 151
Initial state: 0 0.138977 0.341187 0.569079 0.878311 0.501912 0.810909 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159872 episodes
GETTING ACTION FROM:
action 1, numVisits=159813, meanQ=4.919819, numObservations: 5
action 0, numVisits=47, meanQ=3.877783, numObservations: 1
action 2, numVisits=7, meanQ=2.002871, numObservations: 3
action 3, numVisits=3, meanQ=0.000033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.138977 0.341187 0.569079 0.878311 0.501912 0.810909 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22250, meanQ=8.409853, numObservations: 3
action 2, numVisits=15, meanQ=6.465340, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7501 episodes
GETTING ACTION FROM:
action 3, numVisits=23246, meanQ=8.296964, numObservations: 3
action 2, numVisits=294, meanQ=6.810759, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=6150, meanQ=0.259933, numObservations: 1
action 0, numVisits=77, meanQ=-0.482857, numObservations: 1
action: 3
Next state: 1 0.138977 0.341187 0.569079 0.878311 0.501912 0.810909 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 152
Initial state: 0 0.681901 0.861768 0.519616 0.641996 0.545988 0.866422 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154745 episodes
GETTING ACTION FROM:
action 1, numVisits=154724, meanQ=4.840696, numObservations: 3
action 3, numVisits=14, meanQ=1.079293, numObservations: 3
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.681901 0.861768 0.519616 0.641996 0.545988 0.866422 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 153
Initial state: 0 0.536311 0.824676 0.430168 0.399834 0.577267 0.834082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159505 episodes
GETTING ACTION FROM:
action 3, numVisits=159432, meanQ=4.887551, numObservations: 5
action 0, numVisits=66, meanQ=4.030878, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.536311 0.824676 0.430168 0.399834 0.577267 0.834082 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 154
Initial state: 0 0.746536 0.789746 0.666615 0.86426 0.515427 0.896355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161508 episodes
GETTING ACTION FROM:
action 3, numVisits=161494, meanQ=5.202561, numObservations: 5
action 2, numVisits=9, meanQ=0.456667, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.746536 0.789746 0.666615 0.86426 0.515427 0.896355 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=3249, meanQ=4.783938, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 7122 episodes
GETTING ACTION FROM:
action -1, numVisits=10357, meanQ=1.223111, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=12, meanQ=-0.515825, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.746536 0.789746 0.666615 0.86426 0.515427 0.896355 w: 1
Observation: 0 0.783611 0 0.603566 0 0.537808 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=3243, meanQ=6.830828, numObservations: 4
action -1, numVisits=1676, meanQ=4.817939, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=3, meanQ=-3.017607, numObservations: 1
action 0, numVisits=2, meanQ=-196.676574, numObservations: 1
Sampled 6729 episodes
GETTING ACTION FROM:
action 2, numVisits=3243, meanQ=6.830828, numObservations: 4
action -1, numVisits=8404, meanQ=0.743648, numObservations: 1
action 1, numVisits=3, meanQ=-3.017607, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 0, numVisits=2, meanQ=-196.676574, numObservations: 1
action: 2
Next state: 1 0.746536 0.789746 0.666615 0.86426 0.515427 0.896355 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8409
Run # 155
Initial state: 0 0.674844 0.808948 0.608294 0.849269 0.00203629 0.274316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161896 episodes
GETTING ACTION FROM:
action 3, numVisits=161651, meanQ=5.005160, numObservations: 5
action -1, numVisits=234, meanQ=2.009860, numObservations: 1
action 1, numVisits=7, meanQ=0.428571, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 3
Next state: 0 0.674844 0.808948 0.608294 0.849269 0.00203629 0.274316 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=22599, meanQ=8.422515, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3658 episodes
GETTING ACTION FROM:
action 2, numVisits=22599, meanQ=8.422515, numObservations: 4
action 1, numVisits=57, meanQ=6.445972, numObservations: 4
action 3, numVisits=4, meanQ=2.497525, numObservations: 2
action -1, numVisits=3590, meanQ=0.072100, numObservations: 1
action 0, numVisits=12, meanQ=-2.000825, numObservations: 1
action: 2
Next state: 1 0.674844 0.808948 0.608294 0.849269 0.00203629 0.274316 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 156
Initial state: 0 0.575059 0.896744 0.302756 0.249122 0.535914 0.876833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162748 episodes
GETTING ACTION FROM:
action 3, numVisits=162724, meanQ=5.000398, numObservations: 4
action 1, numVisits=10, meanQ=1.700000, numObservations: 3
action 2, numVisits=10, meanQ=1.681000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.575059 0.896744 0.302756 0.249122 0.535914 0.876833 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26775, meanQ=8.291413, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6895 episodes
GETTING ACTION FROM:
action 2, numVisits=26834, meanQ=8.283851, numObservations: 4
action 1, numVisits=37, meanQ=5.432162, numObservations: 3
action 0, numVisits=6801, meanQ=0.335468, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=2, meanQ=-196.214893, numObservations: 1
action: 2
Next state: 0 0.575059 0.896744 0.302756 0.249122 0.535914 0.876833 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=173, meanQ=8.599595, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10999 episodes
GETTING ACTION FROM:
action 1, numVisits=231, meanQ=7.488009, numObservations: 5
action 3, numVisits=39, meanQ=5.768977, numObservations: 4
action 2, numVisits=42, meanQ=5.547381, numObservations: 4
action 0, numVisits=10799, meanQ=-1.605614, numObservations: 1
action -1, numVisits=65, meanQ=-4.967229, numObservations: 1
action: 1
Next state: 1 0.575059 0.896744 0.302756 0.249122 0.535914 0.876833 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 157
Initial state: 0 0.611275 0.80691 0.525818 0.899344 0.142729 0.480886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162989 episodes
GETTING ACTION FROM:
action 2, numVisits=162960, meanQ=4.971511, numObservations: 5
action 3, numVisits=21, meanQ=3.415238, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.611275 0.80691 0.525818 0.899344 0.142729 0.480886 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 158
Initial state: 0 0.672076 0.833223 0.330545 0.317266 0.698823 0.864613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161261 episodes
GETTING ACTION FROM:
action 3, numVisits=161240, meanQ=4.962357, numObservations: 4
action 2, numVisits=16, meanQ=2.920000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.672076 0.833223 0.330545 0.317266 0.698823 0.864613 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 159
Initial state: 0 0.667249 0.875225 0.599804 0.835772 0.180803 0.691154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153697 episodes
GETTING ACTION FROM:
action 1, numVisits=153688, meanQ=4.825191, numObservations: 4
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.667249 0.875225 0.599804 0.835772 0.180803 0.691154 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 160
Initial state: 0 0.66898 0.837531 0.00565168 0.357681 0.639125 0.822711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162210 episodes
GETTING ACTION FROM:
action 3, numVisits=162180, meanQ=4.949125, numObservations: 4
action 1, numVisits=18, meanQ=2.872783, numObservations: 3
action 2, numVisits=8, meanQ=2.498750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.66898 0.837531 0.00565168 0.357681 0.639125 0.822711 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 161
Initial state: 0 0.538005 0.807201 0.858065 0.0752477 0.563073 0.877033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162450 episodes
GETTING ACTION FROM:
action 2, numVisits=162288, meanQ=4.982853, numObservations: 5
action 3, numVisits=144, meanQ=4.403964, numObservations: 5
action 0, numVisits=15, meanQ=3.171164, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.538005 0.807201 0.858065 0.0752477 0.563073 0.877033 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 162
Initial state: 0 0.640401 0.840806 0.643058 0.856616 0.190854 0.964162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155061 episodes
GETTING ACTION FROM:
action 3, numVisits=154947, meanQ=4.845481, numObservations: 4
action -1, numVisits=40, meanQ=3.752133, numObservations: 1
action 1, numVisits=38, meanQ=3.733684, numObservations: 4
action 2, numVisits=34, meanQ=3.545294, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.640401 0.840806 0.643058 0.856616 0.190854 0.964162 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 163
Initial state: 0 0.150595 0.55852 0.666645 0.873599 0.598605 0.897305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159551 episodes
GETTING ACTION FROM:
action 2, numVisits=159378, meanQ=4.896916, numObservations: 5
action 0, numVisits=110, meanQ=4.239915, numObservations: 1
action -1, numVisits=60, meanQ=3.795979, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.150595 0.55852 0.666645 0.873599 0.598605 0.897305 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 164
Initial state: 0 0.565348 0.867369 0.535776 0.898058 0.658664 0.0678095 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158753 episodes
GETTING ACTION FROM:
action 2, numVisits=152545, meanQ=5.004400, numObservations: 3
action 0, numVisits=6181, meanQ=3.104246, numObservations: 1
action 3, numVisits=20, meanQ=1.699510, numObservations: 5
action 1, numVisits=5, meanQ=-0.002000, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.565348 0.867369 0.535776 0.898058 0.658664 0.0678095 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 165
Initial state: 0 0.684842 0.865881 0.682245 0.862357 0.753106 0.915937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156465 episodes
GETTING ACTION FROM:
action 1, numVisits=156454, meanQ=4.877860, numObservations: 5
action 3, numVisits=6, meanQ=1.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.684842 0.865881 0.682245 0.862357 0.753106 0.915937 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 166
Initial state: 0 0.569645 0.847718 0.528446 0.870846 0.94983 0.535598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161568 episodes
GETTING ACTION FROM:
action 2, numVisits=161445, meanQ=4.951640, numObservations: 5
action 0, numVisits=113, meanQ=4.300330, numObservations: 1
action 3, numVisits=7, meanQ=1.428571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.569645 0.847718 0.528446 0.870846 0.94983 0.535598 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 167
Initial state: 0 0.626209 0.818061 0.681009 0.778466 0.62513 0.871678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162649 episodes
GETTING ACTION FROM:
action 1, numVisits=162578, meanQ=5.043458, numObservations: 3
action -1, numVisits=67, meanQ=4.189556, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.626209 0.818061 0.681009 0.778466 0.62513 0.871678 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=11882, meanQ=5.561174, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 200743 episodes
GETTING ACTION FROM:
action 3, numVisits=200722, meanQ=5.809423, numObservations: 4
action 1, numVisits=11882, meanQ=5.561174, numObservations: 4
action 2, numVisits=19, meanQ=2.847895, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 3
Next state: 1 0.626209 0.818061 0.681009 0.778466 0.62513 0.871678 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 168
Initial state: 0 0.582884 0.816875 0.651756 0.801993 0.858406 0.937153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160978 episodes
GETTING ACTION FROM:
action 1, numVisits=160935, meanQ=4.931615, numObservations: 5
action 0, numVisits=23, meanQ=3.495854, numObservations: 1
action 2, numVisits=12, meanQ=2.415842, numObservations: 4
action 3, numVisits=6, meanQ=1.498333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.582884 0.816875 0.651756 0.801993 0.858406 0.937153 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3983, meanQ=7.756979, numObservations: 5
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 13381 episodes
GETTING ACTION FROM:
action 3, numVisits=4080, meanQ=7.688516, numObservations: 5
action 2, numVisits=21, meanQ=5.570952, numObservations: 4
action 1, numVisits=3, meanQ=4.996667, numObservations: 1
action 0, numVisits=13263, meanQ=-0.012854, numObservations: 1
action -1, numVisits=2, meanQ=-195.905847, numObservations: 1
action: 3
Next state: 1 0.582884 0.816875 0.651756 0.801993 0.858406 0.937153 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 169
Initial state: 0 0.676476 0.899266 0.30898 0.710663 0.66721 0.875369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162541 episodes
GETTING ACTION FROM:
action 1, numVisits=162517, meanQ=4.959877, numObservations: 4
action 0, numVisits=17, meanQ=3.156198, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.676476 0.899266 0.30898 0.710663 0.66721 0.875369 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 170
Initial state: 0 0.0180232 0.273074 0.516139 0.817545 0.625852 0.84675 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162719 episodes
GETTING ACTION FROM:
action 3, numVisits=162713, meanQ=4.954636, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0180232 0.273074 0.516139 0.817545 0.625852 0.84675 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 171
Initial state: 0 0.514763 0.850732 0.648417 0.806515 0.252806 0.365383 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162029 episodes
GETTING ACTION FROM:
action 1, numVisits=161983, meanQ=4.964516, numObservations: 4
action -1, numVisits=37, meanQ=3.835802, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=3, meanQ=0.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.514763 0.850732 0.648417 0.806515 0.252806 0.365383 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 172
Initial state: 0 0.590443 0.855623 0.103413 0.954852 0.648251 0.838039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155246 episodes
GETTING ACTION FROM:
action 1, numVisits=155185, meanQ=4.863359, numObservations: 3
action 0, numVisits=32, meanQ=3.616425, numObservations: 1
action -1, numVisits=27, meanQ=3.508878, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.590443 0.855623 0.103413 0.954852 0.648251 0.838039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 173
Initial state: 0 0.692692 0.828361 0.543574 0.837016 0.0714691 0.900105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162490 episodes
GETTING ACTION FROM:
action 3, numVisits=162484, meanQ=4.936283, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.692692 0.828361 0.543574 0.837016 0.0714691 0.900105 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 174
Initial state: 0 0.600796 0.81934 0.634093 0.862808 0.717267 0.617014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161830 episodes
GETTING ACTION FROM:
action 1, numVisits=161782, meanQ=4.926482, numObservations: 4
action 0, numVisits=42, meanQ=3.851533, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.600796 0.81934 0.634093 0.862808 0.717267 0.617014 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 175
Initial state: 0 0.513473 0.878724 0.676636 0.84675 0.737693 0.79459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157977 episodes
GETTING ACTION FROM:
action 3, numVisits=152363, meanQ=4.941296, numObservations: 5
action -1, numVisits=5604, meanQ=2.804011, numObservations: 1
action 2, numVisits=5, meanQ=-0.200000, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.513473 0.878724 0.676636 0.84675 0.737693 0.79459 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 176
Initial state: 0 0.592591 0.889035 0.589639 0.821714 0.81475 0.162712 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154212 episodes
GETTING ACTION FROM:
action 1, numVisits=154201, meanQ=4.798909, numObservations: 4
action 2, numVisits=4, meanQ=0.750000, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.592591 0.889035 0.589639 0.821714 0.81475 0.162712 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 177
Initial state: 0 0.510207 0.826927 0.476016 0.728362 0.553196 0.828907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163314 episodes
GETTING ACTION FROM:
action 2, numVisits=163305, meanQ=5.016370, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.510207 0.826927 0.476016 0.728362 0.553196 0.828907 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=26984, meanQ=8.322467, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9343 episodes
GETTING ACTION FROM:
action 1, numVisits=26984, meanQ=8.322467, numObservations: 3
action 3, numVisits=55, meanQ=5.694648, numObservations: 4
action 2, numVisits=16, meanQ=4.681250, numObservations: 2
action -1, numVisits=9262, meanQ=0.114464, numObservations: 1
action 0, numVisits=15, meanQ=-2.000660, numObservations: 1
action: 1
Next state: 1 0.510207 0.826927 0.476016 0.728362 0.553196 0.828907 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 178
Initial state: 0 0.636056 0.80131 0.586797 0.894957 0.807246 0.392759 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162519 episodes
GETTING ACTION FROM:
action 2, numVisits=162461, meanQ=4.960475, numObservations: 5
action 0, numVisits=40, meanQ=3.881230, numObservations: 1
action 1, numVisits=15, meanQ=3.068007, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.636056 0.80131 0.586797 0.894957 0.807246 0.392759 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 179
Initial state: 0 0.0110099 0.0634122 0.684036 0.886226 0.606552 0.831784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162281 episodes
GETTING ACTION FROM:
action 2, numVisits=162259, meanQ=5.146764, numObservations: 4
action 0, numVisits=18, meanQ=3.484364, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0110099 0.0634122 0.684036 0.886226 0.606552 0.831784 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 180
Initial state: 0 0.673947 0.819647 0.508104 0.854907 0.369693 0.55465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161734 episodes
GETTING ACTION FROM:
action 2, numVisits=161643, meanQ=5.035474, numObservations: 5
action 1, numVisits=70, meanQ=3.070520, numObservations: 5
action 3, numVisits=17, meanQ=2.410600, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.673947 0.819647 0.508104 0.854907 0.369693 0.55465 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 181
Initial state: 0 0.688568 0.854227 0.997326 0.700593 0.540202 0.886096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161642 episodes
GETTING ACTION FROM:
action 3, numVisits=161598, meanQ=4.945823, numObservations: 4
action 2, numVisits=23, meanQ=2.870004, numObservations: 4
action 1, numVisits=17, meanQ=2.803535, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.688568 0.854227 0.997326 0.700593 0.540202 0.886096 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 182
Initial state: 0 0.629657 0.897777 0.780136 0.539164 0.516714 0.814251 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163508 episodes
GETTING ACTION FROM:
action 1, numVisits=163497, meanQ=5.151594, numObservations: 5
action 3, numVisits=6, meanQ=0.836683, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.629657 0.897777 0.780136 0.539164 0.516714 0.814251 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9294, meanQ=7.879122, numObservations: 5
action 2, numVisits=130, meanQ=7.004772, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9357 episodes
GETTING ACTION FROM:
action 3, numVisits=9294, meanQ=7.879122, numObservations: 5
action 2, numVisits=130, meanQ=7.004772, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action 0, numVisits=9351, meanQ=0.021924, numObservations: 1
action -1, numVisits=7, meanQ=-3.414286, numObservations: 1
action: 3
Next state: 1 0.629657 0.897777 0.780136 0.539164 0.516714 0.814251 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 183
Initial state: 0 0.793015 0.510721 0.572153 0.834624 0.506858 0.880592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94757 episodes
GETTING ACTION FROM:
action -1, numVisits=94752, meanQ=2.911946, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.793015 0.510721 0.572153 0.834624 0.506858 0.880592 w: 1
Observation: 0 0.754402 0 0.509142 0 0.544841 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=94647, meanQ=4.961639, numObservations: 4
action 0, numVisits=100, meanQ=4.297165, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 162535 episodes
GETTING ACTION FROM:
action 2, numVisits=257133, meanQ=4.797296, numObservations: 4
action 0, numVisits=144, meanQ=4.221129, numObservations: 1
action 3, numVisits=5, meanQ=1.596000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.793015 0.510721 0.572153 0.834624 0.506858 0.880592 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 184
Initial state: 0 0.690117 0.813596 0.62336 0.86057 0.788821 0.489891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161476 episodes
GETTING ACTION FROM:
action 3, numVisits=161373, meanQ=4.987554, numObservations: 4
action 0, numVisits=54, meanQ=4.025099, numObservations: 1
action 1, numVisits=40, meanQ=3.863255, numObservations: 4
action 2, numVisits=7, meanQ=2.285729, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.690117 0.813596 0.62336 0.86057 0.788821 0.489891 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 185
Initial state: 0 0.829033 0.574024 0.638657 0.896628 0.557797 0.863828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159894 episodes
GETTING ACTION FROM:
action 3, numVisits=159793, meanQ=4.976035, numObservations: 5
action 0, numVisits=40, meanQ=1.345867, numObservations: 1
action 1, numVisits=35, meanQ=1.314300, numObservations: 3
action -1, numVisits=25, meanQ=1.140054, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.829033 0.574024 0.638657 0.896628 0.557797 0.863828 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 186
Initial state: 0 0.607068 0.888137 0.715976 0.727926 0.524536 0.818553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162332 episodes
GETTING ACTION FROM:
action 3, numVisits=162319, meanQ=5.145784, numObservations: 4
action 1, numVisits=7, meanQ=0.285743, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.607068 0.888137 0.715976 0.727926 0.524536 0.818553 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 187
Initial state: 0 0.685859 0.864693 0.656778 0.838909 0.72662 0.999279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162865 episodes
GETTING ACTION FROM:
action 3, numVisits=162858, meanQ=5.006360, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.685859 0.864693 0.656778 0.838909 0.72662 0.999279 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 188
Initial state: 0 0.668486 0.865315 0.557836 0.87166 0.803762 0.623419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155815 episodes
GETTING ACTION FROM:
action 3, numVisits=155753, meanQ=4.898590, numObservations: 3
action -1, numVisits=38, meanQ=3.773320, numObservations: 1
action 0, numVisits=18, meanQ=3.159666, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 3
action 2, numVisits=3, meanQ=-3.363333, numObservations: 1
action: 3
Next state: 2 0.668486 0.865315 0.557836 0.87166 0.803762 0.623419 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 189
Initial state: 0 0.549519 0.861216 0.661079 0.805925 0.0423052 0.750796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162728 episodes
GETTING ACTION FROM:
action 2, numVisits=162672, meanQ=5.041478, numObservations: 4
action -1, numVisits=40, meanQ=3.915500, numObservations: 1
action 0, numVisits=13, meanQ=3.107334, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.549519 0.861216 0.661079 0.805925 0.0423052 0.750796 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 190
Initial state: 0 0.13638 0.196762 0.580822 0.86774 0.664492 0.840618 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154151 episodes
GETTING ACTION FROM:
action 1, numVisits=153007, meanQ=4.856555, numObservations: 4
action 2, numVisits=793, meanQ=4.621279, numObservations: 4
action 3, numVisits=255, meanQ=4.407580, numObservations: 4
action 0, numVisits=62, meanQ=3.983009, numObservations: 1
action -1, numVisits=34, meanQ=3.682506, numObservations: 1
action: 1
Next state: 0 0.13638 0.196762 0.580822 0.86774 0.664492 0.840618 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=21406, meanQ=8.368995, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12059 episodes
GETTING ACTION FROM:
action 3, numVisits=21406, meanQ=8.368995, numObservations: 4
action 1, numVisits=12, meanQ=7.658333, numObservations: 4
action 2, numVisits=20, meanQ=4.399500, numObservations: 3
action 0, numVisits=12022, meanQ=0.311042, numObservations: 3
action -1, numVisits=9, meanQ=-2.112200, numObservations: 1
action: 3
Next state: 0 0.13638 0.196762 0.580822 0.86774 0.664492 0.840618 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1774, meanQ=8.181220, numObservations: 4
action 3, numVisits=6, meanQ=4.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 19637 episodes
GETTING ACTION FROM:
action 2, numVisits=1799, meanQ=8.155560, numObservations: 4
action 3, numVisits=24, meanQ=3.832500, numObservations: 4
action 1, numVisits=20, meanQ=3.399500, numObservations: 3
action -1, numVisits=19571, meanQ=-1.633461, numObservations: 1
action 0, numVisits=6, meanQ=-65.946146, numObservations: 1
action: 2
Next state: 1 0.13638 0.196762 0.580822 0.86774 0.664492 0.840618 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 191
Initial state: 0 0.602785 0.817112 0.597355 0.875469 0.740963 0.364733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161701 episodes
GETTING ACTION FROM:
action 1, numVisits=154168, meanQ=4.940118, numObservations: 4
action 2, numVisits=7512, meanQ=4.872652, numObservations: 3
action -1, numVisits=12, meanQ=2.812500, numObservations: 1
action 3, numVisits=7, meanQ=2.285729, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.602785 0.817112 0.597355 0.875469 0.740963 0.364733 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 192
Initial state: 0 0.610762 0.891355 0.557331 0.89139 0.955898 0.286726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163131 episodes
GETTING ACTION FROM:
action 3, numVisits=159804, meanQ=5.056076, numObservations: 5
action 2, numVisits=3314, meanQ=4.950373, numObservations: 5
action 0, numVisits=10, meanQ=2.485195, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.610762 0.891355 0.557331 0.89139 0.955898 0.286726 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 193
Initial state: 0 0.587039 0.820306 0.620818 0.602569 0.576314 0.899919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162718 episodes
GETTING ACTION FROM:
action 3, numVisits=162361, meanQ=5.015545, numObservations: 5
action 2, numVisits=296, meanQ=4.621800, numObservations: 4
action 0, numVisits=44, meanQ=3.946368, numObservations: 1
action -1, numVisits=16, meanQ=3.224806, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.587039 0.820306 0.620818 0.602569 0.576314 0.899919 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 194
Initial state: 0 0.668597 0.871019 0.621793 0.892036 0.445936 0.753536 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161390 episodes
GETTING ACTION FROM:
action 1, numVisits=161382, meanQ=4.949662, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 1
Next state: 1 0.668597 0.871019 0.621793 0.892036 0.445936 0.753536 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 195
Initial state: 0 0.648783 0.818629 0.693712 0.808671 0.754909 0.337232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164328 episodes
GETTING ACTION FROM:
action 2, numVisits=164187, meanQ=5.020451, numObservations: 5
action 0, numVisits=72, meanQ=4.215791, numObservations: 1
action -1, numVisits=67, meanQ=4.171395, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.648783 0.818629 0.693712 0.808671 0.754909 0.337232 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 196
Initial state: 0 0.672128 0.880703 0.332494 0.495363 0.589816 0.835361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163495 episodes
GETTING ACTION FROM:
action 2, numVisits=163458, meanQ=5.009497, numObservations: 3
action -1, numVisits=26, meanQ=3.661815, numObservations: 1
action 1, numVisits=6, meanQ=2.003350, numObservations: 3
action 3, numVisits=3, meanQ=-0.659967, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.672128 0.880703 0.332494 0.495363 0.589816 0.835361 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=26877, meanQ=8.299864, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3539 episodes
GETTING ACTION FROM:
action 3, numVisits=26877, meanQ=8.299864, numObservations: 3
action 1, numVisits=34, meanQ=4.648699, numObservations: 4
action 0, numVisits=3493, meanQ=0.282977, numObservations: 1
action -1, numVisits=15, meanQ=-1.340000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.672128 0.880703 0.332494 0.495363 0.589816 0.835361 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 197
Initial state: 0 0.635258 0.824394 0.874795 0.199316 0.639086 0.847787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154158 episodes
GETTING ACTION FROM:
action 2, numVisits=154151, meanQ=4.805249, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-4.499950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.635258 0.824394 0.874795 0.199316 0.639086 0.847787 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 198
Initial state: 0 0.481919 0.732411 0.586716 0.893243 0.66846 0.855936 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162048 episodes
GETTING ACTION FROM:
action 1, numVisits=161974, meanQ=5.000269, numObservations: 4
action 0, numVisits=49, meanQ=4.003447, numObservations: 1
action 3, numVisits=14, meanQ=2.852150, numObservations: 3
action 2, numVisits=9, meanQ=2.443344, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.481919 0.732411 0.586716 0.893243 0.66846 0.855936 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26683, meanQ=8.326032, numObservations: 5
action 3, numVisits=17, meanQ=6.647065, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8203 episodes
GETTING ACTION FROM:
action 2, numVisits=26683, meanQ=8.326032, numObservations: 5
action 3, numVisits=17, meanQ=6.647065, numObservations: 3
action 0, numVisits=8194, meanQ=0.271659, numObservations: 2
action -1, numVisits=10, meanQ=-1.901000, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 2
Next state: 0 0.481919 0.732411 0.586716 0.893243 0.66846 0.855936 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=2057, meanQ=8.414668, numObservations: 3
action 3, numVisits=45, meanQ=7.575780, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 40293 episodes
GETTING ACTION FROM:
action 2, numVisits=2087, meanQ=8.392072, numObservations: 3
action 3, numVisits=124, meanQ=6.870243, numObservations: 4
action 1, numVisits=37, meanQ=4.891622, numObservations: 4
action -1, numVisits=40146, meanQ=-1.634243, numObservations: 1
action 0, numVisits=4, meanQ=-5.375042, numObservations: 1
action: 2
Next state: 1 0.481919 0.732411 0.586716 0.893243 0.66846 0.855936 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 199
Initial state: 0 0.442569 0.586955 0.545855 0.831956 0.67101 0.895907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161598 episodes
GETTING ACTION FROM:
action 3, numVisits=161542, meanQ=5.037804, numObservations: 4
action 0, numVisits=48, meanQ=4.044931, numObservations: 1
action 1, numVisits=5, meanQ=-0.399980, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.442569 0.586955 0.545855 0.831956 0.67101 0.895907 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 200
Initial state: 0 0.681808 0.830195 0.543529 0.811129 0.355955 0.822175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161799 episodes
GETTING ACTION FROM:
action 3, numVisits=161793, meanQ=4.934224, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.681808 0.830195 0.543529 0.811129 0.355955 0.822175 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 201
Initial state: 0 0.279526 0.120041 0.612297 0.806684 0.516189 0.836526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161614 episodes
GETTING ACTION FROM:
action 1, numVisits=160494, meanQ=4.935126, numObservations: 5
action 0, numVisits=1106, meanQ=3.233811, numObservations: 1
action 2, numVisits=6, meanQ=0.836683, numObservations: 4
action 3, numVisits=6, meanQ=0.166667, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.279526 0.120041 0.612297 0.806684 0.516189 0.836526 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=22412, meanQ=8.398109, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29042 episodes
GETTING ACTION FROM:
action 2, numVisits=22412, meanQ=8.398109, numObservations: 4
action 3, numVisits=200, meanQ=5.308299, numObservations: 5
action -1, numVisits=28844, meanQ=0.226161, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=2, meanQ=-133.568866, numObservations: 1
action: 2
Next state: 1 0.279526 0.120041 0.612297 0.806684 0.516189 0.836526 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 202
Initial state: 0 0.099368 0.142749 0.581641 0.845686 0.625126 0.88666 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162910 episodes
GETTING ACTION FROM:
action 1, numVisits=162829, meanQ=4.969851, numObservations: 4
action 0, numVisits=66, meanQ=4.120075, numObservations: 1
action 3, numVisits=11, meanQ=1.974545, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 1
Next state: 0 0.099368 0.142749 0.581641 0.845686 0.625126 0.88666 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26639, meanQ=8.320577, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7765 episodes
GETTING ACTION FROM:
action 2, numVisits=26639, meanQ=8.320577, numObservations: 4
action 0, numVisits=7748, meanQ=0.151729, numObservations: 1
action 3, numVisits=8, meanQ=-0.001250, numObservations: 4
action -1, numVisits=10, meanQ=-1.901000, numObservations: 1
action 1, numVisits=4, meanQ=-98.093854, numObservations: 3
action: 2
Next state: 1 0.099368 0.142749 0.581641 0.845686 0.625126 0.88666 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 203
Initial state: 0 0.593735 0.892781 0.575281 0.889243 0.746062 0.141735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95993 episodes
GETTING ACTION FROM:
action -1, numVisits=95986, meanQ=2.936876, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.593735 0.892781 0.575281 0.889243 0.746062 0.141735 w: 1
Observation: 0 0.65343 0 0.576509 0 0.787105 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=95961, meanQ=5.023034, numObservations: 4
action 3, numVisits=19, meanQ=2.042105, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 162952 episodes
GETTING ACTION FROM:
action 2, numVisits=258904, meanQ=5.114505, numObservations: 4
action 3, numVisits=19, meanQ=2.042105, numObservations: 4
action 1, numVisits=9, meanQ=0.998889, numObservations: 3
action -1, numVisits=3, meanQ=0.966700, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.593735 0.892781 0.575281 0.889243 0.746062 0.141735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 204
Initial state: 0 0.669202 0.818979 0.644483 0.81925 0.481905 0.175685 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95045 episodes
GETTING ACTION FROM:
action -1, numVisits=80602, meanQ=2.869115, numObservations: 1
action 0, numVisits=14428, meanQ=2.823091, numObservations: 1
action 3, numVisits=13, meanQ=0.768485, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.669202 0.818979 0.644483 0.81925 0.481905 0.175685 w: 1
Observation: 0 0.616679 0 0.583194 0 0.48053 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=80492, meanQ=4.953413, numObservations: 5
action 0, numVisits=78, meanQ=4.154668, numObservations: 1
action 3, numVisits=25, meanQ=3.401620, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 163592 episodes
GETTING ACTION FROM:
action 2, numVisits=244083, meanQ=5.028464, numObservations: 5
action 0, numVisits=79, meanQ=4.152982, numObservations: 1
action 3, numVisits=25, meanQ=3.401620, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.669202 0.818979 0.644483 0.81925 0.481905 0.175685 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 205
Initial state: 0 0.999258 0.388056 0.547347 0.851641 0.659921 0.854517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154072 episodes
GETTING ACTION FROM:
action 1, numVisits=153924, meanQ=4.860080, numObservations: 4
action 0, numVisits=41, meanQ=3.778139, numObservations: 1
action -1, numVisits=104, meanQ=3.382766, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.999258 0.388056 0.547347 0.851641 0.659921 0.854517 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 206
Initial state: 0 0.676334 0.852152 0.501449 0.899029 0.0973638 0.880607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162231 episodes
GETTING ACTION FROM:
action 1, numVisits=162200, meanQ=4.955921, numObservations: 5
action 0, numVisits=20, meanQ=3.362002, numObservations: 1
action 3, numVisits=5, meanQ=1.622000, numObservations: 3
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.676334 0.852152 0.501449 0.899029 0.0973638 0.880607 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 207
Initial state: 0 0.534746 0.858845 0.714888 0.712583 0.623889 0.807678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162328 episodes
GETTING ACTION FROM:
action 3, numVisits=162321, meanQ=4.974654, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.534746 0.858845 0.714888 0.712583 0.623889 0.807678 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 208
Initial state: 0 0.549912 0.884686 0.578827 0.86559 0.450493 0.300923 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158356 episodes
GETTING ACTION FROM:
action 2, numVisits=152001, meanQ=5.023561, numObservations: 3
action -1, numVisits=6330, meanQ=2.942224, numObservations: 1
action 3, numVisits=17, meanQ=1.471188, numObservations: 3
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.549912 0.884686 0.578827 0.86559 0.450493 0.300923 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 209
Initial state: 0 0.576786 0.854391 0.6951 0.850758 0.171437 0.726267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163266 episodes
GETTING ACTION FROM:
action 2, numVisits=163258, meanQ=5.014937, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=3, meanQ=-3.296667, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.576786 0.854391 0.6951 0.850758 0.171437 0.726267 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 210
Initial state: 0 0.515844 0.881449 0.573581 0.84795 0.734164 0.904748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162370 episodes
GETTING ACTION FROM:
action 1, numVisits=162342, meanQ=4.985781, numObservations: 4
action 0, numVisits=19, meanQ=3.390260, numObservations: 1
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.515844 0.881449 0.573581 0.84795 0.734164 0.904748 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 211
Initial state: 0 0.610441 0.894636 0.446646 0.970392 0.54347 0.858589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162544 episodes
GETTING ACTION FROM:
action 1, numVisits=162491, meanQ=4.951716, numObservations: 3
action 0, numVisits=47, meanQ=3.927855, numObservations: 1
action 2, numVisits=3, meanQ=0.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.610441 0.894636 0.446646 0.970392 0.54347 0.858589 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 212
Initial state: 0 0.561088 0.832742 0.525274 0.30076 0.568527 0.887438 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159917 episodes
GETTING ACTION FROM:
action 3, numVisits=159911, meanQ=4.951310, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.561088 0.832742 0.525274 0.30076 0.568527 0.887438 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 213
Initial state: 0 0.514472 0.811122 0.169653 0.225656 0.567623 0.874334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162160 episodes
GETTING ACTION FROM:
action 3, numVisits=162154, meanQ=5.013859, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.514472 0.811122 0.169653 0.225656 0.567623 0.874334 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 214
Initial state: 0 0.490467 0.757802 0.550686 0.869132 0.559685 0.803384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162438 episodes
GETTING ACTION FROM:
action 2, numVisits=162172, meanQ=4.989051, numObservations: 4
action 0, numVisits=105, meanQ=4.319728, numObservations: 1
action -1, numVisits=151, meanQ=3.895023, numObservations: 1
action 1, numVisits=6, meanQ=1.333333, numObservations: 3
action 3, numVisits=4, meanQ=0.750000, numObservations: 3
action: 2
Next state: 1 0.490467 0.757802 0.550686 0.869132 0.559685 0.803384 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 215
Initial state: 0 0.539648 0.832975 0.997892 0.231653 0.582814 0.896059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95612 episodes
GETTING ACTION FROM:
action -1, numVisits=95605, meanQ=2.920015, numObservations: 1
action 0, numVisits=4, meanQ=-2.502425, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.539648 0.832975 0.997892 0.231653 0.582814 0.896059 w: 1
Observation: 0 0.592897 0 1 0 0.644334 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=95568, meanQ=4.950745, numObservations: 5
action -1, numVisits=28, meanQ=3.633713, numObservations: 1
action 1, numVisits=5, meanQ=-0.201980, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 162861 episodes
GETTING ACTION FROM:
action 3, numVisits=258428, meanQ=4.834430, numObservations: 5
action -1, numVisits=29, meanQ=3.500861, numObservations: 1
action 1, numVisits=5, meanQ=-0.201980, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.539648 0.832975 0.997892 0.231653 0.582814 0.896059 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 216
Initial state: 0 0.677234 0.863454 0.514558 0.830615 0.967127 0.266717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95728 episodes
GETTING ACTION FROM:
action -1, numVisits=94519, meanQ=2.869385, numObservations: 1
action 0, numVisits=1204, meanQ=2.618225, numObservations: 1
action 3, numVisits=3, meanQ=-3.363333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.677234 0.863454 0.514558 0.830615 0.967127 0.266717 w: 1
Observation: 0 0.618972 0 0.50594 0 0.910966 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=94443, meanQ=4.950948, numObservations: 5
action -1, numVisits=34, meanQ=3.738695, numObservations: 1
action 0, numVisits=19, meanQ=3.201410, numObservations: 1
action 2, numVisits=17, meanQ=3.106471, numObservations: 4
action 3, numVisits=5, meanQ=1.794000, numObservations: 3
Sampled 161818 episodes
GETTING ACTION FROM:
action 1, numVisits=256220, meanQ=4.809747, numObservations: 5
action -1, numVisits=37, meanQ=3.649946, numObservations: 1
action 3, numVisits=43, meanQ=3.587681, numObservations: 5
action 0, numVisits=19, meanQ=3.201410, numObservations: 1
action 2, numVisits=17, meanQ=3.106471, numObservations: 4
action: 1
Next state: 1 0.677234 0.863454 0.514558 0.830615 0.967127 0.266717 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 217
Initial state: 0 0.637514 0.836967 0.507002 0.873277 0.223393 0.688638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162149 episodes
GETTING ACTION FROM:
action 2, numVisits=161875, meanQ=4.909028, numObservations: 5
action 1, numVisits=234, meanQ=4.444915, numObservations: 5
action 0, numVisits=37, meanQ=3.768869, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.637514 0.836967 0.507002 0.873277 0.223393 0.688638 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 218
Initial state: 0 0.0797431 0.136883 0.696539 0.856412 0.637455 0.817481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163357 episodes
GETTING ACTION FROM:
action 1, numVisits=163338, meanQ=4.953678, numObservations: 4
action 2, numVisits=13, meanQ=-1.383831, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 1
Next state: 0 0.0797431 0.136883 0.696539 0.856412 0.637455 0.817481 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26789, meanQ=8.278575, numObservations: 4
action 3, numVisits=5, meanQ=5.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7046 episodes
GETTING ACTION FROM:
action 2, numVisits=26830, meanQ=8.272792, numObservations: 4
action 3, numVisits=590, meanQ=5.679832, numObservations: 3
action -1, numVisits=6416, meanQ=0.046192, numObservations: 1
action 1, numVisits=4, meanQ=-4.002500, numObservations: 3
action 0, numVisits=3, meanQ=-131.424408, numObservations: 1
action: 2
Next state: 1 0.0797431 0.136883 0.696539 0.856412 0.637455 0.817481 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 219
Initial state: 0 0.623787 0.884982 0.916125 0.470631 0.613606 0.897861 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162410 episodes
GETTING ACTION FROM:
action 3, numVisits=162313, meanQ=5.000356, numObservations: 5
action 0, numVisits=91, meanQ=4.251555, numObservations: 1
action 2, numVisits=3, meanQ=0.000033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.623787 0.884982 0.916125 0.470631 0.613606 0.897861 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 220
Initial state: 0 0.657254 0.875515 0.314391 0.235116 0.597888 0.891869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161792 episodes
GETTING ACTION FROM:
action 3, numVisits=161655, meanQ=4.945511, numObservations: 4
action -1, numVisits=83, meanQ=4.186900, numObservations: 1
action 0, numVisits=50, meanQ=3.975180, numObservations: 1
action 1, numVisits=3, meanQ=0.000033, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.657254 0.875515 0.314391 0.235116 0.597888 0.891869 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 221
Initial state: 0 0.668476 0.735134 0.677931 0.833918 0.698817 0.871386 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162819 episodes
GETTING ACTION FROM:
action 3, numVisits=162813, meanQ=4.956769, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.668476 0.735134 0.677931 0.833918 0.698817 0.871386 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 222
Initial state: 0 0.669401 0.891274 0.0220063 0.849165 0.55415 0.85465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157110 episodes
GETTING ACTION FROM:
action 2, numVisits=157073, meanQ=4.858856, numObservations: 5
action 0, numVisits=13, meanQ=2.491813, numObservations: 1
action 1, numVisits=21, meanQ=2.000005, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.669401 0.891274 0.0220063 0.849165 0.55415 0.85465 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3860, meanQ=7.745717, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12904 episodes
GETTING ACTION FROM:
action 3, numVisits=3860, meanQ=7.745717, numObservations: 3
action 1, numVisits=37, meanQ=4.781081, numObservations: 3
action -1, numVisits=12866, meanQ=0.015319, numObservations: 1
action 0, numVisits=3, meanQ=-4.659443, numObservations: 1
action 2, numVisits=2, meanQ=-11.000000, numObservations: 2
action: 3
Next state: 1 0.669401 0.891274 0.0220063 0.849165 0.55415 0.85465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 223
Initial state: 0 0.685609 0.205681 0.661934 0.848319 0.505869 0.85803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163259 episodes
GETTING ACTION FROM:
action 2, numVisits=163118, meanQ=5.046212, numObservations: 3
action 0, numVisits=70, meanQ=4.227008, numObservations: 1
action -1, numVisits=60, meanQ=4.165442, numObservations: 1
action 1, numVisits=10, meanQ=0.901010, numObservations: 4
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.685609 0.205681 0.661934 0.848319 0.505869 0.85803 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 224
Initial state: 0 0.517755 0.828328 0.663183 0.837421 0.168627 0.733394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161870 episodes
GETTING ACTION FROM:
action 2, numVisits=161863, meanQ=5.038068, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.517755 0.828328 0.663183 0.837421 0.168627 0.733394 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 225
Initial state: 0 0.602034 0.834136 0.677447 0.861386 0.267286 0.000413726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162280 episodes
GETTING ACTION FROM:
action 3, numVisits=162274, meanQ=4.975572, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.602034 0.834136 0.677447 0.861386 0.267286 0.000413726 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=22757, meanQ=8.431897, numObservations: 4
action 2, numVisits=4, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11973 episodes
GETTING ACTION FROM:
action 1, numVisits=22757, meanQ=8.431897, numObservations: 4
action 2, numVisits=35, meanQ=6.214296, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=11933, meanQ=0.219930, numObservations: 1
action 0, numVisits=10, meanQ=-1.901000, numObservations: 1
action: 1
Next state: 1 0.602034 0.834136 0.677447 0.861386 0.267286 0.000413726 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 226
Initial state: 0 0.664001 0.840796 0.828037 0.509064 0.6736 0.891687 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161840 episodes
GETTING ACTION FROM:
action 3, numVisits=161706, meanQ=4.952916, numObservations: 4
action 1, numVisits=102, meanQ=4.276392, numObservations: 4
action -1, numVisits=28, meanQ=3.604023, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 3
Next state: 1 0.664001 0.840796 0.828037 0.509064 0.6736 0.891687 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 227
Initial state: 0 0.43132 0.825721 0.679021 0.855427 0.56936 0.807707 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160888 episodes
GETTING ACTION FROM:
action 3, numVisits=160837, meanQ=5.012790, numObservations: 5
action -1, numVisits=47, meanQ=4.003820, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.43132 0.825721 0.679021 0.855427 0.56936 0.807707 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 228
Initial state: 0 0.59419 0.810319 0.222403 0.691362 0.617183 0.817741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161421 episodes
GETTING ACTION FROM:
action 1, numVisits=161183, meanQ=4.953332, numObservations: 5
action 3, numVisits=190, meanQ=4.441824, numObservations: 4
action -1, numVisits=36, meanQ=3.726696, numObservations: 1
action 2, numVisits=10, meanQ=2.090000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.59419 0.810319 0.222403 0.691362 0.617183 0.817741 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 229
Initial state: 0 0.614777 0.843635 0.618757 0.885228 0.0595024 0.376239 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162852 episodes
GETTING ACTION FROM:
action 1, numVisits=162820, meanQ=5.012670, numObservations: 4
action -1, numVisits=14, meanQ=3.119481, numObservations: 1
action 3, numVisits=10, meanQ=2.499000, numObservations: 4
action 2, numVisits=6, meanQ=1.166683, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.614777 0.843635 0.618757 0.885228 0.0595024 0.376239 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 230
Initial state: 0 0.330556 0.376099 0.551482 0.89553 0.550534 0.882215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155688 episodes
GETTING ACTION FROM:
action 3, numVisits=155604, meanQ=4.996510, numObservations: 5
action -1, numVisits=59, meanQ=4.084165, numObservations: 1
action 0, numVisits=19, meanQ=3.197321, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 3
Next state: 1 0.330556 0.376099 0.551482 0.89553 0.550534 0.882215 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 231
Initial state: 0 0.674155 0.858841 0.506065 0.0823337 0.512626 0.848055 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161594 episodes
GETTING ACTION FROM:
action 1, numVisits=161119, meanQ=5.003668, numObservations: 4
action -1, numVisits=367, meanQ=2.940994, numObservations: 1
action 0, numVisits=101, meanQ=2.698592, numObservations: 1
action 2, numVisits=5, meanQ=-0.002000, numObservations: 3
action 3, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 1
Next state: 1 0.674155 0.858841 0.506065 0.0823337 0.512626 0.848055 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 232
Initial state: 0 0.603015 0.857718 0.533526 0.816362 0.265678 0.297191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155024 episodes
GETTING ACTION FROM:
action 3, numVisits=155014, meanQ=4.881479, numObservations: 5
action 2, numVisits=4, meanQ=-0.999975, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 3
Next state: 0 0.603015 0.857718 0.533526 0.816362 0.265678 0.297191 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=21831, meanQ=8.391777, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6253 episodes
GETTING ACTION FROM:
action 1, numVisits=21831, meanQ=8.391777, numObservations: 4
action 2, numVisits=83, meanQ=6.442270, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=6100, meanQ=0.475974, numObservations: 1
action 0, numVisits=73, meanQ=-0.215139, numObservations: 1
action: 1
Next state: 1 0.603015 0.857718 0.533526 0.816362 0.265678 0.297191 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 233
Initial state: 0 0.699204 0.875044 0.61121 0.862675 0.365283 0.0629845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163286 episodes
GETTING ACTION FROM:
action 1, numVisits=163237, meanQ=4.997880, numObservations: 4
action -1, numVisits=37, meanQ=3.865039, numObservations: 1
action 2, numVisits=9, meanQ=2.223344, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.699204 0.875044 0.61121 0.862675 0.365283 0.0629845 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 234
Initial state: 0 0.592898 0.874619 0.0798959 0.15092 0.615567 0.873103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162373 episodes
GETTING ACTION FROM:
action 3, numVisits=162366, meanQ=5.006180, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.592898 0.874619 0.0798959 0.15092 0.615567 0.873103 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 235
Initial state: 0 0.650911 0.887456 0.394078 0.156925 0.535683 0.817192 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162988 episodes
GETTING ACTION FROM:
action 2, numVisits=162929, meanQ=5.003282, numObservations: 4
action 0, numVisits=47, meanQ=3.967753, numObservations: 1
action 3, numVisits=4, meanQ=0.750000, numObservations: 3
action 1, numVisits=6, meanQ=-0.481667, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.650911 0.887456 0.394078 0.156925 0.535683 0.817192 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8071, meanQ=7.822277, numObservations: 3
action 1, numVisits=10, meanQ=5.799000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 19459 episodes
GETTING ACTION FROM:
action 3, numVisits=8071, meanQ=7.822277, numObservations: 3
action 1, numVisits=10, meanQ=5.799000, numObservations: 3
action 0, numVisits=19450, meanQ=0.131579, numObservations: 1
action -1, numVisits=10, meanQ=-1.901000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 3
Next state: 1 0.650911 0.887456 0.394078 0.156925 0.535683 0.817192 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 236
Initial state: 0 0.559592 0.834004 0.421698 0.514423 0.539634 0.896111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161323 episodes
GETTING ACTION FROM:
action 1, numVisits=161297, meanQ=5.156621, numObservations: 4
action 0, numVisits=18, meanQ=3.481167, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.559592 0.834004 0.421698 0.514423 0.539634 0.896111 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 237
Initial state: 0 0.537495 0.974681 0.639549 0.844951 0.583488 0.847495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162602 episodes
GETTING ACTION FROM:
action 2, numVisits=162590, meanQ=4.937778, numObservations: 4
action 1, numVisits=7, meanQ=1.428571, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.537495 0.974681 0.639549 0.844951 0.583488 0.847495 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9970, meanQ=3.993325, numObservations: 4
action -1, numVisits=32, meanQ=2.261003, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 202107 episodes
GETTING ACTION FROM:
action 1, numVisits=202027, meanQ=5.993785, numObservations: 4
action 2, numVisits=81, meanQ=4.786917, numObservations: 4
action 3, numVisits=9970, meanQ=3.993325, numObservations: 4
action -1, numVisits=34, meanQ=2.103366, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.537495 0.974681 0.639549 0.844951 0.583488 0.847495 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 238
Initial state: 0 0.569403 0.860332 0.143902 0.198713 0.524504 0.825713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163407 episodes
GETTING ACTION FROM:
action 2, numVisits=163228, meanQ=5.007811, numObservations: 4
action -1, numVisits=111, meanQ=4.358798, numObservations: 1
action 0, numVisits=66, meanQ=4.148245, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.569403 0.860332 0.143902 0.198713 0.524504 0.825713 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 239
Initial state: 0 0.559364 0.154227 0.556507 0.8284 0.615352 0.87369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162769 episodes
GETTING ACTION FROM:
action 1, numVisits=162200, meanQ=4.974903, numObservations: 4
action 2, numVisits=384, meanQ=4.603235, numObservations: 4
action 0, numVisits=131, meanQ=4.353590, numObservations: 1
action 3, numVisits=52, meanQ=3.926927, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.559364 0.154227 0.556507 0.8284 0.615352 0.87369 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=26782, meanQ=8.313651, numObservations: 5
action 2, numVisits=25, meanQ=6.998804, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 5802 episodes
GETTING ACTION FROM:
action 3, numVisits=26782, meanQ=8.313651, numObservations: 5
action 2, numVisits=94, meanQ=6.935106, numObservations: 4
action -1, numVisits=5724, meanQ=0.145173, numObservations: 1
action 0, numVisits=9, meanQ=-2.112200, numObservations: 1
action 1, numVisits=3, meanQ=-6.336633, numObservations: 2
action: 3
Next state: 1 0.559364 0.154227 0.556507 0.8284 0.615352 0.87369 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 240
Initial state: 0 0.532204 0.810086 0.661706 0.686165 0.554747 0.842325 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162601 episodes
GETTING ACTION FROM:
action 2, numVisits=162575, meanQ=5.006839, numObservations: 5
action -1, numVisits=19, meanQ=3.281934, numObservations: 1
action 1, numVisits=3, meanQ=0.000033, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.532204 0.810086 0.661706 0.686165 0.554747 0.842325 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 241
Initial state: 0 0.15164 0.274187 0.546891 0.875031 0.544741 0.881546 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162101 episodes
GETTING ACTION FROM:
action 3, numVisits=135422, meanQ=4.976934, numObservations: 5
action 1, numVisits=26660, meanQ=4.930863, numObservations: 4
action 2, numVisits=15, meanQ=3.060000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.15164 0.274187 0.546891 0.875031 0.544741 0.881546 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 242
Initial state: 0 0.346505 0.301868 0.625512 0.891071 0.611311 0.819711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161060 episodes
GETTING ACTION FROM:
action 2, numVisits=161036, meanQ=5.141351, numObservations: 4
action 1, numVisits=17, meanQ=3.037059, numObservations: 3
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.346505 0.301868 0.625512 0.891071 0.611311 0.819711 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10532, meanQ=7.462313, numObservations: 3
action 3, numVisits=4, meanQ=4.000000, numObservations: 2
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 196506 episodes
GETTING ACTION FROM:
action 1, numVisits=149815, meanQ=5.726425, numObservations: 4
action 2, numVisits=57201, meanQ=5.626609, numObservations: 4
action 3, numVisits=24, meanQ=3.708338, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 1
Next state: 0 0.346505 0.301868 0.625512 0.891071 0.611311 0.819711 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=2468, meanQ=8.278199, numObservations: 3
action 3, numVisits=9, meanQ=5.890011, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 18958 episodes
GETTING ACTION FROM:
action 2, numVisits=2468, meanQ=8.278199, numObservations: 3
action 3, numVisits=75, meanQ=5.160135, numObservations: 4
action 0, numVisits=16106, meanQ=-1.622220, numObservations: 1
action -1, numVisits=2787, meanQ=-1.693093, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 2
Next state: 1 0.346505 0.301868 0.625512 0.891071 0.611311 0.819711 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 243
Initial state: 0 0.21236 0.0880939 0.644538 0.860274 0.540293 0.823289 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163234 episodes
GETTING ACTION FROM:
action 1, numVisits=163226, meanQ=5.032717, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 1
Next state: 2 0.21236 0.0880939 0.644538 0.860274 0.540293 0.823289 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 244
Initial state: 0 0.582231 0.869957 0.39255 0.990336 0.667615 0.830745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160709 episodes
GETTING ACTION FROM:
action 2, numVisits=160670, meanQ=4.923115, numObservations: 4
action 0, numVisits=35, meanQ=3.735708, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.582231 0.869957 0.39255 0.990336 0.667615 0.830745 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8129, meanQ=7.789883, numObservations: 4
action 3, numVisits=167, meanQ=7.303103, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8515 episodes
GETTING ACTION FROM:
action 1, numVisits=8129, meanQ=7.789883, numObservations: 4
action 3, numVisits=206, meanQ=7.014285, numObservations: 4
action 0, numVisits=8457, meanQ=0.337978, numObservations: 1
action -1, numVisits=20, meanQ=-1.059500, numObservations: 1
action 2, numVisits=2, meanQ=-11.000000, numObservations: 2
action: 1
Next state: 1 0.582231 0.869957 0.39255 0.990336 0.667615 0.830745 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 245
Initial state: 0 0.655208 0.890359 0.535906 0.81311 0.238561 0.72331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156979 episodes
GETTING ACTION FROM:
action 1, numVisits=156965, meanQ=4.897866, numObservations: 5
action 2, numVisits=7, meanQ=1.428571, numObservations: 3
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.655208 0.890359 0.535906 0.81311 0.238561 0.72331 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 246
Initial state: 0 0.610558 0.814694 0.575081 0.859212 0.876943 0.465942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162395 episodes
GETTING ACTION FROM:
action 3, numVisits=162319, meanQ=4.957656, numObservations: 5
action 2, numVisits=65, meanQ=3.899540, numObservations: 4
action 1, numVisits=7, meanQ=2.285729, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.610558 0.814694 0.575081 0.859212 0.876943 0.465942 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 247
Initial state: 0 0.407008 0.818075 0.535802 0.828864 0.609747 0.859395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162764 episodes
GETTING ACTION FROM:
action 2, numVisits=162721, meanQ=5.017339, numObservations: 5
action 0, numVisits=30, meanQ=3.617329, numObservations: 1
action 3, numVisits=10, meanQ=2.300010, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.407008 0.818075 0.535802 0.828864 0.609747 0.859395 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 248
Initial state: 0 0.0960032 0.806892 0.675614 0.831073 0.644305 0.840115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162231 episodes
GETTING ACTION FROM:
action 2, numVisits=162163, meanQ=4.949623, numObservations: 4
action 0, numVisits=58, meanQ=4.036611, numObservations: 1
action 3, numVisits=6, meanQ=1.836700, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 2
Next state: 1 0.0960032 0.806892 0.675614 0.831073 0.644305 0.840115 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 249
Initial state: 0 0.611186 0.807254 0.781161 0.59504 0.659427 0.81711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153258 episodes
GETTING ACTION FROM:
action 2, numVisits=150967, meanQ=4.864535, numObservations: 5
action -1, numVisits=2286, meanQ=2.817472, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.611186 0.807254 0.781161 0.59504 0.659427 0.81711 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 250
Initial state: 0 0.52004 0.662674 0.500419 0.888242 0.606043 0.815396 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157992 episodes
GETTING ACTION FROM:
action 1, numVisits=157974, meanQ=4.863397, numObservations: 4
action 3, numVisits=13, meanQ=2.922315, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.52004 0.662674 0.500419 0.888242 0.606043 0.815396 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 251
Initial state: 0 0.0484425 0.916113 0.639919 0.878553 0.528983 0.825327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162634 episodes
GETTING ACTION FROM:
action 3, numVisits=162624, meanQ=5.032768, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.0484425 0.916113 0.639919 0.878553 0.528983 0.825327 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 252
Initial state: 0 0.456229 0.541864 0.608753 0.892309 0.612841 0.84827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162923 episodes
GETTING ACTION FROM:
action 2, numVisits=162914, meanQ=5.035263, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.456229 0.541864 0.608753 0.892309 0.612841 0.84827 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 253
Initial state: 0 0.648953 0.865691 0.484747 0.915383 0.600142 0.891982 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161372 episodes
GETTING ACTION FROM:
action 3, numVisits=160290, meanQ=4.977929, numObservations: 4
action -1, numVisits=914, meanQ=2.850268, numObservations: 1
action 0, numVisits=162, meanQ=2.608862, numObservations: 1
action 1, numVisits=4, meanQ=-2.500000, numObservations: 2
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 3
Next state: 1 0.648953 0.865691 0.484747 0.915383 0.600142 0.891982 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 254
Initial state: 0 0.594881 0.810527 0.373686 0.371222 0.599845 0.873115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161701 episodes
GETTING ACTION FROM:
action 2, numVisits=161648, meanQ=4.982792, numObservations: 5
action 0, numVisits=28, meanQ=3.645950, numObservations: 1
action 1, numVisits=16, meanQ=3.001263, numObservations: 4
action 3, numVisits=7, meanQ=2.285729, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.594881 0.810527 0.373686 0.371222 0.599845 0.873115 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 255
Initial state: 0 0.262698 0.537961 0.680285 0.831607 0.607489 0.817896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162067 episodes
GETTING ACTION FROM:
action 3, numVisits=161851, meanQ=4.990180, numObservations: 4
action -1, numVisits=208, meanQ=3.490944, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 3
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.262698 0.537961 0.680285 0.831607 0.607489 0.817896 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 256
Initial state: 0 0.266876 0.21383 0.644531 0.895272 0.540743 0.819182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162853 episodes
GETTING ACTION FROM:
action 2, numVisits=162819, meanQ=5.045655, numObservations: 3
action 1, numVisits=29, meanQ=3.269310, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.266876 0.21383 0.644531 0.895272 0.540743 0.819182 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 257
Initial state: 0 0.164792 0.398978 0.550139 0.878476 0.640802 0.827583 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161953 episodes
GETTING ACTION FROM:
action 3, numVisits=161914, meanQ=4.918489, numObservations: 4
action -1, numVisits=32, meanQ=3.682272, numObservations: 1
action 2, numVisits=4, meanQ=-0.272500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.164792 0.398978 0.550139 0.878476 0.640802 0.827583 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 258
Initial state: 0 0.218861 0.817863 0.542547 0.84691 0.666645 0.89732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162877 episodes
GETTING ACTION FROM:
action 1, numVisits=162864, meanQ=5.170909, numObservations: 4
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.218861 0.817863 0.542547 0.84691 0.666645 0.89732 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5290, meanQ=7.901550, numObservations: 4
action 2, numVisits=17, meanQ=6.181765, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12719 episodes
GETTING ACTION FROM:
action 3, numVisits=6716, meanQ=7.492054, numObservations: 4
action 2, numVisits=55, meanQ=4.781818, numObservations: 5
action 1, numVisits=5, meanQ=3.798020, numObservations: 3
action -1, numVisits=9983, meanQ=-0.321132, numObservations: 1
action 0, numVisits=1270, meanQ=-0.481162, numObservations: 2
action: 3
Next state: 1 0.218861 0.817863 0.542547 0.84691 0.666645 0.89732 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 259
Initial state: 0 0.57062 0.830545 0.922368 0.264289 0.638832 0.82752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161098 episodes
GETTING ACTION FROM:
action 3, numVisits=161026, meanQ=4.998596, numObservations: 5
action -1, numVisits=48, meanQ=3.812308, numObservations: 1
action 0, numVisits=13, meanQ=3.033771, numObservations: 1
action 2, numVisits=8, meanQ=1.113750, numObservations: 4
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action: 3
Next state: 1 0.57062 0.830545 0.922368 0.264289 0.638832 0.82752 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 260
Initial state: 0 0.769729 0.174224 0.528353 0.840095 0.611915 0.876464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154469 episodes
GETTING ACTION FROM:
action 3, numVisits=154459, meanQ=4.908617, numObservations: 3
action 1, numVisits=5, meanQ=-0.795980, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.769729 0.174224 0.528353 0.840095 0.611915 0.876464 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=11542, meanQ=3.533631, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 182385 episodes
GETTING ACTION FROM:
action 3, numVisits=182379, meanQ=5.108749, numObservations: 4
action -1, numVisits=11544, meanQ=3.533147, numObservations: 1
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.769729 0.174224 0.528353 0.840095 0.611915 0.876464 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 261
Initial state: 0 0.537455 0.831628 0.589679 0.846201 0.700737 0.502552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155025 episodes
GETTING ACTION FROM:
action 3, numVisits=154859, meanQ=4.813085, numObservations: 4
action -1, numVisits=157, meanQ=4.256915, numObservations: 1
action 1, numVisits=6, meanQ=1.498333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.537455 0.831628 0.589679 0.846201 0.700737 0.502552 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 262
Initial state: 0 0.924221 0.093501 0.674784 0.899212 0.547211 0.858202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155149 episodes
GETTING ACTION FROM:
action 3, numVisits=155018, meanQ=4.832261, numObservations: 4
action 0, numVisits=68, meanQ=4.006247, numObservations: 1
action 2, numVisits=41, meanQ=3.551959, numObservations: 3
action -1, numVisits=21, meanQ=3.133527, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.924221 0.093501 0.674784 0.899212 0.547211 0.858202 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 263
Initial state: 0 0.0413517 0.195772 0.530394 0.829606 0.681857 0.838929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163042 episodes
GETTING ACTION FROM:
action 1, numVisits=163012, meanQ=4.948073, numObservations: 4
action -1, numVisits=26, meanQ=3.600335, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0413517 0.195772 0.530394 0.829606 0.681857 0.838929 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=26990, meanQ=8.294546, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6016 episodes
GETTING ACTION FROM:
action 3, numVisits=26990, meanQ=8.294546, numObservations: 4
action 2, numVisits=123, meanQ=5.841639, numObservations: 5
action 1, numVisits=11, meanQ=4.271818, numObservations: 4
action -1, numVisits=5884, meanQ=0.301358, numObservations: 1
action 0, numVisits=3, meanQ=-132.088089, numObservations: 1
action: 3
Next state: 1 0.0413517 0.195772 0.530394 0.829606 0.681857 0.838929 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 264
Initial state: 0 0.657686 0.58363 0.611854 0.861094 0.518797 0.871909 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161882 episodes
GETTING ACTION FROM:
action 3, numVisits=161800, meanQ=4.950875, numObservations: 5
action 0, numVisits=55, meanQ=4.017649, numObservations: 1
action -1, numVisits=25, meanQ=3.549700, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.657686 0.58363 0.611854 0.861094 0.518797 0.871909 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 265
Initial state: 0 0.682696 0.822504 0.108425 0.192147 0.536245 0.812842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162204 episodes
GETTING ACTION FROM:
action 3, numVisits=162083, meanQ=5.139689, numObservations: 4
action 1, numVisits=103, meanQ=3.723013, numObservations: 4
action -1, numVisits=15, meanQ=3.015291, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.682696 0.822504 0.108425 0.192147 0.536245 0.812842 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 266
Initial state: 0 0.677463 0.823695 0.510693 0.801065 0.182196 0.653038 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162577 episodes
GETTING ACTION FROM:
action 2, numVisits=84846, meanQ=4.974681, numObservations: 5
action 1, numVisits=77686, meanQ=4.960620, numObservations: 5
action 0, numVisits=23, meanQ=3.427903, numObservations: 1
action 3, numVisits=20, meanQ=3.399505, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.677463 0.823695 0.510693 0.801065 0.182196 0.653038 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 267
Initial state: 0 0.547875 0.887509 0.873663 0.956025 0.634426 0.859635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95491 episodes
GETTING ACTION FROM:
action -1, numVisits=95477, meanQ=2.911812, numObservations: 1
action 3, numVisits=5, meanQ=-0.795980, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action: -1
Next state: 0 0.547875 0.887509 0.873663 0.956025 0.634426 0.859635 w: 1
Observation: 0 0.60651 0 0.931102 0 0.586717 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=95467, meanQ=4.943540, numObservations: 4
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 161878 episodes
GETTING ACTION FROM:
action 2, numVisits=257340, meanQ=5.172319, numObservations: 4
action 1, numVisits=6, meanQ=0.981667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=4, meanQ=-2.500000, numObservations: 2
action: 2
Next state: 1 0.547875 0.887509 0.873663 0.956025 0.634426 0.859635 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 268
Initial state: 0 0.627532 0.628047 0.662454 0.843587 0.592067 0.881049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96094 episodes
GETTING ACTION FROM:
action -1, numVisits=96085, meanQ=2.909345, numObservations: 1
action 2, numVisits=5, meanQ=-0.200000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.627532 0.628047 0.662454 0.843587 0.592067 0.881049 w: 1
Observation: 0 0.617205 0 0.75126 0 0.655821 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=95951, meanQ=4.990460, numObservations: 4
action -1, numVisits=90, meanQ=4.267823, numObservations: 1
action 1, numVisits=40, meanQ=3.695003, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 163808 episodes
GETTING ACTION FROM:
action 2, numVisits=259684, meanQ=4.776987, numObservations: 4
action -1, numVisits=162, meanQ=4.232572, numObservations: 1
action 1, numVisits=42, meanQ=3.516910, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 2
Next state: 1 0.627532 0.628047 0.662454 0.843587 0.592067 0.881049 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 269
Initial state: 0 0.232104 0.805127 0.671518 0.861792 0.692307 0.825387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162448 episodes
GETTING ACTION FROM:
action 1, numVisits=162391, meanQ=5.019063, numObservations: 5
action -1, numVisits=44, meanQ=3.987005, numObservations: 1
action 2, numVisits=10, meanQ=2.090000, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.232104 0.805127 0.671518 0.861792 0.692307 0.825387 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 270
Initial state: 0 0.751042 0.697345 0.536129 0.874412 0.591656 0.855195 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164244 episodes
GETTING ACTION FROM:
action 2, numVisits=164195, meanQ=5.055662, numObservations: 4
action 1, numVisits=44, meanQ=3.830461, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.751042 0.697345 0.536129 0.874412 0.591656 0.855195 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 271
Initial state: 0 0.539936 0.889354 0.593596 0.874375 0.0149365 0.214421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162577 episodes
GETTING ACTION FROM:
action 3, numVisits=162557, meanQ=4.987687, numObservations: 3
action 1, numVisits=14, meanQ=1.579293, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.539936 0.889354 0.593596 0.874375 0.0149365 0.214421 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26469, meanQ=8.308427, numObservations: 5
action 1, numVisits=44, meanQ=7.353184, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 13797 episodes
GETTING ACTION FROM:
action 2, numVisits=26469, meanQ=8.308427, numObservations: 5
action 1, numVisits=47, meanQ=7.032768, numObservations: 3
action 0, numVisits=7026, meanQ=0.237149, numObservations: 3
action -1, numVisits=6762, meanQ=0.141340, numObservations: 1
action 3, numVisits=9, meanQ=-38.604331, numObservations: 4
action: 2
Next state: 1 0.539936 0.889354 0.593596 0.874375 0.0149365 0.214421 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 272
Initial state: 0 0.500622 0.878103 0.309981 0.0272231 0.661311 0.842626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161928 episodes
GETTING ACTION FROM:
action 1, numVisits=161917, meanQ=5.022414, numObservations: 5
action 2, numVisits=6, meanQ=1.166683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.500622 0.878103 0.309981 0.0272231 0.661311 0.842626 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 273
Initial state: 0 0.518889 0.891145 0.852917 0.12753 0.680353 0.84479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163008 episodes
GETTING ACTION FROM:
action 1, numVisits=163002, meanQ=5.057340, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.518889 0.891145 0.852917 0.12753 0.680353 0.84479 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 274
Initial state: 0 0.571074 0.86981 0.470267 0.0282276 0.644153 0.87945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163275 episodes
GETTING ACTION FROM:
action 1, numVisits=163268, meanQ=5.000454, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.499950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.571074 0.86981 0.470267 0.0282276 0.644153 0.87945 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 275
Initial state: 0 0.606552 0.881443 0.598064 0.852504 0.233948 0.718644 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96069 episodes
GETTING ACTION FROM:
action -1, numVisits=96052, meanQ=3.021530, numObservations: 1
action 3, numVisits=6, meanQ=0.165033, numObservations: 2
action 2, numVisits=8, meanQ=-0.752487, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.606552 0.881443 0.598064 0.852504 0.233948 0.718644 w: 1
Observation: 0 0.567421 0 0.526462 0 0.279125 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=95998, meanQ=5.043177, numObservations: 3
action 1, numVisits=28, meanQ=3.705011, numObservations: 4
action 3, numVisits=21, meanQ=2.987152, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 163014 episodes
GETTING ACTION FROM:
action 2, numVisits=259010, meanQ=4.834417, numObservations: 3
action 1, numVisits=29, meanQ=3.473459, numObservations: 4
action 3, numVisits=21, meanQ=2.987152, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action: 2
Next state: 1 0.606552 0.881443 0.598064 0.852504 0.233948 0.718644 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 276
Initial state: 0 0.671839 0.823097 0.61404 0.856676 0.980972 0.307576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162584 episodes
GETTING ACTION FROM:
action 1, numVisits=162559, meanQ=4.947029, numObservations: 3
action 0, numVisits=19, meanQ=3.191129, numObservations: 1
action 3, numVisits=3, meanQ=0.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.671839 0.823097 0.61404 0.856676 0.980972 0.307576 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 277
Initial state: 0 0.166442 0.966129 0.594012 0.885679 0.689053 0.830226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162154 episodes
GETTING ACTION FROM:
action 3, numVisits=162108, meanQ=4.949718, numObservations: 3
action 0, numVisits=30, meanQ=3.689280, numObservations: 1
action 2, numVisits=10, meanQ=1.700000, numObservations: 2
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.166442 0.966129 0.594012 0.885679 0.689053 0.830226 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.31502 0.30621 0.513612 0.825367 0.656118 0.896393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161376 episodes
GETTING ACTION FROM:
action 3, numVisits=161369, meanQ=5.014076, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.31502 0.30621 0.513612 0.825367 0.656118 0.896393 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 279
Initial state: 0 0.642175 0.837332 0.603202 0.804671 0.909466 0.564665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161881 episodes
GETTING ACTION FROM:
action 3, numVisits=161873, meanQ=4.922431, numObservations: 5
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.642175 0.837332 0.603202 0.804671 0.909466 0.564665 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 280
Initial state: 0 0.158652 0.412198 0.538739 0.824708 0.516674 0.804132 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158891 episodes
GETTING ACTION FROM:
action 3, numVisits=158862, meanQ=4.869168, numObservations: 5
action -1, numVisits=23, meanQ=3.426784, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.158652 0.412198 0.538739 0.824708 0.516674 0.804132 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 281
Initial state: 0 0.606074 0.827964 0.684198 0.863934 0.141444 0.00286261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163418 episodes
GETTING ACTION FROM:
action 1, numVisits=163380, meanQ=4.984009, numObservations: 4
action -1, numVisits=29, meanQ=3.709438, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.606074 0.827964 0.684198 0.863934 0.141444 0.00286261 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 282
Initial state: 0 0.635696 0.813801 0.133372 0.100955 0.593847 0.875475 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162111 episodes
GETTING ACTION FROM:
action 3, numVisits=162099, meanQ=4.961760, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.635696 0.813801 0.133372 0.100955 0.593847 0.875475 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 283
Initial state: 0 0.665432 0.853079 0.151701 0.485822 0.600855 0.853184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161711 episodes
GETTING ACTION FROM:
action 3, numVisits=161676, meanQ=4.978512, numObservations: 4
action 1, numVisits=30, meanQ=3.265680, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.665432 0.853079 0.151701 0.485822 0.600855 0.853184 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=12001, meanQ=5.520357, numObservations: 4
action 1, numVisits=12, meanQ=2.999167, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 197254 episodes
GETTING ACTION FROM:
action 2, numVisits=186173, meanQ=5.875935, numObservations: 3
action 3, numVisits=23079, meanQ=5.119103, numObservations: 5
action 1, numVisits=12, meanQ=2.999167, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 2
Next state: 0 0.665432 0.853079 0.151701 0.485822 0.600855 0.853184 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2746, meanQ=8.161190, numObservations: 4
action 3, numVisits=40, meanQ=6.742752, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 17514 episodes
GETTING ACTION FROM:
action 1, numVisits=2919, meanQ=8.043718, numObservations: 5
action 3, numVisits=126, meanQ=6.378652, numObservations: 5
action 2, numVisits=17, meanQ=2.352941, numObservations: 4
action -1, numVisits=16511, meanQ=-1.651514, numObservations: 1
action 0, numVisits=730, meanQ=-1.865767, numObservations: 3
action: 1
Next state: 1 0.665432 0.853079 0.151701 0.485822 0.600855 0.853184 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 284
Initial state: 0 0.576087 0.895581 0.685029 0.874918 0.389889 0.307844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161988 episodes
GETTING ACTION FROM:
action 3, numVisits=160887, meanQ=4.971330, numObservations: 4
action 1, numVisits=1087, meanQ=4.687096, numObservations: 5
action 2, numVisits=10, meanQ=2.499000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.576087 0.895581 0.685029 0.874918 0.389889 0.307844 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=22398, meanQ=8.407194, numObservations: 5
action 1, numVisits=9, meanQ=5.890011, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7741 episodes
GETTING ACTION FROM:
action 2, numVisits=22398, meanQ=8.407194, numObservations: 5
action 3, numVisits=9, meanQ=4.988889, numObservations: 3
action 1, numVisits=20, meanQ=4.773891, numObservations: 3
action 0, numVisits=7706, meanQ=0.194416, numObservations: 1
action -1, numVisits=18, meanQ=-1.505550, numObservations: 1
action: 2
Next state: 1 0.576087 0.895581 0.685029 0.874918 0.389889 0.307844 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 285
Initial state: 0 0.610427 0.850111 0.500877 0.840831 0.722993 0.0103335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162426 episodes
GETTING ACTION FROM:
action 1, numVisits=162246, meanQ=4.983596, numObservations: 5
action 0, numVisits=140, meanQ=4.398506, numObservations: 2
action 3, numVisits=32, meanQ=3.337819, numObservations: 3
action 2, numVisits=6, meanQ=0.836683, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.610427 0.850111 0.500877 0.840831 0.722993 0.0103335 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 286
Initial state: 0 0.832338 0.0611842 0.637529 0.818852 0.69205 0.889205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160538 episodes
GETTING ACTION FROM:
action 2, numVisits=157490, meanQ=4.955801, numObservations: 4
action -1, numVisits=3042, meanQ=3.163855, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.832338 0.0611842 0.637529 0.818852 0.69205 0.889205 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 287
Initial state: 0 0.615219 0.896428 0.991254 0.751761 0.656484 0.837853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162050 episodes
GETTING ACTION FROM:
action 3, numVisits=161902, meanQ=4.986127, numObservations: 5
action 0, numVisits=94, meanQ=4.284650, numObservations: 1
action -1, numVisits=47, meanQ=3.980563, numObservations: 1
action 1, numVisits=6, meanQ=1.498333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.615219 0.896428 0.991254 0.751761 0.656484 0.837853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 288
Initial state: 0 0.522193 0.846713 0.937829 0.439472 0.688336 0.865882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153008 episodes
GETTING ACTION FROM:
action 2, numVisits=153002, meanQ=4.860953, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.522193 0.846713 0.937829 0.439472 0.688336 0.865882 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 289
Initial state: 0 0.319445 0.985919 0.530388 0.817245 0.510731 0.844035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161303 episodes
GETTING ACTION FROM:
action 3, numVisits=161266, meanQ=4.949054, numObservations: 4
action 1, numVisits=28, meanQ=3.106786, numObservations: 4
action 2, numVisits=5, meanQ=-0.399980, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.319445 0.985919 0.530388 0.817245 0.510731 0.844035 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 290
Initial state: 0 0.369102 0.53787 0.546581 0.855002 0.644598 0.863801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144730 episodes
GETTING ACTION FROM:
action 1, numVisits=120593, meanQ=5.009016, numObservations: 4
action 0, numVisits=24037, meanQ=2.719490, numObservations: 1
action -1, numVisits=92, meanQ=2.094840, numObservations: 1
action 3, numVisits=5, meanQ=-1.600000, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 1
Next state: 0 0.369102 0.53787 0.546581 0.855002 0.644598 0.863801 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=19865, meanQ=8.273965, numObservations: 5
action 3, numVisits=18, meanQ=6.333894, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10671 episodes
GETTING ACTION FROM:
action 2, numVisits=19865, meanQ=8.273965, numObservations: 5
action 1, numVisits=14, meanQ=4.356429, numObservations: 4
action 3, numVisits=34, meanQ=4.170663, numObservations: 4
action 0, numVisits=10641, meanQ=0.202313, numObservations: 2
action -1, numVisits=3, meanQ=-3.896874, numObservations: 1
action: 2
Next state: 1 0.369102 0.53787 0.546581 0.855002 0.644598 0.863801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 291
Initial state: 0 0.526255 0.894772 0.579389 0.831126 0.829551 0.484403 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 141283 episodes
GETTING ACTION FROM:
action 2, numVisits=141218, meanQ=4.599613, numObservations: 5
action 1, numVisits=52, meanQ=3.454237, numObservations: 5
action 3, numVisits=9, meanQ=1.665578, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.526255 0.894772 0.579389 0.831126 0.829551 0.484403 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 292
Initial state: 0 0.625251 0.884262 0.204972 0.740706 0.58682 0.852902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95989 episodes
GETTING ACTION FROM:
action -1, numVisits=95884, meanQ=2.942385, numObservations: 1
action 0, numVisits=82, meanQ=2.209669, numObservations: 1
action 3, numVisits=8, meanQ=-0.125000, numObservations: 3
action 1, numVisits=7, meanQ=-0.287143, numObservations: 4
action 2, numVisits=8, meanQ=-0.487500, numObservations: 3
action: -1
Next state: 0 0.625251 0.884262 0.204972 0.740706 0.58682 0.852902 w: 1
Observation: 0 0.671402 0 0.117774 0 0.501845 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=95875, meanQ=4.975592, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 163633 episodes
GETTING ACTION FROM:
action 1, numVisits=259502, meanQ=5.139911, numObservations: 4
action 2, numVisits=7, meanQ=2.002871, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.625251 0.884262 0.204972 0.740706 0.58682 0.852902 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 293
Initial state: 0 0.55661 0.51866 0.582579 0.82354 0.695077 0.889006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162830 episodes
GETTING ACTION FROM:
action 1, numVisits=162824, meanQ=4.948385, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.55661 0.51866 0.582579 0.82354 0.695077 0.889006 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 294
Initial state: 0 0.908849 0.876727 0.534581 0.801969 0.545454 0.885963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162436 episodes
GETTING ACTION FROM:
action 1, numVisits=162351, meanQ=5.014290, numObservations: 4
action -1, numVisits=31, meanQ=3.783354, numObservations: 1
action 0, numVisits=29, meanQ=3.635439, numObservations: 1
action 3, numVisits=24, meanQ=3.079167, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.908849 0.876727 0.534581 0.801969 0.545454 0.885963 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 295
Initial state: 0 0.674827 0.839221 0.0709241 0.0299288 0.6409 0.84272 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162406 episodes
GETTING ACTION FROM:
action 3, numVisits=162364, meanQ=4.975214, numObservations: 4
action 0, numVisits=38, meanQ=3.853133, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.674827 0.839221 0.0709241 0.0299288 0.6409 0.84272 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 296
Initial state: 0 0.491961 0.619963 0.604256 0.82848 0.55883 0.821166 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161239 episodes
GETTING ACTION FROM:
action 1, numVisits=161231, meanQ=4.939520, numObservations: 5
action 2, numVisits=3, meanQ=-0.659967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.491961 0.619963 0.604256 0.82848 0.55883 0.821166 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=20204, meanQ=8.401260, numObservations: 4
action 3, numVisits=2452, meanQ=8.330214, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6320 episodes
GETTING ACTION FROM:
action 2, numVisits=21224, meanQ=8.271053, numObservations: 4
action 3, numVisits=3228, meanQ=7.780126, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=4478, meanQ=0.276469, numObservations: 1
action 0, numVisits=47, meanQ=-0.600957, numObservations: 1
action: 2
Next state: 1 0.491961 0.619963 0.604256 0.82848 0.55883 0.821166 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 297
Initial state: 0 0.663611 0.872238 0.603324 0.807548 0.850451 0.24025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155158 episodes
GETTING ACTION FROM:
action 1, numVisits=155151, meanQ=4.883009, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.663611 0.872238 0.603324 0.807548 0.850451 0.24025 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 298
Initial state: 0 0.699605 0.892617 0.67944 0.828081 0.546945 0.379549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162502 episodes
GETTING ACTION FROM:
action 3, numVisits=162363, meanQ=4.979768, numObservations: 4
action -1, numVisits=99, meanQ=4.294446, numObservations: 1
action 0, numVisits=38, meanQ=3.836480, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.699605 0.892617 0.67944 0.828081 0.546945 0.379549 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 299
Initial state: 0 0.552636 0.862493 0.781395 0.427471 0.637265 0.834051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162102 episodes
GETTING ACTION FROM:
action 3, numVisits=162013, meanQ=4.960324, numObservations: 5
action 0, numVisits=58, meanQ=4.056355, numObservations: 1
action -1, numVisits=29, meanQ=3.622804, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.552636 0.862493 0.781395 0.427471 0.637265 0.834051 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 300
Initial state: 0 0.661712 0.872223 0.690624 0.826086 0.808393 0.436365 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163363 episodes
GETTING ACTION FROM:
action 2, numVisits=163346, meanQ=5.010379, numObservations: 4
action 1, numVisits=11, meanQ=2.363636, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.661712 0.872223 0.690624 0.826086 0.808393 0.436365 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 301
Initial state: 0 0.592939 0.808787 0.640698 0.591152 0.616872 0.889792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164078 episodes
GETTING ACTION FROM:
action 2, numVisits=164049, meanQ=5.035893, numObservations: 5
action 1, numVisits=21, meanQ=3.380005, numObservations: 4
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.592939 0.808787 0.640698 0.591152 0.616872 0.889792 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10247, meanQ=5.685051, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6084 episodes
GETTING ACTION FROM:
action 2, numVisits=10247, meanQ=5.685051, numObservations: 3
action 1, numVisits=38, meanQ=4.631579, numObservations: 3
action -1, numVisits=6006, meanQ=0.309834, numObservations: 1
action 3, numVisits=41, meanQ=-3.034927, numObservations: 4
action 0, numVisits=4, meanQ=-98.277255, numObservations: 1
action: 2
Next state: 2 0.592939 0.808787 0.640698 0.591152 0.616872 0.889792 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 302
Initial state: 0 0.582205 0.800056 0.949634 0.753379 0.684225 0.898801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162641 episodes
GETTING ACTION FROM:
action 3, numVisits=162546, meanQ=5.016889, numObservations: 4
action 0, numVisits=26, meanQ=3.657033, numObservations: 1
action -1, numVisits=28, meanQ=3.649717, numObservations: 1
action 1, numVisits=40, meanQ=3.490503, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.582205 0.800056 0.949634 0.753379 0.684225 0.898801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 303
Initial state: 0 0.603077 0.877705 0.642172 0.83236 0.756355 0.987832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163572 episodes
GETTING ACTION FROM:
action 2, numVisits=163482, meanQ=4.998549, numObservations: 4
action -1, numVisits=86, meanQ=4.255781, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.603077 0.877705 0.642172 0.83236 0.756355 0.987832 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 304
Initial state: 0 0.50238 0.892975 0.0242168 0.248734 0.651249 0.807523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94957 episodes
GETTING ACTION FROM:
action 0, numVisits=94950, meanQ=3.138683, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.50238 0.892975 0.0242168 0.248734 0.651249 0.807523 w: 1
Observation: 0 0 0.799079 0 0.247186 0 0.851259 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=60915, meanQ=3.946409, numObservations: 4
action 2, numVisits=21, meanQ=2.141438, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 162862 episodes
GETTING ACTION FROM:
action 3, numVisits=162863, meanQ=4.987650, numObservations: 4
action 1, numVisits=60915, meanQ=3.946409, numObservations: 4
action 2, numVisits=21, meanQ=2.141438, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.50238 0.892975 0.0242168 0.248734 0.651249 0.807523 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 305
Initial state: 0 0.614403 0.892416 0.601118 0.894754 0.0355434 0.925205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162657 episodes
GETTING ACTION FROM:
action 1, numVisits=162610, meanQ=5.006500, numObservations: 4
action 0, numVisits=30, meanQ=3.691483, numObservations: 1
action 2, numVisits=14, meanQ=2.215014, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.614403 0.892416 0.601118 0.894754 0.0355434 0.925205 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 306
Initial state: 0 0.701018 0.163356 0.62221 0.885053 0.510768 0.842325 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 150795 episodes
GETTING ACTION FROM:
action 3, numVisits=150759, meanQ=4.794717, numObservations: 5
action 2, numVisits=29, meanQ=3.248624, numObservations: 4
action 1, numVisits=3, meanQ=-0.659967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.701018 0.163356 0.62221 0.885053 0.510768 0.842325 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 307
Initial state: 0 0.604847 0.803534 0.326109 0.0990396 0.540047 0.889875 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163099 episodes
GETTING ACTION FROM:
action 3, numVisits=163092, meanQ=5.058465, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.604847 0.803534 0.326109 0.0990396 0.540047 0.889875 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 308
Initial state: 0 0.557627 0.809937 0.654655 0.203189 0.653443 0.808745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153888 episodes
GETTING ACTION FROM:
action 2, numVisits=153860, meanQ=4.837915, numObservations: 5
action 0, numVisits=13, meanQ=2.772320, numObservations: 1
action 3, numVisits=6, meanQ=1.498333, numObservations: 2
action 1, numVisits=7, meanQ=1.428571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.557627 0.809937 0.654655 0.203189 0.653443 0.808745 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=17459, meanQ=8.543164, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 20904 episodes
GETTING ACTION FROM:
action 3, numVisits=17459, meanQ=8.543164, numObservations: 3
action 1, numVisits=45, meanQ=6.355491, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=20851, meanQ=0.229033, numObservations: 1
action 0, numVisits=11, meanQ=-2.641414, numObservations: 1
action: 3
Next state: 1 0.557627 0.809937 0.654655 0.203189 0.653443 0.808745 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 309
Initial state: 0 0.600222 0.848222 0.647961 0.810758 0.934388 0.308812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162033 episodes
GETTING ACTION FROM:
action 3, numVisits=162023, meanQ=4.959798, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.600222 0.848222 0.647961 0.810758 0.934388 0.308812 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 310
Initial state: 0 0.523585 0.870427 0.694118 0.80475 0.763894 0.739635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162963 episodes
GETTING ACTION FROM:
action 2, numVisits=161593, meanQ=4.961086, numObservations: 3
action 3, numVisits=1335, meanQ=4.624832, numObservations: 5
action -1, numVisits=30, meanQ=3.688812, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.523585 0.870427 0.694118 0.80475 0.763894 0.739635 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 311
Initial state: 0 0.560508 0.873192 0.625829 0.802134 0.926279 0.962925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162859 episodes
GETTING ACTION FROM:
action 1, numVisits=162827, meanQ=5.043308, numObservations: 4
action 2, numVisits=25, meanQ=3.441616, numObservations: 3
action 3, numVisits=3, meanQ=0.000033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.560508 0.873192 0.625829 0.802134 0.926279 0.962925 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 312
Initial state: 0 0.947366 0.297347 0.56117 0.812277 0.531039 0.813696 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161739 episodes
GETTING ACTION FROM:
action 3, numVisits=161729, meanQ=4.940428, numObservations: 5
action 1, numVisits=5, meanQ=1.622000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.947366 0.297347 0.56117 0.812277 0.531039 0.813696 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 313
Initial state: 0 0.663049 0.864476 0.863898 0.73506 0.64008 0.811542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163141 episodes
GETTING ACTION FROM:
action 3, numVisits=163030, meanQ=5.017981, numObservations: 5
action -1, numVisits=96, meanQ=3.829101, numObservations: 1
action 1, numVisits=9, meanQ=2.333333, numObservations: 3
action 2, numVisits=4, meanQ=0.750000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.663049 0.864476 0.863898 0.73506 0.64008 0.811542 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 314
Initial state: 0 0.717523 0.943146 0.633773 0.809451 0.611285 0.825898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95705 episodes
GETTING ACTION FROM:
action 0, numVisits=95689, meanQ=2.919440, numObservations: 1
action 1, numVisits=10, meanQ=0.690010, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.489950, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 0
Next state: 0 0.717523 0.943146 0.633773 0.809451 0.611285 0.825898 w: 1
Observation: 0 0 0.905897 0 0.829319 0 0.81445 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=95670, meanQ=4.993100, numObservations: 5
action 3, numVisits=13, meanQ=1.907692, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 163709 episodes
GETTING ACTION FROM:
action 2, numVisits=259374, meanQ=5.031070, numObservations: 5
action 3, numVisits=13, meanQ=1.907692, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=5, meanQ=-4.002000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.717523 0.943146 0.633773 0.809451 0.611285 0.825898 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 315
Initial state: 0 0.680561 0.814651 0.522945 0.877709 0.863858 0.543424 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162180 episodes
GETTING ACTION FROM:
action 3, numVisits=161353, meanQ=5.149482, numObservations: 4
action -1, numVisits=821, meanQ=3.161207, numObservations: 1
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.680561 0.814651 0.522945 0.877709 0.863858 0.543424 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 316
Initial state: 0 0.479973 0.0904775 0.675697 0.896892 0.604165 0.876603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162667 episodes
GETTING ACTION FROM:
action 2, numVisits=162596, meanQ=5.011382, numObservations: 5
action 0, numVisits=61, meanQ=4.126384, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 3, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.479973 0.0904775 0.675697 0.896892 0.604165 0.876603 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 317
Initial state: 0 0.116253 0.66237 0.626493 0.875051 0.545592 0.842779 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162795 episodes
GETTING ACTION FROM:
action 2, numVisits=162778, meanQ=5.010225, numObservations: 3
action 0, numVisits=10, meanQ=2.752505, numObservations: 1
action 1, numVisits=4, meanQ=-0.272500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.116253 0.66237 0.626493 0.875051 0.545592 0.842779 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 318
Initial state: 0 0.853331 0.766396 0.631209 0.851569 0.548513 0.886045 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154188 episodes
GETTING ACTION FROM:
action 2, numVisits=154155, meanQ=4.747782, numObservations: 4
action 0, numVisits=15, meanQ=2.768204, numObservations: 1
action 3, numVisits=15, meanQ=2.065333, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.853331 0.766396 0.631209 0.851569 0.548513 0.886045 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 319
Initial state: 0 0.555576 0.830732 0.0434337 0.0117121 0.67568 0.855769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162747 episodes
GETTING ACTION FROM:
action 3, numVisits=162657, meanQ=5.023547, numObservations: 4
action 0, numVisits=70, meanQ=4.207246, numObservations: 1
action 1, numVisits=12, meanQ=2.999167, numObservations: 2
action 2, numVisits=6, meanQ=2.003350, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.555576 0.830732 0.0434337 0.0117121 0.67568 0.855769 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 320
Initial state: 0 0.501503 0.865213 0.759274 0.186975 0.546341 0.82453 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161045 episodes
GETTING ACTION FROM:
action 1, numVisits=161039, meanQ=4.980870, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.501503 0.865213 0.759274 0.186975 0.546341 0.82453 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 321
Initial state: 0 0.615587 0.864655 0.713593 0.505338 0.555914 0.841187 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159056 episodes
GETTING ACTION FROM:
action 3, numVisits=159003, meanQ=4.904817, numObservations: 5
action 1, numVisits=48, meanQ=3.901460, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.615587 0.864655 0.713593 0.505338 0.555914 0.841187 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 322
Initial state: 0 0.557879 0.82955 0.715244 0.546556 0.620265 0.82859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161453 episodes
GETTING ACTION FROM:
action 1, numVisits=161148, meanQ=4.925788, numObservations: 5
action -1, numVisits=238, meanQ=2.785279, numObservations: 1
action 0, numVisits=63, meanQ=2.472297, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.557879 0.82955 0.715244 0.546556 0.620265 0.82859 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 323
Initial state: 0 0.593383 0.821548 0.624499 0.834841 0.514301 0.313349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162477 episodes
GETTING ACTION FROM:
action 2, numVisits=162324, meanQ=5.002278, numObservations: 5
action 0, numVisits=139, meanQ=4.427759, numObservations: 1
action 3, numVisits=11, meanQ=2.363636, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.593383 0.821548 0.624499 0.834841 0.514301 0.313349 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 324
Initial state: 0 0.696229 0.785754 0.672765 0.804301 0.522551 0.824568 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162667 episodes
GETTING ACTION FROM:
action 1, numVisits=160895, meanQ=5.013217, numObservations: 5
action 2, numVisits=1739, meanQ=4.816161, numObservations: 4
action -1, numVisits=29, meanQ=3.735145, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.696229 0.785754 0.672765 0.804301 0.522551 0.824568 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 325
Initial state: 0 0.686117 0.803721 0.619863 0.885465 0.501576 0.0401868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162286 episodes
GETTING ACTION FROM:
action 3, numVisits=162271, meanQ=4.974396, numObservations: 4
action 1, numVisits=9, meanQ=1.990000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.686117 0.803721 0.619863 0.885465 0.501576 0.0401868 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=204, meanQ=8.368187, numObservations: 3
action 1, numVisits=22649, meanQ=8.361288, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 5821 episodes
GETTING ACTION FROM:
action 1, numVisits=22649, meanQ=8.361288, numObservations: 4
action 2, numVisits=344, meanQ=7.380611, numObservations: 3
action 3, numVisits=16, meanQ=4.243750, numObservations: 3
action 0, numVisits=5658, meanQ=0.288127, numObservations: 1
action -1, numVisits=10, meanQ=-1.901000, numObservations: 1
action: 1
Next state: 1 0.686117 0.803721 0.619863 0.885465 0.501576 0.0401868 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 326
Initial state: 0 0.519811 0.879444 0.675706 0.88188 0.057243 0.313082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 145333 episodes
GETTING ACTION FROM:
action 1, numVisits=123543, meanQ=4.914906, numObservations: 4
action 0, numVisits=17941, meanQ=3.119658, numObservations: 1
action -1, numVisits=3839, meanQ=3.064819, numObservations: 1
action 3, numVisits=7, meanQ=-0.145714, numObservations: 3
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action: 1
Next state: 1 0.519811 0.879444 0.675706 0.88188 0.057243 0.313082 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 327
Initial state: 0 0.52635 0.889071 0.260745 0.944831 0.542898 0.846039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161771 episodes
GETTING ACTION FROM:
action 1, numVisits=161764, meanQ=4.947531, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.52635 0.889071 0.260745 0.944831 0.542898 0.846039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 328
Initial state: 0 0.0569368 0.806881 0.648256 0.82032 0.64822 0.873147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160407 episodes
GETTING ACTION FROM:
action 2, numVisits=160338, meanQ=4.905629, numObservations: 4
action -1, numVisits=61, meanQ=2.925077, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.0569368 0.806881 0.648256 0.82032 0.64822 0.873147 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 329
Initial state: 0 0.312372 0.51452 0.623461 0.857412 0.671471 0.837443 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161331 episodes
GETTING ACTION FROM:
action 2, numVisits=161324, meanQ=4.968871, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.312372 0.51452 0.623461 0.857412 0.671471 0.837443 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 330
Initial state: 0 0.620946 0.858623 0.752257 0.521886 0.607634 0.805968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162812 episodes
GETTING ACTION FROM:
action 1, numVisits=162637, meanQ=5.031648, numObservations: 3
action 0, numVisits=104, meanQ=4.357012, numObservations: 1
action -1, numVisits=59, meanQ=4.127210, numObservations: 1
action 3, numVisits=10, meanQ=2.102010, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.620946 0.858623 0.752257 0.521886 0.607634 0.805968 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 331
Initial state: 0 0.531002 0.870426 0.510754 0.431861 0.57921 0.890188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161102 episodes
GETTING ACTION FROM:
action 2, numVisits=161093, meanQ=4.976588, numObservations: 4
action 3, numVisits=4, meanQ=0.750000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.531002 0.870426 0.510754 0.431861 0.57921 0.890188 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 332
Initial state: 0 0.55849 0.830527 0.858597 0.576832 0.640326 0.852057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161752 episodes
GETTING ACTION FROM:
action 3, numVisits=161740, meanQ=4.976647, numObservations: 4
action 2, numVisits=6, meanQ=1.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 3
Next state: 1 0.55849 0.830527 0.858597 0.576832 0.640326 0.852057 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 333
Initial state: 0 0.523899 0.803154 0.632567 0.896516 0.124041 0.830105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155078 episodes
GETTING ACTION FROM:
action 2, numVisits=144320, meanQ=4.943856, numObservations: 4
action 0, numVisits=10752, meanQ=3.050467, numObservations: 1
action 3, numVisits=3, meanQ=-0.659967, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.523899 0.803154 0.632567 0.896516 0.124041 0.830105 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 334
Initial state: 0 0.551274 0.849126 0.352483 0.524787 0.571198 0.857386 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160920 episodes
GETTING ACTION FROM:
action 3, numVisits=160831, meanQ=4.940986, numObservations: 4
action -1, numVisits=53, meanQ=3.985673, numObservations: 1
action 0, numVisits=30, meanQ=3.621178, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 1 0.551274 0.849126 0.352483 0.524787 0.571198 0.857386 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 335
Initial state: 0 0.609174 0.825233 0.662313 0.820723 0.0721127 0.706709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163593 episodes
GETTING ACTION FROM:
action 2, numVisits=163543, meanQ=5.039255, numObservations: 4
action 3, numVisits=36, meanQ=3.803344, numObservations: 3
action 1, numVisits=10, meanQ=2.400000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.609174 0.825233 0.662313 0.820723 0.0721127 0.706709 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 336
Initial state: 0 0.64009 0.828494 0.646579 0.866496 0.0414813 0.556307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162372 episodes
GETTING ACTION FROM:
action 3, numVisits=162353, meanQ=5.013501, numObservations: 4
action 2, numVisits=14, meanQ=2.603571, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.64009 0.828494 0.646579 0.866496 0.0414813 0.556307 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26669, meanQ=8.293728, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8846 episodes
GETTING ACTION FROM:
action 2, numVisits=26669, meanQ=8.293728, numObservations: 3
action 1, numVisits=21, meanQ=5.376190, numObservations: 4
action 3, numVisits=16, meanQ=4.061881, numObservations: 4
action -1, numVisits=8802, meanQ=0.131839, numObservations: 1
action 0, numVisits=11, meanQ=-2.900000, numObservations: 1
action: 2
Next state: 1 0.64009 0.828494 0.646579 0.866496 0.0414813 0.556307 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 337
Initial state: 0 0.590276 0.807828 0.843243 0.164086 0.558941 0.858633 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95736 episodes
GETTING ACTION FROM:
action 0, numVisits=95675, meanQ=2.879025, numObservations: 1
action -1, numVisits=53, meanQ=1.966360, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=4, meanQ=-2.749975, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.590276 0.807828 0.843243 0.164086 0.558941 0.858633 w: 1
Observation: 0 0 0.763733 0 0.206019 0 0.776575 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=95637, meanQ=4.915428, numObservations: 4
action 0, numVisits=29, meanQ=3.527283, numObservations: 1
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 2, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 162034 episodes
GETTING ACTION FROM:
action 3, numVisits=257666, meanQ=5.038955, numObservations: 4
action 0, numVisits=30, meanQ=3.375897, numObservations: 1
action 1, numVisits=5, meanQ=1.396020, numObservations: 2
action 2, numVisits=5, meanQ=1.396020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.590276 0.807828 0.843243 0.164086 0.558941 0.858633 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 338
Initial state: 0 0.549718 0.810557 0.224334 0.135478 0.666357 0.82749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160506 episodes
GETTING ACTION FROM:
action 1, numVisits=160499, meanQ=4.897458, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=2, meanQ=-7.500000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.549718 0.810557 0.224334 0.135478 0.666357 0.82749 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11999, meanQ=4.545840, numObservations: 4
action 1, numVisits=8, meanQ=1.747513, numObservations: 2
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 201357 episodes
GETTING ACTION FROM:
action 2, numVisits=201358, meanQ=5.988159, numObservations: 5
action 3, numVisits=11999, meanQ=4.545840, numObservations: 4
action 1, numVisits=9, meanQ=0.331122, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.549718 0.810557 0.224334 0.135478 0.666357 0.82749 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2460, meanQ=8.433740, numObservations: 3
action 1, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 41793 episodes
GETTING ACTION FROM:
action 3, numVisits=3556, meanQ=7.821574, numObservations: 4
action 2, numVisits=55, meanQ=5.000000, numObservations: 4
action 1, numVisits=7, meanQ=-1.287143, numObservations: 2
action 0, numVisits=23731, meanQ=-1.721745, numObservations: 3
action -1, numVisits=16910, meanQ=-1.734380, numObservations: 1
action: 3
Next state: 1 0.549718 0.810557 0.224334 0.135478 0.666357 0.82749 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 339
Initial state: 0 0.612544 0.84963 0.644583 0.871562 0.64135 0.591443 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162717 episodes
GETTING ACTION FROM:
action 3, numVisits=162669, meanQ=5.006397, numObservations: 3
action 0, numVisits=38, meanQ=3.853356, numObservations: 1
action 1, numVisits=6, meanQ=1.166683, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.612544 0.84963 0.644583 0.871562 0.64135 0.591443 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 340
Initial state: 0 0.574452 0.805612 0.649008 0.810413 0.316115 0.715601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162278 episodes
GETTING ACTION FROM:
action 2, numVisits=162272, meanQ=4.947986, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.574452 0.805612 0.649008 0.810413 0.316115 0.715601 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 341
Initial state: 0 0.613565 0.369652 0.668024 0.871986 0.573445 0.896459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94015 episodes
GETTING ACTION FROM:
action 0, numVisits=94003, meanQ=2.829702, numObservations: 1
action 3, numVisits=8, meanQ=-0.126225, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.613565 0.369652 0.668024 0.871986 0.573445 0.896459 w: 1
Observation: 0 0 0.374393 0 0.891348 0 0.914298 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=93972, meanQ=4.851183, numObservations: 4
action 0, numVisits=23, meanQ=3.348415, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 160395 episodes
GETTING ACTION FROM:
action 3, numVisits=254366, meanQ=4.905308, numObservations: 4
action 0, numVisits=24, meanQ=3.214562, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.613565 0.369652 0.668024 0.871986 0.573445 0.896459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 342
Initial state: 0 0.196788 0.0613518 0.66138 0.875281 0.580049 0.88276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162716 episodes
GETTING ACTION FROM:
action 1, numVisits=162660, meanQ=4.971251, numObservations: 5
action -1, numVisits=51, meanQ=2.174266, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.196788 0.0613518 0.66138 0.875281 0.580049 0.88276 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=22587, meanQ=8.399439, numObservations: 5
action 3, numVisits=21, meanQ=6.709048, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 15622 episodes
GETTING ACTION FROM:
action 2, numVisits=22587, meanQ=8.399439, numObservations: 5
action 3, numVisits=27, meanQ=5.585185, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action 0, numVisits=15614, meanQ=0.174779, numObservations: 1
action -1, numVisits=3, meanQ=-131.078173, numObservations: 1
action: 2
Next state: 1 0.196788 0.0613518 0.66138 0.875281 0.580049 0.88276 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 343
Initial state: 0 0.512173 0.833236 0.401419 0.466835 0.62334 0.83255 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162781 episodes
GETTING ACTION FROM:
action 2, numVisits=162689, meanQ=5.020586, numObservations: 4
action -1, numVisits=88, meanQ=4.272018, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.512173 0.833236 0.401419 0.466835 0.62334 0.83255 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4118, meanQ=7.750077, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 5888 episodes
GETTING ACTION FROM:
action 1, numVisits=4129, meanQ=7.742514, numObservations: 4
action 3, numVisits=13, meanQ=1.922308, numObservations: 4
action 2, numVisits=2, meanQ=0.950000, numObservations: 1
action -1, numVisits=5756, meanQ=0.221306, numObservations: 1
action 0, numVisits=111, meanQ=-0.314414, numObservations: 1
action: 1
Next state: 1 0.512173 0.833236 0.401419 0.466835 0.62334 0.83255 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 344
Initial state: 0 0.722798 0.234265 0.66576 0.857368 0.620628 0.823467 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162417 episodes
GETTING ACTION FROM:
action 3, numVisits=162380, meanQ=5.132749, numObservations: 5
action 0, numVisits=24, meanQ=3.628151, numObservations: 1
action 2, numVisits=10, meanQ=0.900020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.722798 0.234265 0.66576 0.857368 0.620628 0.823467 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 345
Initial state: 0 0.518738 0.857253 0.0530357 0.403738 0.525132 0.831427 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162560 episodes
GETTING ACTION FROM:
action 3, numVisits=159685, meanQ=5.164321, numObservations: 4
action 1, numVisits=2870, meanQ=4.815967, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.518738 0.857253 0.0530357 0.403738 0.525132 0.831427 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 346
Initial state: 0 0.673205 0.822737 0.849312 0.564207 0.588414 0.80254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164526 episodes
GETTING ACTION FROM:
action 3, numVisits=164471, meanQ=5.053997, numObservations: 4
action 0, numVisits=51, meanQ=4.068430, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.673205 0.822737 0.849312 0.564207 0.588414 0.80254 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 347
Initial state: 0 0.503532 0.812809 0.0806566 0.0802904 0.652522 0.822786 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162909 episodes
GETTING ACTION FROM:
action 1, numVisits=162782, meanQ=5.187429, numObservations: 5
action 3, numVisits=118, meanQ=3.026618, numObservations: 4
action 2, numVisits=5, meanQ=-0.200000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.503532 0.812809 0.0806566 0.0802904 0.652522 0.822786 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9352, meanQ=7.881010, numObservations: 3
action 2, numVisits=21, meanQ=6.237148, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7976 episodes
GETTING ACTION FROM:
action 3, numVisits=9352, meanQ=7.881010, numObservations: 3
action 2, numVisits=66, meanQ=5.634698, numObservations: 4
action 1, numVisits=4, meanQ=4.975000, numObservations: 2
action -1, numVisits=7924, meanQ=0.180020, numObservations: 1
action 0, numVisits=6, meanQ=-3.650000, numObservations: 1
action: 3
Next state: 0 0.503532 0.812809 0.0806566 0.0802904 0.652522 0.822786 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=735, meanQ=7.816859, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21305 episodes
GETTING ACTION FROM:
action 3, numVisits=735, meanQ=7.816859, numObservations: 3
action 2, numVisits=839, meanQ=6.371529, numObservations: 4
action 0, numVisits=20460, meanQ=-1.635403, numObservations: 2
action -1, numVisits=8, meanQ=-4.115868, numObservations: 1
action 1, numVisits=2, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.503532 0.812809 0.0806566 0.0802904 0.652522 0.822786 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=50, meanQ=5.916204, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 26910 episodes
GETTING ACTION FROM:
action 2, numVisits=50, meanQ=5.916204, numObservations: 4
action 3, numVisits=63, meanQ=5.809527, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=14793, meanQ=-1.755530, numObservations: 1
action 0, numVisits=12058, meanQ=-1.757632, numObservations: 1
action: 2
Next state: 0 0.503532 0.812809 0.0806566 0.0802904 0.652522 0.822786 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92757 episodes
GETTING ACTION FROM:
action 1, numVisits=625, meanQ=6.579200, numObservations: 4
action 2, numVisits=606, meanQ=6.557756, numObservations: 4
action 3, numVisits=423, meanQ=5.919745, numObservations: 4
action -1, numVisits=48714, meanQ=-1.958095, numObservations: 1
action 0, numVisits=42389, meanQ=-1.960483, numObservations: 1
action: 1
Next state: 1 0.503532 0.812809 0.0806566 0.0802904 0.652522 0.822786 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -7.11623
Run # 348
Initial state: 0 0.636874 0.854103 0.799996 0.526649 0.528781 0.806115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163371 episodes
GETTING ACTION FROM:
action 1, numVisits=163297, meanQ=5.049363, numObservations: 4
action 0, numVisits=54, meanQ=4.108358, numObservations: 1
action 3, numVisits=13, meanQ=1.846154, numObservations: 3
action 2, numVisits=5, meanQ=0.802020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.636874 0.854103 0.799996 0.526649 0.528781 0.806115 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 349
Initial state: 0 0.636214 0.835614 0.621115 0.874556 0.322199 0.0215171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95706 episodes
GETTING ACTION FROM:
action -1, numVisits=95694, meanQ=2.960198, numObservations: 1
action 1, numVisits=7, meanQ=-0.145714, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-7.500000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.636214 0.835614 0.621115 0.874556 0.322199 0.0215171 w: 1
Observation: 0 0.656488 0 0.573026 0 0.416183 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=95595, meanQ=5.013535, numObservations: 5
action -1, numVisits=71, meanQ=4.217136, numObservations: 1
action 2, numVisits=24, meanQ=2.988337, numObservations: 4
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 165000 episodes
GETTING ACTION FROM:
action 1, numVisits=260593, meanQ=5.079591, numObservations: 5
action -1, numVisits=72, meanQ=4.214016, numObservations: 1
action 2, numVisits=24, meanQ=2.988337, numObservations: 4
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=2, meanQ=-3.505000, numObservations: 2
action: 1
Next state: 1 0.636214 0.835614 0.621115 0.874556 0.322199 0.0215171 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 350
Initial state: 0 0.628859 0.893509 0.801725 0.0812511 0.605068 0.886063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160404 episodes
GETTING ACTION FROM:
action 3, numVisits=160398, meanQ=4.933139, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.628859 0.893509 0.801725 0.0812511 0.605068 0.886063 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 351
Initial state: 0 0.658665 0.89527 0.987012 0.31525 0.662803 0.800152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162545 episodes
GETTING ACTION FROM:
action 3, numVisits=162537, meanQ=5.015429, numObservations: 5
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.658665 0.89527 0.987012 0.31525 0.662803 0.800152 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 352
Initial state: 0 0.602369 0.810847 0.554903 0.853673 0.0227882 0.620431 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162399 episodes
GETTING ACTION FROM:
action 1, numVisits=154951, meanQ=4.962831, numObservations: 3
action 3, numVisits=7306, meanQ=4.861569, numObservations: 3
action -1, numVisits=83, meanQ=4.202927, numObservations: 1
action 0, numVisits=51, meanQ=3.979042, numObservations: 1
action 2, numVisits=8, meanQ=2.375000, numObservations: 3
action: 1
Next state: 1 0.602369 0.810847 0.554903 0.853673 0.0227882 0.620431 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 353
Initial state: 0 0.527233 0.802068 0.437149 0.656388 0.659888 0.826586 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163668 episodes
GETTING ACTION FROM:
action 2, numVisits=163559, meanQ=5.038622, numObservations: 4
action 3, numVisits=53, meanQ=4.008063, numObservations: 5
action 1, numVisits=52, meanQ=3.991348, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.527233 0.802068 0.437149 0.656388 0.659888 0.826586 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=24736, meanQ=8.319683, numObservations: 3
action 1, numVisits=2104, meanQ=8.217585, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10392 episodes
GETTING ACTION FROM:
action 3, numVisits=24736, meanQ=8.319683, numObservations: 3
action 1, numVisits=2129, meanQ=8.196237, numObservations: 3
action 2, numVisits=14, meanQ=1.428571, numObservations: 4
action -1, numVisits=10347, meanQ=0.208866, numObservations: 1
action 0, numVisits=9, meanQ=-2.001100, numObservations: 1
action: 3
Next state: 1 0.527233 0.802068 0.437149 0.656388 0.659888 0.826586 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 354
Initial state: 0 0.64366 0.831279 0.648461 0.81814 0.878569 0.203635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162714 episodes
GETTING ACTION FROM:
action 1, numVisits=162593, meanQ=5.010561, numObservations: 5
action -1, numVisits=99, meanQ=4.263343, numObservations: 1
action 2, numVisits=19, meanQ=2.788426, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.64366 0.831279 0.648461 0.81814 0.878569 0.203635 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 355
Initial state: 0 0.593895 0.873423 0.58272 0.824702 0.181259 0.971429 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160548 episodes
GETTING ACTION FROM:
action 1, numVisits=160491, meanQ=4.988549, numObservations: 5
action 0, numVisits=22, meanQ=3.511580, numObservations: 1
action 2, numVisits=32, meanQ=2.751266, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.593895 0.873423 0.58272 0.824702 0.181259 0.971429 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 356
Initial state: 0 0.65583 0.812178 0.603696 0.86552 0.591745 0.644904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89418 episodes
GETTING ACTION FROM:
action 0, numVisits=21122, meanQ=3.975945, numObservations: 2
action -1, numVisits=68285, meanQ=2.687911, numObservations: 1
action 2, numVisits=9, meanQ=-0.020000, numObservations: 4
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.65583 0.812178 0.603696 0.86552 0.591745 0.644904 w: 1
Observation: 0 0 0.770092 0 0.833718 0 0.684482 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=12918, meanQ=5.237820, numObservations: 1
action 1, numVisits=2618, meanQ=4.489732, numObservations: 5
action 2, numVisits=27, meanQ=3.000385, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 145729 episodes
GETTING ACTION FROM:
action 1, numVisits=126765, meanQ=4.912050, numObservations: 5
action 0, numVisits=34500, meanQ=4.561200, numObservations: 1
action 2, numVisits=27, meanQ=3.000385, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.65583 0.812178 0.603696 0.86552 0.591745 0.644904 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 357
Initial state: 0 0.665384 0.82776 0.113538 0.527636 0.542505 0.817949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161663 episodes
GETTING ACTION FROM:
action 2, numVisits=161633, meanQ=5.008415, numObservations: 4
action 0, numVisits=24, meanQ=3.601250, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.665384 0.82776 0.113538 0.527636 0.542505 0.817949 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3959, meanQ=7.689747, numObservations: 4
action 1, numVisits=7, meanQ=4.427143, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 5686 episodes
GETTING ACTION FROM:
action 3, numVisits=3959, meanQ=7.689747, numObservations: 4
action 2, numVisits=10, meanQ=5.390000, numObservations: 3
action 1, numVisits=24, meanQ=5.166250, numObservations: 3
action 0, numVisits=2655, meanQ=0.252203, numObservations: 1
action -1, numVisits=3007, meanQ=0.216385, numObservations: 1
action: 3
Next state: 1 0.665384 0.82776 0.113538 0.527636 0.542505 0.817949 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 358
Initial state: 0 0.639742 0.808951 0.410401 0.247852 0.624317 0.805361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 112209 episodes
GETTING ACTION FROM:
action 3, numVisits=40337, meanQ=4.992892, numObservations: 4
action -1, numVisits=71855, meanQ=2.855951, numObservations: 1
action 1, numVisits=9, meanQ=0.000022, numObservations: 4
action 2, numVisits=6, meanQ=-0.834983, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.639742 0.808951 0.410401 0.247852 0.624317 0.805361 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 359
Initial state: 0 0.562913 0.843467 0.724381 0.97021 0.563561 0.84794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162647 episodes
GETTING ACTION FROM:
action 2, numVisits=162640, meanQ=4.957442, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.562913 0.843467 0.724381 0.97021 0.563561 0.84794 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 360
Initial state: 0 0.564552 0.85576 0.546904 0.831049 0.764359 0.881344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162100 episodes
GETTING ACTION FROM:
action 2, numVisits=162082, meanQ=4.966166, numObservations: 4
action 3, numVisits=10, meanQ=2.690010, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.564552 0.85576 0.546904 0.831049 0.764359 0.881344 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 361
Initial state: 0 0.918519 0.566571 0.58095 0.804697 0.667433 0.817625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155662 episodes
GETTING ACTION FROM:
action 2, numVisits=155627, meanQ=4.963847, numObservations: 4
action 3, numVisits=30, meanQ=3.633343, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.918519 0.566571 0.58095 0.804697 0.667433 0.817625 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 362
Initial state: 0 0.58733 0.890484 0.598768 0.809238 0.1706 0.124014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162703 episodes
GETTING ACTION FROM:
action 1, numVisits=162694, meanQ=5.007418, numObservations: 4
action 3, numVisits=3, meanQ=-0.700000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 1
Next state: 1 0.58733 0.890484 0.598768 0.809238 0.1706 0.124014 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 363
Initial state: 0 0.592568 0.887403 0.702706 0.457978 0.649448 0.872517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161652 episodes
GETTING ACTION FROM:
action 2, numVisits=161573, meanQ=4.974515, numObservations: 4
action -1, numVisits=60, meanQ=4.071388, numObservations: 1
action 3, numVisits=13, meanQ=2.846162, numObservations: 2
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.592568 0.887403 0.702706 0.457978 0.649448 0.872517 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11985, meanQ=5.599954, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 3962 episodes
GETTING ACTION FROM:
action 3, numVisits=201, meanQ=6.526520, numObservations: 5
action 1, numVisits=45, meanQ=5.888889, numObservations: 4
action 2, numVisits=11985, meanQ=5.599954, numObservations: 3
action 0, numVisits=3720, meanQ=0.204295, numObservations: 1
action -1, numVisits=2, meanQ=-197.767295, numObservations: 1
action: 3
Next state: 0 0.592568 0.887403 0.702706 0.457978 0.649448 0.872517 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=9.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 11921 episodes
GETTING ACTION FROM:
action 1, numVisits=1129, meanQ=6.312807, numObservations: 5
action 2, numVisits=97, meanQ=4.876289, numObservations: 3
action 3, numVisits=43, meanQ=3.883721, numObservations: 4
action 0, numVisits=10605, meanQ=-1.495153, numObservations: 1
action -1, numVisits=49, meanQ=-2.314062, numObservations: 1
action: 1
Next state: 1 0.592568 0.887403 0.702706 0.457978 0.649448 0.872517 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 364
Initial state: 0 0.571981 0.872471 0.82741 0.405738 0.551129 0.823451 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154047 episodes
GETTING ACTION FROM:
action 1, numVisits=153179, meanQ=4.790656, numObservations: 4
action -1, numVisits=841, meanQ=3.147854, numObservations: 1
action 0, numVisits=24, meanQ=2.167465, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.571981 0.872471 0.82741 0.405738 0.551129 0.823451 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 365
Initial state: 0 0.675213 0.885877 0.591144 0.879912 0.695946 0.260405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161560 episodes
GETTING ACTION FROM:
action 1, numVisits=161522, meanQ=4.982288, numObservations: 4
action -1, numVisits=34, meanQ=3.779946, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.675213 0.885877 0.591144 0.879912 0.695946 0.260405 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 366
Initial state: 0 0.598501 0.881158 0.531993 0.860829 0.753703 0.82579 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161729 episodes
GETTING ACTION FROM:
action 3, numVisits=161616, meanQ=4.939055, numObservations: 4
action -1, numVisits=102, meanQ=3.744728, numObservations: 1
action 1, numVisits=7, meanQ=0.428571, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 3
Next state: 2 0.598501 0.881158 0.531993 0.860829 0.753703 0.82579 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 367
Initial state: 0 0.131466 0.00166442 0.648489 0.82122 0.622648 0.834654 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161799 episodes
GETTING ACTION FROM:
action 1, numVisits=161752, meanQ=4.960400, numObservations: 4
action 0, numVisits=36, meanQ=3.807883, numObservations: 1
action 3, numVisits=8, meanQ=1.013762, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.131466 0.00166442 0.648489 0.82122 0.622648 0.834654 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22720, meanQ=8.420674, numObservations: 5
action 2, numVisits=16, meanQ=6.500006, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10077 episodes
GETTING ACTION FROM:
action 3, numVisits=22720, meanQ=8.420674, numObservations: 5
action 2, numVisits=44, meanQ=5.588866, numObservations: 4
action 0, numVisits=9714, meanQ=0.333542, numObservations: 1
action -1, numVisits=335, meanQ=0.024328, numObservations: 1
action 1, numVisits=3, meanQ=-8.336667, numObservations: 2
action: 3
Next state: 1 0.131466 0.00166442 0.648489 0.82122 0.622648 0.834654 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 368
Initial state: 0 0.591305 0.81697 0.284871 0.780421 0.607026 0.842998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162726 episodes
GETTING ACTION FROM:
action 1, numVisits=162515, meanQ=5.004670, numObservations: 4
action 2, numVisits=206, meanQ=4.517431, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.591305 0.81697 0.284871 0.780421 0.607026 0.842998 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 369
Initial state: 0 0.650705 0.874624 0.347501 0.350561 0.547632 0.841258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160725 episodes
GETTING ACTION FROM:
action 1, numVisits=160577, meanQ=4.936171, numObservations: 5
action -1, numVisits=144, meanQ=4.363144, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.650705 0.874624 0.347501 0.350561 0.547632 0.841258 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 370
Initial state: 0 0.712267 0.193921 0.660464 0.891871 0.683144 0.87676 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160986 episodes
GETTING ACTION FROM:
action 1, numVisits=160004, meanQ=4.988244, numObservations: 4
action -1, numVisits=811, meanQ=3.179705, numObservations: 1
action 0, numVisits=152, meanQ=2.936812, numObservations: 1
action 2, numVisits=17, meanQ=1.234712, numObservations: 4
action 3, numVisits=2, meanQ=-5.489950, numObservations: 1
action: 1
Next state: 2 0.712267 0.193921 0.660464 0.891871 0.683144 0.87676 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 371
Initial state: 0 0.58813 0.838787 0.211374 0.202675 0.512919 0.837124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157295 episodes
GETTING ACTION FROM:
action 1, numVisits=157186, meanQ=4.837700, numObservations: 4
action -1, numVisits=94, meanQ=4.134528, numObservations: 1
action 2, numVisits=8, meanQ=2.125037, numObservations: 3
action 3, numVisits=5, meanQ=1.596000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.58813 0.838787 0.211374 0.202675 0.512919 0.837124 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11571, meanQ=4.667487, numObservations: 4
action -1, numVisits=48, meanQ=3.824704, numObservations: 1
action 2, numVisits=9, meanQ=1.445567, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 198215 episodes
GETTING ACTION FROM:
action 3, numVisits=209783, meanQ=5.969165, numObservations: 4
action -1, numVisits=49, meanQ=3.813458, numObservations: 1
action 2, numVisits=9, meanQ=1.445567, numObservations: 2
action 1, numVisits=3, meanQ=0.663333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.58813 0.838787 0.211374 0.202675 0.512919 0.837124 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 372
Initial state: 0 0.229369 0.361869 0.523949 0.864832 0.565478 0.855503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162257 episodes
GETTING ACTION FROM:
action 1, numVisits=162251, meanQ=5.028765, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.229369 0.361869 0.523949 0.864832 0.565478 0.855503 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22339, meanQ=8.404456, numObservations: 5
action 2, numVisits=300, meanQ=8.076175, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12612 episodes
GETTING ACTION FROM:
action 3, numVisits=23742, meanQ=8.266744, numObservations: 5
action 2, numVisits=438, meanQ=7.410128, numObservations: 4
action -1, numVisits=11063, meanQ=0.179287, numObservations: 1
action 0, numVisits=6, meanQ=-66.427955, numObservations: 1
action 1, numVisits=5, meanQ=-73.740621, numObservations: 3
action: 3
Next state: 1 0.229369 0.361869 0.523949 0.864832 0.565478 0.855503 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 373
Initial state: 0 0.821933 0.575685 0.580517 0.842645 0.574292 0.857031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96277 episodes
GETTING ACTION FROM:
action -1, numVisits=96268, meanQ=3.049826, numObservations: 1
action 1, numVisits=5, meanQ=-0.399980, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.821933 0.575685 0.580517 0.842645 0.574292 0.857031 w: 1
Observation: 0 0.866574 0 0.498529 0 0.523699 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=96207, meanQ=5.074163, numObservations: 4
action 3, numVisits=34, meanQ=3.694712, numObservations: 5
action -1, numVisits=23, meanQ=3.626891, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 164276 episodes
GETTING ACTION FROM:
action 2, numVisits=260482, meanQ=5.001813, numObservations: 4
action 3, numVisits=34, meanQ=3.694712, numObservations: 5
action -1, numVisits=24, meanQ=3.545233, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.821933 0.575685 0.580517 0.842645 0.574292 0.857031 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 374
Initial state: 0 0.154673 0.559344 0.538657 0.801697 0.678657 0.87503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161871 episodes
GETTING ACTION FROM:
action 2, numVisits=161864, meanQ=5.010431, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.154673 0.559344 0.538657 0.801697 0.678657 0.87503 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 375
Initial state: 0 0.613611 0.868937 0.617934 0.817709 0.329784 0.00391584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154709 episodes
GETTING ACTION FROM:
action 1, numVisits=154652, meanQ=4.876680, numObservations: 5
action -1, numVisits=44, meanQ=3.343496, numObservations: 1
action 3, numVisits=10, meanQ=2.499000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.613611 0.868937 0.617934 0.817709 0.329784 0.00391584 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 376
Initial state: 0 0.668192 0.836577 0.246522 0.33167 0.651675 0.846694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163148 episodes
GETTING ACTION FROM:
action 3, numVisits=163103, meanQ=4.982209, numObservations: 5
action 0, numVisits=25, meanQ=3.517480, numObservations: 1
action 2, numVisits=14, meanQ=1.499286, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.668192 0.836577 0.246522 0.33167 0.651675 0.846694 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 377
Initial state: 0 0.35637 0.878908 0.537482 0.813267 0.691365 0.839129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160998 episodes
GETTING ACTION FROM:
action 2, numVisits=160883, meanQ=5.170052, numObservations: 5
action -1, numVisits=111, meanQ=3.330049, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.35637 0.878908 0.537482 0.813267 0.691365 0.839129 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 378
Initial state: 0 0.280683 0.123318 0.619271 0.877538 0.640872 0.891965 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153721 episodes
GETTING ACTION FROM:
action 1, numVisits=153436, meanQ=4.973987, numObservations: 4
action 0, numVisits=266, meanQ=2.838442, numObservations: 1
action 3, numVisits=15, meanQ=1.594007, numObservations: 3
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.280683 0.123318 0.619271 0.877538 0.640872 0.891965 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=21351, meanQ=8.426256, numObservations: 4
action 3, numVisits=39, meanQ=7.242051, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6794 episodes
GETTING ACTION FROM:
action 2, numVisits=22621, meanQ=8.270136, numObservations: 4
action 3, numVisits=81, meanQ=5.490282, numObservations: 3
action 1, numVisits=3, meanQ=3.633333, numObservations: 2
action -1, numVisits=5479, meanQ=-0.255015, numObservations: 1
action 0, numVisits=3, meanQ=-131.554860, numObservations: 1
action: 2
Next state: 1 0.280683 0.123318 0.619271 0.877538 0.640872 0.891965 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 379
Initial state: 0 0.669227 0.899831 0.0385543 0.346819 0.64073 0.878506 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162423 episodes
GETTING ACTION FROM:
action 1, numVisits=153477, meanQ=4.980965, numObservations: 4
action 3, numVisits=8941, meanQ=4.921265, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.669227 0.899831 0.0385543 0.346819 0.64073 0.878506 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 380
Initial state: 0 0.561763 0.860301 0.707111 0.734842 0.523991 0.816381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95983 episodes
GETTING ACTION FROM:
action -1, numVisits=93138, meanQ=2.930777, numObservations: 1
action 0, numVisits=2832, meanQ=2.825639, numObservations: 1
action 1, numVisits=9, meanQ=-0.100000, numObservations: 3
action 2, numVisits=2, meanQ=-7.500000, numObservations: 1
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action: -1
Next state: 0 0.561763 0.860301 0.707111 0.734842 0.523991 0.816381 w: 1
Observation: 0 0.495202 0 0.710152 0 0.49626 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=93098, meanQ=4.988841, numObservations: 4
action 0, numVisits=22, meanQ=3.511893, numObservations: 1
action 1, numVisits=12, meanQ=2.977508, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 161959 episodes
GETTING ACTION FROM:
action 2, numVisits=255056, meanQ=5.171670, numObservations: 4
action 0, numVisits=23, meanQ=3.399224, numObservations: 1
action 1, numVisits=12, meanQ=2.977508, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.561763 0.860301 0.707111 0.734842 0.523991 0.816381 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 381
Initial state: 0 0.552228 0.898273 0.135078 0.751156 0.676403 0.807362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155925 episodes
GETTING ACTION FROM:
action 1, numVisits=154010, meanQ=4.938673, numObservations: 5
action 3, numVisits=1884, meanQ=4.749127, numObservations: 5
action 0, numVisits=25, meanQ=3.516581, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.552228 0.898273 0.135078 0.751156 0.676403 0.807362 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 382
Initial state: 0 0.579 0.811702 0.978889 0.11656 0.595995 0.804314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162922 episodes
GETTING ACTION FROM:
action 3, numVisits=162912, meanQ=4.958970, numObservations: 5
action -1, numVisits=4, meanQ=-2.502425, numObservations: 1
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 3
Next state: 1 0.579 0.811702 0.978889 0.11656 0.595995 0.804314 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 383
Initial state: 0 0.431571 0.541891 0.501407 0.889423 0.650773 0.865237 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162625 episodes
GETTING ACTION FROM:
action 1, numVisits=162541, meanQ=4.990288, numObservations: 5
action -1, numVisits=63, meanQ=4.116514, numObservations: 1
action 3, numVisits=16, meanQ=3.186888, numObservations: 4
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.431571 0.541891 0.501407 0.889423 0.650773 0.865237 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22945, meanQ=8.388209, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 13295 episodes
GETTING ACTION FROM:
action 3, numVisits=24628, meanQ=8.231130, numObservations: 4
action 2, numVisits=69, meanQ=5.580991, numObservations: 4
action 0, numVisits=11543, meanQ=0.247846, numObservations: 3
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action -1, numVisits=3, meanQ=-130.492204, numObservations: 1
action: 3
Next state: 1 0.431571 0.541891 0.501407 0.889423 0.650773 0.865237 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 384
Initial state: 0 0.500635 0.867015 0.52537 0.894087 0.640497 0.0926454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161979 episodes
GETTING ACTION FROM:
action 3, numVisits=161971, meanQ=4.935026, numObservations: 4
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.500635 0.867015 0.52537 0.894087 0.640497 0.0926454 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 385
Initial state: 0 0.613972 0.878728 0.62275 0.863584 0.372459 0.866104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162472 episodes
GETTING ACTION FROM:
action 1, numVisits=162322, meanQ=4.928168, numObservations: 4
action 0, numVisits=145, meanQ=2.531485, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.613972 0.878728 0.62275 0.863584 0.372459 0.866104 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 386
Initial state: 0 0.887138 0.673646 0.609437 0.892 0.580019 0.891595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95807 episodes
GETTING ACTION FROM:
action -1, numVisits=95798, meanQ=2.857767, numObservations: 1
action 3, numVisits=5, meanQ=-1.177980, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.887138 0.673646 0.609437 0.892 0.580019 0.891595 w: 1
Observation: 0 0.9784 0 0.693559 0 0.609243 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=95520, meanQ=4.936625, numObservations: 4
action 1, numVisits=268, meanQ=4.511364, numObservations: 4
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 163801 episodes
GETTING ACTION FROM:
action 2, numVisits=259316, meanQ=4.926194, numObservations: 4
action 1, numVisits=269, meanQ=4.500085, numObservations: 4
action 3, numVisits=9, meanQ=-2.111100, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.887138 0.673646 0.609437 0.892 0.580019 0.891595 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=18090, meanQ=4.692768, numObservations: 3
action 1, numVisits=1275, meanQ=4.288325, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 200216 episodes
GETTING ACTION FROM:
action 3, numVisits=218083, meanQ=5.562454, numObservations: 3
action 2, numVisits=225, meanQ=4.308342, numObservations: 5
action 1, numVisits=1275, meanQ=4.288325, numObservations: 5
action -1, numVisits=4, meanQ=-2.002475, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.887138 0.673646 0.609437 0.892 0.580019 0.891595 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 387
Initial state: 0 0.722125 0.180301 0.660679 0.80474 0.511846 0.892098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162092 episodes
GETTING ACTION FROM:
action 2, numVisits=162078, meanQ=4.979450, numObservations: 4
action 1, numVisits=9, meanQ=2.223344, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.722125 0.180301 0.660679 0.80474 0.511846 0.892098 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 388
Initial state: 0 0.679467 0.859404 0.547925 0.155013 0.660083 0.834681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163804 episodes
GETTING ACTION FROM:
action 3, numVisits=163738, meanQ=5.024890, numObservations: 4
action 0, numVisits=45, meanQ=3.972942, numObservations: 1
action -1, numVisits=15, meanQ=2.903519, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action: 3
Next state: 1 0.679467 0.859404 0.547925 0.155013 0.660083 0.834681 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 389
Initial state: 0 0.551708 0.892923 0.768338 0.448798 0.637642 0.809235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161521 episodes
GETTING ACTION FROM:
action 1, numVisits=161499, meanQ=5.135934, numObservations: 5
action 3, numVisits=17, meanQ=3.117071, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.551708 0.892923 0.768338 0.448798 0.637642 0.809235 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 390
Initial state: 0 0.641838 0.696305 0.519722 0.876851 0.520041 0.824824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161492 episodes
GETTING ACTION FROM:
action 1, numVisits=161429, meanQ=4.955165, numObservations: 4
action 0, numVisits=59, meanQ=4.060417, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.641838 0.696305 0.519722 0.876851 0.520041 0.824824 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 391
Initial state: 0 0.260208 0.649849 0.584352 0.862609 0.602371 0.818899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153411 episodes
GETTING ACTION FROM:
action 2, numVisits=152753, meanQ=4.863040, numObservations: 4
action -1, numVisits=637, meanQ=3.666450, numObservations: 1
action 3, numVisits=10, meanQ=1.799000, numObservations: 4
action 1, numVisits=9, meanQ=0.456667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.260208 0.649849 0.584352 0.862609 0.602371 0.818899 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 392
Initial state: 0 0.692292 0.851097 0.440376 0.670602 0.612532 0.879024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161737 episodes
GETTING ACTION FROM:
action 1, numVisits=161598, meanQ=4.994008, numObservations: 5
action 2, numVisits=114, meanQ=4.070177, numObservations: 4
action 0, numVisits=17, meanQ=3.291555, numObservations: 1
action 3, numVisits=6, meanQ=2.168350, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.692292 0.851097 0.440376 0.670602 0.612532 0.879024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 393
Initial state: 0 0.508461 0.877844 0.532129 0.871989 0.286609 0.249515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163551 episodes
GETTING ACTION FROM:
action 2, numVisits=163394, meanQ=5.005684, numObservations: 4
action -1, numVisits=117, meanQ=4.373424, numObservations: 1
action 0, numVisits=36, meanQ=3.866922, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.508461 0.877844 0.532129 0.871989 0.286609 0.249515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 394
Initial state: 0 0.18521 0.948052 0.689427 0.8587 0.525463 0.827343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161152 episodes
GETTING ACTION FROM:
action 1, numVisits=160910, meanQ=4.925795, numObservations: 4
action 3, numVisits=236, meanQ=4.290669, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.18521 0.948052 0.689427 0.8587 0.525463 0.827343 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11727, meanQ=4.731644, numObservations: 3
action 0, numVisits=53, meanQ=3.843314, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 200080 episodes
GETTING ACTION FROM:
action 2, numVisits=211804, meanQ=5.890518, numObservations: 3
action 0, numVisits=54, meanQ=3.810292, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.18521 0.948052 0.689427 0.8587 0.525463 0.827343 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=5167, meanQ=3.929720, numObservations: 3
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 206714 episodes
GETTING ACTION FROM:
action 2, numVisits=206666, meanQ=5.275662, numObservations: 4
action 3, numVisits=52, meanQ=4.307308, numObservations: 4
action 1, numVisits=5167, meanQ=3.929720, numObservations: 3
action -1, numVisits=3, meanQ=-2.003300, numObservations: 1
action 0, numVisits=3, meanQ=-2.003300, numObservations: 1
action: 2
Next state: 0 0.18521 0.948052 0.689427 0.8587 0.525463 0.827343 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=651, meanQ=6.859668, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 212109 episodes
GETTING ACTION FROM:
action 1, numVisits=210594, meanQ=5.852575, numObservations: 4
action 2, numVisits=2141, meanQ=5.708655, numObservations: 4
action 3, numVisits=23, meanQ=2.913043, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 1
Next state: 1 0.18521 0.948052 0.689427 0.8587 0.525463 0.827343 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 395
Initial state: 0 0.352013 0.380192 0.562324 0.898162 0.602928 0.866897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161785 episodes
GETTING ACTION FROM:
action 1, numVisits=161235, meanQ=4.913086, numObservations: 5
action -1, numVisits=316, meanQ=3.130213, numObservations: 1
action 0, numVisits=231, meanQ=3.080182, numObservations: 1
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.352013 0.380192 0.562324 0.898162 0.602928 0.866897 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8173, meanQ=7.803132, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22304 episodes
GETTING ACTION FROM:
action 3, numVisits=8173, meanQ=7.803132, numObservations: 4
action 2, numVisits=22, meanQ=5.999550, numObservations: 4
action 1, numVisits=3, meanQ=4.996667, numObservations: 3
action -1, numVisits=22254, meanQ=0.063900, numObservations: 1
action 0, numVisits=30, meanQ=-1.109330, numObservations: 1
action: 3
Next state: 1 0.352013 0.380192 0.562324 0.898162 0.602928 0.866897 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 396
Initial state: 0 0.547666 0.897352 0.0696879 0.96297 0.612194 0.862575 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160919 episodes
GETTING ACTION FROM:
action 1, numVisits=160868, meanQ=4.922182, numObservations: 4
action 3, numVisits=43, meanQ=3.716058, numObservations: 4
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.547666 0.897352 0.0696879 0.96297 0.612194 0.862575 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 397
Initial state: 0 0.617789 0.88361 0.512277 0.852755 0.980995 0.889058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163472 episodes
GETTING ACTION FROM:
action 1, numVisits=163361, meanQ=5.049470, numObservations: 5
action 2, numVisits=104, meanQ=3.808221, numObservations: 4
action 3, numVisits=3, meanQ=-0.700000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.617789 0.88361 0.512277 0.852755 0.980995 0.889058 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 398
Initial state: 0 0.568396 0.877275 0.671369 0.866756 0.726058 0.413927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163007 episodes
GETTING ACTION FROM:
action 2, numVisits=162984, meanQ=5.024641, numObservations: 5
action 3, numVisits=9, meanQ=2.668922, numObservations: 2
action 1, numVisits=10, meanQ=2.598000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.568396 0.877275 0.671369 0.866756 0.726058 0.413927 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 399
Initial state: 0 0.277474 0.459105 0.511948 0.894202 0.531006 0.84646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163276 episodes
GETTING ACTION FROM:
action 2, numVisits=123359, meanQ=4.995411, numObservations: 4
action 3, numVisits=39851, meanQ=4.934874, numObservations: 5
action -1, numVisits=57, meanQ=4.087863, numObservations: 1
action 1, numVisits=7, meanQ=2.002871, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.277474 0.459105 0.511948 0.894202 0.531006 0.84646 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 400
Initial state: 0 0.587266 0.815403 0.550744 0.862265 0.616207 0.934185 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91771 episodes
GETTING ACTION FROM:
action 0, numVisits=91722, meanQ=5.280009, numObservations: 3
action 1, numVisits=31, meanQ=2.160652, numObservations: 4
action 2, numVisits=13, meanQ=1.530785, numObservations: 3
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.587266 0.815403 0.550744 0.862265 0.616207 0.934185 w: 1
Observation: 0 0 0.745728 0 0.801624 0 0.949683 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=41574, meanQ=7.421144, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 166088 episodes
GETTING ACTION FROM:
action 3, numVisits=207659, meanQ=5.833559, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.587266 0.815403 0.550744 0.862265 0.616207 0.934185 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 401
Initial state: 0 0.555226 0.870801 0.619112 0.850503 0.10021 0.0316699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162745 episodes
GETTING ACTION FROM:
action 3, numVisits=162730, meanQ=5.003298, numObservations: 4
action 1, numVisits=10, meanQ=2.499000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.555226 0.870801 0.619112 0.850503 0.10021 0.0316699 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10168, meanQ=8.545153, numObservations: 3
action 2, numVisits=8544, meanQ=8.534590, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9945 episodes
GETTING ACTION FROM:
action 1, numVisits=10168, meanQ=8.545153, numObservations: 3
action 2, numVisits=8580, meanQ=8.529663, numObservations: 5
action -1, numVisits=9904, meanQ=0.321061, numObservations: 1
action 0, numVisits=7, meanQ=-2.144257, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.555226 0.870801 0.619112 0.850503 0.10021 0.0316699 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 402
Initial state: 0 0.715167 0.645823 0.628103 0.898888 0.676007 0.858556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162994 episodes
GETTING ACTION FROM:
action 1, numVisits=162935, meanQ=5.005993, numObservations: 5
action 0, numVisits=45, meanQ=3.966787, numObservations: 1
action -1, numVisits=11, meanQ=2.877550, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.715167 0.645823 0.628103 0.898888 0.676007 0.858556 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 403
Initial state: 0 0.625736 0.890027 0.472545 0.665974 0.678328 0.87177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162877 episodes
GETTING ACTION FROM:
action 2, numVisits=162869, meanQ=5.037641, numObservations: 5
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.625736 0.890027 0.472545 0.665974 0.678328 0.87177 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=22825, meanQ=8.437467, numObservations: 4
action 3, numVisits=8, meanQ=5.997500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 5569 episodes
GETTING ACTION FROM:
action 1, numVisits=22825, meanQ=8.437467, numObservations: 4
action 3, numVisits=47, meanQ=6.699787, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=5503, meanQ=0.148566, numObservations: 1
action 0, numVisits=28, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.625736 0.890027 0.472545 0.665974 0.678328 0.87177 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 404
Initial state: 0 0.610306 0.86853 0.527569 0.642558 0.559573 0.892314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160172 episodes
GETTING ACTION FROM:
action 3, numVisits=160096, meanQ=4.932955, numObservations: 4
action 0, numVisits=33, meanQ=3.739193, numObservations: 1
action -1, numVisits=24, meanQ=3.457520, numObservations: 1
action 2, numVisits=17, meanQ=2.582353, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 1 0.610306 0.86853 0.527569 0.642558 0.559573 0.892314 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 405
Initial state: 0 0.539828 0.831295 0.616409 0.818782 0.88797 0.799093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95776 episodes
GETTING ACTION FROM:
action -1, numVisits=95760, meanQ=2.892137, numObservations: 1
action 2, numVisits=11, meanQ=0.455464, numObservations: 4
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.539828 0.831295 0.616409 0.818782 0.88797 0.799093 w: 1
Observation: 0 0.561324 0 0.594403 0 0.946792 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=95718, meanQ=4.974337, numObservations: 5
action 0, numVisits=20, meanQ=3.441464, numObservations: 1
action -1, numVisits=16, meanQ=2.967558, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 165337 episodes
GETTING ACTION FROM:
action 3, numVisits=261053, meanQ=4.855783, numObservations: 5
action 0, numVisits=22, meanQ=3.228155, numObservations: 1
action -1, numVisits=16, meanQ=2.967558, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.539828 0.831295 0.616409 0.818782 0.88797 0.799093 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 406
Initial state: 0 0.273561 0.155829 0.603008 0.880935 0.570394 0.837097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162668 episodes
GETTING ACTION FROM:
action 2, numVisits=162558, meanQ=4.952241, numObservations: 5
action -1, numVisits=68, meanQ=4.125950, numObservations: 1
action 1, numVisits=22, meanQ=2.954550, numObservations: 4
action 0, numVisits=14, meanQ=2.779025, numObservations: 1
action 3, numVisits=6, meanQ=1.498333, numObservations: 3
action: 2
Next state: 0 0.273561 0.155829 0.603008 0.880935 0.570394 0.837097 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=11789, meanQ=4.847896, numObservations: 5
action -1, numVisits=116, meanQ=2.413612, numObservations: 1
action 0, numVisits=43, meanQ=2.107059, numObservations: 1
action 3, numVisits=15, meanQ=1.532013, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 201202 episodes
GETTING ACTION FROM:
action 1, numVisits=212986, meanQ=5.797982, numObservations: 5
action -1, numVisits=116, meanQ=2.413612, numObservations: 1
action 2, numVisits=6, meanQ=2.168350, numObservations: 3
action 0, numVisits=43, meanQ=2.107059, numObservations: 1
action 3, numVisits=15, meanQ=1.532013, numObservations: 4
action: 1
Next state: 0 0.273561 0.155829 0.603008 0.880935 0.570394 0.837097 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=3930, meanQ=8.380697, numObservations: 3
action 2, numVisits=3, meanQ=4.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 23224 episodes
GETTING ACTION FROM:
action 3, numVisits=3930, meanQ=8.380697, numObservations: 3
action 2, numVisits=216, meanQ=6.196731, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=16788, meanQ=-1.650836, numObservations: 1
action 0, numVisits=6222, meanQ=-1.684797, numObservations: 1
action: 3
Next state: 1 0.273561 0.155829 0.603008 0.880935 0.570394 0.837097 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 407
Initial state: 0 0.623217 0.841869 0.771113 0.209735 0.588443 0.811727 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162281 episodes
GETTING ACTION FROM:
action 3, numVisits=162269, meanQ=4.966120, numObservations: 5
action 1, numVisits=7, meanQ=0.711443, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.623217 0.841869 0.771113 0.209735 0.588443 0.811727 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 408
Initial state: 0 0.544343 0.827416 0.584637 0.878452 0.27136 0.641813 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162604 episodes
GETTING ACTION FROM:
action 3, numVisits=162597, meanQ=5.036694, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.544343 0.827416 0.584637 0.878452 0.27136 0.641813 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=21716, meanQ=8.430711, numObservations: 5
action 1, numVisits=823, meanQ=8.170702, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10938 episodes
GETTING ACTION FROM:
action 2, numVisits=21716, meanQ=8.430711, numObservations: 5
action 1, numVisits=823, meanQ=8.170702, numObservations: 4
action 3, numVisits=10, meanQ=5.390000, numObservations: 3
action -1, numVisits=10925, meanQ=0.275505, numObservations: 1
action 0, numVisits=6, meanQ=-3.044478, numObservations: 1
action: 2
Next state: 0 0.544343 0.827416 0.584637 0.878452 0.27136 0.641813 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1773, meanQ=8.472336, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34475 episodes
GETTING ACTION FROM:
action 2, numVisits=1773, meanQ=8.472336, numObservations: 3
action 1, numVisits=664, meanQ=6.351169, numObservations: 4
action -1, numVisits=19861, meanQ=-1.637134, numObservations: 1
action 0, numVisits=13953, meanQ=-1.651269, numObservations: 1
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 2
Next state: 1 0.544343 0.827416 0.584637 0.878452 0.27136 0.641813 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 409
Initial state: 0 0.695764 0.425973 0.537281 0.873463 0.637506 0.895413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164494 episodes
GETTING ACTION FROM:
action 3, numVisits=164486, meanQ=5.049550, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 3
Next state: 1 0.695764 0.425973 0.537281 0.873463 0.637506 0.895413 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 410
Initial state: 0 0.639764 0.869301 0.0802168 0.507486 0.544209 0.858505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162485 episodes
GETTING ACTION FROM:
action 3, numVisits=162358, meanQ=5.123034, numObservations: 4
action -1, numVisits=109, meanQ=4.453196, numObservations: 1
action 0, numVisits=16, meanQ=3.366894, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.639764 0.869301 0.0802168 0.507486 0.544209 0.858505 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 411
Initial state: 0 0.632572 0.873451 0.603828 0.82913 0.456077 0.394977 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162552 episodes
GETTING ACTION FROM:
action 1, numVisits=161572, meanQ=4.983134, numObservations: 4
action 0, numVisits=976, meanQ=2.660878, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.632572 0.873451 0.603828 0.82913 0.456077 0.394977 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 412
Initial state: 0 0.668345 0.602103 0.693543 0.851728 0.567147 0.829163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163058 episodes
GETTING ACTION FROM:
action 1, numVisits=163051, meanQ=5.005004, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.668345 0.602103 0.693543 0.851728 0.567147 0.829163 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 413
Initial state: 0 0.556085 0.832665 0.623554 0.853152 0.623801 0.931594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162188 episodes
GETTING ACTION FROM:
action 3, numVisits=162129, meanQ=4.956362, numObservations: 5
action 0, numVisits=54, meanQ=4.021404, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.556085 0.832665 0.623554 0.853152 0.623801 0.931594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 414
Initial state: 0 0.646752 0.856308 0.540331 0.862265 0.811611 0.40426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160866 episodes
GETTING ACTION FROM:
action 1, numVisits=160857, meanQ=4.957192, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=4, meanQ=-2.500000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.646752 0.856308 0.540331 0.862265 0.811611 0.40426 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 415
Initial state: 0 0.607395 0.857891 0.626433 0.899483 0.252125 0.0102877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162575 episodes
GETTING ACTION FROM:
action 2, numVisits=162566, meanQ=4.969551, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.607395 0.857891 0.626433 0.899483 0.252125 0.0102877 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 416
Initial state: 0 0.553144 0.898907 0.689398 0.872459 0.410173 0.370394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161602 episodes
GETTING ACTION FROM:
action 3, numVisits=161594, meanQ=4.923711, numObservations: 4
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.553144 0.898907 0.689398 0.872459 0.410173 0.370394 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10658, meanQ=8.387597, numObservations: 4
action 1, numVisits=11939, meanQ=8.385268, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10281 episodes
GETTING ACTION FROM:
action 2, numVisits=10658, meanQ=8.387597, numObservations: 4
action 1, numVisits=11939, meanQ=8.385268, numObservations: 5
action 3, numVisits=10, meanQ=4.399010, numObservations: 2
action 0, numVisits=10266, meanQ=0.198424, numObservations: 1
action -1, numVisits=8, meanQ=-2.126225, numObservations: 1
action: 2
Next state: 1 0.553144 0.898907 0.689398 0.872459 0.410173 0.370394 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 417
Initial state: 0 0.652559 0.864792 0.564472 0.836992 0.296059 0.872863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154276 episodes
GETTING ACTION FROM:
action 3, numVisits=154265, meanQ=4.852275, numObservations: 3
action 2, numVisits=4, meanQ=0.750000, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.652559 0.864792 0.564472 0.836992 0.296059 0.872863 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25349, meanQ=8.338512, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 13940 episodes
GETTING ACTION FROM:
action 2, numVisits=25349, meanQ=8.338512, numObservations: 3
action 1, numVisits=17, meanQ=4.764118, numObservations: 4
action -1, numVisits=13924, meanQ=0.461775, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 0, numVisits=2, meanQ=-196.528775, numObservations: 1
action: 2
Next state: 1 0.652559 0.864792 0.564472 0.836992 0.296059 0.872863 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 418
Initial state: 0 0.646661 0.825092 0.624714 0.184185 0.649786 0.8007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161420 episodes
GETTING ACTION FROM:
action 3, numVisits=161365, meanQ=4.916170, numObservations: 5
action -1, numVisits=51, meanQ=3.931873, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.646661 0.825092 0.624714 0.184185 0.649786 0.8007 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 419
Initial state: 0 0.511756 0.818134 0.928037 0.762931 0.694654 0.822835 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159354 episodes
GETTING ACTION FROM:
action 2, numVisits=159332, meanQ=4.876408, numObservations: 4
action 3, numVisits=13, meanQ=1.993085, numObservations: 4
action 1, numVisits=5, meanQ=0.604020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.511756 0.818134 0.928037 0.762931 0.694654 0.822835 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 420
Initial state: 0 0.642523 0.83931 0.455452 0.969451 0.545318 0.83527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161588 episodes
GETTING ACTION FROM:
action 2, numVisits=161579, meanQ=5.023585, numObservations: 4
action 3, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.642523 0.83931 0.455452 0.969451 0.545318 0.83527 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11961, meanQ=5.744891, numObservations: 4
action 1, numVisits=5, meanQ=-1.402000, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 181075 episodes
GETTING ACTION FROM:
action 2, numVisits=192980, meanQ=5.152604, numObservations: 5
action 1, numVisits=43, meanQ=4.069535, numObservations: 4
action 3, numVisits=19, meanQ=2.211584, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.642523 0.83931 0.455452 0.969451 0.545318 0.83527 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2450, meanQ=8.260625, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 32512 episodes
GETTING ACTION FROM:
action 3, numVisits=16613, meanQ=6.395891, numObservations: 4
action 1, numVisits=5158, meanQ=6.038439, numObservations: 4
action 2, numVisits=19, meanQ=5.894216, numObservations: 4
action 0, numVisits=12732, meanQ=-0.621294, numObservations: 1
action -1, numVisits=445, meanQ=-0.881188, numObservations: 1
action: 3
Next state: 1 0.642523 0.83931 0.455452 0.969451 0.545318 0.83527 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 421
Initial state: 0 0.866975 0.584154 0.523068 0.833005 0.586994 0.8344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161665 episodes
GETTING ACTION FROM:
action 2, numVisits=161413, meanQ=4.961159, numObservations: 4
action 0, numVisits=26, meanQ=3.600895, numObservations: 1
action -1, numVisits=216, meanQ=3.515378, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action: 2
Next state: 1 0.866975 0.584154 0.523068 0.833005 0.586994 0.8344 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 422
Initial state: 0 0.598488 0.838742 0.0544601 0.624765 0.665441 0.861074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158907 episodes
GETTING ACTION FROM:
action 2, numVisits=152844, meanQ=5.006111, numObservations: 5
action -1, numVisits=6055, meanQ=3.097898, numObservations: 1
action 3, numVisits=5, meanQ=-0.200000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.598488 0.838742 0.0544601 0.624765 0.665441 0.861074 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7675, meanQ=7.828178, numObservations: 3
action 3, numVisits=6, meanQ=4.665017, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 4063 episodes
GETTING ACTION FROM:
action 1, numVisits=7675, meanQ=7.828178, numObservations: 3
action 2, numVisits=3, meanQ=4.996667, numObservations: 3
action 3, numVisits=64, meanQ=4.218595, numObservations: 3
action -1, numVisits=3989, meanQ=-0.036881, numObservations: 1
action 0, numVisits=16, meanQ=-2.188100, numObservations: 1
action: 1
Next state: 1 0.598488 0.838742 0.0544601 0.624765 0.665441 0.861074 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 423
Initial state: 0 0.512439 0.874582 0.599304 0.817106 0.945576 0.650189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153998 episodes
GETTING ACTION FROM:
action 2, numVisits=153990, meanQ=4.877464, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.512439 0.874582 0.599304 0.817106 0.945576 0.650189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 424
Initial state: 0 0.638334 0.802386 0.506497 0.135079 0.652629 0.895775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161822 episodes
GETTING ACTION FROM:
action 2, numVisits=161816, meanQ=4.939124, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.638334 0.802386 0.506497 0.135079 0.652629 0.895775 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 425
Initial state: 0 0.512181 0.836023 0.568503 0.834586 0.760669 0.146781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162307 episodes
GETTING ACTION FROM:
action 1, numVisits=161976, meanQ=5.024647, numObservations: 5
action 2, numVisits=324, meanQ=4.640530, numObservations: 5
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.512181 0.836023 0.568503 0.834586 0.760669 0.146781 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=839, meanQ=7.304399, numObservations: 3
action 3, numVisits=7, meanQ=4.427143, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 8376 episodes
GETTING ACTION FROM:
action 1, numVisits=839, meanQ=7.304399, numObservations: 3
action 2, numVisits=54, meanQ=6.425743, numObservations: 4
action 3, numVisits=13, meanQ=3.460769, numObservations: 3
action 0, numVisits=8310, meanQ=0.315835, numObservations: 1
action -1, numVisits=10, meanQ=-2.100980, numObservations: 1
action: 1
Next state: 1 0.512181 0.836023 0.568503 0.834586 0.760669 0.146781 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 426
Initial state: 0 0.90102 0.418802 0.578211 0.85847 0.55374 0.879215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162582 episodes
GETTING ACTION FROM:
action 1, numVisits=162446, meanQ=5.012030, numObservations: 5
action 0, numVisits=132, meanQ=4.416602, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.90102 0.418802 0.578211 0.85847 0.55374 0.879215 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 427
Initial state: 0 0.564356 0.890483 0.35557 0.711354 0.599251 0.812078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157980 episodes
GETTING ACTION FROM:
action 3, numVisits=157927, meanQ=4.873744, numObservations: 4
action -1, numVisits=36, meanQ=3.670185, numObservations: 1
action 1, numVisits=14, meanQ=2.927857, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.564356 0.890483 0.35557 0.711354 0.599251 0.812078 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 428
Initial state: 0 0.549897 0.804938 0.519024 0.896749 0.469978 0.516441 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163132 episodes
GETTING ACTION FROM:
action 2, numVisits=163126, meanQ=4.986604, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.549897 0.804938 0.519024 0.896749 0.469978 0.516441 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 429
Initial state: 0 0.643084 0.829783 0.642428 0.835101 0.70331 0.238065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162918 episodes
GETTING ACTION FROM:
action 1, numVisits=162660, meanQ=5.025501, numObservations: 4
action 0, numVisits=68, meanQ=4.197335, numObservations: 1
action 3, numVisits=181, meanQ=4.040605, numObservations: 4
action 2, numVisits=7, meanQ=2.285729, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.643084 0.829783 0.642428 0.835101 0.70331 0.238065 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 430
Initial state: 0 0.595631 0.855598 0.56907 0.84642 0.733885 0.388037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94447 episodes
GETTING ACTION FROM:
action 0, numVisits=94432, meanQ=2.857976, numObservations: 1
action 3, numVisits=5, meanQ=-0.399980, numObservations: 3
action 2, numVisits=4, meanQ=-1.494975, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=4, meanQ=-2.500000, numObservations: 2
action: 0
Next state: 0 0.595631 0.855598 0.56907 0.84642 0.733885 0.388037 w: 1
Observation: 0 0 0.832072 0 0.826116 0 0.413899 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=94374, meanQ=4.938955, numObservations: 4
action 3, numVisits=51, meanQ=3.510406, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 161320 episodes
GETTING ACTION FROM:
action 2, numVisits=255683, meanQ=5.068668, numObservations: 4
action 3, numVisits=51, meanQ=3.510406, numObservations: 4
action 1, numVisits=13, meanQ=2.693854, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.595631 0.855598 0.56907 0.84642 0.733885 0.388037 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 431
Initial state: 0 0.520939 0.864672 0.662869 0.810378 0.153888 0.323354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162101 episodes
GETTING ACTION FROM:
action 2, numVisits=162058, meanQ=4.976945, numObservations: 4
action 0, numVisits=22, meanQ=3.310660, numObservations: 1
action 1, numVisits=8, meanQ=2.375000, numObservations: 2
action 3, numVisits=11, meanQ=1.908182, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.520939 0.864672 0.662869 0.810378 0.153888 0.323354 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 432
Initial state: 0 0.819088 0.0510773 0.657624 0.872002 0.52039 0.849144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161417 episodes
GETTING ACTION FROM:
action 3, numVisits=161401, meanQ=4.960211, numObservations: 4
action 2, numVisits=9, meanQ=1.776667, numObservations: 4
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.819088 0.0510773 0.657624 0.872002 0.52039 0.849144 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 433
Initial state: 0 0.698247 0.838996 0.527386 0.87889 0.144415 0.0634015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162212 episodes
GETTING ACTION FROM:
action 1, numVisits=162166, meanQ=4.954578, numObservations: 4
action 0, numVisits=34, meanQ=3.692567, numObservations: 1
action 2, numVisits=6, meanQ=1.498333, numObservations: 3
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.698247 0.838996 0.527386 0.87889 0.144415 0.0634015 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 434
Initial state: 0 0.275342 0.051455 0.639912 0.848721 0.671453 0.875819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162786 episodes
GETTING ACTION FROM:
action 2, numVisits=162701, meanQ=5.002963, numObservations: 5
action -1, numVisits=68, meanQ=2.202587, numObservations: 1
action 1, numVisits=14, meanQ=1.215729, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.275342 0.051455 0.639912 0.848721 0.671453 0.875819 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11941, meanQ=5.508176, numObservations: 4
action 1, numVisits=35, meanQ=4.194300, numObservations: 4
action 3, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 200479 episodes
GETTING ACTION FROM:
action 3, numVisits=190786, meanQ=6.241420, numObservations: 5
action 2, numVisits=21635, meanQ=5.279716, numObservations: 4
action 1, numVisits=35, meanQ=4.194300, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.275342 0.051455 0.639912 0.848721 0.671453 0.875819 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 435
Initial state: 0 0.692075 0.84966 0.301698 0.804825 0.593228 0.869349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163044 episodes
GETTING ACTION FROM:
action 3, numVisits=163034, meanQ=5.002834, numObservations: 3
action 1, numVisits=5, meanQ=0.604020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.692075 0.84966 0.301698 0.804825 0.593228 0.869349 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 436
Initial state: 0 0.137163 0.506675 0.651596 0.873938 0.648114 0.830652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163029 episodes
GETTING ACTION FROM:
action 3, numVisits=163018, meanQ=4.991650, numObservations: 4
action 1, numVisits=6, meanQ=0.836683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.137163 0.506675 0.651596 0.873938 0.648114 0.830652 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 437
Initial state: 0 0.572076 0.8249 0.541591 0.872487 0.426322 0.696467 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162993 episodes
GETTING ACTION FROM:
action 3, numVisits=162949, meanQ=5.161748, numObservations: 5
action 1, numVisits=21, meanQ=3.046676, numObservations: 4
action 2, numVisits=11, meanQ=2.999100, numObservations: 3
action 0, numVisits=10, meanQ=2.942575, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.572076 0.8249 0.541591 0.872487 0.426322 0.696467 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=18650, meanQ=8.523077, numObservations: 3
action 2, numVisits=64, meanQ=7.741981, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6802 episodes
GETTING ACTION FROM:
action 1, numVisits=18650, meanQ=8.523077, numObservations: 3
action 2, numVisits=96, meanQ=6.929904, numObservations: 4
action 3, numVisits=25, meanQ=4.519600, numObservations: 3
action 0, numVisits=6737, meanQ=0.082522, numObservations: 1
action -1, numVisits=11, meanQ=-3.208443, numObservations: 1
action: 1
Next state: 1 0.572076 0.8249 0.541591 0.872487 0.426322 0.696467 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 438
Initial state: 0 0.67801 0.874126 0.0872217 0.699885 0.563761 0.888813 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161778 episodes
GETTING ACTION FROM:
action 1, numVisits=161765, meanQ=5.013059, numObservations: 3
action 3, numVisits=7, meanQ=1.428571, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 1
Next state: 1 0.67801 0.874126 0.0872217 0.699885 0.563761 0.888813 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 439
Initial state: 0 0.679378 0.805938 0.619049 0.861149 0.902641 0.352284 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162790 episodes
GETTING ACTION FROM:
action 2, numVisits=162775, meanQ=5.134221, numObservations: 4
action 1, numVisits=10, meanQ=2.492010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.679378 0.805938 0.619049 0.861149 0.902641 0.352284 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 440
Initial state: 0 0.199504 0.256707 0.544182 0.832346 0.510777 0.815252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132683 episodes
GETTING ACTION FROM:
action 1, numVisits=89382, meanQ=4.985167, numObservations: 5
action 0, numVisits=43290, meanQ=3.029851, numObservations: 1
action 2, numVisits=8, meanQ=-0.248737, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.199504 0.256707 0.544182 0.832346 0.510777 0.815252 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=12601, meanQ=8.389749, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 20663 episodes
GETTING ACTION FROM:
action 3, numVisits=12601, meanQ=8.389749, numObservations: 4
action 2, numVisits=32, meanQ=5.976738, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action 0, numVisits=20631, meanQ=0.121318, numObservations: 1
action -1, numVisits=3, meanQ=-130.961398, numObservations: 1
action: 3
Next state: 1 0.199504 0.256707 0.544182 0.832346 0.510777 0.815252 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 441
Initial state: 0 0.670004 0.816219 0.100897 0.140974 0.590253 0.802344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162818 episodes
GETTING ACTION FROM:
action 3, numVisits=162727, meanQ=4.943921, numObservations: 4
action -1, numVisits=83, meanQ=4.169233, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.670004 0.816219 0.100897 0.140974 0.590253 0.802344 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 442
Initial state: 0 0.554081 0.872632 0.511608 0.877793 0.472323 0.600009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162689 episodes
GETTING ACTION FROM:
action 2, numVisits=162585, meanQ=4.943621, numObservations: 5
action 0, numVisits=92, meanQ=4.236004, numObservations: 1
action 3, numVisits=7, meanQ=2.002871, numObservations: 4
action 1, numVisits=3, meanQ=-0.659967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.554081 0.872632 0.511608 0.877793 0.472323 0.600009 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 443
Initial state: 0 0.533028 0.840099 0.570917 0.846355 0.037337 0.756871 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162772 episodes
GETTING ACTION FROM:
action 1, numVisits=162763, meanQ=4.962576, numObservations: 3
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.533028 0.840099 0.570917 0.846355 0.037337 0.756871 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 444
Initial state: 0 0.584488 0.825398 0.908567 0.486819 0.511439 0.83493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95928 episodes
GETTING ACTION FROM:
action 0, numVisits=95921, meanQ=2.958978, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=2, meanQ=-5.489950, numObservations: 1
action: 0
Next state: 0 0.584488 0.825398 0.908567 0.486819 0.511439 0.83493 w: 1
Observation: 0 0 0.880561 0 0.52254 0 0.891097 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=95695, meanQ=4.967617, numObservations: 3
action 3, numVisits=203, meanQ=4.495639, numObservations: 5
action -1, numVisits=17, meanQ=3.055702, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 165081 episodes
GETTING ACTION FROM:
action 2, numVisits=260775, meanQ=5.187911, numObservations: 3
action 3, numVisits=203, meanQ=4.495639, numObservations: 5
action -1, numVisits=18, meanQ=2.774761, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.584488 0.825398 0.908567 0.486819 0.511439 0.83493 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 445
Initial state: 0 0.528058 0.860453 0.69712 0.82728 0.0397495 0.791718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161337 episodes
GETTING ACTION FROM:
action 1, numVisits=160755, meanQ=4.987319, numObservations: 4
action 3, numVisits=403, meanQ=4.513301, numObservations: 4
action 0, numVisits=104, meanQ=4.234118, numObservations: 1
action -1, numVisits=74, meanQ=4.115714, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.528058 0.860453 0.69712 0.82728 0.0397495 0.791718 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 446
Initial state: 0 0.65885 0.865886 0.853266 0.49378 0.573199 0.890744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161374 episodes
GETTING ACTION FROM:
action 1, numVisits=161326, meanQ=4.943305, numObservations: 3
action 0, numVisits=35, meanQ=3.779504, numObservations: 1
action 3, numVisits=9, meanQ=1.782244, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.65885 0.865886 0.853266 0.49378 0.573199 0.890744 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 447
Initial state: 0 0.580699 0.892843 0.62742 0.83625 0.742258 0.0982556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160564 episodes
GETTING ACTION FROM:
action 1, numVisits=160389, meanQ=4.992882, numObservations: 5
action 0, numVisits=168, meanQ=4.472745, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.580699 0.892843 0.62742 0.83625 0.742258 0.0982556 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 448
Initial state: 0 0.666971 0.803538 0.594309 0.854534 0.443409 0.483806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162632 episodes
GETTING ACTION FROM:
action 2, numVisits=162551, meanQ=5.049031, numObservations: 5
action 0, numVisits=50, meanQ=4.048941, numObservations: 1
action 3, numVisits=28, meanQ=3.710007, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.666971 0.803538 0.594309 0.854534 0.443409 0.483806 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 449
Initial state: 0 0.671042 0.893386 0.538899 0.886894 0.26948 0.58387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163079 episodes
GETTING ACTION FROM:
action 2, numVisits=162974, meanQ=5.022239, numObservations: 4
action 0, numVisits=93, meanQ=4.300993, numObservations: 1
action 3, numVisits=9, meanQ=2.223344, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.671042 0.893386 0.538899 0.886894 0.26948 0.58387 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 450
Initial state: 0 0.504664 0.839373 0.511966 0.887812 0.374495 0.770573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 106469 episodes
GETTING ACTION FROM:
action 0, numVisits=94240, meanQ=5.968969, numObservations: 3
action 3, numVisits=12221, meanQ=5.069532, numObservations: 3
action 2, numVisits=4, meanQ=0.750000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.504664 0.839373 0.511966 0.887812 0.374495 0.770573 w: 1
Observation: 0 0 0.770434 0 0.821533 0 0.689558 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=30354, meanQ=8.150828, numObservations: 3
action 2, numVisits=3, meanQ=2.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 167770 episodes
GETTING ACTION FROM:
action 1, numVisits=198057, meanQ=5.534442, numObservations: 3
action -1, numVisits=48, meanQ=4.527867, numObservations: 1
action 3, numVisits=18, meanQ=3.206122, numObservations: 2
action 2, numVisits=5, meanQ=1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.504664 0.839373 0.511966 0.887812 0.374495 0.770573 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=16240, meanQ=5.843505, numObservations: 4
action 1, numVisits=7, meanQ=3.285714, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 201652 episodes
GETTING ACTION FROM:
action 2, numVisits=217860, meanQ=6.222794, numObservations: 4
action 3, numVisits=23, meanQ=4.390874, numObservations: 3
action 1, numVisits=13, meanQ=1.846154, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 2
Next state: 1 0.504664 0.839373 0.511966 0.887812 0.374495 0.770573 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 451
Initial state: 0 0.785896 0.730125 0.604491 0.859952 0.605953 0.868139 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153447 episodes
GETTING ACTION FROM:
action 3, numVisits=153301, meanQ=4.756354, numObservations: 4
action -1, numVisits=139, meanQ=4.185167, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.785896 0.730125 0.604491 0.859952 0.605953 0.868139 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 452
Initial state: 0 0.132372 0.389134 0.630827 0.827624 0.615319 0.882192 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163164 episodes
GETTING ACTION FROM:
action 3, numVisits=163047, meanQ=4.973384, numObservations: 5
action -1, numVisits=79, meanQ=4.196822, numObservations: 1
action 2, numVisits=17, meanQ=3.292941, numObservations: 3
action 1, numVisits=19, meanQ=3.253700, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.132372 0.389134 0.630827 0.827624 0.615319 0.882192 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 453
Initial state: 0 0.153515 0.947029 0.527294 0.884605 0.560498 0.817489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154395 episodes
GETTING ACTION FROM:
action 1, numVisits=154360, meanQ=4.843787, numObservations: 5
action 0, numVisits=25, meanQ=3.422662, numObservations: 1
action 3, numVisits=6, meanQ=2.003350, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.153515 0.947029 0.527294 0.884605 0.560498 0.817489 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=11076, meanQ=2.812954, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 1
action 3, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
Sampled 200817 episodes
GETTING ACTION FROM:
action 3, numVisits=193509, meanQ=6.038625, numObservations: 4
action 0, numVisits=18379, meanQ=1.354494, numObservations: 1
action -1, numVisits=11, meanQ=-0.560900, numObservations: 1
action 1, numVisits=5, meanQ=-3.000000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 3
Next state: 1 0.153515 0.947029 0.527294 0.884605 0.560498 0.817489 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 454
Initial state: 0 0.75684 0.715244 0.697773 0.831123 0.672325 0.879264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162781 episodes
GETTING ACTION FROM:
action 3, numVisits=162681, meanQ=5.021336, numObservations: 4
action 0, numVisits=50, meanQ=4.053206, numObservations: 1
action -1, numVisits=39, meanQ=3.902069, numObservations: 1
action 2, numVisits=10, meanQ=1.681000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.75684 0.715244 0.697773 0.831123 0.672325 0.879264 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 455
Initial state: 0 0.5098 0.893288 0.438886 0.216541 0.604983 0.865432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94572 episodes
GETTING ACTION FROM:
action 0, numVisits=91770, meanQ=2.921860, numObservations: 1
action -1, numVisits=2791, meanQ=0.810210, numObservations: 1
action 3, numVisits=7, meanQ=-1.287143, numObservations: 3
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 0
Next state: 0 0.5098 0.893288 0.438886 0.216541 0.604983 0.865432 w: 1
Observation: 0 0 0.823519 0 0.312786 0 0.873615 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=91763, meanQ=4.956345, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 162464 episodes
GETTING ACTION FROM:
action 2, numVisits=254218, meanQ=4.818743, numObservations: 5
action 3, numVisits=9, meanQ=2.100000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-11.000000, numObservations: 2
action: 2
Next state: 0 0.5098 0.893288 0.438886 0.216541 0.604983 0.865432 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=29800, meanQ=8.536836, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6379 episodes
GETTING ACTION FROM:
action 1, numVisits=29800, meanQ=8.536836, numObservations: 3
action 3, numVisits=35, meanQ=4.656857, numObservations: 3
action 0, numVisits=6331, meanQ=0.356078, numObservations: 1
action -1, numVisits=15, meanQ=-1.340000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 1
Next state: 1 0.5098 0.893288 0.438886 0.216541 0.604983 0.865432 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 456
Initial state: 0 0.349162 0.244432 0.636311 0.817136 0.617978 0.886416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163514 episodes
GETTING ACTION FROM:
action 3, numVisits=163403, meanQ=4.994614, numObservations: 4
action 0, numVisits=68, meanQ=4.144411, numObservations: 2
action 2, numVisits=30, meanQ=3.197680, numObservations: 4
action 1, numVisits=11, meanQ=2.363636, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.349162 0.244432 0.636311 0.817136 0.617978 0.886416 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 457
Initial state: 0 0.607287 0.815648 0.0568357 0.951961 0.568654 0.804451 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162807 episodes
GETTING ACTION FROM:
action 2, numVisits=162746, meanQ=5.019975, numObservations: 4
action 3, numVisits=55, meanQ=3.074364, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.607287 0.815648 0.0568357 0.951961 0.568654 0.804451 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11993, meanQ=5.503602, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 186482 episodes
GETTING ACTION FROM:
action 2, numVisits=198465, meanQ=5.438582, numObservations: 4
action 1, numVisits=5, meanQ=-0.002000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-5.300000, numObservations: 1
action: 2
Next state: 0 0.607287 0.815648 0.0568357 0.951961 0.568654 0.804451 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=4533, meanQ=6.534117, numObservations: 4
action 3, numVisits=38, meanQ=5.516053, numObservations: 4
action 2, numVisits=5, meanQ=3.798020, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 207513 episodes
GETTING ACTION FROM:
action 1, numVisits=212030, meanQ=5.789949, numObservations: 4
action 3, numVisits=50, meanQ=4.752200, numObservations: 4
action 2, numVisits=7, meanQ=2.427157, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.607287 0.815648 0.0568357 0.951961 0.568654 0.804451 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 458
Initial state: 0 0.60317 0.832092 0.0767065 0.00748439 0.559056 0.808396 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162245 episodes
GETTING ACTION FROM:
action 1, numVisits=162224, meanQ=4.936777, numObservations: 5
action 2, numVisits=16, meanQ=2.936250, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.60317 0.832092 0.0767065 0.00748439 0.559056 0.808396 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 459
Initial state: 0 0.071175 0.183908 0.607695 0.872066 0.655763 0.816785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94661 episodes
GETTING ACTION FROM:
action 0, numVisits=94640, meanQ=2.949659, numObservations: 1
action 3, numVisits=11, meanQ=0.910918, numObservations: 3
action 2, numVisits=5, meanQ=-0.200000, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.071175 0.183908 0.607695 0.872066 0.655763 0.816785 w: 1
Observation: 0 0 0.242693 0 0.909588 0 0.743277 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=94560, meanQ=5.017767, numObservations: 5
action 0, numVisits=35, meanQ=3.852709, numObservations: 1
action -1, numVisits=29, meanQ=3.773340, numObservations: 1
action 3, numVisits=13, meanQ=2.836923, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
Sampled 162316 episodes
GETTING ACTION FROM:
action 1, numVisits=256875, meanQ=5.194730, numObservations: 5
action 0, numVisits=35, meanQ=3.852709, numObservations: 1
action -1, numVisits=30, meanQ=3.711030, numObservations: 1
action 3, numVisits=13, meanQ=2.836923, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 0 0.071175 0.183908 0.607695 0.872066 0.655763 0.816785 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=28640, meanQ=8.517169, numObservations: 3
action 2, numVisits=20, meanQ=7.099005, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6655 episodes
GETTING ACTION FROM:
action 3, numVisits=31373, meanQ=8.291015, numObservations: 5
action 2, numVisits=127, meanQ=5.874575, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=3776, meanQ=-0.342339, numObservations: 1
action 0, numVisits=40, meanQ=-1.529997, numObservations: 2
action: 3
Next state: 1 0.071175 0.183908 0.607695 0.872066 0.655763 0.816785 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 460
Initial state: 0 0.442962 0.966519 0.543346 0.890405 0.538551 0.832094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162616 episodes
GETTING ACTION FROM:
action 1, numVisits=162575, meanQ=5.165884, numObservations: 5
action 0, numVisits=33, meanQ=3.925869, numObservations: 1
action 3, numVisits=3, meanQ=0.333333, numObservations: 3
action 2, numVisits=3, meanQ=-2.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.442962 0.966519 0.543346 0.890405 0.538551 0.832094 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 461
Initial state: 0 0.559781 0.854086 0.655541 0.831202 0.216446 0.114555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154185 episodes
GETTING ACTION FROM:
action 1, numVisits=154176, meanQ=4.809361, numObservations: 5
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 1
Next state: 1 0.559781 0.854086 0.655541 0.831202 0.216446 0.114555 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 462
Initial state: 0 0.526604 0.867378 0.651371 0.812071 0.485286 0.191267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162952 episodes
GETTING ACTION FROM:
action 1, numVisits=162938, meanQ=5.021855, numObservations: 4
action 2, numVisits=5, meanQ=-0.200000, numObservations: 2
action 3, numVisits=5, meanQ=-0.200000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.526604 0.867378 0.651371 0.812071 0.485286 0.191267 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 463
Initial state: 0 0.640778 0.816838 0.187256 0.56718 0.68302 0.870482 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95694 episodes
GETTING ACTION FROM:
action 0, numVisits=91473, meanQ=2.953999, numObservations: 1
action -1, numVisits=4215, meanQ=2.872019, numObservations: 1
action 1, numVisits=4, meanQ=-3.244975, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.640778 0.816838 0.187256 0.56718 0.68302 0.870482 w: 1
Observation: 0 0 0.882423 0 0.588101 0 0.8724 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=91450, meanQ=4.971473, numObservations: 5
action 2, numVisits=8, meanQ=2.497525, numObservations: 3
action 3, numVisits=10, meanQ=1.799000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 164217 episodes
GETTING ACTION FROM:
action 1, numVisits=255663, meanQ=4.931451, numObservations: 5
action 2, numVisits=12, meanQ=1.831692, numObservations: 4
action 3, numVisits=10, meanQ=1.799000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.640778 0.816838 0.187256 0.56718 0.68302 0.870482 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 464
Initial state: 0 0.551122 0.802062 0.0314858 0.628322 0.536574 0.819471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161607 episodes
GETTING ACTION FROM:
action 2, numVisits=161587, meanQ=4.978760, numObservations: 5
action -1, numVisits=16, meanQ=1.463652, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.551122 0.802062 0.0314858 0.628322 0.536574 0.819471 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=18614, meanQ=8.545578, numObservations: 3
action 1, numVisits=10, meanQ=6.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6054 episodes
GETTING ACTION FROM:
action 3, numVisits=18614, meanQ=8.545578, numObservations: 3
action 1, numVisits=18, meanQ=6.554444, numObservations: 5
action 2, numVisits=10, meanQ=4.399010, numObservations: 3
action 0, numVisits=6030, meanQ=0.305239, numObservations: 1
action -1, numVisits=9, meanQ=-2.112200, numObservations: 1
action: 3
Next state: 1 0.551122 0.802062 0.0314858 0.628322 0.536574 0.819471 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 465
Initial state: 0 0.575154 0.823607 0.296922 0.0874944 0.653243 0.853742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162256 episodes
GETTING ACTION FROM:
action 2, numVisits=162233, meanQ=4.980839, numObservations: 5
action 1, numVisits=18, meanQ=2.934456, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.575154 0.823607 0.296922 0.0874944 0.653243 0.853742 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 466
Initial state: 0 0.456011 0.647135 0.525687 0.855279 0.60046 0.894991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163146 episodes
GETTING ACTION FROM:
action 1, numVisits=156185, meanQ=5.013726, numObservations: 3
action 2, numVisits=6956, meanQ=4.936823, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.456011 0.647135 0.525687 0.855279 0.60046 0.894991 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=25771, meanQ=8.316115, numObservations: 4
action 2, numVisits=12, meanQ=5.500850, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11835 episodes
GETTING ACTION FROM:
action 3, numVisits=28631, meanQ=8.093173, numObservations: 4
action 2, numVisits=84, meanQ=5.538807, numObservations: 3
action -1, numVisits=8902, meanQ=-0.437027, numObservations: 1
action 0, numVisits=2, meanQ=-197.777518, numObservations: 1
action 1, numVisits=2, meanQ=-200.239935, numObservations: 1
action: 3
Next state: 0 0.456011 0.647135 0.525687 0.855279 0.60046 0.894991 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2102, meanQ=8.373961, numObservations: 3
action -1, numVisits=55, meanQ=6.766000, numObservations: 1
action 2, numVisits=8, meanQ=5.501263, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 26139 episodes
GETTING ACTION FROM:
action 3, numVisits=2102, meanQ=8.373961, numObservations: 3
action 2, numVisits=8, meanQ=5.501263, numObservations: 3
action 1, numVisits=3, meanQ=4.996667, numObservations: 2
action -1, numVisits=26191, meanQ=-1.680861, numObservations: 1
action 0, numVisits=2, meanQ=-193.578372, numObservations: 1
action: 3
Next state: 1 0.456011 0.647135 0.525687 0.855279 0.60046 0.894991 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 467
Initial state: 0 0.528112 0.81022 0.670351 0.0317536 0.596762 0.809774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161849 episodes
GETTING ACTION FROM:
action 3, numVisits=161810, meanQ=4.927720, numObservations: 4
action 0, numVisits=31, meanQ=3.642170, numObservations: 1
action 1, numVisits=5, meanQ=-0.399980, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.528112 0.81022 0.670351 0.0317536 0.596762 0.809774 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 468
Initial state: 0 0.610146 0.853867 0.234743 0.24861 0.594362 0.853271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162944 episodes
GETTING ACTION FROM:
action 1, numVisits=162706, meanQ=5.027906, numObservations: 4
action 3, numVisits=180, meanQ=4.516281, numObservations: 5
action 0, numVisits=50, meanQ=4.062047, numObservations: 1
action 2, numVisits=6, meanQ=1.333333, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.610146 0.853867 0.234743 0.24861 0.594362 0.853271 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 469
Initial state: 0 0.193699 0.394026 0.564224 0.827538 0.65696 0.863791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95877 episodes
GETTING ACTION FROM:
action 0, numVisits=95869, meanQ=2.940339, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=4, meanQ=-3.244975, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.193699 0.394026 0.564224 0.827538 0.65696 0.863791 w: 1
Observation: 0 0 0.442939 0 0.750556 0 0.79793 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=95855, meanQ=5.016761, numObservations: 4
action 3, numVisits=8, meanQ=2.498750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 165523 episodes
GETTING ACTION FROM:
action 2, numVisits=261374, meanQ=5.208473, numObservations: 4
action 3, numVisits=8, meanQ=2.498750, numObservations: 3
action 1, numVisits=5, meanQ=0.802020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.193699 0.394026 0.564224 0.827538 0.65696 0.863791 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 470
Initial state: 0 0.64156 0.883187 0.925472 0.0922544 0.693431 0.801012 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154882 episodes
GETTING ACTION FROM:
action 3, numVisits=154874, meanQ=4.858876, numObservations: 4
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.64156 0.883187 0.925472 0.0922544 0.693431 0.801012 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 471
Initial state: 0 0.558487 0.845103 0.612146 0.838126 0.642473 0.0390133 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154579 episodes
GETTING ACTION FROM:
action 1, numVisits=154390, meanQ=4.843255, numObservations: 5
action 0, numVisits=185, meanQ=4.339270, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.558487 0.845103 0.612146 0.838126 0.642473 0.0390133 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 472
Initial state: 0 0.639045 0.894336 0.404192 0.803471 0.675064 0.887785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161118 episodes
GETTING ACTION FROM:
action 3, numVisits=161056, meanQ=4.939181, numObservations: 4
action 0, numVisits=28, meanQ=3.605147, numObservations: 1
action -1, numVisits=29, meanQ=3.586689, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.639045 0.894336 0.404192 0.803471 0.675064 0.887785 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 473
Initial state: 0 0.420559 0.52577 0.538902 0.829938 0.505699 0.877099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162239 episodes
GETTING ACTION FROM:
action 3, numVisits=162146, meanQ=5.000261, numObservations: 4
action 0, numVisits=31, meanQ=3.659148, numObservations: 1
action 2, numVisits=58, meanQ=3.465693, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.420559 0.52577 0.538902 0.829938 0.505699 0.877099 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 474
Initial state: 0 0.631354 0.841743 0.609927 0.854124 0.295392 0.938876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163307 episodes
GETTING ACTION FROM:
action 1, numVisits=146943, meanQ=5.046763, numObservations: 5
action 2, numVisits=16359, meanQ=4.984636, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.631354 0.841743 0.609927 0.854124 0.295392 0.938876 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 475
Initial state: 0 0.587882 0.851818 0.991895 0.95936 0.595271 0.816343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161454 episodes
GETTING ACTION FROM:
action 3, numVisits=161447, meanQ=4.946564, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.587882 0.851818 0.991895 0.95936 0.595271 0.816343 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 476
Initial state: 0 0.618693 0.888407 0.0354285 0.0214726 0.578663 0.834008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162207 episodes
GETTING ACTION FROM:
action 3, numVisits=162142, meanQ=5.037097, numObservations: 4
action -1, numVisits=58, meanQ=3.699057, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 3
Next state: 1 0.618693 0.888407 0.0354285 0.0214726 0.578663 0.834008 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 477
Initial state: 0 0.671563 0.8625 0.60119 0.871771 0.219726 0.923129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162509 episodes
GETTING ACTION FROM:
action 3, numVisits=162433, meanQ=4.956917, numObservations: 5
action -1, numVisits=37, meanQ=3.697790, numObservations: 1
action 0, numVisits=26, meanQ=3.570194, numObservations: 1
action 1, numVisits=12, meanQ=2.250842, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.671563 0.8625 0.60119 0.871771 0.219726 0.923129 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.503894 0.861346 0.295659 0.856591 0.680949 0.823624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161594 episodes
GETTING ACTION FROM:
action 3, numVisits=161587, meanQ=4.947798, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.503894 0.861346 0.295659 0.856591 0.680949 0.823624 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 479
Initial state: 0 0.59677 0.819111 0.657536 0.895712 0.705282 0.190626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162365 episodes
GETTING ACTION FROM:
action 1, numVisits=162352, meanQ=4.967288, numObservations: 4
action 3, numVisits=8, meanQ=2.375000, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.59677 0.819111 0.657536 0.895712 0.705282 0.190626 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 480
Initial state: 0 0.505625 0.80275 0.569949 0.834746 0.0374106 0.942314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162002 episodes
GETTING ACTION FROM:
action 3, numVisits=161890, meanQ=4.947835, numObservations: 5
action 0, numVisits=82, meanQ=4.180842, numObservations: 1
action -1, numVisits=25, meanQ=3.270075, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action: 3
Next state: 0 0.505625 0.80275 0.569949 0.834746 0.0374106 0.942314 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=11686, meanQ=4.779240, numObservations: 4
action 0, numVisits=47, meanQ=3.855695, numObservations: 1
action -1, numVisits=32, meanQ=3.688167, numObservations: 1
action 3, numVisits=9, meanQ=1.445567, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 201061 episodes
GETTING ACTION FROM:
action 2, numVisits=201044, meanQ=5.827470, numObservations: 5
action 1, numVisits=11686, meanQ=4.779240, numObservations: 4
action 0, numVisits=57, meanQ=2.828380, numObservations: 1
action -1, numVisits=40, meanQ=2.684471, numObservations: 1
action 3, numVisits=9, meanQ=1.445567, numObservations: 2
action: 2
Next state: 1 0.505625 0.80275 0.569949 0.834746 0.0374106 0.942314 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 481
Initial state: 0 0.0757449 0.0188659 0.608824 0.812753 0.603471 0.867289 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162803 episodes
GETTING ACTION FROM:
action 1, numVisits=162787, meanQ=4.981947, numObservations: 5
action 3, numVisits=11, meanQ=2.718182, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0757449 0.0188659 0.608824 0.812753 0.603471 0.867289 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3814, meanQ=7.834066, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 19948 episodes
GETTING ACTION FROM:
action 2, numVisits=3814, meanQ=7.834066, numObservations: 5
action 3, numVisits=25, meanQ=7.713843, numObservations: 4
action -1, numVisits=17321, meanQ=0.257721, numObservations: 1
action 0, numVisits=2606, meanQ=0.174885, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.0757449 0.0188659 0.608824 0.812753 0.603471 0.867289 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 482
Initial state: 0 0.635282 0.878893 0.721513 0.0423981 0.508292 0.875499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162646 episodes
GETTING ACTION FROM:
action 3, numVisits=162598, meanQ=5.000614, numObservations: 5
action -1, numVisits=44, meanQ=3.926081, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.635282 0.878893 0.721513 0.0423981 0.508292 0.875499 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 483
Initial state: 0 0.901106 0.667452 0.612346 0.863256 0.649715 0.872191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153682 episodes
GETTING ACTION FROM:
action 1, numVisits=153527, meanQ=4.863506, numObservations: 4
action -1, numVisits=95, meanQ=4.166456, numObservations: 1
action 0, numVisits=50, meanQ=3.900115, numObservations: 1
action 3, numVisits=7, meanQ=1.428571, numObservations: 2
action 2, numVisits=3, meanQ=0.000033, numObservations: 2
action: 1
Next state: 2 0.901106 0.667452 0.612346 0.863256 0.649715 0.872191 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 484
Initial state: 0 0.016638 0.23111 0.530612 0.816564 0.544671 0.872442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162192 episodes
GETTING ACTION FROM:
action 2, numVisits=162044, meanQ=4.980454, numObservations: 3
action 0, numVisits=129, meanQ=4.383506, numObservations: 1
action 3, numVisits=7, meanQ=2.285729, numObservations: 2
action 1, numVisits=10, meanQ=2.281010, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.016638 0.23111 0.530612 0.816564 0.544671 0.872442 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 485
Initial state: 0 0.203295 0.327788 0.551711 0.896612 0.632617 0.809851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161921 episodes
GETTING ACTION FROM:
action 3, numVisits=161853, meanQ=4.991084, numObservations: 4
action 0, numVisits=59, meanQ=4.100520, numObservations: 1
action 1, numVisits=6, meanQ=0.166667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.203295 0.327788 0.551711 0.896612 0.632617 0.809851 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 486
Initial state: 0 0.893966 0.453965 0.654586 0.899175 0.535977 0.833188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154667 episodes
GETTING ACTION FROM:
action 2, numVisits=154579, meanQ=4.823333, numObservations: 5
action -1, numVisits=49, meanQ=3.835211, numObservations: 1
action 0, numVisits=36, meanQ=3.644067, numObservations: 1
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.893966 0.453965 0.654586 0.899175 0.535977 0.833188 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 487
Initial state: 0 0.635044 0.836366 0.927425 0.569132 0.616606 0.813918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162969 episodes
GETTING ACTION FROM:
action 2, numVisits=162879, meanQ=5.027371, numObservations: 5
action 3, numVisits=85, meanQ=3.905534, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.635044 0.836366 0.927425 0.569132 0.616606 0.813918 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 488
Initial state: 0 0.567078 0.830738 0.625358 0.855874 0.961276 0.703393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162245 episodes
GETTING ACTION FROM:
action 2, numVisits=161766, meanQ=4.924129, numObservations: 5
action -1, numVisits=475, meanQ=2.135396, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.567078 0.830738 0.625358 0.855874 0.961276 0.703393 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 489
Initial state: 0 0.504726 0.892068 0.687953 0.838609 0.965662 0.217869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96100 episodes
GETTING ACTION FROM:
action -1, numVisits=96085, meanQ=2.852060, numObservations: 1
action 2, numVisits=8, meanQ=-1.123737, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=4, meanQ=-2.749975, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.504726 0.892068 0.687953 0.838609 0.965662 0.217869 w: 1
Observation: 0 0.444503 0 0.616001 0 0.868236 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=96029, meanQ=4.923988, numObservations: 4
action -1, numVisits=19, meanQ=3.376945, numObservations: 1
action 3, numVisits=27, meanQ=2.404452, numObservations: 4
action 1, numVisits=7, meanQ=-0.145714, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 160623 episodes
GETTING ACTION FROM:
action 2, numVisits=256651, meanQ=4.895494, numObservations: 4
action -1, numVisits=20, meanQ=3.318349, numObservations: 1
action 3, numVisits=27, meanQ=2.404452, numObservations: 4
action 1, numVisits=7, meanQ=-0.145714, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.504726 0.892068 0.687953 0.838609 0.965662 0.217869 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=36988, meanQ=8.423548, numObservations: 4
action 3, numVisits=742, meanQ=8.209766, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9317 episodes
GETTING ACTION FROM:
action 1, numVisits=40590, meanQ=8.187929, numObservations: 4
action 3, numVisits=1169, meanQ=7.428079, numObservations: 4
action 2, numVisits=7, meanQ=1.985714, numObservations: 2
action 0, numVisits=5276, meanQ=0.211920, numObservations: 1
action -1, numVisits=8, meanQ=-2.960835, numObservations: 1
action: 1
Next state: 1 0.504726 0.892068 0.687953 0.838609 0.965662 0.217869 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 490
Initial state: 0 0.0617081 0.0862367 0.652285 0.879212 0.603962 0.827821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162691 episodes
GETTING ACTION FROM:
action 2, numVisits=162685, meanQ=4.976093, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.0617081 0.0862367 0.652285 0.879212 0.603962 0.827821 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 491
Initial state: 0 0.0208255 0.177726 0.590496 0.824303 0.692694 0.849689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162830 episodes
GETTING ACTION FROM:
action 1, numVisits=162791, meanQ=4.962473, numObservations: 5
action -1, numVisits=29, meanQ=3.684153, numObservations: 1
action 3, numVisits=7, meanQ=2.002871, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.0208255 0.177726 0.590496 0.824303 0.692694 0.849689 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9561, meanQ=7.884400, numObservations: 4
action 2, numVisits=4, meanQ=2.497525, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6705 episodes
GETTING ACTION FROM:
action 3, numVisits=9561, meanQ=7.884400, numObservations: 4
action 2, numVisits=57, meanQ=7.068423, numObservations: 4
action 1, numVisits=19, meanQ=6.262632, numObservations: 3
action 0, numVisits=6582, meanQ=0.184857, numObservations: 1
action -1, numVisits=54, meanQ=-0.661667, numObservations: 1
action: 3
Next state: 0 0.0208255 0.177726 0.590496 0.824303 0.692694 0.849689 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=813, meanQ=8.083674, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 34430 episodes
GETTING ACTION FROM:
action 3, numVisits=867, meanQ=8.032326, numObservations: 4
action 2, numVisits=118, meanQ=6.754153, numObservations: 4
action 1, numVisits=8, meanQ=-0.001250, numObservations: 4
action -1, numVisits=20336, meanQ=-1.685904, numObservations: 1
action 0, numVisits=13919, meanQ=-1.701841, numObservations: 1
action: 3
Next state: 0 0.0208255 0.177726 0.590496 0.824303 0.692694 0.849689 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=56, meanQ=7.390898, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 56168 episodes
GETTING ACTION FROM:
action 2, numVisits=357, meanQ=6.943418, numObservations: 4
action 1, numVisits=79, meanQ=5.645443, numObservations: 4
action 3, numVisits=20, meanQ=3.399500, numObservations: 4
action -1, numVisits=33932, meanQ=-1.838482, numObservations: 1
action 0, numVisits=21841, meanQ=-1.849830, numObservations: 1
action: 2
Next state: 1 0.0208255 0.177726 0.590496 0.824303 0.692694 0.849689 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 492
Initial state: 0 0.789526 0.669829 0.543449 0.808628 0.553559 0.814625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162941 episodes
GETTING ACTION FROM:
action 2, numVisits=162927, meanQ=5.124096, numObservations: 5
action 3, numVisits=8, meanQ=2.127512, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.789526 0.669829 0.543449 0.808628 0.553559 0.814625 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 493
Initial state: 0 0.602947 0.849362 0.616539 0.87312 0.125689 0.0767965 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162780 episodes
GETTING ACTION FROM:
action 2, numVisits=151146, meanQ=4.941491, numObservations: 4
action 3, numVisits=11564, meanQ=4.890857, numObservations: 4
action -1, numVisits=39, meanQ=3.788247, numObservations: 1
action 1, numVisits=29, meanQ=3.478621, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.602947 0.849362 0.616539 0.87312 0.125689 0.0767965 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 494
Initial state: 0 0.63336 0.898223 0.638341 0.864379 0.357266 0.679586 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 135500 episodes
GETTING ACTION FROM:
action 1, numVisits=93990, meanQ=5.081910, numObservations: 4
action -1, numVisits=41473, meanQ=2.956420, numObservations: 1
action 2, numVisits=21, meanQ=1.419052, numObservations: 3
action 3, numVisits=14, meanQ=0.929286, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.63336 0.898223 0.638341 0.864379 0.357266 0.679586 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 495
Initial state: 0 0.529967 0.885259 0.546813 0.879312 0.538508 0.751962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161638 episodes
GETTING ACTION FROM:
action 3, numVisits=161578, meanQ=4.931020, numObservations: 5
action 0, numVisits=56, meanQ=4.007465, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.529967 0.885259 0.546813 0.879312 0.538508 0.751962 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 496
Initial state: 0 0.543476 0.834389 0.356187 0.34649 0.631739 0.841448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96024 episodes
GETTING ACTION FROM:
action -1, numVisits=96016, meanQ=2.991864, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=2, meanQ=-5.489950, numObservations: 1
action: -1
Next state: 0 0.543476 0.834389 0.356187 0.34649 0.631739 0.841448 w: 1
Observation: 0 0.469878 0 0.429182 0 0.535048 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=94581, meanQ=5.052409, numObservations: 4
action 2, numVisits=1236, meanQ=4.852523, numObservations: 5
action 0, numVisits=131, meanQ=4.463215, numObservations: 1
action -1, numVisits=60, meanQ=4.153628, numObservations: 1
action 1, numVisits=7, meanQ=2.127143, numObservations: 3
Sampled 161975 episodes
GETTING ACTION FROM:
action 3, numVisits=256555, meanQ=5.137471, numObservations: 4
action 2, numVisits=1236, meanQ=4.852523, numObservations: 5
action 0, numVisits=132, meanQ=4.459690, numObservations: 1
action -1, numVisits=60, meanQ=4.153628, numObservations: 1
action 1, numVisits=7, meanQ=2.127143, numObservations: 3
action: 3
Next state: 1 0.543476 0.834389 0.356187 0.34649 0.631739 0.841448 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 497
Initial state: 0 0.232532 0.996886 0.643048 0.884452 0.638425 0.876898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162985 episodes
GETTING ACTION FROM:
action 3, numVisits=162977, meanQ=5.018800, numObservations: 5
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.232532 0.996886 0.643048 0.884452 0.638425 0.876898 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 498
Initial state: 0 0.501249 0.811638 0.678462 0.898059 0.179601 0.611244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105253 episodes
GETTING ACTION FROM:
action 0, numVisits=95721, meanQ=5.951559, numObservations: 3
action 2, numVisits=9524, meanQ=4.981777, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.501249 0.811638 0.678462 0.898059 0.179601 0.611244 w: 1
Observation: 0 0 0.729147 0 0.810346 0 0.673436 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=34962, meanQ=7.907183, numObservations: 3
action 2, numVisits=3, meanQ=2.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 164423 episodes
GETTING ACTION FROM:
action 1, numVisits=199363, meanQ=5.776392, numObservations: 3
action -1, numVisits=17, meanQ=4.061773, numObservations: 1
action 3, numVisits=4, meanQ=2.002525, numObservations: 2
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.501249 0.811638 0.678462 0.898059 0.179601 0.611244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 499
Initial state: 0 0.595547 0.0751237 0.575938 0.852813 0.588307 0.815231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162744 episodes
GETTING ACTION FROM:
action 2, numVisits=162629, meanQ=5.010912, numObservations: 5
action 1, numVisits=73, meanQ=3.874849, numObservations: 4
action -1, numVisits=39, meanQ=3.702834, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.595547 0.0751237 0.575938 0.852813 0.588307 0.815231 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 500
Initial state: 0 0.66166 0.875094 0.488384 0.19827 0.664757 0.891547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161406 episodes
GETTING ACTION FROM:
action 3, numVisits=161380, meanQ=4.977139, numObservations: 5
action -1, numVisits=21, meanQ=3.335772, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.66166 0.875094 0.488384 0.19827 0.664757 0.891547 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
