Run # 1
Initial state: 0 0.542235 0.834782 0.84827 0.0112551 0.674585 0.864783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161037 episodes
GETTING ACTION FROM:
action 3, numVisits=161031, meanQ=4.977064, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.542235 0.834782 0.84827 0.0112551 0.674585 0.864783 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.657738 0.845 0.87828 0.66457 0.568705 0.823132 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163273 episodes
GETTING ACTION FROM:
action 3, numVisits=163234, meanQ=5.032812, numObservations: 4
action 0, numVisits=25, meanQ=3.552183, numObservations: 1
action 1, numVisits=10, meanQ=1.600020, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.657738 0.845 0.87828 0.66457 0.568705 0.823132 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 3
Initial state: 0 0.546612 0.802114 0.987938 0.0197881 0.591244 0.849135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154627 episodes
GETTING ACTION FROM:
action 2, numVisits=154560, meanQ=4.863938, numObservations: 4
action -1, numVisits=58, meanQ=3.965059, numObservations: 1
action 1, numVisits=6, meanQ=0.166667, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.546612 0.802114 0.987938 0.0197881 0.591244 0.849135 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.60632 0.811069 0.125945 0.324382 0.601811 0.858116 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 152774 episodes
GETTING ACTION FROM:
action 2, numVisits=152761, meanQ=4.968805, numObservations: 5
action 1, numVisits=6, meanQ=1.498333, numObservations: 3
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.60632 0.811069 0.125945 0.324382 0.601811 0.858116 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 5
Initial state: 0 0.10484 0.334873 0.691403 0.873512 0.591928 0.860175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155316 episodes
GETTING ACTION FROM:
action 3, numVisits=155310, meanQ=4.888744, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.10484 0.334873 0.691403 0.873512 0.591928 0.860175 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 6
Initial state: 0 0.571985 0.861728 0.627182 0.824135 0.925926 0.505538 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 102039 episodes
GETTING ACTION FROM:
action 0, numVisits=100996, meanQ=5.795833, numObservations: 3
action -1, numVisits=1039, meanQ=3.028028, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.571985 0.861728 0.627182 0.824135 0.925926 0.505538 w: 1
Observation: 0 0 0.767119 0 0.864692 0 0.467267 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=43486, meanQ=7.462331, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 165985 episodes
GETTING ACTION FROM:
action 1, numVisits=209413, meanQ=5.713628, numObservations: 4
action 0, numVisits=58, meanQ=4.789910, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.571985 0.861728 0.627182 0.824135 0.925926 0.505538 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 7
Initial state: 0 0.662508 0.864788 0.371487 0.247077 0.597792 0.878523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163270 episodes
GETTING ACTION FROM:
action 3, numVisits=163237, meanQ=4.955643, numObservations: 3
action 0, numVisits=22, meanQ=3.373707, numObservations: 1
action 1, numVisits=8, meanQ=2.373775, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.662508 0.864788 0.371487 0.247077 0.597792 0.878523 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 8
Initial state: 0 0.027183 0.0794232 0.656872 0.886005 0.505616 0.815778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163451 episodes
GETTING ACTION FROM:
action 1, numVisits=163395, meanQ=4.967887, numObservations: 5
action -1, numVisits=31, meanQ=3.682685, numObservations: 1
action 2, numVisits=21, meanQ=3.464776, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.027183 0.0794232 0.656872 0.886005 0.505616 0.815778 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8099, meanQ=7.820063, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 38798 episodes
GETTING ACTION FROM:
action 2, numVisits=42857, meanQ=6.538852, numObservations: 4
action 0, numVisits=4037, meanQ=0.187466, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action -1, numVisits=3, meanQ=-5.300000, numObservations: 1
action 3, numVisits=2, meanQ=-5.929950, numObservations: 2
action: 2
Next state: 1 0.027183 0.0794232 0.656872 0.886005 0.505616 0.815778 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 9
Initial state: 0 0.517757 0.891326 0.0398704 0.220499 0.653396 0.875726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163021 episodes
GETTING ACTION FROM:
action 2, numVisits=162824, meanQ=4.974448, numObservations: 4
action -1, numVisits=169, meanQ=3.628923, numObservations: 1
action 0, numVisits=25, meanQ=3.451119, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.517757 0.891326 0.0398704 0.220499 0.653396 0.875726 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 10
Initial state: 0 0.652083 0.823545 0.569099 0.850814 0.83339 0.881414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164778 episodes
GETTING ACTION FROM:
action 1, numVisits=164772, meanQ=5.000189, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.652083 0.823545 0.569099 0.850814 0.83339 0.881414 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12092, meanQ=5.588267, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 199782 episodes
GETTING ACTION FROM:
action 3, numVisits=189327, meanQ=6.030139, numObservations: 3
action 1, numVisits=22501, meanQ=5.299537, numObservations: 5
action 2, numVisits=48, meanQ=4.145833, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.652083 0.823545 0.569099 0.850814 0.83339 0.881414 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 11
Initial state: 0 0.513766 0.87511 0.245178 0.678655 0.6463 0.860928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163230 episodes
GETTING ACTION FROM:
action 2, numVisits=163222, meanQ=4.934746, numObservations: 4
action 1, numVisits=3, meanQ=0.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.513766 0.87511 0.245178 0.678655 0.6463 0.860928 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=26747, meanQ=8.331096, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 28857 episodes
GETTING ACTION FROM:
action 1, numVisits=43424, meanQ=7.413172, numObservations: 4
action 3, numVisits=172, meanQ=5.829965, numObservations: 3
action 0, numVisits=12002, meanQ=0.219045, numObservations: 1
action -1, numVisits=10, meanQ=-1.901000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.513766 0.87511 0.245178 0.678655 0.6463 0.860928 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 12
Initial state: 0 0.57743 0.819811 0.974986 0.577771 0.51806 0.850873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96464 episodes
GETTING ACTION FROM:
action -1, numVisits=79210, meanQ=3.068837, numObservations: 1
action 0, numVisits=17251, meanQ=3.041317, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.57743 0.819811 0.974986 0.577771 0.51806 0.850873 w: 1
Observation: 0 0.540469 0 0.91119 0 0.556544 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=79199, meanQ=5.094865, numObservations: 5
action 3, numVisits=3, meanQ=0.993333, numObservations: 3
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 164926 episodes
GETTING ACTION FROM:
action 2, numVisits=244124, meanQ=5.094447, numObservations: 5
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action 3, numVisits=4, meanQ=-0.504975, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.57743 0.819811 0.974986 0.577771 0.51806 0.850873 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 13
Initial state: 0 0.544687 0.891589 0.221725 0.217617 0.602944 0.858432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164122 episodes
GETTING ACTION FROM:
action 2, numVisits=164073, meanQ=5.003226, numObservations: 5
action -1, numVisits=28, meanQ=3.611744, numObservations: 1
action 3, numVisits=18, meanQ=3.261672, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.544687 0.891589 0.221725 0.217617 0.602944 0.858432 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 14
Initial state: 0 0.697674 0.815623 0.21482 0.166798 0.615179 0.836215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156042 episodes
GETTING ACTION FROM:
action 2, numVisits=155979, meanQ=4.849352, numObservations: 5
action 0, numVisits=33, meanQ=3.604863, numObservations: 1
action -1, numVisits=26, meanQ=3.459029, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 0 0.697674 0.815623 0.21482 0.166798 0.615179 0.836215 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=21846, meanQ=8.421496, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 25285 episodes
GETTING ACTION FROM:
action 3, numVisits=43441, meanQ=7.246541, numObservations: 5
action 0, numVisits=3591, meanQ=0.377268, numObservations: 1
action -1, numVisits=100, meanQ=-0.218099, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.697674 0.815623 0.21482 0.166798 0.615179 0.836215 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 15
Initial state: 0 0.801716 0.730205 0.569141 0.800926 0.572295 0.843528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164361 episodes
GETTING ACTION FROM:
action 2, numVisits=164267, meanQ=5.160511, numObservations: 4
action -1, numVisits=47, meanQ=4.112791, numObservations: 1
action 0, numVisits=30, meanQ=3.856932, numObservations: 1
action 1, numVisits=14, meanQ=2.357143, numObservations: 2
action 3, numVisits=3, meanQ=0.000033, numObservations: 1
action: 2
Next state: 1 0.801716 0.730205 0.569141 0.800926 0.572295 0.843528 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 16
Initial state: 0 0.521172 0.738269 0.659342 0.807374 0.648924 0.806511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161959 episodes
GETTING ACTION FROM:
action 2, numVisits=161845, meanQ=4.938746, numObservations: 5
action -1, numVisits=76, meanQ=4.160248, numObservations: 1
action 0, numVisits=36, meanQ=3.791280, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.521172 0.738269 0.659342 0.807374 0.648924 0.806511 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 17
Initial state: 0 0.52977 0.836954 0.684633 0.836475 0.993695 0.69797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163910 episodes
GETTING ACTION FROM:
action 3, numVisits=163896, meanQ=5.169738, numObservations: 4
action 0, numVisits=10, meanQ=2.452035, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.52977 0.836954 0.684633 0.836475 0.993695 0.69797 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 18
Initial state: 0 0.860706 0.910101 0.556668 0.867466 0.524148 0.871442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96528 episodes
GETTING ACTION FROM:
action -1, numVisits=95485, meanQ=3.079233, numObservations: 1
action 0, numVisits=1040, meanQ=2.890860, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.860706 0.910101 0.556668 0.867466 0.524148 0.871442 w: 1
Observation: 0 0.808527 0 0.655483 0 0.571504 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=95420, meanQ=5.137762, numObservations: 5
action 0, numVisits=50, meanQ=4.179340, numObservations: 1
action 3, numVisits=10, meanQ=2.999020, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 163018 episodes
GETTING ACTION FROM:
action 2, numVisits=258431, meanQ=4.937056, numObservations: 5
action 0, numVisits=56, meanQ=3.970644, numObservations: 1
action 3, numVisits=11, meanQ=2.271845, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.860706 0.910101 0.556668 0.867466 0.524148 0.871442 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 19
Initial state: 0 0.214715 0.629567 0.665016 0.854947 0.552053 0.86873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156161 episodes
GETTING ACTION FROM:
action 1, numVisits=156122, meanQ=4.925396, numObservations: 3
action 0, numVisits=28, meanQ=3.552473, numObservations: 1
action 3, numVisits=6, meanQ=1.331683, numObservations: 3
action 2, numVisits=3, meanQ=0.663333, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.214715 0.629567 0.665016 0.854947 0.552053 0.86873 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=25759, meanQ=8.304330, numObservations: 4
action 2, numVisits=18, meanQ=6.106672, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30795 episodes
GETTING ACTION FROM:
action 3, numVisits=47334, meanQ=7.253755, numObservations: 4
action 2, numVisits=299, meanQ=4.604520, numObservations: 5
action 0, numVisits=8935, meanQ=0.181989, numObservations: 1
action 1, numVisits=2, meanQ=-3.505000, numObservations: 2
action -1, numVisits=5, meanQ=-77.754800, numObservations: 1
action: 3
Next state: 1 0.214715 0.629567 0.665016 0.854947 0.552053 0.86873 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 20
Initial state: 0 0.645525 0.831916 0.546913 0.827648 0.8346 0.185205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165240 episodes
GETTING ACTION FROM:
action 1, numVisits=165233, meanQ=4.994927, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.645525 0.831916 0.546913 0.827648 0.8346 0.185205 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 21
Initial state: 0 0.85193 0.423719 0.614141 0.860086 0.518827 0.845019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96592 episodes
GETTING ACTION FROM:
action 0, numVisits=96575, meanQ=2.905738, numObservations: 1
action 3, numVisits=8, meanQ=0.263750, numObservations: 2
action 2, numVisits=4, meanQ=-0.502500, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.85193 0.423719 0.614141 0.860086 0.518827 0.845019 w: 1
Observation: 0 0 0.390937 0 0.760985 0 0.901854 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=96528, meanQ=4.969262, numObservations: 5
action 0, numVisits=42, meanQ=3.886067, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 163823 episodes
GETTING ACTION FROM:
action 1, numVisits=260348, meanQ=5.055500, numObservations: 5
action 0, numVisits=43, meanQ=3.860379, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.85193 0.423719 0.614141 0.860086 0.518827 0.845019 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 22
Initial state: 0 0.0746045 0.909477 0.69123 0.854564 0.596065 0.837101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164689 episodes
GETTING ACTION FROM:
action 3, numVisits=164631, meanQ=5.009932, numObservations: 4
action 0, numVisits=54, meanQ=4.053078, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0746045 0.909477 0.69123 0.854564 0.596065 0.837101 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 23
Initial state: 0 0.617021 0.865903 0.653472 0.851468 0.150695 0.136656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162872 episodes
GETTING ACTION FROM:
action 2, numVisits=162853, meanQ=4.978145, numObservations: 4
action 3, numVisits=14, meanQ=1.715721, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.617021 0.865903 0.653472 0.851468 0.150695 0.136656 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 24
Initial state: 0 0.676638 0.820552 0.526939 0.848796 0.341249 0.413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163596 episodes
GETTING ACTION FROM:
action 3, numVisits=163589, meanQ=4.981557, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.676638 0.820552 0.526939 0.848796 0.341249 0.413 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4140, meanQ=7.604442, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 28494 episodes
GETTING ACTION FROM:
action 2, numVisits=9965, meanQ=6.631881, numObservations: 4
action 1, numVisits=12, meanQ=1.332500, numObservations: 3
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=22657, meanQ=0.144468, numObservations: 1
action -1, numVisits=2, meanQ=-198.575597, numObservations: 1
action: 2
Next state: 1 0.676638 0.820552 0.526939 0.848796 0.341249 0.413 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 25
Initial state: 0 0.0989614 0.996222 0.63679 0.845941 0.567475 0.837087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164117 episodes
GETTING ACTION FROM:
action 3, numVisits=164110, meanQ=5.195980, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.0989614 0.996222 0.63679 0.845941 0.567475 0.837087 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 26
Initial state: 0 0.581407 0.815145 0.206739 0.883595 0.521633 0.883264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165104 episodes
GETTING ACTION FROM:
action 3, numVisits=165073, meanQ=5.048787, numObservations: 4
action 0, numVisits=16, meanQ=3.033940, numObservations: 1
action 2, numVisits=12, meanQ=2.235000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.581407 0.815145 0.206739 0.883595 0.521633 0.883264 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 27
Initial state: 0 0.600193 0.825132 0.705563 0.209955 0.672662 0.861891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162992 episodes
GETTING ACTION FROM:
action 2, numVisits=162923, meanQ=4.931814, numObservations: 4
action 1, numVisits=51, meanQ=3.953731, numObservations: 4
action 3, numVisits=14, meanQ=2.856443, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.600193 0.825132 0.705563 0.209955 0.672662 0.861891 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 28
Initial state: 0 0.568973 0.866622 0.599308 0.876127 0.832277 0.591813 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163403 episodes
GETTING ACTION FROM:
action 3, numVisits=163222, meanQ=4.992059, numObservations: 3
action 1, numVisits=176, meanQ=4.473301, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.568973 0.866622 0.599308 0.876127 0.832277 0.591813 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 29
Initial state: 0 0.521296 0.81091 0.199432 0.465529 0.651944 0.899039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96343 episodes
GETTING ACTION FROM:
action -1, numVisits=96338, meanQ=2.883276, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.521296 0.81091 0.199432 0.465529 0.651944 0.899039 w: 1
Observation: 0 0.427362 0 0.291011 0 0.651111 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=96331, meanQ=4.952793, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 162480 episodes
GETTING ACTION FROM:
action 2, numVisits=258810, meanQ=5.148974, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.521296 0.81091 0.199432 0.465529 0.651944 0.899039 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 30
Initial state: 0 0.741008 0.0590811 0.555308 0.816901 0.651226 0.811991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154184 episodes
GETTING ACTION FROM:
action 1, numVisits=154079, meanQ=4.860447, numObservations: 5
action -1, numVisits=51, meanQ=3.908724, numObservations: 1
action 0, numVisits=51, meanQ=3.906045, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.741008 0.0590811 0.555308 0.816901 0.651226 0.811991 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 31
Initial state: 0 0.51014 0.870126 0.685784 0.899665 0.381749 0.964087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162744 episodes
GETTING ACTION FROM:
action 2, numVisits=162728, meanQ=5.155834, numObservations: 5
action 1, numVisits=9, meanQ=-0.987778, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.51014 0.870126 0.685784 0.899665 0.381749 0.964087 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 32
Initial state: 0 0.501262 0.800729 0.663912 0.832435 0.692449 0.350386 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163298 episodes
GETTING ACTION FROM:
action 1, numVisits=163263, meanQ=4.950904, numObservations: 4
action 0, numVisits=31, meanQ=3.611194, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.501262 0.800729 0.663912 0.832435 0.692449 0.350386 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 33
Initial state: 0 0.696564 0.848977 0.508193 0.848444 0.41315 0.983089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163669 episodes
GETTING ACTION FROM:
action 2, numVisits=163565, meanQ=5.025657, numObservations: 4
action -1, numVisits=63, meanQ=4.159072, numObservations: 1
action 1, numVisits=31, meanQ=2.450648, numObservations: 4
action 3, numVisits=8, meanQ=1.625000, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.696564 0.848977 0.508193 0.848444 0.41315 0.983089 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 34
Initial state: 0 0.509731 0.872742 0.0319764 0.294612 0.662986 0.855261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163749 episodes
GETTING ACTION FROM:
action 3, numVisits=163710, meanQ=4.967831, numObservations: 4
action -1, numVisits=26, meanQ=3.611546, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 1, numVisits=5, meanQ=-0.399980, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.509731 0.872742 0.0319764 0.294612 0.662986 0.855261 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 35
Initial state: 0 0.585001 0.825969 0.69089 0.215266 0.538785 0.805847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155307 episodes
GETTING ACTION FROM:
action 2, numVisits=155292, meanQ=4.866167, numObservations: 4
action 3, numVisits=9, meanQ=2.333333, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.585001 0.825969 0.69089 0.215266 0.538785 0.805847 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 36
Initial state: 0 0.575587 0.826966 0.0670726 0.548938 0.598579 0.819739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96133 episodes
GETTING ACTION FROM:
action 0, numVisits=96122, meanQ=2.886750, numObservations: 1
action 1, numVisits=7, meanQ=-0.854271, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.575587 0.826966 0.0670726 0.548938 0.598579 0.819739 w: 1
Observation: 0 0 0.834145 0 0.64356 0 0.796384 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=95993, meanQ=4.997622, numObservations: 5
action 0, numVisits=72, meanQ=4.144761, numObservations: 1
action 3, numVisits=41, meanQ=3.272441, numObservations: 3
action 1, numVisits=13, meanQ=2.693092, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 164372 episodes
GETTING ACTION FROM:
action 2, numVisits=260364, meanQ=5.000255, numObservations: 5
action 0, numVisits=73, meanQ=4.144823, numObservations: 1
action 3, numVisits=41, meanQ=3.272441, numObservations: 3
action 1, numVisits=13, meanQ=2.693092, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.575587 0.826966 0.0670726 0.548938 0.598579 0.819739 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=29082, meanQ=8.553413, numObservations: 3
action 1, numVisits=64, meanQ=7.717189, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29302 episodes
GETTING ACTION FROM:
action 3, numVisits=55163, meanQ=7.589000, numObservations: 5
action 1, numVisits=188, meanQ=6.849576, numObservations: 4
action 2, numVisits=9, meanQ=3.221111, numObservations: 2
action -1, numVisits=3082, meanQ=0.125191, numObservations: 1
action 0, numVisits=9, meanQ=-2.001100, numObservations: 1
action: 3
Next state: 0 0.575587 0.826966 0.0670726 0.548938 0.598579 0.819739 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=2023, meanQ=8.562649, numObservations: 3
action 1, numVisits=239, meanQ=8.315734, numObservations: 3
action 0, numVisits=490, meanQ=6.873612, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 30265 episodes
GETTING ACTION FROM:
action 1, numVisits=239, meanQ=8.315734, numObservations: 3
action 3, numVisits=2770, meanQ=7.992486, numObservations: 4
action 0, numVisits=30008, meanQ=-1.398439, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.575587 0.826966 0.0670726 0.548938 0.598579 0.819739 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -1.14771
Run # 37
Initial state: 0 0.72526 0.418408 0.694752 0.846036 0.512557 0.880855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163894 episodes
GETTING ACTION FROM:
action 1, numVisits=163823, meanQ=4.994003, numObservations: 4
action 0, numVisits=67, meanQ=4.152220, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.72526 0.418408 0.694752 0.846036 0.512557 0.880855 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 38
Initial state: 0 0.300402 0.465742 0.532471 0.877424 0.606731 0.87635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156476 episodes
GETTING ACTION FROM:
action 1, numVisits=156412, meanQ=4.813131, numObservations: 3
action -1, numVisits=25, meanQ=3.433025, numObservations: 1
action 0, numVisits=24, meanQ=3.401637, numObservations: 1
action 3, numVisits=14, meanQ=2.572879, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.300402 0.465742 0.532471 0.877424 0.606731 0.87635 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25872, meanQ=8.324494, numObservations: 3
action 3, numVisits=27, meanQ=7.066667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 31203 episodes
GETTING ACTION FROM:
action 2, numVisits=50420, meanQ=7.123234, numObservations: 3
action 3, numVisits=206, meanQ=5.597022, numObservations: 4
action 1, numVisits=6, meanQ=1.498333, numObservations: 3
action -1, numVisits=6378, meanQ=0.175268, numObservations: 1
action 0, numVisits=95, meanQ=-0.628597, numObservations: 2
action: 2
Next state: 1 0.300402 0.465742 0.532471 0.877424 0.606731 0.87635 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 39
Initial state: 0 0.543016 0.838008 0.296399 0.155723 0.559433 0.879076 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168009 episodes
GETTING ACTION FROM:
action 3, numVisits=168002, meanQ=4.916922, numObservations: 4
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.543016 0.838008 0.296399 0.155723 0.559433 0.879076 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 40
Initial state: 0 0.663683 0.893493 0.622857 0.863729 0.842457 0.685828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158706 episodes
GETTING ACTION FROM:
action 1, numVisits=158591, meanQ=4.825398, numObservations: 4
action 0, numVisits=111, meanQ=4.180489, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.663683 0.893493 0.622857 0.863729 0.842457 0.685828 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 41
Initial state: 0 0.559634 0.874504 0.358826 0.640198 0.550473 0.858236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166900 episodes
GETTING ACTION FROM:
action 3, numVisits=166894, meanQ=4.917024, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.559634 0.874504 0.358826 0.640198 0.550473 0.858236 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4243, meanQ=7.786914, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 34847 episodes
GETTING ACTION FROM:
action 1, numVisits=33993, meanQ=6.201495, numObservations: 4
action -1, numVisits=5070, meanQ=0.196941, numObservations: 1
action 0, numVisits=29, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.559634 0.874504 0.358826 0.640198 0.550473 0.858236 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 42
Initial state: 0 0.56843 0.829565 0.515607 0.816206 0.84308 0.427094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167528 episodes
GETTING ACTION FROM:
action 3, numVisits=167314, meanQ=5.042969, numObservations: 4
action 2, numVisits=168, meanQ=4.429706, numObservations: 4
action 1, numVisits=42, meanQ=3.936671, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.56843 0.829565 0.515607 0.816206 0.84308 0.427094 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.61226 0.800648 0.229634 0.510958 0.598674 0.86117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166523 episodes
GETTING ACTION FROM:
action 2, numVisits=166153, meanQ=4.912013, numObservations: 5
action 0, numVisits=111, meanQ=4.231914, numObservations: 1
action 3, numVisits=255, meanQ=3.642129, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.61226 0.800648 0.229634 0.510958 0.598674 0.86117 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23170, meanQ=8.407868, numObservations: 3
action 1, numVisits=14, meanQ=6.284293, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29983 episodes
GETTING ACTION FROM:
action 3, numVisits=50018, meanQ=7.263374, numObservations: 3
action 1, numVisits=100, meanQ=6.037514, numObservations: 4
action -1, numVisits=2995, meanQ=0.240474, numObservations: 1
action 0, numVisits=44, meanQ=-0.965000, numObservations: 1
action 2, numVisits=13, meanQ=-22.969583, numObservations: 3
action: 3
Next state: 1 0.61226 0.800648 0.229634 0.510958 0.598674 0.86117 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 44
Initial state: 0 0.661187 0.810844 0.613208 0.806215 0.48067 0.0415302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164819 episodes
GETTING ACTION FROM:
action 1, numVisits=164756, meanQ=4.930934, numObservations: 4
action 0, numVisits=35, meanQ=3.766668, numObservations: 1
action 2, numVisits=15, meanQ=2.267340, numObservations: 3
action 3, numVisits=11, meanQ=1.456382, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.661187 0.810844 0.613208 0.806215 0.48067 0.0415302 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7132, meanQ=7.733755, numObservations: 4
action 3, numVisits=1079, meanQ=7.616922, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 28557 episodes
GETTING ACTION FROM:
action 2, numVisits=23841, meanQ=6.427728, numObservations: 4
action 3, numVisits=5664, meanQ=6.347164, numObservations: 3
action 0, numVisits=5024, meanQ=0.190056, numObservations: 1
action -1, numVisits=2240, meanQ=-0.354797, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 2
Next state: 1 0.661187 0.810844 0.613208 0.806215 0.48067 0.0415302 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 45
Initial state: 0 0.563439 0.885913 0.677027 0.865693 0.209863 0.3406 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161128 episodes
GETTING ACTION FROM:
action 1, numVisits=161114, meanQ=4.982714, numObservations: 5
action 3, numVisits=9, meanQ=0.654456, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.563439 0.885913 0.677027 0.865693 0.209863 0.3406 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 46
Initial state: 0 0.768857 0.577422 0.636088 0.874946 0.520361 0.874511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 103905 episodes
GETTING ACTION FROM:
action 0, numVisits=103889, meanQ=5.496868, numObservations: 2
action 1, numVisits=12, meanQ=1.234167, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.768857 0.577422 0.636088 0.874946 0.520361 0.874511 w: 1
Observation: 0 0 0.506614 0 0.970354 0 0.907594 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=28467, meanQ=8.216555, numObservations: 5
action 3, numVisits=9, meanQ=5.443333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 170265 episodes
GETTING ACTION FROM:
action 2, numVisits=198704, meanQ=5.723437, numObservations: 5
action -1, numVisits=25, meanQ=4.308485, numObservations: 1
action 3, numVisits=12, meanQ=2.498342, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.768857 0.577422 0.636088 0.874946 0.520361 0.874511 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=15233, meanQ=6.151369, numObservations: 4
action 3, numVisits=18, meanQ=4.094444, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 204320 episodes
GETTING ACTION FROM:
action 3, numVisits=172393, meanQ=5.834866, numObservations: 4
action 2, numVisits=46696, meanQ=5.610555, numObservations: 5
action 1, numVisits=481, meanQ=5.338295, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.768857 0.577422 0.636088 0.874946 0.520361 0.874511 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 47
Initial state: 0 0.952078 0.719017 0.673845 0.824373 0.564792 0.809949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167810 episodes
GETTING ACTION FROM:
action 3, numVisits=167799, meanQ=5.031567, numObservations: 5
action 1, numVisits=6, meanQ=-0.999983, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.952078 0.719017 0.673845 0.824373 0.564792 0.809949 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 48
Initial state: 0 0.0171286 0.162424 0.515569 0.800517 0.65656 0.86128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168269 episodes
GETTING ACTION FROM:
action 3, numVisits=168258, meanQ=5.186180, numObservations: 5
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.0171286 0.162424 0.515569 0.800517 0.65656 0.86128 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 49
Initial state: 0 0.779995 0.662903 0.687053 0.827461 0.53572 0.813549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168015 episodes
GETTING ACTION FROM:
action 2, numVisits=163106, meanQ=4.993819, numObservations: 5
action 3, numVisits=4776, meanQ=4.896181, numObservations: 4
action 1, numVisits=109, meanQ=4.277273, numObservations: 4
action 0, numVisits=22, meanQ=3.500466, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.779995 0.662903 0.687053 0.827461 0.53572 0.813549 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 50
Initial state: 0 0.544714 0.858113 0.341632 0.0764465 0.629021 0.834486 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166989 episodes
GETTING ACTION FROM:
action 2, numVisits=166934, meanQ=4.954490, numObservations: 5
action 0, numVisits=29, meanQ=3.674504, numObservations: 1
action -1, numVisits=22, meanQ=3.448136, numObservations: 1
action 3, numVisits=3, meanQ=0.333333, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.544714 0.858113 0.341632 0.0764465 0.629021 0.834486 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23320, meanQ=8.414519, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29202 episodes
GETTING ACTION FROM:
action 3, numVisits=45217, meanQ=7.213665, numObservations: 5
action 1, numVisits=61, meanQ=5.469346, numObservations: 4
action 0, numVisits=7236, meanQ=0.230100, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=9, meanQ=-2.112200, numObservations: 1
action: 3
Next state: 1 0.544714 0.858113 0.341632 0.0764465 0.629021 0.834486 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 51
Initial state: 0 0.582761 0.8855 0.964433 0.70362 0.689688 0.833384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168778 episodes
GETTING ACTION FROM:
action 1, numVisits=168755, meanQ=4.998898, numObservations: 4
action 0, numVisits=16, meanQ=3.226370, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.582761 0.8855 0.964433 0.70362 0.689688 0.833384 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 52
Initial state: 0 0.367443 0.450034 0.519918 0.831021 0.654193 0.881613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166399 episodes
GETTING ACTION FROM:
action 3, numVisits=166338, meanQ=4.892576, numObservations: 5
action -1, numVisits=49, meanQ=3.900209, numObservations: 1
action 1, numVisits=9, meanQ=2.333344, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.367443 0.450034 0.519918 0.831021 0.654193 0.881613 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 53
Initial state: 0 0.583567 0.849968 0.875131 0.704639 0.673547 0.822173 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168689 episodes
GETTING ACTION FROM:
action 3, numVisits=168678, meanQ=5.031099, numObservations: 4
action 2, numVisits=6, meanQ=0.166667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.583567 0.849968 0.875131 0.704639 0.673547 0.822173 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 54
Initial state: 0 0.570245 0.828628 0.336339 0.414448 0.65868 0.837865 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167480 episodes
GETTING ACTION FROM:
action 2, numVisits=40427, meanQ=5.055792, numObservations: 5
action 3, numVisits=125234, meanQ=4.971759, numObservations: 5
action 1, numVisits=1815, meanQ=4.825835, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.570245 0.828628 0.336339 0.414448 0.65868 0.837865 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3686, meanQ=8.419204, numObservations: 4
action 3, numVisits=1916, meanQ=8.358206, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30123 episodes
GETTING ACTION FROM:
action 1, numVisits=19036, meanQ=6.470056, numObservations: 5
action 3, numVisits=7077, meanQ=6.428914, numObservations: 4
action 0, numVisits=9611, meanQ=-0.290609, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=3, meanQ=-129.197728, numObservations: 1
action: 1
Next state: 1 0.570245 0.828628 0.336339 0.414448 0.65868 0.837865 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 55
Initial state: 0 0.664746 0.820485 0.796994 0.176122 0.666939 0.842583 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167841 episodes
GETTING ACTION FROM:
action 2, numVisits=167835, meanQ=5.013823, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.664746 0.820485 0.796994 0.176122 0.666939 0.842583 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 56
Initial state: 0 0.505688 0.884856 0.838065 0.351791 0.561647 0.835304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167300 episodes
GETTING ACTION FROM:
action 3, numVisits=167289, meanQ=4.936892, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 3
action 2, numVisits=3, meanQ=-2.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.505688 0.884856 0.838065 0.351791 0.561647 0.835304 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 57
Initial state: 0 0.693624 0.819211 0.503218 0.818104 0.161855 0.383257 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167938 episodes
GETTING ACTION FROM:
action 3, numVisits=167927, meanQ=5.028584, numObservations: 5
action 1, numVisits=6, meanQ=1.498333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.693624 0.819211 0.503218 0.818104 0.161855 0.383257 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11705, meanQ=8.553983, numObservations: 3
action 1, numVisits=7232, meanQ=8.540009, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29984 episodes
GETTING ACTION FROM:
action 2, numVisits=20364, meanQ=7.204816, numObservations: 5
action 1, numVisits=24656, meanQ=6.898149, numObservations: 5
action -1, numVisits=3895, meanQ=-0.434177, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=6, meanQ=-3.650000, numObservations: 1
action: 2
Next state: 1 0.693624 0.819211 0.503218 0.818104 0.161855 0.383257 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 58
Initial state: 0 0.724593 0.486052 0.644895 0.88211 0.61829 0.829459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 152785 episodes
GETTING ACTION FROM:
action 1, numVisits=133294, meanQ=5.016981, numObservations: 4
action -1, numVisits=10694, meanQ=3.034209, numObservations: 1
action 0, numVisits=8781, meanQ=3.027917, numObservations: 1
action 3, numVisits=12, meanQ=0.666675, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action: 1
Next state: 2 0.724593 0.486052 0.644895 0.88211 0.61829 0.829459 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 59
Initial state: 0 0.645077 0.894623 0.449338 0.201736 0.663319 0.837808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 149046 episodes
GETTING ACTION FROM:
action 1, numVisits=149021, meanQ=4.585589, numObservations: 3
action -1, numVisits=17, meanQ=2.701457, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.645077 0.894623 0.449338 0.201736 0.663319 0.837808 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 60
Initial state: 0 0.631612 0.80079 0.680356 0.878865 0.875848 0.421839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98711 episodes
GETTING ACTION FROM:
action 0, numVisits=98700, meanQ=2.960724, numObservations: 1
action 3, numVisits=6, meanQ=-2.000000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.631612 0.80079 0.680356 0.878865 0.875848 0.421839 w: 1
Observation: 0 0 0.833587 0 0.924812 0 0.455788 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=98681, meanQ=4.969594, numObservations: 5
action 1, numVisits=13, meanQ=2.836923, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 167920 episodes
GETTING ACTION FROM:
action 3, numVisits=266600, meanQ=4.967288, numObservations: 5
action 1, numVisits=14, meanQ=2.985000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.631612 0.80079 0.680356 0.878865 0.875848 0.421839 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 61
Initial state: 0 0.590215 0.866009 0.562469 0.00804177 0.545956 0.859437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168529 episodes
GETTING ACTION FROM:
action 1, numVisits=168449, meanQ=4.995169, numObservations: 5
action -1, numVisits=42, meanQ=3.917117, numObservations: 1
action 0, numVisits=26, meanQ=3.604979, numObservations: 1
action 3, numVisits=9, meanQ=1.212222, numObservations: 3
action 2, numVisits=3, meanQ=0.663333, numObservations: 3
action: 1
Next state: 1 0.590215 0.866009 0.562469 0.00804177 0.545956 0.859437 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 62
Initial state: 0 0.514605 0.883633 0.701744 0.654758 0.537399 0.808215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159155 episodes
GETTING ACTION FROM:
action 3, numVisits=159149, meanQ=4.795610, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.514605 0.883633 0.701744 0.654758 0.537399 0.808215 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 63
Initial state: 0 0.549263 0.891005 0.600603 0.84451 0.785962 0.0201028 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167218 episodes
GETTING ACTION FROM:
action 3, numVisits=165507, meanQ=4.984075, numObservations: 5
action 1, numVisits=1682, meanQ=4.817556, numObservations: 5
action -1, numVisits=21, meanQ=3.365901, numObservations: 1
action 2, numVisits=6, meanQ=0.166667, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.549263 0.891005 0.600603 0.84451 0.785962 0.0201028 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12033, meanQ=4.610508, numObservations: 5
action 0, numVisits=22, meanQ=3.337775, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 31079 episodes
GETTING ACTION FROM:
action 1, numVisits=34924, meanQ=5.192290, numObservations: 5
action 2, numVisits=107, meanQ=2.505246, numObservations: 4
action 0, numVisits=8090, meanQ=-0.500138, numObservations: 1
action -1, numVisits=16, meanQ=-2.063112, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.549263 0.891005 0.600603 0.84451 0.785962 0.0201028 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 64
Initial state: 0 0.603707 0.884296 0.810766 0.463966 0.530681 0.896395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169455 episodes
GETTING ACTION FROM:
action 2, numVisits=169423, meanQ=5.036406, numObservations: 5
action 0, numVisits=27, meanQ=3.657286, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.603707 0.884296 0.810766 0.463966 0.530681 0.896395 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 65
Initial state: 0 0.608443 0.839994 0.666371 0.826116 0.466089 0.751062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166962 episodes
GETTING ACTION FROM:
action 3, numVisits=166947, meanQ=5.003052, numObservations: 5
action 2, numVisits=8, meanQ=0.263750, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.608443 0.839994 0.666371 0.826116 0.466089 0.751062 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23096, meanQ=8.421104, numObservations: 3
action 1, numVisits=41, meanQ=7.341229, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 32031 episodes
GETTING ACTION FROM:
action 2, numVisits=51027, meanQ=7.173939, numObservations: 3
action 1, numVisits=390, meanQ=5.928314, numObservations: 5
action -1, numVisits=3751, meanQ=0.093898, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-68.953832, numObservations: 1
action: 2
Next state: 1 0.608443 0.839994 0.666371 0.826116 0.466089 0.751062 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 66
Initial state: 0 0.548611 0.801373 0.39365 0.720309 0.580517 0.803947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166877 episodes
GETTING ACTION FROM:
action 1, numVisits=166863, meanQ=4.913089, numObservations: 4
action 3, numVisits=9, meanQ=1.666667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.548611 0.801373 0.39365 0.720309 0.580517 0.803947 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 67
Initial state: 0 0.530051 0.867273 0.699582 0.836875 0.63435 0.326581 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167663 episodes
GETTING ACTION FROM:
action 3, numVisits=167656, meanQ=5.053974, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.530051 0.867273 0.699582 0.836875 0.63435 0.326581 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 68
Initial state: 0 0.600245 0.887401 0.861604 0.813264 0.606446 0.845101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98288 episodes
GETTING ACTION FROM:
action -1, numVisits=98270, meanQ=2.880653, numObservations: 1
action 3, numVisits=14, meanQ=0.928571, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.600245 0.887401 0.861604 0.813264 0.606446 0.845101 w: 1
Observation: 0 0.563932 0 0.944067 0 0.55132 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=98205, meanQ=4.899756, numObservations: 4
action 0, numVisits=40, meanQ=3.795591, numObservations: 1
action -1, numVisits=17, meanQ=3.225043, numObservations: 1
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 164582 episodes
GETTING ACTION FROM:
action 3, numVisits=262781, meanQ=4.823808, numObservations: 4
action 0, numVisits=42, meanQ=3.710321, numObservations: 1
action -1, numVisits=18, meanQ=3.090794, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action: 3
Next state: 1 0.600245 0.887401 0.861604 0.813264 0.606446 0.845101 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 69
Initial state: 0 0.642558 0.879689 0.836333 0.0654335 0.657369 0.863416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98232 episodes
GETTING ACTION FROM:
action -1, numVisits=98227, meanQ=2.927080, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.642558 0.879689 0.836333 0.0654335 0.657369 0.863416 w: 1
Observation: 0 0.61653 0 0.903272 0 0.640934 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=98120, meanQ=4.934066, numObservations: 4
action 0, numVisits=91, meanQ=4.220723, numObservations: 1
action 2, numVisits=9, meanQ=2.333344, numObservations: 3
action 3, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 167219 episodes
GETTING ACTION FROM:
action 1, numVisits=265338, meanQ=5.006866, numObservations: 4
action 0, numVisits=92, meanQ=4.201591, numObservations: 1
action 2, numVisits=9, meanQ=2.333344, numObservations: 3
action 3, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.642558 0.879689 0.836333 0.0654335 0.657369 0.863416 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 70
Initial state: 0 0.413181 0.246323 0.53118 0.832425 0.53161 0.883768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98973 episodes
GETTING ACTION FROM:
action -1, numVisits=98943, meanQ=3.066764, numObservations: 1
action 3, numVisits=26, meanQ=1.345396, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.413181 0.246323 0.53118 0.832425 0.53161 0.883768 w: 1
Observation: 0 0.372602 0 0.60572 0 0.44507 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=98911, meanQ=5.153518, numObservations: 4
action 1, numVisits=16, meanQ=3.248762, numObservations: 3
action 2, numVisits=11, meanQ=2.633645, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 165912 episodes
GETTING ACTION FROM:
action 3, numVisits=264821, meanQ=5.163340, numObservations: 4
action 1, numVisits=16, meanQ=3.248762, numObservations: 3
action 2, numVisits=13, meanQ=2.383862, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.413181 0.246323 0.53118 0.832425 0.53161 0.883768 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 71
Initial state: 0 0.628079 0.874223 0.683447 0.893922 0.514821 0.989295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166323 episodes
GETTING ACTION FROM:
action 1, numVisits=166283, meanQ=4.929102, numObservations: 3
action 0, numVisits=33, meanQ=3.696941, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.628079 0.874223 0.683447 0.893922 0.514821 0.989295 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 72
Initial state: 0 0.52282 0.869303 0.57672 0.873347 0.269587 0.0637326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167538 episodes
GETTING ACTION FROM:
action 3, numVisits=167520, meanQ=4.993180, numObservations: 5
action 0, numVisits=12, meanQ=2.668953, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.52282 0.869303 0.57672 0.873347 0.269587 0.0637326 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23352, meanQ=8.377204, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29195 episodes
GETTING ACTION FROM:
action 2, numVisits=49961, meanQ=7.195415, numObservations: 4
action 1, numVisits=73, meanQ=4.451918, numObservations: 4
action -1, numVisits=2510, meanQ=-0.282814, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=6, meanQ=-3.650000, numObservations: 1
action: 2
Next state: 1 0.52282 0.869303 0.57672 0.873347 0.269587 0.0637326 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 73
Initial state: 0 0.546949 0.83141 0.124383 0.800245 0.500521 0.802961 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168086 episodes
GETTING ACTION FROM:
action 2, numVisits=167760, meanQ=5.017777, numObservations: 4
action 1, numVisits=182, meanQ=4.515718, numObservations: 3
action -1, numVisits=111, meanQ=4.368973, numObservations: 1
action 3, numVisits=31, meanQ=3.606461, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.546949 0.83141 0.124383 0.800245 0.500521 0.802961 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8496, meanQ=7.842731, numObservations: 4
action 1, numVisits=6, meanQ=4.996667, numObservations: 2
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 13085 episodes
GETTING ACTION FROM:
action 3, numVisits=11350, meanQ=7.217708, numObservations: 4
action 1, numVisits=1417, meanQ=5.645453, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=8786, meanQ=0.139890, numObservations: 3
action -1, numVisits=34, meanQ=-0.922647, numObservations: 1
action: 3
Next state: 1 0.546949 0.83141 0.124383 0.800245 0.500521 0.802961 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 74
Initial state: 0 0.113393 0.648119 0.662715 0.839748 0.683887 0.891787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167020 episodes
GETTING ACTION FROM:
action 3, numVisits=166938, meanQ=4.955877, numObservations: 5
action -1, numVisits=78, meanQ=4.175966, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.113393 0.648119 0.662715 0.839748 0.683887 0.891787 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 75
Initial state: 0 0.60326 0.812106 0.766978 0.429983 0.698408 0.87195 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98960 episodes
GETTING ACTION FROM:
action 0, numVisits=98937, meanQ=3.113658, numObservations: 1
action 1, numVisits=17, meanQ=1.161182, numObservations: 4
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.60326 0.812106 0.766978 0.429983 0.698408 0.87195 w: 1
Observation: 0 0 0.833496 0 0.429 0 0.951194 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=98867, meanQ=5.166834, numObservations: 5
action -1, numVisits=60, meanQ=4.301742, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 168093 episodes
GETTING ACTION FROM:
action 3, numVisits=266959, meanQ=5.262143, numObservations: 5
action -1, numVisits=61, meanQ=4.295771, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.60326 0.812106 0.766978 0.429983 0.698408 0.87195 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 76
Initial state: 0 0.647426 0.842902 0.826153 0.737149 0.584887 0.809647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168440 episodes
GETTING ACTION FROM:
action 2, numVisits=168411, meanQ=4.931182, numObservations: 4
action 0, numVisits=25, meanQ=3.399058, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.647426 0.842902 0.826153 0.737149 0.584887 0.809647 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27827, meanQ=8.294603, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 41495 episodes
GETTING ACTION FROM:
action 1, numVisits=64551, meanQ=7.093514, numObservations: 3
action 3, numVisits=25, meanQ=4.799600, numObservations: 4
action -1, numVisits=4745, meanQ=0.274183, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 0, numVisits=4, meanQ=-90.644970, numObservations: 1
action: 1
Next state: 1 0.647426 0.842902 0.826153 0.737149 0.584887 0.809647 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 77
Initial state: 0 0.602942 0.846263 0.59495 0.849701 0.901736 0.410389 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166961 episodes
GETTING ACTION FROM:
action 1, numVisits=166911, meanQ=4.930560, numObservations: 5
action 0, numVisits=38, meanQ=3.800452, numObservations: 1
action 2, numVisits=7, meanQ=1.002886, numObservations: 2
action 3, numVisits=3, meanQ=-3.296667, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.602942 0.846263 0.59495 0.849701 0.901736 0.410389 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 78
Initial state: 0 0.860067 0.768536 0.58105 0.876382 0.629041 0.829111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158858 episodes
GETTING ACTION FROM:
action 3, numVisits=158831, meanQ=4.830276, numObservations: 5
action -1, numVisits=19, meanQ=3.140824, numObservations: 1
action 1, numVisits=5, meanQ=1.198020, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.860067 0.768536 0.58105 0.876382 0.629041 0.829111 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 79
Initial state: 0 0.693348 0.847177 0.0586738 0.968411 0.614498 0.896503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167742 episodes
GETTING ACTION FROM:
action 2, numVisits=167713, meanQ=5.033485, numObservations: 4
action 0, numVisits=16, meanQ=3.270596, numObservations: 1
action 3, numVisits=7, meanQ=1.428571, numObservations: 2
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.693348 0.847177 0.0586738 0.968411 0.614498 0.896503 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12466, meanQ=5.402178, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 188886 episodes
GETTING ACTION FROM:
action 2, numVisits=201348, meanQ=4.942029, numObservations: 5
action 0, numVisits=4, meanQ=0.475000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.693348 0.847177 0.0586738 0.968411 0.614498 0.896503 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=4322, meanQ=6.370116, numObservations: 4
action 2, numVisits=3, meanQ=0.330033, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 212897 episodes
GETTING ACTION FROM:
action 3, numVisits=217216, meanQ=5.831308, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 2, numVisits=3, meanQ=0.330033, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.693348 0.847177 0.0586738 0.968411 0.614498 0.896503 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 80
Initial state: 0 0.550832 0.836345 0.507683 0.889418 0.913043 0.900154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167987 episodes
GETTING ACTION FROM:
action 2, numVisits=167912, meanQ=4.973484, numObservations: 3
action 3, numVisits=69, meanQ=4.069639, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.550832 0.836345 0.507683 0.889418 0.913043 0.900154 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27734, meanQ=8.297905, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 30397 episodes
GETTING ACTION FROM:
action 3, numVisits=47166, meanQ=7.356769, numObservations: 4
action 1, numVisits=3108, meanQ=5.858946, numObservations: 5
action -1, numVisits=7856, meanQ=0.230774, numObservations: 1
action 0, numVisits=5, meanQ=-4.139303, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.550832 0.836345 0.507683 0.889418 0.913043 0.900154 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 81
Initial state: 0 0.520043 0.83861 0.564822 0.839184 0.385235 0.184661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166456 episodes
GETTING ACTION FROM:
action 3, numVisits=163489, meanQ=5.013115, numObservations: 4
action -1, numVisits=2950, meanQ=3.158960, numObservations: 1
action 2, numVisits=14, meanQ=1.428571, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.520043 0.83861 0.564822 0.839184 0.385235 0.184661 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=15445, meanQ=8.532579, numObservations: 3
action 1, numVisits=3097, meanQ=8.504325, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 35533 episodes
GETTING ACTION FROM:
action 2, numVisits=28081, meanQ=7.321466, numObservations: 4
action 1, numVisits=10485, meanQ=6.745010, numObservations: 5
action -1, numVisits=15509, meanQ=0.127902, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-196.636569, numObservations: 1
action: 2
Next state: 1 0.520043 0.83861 0.564822 0.839184 0.385235 0.184661 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 82
Initial state: 0 0.59309 0.884452 0.691672 0.00654285 0.609744 0.84106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168087 episodes
GETTING ACTION FROM:
action 1, numVisits=168081, meanQ=5.018435, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.59309 0.884452 0.691672 0.00654285 0.609744 0.84106 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 83
Initial state: 0 0.671233 0.829933 0.421522 0.580012 0.60623 0.851838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166003 episodes
GETTING ACTION FROM:
action 3, numVisits=165578, meanQ=5.145773, numObservations: 5
action 1, numVisits=367, meanQ=4.749779, numObservations: 4
action 0, numVisits=42, meanQ=4.090600, numObservations: 1
action -1, numVisits=15, meanQ=3.358045, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.671233 0.829933 0.421522 0.580012 0.60623 0.851838 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 84
Initial state: 0 0.514232 0.836459 0.281258 0.496436 0.589149 0.890134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167946 episodes
GETTING ACTION FROM:
action 2, numVisits=167940, meanQ=5.049217, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.514232 0.836459 0.281258 0.496436 0.589149 0.890134 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=23175, meanQ=8.395969, numObservations: 3
action 3, numVisits=48, meanQ=7.417088, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 38889 episodes
GETTING ACTION FROM:
action 1, numVisits=37993, meanQ=7.463543, numObservations: 3
action 2, numVisits=7, meanQ=6.700000, numObservations: 2
action 3, numVisits=88, meanQ=2.286549, numObservations: 4
action -1, numVisits=24021, meanQ=0.135005, numObservations: 1
action 0, numVisits=6, meanQ=-4.150774, numObservations: 1
action: 1
Next state: 0 0.514232 0.836459 0.281258 0.496436 0.589149 0.890134 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2158, meanQ=8.356797, numObservations: 3
action 1, numVisits=9, meanQ=3.769959, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action -1, numVisits=2, meanQ=-7.417489, numObservations: 1
Sampled 20219 episodes
GETTING ACTION FROM:
action 3, numVisits=3936, meanQ=7.307397, numObservations: 3
action 2, numVisits=23, meanQ=4.999565, numObservations: 4
action 1, numVisits=9, meanQ=3.769959, numObservations: 3
action 0, numVisits=18421, meanQ=-1.713765, numObservations: 1
action -1, numVisits=2, meanQ=-7.417489, numObservations: 1
action: 3
Next state: 1 0.514232 0.836459 0.281258 0.496436 0.589149 0.890134 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 85
Initial state: 0 0.633521 0.893714 0.518892 0.860265 0.290422 0.852596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167977 episodes
GETTING ACTION FROM:
action 2, numVisits=167971, meanQ=5.015150, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.633521 0.893714 0.518892 0.860265 0.290422 0.852596 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 86
Initial state: 0 0.652239 0.256155 0.550909 0.884372 0.660093 0.835873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168406 episodes
GETTING ACTION FROM:
action 2, numVisits=168305, meanQ=5.020926, numObservations: 5
action 0, numVisits=72, meanQ=4.219444, numObservations: 1
action 1, numVisits=20, meanQ=2.749500, numObservations: 3
action 3, numVisits=7, meanQ=1.701443, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.652239 0.256155 0.550909 0.884372 0.660093 0.835873 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 87
Initial state: 0 0.614952 0.822421 0.222782 0.569946 0.669156 0.820303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167750 episodes
GETTING ACTION FROM:
action 2, numVisits=167725, meanQ=5.021140, numObservations: 4
action 3, numVisits=18, meanQ=2.835017, numObservations: 3
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.614952 0.822421 0.222782 0.569946 0.669156 0.820303 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=18990, meanQ=8.538792, numObservations: 3
action 1, numVisits=60, meanQ=7.728337, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 38737 episodes
GETTING ACTION FROM:
action 3, numVisits=50300, meanQ=6.980141, numObservations: 4
action 1, numVisits=658, meanQ=5.999182, numObservations: 4
action 0, numVisits=6827, meanQ=0.255669, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=4, meanQ=-4.475000, numObservations: 1
action: 3
Next state: 1 0.614952 0.822421 0.222782 0.569946 0.669156 0.820303 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 88
Initial state: 0 0.540955 0.873789 0.513128 0.890823 0.930769 0.316119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166889 episodes
GETTING ACTION FROM:
action 2, numVisits=166707, meanQ=4.931796, numObservations: 4
action 0, numVisits=176, meanQ=4.323103, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.540955 0.873789 0.513128 0.890823 0.930769 0.316119 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 89
Initial state: 0 0.603698 0.97296 0.556351 0.885376 0.687803 0.89086 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167266 episodes
GETTING ACTION FROM:
action 1, numVisits=167244, meanQ=4.982367, numObservations: 5
action 2, numVisits=17, meanQ=2.767082, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.603698 0.97296 0.556351 0.885376 0.687803 0.89086 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 90
Initial state: 0 0.901484 0.243013 0.568855 0.882852 0.537968 0.857572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167547 episodes
GETTING ACTION FROM:
action 2, numVisits=167315, meanQ=4.926547, numObservations: 5
action 0, numVisits=111, meanQ=4.277038, numObservations: 1
action -1, numVisits=103, meanQ=4.255941, numObservations: 1
action 1, numVisits=11, meanQ=2.808182, numObservations: 2
action 3, numVisits=7, meanQ=2.002871, numObservations: 3
action: 2
Next state: 1 0.901484 0.243013 0.568855 0.882852 0.537968 0.857572 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 91
Initial state: 0 0.911329 0.0572291 0.575778 0.816607 0.560633 0.808431 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167112 episodes
GETTING ACTION FROM:
action 2, numVisits=167104, meanQ=4.951596, numObservations: 4
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.911329 0.0572291 0.575778 0.816607 0.560633 0.808431 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 92
Initial state: 0 0.595102 0.832398 0.649544 0.845665 0.749461 0.530891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166719 episodes
GETTING ACTION FROM:
action 1, numVisits=166694, meanQ=4.930701, numObservations: 3
action -1, numVisits=21, meanQ=3.424457, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.595102 0.832398 0.649544 0.845665 0.749461 0.530891 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 93
Initial state: 0 0.556162 0.897579 0.581744 0.628757 0.645221 0.829229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167791 episodes
GETTING ACTION FROM:
action 1, numVisits=167778, meanQ=4.957609, numObservations: 4
action 2, numVisits=8, meanQ=1.748750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.556162 0.897579 0.581744 0.628757 0.645221 0.829229 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 94
Initial state: 0 0.608633 0.888303 0.679349 0.861524 0.577046 0.333889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 152093 episodes
GETTING ACTION FROM:
action 1, numVisits=151827, meanQ=4.623353, numObservations: 4
action -1, numVisits=131, meanQ=4.035719, numObservations: 1
action 0, numVisits=108, meanQ=3.974002, numObservations: 1
action 2, numVisits=20, meanQ=2.845005, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action: 1
Next state: 1 0.608633 0.888303 0.679349 0.861524 0.577046 0.333889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 95
Initial state: 0 0.575067 0.867749 0.698553 0.856649 0.35622 0.757482 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167464 episodes
GETTING ACTION FROM:
action 2, numVisits=167442, meanQ=4.944349, numObservations: 5
action 0, numVisits=13, meanQ=3.000769, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.575067 0.867749 0.698553 0.856649 0.35622 0.757482 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 96
Initial state: 0 0.537782 0.893649 0.849492 0.70893 0.671435 0.863115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168419 episodes
GETTING ACTION FROM:
action 2, numVisits=168404, meanQ=5.001071, numObservations: 5
action 1, numVisits=8, meanQ=1.878775, numObservations: 2
action 3, numVisits=3, meanQ=0.000033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.537782 0.893649 0.849492 0.70893 0.671435 0.863115 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 97
Initial state: 0 0.624337 0.836196 0.859761 0.443952 0.514126 0.802775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168024 episodes
GETTING ACTION FROM:
action 3, numVisits=167998, meanQ=5.016237, numObservations: 4
action 0, numVisits=16, meanQ=3.275601, numObservations: 1
action 1, numVisits=3, meanQ=0.663333, numObservations: 2
action 2, numVisits=5, meanQ=-0.002000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.624337 0.836196 0.859761 0.443952 0.514126 0.802775 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 98
Initial state: 0 0.674109 0.20005 0.523559 0.885044 0.575064 0.824796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 108148 episodes
GETTING ACTION FROM:
action 0, numVisits=98772, meanQ=5.927170, numObservations: 3
action 3, numVisits=9321, meanQ=4.973115, numObservations: 3
action -1, numVisits=48, meanQ=4.136053, numObservations: 1
action 1, numVisits=6, meanQ=1.506700, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.674109 0.20005 0.523559 0.885044 0.575064 0.824796 w: 1
Observation: 0 0 0.180024 0 0.786874 0 0.772176 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31015, meanQ=8.153654, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 152472 episodes
GETTING ACTION FROM:
action 3, numVisits=183485, meanQ=5.327090, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.674109 0.20005 0.523559 0.885044 0.575064 0.824796 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 99
Initial state: 0 0.593898 0.893231 0.624371 0.867253 0.816757 0.976001 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165373 episodes
GETTING ACTION FROM:
action 1, numVisits=165323, meanQ=4.987807, numObservations: 4
action 0, numVisits=41, meanQ=3.860408, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 3
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.593898 0.893231 0.624371 0.867253 0.816757 0.976001 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 100
Initial state: 0 0.562421 0.804881 0.641811 0.89216 0.826618 0.667644 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166717 episodes
GETTING ACTION FROM:
action 1, numVisits=166686, meanQ=5.111678, numObservations: 5
action 2, numVisits=26, meanQ=3.226931, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.562421 0.804881 0.641811 0.89216 0.826618 0.667644 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 101
Initial state: 0 0.581019 0.884406 0.539303 0.480394 0.656251 0.82811 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167322 episodes
GETTING ACTION FROM:
action 2, numVisits=167265, meanQ=4.923701, numObservations: 5
action 3, numVisits=35, meanQ=3.449440, numObservations: 4
action 0, numVisits=19, meanQ=3.345246, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.581019 0.884406 0.539303 0.480394 0.656251 0.82811 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8534, meanQ=7.788873, numObservations: 3
action 1, numVisits=22, meanQ=6.453182, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 24109 episodes
GETTING ACTION FROM:
action 3, numVisits=23825, meanQ=6.685703, numObservations: 3
action 1, numVisits=56, meanQ=4.785179, numObservations: 4
action 2, numVisits=15, meanQ=4.199333, numObservations: 4
action 0, numVisits=8367, meanQ=0.395074, numObservations: 1
action -1, numVisits=406, meanQ=-0.385602, numObservations: 1
action: 3
Next state: 1 0.581019 0.884406 0.539303 0.480394 0.656251 0.82811 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 102
Initial state: 0 0.663656 0.839482 0.178878 0.742246 0.541669 0.844541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167719 episodes
GETTING ACTION FROM:
action 3, numVisits=167676, meanQ=4.987600, numObservations: 5
action 0, numVisits=22, meanQ=3.497951, numObservations: 1
action 1, numVisits=18, meanQ=2.611678, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.663656 0.839482 0.178878 0.742246 0.541669 0.844541 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 103
Initial state: 0 0.646719 0.804343 0.525473 0.895819 0.951835 0.566978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166828 episodes
GETTING ACTION FROM:
action 1, numVisits=166794, meanQ=4.933499, numObservations: 4
action 0, numVisits=28, meanQ=3.603008, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.646719 0.804343 0.525473 0.895819 0.951835 0.566978 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 104
Initial state: 0 0.541068 0.860347 0.533983 0.845406 0.861307 0.260008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168082 episodes
GETTING ACTION FROM:
action 1, numVisits=167923, meanQ=4.955561, numObservations: 4
action 0, numVisits=154, meanQ=4.409772, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.541068 0.860347 0.533983 0.845406 0.861307 0.260008 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 105
Initial state: 0 0.593942 0.840636 0.840237 0.736345 0.618411 0.88046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167840 episodes
GETTING ACTION FROM:
action 2, numVisits=167830, meanQ=4.954586, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.593942 0.840636 0.840237 0.736345 0.618411 0.88046 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=12417, meanQ=4.787425, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 30096 episodes
GETTING ACTION FROM:
action 3, numVisits=32301, meanQ=5.541539, numObservations: 4
action -1, numVisits=7940, meanQ=-0.234109, numObservations: 1
action 0, numVisits=2273, meanQ=-0.362761, numObservations: 3
action 2, numVisits=4, meanQ=-4.002500, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.593942 0.840636 0.840237 0.736345 0.618411 0.88046 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 106
Initial state: 0 0.525288 0.512414 0.685961 0.848275 0.642321 0.847813 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168315 episodes
GETTING ACTION FROM:
action 2, numVisits=168309, meanQ=5.029648, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.525288 0.512414 0.685961 0.848275 0.642321 0.847813 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 107
Initial state: 0 0.45534 0.274185 0.636559 0.87252 0.696116 0.872827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168055 episodes
GETTING ACTION FROM:
action 3, numVisits=168045, meanQ=5.027167, numObservations: 3
action 2, numVisits=5, meanQ=1.198020, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.45534 0.274185 0.636559 0.87252 0.696116 0.872827 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 108
Initial state: 0 0.813947 0.0494268 0.589982 0.864513 0.657678 0.880065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165183 episodes
GETTING ACTION FROM:
action 3, numVisits=165150, meanQ=4.882609, numObservations: 4
action 0, numVisits=18, meanQ=3.110016, numObservations: 1
action 1, numVisits=9, meanQ=1.666667, numObservations: 2
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.813947 0.0494268 0.589982 0.864513 0.657678 0.880065 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 109
Initial state: 0 0.617866 0.860479 0.796011 0.1418 0.528787 0.837048 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167408 episodes
GETTING ACTION FROM:
action 3, numVisits=167402, meanQ=4.948744, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.617866 0.860479 0.796011 0.1418 0.528787 0.837048 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 110
Initial state: 0 0.533666 0.823782 0.664885 0.895437 0.728206 0.645248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166556 episodes
GETTING ACTION FROM:
action 2, numVisits=166441, meanQ=4.946120, numObservations: 4
action -1, numVisits=105, meanQ=4.193760, numObservations: 1
action 1, numVisits=7, meanQ=1.427171, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.533666 0.823782 0.664885 0.895437 0.728206 0.645248 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 111
Initial state: 0 0.698548 0.870248 0.673257 0.883686 0.344097 0.924896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 104293 episodes
GETTING ACTION FROM:
action 0, numVisits=104285, meanQ=5.859732, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.698548 0.870248 0.673257 0.883686 0.344097 0.924896 w: 1
Observation: 0 0 0.776724 0 0.801441 0 0.948656 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=42340, meanQ=7.725219, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 169703 episodes
GETTING ACTION FROM:
action 3, numVisits=211993, meanQ=5.525299, numObservations: 4
action -1, numVisits=28, meanQ=4.173201, numObservations: 1
action 0, numVisits=14, meanQ=3.633163, numObservations: 1
action 2, numVisits=12, meanQ=2.915850, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.698548 0.870248 0.673257 0.883686 0.344097 0.924896 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=15973, meanQ=6.167218, numObservations: 3
action 2, numVisits=7, meanQ=3.852857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 205375 episodes
GETTING ACTION FROM:
action 2, numVisits=201665, meanQ=5.904954, numObservations: 5
action 3, numVisits=19675, meanQ=5.845756, numObservations: 4
action 1, numVisits=14, meanQ=2.650000, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.698548 0.870248 0.673257 0.883686 0.344097 0.924896 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 112
Initial state: 0 0.696716 0.824429 0.518161 0.866252 0.0632087 0.412747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98501 episodes
GETTING ACTION FROM:
action -1, numVisits=98483, meanQ=2.928527, numObservations: 1
action 1, numVisits=12, meanQ=0.666675, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action: -1
Next state: 0 0.696716 0.824429 0.518161 0.866252 0.0632087 0.412747 w: 1
Observation: 0 0.760481 0 0.598772 0 0.0442759 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=98470, meanQ=5.019699, numObservations: 3
action 2, numVisits=3, meanQ=0.993333, numObservations: 3
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 165077 episodes
GETTING ACTION FROM:
action 1, numVisits=263541, meanQ=4.951212, numObservations: 3
action 2, numVisits=9, meanQ=1.775578, numObservations: 3
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.696716 0.824429 0.518161 0.866252 0.0632087 0.412747 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 113
Initial state: 0 0.607201 0.832382 0.648908 0.855285 0.932365 0.408514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 102121 episodes
GETTING ACTION FROM:
action 0, numVisits=102113, meanQ=5.917447, numObservations: 3
action 1, numVisits=4, meanQ=-0.999975, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.607201 0.832382 0.648908 0.855285 0.932365 0.408514 w: 1
Observation: 0 0 0.878058 0 0.839577 0 0.469315 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=35565, meanQ=7.843758, numObservations: 4
action 3, numVisits=4, meanQ=2.995000, numObservations: 2
action 1, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 162570 episodes
GETTING ACTION FROM:
action 2, numVisits=198076, meanQ=5.485257, numObservations: 4
action 0, numVisits=35, meanQ=4.311839, numObservations: 1
action 3, numVisits=27, meanQ=4.022967, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.607201 0.832382 0.648908 0.855285 0.932365 0.408514 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 114
Initial state: 0 0.540906 0.816766 0.593046 0.868601 0.719816 0.472856 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167129 episodes
GETTING ACTION FROM:
action 2, numVisits=167122, meanQ=4.944187, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.540906 0.816766 0.593046 0.868601 0.719816 0.472856 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 115
Initial state: 0 0.629843 0.880117 0.156235 0.170597 0.622405 0.888421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167131 episodes
GETTING ACTION FROM:
action 3, numVisits=167125, meanQ=4.999078, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.629843 0.880117 0.156235 0.170597 0.622405 0.888421 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=12160, meanQ=5.402896, numObservations: 4
action 2, numVisits=9, meanQ=3.221111, numObservations: 4
action 1, numVisits=11, meanQ=3.184564, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 207486 episodes
GETTING ACTION FROM:
action 2, numVisits=203494, meanQ=6.079086, numObservations: 4
action 3, numVisits=16160, meanQ=5.247256, numObservations: 4
action 1, numVisits=11, meanQ=3.184564, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.629843 0.880117 0.156235 0.170597 0.622405 0.888421 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2186, meanQ=8.498084, numObservations: 3
action 3, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 41601 episodes
GETTING ACTION FROM:
action 1, numVisits=7739, meanQ=6.909319, numObservations: 4
action 3, numVisits=55, meanQ=6.599818, numObservations: 3
action 0, numVisits=24011, meanQ=-1.698778, numObservations: 2
action -1, numVisits=11987, meanQ=-1.712496, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.629843 0.880117 0.156235 0.170597 0.622405 0.888421 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 116
Initial state: 0 0.595397 0.867486 0.205285 0.137838 0.509708 0.874606 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159827 episodes
GETTING ACTION FROM:
action 3, numVisits=159819, meanQ=4.858699, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=3, meanQ=-3.296667, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.595397 0.867486 0.205285 0.137838 0.509708 0.874606 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 117
Initial state: 0 0.616991 0.890776 0.209524 0.18846 0.591795 0.890489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166518 episodes
GETTING ACTION FROM:
action 2, numVisits=166473, meanQ=4.913788, numObservations: 4
action -1, numVisits=33, meanQ=3.706496, numObservations: 1
action 3, numVisits=9, meanQ=1.666667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.616991 0.890776 0.209524 0.18846 0.591795 0.890489 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 118
Initial state: 0 0.577614 0.858148 0.324906 0.00308434 0.693202 0.851835 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167385 episodes
GETTING ACTION FROM:
action 3, numVisits=167362, meanQ=4.945537, numObservations: 4
action 2, numVisits=18, meanQ=2.776678, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.577614 0.858148 0.324906 0.00308434 0.693202 0.851835 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 119
Initial state: 0 0.698281 0.80597 0.805593 0.0298138 0.539637 0.827841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159413 episodes
GETTING ACTION FROM:
action 1, numVisits=159320, meanQ=4.878925, numObservations: 4
action -1, numVisits=65, meanQ=4.026016, numObservations: 1
action 0, numVisits=25, meanQ=3.491480, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.698281 0.80597 0.805593 0.0298138 0.539637 0.827841 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 120
Initial state: 0 0.69421 0.859365 0.238063 0.353918 0.602567 0.83931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165407 episodes
GETTING ACTION FROM:
action 2, numVisits=165400, meanQ=4.939849, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.69421 0.859365 0.238063 0.353918 0.602567 0.83931 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=22948, meanQ=8.436087, numObservations: 3
action 3, numVisits=19, meanQ=6.894742, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 39648 episodes
GETTING ACTION FROM:
action 1, numVisits=44489, meanQ=7.161197, numObservations: 3
action 0, numVisits=18099, meanQ=-0.455412, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=3, meanQ=-5.300000, numObservations: 1
action 3, numVisits=26, meanQ=-9.398157, numObservations: 3
action: 1
Next state: 1 0.69421 0.859365 0.238063 0.353918 0.602567 0.83931 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 121
Initial state: 0 0.568457 0.873154 0.972534 0.190239 0.576847 0.818751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167472 episodes
GETTING ACTION FROM:
action 3, numVisits=167408, meanQ=5.135062, numObservations: 4
action 0, numVisits=48, meanQ=4.121341, numObservations: 1
action 1, numVisits=13, meanQ=2.536923, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.568457 0.873154 0.972534 0.190239 0.576847 0.818751 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 122
Initial state: 0 0.655666 0.872272 0.554168 0.896865 0.31948 0.758851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167831 episodes
GETTING ACTION FROM:
action 2, numVisits=167716, meanQ=5.022679, numObservations: 3
action 0, numVisits=110, meanQ=4.362184, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.655666 0.872272 0.554168 0.896865 0.31948 0.758851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 123
Initial state: 0 0.658777 0.867603 0.24884 0.178654 0.68009 0.870009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167876 episodes
GETTING ACTION FROM:
action 1, numVisits=167869, meanQ=5.146409, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.658777 0.867603 0.24884 0.178654 0.68009 0.870009 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 124
Initial state: 0 0.514216 0.843497 0.618081 0.827475 0.104747 0.549343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166967 episodes
GETTING ACTION FROM:
action 2, numVisits=166957, meanQ=4.988964, numObservations: 5
action 3, numVisits=3, meanQ=0.333333, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.514216 0.843497 0.618081 0.827475 0.104747 0.549343 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 125
Initial state: 0 0.348308 0.200829 0.67313 0.868322 0.551937 0.819287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165379 episodes
GETTING ACTION FROM:
action 1, numVisits=165137, meanQ=4.943197, numObservations: 5
action 0, numVisits=139, meanQ=4.367939, numObservations: 1
action 3, numVisits=90, meanQ=4.023336, numObservations: 4
action 2, numVisits=11, meanQ=2.520009, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.348308 0.200829 0.67313 0.868322 0.551937 0.819287 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 126
Initial state: 0 0.590659 0.805496 0.631963 0.81507 0.298313 0.0236268 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 121948 episodes
GETTING ACTION FROM:
action 2, numVisits=56678, meanQ=4.977034, numObservations: 5
action 0, numVisits=65266, meanQ=2.950034, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.590659 0.805496 0.631963 0.81507 0.298313 0.0236268 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 127
Initial state: 0 0.542025 0.83909 0.441066 0.443415 0.571089 0.82361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131037 episodes
GETTING ACTION FROM:
action 2, numVisits=79176, meanQ=4.967913, numObservations: 4
action -1, numVisits=51857, meanQ=2.916115, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.542025 0.83909 0.441066 0.443415 0.571089 0.82361 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13073, meanQ=8.338370, numObservations: 4
action 1, numVisits=9, meanQ=6.331111, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 24589 episodes
GETTING ACTION FROM:
action 3, numVisits=32784, meanQ=6.967903, numObservations: 4
action 1, numVisits=123, meanQ=5.821450, numObservations: 4
action 0, numVisits=4718, meanQ=0.372181, numObservations: 1
action -1, numVisits=48, meanQ=-0.515206, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.542025 0.83909 0.441066 0.443415 0.571089 0.82361 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 128
Initial state: 0 0.602357 0.879808 0.0461538 0.181729 0.58616 0.84387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166215 episodes
GETTING ACTION FROM:
action 1, numVisits=166204, meanQ=4.965074, numObservations: 4
action 2, numVisits=6, meanQ=1.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.602357 0.879808 0.0461538 0.181729 0.58616 0.84387 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 129
Initial state: 0 0.570527 0.889819 0.697886 0.815719 0.955996 0.253067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167009 episodes
GETTING ACTION FROM:
action 2, numVisits=166937, meanQ=4.953197, numObservations: 3
action -1, numVisits=54, meanQ=3.988178, numObservations: 1
action 3, numVisits=12, meanQ=1.833333, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.570527 0.889819 0.697886 0.815719 0.955996 0.253067 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 130
Initial state: 0 0.642636 0.818135 0.606991 0.858597 0.225827 0.4902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166492 episodes
GETTING ACTION FROM:
action 1, numVisits=166354, meanQ=4.959372, numObservations: 5
action 0, numVisits=81, meanQ=4.205365, numObservations: 1
action 3, numVisits=54, meanQ=3.986481, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.642636 0.818135 0.606991 0.858597 0.225827 0.4902 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 131
Initial state: 0 0.510875 0.866709 0.601001 0.852245 0.70104 0.385787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167512 episodes
GETTING ACTION FROM:
action 2, numVisits=167500, meanQ=4.948487, numObservations: 5
action 1, numVisits=7, meanQ=1.570000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.510875 0.866709 0.601001 0.852245 0.70104 0.385787 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 132
Initial state: 0 0.476473 0.185299 0.692107 0.887363 0.516266 0.813533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158295 episodes
GETTING ACTION FROM:
action 1, numVisits=155362, meanQ=4.801260, numObservations: 4
action -1, numVisits=2929, meanQ=2.891581, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.476473 0.185299 0.692107 0.887363 0.516266 0.813533 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=21591, meanQ=8.421046, numObservations: 4
action 2, numVisits=7, meanQ=5.568571, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 27845 episodes
GETTING ACTION FROM:
action 3, numVisits=43958, meanQ=7.300957, numObservations: 4
action 2, numVisits=402, meanQ=4.689466, numObservations: 5
action -1, numVisits=5078, meanQ=0.321373, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=7, meanQ=-56.412425, numObservations: 1
action: 3
Next state: 1 0.476473 0.185299 0.692107 0.887363 0.516266 0.813533 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 133
Initial state: 0 0.555046 0.880852 0.652608 0.889214 0.500139 0.787281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167836 episodes
GETTING ACTION FROM:
action 2, numVisits=167567, meanQ=5.016501, numObservations: 4
action 1, numVisits=254, meanQ=4.566950, numObservations: 4
action 3, numVisits=11, meanQ=1.726382, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.555046 0.880852 0.652608 0.889214 0.500139 0.787281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 134
Initial state: 0 0.6862 0.89637 0.867486 0.454856 0.584369 0.81315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167904 episodes
GETTING ACTION FROM:
action 1, numVisits=167889, meanQ=5.002670, numObservations: 3
action 2, numVisits=10, meanQ=2.300010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.6862 0.89637 0.867486 0.454856 0.584369 0.81315 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 135
Initial state: 0 0.740404 0.597232 0.661227 0.853304 0.60758 0.824194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168669 episodes
GETTING ACTION FROM:
action 1, numVisits=168628, meanQ=5.013225, numObservations: 3
action -1, numVisits=36, meanQ=3.831102, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.740404 0.597232 0.661227 0.853304 0.60758 0.824194 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 136
Initial state: 0 0.589544 0.872379 0.532333 0.859707 0.659223 0.694082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166850 episodes
GETTING ACTION FROM:
action 3, numVisits=166825, meanQ=4.935050, numObservations: 4
action 1, numVisits=14, meanQ=2.351450, numObservations: 4
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.589544 0.872379 0.532333 0.859707 0.659223 0.694082 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10083, meanQ=4.667841, numObservations: 4
action 2, numVisits=2469, meanQ=4.550105, numObservations: 4
action 3, numVisits=12, meanQ=2.498342, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 44722 episodes
GETTING ACTION FROM:
action 1, numVisits=39841, meanQ=5.775472, numObservations: 4
action 2, numVisits=2566, meanQ=4.577558, numObservations: 4
action 3, numVisits=14, meanQ=2.206436, numObservations: 4
action 0, numVisits=11884, meanQ=-0.282217, numObservations: 1
action -1, numVisits=2985, meanQ=-0.591022, numObservations: 1
action: 1
Next state: 1 0.589544 0.872379 0.532333 0.859707 0.659223 0.694082 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 137
Initial state: 0 0.534189 0.856377 0.589259 0.860724 0.0775392 0.151129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167179 episodes
GETTING ACTION FROM:
action 2, numVisits=167076, meanQ=5.008267, numObservations: 5
action -1, numVisits=55, meanQ=4.088298, numObservations: 1
action 0, numVisits=46, meanQ=3.969807, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.534189 0.856377 0.589259 0.860724 0.0775392 0.151129 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12503, meanQ=5.514342, numObservations: 3
action 1, numVisits=9, meanQ=0.997800, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 186639 episodes
GETTING ACTION FROM:
action 2, numVisits=199137, meanQ=5.053635, numObservations: 4
action 1, numVisits=9, meanQ=0.997800, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.534189 0.856377 0.589259 0.860724 0.0775392 0.151129 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 138
Initial state: 0 0.601195 0.805156 0.0815737 0.998331 0.606369 0.839319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165593 episodes
GETTING ACTION FROM:
action 3, numVisits=165543, meanQ=4.913309, numObservations: 4
action 1, numVisits=41, meanQ=3.553905, numObservations: 4
action 2, numVisits=5, meanQ=-0.200000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.601195 0.805156 0.0815737 0.998331 0.606369 0.839319 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 139
Initial state: 0 0.627585 0.890295 0.837847 0.692248 0.520503 0.889881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168357 episodes
GETTING ACTION FROM:
action 3, numVisits=168346, meanQ=5.050245, numObservations: 5
action 2, numVisits=5, meanQ=-0.002000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.627585 0.890295 0.837847 0.692248 0.520503 0.889881 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 140
Initial state: 0 0.590131 0.848619 0.595012 0.837822 0.188842 0.955642 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167667 episodes
GETTING ACTION FROM:
action 2, numVisits=167660, meanQ=4.978965, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.590131 0.848619 0.595012 0.837822 0.188842 0.955642 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 141
Initial state: 0 0.577607 0.82896 0.042172 0.0851104 0.626216 0.892725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168550 episodes
GETTING ACTION FROM:
action 2, numVisits=168534, meanQ=5.015227, numObservations: 3
action 1, numVisits=8, meanQ=2.498750, numObservations: 3
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.577607 0.82896 0.042172 0.0851104 0.626216 0.892725 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27542, meanQ=8.348168, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 32122 episodes
GETTING ACTION FROM:
action 1, numVisits=39337, meanQ=7.632794, numObservations: 4
action 3, numVisits=14558, meanQ=6.057431, numObservations: 5
action -1, numVisits=5701, meanQ=0.165980, numObservations: 1
action 0, numVisits=72, meanQ=-0.699530, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.577607 0.82896 0.042172 0.0851104 0.626216 0.892725 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=245, meanQ=8.004940, numObservations: 3
action 1, numVisits=40, meanQ=7.349507, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 33313 episodes
GETTING ACTION FROM:
action 1, numVisits=65, meanQ=6.445851, numObservations: 4
action 3, numVisits=18819, meanQ=6.263763, numObservations: 3
action 0, numVisits=10340, meanQ=-1.568482, numObservations: 1
action -1, numVisits=4378, meanQ=-1.623495, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.577607 0.82896 0.042172 0.0851104 0.626216 0.892725 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 142
Initial state: 0 0.575692 0.889725 0.161158 0.552015 0.638384 0.846058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165894 episodes
GETTING ACTION FROM:
action 1, numVisits=165853, meanQ=4.972266, numObservations: 4
action -1, numVisits=24, meanQ=3.484689, numObservations: 1
action 3, numVisits=14, meanQ=2.998571, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.575692 0.889725 0.161158 0.552015 0.638384 0.846058 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 143
Initial state: 0 0.568167 0.803354 0.390812 0.83963 0.683248 0.808197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166698 episodes
GETTING ACTION FROM:
action 3, numVisits=166681, meanQ=4.968210, numObservations: 3
action 2, numVisits=11, meanQ=2.273645, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.568167 0.803354 0.390812 0.83963 0.683248 0.808197 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 144
Initial state: 0 0.681665 0.836763 0.681126 0.871936 0.343943 0.435158 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167305 episodes
GETTING ACTION FROM:
action 1, numVisits=167295, meanQ=4.974557, numObservations: 5
action 2, numVisits=5, meanQ=-0.200000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.681665 0.836763 0.681126 0.871936 0.343943 0.435158 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=12306, meanQ=4.781712, numObservations: 4
action 0, numVisits=80, meanQ=4.049016, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 208440 episodes
GETTING ACTION FROM:
action 2, numVisits=208439, meanQ=5.896288, numObservations: 5
action 3, numVisits=12306, meanQ=4.781712, numObservations: 4
action 0, numVisits=82, meanQ=3.901479, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.681665 0.836763 0.681126 0.871936 0.343943 0.435158 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 145
Initial state: 0 0.665011 0.889758 0.619331 0.801072 0.0254883 0.128001 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167746 episodes
GETTING ACTION FROM:
action 2, numVisits=167735, meanQ=4.968073, numObservations: 4
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.665011 0.889758 0.619331 0.801072 0.0254883 0.128001 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 146
Initial state: 0 0.652598 0.89012 0.669899 0.844054 0.449192 0.476873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166061 episodes
GETTING ACTION FROM:
action 3, numVisits=166032, meanQ=4.999808, numObservations: 5
action -1, numVisits=18, meanQ=3.293093, numObservations: 1
action 2, numVisits=7, meanQ=2.285729, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.652598 0.89012 0.669899 0.844054 0.449192 0.476873 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=23150, meanQ=8.425181, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 19176 episodes
GETTING ACTION FROM:
action 1, numVisits=36698, meanQ=7.542530, numObservations: 4
action 2, numVisits=18, meanQ=5.388333, numObservations: 3
action -1, numVisits=5406, meanQ=-0.611685, numObservations: 1
action 0, numVisits=207, meanQ=-1.023027, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.652598 0.89012 0.669899 0.844054 0.449192 0.476873 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 147
Initial state: 0 0.0054399 0.782811 0.60594 0.849947 0.59278 0.877261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167896 episodes
GETTING ACTION FROM:
action 3, numVisits=167890, meanQ=5.026410, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0054399 0.782811 0.60594 0.849947 0.59278 0.877261 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 148
Initial state: 0 0.145886 0.294856 0.578766 0.864062 0.554368 0.827556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167778 episodes
GETTING ACTION FROM:
action 1, numVisits=167656, meanQ=4.949215, numObservations: 3
action -1, numVisits=118, meanQ=2.259058, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.145886 0.294856 0.578766 0.864062 0.554368 0.827556 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=27570, meanQ=8.306276, numObservations: 4
action 3, numVisits=7, meanQ=5.568571, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 24622 episodes
GETTING ACTION FROM:
action 2, numVisits=43550, meanQ=7.504274, numObservations: 4
action 3, numVisits=497, meanQ=4.633120, numObservations: 3
action 1, numVisits=5, meanQ=3.798020, numObservations: 2
action -1, numVisits=8009, meanQ=0.090508, numObservations: 1
action 0, numVisits=141, meanQ=-0.470428, numObservations: 1
action: 2
Next state: 1 0.145886 0.294856 0.578766 0.864062 0.554368 0.827556 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 149
Initial state: 0 0.629209 0.894972 0.52686 0.83062 0.257218 0.872722 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165623 episodes
GETTING ACTION FROM:
action 3, numVisits=165470, meanQ=4.917658, numObservations: 4
action 1, numVisits=61, meanQ=4.023772, numObservations: 3
action 0, numVisits=35, meanQ=3.735599, numObservations: 1
action 2, numVisits=27, meanQ=3.592230, numObservations: 4
action -1, numVisits=30, meanQ=3.578418, numObservations: 1
action: 3
Next state: 0 0.629209 0.894972 0.52686 0.83062 0.257218 0.872722 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=27312, meanQ=8.303363, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 15691 episodes
GETTING ACTION FROM:
action 2, numVisits=33969, meanQ=7.812879, numObservations: 4
action 1, numVisits=152, meanQ=5.512257, numObservations: 4
action 0, numVisits=8884, meanQ=0.128433, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.629209 0.894972 0.52686 0.83062 0.257218 0.872722 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 150
Initial state: 0 0.876485 0.617626 0.578476 0.863003 0.679081 0.872614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167242 episodes
GETTING ACTION FROM:
action 1, numVisits=167201, meanQ=4.925177, numObservations: 5
action 0, numVisits=28, meanQ=3.608830, numObservations: 1
action 2, numVisits=7, meanQ=1.428571, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.876485 0.617626 0.578476 0.863003 0.679081 0.872614 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 151
Initial state: 0 0.550689 0.883628 0.498198 0.949697 0.558719 0.822675 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167483 episodes
GETTING ACTION FROM:
action 1, numVisits=167425, meanQ=4.972314, numObservations: 5
action 0, numVisits=52, meanQ=3.954771, numObservations: 1
action 2, numVisits=3, meanQ=0.000033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.550689 0.883628 0.498198 0.949697 0.558719 0.822675 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 152
Initial state: 0 0.888299 0.183126 0.619682 0.865413 0.681819 0.818444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168929 episodes
GETTING ACTION FROM:
action 2, numVisits=168919, meanQ=5.019993, numObservations: 4
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.888299 0.183126 0.619682 0.865413 0.681819 0.818444 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 153
Initial state: 0 0.654863 0.80126 0.521988 0.889221 0.0805524 0.0132491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166734 episodes
GETTING ACTION FROM:
action 3, numVisits=166466, meanQ=4.949131, numObservations: 5
action -1, numVisits=264, meanQ=1.288477, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.654863 0.80126 0.521988 0.889221 0.0805524 0.0132491 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12041, meanQ=8.421533, numObservations: 3
action 2, numVisits=11056, meanQ=8.413659, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 28292 episodes
GETTING ACTION FROM:
action 1, numVisits=25925, meanQ=7.225189, numObservations: 3
action 2, numVisits=22107, meanQ=7.097698, numObservations: 5
action 3, numVisits=6, meanQ=4.665017, numObservations: 2
action -1, numVisits=3316, meanQ=0.307805, numObservations: 1
action 0, numVisits=38, meanQ=-0.991044, numObservations: 1
action: 1
Next state: 1 0.654863 0.80126 0.521988 0.889221 0.0805524 0.0132491 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 154
Initial state: 0 0.864725 0.902765 0.573129 0.817297 0.549525 0.886381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98922 episodes
GETTING ACTION FROM:
action 0, numVisits=98912, meanQ=2.944175, numObservations: 1
action 2, numVisits=6, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.864725 0.902765 0.573129 0.817297 0.549525 0.886381 w: 1
Observation: 0 0 0.886386 0 0.899601 0 0.962997 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=98900, meanQ=5.021245, numObservations: 4
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 169486 episodes
GETTING ACTION FROM:
action 3, numVisits=268379, meanQ=4.771331, numObservations: 4
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 1, numVisits=8, meanQ=0.486250, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.864725 0.902765 0.573129 0.817297 0.549525 0.886381 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 155
Initial state: 0 0.67295 0.845102 0.593416 0.880607 0.899343 0.245288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166277 episodes
GETTING ACTION FROM:
action 3, numVisits=165183, meanQ=4.965803, numObservations: 5
action 2, numVisits=1076, meanQ=4.759129, numObservations: 4
action 1, numVisits=14, meanQ=2.343571, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.67295 0.845102 0.593416 0.880607 0.899343 0.245288 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 156
Initial state: 0 0.487184 0.238372 0.656339 0.827941 0.613142 0.825603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157818 episodes
GETTING ACTION FROM:
action 2, numVisits=157739, meanQ=4.890992, numObservations: 4
action -1, numVisits=72, meanQ=2.548758, numObservations: 1
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.487184 0.238372 0.656339 0.827941 0.613142 0.825603 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=11799, meanQ=3.592956, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
Sampled 187553 episodes
GETTING ACTION FROM:
action 2, numVisits=187540, meanQ=5.336301, numObservations: 4
action -1, numVisits=11799, meanQ=3.592956, numObservations: 1
action 1, numVisits=15, meanQ=2.866000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 2
Next state: 1 0.487184 0.238372 0.656339 0.827941 0.613142 0.825603 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 157
Initial state: 0 0.222586 0.835869 0.606157 0.831887 0.666538 0.884507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168748 episodes
GETTING ACTION FROM:
action 2, numVisits=168742, meanQ=5.029156, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.222586 0.835869 0.606157 0.831887 0.666538 0.884507 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10769, meanQ=5.799599, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
Sampled 207090 episodes
GETTING ACTION FROM:
action 1, numVisits=205683, meanQ=5.763114, numObservations: 5
action 2, numVisits=12178, meanQ=5.711350, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 1
Next state: 0 0.222586 0.835869 0.606157 0.831887 0.666538 0.884507 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=638, meanQ=7.772923, numObservations: 5
action 2, numVisits=4, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 69129 episodes
GETTING ACTION FROM:
action 3, numVisits=46654, meanQ=6.201650, numObservations: 5
action 2, numVisits=10, meanQ=4.598000, numObservations: 3
action 0, numVisits=23056, meanQ=-1.749924, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=53, meanQ=-8.853408, numObservations: 1
action: 3
Next state: 1 0.222586 0.835869 0.606157 0.831887 0.666538 0.884507 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 158
Initial state: 0 0.115799 0.335802 0.546398 0.861508 0.699524 0.843584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167783 episodes
GETTING ACTION FROM:
action 2, numVisits=167709, meanQ=4.997502, numObservations: 3
action 1, numVisits=64, meanQ=4.036177, numObservations: 4
action 3, numVisits=6, meanQ=2.168350, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.115799 0.335802 0.546398 0.861508 0.699524 0.843584 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 159
Initial state: 0 0.629907 0.80385 0.682345 0.831317 0.710856 0.35361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168325 episodes
GETTING ACTION FROM:
action 1, numVisits=146220, meanQ=4.980781, numObservations: 5
action 2, numVisits=22010, meanQ=4.949792, numObservations: 3
action -1, numVisits=62, meanQ=4.114885, numObservations: 1
action 3, numVisits=31, meanQ=3.642590, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.629907 0.80385 0.682345 0.831317 0.710856 0.35361 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 160
Initial state: 0 0.556557 0.899422 0.814922 0.147723 0.537206 0.801619 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 99164 episodes
GETTING ACTION FROM:
action -1, numVisits=99113, meanQ=2.980377, numObservations: 1
action 0, numVisits=45, meanQ=1.982165, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.556557 0.899422 0.814922 0.147723 0.537206 0.801619 w: 1
Observation: 0 0.530414 0 0.842728 0 0.538792 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=99081, meanQ=5.010874, numObservations: 4
action -1, numVisits=14, meanQ=3.035978, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action 1, numVisits=8, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 167743 episodes
GETTING ACTION FROM:
action 3, numVisits=266823, meanQ=4.858344, numObservations: 4
action -1, numVisits=15, meanQ=2.922733, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action 1, numVisits=8, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.556557 0.899422 0.814922 0.147723 0.537206 0.801619 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=20043, meanQ=5.354102, numObservations: 4
action 1, numVisits=13, meanQ=1.460008, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 187035 episodes
GETTING ACTION FROM:
action 3, numVisits=207074, meanQ=4.783154, numObservations: 4
action 1, numVisits=13, meanQ=1.460008, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.556557 0.899422 0.814922 0.147723 0.537206 0.801619 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 161
Initial state: 0 0.61182 0.871826 0.529776 0.826477 0.822365 0.511085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 145725 episodes
GETTING ACTION FROM:
action 3, numVisits=114786, meanQ=4.937713, numObservations: 3
action 0, numVisits=30935, meanQ=3.013162, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.61182 0.871826 0.529776 0.826477 0.822365 0.511085 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 162
Initial state: 0 0.892484 0.684252 0.612756 0.802498 0.641149 0.881485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166307 episodes
GETTING ACTION FROM:
action 2, numVisits=166268, meanQ=4.969249, numObservations: 4
action -1, numVisits=34, meanQ=3.769626, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.892484 0.684252 0.612756 0.802498 0.641149 0.881485 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 163
Initial state: 0 0.584527 0.84786 0.54533 0.803286 0.0105241 0.31642 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98474 episodes
GETTING ACTION FROM:
action -1, numVisits=98469, meanQ=2.920417, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.584527 0.84786 0.54533 0.803286 0.0105241 0.31642 w: 1
Observation: 0 0.510888 0 0.567268 0 0 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=98427, meanQ=4.993284, numObservations: 5
action 0, numVisits=37, meanQ=3.879610, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 167429 episodes
GETTING ACTION FROM:
action 2, numVisits=265855, meanQ=5.053202, numObservations: 5
action 0, numVisits=38, meanQ=3.803056, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.584527 0.84786 0.54533 0.803286 0.0105241 0.31642 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 164
Initial state: 0 0.547175 0.896958 0.581635 0.874216 0.0099655 0.689124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166600 episodes
GETTING ACTION FROM:
action 1, numVisits=166524, meanQ=5.002217, numObservations: 4
action 0, numVisits=37, meanQ=3.822632, numObservations: 1
action 3, numVisits=33, meanQ=3.161824, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.547175 0.896958 0.581635 0.874216 0.0099655 0.689124 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 165
Initial state: 0 0.520908 0.828715 0.733651 0.348234 0.532437 0.818252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98127 episodes
GETTING ACTION FROM:
action 0, numVisits=98122, meanQ=2.908806, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.520908 0.828715 0.733651 0.348234 0.532437 0.818252 w: 1
Observation: 0 0 0.788263 0 0.260002 0 0.742398 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=98113, meanQ=4.961107, numObservations: 4
action 3, numVisits=3, meanQ=0.993333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 165432 episodes
GETTING ACTION FROM:
action 1, numVisits=263540, meanQ=4.792068, numObservations: 4
action 3, numVisits=6, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=3, meanQ=-4.003300, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.520908 0.828715 0.733651 0.348234 0.532437 0.818252 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 166
Initial state: 0 0.642436 0.834951 0.611053 0.0841512 0.698974 0.856997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167028 episodes
GETTING ACTION FROM:
action 3, numVisits=166998, meanQ=4.920468, numObservations: 5
action 1, numVisits=25, meanQ=1.884408, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.642436 0.834951 0.611053 0.0841512 0.698974 0.856997 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 167
Initial state: 0 0.564027 0.408917 0.639969 0.887072 0.601507 0.88224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167368 episodes
GETTING ACTION FROM:
action 3, numVisits=167359, meanQ=5.001029, numObservations: 3
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.564027 0.408917 0.639969 0.887072 0.601507 0.88224 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 168
Initial state: 0 0.533689 0.890014 0.674377 0.80418 0.197746 0.573251 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166506 episodes
GETTING ACTION FROM:
action 3, numVisits=166472, meanQ=4.954139, numObservations: 4
action -1, numVisits=30, meanQ=3.695127, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.533689 0.890014 0.674377 0.80418 0.197746 0.573251 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26692, meanQ=8.323990, numObservations: 4
action 1, numVisits=588, meanQ=8.084406, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 32155 episodes
GETTING ACTION FROM:
action 2, numVisits=48825, meanQ=7.240084, numObservations: 4
action 1, numVisits=1486, meanQ=6.553610, numObservations: 3
action 3, numVisits=28, meanQ=6.532143, numObservations: 4
action -1, numVisits=9089, meanQ=0.139136, numObservations: 1
action 0, numVisits=10, meanQ=-2.100980, numObservations: 1
action: 2
Next state: 1 0.533689 0.890014 0.674377 0.80418 0.197746 0.573251 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 169
Initial state: 0 0.802586 0.00921603 0.691759 0.843856 0.563928 0.884235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166998 episodes
GETTING ACTION FROM:
action 1, numVisits=166986, meanQ=4.988069, numObservations: 4
action 3, numVisits=7, meanQ=0.428571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.802586 0.00921603 0.691759 0.843856 0.563928 0.884235 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 170
Initial state: 0 0.0955307 0.957906 0.587809 0.82198 0.522611 0.843942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 108812 episodes
GETTING ACTION FROM:
action 0, numVisits=98347, meanQ=5.956663, numObservations: 3
action 3, numVisits=10428, meanQ=5.014300, numObservations: 5
action -1, numVisits=25, meanQ=3.855144, numObservations: 1
action 1, numVisits=10, meanQ=1.799000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 0
Next state: 0 0.0955307 0.957906 0.587809 0.82198 0.522611 0.843942 w: 1
Observation: 0 0 0.901434 0 0.752997 0 0.925002 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=34175, meanQ=7.972472, numObservations: 5
action 2, numVisits=7, meanQ=5.001443, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 172999 episodes
GETTING ACTION FROM:
action 3, numVisits=207169, meanQ=5.599952, numObservations: 5
action 2, numVisits=10, meanQ=3.000010, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0955307 0.957906 0.587809 0.82198 0.522611 0.843942 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 171
Initial state: 0 0.985162 0.0423365 0.679215 0.862567 0.680059 0.879496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167276 episodes
GETTING ACTION FROM:
action 1, numVisits=167241, meanQ=4.944940, numObservations: 4
action 0, numVisits=31, meanQ=3.617235, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.985162 0.0423365 0.679215 0.862567 0.680059 0.879496 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 172
Initial state: 0 0.461335 0.302753 0.6582 0.896315 0.693938 0.819133 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167069 episodes
GETTING ACTION FROM:
action 2, numVisits=167053, meanQ=4.994881, numObservations: 4
action 1, numVisits=11, meanQ=2.362745, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.461335 0.302753 0.6582 0.896315 0.693938 0.819133 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 173
Initial state: 0 0.447873 0.261461 0.629594 0.876281 0.506811 0.831919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 103953 episodes
GETTING ACTION FROM:
action 0, numVisits=103724, meanQ=5.850953, numObservations: 3
action -1, numVisits=224, meanQ=3.339076, numObservations: 1
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.447873 0.261461 0.629594 0.876281 0.506811 0.831919 w: 1
Observation: 0 0 0.238742 0 0.77652 0 0.807195 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=42839, meanQ=7.511277, numObservations: 4
action 2, numVisits=7, meanQ=3.268571, numObservations: 3
action 1, numVisits=15, meanQ=2.866000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 167094 episodes
GETTING ACTION FROM:
action 3, numVisits=209930, meanQ=5.619632, numObservations: 4
action 1, numVisits=15, meanQ=2.866000, numObservations: 4
action 2, numVisits=8, meanQ=1.987513, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.447873 0.261461 0.629594 0.876281 0.506811 0.831919 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 174
Initial state: 0 0.100006 0.270295 0.530178 0.876271 0.622816 0.806512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168013 episodes
GETTING ACTION FROM:
action 1, numVisits=167732, meanQ=5.046111, numObservations: 4
action 3, numVisits=245, meanQ=4.613882, numObservations: 3
action 2, numVisits=23, meanQ=3.556096, numObservations: 4
action -1, numVisits=11, meanQ=2.949550, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.100006 0.270295 0.530178 0.876271 0.622816 0.806512 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23319, meanQ=8.392661, numObservations: 4
action 3, numVisits=51, meanQ=7.545104, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 47835 episodes
GETTING ACTION FROM:
action 2, numVisits=60552, meanQ=7.166950, numObservations: 4
action 3, numVisits=156, meanQ=6.187566, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=10486, meanQ=0.237366, numObservations: 1
action 0, numVisits=10, meanQ=-1.901000, numObservations: 1
action: 2
Next state: 1 0.100006 0.270295 0.530178 0.876271 0.622816 0.806512 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 175
Initial state: 0 0.637258 0.890582 0.764516 0.423943 0.553117 0.839641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166779 episodes
GETTING ACTION FROM:
action 3, numVisits=166661, meanQ=4.993612, numObservations: 4
action -1, numVisits=114, meanQ=4.355002, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.637258 0.890582 0.764516 0.423943 0.553117 0.839641 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 176
Initial state: 0 0.567603 0.814422 0.2222 0.165205 0.640297 0.84111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167308 episodes
GETTING ACTION FROM:
action 3, numVisits=167163, meanQ=4.991413, numObservations: 4
action 0, numVisits=111, meanQ=4.342554, numObservations: 1
action -1, numVisits=29, meanQ=3.611074, numObservations: 1
action 1, numVisits=3, meanQ=-0.659967, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 1 0.567603 0.814422 0.2222 0.165205 0.640297 0.84111 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 177
Initial state: 0 0.554734 0.800972 0.919004 0.859357 0.501521 0.814188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 99247 episodes
GETTING ACTION FROM:
action 0, numVisits=82084, meanQ=2.938139, numObservations: 1
action -1, numVisits=17146, meanQ=2.910008, numObservations: 1
action 1, numVisits=6, meanQ=0.166667, numObservations: 2
action 3, numVisits=8, meanQ=-0.001250, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action: 0
Next state: 0 0.554734 0.800972 0.919004 0.859357 0.501521 0.814188 w: 1
Observation: 0 0 0.757567 0 0.76543 0 0.801887 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=81985, meanQ=4.988145, numObservations: 5
action -1, numVisits=43, meanQ=3.983210, numObservations: 1
action 0, numVisits=33, meanQ=3.804058, numObservations: 1
action 1, numVisits=9, meanQ=2.553344, numObservations: 3
action 3, numVisits=13, meanQ=2.516923, numObservations: 3
Sampled 169194 episodes
GETTING ACTION FROM:
action 2, numVisits=251178, meanQ=5.064746, numObservations: 5
action -1, numVisits=44, meanQ=3.967524, numObservations: 1
action 0, numVisits=33, meanQ=3.804058, numObservations: 1
action 1, numVisits=9, meanQ=2.553344, numObservations: 3
action 3, numVisits=13, meanQ=2.516923, numObservations: 3
action: 2
Next state: 1 0.554734 0.800972 0.919004 0.859357 0.501521 0.814188 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 178
Initial state: 0 0.696639 0.705044 0.505799 0.896798 0.581491 0.807566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168126 episodes
GETTING ACTION FROM:
action 1, numVisits=168097, meanQ=5.020265, numObservations: 5
action -1, numVisits=25, meanQ=3.648289, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.696639 0.705044 0.505799 0.896798 0.581491 0.807566 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8217, meanQ=7.881335, numObservations: 3
action 2, numVisits=120, meanQ=7.245337, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 26844 episodes
GETTING ACTION FROM:
action 3, numVisits=8217, meanQ=7.881335, numObservations: 3
action 2, numVisits=148, meanQ=6.873989, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=26804, meanQ=-0.155651, numObservations: 1
action -1, numVisits=12, meanQ=-2.084150, numObservations: 1
action: 3
Next state: 1 0.696639 0.705044 0.505799 0.896798 0.581491 0.807566 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 179
Initial state: 0 0.638903 0.87749 0.606465 0.887657 0.201183 0.626035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166095 episodes
GETTING ACTION FROM:
action 1, numVisits=166069, meanQ=4.929407, numObservations: 4
action 2, numVisits=21, meanQ=3.335252, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.638903 0.87749 0.606465 0.887657 0.201183 0.626035 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 180
Initial state: 0 0.618366 0.883643 0.171925 0.926814 0.553862 0.890473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159151 episodes
GETTING ACTION FROM:
action 2, numVisits=159106, meanQ=4.840264, numObservations: 4
action -1, numVisits=41, meanQ=3.773380, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.618366 0.883643 0.171925 0.926814 0.553862 0.890473 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=11832, meanQ=3.394893, numObservations: 1
action 1, numVisits=18, meanQ=1.666111, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 208501 episodes
GETTING ACTION FROM:
action 3, numVisits=208493, meanQ=5.981021, numObservations: 5
action -1, numVisits=11840, meanQ=3.391701, numObservations: 1
action 1, numVisits=18, meanQ=1.666111, numObservations: 4
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.618366 0.883643 0.171925 0.926814 0.553862 0.890473 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 181
Initial state: 0 0.921653 0.795255 0.537228 0.893992 0.6305 0.889058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97867 episodes
GETTING ACTION FROM:
action 0, numVisits=97858, meanQ=3.017789, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=4, meanQ=-2.500000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.921653 0.795255 0.537228 0.893992 0.6305 0.889058 w: 1
Observation: 0 0 0.840843 0 0.820366 0 0.954018 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=97850, meanQ=5.043623, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 167334 episodes
GETTING ACTION FROM:
action 2, numVisits=265182, meanQ=5.133149, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.921653 0.795255 0.537228 0.893992 0.6305 0.889058 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=19969, meanQ=5.628396, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 206738 episodes
GETTING ACTION FROM:
action 1, numVisits=201600, meanQ=5.607241, numObservations: 5
action 2, numVisits=25108, meanQ=5.537338, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 1
Next state: 2 0.921653 0.795255 0.537228 0.893992 0.6305 0.889058 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -16.7411
Run # 182
Initial state: 0 0.656742 0.837557 0.523491 0.86938 0.757869 0.247699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168216 episodes
GETTING ACTION FROM:
action 1, numVisits=167785, meanQ=5.027722, numObservations: 4
action 3, numVisits=345, meanQ=4.664995, numObservations: 3
action -1, numVisits=83, meanQ=4.282113, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.656742 0.837557 0.523491 0.86938 0.757869 0.247699 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.327653 0.086559 0.570684 0.838246 0.529885 0.861679 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168439 episodes
GETTING ACTION FROM:
action 1, numVisits=167416, meanQ=5.011290, numObservations: 4
action 3, numVisits=901, meanQ=4.768363, numObservations: 5
action 2, numVisits=118, meanQ=4.380683, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.327653 0.086559 0.570684 0.838246 0.529885 0.861679 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=27651, meanQ=8.311551, numObservations: 3
action 3, numVisits=16, meanQ=6.748125, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 40112 episodes
GETTING ACTION FROM:
action 2, numVisits=64736, meanQ=6.956538, numObservations: 3
action 3, numVisits=346, meanQ=6.353832, numObservations: 4
action -1, numVisits=2693, meanQ=0.051315, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=6, meanQ=-3.882552, numObservations: 1
action: 2
Next state: 1 0.327653 0.086559 0.570684 0.838246 0.529885 0.861679 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 184
Initial state: 0 0.63323 0.830346 0.974891 0.483895 0.516099 0.899502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167362 episodes
GETTING ACTION FROM:
action 3, numVisits=167277, meanQ=5.030184, numObservations: 5
action -1, numVisits=59, meanQ=4.121457, numObservations: 1
action 0, numVisits=24, meanQ=3.563039, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.63323 0.830346 0.974891 0.483895 0.516099 0.899502 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 185
Initial state: 0 0.537809 0.881826 0.158879 0.141304 0.585367 0.895006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162078 episodes
GETTING ACTION FROM:
action 3, numVisits=153560, meanQ=5.009448, numObservations: 4
action -1, numVisits=8510, meanQ=3.028437, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=5, meanQ=-2.378000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.537809 0.881826 0.158879 0.141304 0.585367 0.895006 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 186
Initial state: 0 0.569686 0.844519 0.649069 0.838614 0.0767994 0.360307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167474 episodes
GETTING ACTION FROM:
action 2, numVisits=167459, meanQ=5.020963, numObservations: 3
action 1, numVisits=10, meanQ=1.991000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.569686 0.844519 0.649069 0.838614 0.0767994 0.360307 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 187
Initial state: 0 0.650983 0.876582 0.749546 0.835213 0.690514 0.830058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166657 episodes
GETTING ACTION FROM:
action 2, numVisits=166623, meanQ=4.929534, numObservations: 3
action 0, numVisits=28, meanQ=3.595596, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.650983 0.876582 0.749546 0.835213 0.690514 0.830058 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 188
Initial state: 0 0.637627 0.860387 0.793992 0.527982 0.52475 0.8872 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167376 episodes
GETTING ACTION FROM:
action 3, numVisits=167366, meanQ=4.970729, numObservations: 5
action -1, numVisits=5, meanQ=-2.601920, numObservations: 1
action 1, numVisits=2, meanQ=-3.505000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.637627 0.860387 0.793992 0.527982 0.52475 0.8872 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 189
Initial state: 0 0.620119 0.814824 0.644404 0.846512 0.344154 0.0548796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167700 episodes
GETTING ACTION FROM:
action 2, numVisits=167412, meanQ=5.153164, numObservations: 4
action 3, numVisits=283, meanQ=4.740781, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.620119 0.814824 0.644404 0.846512 0.344154 0.0548796 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 190
Initial state: 0 0.59357 0.868835 0.675844 0.861115 0.843704 0.0920224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167565 episodes
GETTING ACTION FROM:
action 2, numVisits=167439, meanQ=4.940197, numObservations: 5
action -1, numVisits=121, meanQ=4.278375, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.59357 0.868835 0.675844 0.861115 0.843704 0.0920224 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 191
Initial state: 0 0.727901 0.41066 0.604257 0.874258 0.686579 0.870742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167788 episodes
GETTING ACTION FROM:
action 2, numVisits=167776, meanQ=4.996535, numObservations: 4
action 3, numVisits=7, meanQ=0.428571, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.727901 0.41066 0.604257 0.874258 0.686579 0.870742 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 192
Initial state: 0 0.638457 0.821348 0.547244 0.872845 0.350226 0.347355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166585 episodes
GETTING ACTION FROM:
action 2, numVisits=166357, meanQ=4.937697, numObservations: 5
action -1, numVisits=218, meanQ=4.284475, numObservations: 1
action 1, numVisits=5, meanQ=-0.200000, numObservations: 3
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.638457 0.821348 0.547244 0.872845 0.350226 0.347355 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8512, meanQ=4.058097, numObservations: 5
action -1, numVisits=1954, meanQ=2.372009, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 207422 episodes
GETTING ACTION FROM:
action 3, numVisits=215927, meanQ=5.785379, numObservations: 5
action -1, numVisits=1959, meanQ=2.362968, numObservations: 1
action 1, numVisits=5, meanQ=-1.402000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.638457 0.821348 0.547244 0.872845 0.350226 0.347355 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=4050, meanQ=8.530885, numObservations: 3
action 2, numVisits=61, meanQ=7.491318, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 81803 episodes
GETTING ACTION FROM:
action 2, numVisits=64, meanQ=6.937037, numObservations: 3
action 1, numVisits=68030, meanQ=6.341324, numObservations: 4
action -1, numVisits=17769, meanQ=-1.556732, numObservations: 1
action 0, numVisits=53, meanQ=-2.597736, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.638457 0.821348 0.547244 0.872845 0.350226 0.347355 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 193
Initial state: 0 0.589499 0.863065 0.509715 0.865322 0.241935 0.570105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163970 episodes
GETTING ACTION FROM:
action 1, numVisits=163832, meanQ=4.935767, numObservations: 4
action -1, numVisits=81, meanQ=4.098188, numObservations: 1
action 0, numVisits=20, meanQ=3.173696, numObservations: 1
action 3, numVisits=35, meanQ=2.768863, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 1 0.589499 0.863065 0.509715 0.865322 0.241935 0.570105 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 194
Initial state: 0 0.55366 0.894165 0.511345 0.831303 0.393583 0.537031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167728 episodes
GETTING ACTION FROM:
action 2, numVisits=99863, meanQ=5.009106, numObservations: 4
action 3, numVisits=66052, meanQ=4.953664, numObservations: 5
action 1, numVisits=1760, meanQ=4.819289, numObservations: 5
action -1, numVisits=51, meanQ=4.016989, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.55366 0.894165 0.511345 0.831303 0.393583 0.537031 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 195
Initial state: 0 0.2739 0.0580663 0.50189 0.831271 0.521816 0.844699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166128 episodes
GETTING ACTION FROM:
action 2, numVisits=166078, meanQ=4.962865, numObservations: 5
action 1, numVisits=45, meanQ=3.923560, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.2739 0.0580663 0.50189 0.831271 0.521816 0.844699 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 196
Initial state: 0 0.313638 0.777208 0.56358 0.848933 0.653184 0.814656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165881 episodes
GETTING ACTION FROM:
action 3, numVisits=165872, meanQ=4.950478, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.313638 0.777208 0.56358 0.848933 0.653184 0.814656 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11405, meanQ=4.808890, numObservations: 5
action 1, numVisits=1042, meanQ=4.643989, numObservations: 4
action 0, numVisits=35, meanQ=3.750941, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 207203 episodes
GETTING ACTION FROM:
action 2, numVisits=218602, meanQ=5.982295, numObservations: 5
action 1, numVisits=1042, meanQ=4.643989, numObservations: 4
action 0, numVisits=41, meanQ=3.022587, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.313638 0.777208 0.56358 0.848933 0.653184 0.814656 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 197
Initial state: 0 0.522275 0.836778 0.41408 0.484891 0.660221 0.886854 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167316 episodes
GETTING ACTION FROM:
action 1, numVisits=167309, meanQ=4.928097, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.522275 0.836778 0.41408 0.484891 0.660221 0.886854 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 198
Initial state: 0 0.54325 0.831763 0.590004 0.810145 0.482414 0.876308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98842 episodes
GETTING ACTION FROM:
action -1, numVisits=86751, meanQ=2.976520, numObservations: 1
action 0, numVisits=12082, meanQ=2.937834, numObservations: 1
action 3, numVisits=7, meanQ=-0.571414, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.54325 0.831763 0.590004 0.810145 0.482414 0.876308 w: 1
Observation: 0 0.446482 0 0.637266 0 0.571701 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=86665, meanQ=5.012197, numObservations: 4
action -1, numVisits=49, meanQ=4.065765, numObservations: 1
action 0, numVisits=24, meanQ=3.557976, numObservations: 1
action 2, numVisits=11, meanQ=1.008182, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 169631 episodes
GETTING ACTION FROM:
action 3, numVisits=256292, meanQ=4.982774, numObservations: 4
action -1, numVisits=51, meanQ=3.968475, numObservations: 1
action 0, numVisits=25, meanQ=3.431140, numObservations: 1
action 2, numVisits=11, meanQ=1.008182, numObservations: 2
action 1, numVisits=2, meanQ=-3.505000, numObservations: 2
action: 3
Next state: 0 0.54325 0.831763 0.590004 0.810145 0.482414 0.876308 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=5824, meanQ=7.668005, numObservations: 4
action 1, numVisits=151, meanQ=7.244507, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 13572 episodes
GETTING ACTION FROM:
action 2, numVisits=5847, meanQ=7.668969, numObservations: 4
action 1, numVisits=386, meanQ=6.482900, numObservations: 4
action 0, numVisits=13314, meanQ=-0.387040, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-198.273059, numObservations: 1
action: 2
Next state: 1 0.54325 0.831763 0.590004 0.810145 0.482414 0.876308 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 199
Initial state: 0 0.601784 0.865353 0.289653 0.0952303 0.57603 0.854503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167441 episodes
GETTING ACTION FROM:
action 2, numVisits=167381, meanQ=4.932747, numObservations: 3
action 1, numVisits=29, meanQ=3.414148, numObservations: 4
action 3, numVisits=27, meanQ=3.252600, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.601784 0.865353 0.289653 0.0952303 0.57603 0.854503 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27484, meanQ=8.274987, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 28415 episodes
GETTING ACTION FROM:
action 1, numVisits=43427, meanQ=7.458429, numObservations: 5
action 3, numVisits=116, meanQ=5.454327, numObservations: 4
action 2, numVisits=21, meanQ=4.951905, numObservations: 3
action 0, numVisits=10361, meanQ=0.136225, numObservations: 1
action -1, numVisits=1979, meanQ=0.031026, numObservations: 1
action: 1
Next state: 1 0.601784 0.865353 0.289653 0.0952303 0.57603 0.854503 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 200
Initial state: 0 0.574315 0.869211 0.602336 0.854609 0.829076 0.509837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164985 episodes
GETTING ACTION FROM:
action 2, numVisits=164924, meanQ=4.918395, numObservations: 4
action 3, numVisits=49, meanQ=3.728782, numObservations: 4
action 1, numVisits=8, meanQ=1.863750, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.574315 0.869211 0.602336 0.854609 0.829076 0.509837 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 201
Initial state: 0 0.906552 0.427835 0.698286 0.849121 0.556713 0.897091 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166833 episodes
GETTING ACTION FROM:
action 3, numVisits=166821, meanQ=4.989517, numObservations: 5
action 2, numVisits=7, meanQ=1.428571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.906552 0.427835 0.698286 0.849121 0.556713 0.897091 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 202
Initial state: 0 0.728277 0.377204 0.547065 0.876668 0.578252 0.893958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168010 episodes
GETTING ACTION FROM:
action 2, numVisits=168001, meanQ=4.953757, numObservations: 3
action 1, numVisits=4, meanQ=0.750000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.728277 0.377204 0.547065 0.876668 0.578252 0.893958 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 203
Initial state: 0 0.560341 0.85501 0.673654 0.83782 0.214037 0.206411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164295 episodes
GETTING ACTION FROM:
action 1, numVisits=161992, meanQ=4.939869, numObservations: 4
action -1, numVisits=2298, meanQ=1.419121, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.560341 0.85501 0.673654 0.83782 0.214037 0.206411 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 204
Initial state: 0 0.585418 0.808333 0.827389 0.748013 0.522816 0.837735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169195 episodes
GETTING ACTION FROM:
action 2, numVisits=169083, meanQ=5.221569, numObservations: 5
action 0, numVisits=71, meanQ=4.401711, numObservations: 1
action -1, numVisits=39, meanQ=4.085905, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.585418 0.808333 0.827389 0.748013 0.522816 0.837735 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 205
Initial state: 0 0.648388 0.808812 0.596688 0.523868 0.532789 0.882413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158768 episodes
GETTING ACTION FROM:
action 2, numVisits=158760, meanQ=4.877259, numObservations: 5
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.648388 0.808812 0.596688 0.523868 0.532789 0.882413 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=22285, meanQ=8.416027, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 34131 episodes
GETTING ACTION FROM:
action 1, numVisits=35914, meanQ=7.439620, numObservations: 5
action 2, numVisits=5, meanQ=2.598000, numObservations: 2
action 0, numVisits=20496, meanQ=0.247882, numObservations: 2
action -1, numVisits=3, meanQ=-5.967547, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 1
Next state: 1 0.648388 0.808812 0.596688 0.523868 0.532789 0.882413 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 206
Initial state: 0 0.0157531 0.425435 0.53674 0.888334 0.545845 0.828414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167209 episodes
GETTING ACTION FROM:
action 1, numVisits=167186, meanQ=4.975292, numObservations: 5
action 2, numVisits=15, meanQ=2.394680, numObservations: 3
action 3, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0157531 0.425435 0.53674 0.888334 0.545845 0.828414 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23335, meanQ=8.394321, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 35587 episodes
GETTING ACTION FROM:
action 2, numVisits=29529, meanQ=7.853071, numObservations: 5
action 1, numVisits=5, meanQ=1.198020, numObservations: 3
action -1, numVisits=29386, meanQ=0.113915, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 0, numVisits=4, meanQ=-98.687844, numObservations: 1
action: 2
Next state: 1 0.0157531 0.425435 0.53674 0.888334 0.545845 0.828414 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 207
Initial state: 0 0.329972 0.636812 0.546751 0.834125 0.694235 0.801282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166899 episodes
GETTING ACTION FROM:
action 1, numVisits=166883, meanQ=4.976285, numObservations: 5
action 2, numVisits=8, meanQ=2.373775, numObservations: 3
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.329972 0.636812 0.546751 0.834125 0.694235 0.801282 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22902, meanQ=8.393926, numObservations: 3
action 2, numVisits=371, meanQ=8.098130, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 52178 episodes
GETTING ACTION FROM:
action 3, numVisits=22929, meanQ=8.393345, numObservations: 3
action 2, numVisits=448, meanQ=7.477355, numObservations: 4
action -1, numVisits=52065, meanQ=0.242707, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=9, meanQ=-2.001100, numObservations: 2
action: 3
Next state: 1 0.329972 0.636812 0.546751 0.834125 0.694235 0.801282 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 208
Initial state: 0 0.565258 0.734962 0.657062 0.898352 0.599449 0.82542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165478 episodes
GETTING ACTION FROM:
action 3, numVisits=165396, meanQ=4.944779, numObservations: 5
action 0, numVisits=77, meanQ=4.144311, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.565258 0.734962 0.657062 0.898352 0.599449 0.82542 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 209
Initial state: 0 0.529481 0.850554 0.684401 0.874612 0.21952 0.796188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167385 episodes
GETTING ACTION FROM:
action 2, numVisits=167359, meanQ=5.157053, numObservations: 4
action -1, numVisits=18, meanQ=3.381853, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.529481 0.850554 0.684401 0.874612 0.21952 0.796188 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 210
Initial state: 0 0.68352 0.801625 0.500329 0.807902 0.707126 0.00499552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 121135 episodes
GETTING ACTION FROM:
action 2, numVisits=53750, meanQ=5.024214, numObservations: 5
action 0, numVisits=67240, meanQ=2.903512, numObservations: 1
action -1, numVisits=139, meanQ=2.362546, numObservations: 1
action 1, numVisits=5, meanQ=-0.399980, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.68352 0.801625 0.500329 0.807902 0.707126 0.00499552 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 211
Initial state: 0 0.0539267 0.723332 0.506604 0.853605 0.650092 0.841929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167890 episodes
GETTING ACTION FROM:
action 1, numVisits=167866, meanQ=5.017200, numObservations: 5
action 2, numVisits=12, meanQ=1.833333, numObservations: 4
action 3, numVisits=8, meanQ=0.750000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.0539267 0.723332 0.506604 0.853605 0.650092 0.841929 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=19404, meanQ=8.544114, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30435 episodes
GETTING ACTION FROM:
action 2, numVisits=26676, meanQ=7.842376, numObservations: 4
action 3, numVisits=13859, meanQ=6.062983, numObservations: 5
action -1, numVisits=9305, meanQ=0.227260, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-198.338686, numObservations: 1
action: 2
Next state: 1 0.0539267 0.723332 0.506604 0.853605 0.650092 0.841929 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 212
Initial state: 0 0.420361 0.858747 0.647011 0.855712 0.562114 0.823533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167813 episodes
GETTING ACTION FROM:
action 2, numVisits=167770, meanQ=5.046787, numObservations: 4
action 0, numVisits=39, meanQ=3.925953, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.420361 0.858747 0.647011 0.855712 0.562114 0.823533 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 213
Initial state: 0 0.771059 0.99866 0.691537 0.83433 0.57952 0.879149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166054 episodes
GETTING ACTION FROM:
action 2, numVisits=163037, meanQ=4.957367, numObservations: 4
action -1, numVisits=3010, meanQ=2.799670, numObservations: 1
action 3, numVisits=4, meanQ=-1.249950, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.771059 0.99866 0.691537 0.83433 0.57952 0.879149 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 214
Initial state: 0 0.574253 0.284521 0.655667 0.860623 0.637043 0.872451 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167654 episodes
GETTING ACTION FROM:
action 1, numVisits=167648, meanQ=5.013798, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.574253 0.284521 0.655667 0.860623 0.637043 0.872451 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 215
Initial state: 0 0.683424 0.843468 0.530924 0.815294 0.563121 0.408991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 149207 episodes
GETTING ACTION FROM:
action 3, numVisits=125713, meanQ=4.843347, numObservations: 5
action 0, numVisits=23490, meanQ=2.919378, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.683424 0.843468 0.530924 0.815294 0.563121 0.408991 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=13547, meanQ=8.437258, numObservations: 4
action 1, numVisits=3897, meanQ=8.385812, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 35704 episodes
GETTING ACTION FROM:
action 2, numVisits=32316, meanQ=7.162450, numObservations: 4
action 1, numVisits=9604, meanQ=6.714068, numObservations: 3
action 3, numVisits=5, meanQ=5.780000, numObservations: 3
action 0, numVisits=11002, meanQ=0.300791, numObservations: 1
action -1, numVisits=224, meanQ=-0.206867, numObservations: 1
action: 2
Next state: 1 0.683424 0.843468 0.530924 0.815294 0.563121 0.408991 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 216
Initial state: 0 0.492869 0.0656175 0.516036 0.840382 0.578319 0.809715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159355 episodes
GETTING ACTION FROM:
action 2, numVisits=159256, meanQ=4.873326, numObservations: 5
action 1, numVisits=94, meanQ=4.156811, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.492869 0.0656175 0.516036 0.840382 0.578319 0.809715 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 217
Initial state: 0 0.678481 0.802331 0.696362 0.275135 0.502262 0.881303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166496 episodes
GETTING ACTION FROM:
action 3, numVisits=166490, meanQ=4.989923, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.678481 0.802331 0.696362 0.275135 0.502262 0.881303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 218
Initial state: 0 0.560694 0.832738 0.564971 0.869042 0.709551 0.339199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168125 episodes
GETTING ACTION FROM:
action 1, numVisits=167443, meanQ=4.970695, numObservations: 5
action 2, numVisits=613, meanQ=4.686085, numObservations: 4
action -1, numVisits=37, meanQ=3.831432, numObservations: 1
action 0, numVisits=30, meanQ=3.691468, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.560694 0.832738 0.564971 0.869042 0.709551 0.339199 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 219
Initial state: 0 0.0732141 0.0589686 0.694422 0.885769 0.680432 0.875044 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82722 episodes
GETTING ACTION FROM:
action 0, numVisits=82711, meanQ=4.486635, numObservations: 2
action 2, numVisits=4, meanQ=-0.272500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 0
Next state: 0 0.0732141 0.0589686 0.694422 0.885769 0.680432 0.875044 w: 1
Observation: 0 0 0.119307 0 0.872736 0 0.875274 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32623, meanQ=8.338863, numObservations: 4
action 1, numVisits=6, meanQ=2.301667, numObservations: 2
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 171813 episodes
GETTING ACTION FROM:
action 3, numVisits=204414, meanQ=5.551442, numObservations: 4
action -1, numVisits=22, meanQ=3.978020, numObservations: 1
action 1, numVisits=6, meanQ=2.301667, numObservations: 2
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.0732141 0.0589686 0.694422 0.885769 0.680432 0.875044 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 220
Initial state: 0 0.622811 0.811108 0.9837 0.242916 0.625417 0.80346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167798 episodes
GETTING ACTION FROM:
action 2, numVisits=167655, meanQ=4.967570, numObservations: 5
action -1, numVisits=90, meanQ=4.242120, numObservations: 1
action 0, numVisits=33, meanQ=3.727828, numObservations: 1
action 3, numVisits=15, meanQ=2.799347, numObservations: 2
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action: 2
Next state: 2 0.622811 0.811108 0.9837 0.242916 0.625417 0.80346 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 221
Initial state: 0 0.63847 0.839853 0.468091 0.939221 0.590054 0.828467 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168076 episodes
GETTING ACTION FROM:
action 3, numVisits=168064, meanQ=5.005931, numObservations: 5
action 1, numVisits=6, meanQ=1.498333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.63847 0.839853 0.468091 0.939221 0.590054 0.828467 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 222
Initial state: 0 0.584638 0.865774 0.60827 0.856088 0.00195158 0.566826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167929 episodes
GETTING ACTION FROM:
action 1, numVisits=167852, meanQ=5.040272, numObservations: 5
action 0, numVisits=65, meanQ=4.180307, numObservations: 1
action 2, numVisits=9, meanQ=2.664444, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.584638 0.865774 0.60827 0.856088 0.00195158 0.566826 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 223
Initial state: 0 0.966909 0.774433 0.624584 0.824704 0.573811 0.853747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98602 episodes
GETTING ACTION FROM:
action 0, numVisits=98597, meanQ=2.957555, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.966909 0.774433 0.624584 0.824704 0.573811 0.853747 w: 1
Observation: 0 0 0.805706 0 0.871215 0 0.775025 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=98477, meanQ=4.955102, numObservations: 3
action -1, numVisits=68, meanQ=4.152754, numObservations: 1
action 0, numVisits=45, meanQ=3.953616, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
Sampled 167236 episodes
GETTING ACTION FROM:
action 2, numVisits=265709, meanQ=4.934317, numObservations: 3
action -1, numVisits=71, meanQ=4.088474, numObservations: 1
action 0, numVisits=46, meanQ=3.891884, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.966909 0.774433 0.624584 0.824704 0.573811 0.853747 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 224
Initial state: 0 0.694856 0.936039 0.656506 0.86658 0.654926 0.831221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98240 episodes
GETTING ACTION FROM:
action 0, numVisits=89950, meanQ=2.952143, numObservations: 1
action -1, numVisits=8275, meanQ=2.900201, numObservations: 1
action 3, numVisits=5, meanQ=-0.200000, numObservations: 3
action 1, numVisits=9, meanQ=-0.343322, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.694856 0.936039 0.656506 0.86658 0.654926 0.831221 w: 1
Observation: 0 0 1 0 0.771731 0 0.735527 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=89895, meanQ=5.010018, numObservations: 4
action -1, numVisits=49, meanQ=4.042115, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 166711 episodes
GETTING ACTION FROM:
action 1, numVisits=256601, meanQ=4.951684, numObservations: 4
action -1, numVisits=51, meanQ=3.962285, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.694856 0.936039 0.656506 0.86658 0.654926 0.831221 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 225
Initial state: 0 0.583012 0.817531 0.00658921 0.752538 0.583389 0.893526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164332 episodes
GETTING ACTION FROM:
action 3, numVisits=164320, meanQ=4.998299, numObservations: 4
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.583012 0.817531 0.00658921 0.752538 0.583389 0.893526 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 226
Initial state: 0 0.785316 0.615019 0.653729 0.879644 0.624529 0.897703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167782 episodes
GETTING ACTION FROM:
action 1, numVisits=167776, meanQ=4.941934, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.785316 0.615019 0.653729 0.879644 0.624529 0.897703 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 227
Initial state: 0 0.517989 0.884098 0.660269 0.130865 0.55258 0.858856 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168648 episodes
GETTING ACTION FROM:
action 3, numVisits=168613, meanQ=5.062135, numObservations: 5
action -1, numVisits=28, meanQ=3.761217, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.517989 0.884098 0.660269 0.130865 0.55258 0.858856 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 228
Initial state: 0 0.533176 0.832185 0.569565 0.837084 0.669587 0.395435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166134 episodes
GETTING ACTION FROM:
action 1, numVisits=166113, meanQ=4.939138, numObservations: 4
action 2, numVisits=16, meanQ=2.436875, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.533176 0.832185 0.569565 0.837084 0.669587 0.395435 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=10434, meanQ=4.641972, numObservations: 4
action -1, numVisits=1768, meanQ=2.737936, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 207973 episodes
GETTING ACTION FROM:
action 2, numVisits=207972, meanQ=6.004201, numObservations: 5
action 3, numVisits=10434, meanQ=4.641972, numObservations: 4
action -1, numVisits=1768, meanQ=2.737936, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.533176 0.832185 0.569565 0.837084 0.669587 0.395435 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 229
Initial state: 0 0.637197 0.86763 0.946398 0.336003 0.65083 0.800476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159782 episodes
GETTING ACTION FROM:
action 1, numVisits=159776, meanQ=4.867696, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.637197 0.86763 0.946398 0.336003 0.65083 0.800476 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 230
Initial state: 0 0.61383 0.838775 0.689755 0.830203 0.246405 0.389778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167207 episodes
GETTING ACTION FROM:
action 3, numVisits=167134, meanQ=4.936589, numObservations: 4
action 0, numVisits=57, meanQ=4.019286, numObservations: 1
action 1, numVisits=12, meanQ=2.250017, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.61383 0.838775 0.689755 0.830203 0.246405 0.389778 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=13053, meanQ=8.428064, numObservations: 4
action 2, numVisits=10314, meanQ=8.421753, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 39194 episodes
GETTING ACTION FROM:
action 2, numVisits=22325, meanQ=7.140805, numObservations: 5
action 1, numVisits=33620, meanQ=7.073285, numObservations: 4
action -1, numVisits=6616, meanQ=0.127991, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-196.504123, numObservations: 1
action: 2
Next state: 1 0.61383 0.838775 0.689755 0.830203 0.246405 0.389778 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 231
Initial state: 0 0.332631 0.748936 0.651964 0.854033 0.58236 0.80517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166473 episodes
GETTING ACTION FROM:
action 3, numVisits=166457, meanQ=4.922338, numObservations: 4
action 1, numVisits=10, meanQ=2.499000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.332631 0.748936 0.651964 0.854033 0.58236 0.80517 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 232
Initial state: 0 0.636485 0.847448 0.114038 0.532806 0.567467 0.803456 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167961 episodes
GETTING ACTION FROM:
action 1, numVisits=167879, meanQ=5.009671, numObservations: 4
action 3, numVisits=57, meanQ=3.923339, numObservations: 4
action 0, numVisits=22, meanQ=3.490528, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.636485 0.847448 0.114038 0.532806 0.567467 0.803456 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12440, meanQ=5.678031, numObservations: 3
action 3, numVisits=20, meanQ=4.185500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 206596 episodes
GETTING ACTION FROM:
action 2, numVisits=206595, meanQ=5.829327, numObservations: 4
action 1, numVisits=12440, meanQ=5.678031, numObservations: 3
action 3, numVisits=20, meanQ=4.185500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 0 0.636485 0.847448 0.114038 0.532806 0.567467 0.803456 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=3824, meanQ=8.409836, numObservations: 3
action 1, numVisits=138, meanQ=7.960436, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 42761 episodes
GETTING ACTION FROM:
action 1, numVisits=515, meanQ=7.209709, numObservations: 5
action 3, numVisits=25716, meanQ=6.698884, numObservations: 4
action -1, numVisits=10995, meanQ=-1.622460, numObservations: 1
action 0, numVisits=9499, meanQ=-1.622928, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.636485 0.847448 0.114038 0.532806 0.567467 0.803456 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 233
Initial state: 0 0.608076 0.81101 0.277266 0.550234 0.53508 0.886165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167472 episodes
GETTING ACTION FROM:
action 1, numVisits=167313, meanQ=4.971182, numObservations: 4
action 0, numVisits=103, meanQ=4.299182, numObservations: 1
action 2, numVisits=48, meanQ=3.952085, numObservations: 4
action 3, numVisits=6, meanQ=1.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.608076 0.81101 0.277266 0.550234 0.53508 0.886165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 234
Initial state: 0 0.595297 0.87417 0.714018 0.230846 0.662708 0.870974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168403 episodes
GETTING ACTION FROM:
action 1, numVisits=168317, meanQ=4.947411, numObservations: 4
action -1, numVisits=82, meanQ=4.186162, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.595297 0.87417 0.714018 0.230846 0.662708 0.870974 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 235
Initial state: 0 0.554504 0.841322 0.546923 0.856003 0.0426349 0.334958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167482 episodes
GETTING ACTION FROM:
action 2, numVisits=167376, meanQ=4.936070, numObservations: 4
action 0, numVisits=64, meanQ=4.056906, numObservations: 1
action 1, numVisits=27, meanQ=3.612593, numObservations: 3
action 3, numVisits=13, meanQ=2.613085, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.554504 0.841322 0.546923 0.856003 0.0426349 0.334958 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 236
Initial state: 0 0.636251 0.831555 0.575967 0.694801 0.626718 0.832594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165206 episodes
GETTING ACTION FROM:
action 1, numVisits=165091, meanQ=4.929175, numObservations: 5
action 0, numVisits=108, meanQ=4.263940, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.636251 0.831555 0.575967 0.694801 0.626718 0.832594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 237
Initial state: 0 0.597218 0.809075 0.642755 0.242645 0.574931 0.860099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98895 episodes
GETTING ACTION FROM:
action 0, numVisits=98883, meanQ=2.931595, numObservations: 1
action -1, numVisits=3, meanQ=-3.656600, numObservations: 1
action 1, numVisits=4, meanQ=-4.002500, numObservations: 2
action 2, numVisits=3, meanQ=-4.333333, numObservations: 1
action 3, numVisits=2, meanQ=-4.499950, numObservations: 1
action: 0
Next state: 0 0.597218 0.809075 0.642755 0.242645 0.574931 0.860099 w: 1
Observation: 0 0 0.874889 0 0.214578 0 0.885028 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=98788, meanQ=4.989248, numObservations: 4
action 0, numVisits=31, meanQ=3.785835, numObservations: 1
action 3, numVisits=33, meanQ=3.762424, numObservations: 4
action -1, numVisits=29, meanQ=3.715812, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 167390 episodes
GETTING ACTION FROM:
action 1, numVisits=264875, meanQ=4.794871, numObservations: 4
action 3, numVisits=1326, meanQ=4.608881, numObservations: 4
action 0, numVisits=38, meanQ=3.626007, numObservations: 1
action -1, numVisits=31, meanQ=3.525765, numObservations: 1
action 2, numVisits=2, meanQ=-3.505000, numObservations: 2
action: 1
Next state: 1 0.597218 0.809075 0.642755 0.242645 0.574931 0.860099 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 238
Initial state: 0 0.968558 0.231221 0.563846 0.847376 0.590313 0.815966 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167777 episodes
GETTING ACTION FROM:
action 2, numVisits=167751, meanQ=4.971842, numObservations: 4
action 0, numVisits=18, meanQ=3.338395, numObservations: 1
action 3, numVisits=5, meanQ=1.398000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.968558 0.231221 0.563846 0.847376 0.590313 0.815966 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 239
Initial state: 0 0.605224 0.834108 0.303664 0.950032 0.627137 0.877727 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167897 episodes
GETTING ACTION FROM:
action 1, numVisits=167850, meanQ=5.006545, numObservations: 4
action 2, numVisits=42, meanQ=1.996914, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.605224 0.834108 0.303664 0.950032 0.627137 0.877727 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 240
Initial state: 0 0.55507 0.876792 0.133345 0.50848 0.561572 0.854635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168520 episodes
GETTING ACTION FROM:
action 2, numVisits=168504, meanQ=4.991134, numObservations: 4
action 1, numVisits=10, meanQ=2.393010, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.55507 0.876792 0.133345 0.50848 0.561572 0.854635 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 241
Initial state: 0 0.919085 0.682914 0.519475 0.809149 0.569693 0.851243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166937 episodes
GETTING ACTION FROM:
action 2, numVisits=166931, meanQ=4.954033, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.919085 0.682914 0.519475 0.809149 0.569693 0.851243 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 242
Initial state: 0 0.167788 0.600708 0.607507 0.862091 0.650991 0.859618 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167313 episodes
GETTING ACTION FROM:
action 1, numVisits=167306, meanQ=5.010387, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.167788 0.600708 0.607507 0.862091 0.650991 0.859618 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23215, meanQ=8.404269, numObservations: 5
action 2, numVisits=4, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29005 episodes
GETTING ACTION FROM:
action 3, numVisits=45451, meanQ=7.271381, numObservations: 5
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action -1, numVisits=6768, meanQ=-0.322350, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=2, meanQ=-198.166270, numObservations: 1
action: 3
Next state: 1 0.167788 0.600708 0.607507 0.862091 0.650991 0.859618 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 243
Initial state: 0 0.554062 0.867576 0.507023 0.878096 0.710343 0.0909209 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161836 episodes
GETTING ACTION FROM:
action 3, numVisits=161746, meanQ=4.918365, numObservations: 4
action -1, numVisits=53, meanQ=3.966289, numObservations: 1
action 0, numVisits=30, meanQ=3.632443, numObservations: 1
action 1, numVisits=6, meanQ=1.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.554062 0.867576 0.507023 0.878096 0.710343 0.0909209 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 244
Initial state: 0 0.0894902 0.716908 0.643541 0.807832 0.698511 0.852013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98671 episodes
GETTING ACTION FROM:
action -1, numVisits=98656, meanQ=2.926280, numObservations: 1
action 1, numVisits=11, meanQ=0.809109, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.0894902 0.716908 0.643541 0.807832 0.698511 0.852013 w: 1
Observation: 0 0.103915 0 0.564875 0 0.683299 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=98648, meanQ=4.979277, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 168619 episodes
GETTING ACTION FROM:
action 1, numVisits=267263, meanQ=5.070717, numObservations: 5
action 3, numVisits=5, meanQ=1.000020, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.0894902 0.716908 0.643541 0.807832 0.698511 0.852013 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 245
Initial state: 0 0.338609 0.600664 0.691367 0.871002 0.693641 0.800267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167433 episodes
GETTING ACTION FROM:
action 3, numVisits=167404, meanQ=5.022403, numObservations: 5
action 0, numVisits=17, meanQ=3.318697, numObservations: 1
action 2, numVisits=9, meanQ=1.886667, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.338609 0.600664 0.691367 0.871002 0.693641 0.800267 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 246
Initial state: 0 0.99681 0.776424 0.69689 0.862158 0.570156 0.870977 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168502 episodes
GETTING ACTION FROM:
action 1, numVisits=168450, meanQ=5.037472, numObservations: 3
action -1, numVisits=33, meanQ=3.842515, numObservations: 1
action 2, numVisits=16, meanQ=2.688131, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.99681 0.776424 0.69689 0.862158 0.570156 0.870977 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 247
Initial state: 0 0.413315 0.439942 0.646031 0.891155 0.518313 0.887612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164397 episodes
GETTING ACTION FROM:
action 3, numVisits=161358, meanQ=4.931609, numObservations: 4
action -1, numVisits=3030, meanQ=2.901661, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.413315 0.439942 0.646031 0.891155 0.518313 0.887612 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 248
Initial state: 0 0.77133 0.208644 0.627872 0.881868 0.621218 0.836808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166776 episodes
GETTING ACTION FROM:
action 3, numVisits=166756, meanQ=4.912166, numObservations: 4
action 1, numVisits=12, meanQ=1.509167, numObservations: 4
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.77133 0.208644 0.627872 0.881868 0.621218 0.836808 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 249
Initial state: 0 0.569051 0.86769 0.678018 0.852054 0.809263 0.806783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167757 episodes
GETTING ACTION FROM:
action 3, numVisits=167564, meanQ=4.950498, numObservations: 3
action -1, numVisits=83, meanQ=4.201990, numObservations: 1
action 0, numVisits=84, meanQ=4.196662, numObservations: 1
action 2, numVisits=20, meanQ=2.950505, numObservations: 3
action 1, numVisits=6, meanQ=1.498333, numObservations: 3
action: 3
Next state: 2 0.569051 0.86769 0.678018 0.852054 0.809263 0.806783 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 250
Initial state: 0 0.0350402 0.444838 0.637833 0.885844 0.550102 0.80919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159684 episodes
GETTING ACTION FROM:
action 3, numVisits=159635, meanQ=4.835671, numObservations: 5
action 0, numVisits=39, meanQ=3.730439, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0350402 0.444838 0.637833 0.885844 0.550102 0.80919 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 251
Initial state: 0 0.677463 0.815881 0.122228 0.610689 0.501395 0.865613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 130864 episodes
GETTING ACTION FROM:
action 1, numVisits=78032, meanQ=4.971871, numObservations: 5
action -1, numVisits=52821, meanQ=3.116874, numObservations: 1
action 2, numVisits=8, meanQ=0.238750, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.677463 0.815881 0.122228 0.610689 0.501395 0.865613 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 252
Initial state: 0 0.0554063 0.145041 0.695414 0.84592 0.62281 0.870624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98879 episodes
GETTING ACTION FROM:
action 0, numVisits=98857, meanQ=2.954720, numObservations: 1
action 2, numVisits=18, meanQ=1.332228, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0554063 0.145041 0.695414 0.84592 0.62281 0.870624 w: 1
Observation: 0 0 0.0876418 0 0.903274 0 0.89685 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=98190, meanQ=5.011897, numObservations: 3
action 2, numVisits=619, meanQ=4.725492, numObservations: 5
action 0, numVisits=37, meanQ=3.894648, numObservations: 1
action 1, numVisits=8, meanQ=2.498750, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 170879 episodes
GETTING ACTION FROM:
action 3, numVisits=269068, meanQ=5.115071, numObservations: 3
action 2, numVisits=619, meanQ=4.725492, numObservations: 5
action 0, numVisits=38, meanQ=3.859999, numObservations: 1
action 1, numVisits=8, meanQ=2.498750, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.0554063 0.145041 0.695414 0.84592 0.62281 0.870624 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 253
Initial state: 0 0.896753 0.379647 0.562385 0.891504 0.598639 0.873278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164706 episodes
GETTING ACTION FROM:
action 1, numVisits=164597, meanQ=4.927737, numObservations: 5
action 0, numVisits=98, meanQ=4.116771, numObservations: 1
action 2, numVisits=8, meanQ=1.872500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.896753 0.379647 0.562385 0.891504 0.598639 0.873278 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 254
Initial state: 0 0.0697511 0.616496 0.50598 0.879284 0.687425 0.852797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166584 episodes
GETTING ACTION FROM:
action 2, numVisits=166576, meanQ=5.001536, numObservations: 4
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.0697511 0.616496 0.50598 0.879284 0.687425 0.852797 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 255
Initial state: 0 0.678961 0.808335 0.548827 0.845652 0.811742 0.532016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167909 episodes
GETTING ACTION FROM:
action 1, numVisits=167836, meanQ=5.020543, numObservations: 3
action 0, numVisits=66, meanQ=4.155919, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.678961 0.808335 0.548827 0.845652 0.811742 0.532016 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 256
Initial state: 0 0.548248 0.850771 0.683567 0.159706 0.642684 0.840426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168646 episodes
GETTING ACTION FROM:
action 3, numVisits=168597, meanQ=4.998397, numObservations: 3
action 0, numVisits=39, meanQ=3.897307, numObservations: 1
action 1, numVisits=6, meanQ=1.498333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.548248 0.850771 0.683567 0.159706 0.642684 0.840426 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 257
Initial state: 0 0.720529 0.787293 0.676746 0.815673 0.676497 0.862659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166180 episodes
GETTING ACTION FROM:
action 3, numVisits=164166, meanQ=4.968058, numObservations: 5
action 0, numVisits=1889, meanQ=3.387066, numObservations: 1
action -1, numVisits=123, meanQ=3.005901, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.720529 0.787293 0.676746 0.815673 0.676497 0.862659 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 258
Initial state: 0 0.443323 0.936583 0.616352 0.820796 0.621874 0.84989 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166956 episodes
GETTING ACTION FROM:
action 1, numVisits=166815, meanQ=4.948313, numObservations: 5
action 0, numVisits=76, meanQ=4.137179, numObservations: 1
action -1, numVisits=28, meanQ=3.571261, numObservations: 1
action 3, numVisits=24, meanQ=3.499588, numObservations: 3
action 2, numVisits=13, meanQ=2.923077, numObservations: 4
action: 1
Next state: 0 0.443323 0.936583 0.616352 0.820796 0.621874 0.84989 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11024, meanQ=4.193474, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 206915 episodes
GETTING ACTION FROM:
action 3, numVisits=217935, meanQ=5.777331, numObservations: 5
action 1, numVisits=5, meanQ=-0.622000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.443323 0.936583 0.616352 0.820796 0.621874 0.84989 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 259
Initial state: 0 0.61946 0.80306 0.507805 0.815147 0.0877437 0.190248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98826 episodes
GETTING ACTION FROM:
action -1, numVisits=98819, meanQ=2.954715, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.61946 0.80306 0.507805 0.815147 0.0877437 0.190248 w: 1
Observation: 0 0.665967 0 0.525284 0 0.0479449 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=98781, meanQ=5.004363, numObservations: 5
action 0, numVisits=24, meanQ=3.532414, numObservations: 1
action 1, numVisits=10, meanQ=2.598000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 167982 episodes
GETTING ACTION FROM:
action 2, numVisits=266762, meanQ=5.047770, numObservations: 5
action 0, numVisits=25, meanQ=3.437640, numObservations: 1
action 1, numVisits=10, meanQ=2.598000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.61946 0.80306 0.507805 0.815147 0.0877437 0.190248 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 260
Initial state: 0 0.791692 0.396002 0.677604 0.895927 0.550984 0.852632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166727 episodes
GETTING ACTION FROM:
action 2, numVisits=166721, meanQ=4.922011, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.791692 0.396002 0.677604 0.895927 0.550984 0.852632 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 261
Initial state: 0 0.629658 0.851775 0.559019 0.877147 0.129109 0.833281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168698 episodes
GETTING ACTION FROM:
action 2, numVisits=168606, meanQ=5.048951, numObservations: 4
action 0, numVisits=84, meanQ=1.302546, numObservations: 1
action 3, numVisits=5, meanQ=-0.795980, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.629658 0.851775 0.559019 0.877147 0.129109 0.833281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 262
Initial state: 0 0.922933 0.848685 0.534383 0.8773 0.59322 0.814169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160034 episodes
GETTING ACTION FROM:
action 3, numVisits=159832, meanQ=4.823770, numObservations: 4
action 0, numVisits=174, meanQ=4.287981, numObservations: 1
action 2, numVisits=25, meanQ=3.355600, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.922933 0.848685 0.534383 0.8773 0.59322 0.814169 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 263
Initial state: 0 0.645294 0.875731 0.464884 0.905287 0.636209 0.831577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166992 episodes
GETTING ACTION FROM:
action 1, numVisits=166941, meanQ=5.011493, numObservations: 5
action -1, numVisits=44, meanQ=3.973243, numObservations: 1
action 2, numVisits=3, meanQ=0.663333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.645294 0.875731 0.464884 0.905287 0.636209 0.831577 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.270181 0.956597 0.593302 0.893079 0.534265 0.812884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159205 episodes
GETTING ACTION FROM:
action 1, numVisits=158999, meanQ=4.770131, numObservations: 4
action -1, numVisits=134, meanQ=4.178298, numObservations: 1
action 0, numVisits=45, meanQ=3.746931, numObservations: 1
action 2, numVisits=26, meanQ=2.962323, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.270181 0.956597 0.593302 0.893079 0.534265 0.812884 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3896, meanQ=7.618954, numObservations: 4
action 2, numVisits=5, meanQ=4.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46486 episodes
GETTING ACTION FROM:
action 3, numVisits=45677, meanQ=6.332542, numObservations: 4
action 2, numVisits=8, meanQ=0.997500, numObservations: 3
action 1, numVisits=3, meanQ=0.663333, numObservations: 3
action -1, numVisits=4691, meanQ=0.131104, numObservations: 1
action 0, numVisits=11, meanQ=-1.910000, numObservations: 1
action: 3
Next state: 1 0.270181 0.956597 0.593302 0.893079 0.534265 0.812884 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 265
Initial state: 0 0.505567 0.853247 0.0553531 0.520018 0.635403 0.848887 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 99365 episodes
GETTING ACTION FROM:
action 0, numVisits=99319, meanQ=3.150198, numObservations: 1
action -1, numVisits=23, meanQ=1.630875, numObservations: 1
action 3, numVisits=14, meanQ=0.502879, numObservations: 4
action 2, numVisits=8, meanQ=-0.001250, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.505567 0.853247 0.0553531 0.520018 0.635403 0.848887 w: 1
Observation: 0 0 0.761658 0 0.428489 0 0.776197 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=99169, meanQ=5.200749, numObservations: 5
action 3, numVisits=131, meanQ=4.613074, numObservations: 4
action -1, numVisits=15, meanQ=3.461472, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 170522 episodes
GETTING ACTION FROM:
action 2, numVisits=269679, meanQ=5.244853, numObservations: 5
action 3, numVisits=131, meanQ=4.613074, numObservations: 4
action -1, numVisits=17, meanQ=3.503308, numObservations: 1
action 1, numVisits=11, meanQ=2.801827, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.505567 0.853247 0.0553531 0.520018 0.635403 0.848887 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=13603, meanQ=8.548654, numObservations: 3
action 1, numVisits=15531, meanQ=8.533973, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 35631 episodes
GETTING ACTION FROM:
action 1, numVisits=22112, meanQ=7.697674, numObservations: 4
action 3, numVisits=40400, meanQ=7.162855, numObservations: 4
action 0, numVisits=2234, meanQ=-0.281218, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=19, meanQ=-2.053147, numObservations: 1
action: 1
Next state: 1 0.505567 0.853247 0.0553531 0.520018 0.635403 0.848887 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 266
Initial state: 0 0.629793 0.82016 0.795529 0.329436 0.546343 0.87694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168582 episodes
GETTING ACTION FROM:
action 3, numVisits=168571, meanQ=5.003054, numObservations: 3
action 2, numVisits=6, meanQ=1.498333, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.629793 0.82016 0.795529 0.329436 0.546343 0.87694 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 267
Initial state: 0 0.625607 0.848593 0.654318 0.894361 0.700249 0.859163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167608 episodes
GETTING ACTION FROM:
action 2, numVisits=167517, meanQ=5.031691, numObservations: 4
action 0, numVisits=70, meanQ=4.193379, numObservations: 1
action 3, numVisits=18, meanQ=3.000567, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.625607 0.848593 0.654318 0.894361 0.700249 0.859163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 268
Initial state: 0 0.0312332 0.803444 0.52548 0.816824 0.505052 0.877065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164366 episodes
GETTING ACTION FROM:
action 3, numVisits=164262, meanQ=4.943292, numObservations: 4
action 0, numVisits=76, meanQ=4.152922, numObservations: 1
action -1, numVisits=18, meanQ=3.253216, numObservations: 1
action 2, numVisits=9, meanQ=2.444444, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.0312332 0.803444 0.52548 0.816824 0.505052 0.877065 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 269
Initial state: 0 0.612982 0.803332 0.0734346 0.730696 0.559207 0.864131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166495 episodes
GETTING ACTION FROM:
action 2, numVisits=166463, meanQ=4.946002, numObservations: 4
action 0, numVisits=21, meanQ=3.416898, numObservations: 1
action 3, numVisits=8, meanQ=2.498750, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.612982 0.803332 0.0734346 0.730696 0.559207 0.864131 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=19095, meanQ=8.532936, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 49586 episodes
GETTING ACTION FROM:
action 3, numVisits=46153, meanQ=7.192316, numObservations: 5
action 1, numVisits=14831, meanQ=5.833598, numObservations: 5
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=7692, meanQ=-0.704783, numObservations: 1
action 0, numVisits=6, meanQ=-3.650000, numObservations: 1
action: 3
Next state: 1 0.612982 0.803332 0.0734346 0.730696 0.559207 0.864131 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 270
Initial state: 0 0.406298 0.41559 0.543396 0.831243 0.69967 0.847741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166994 episodes
GETTING ACTION FROM:
action 3, numVisits=166984, meanQ=4.984643, numObservations: 5
action 1, numVisits=5, meanQ=-0.399980, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.406298 0.41559 0.543396 0.831243 0.69967 0.847741 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 271
Initial state: 0 0.682976 0.855744 0.606477 0.902347 0.682377 0.871144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167449 episodes
GETTING ACTION FROM:
action 3, numVisits=167426, meanQ=4.913327, numObservations: 4
action -1, numVisits=17, meanQ=3.072968, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.682976 0.855744 0.606477 0.902347 0.682377 0.871144 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 272
Initial state: 0 0.587877 0.870507 0.610996 0.833886 0.669396 0.136907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166480 episodes
GETTING ACTION FROM:
action 2, numVisits=166474, meanQ=4.934974, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.587877 0.870507 0.610996 0.833886 0.669396 0.136907 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 273
Initial state: 0 0.51506 0.882489 0.700279 0.549124 0.652702 0.836122 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167302 episodes
GETTING ACTION FROM:
action 2, numVisits=167294, meanQ=4.944354, numObservations: 5
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.51506 0.882489 0.700279 0.549124 0.652702 0.836122 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 274
Initial state: 0 0.0811801 0.170252 0.674502 0.847828 0.50691 0.830699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165999 episodes
GETTING ACTION FROM:
action 2, numVisits=165956, meanQ=4.943081, numObservations: 5
action -1, numVisits=35, meanQ=3.767333, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0811801 0.170252 0.674502 0.847828 0.50691 0.830699 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 275
Initial state: 0 0.552421 0.876075 0.531413 0.856002 0.913716 0.531459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162156 episodes
GETTING ACTION FROM:
action 1, numVisits=162116, meanQ=5.024818, numObservations: 5
action 0, numVisits=36, meanQ=3.859654, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.552421 0.876075 0.531413 0.856002 0.913716 0.531459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 276
Initial state: 0 0.558047 0.814489 0.511748 0.757811 0.646139 0.826654 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168190 episodes
GETTING ACTION FROM:
action 2, numVisits=167908, meanQ=5.013386, numObservations: 3
action -1, numVisits=278, meanQ=3.229171, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.558047 0.814489 0.511748 0.757811 0.646139 0.826654 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27733, meanQ=8.320292, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 35390 episodes
GETTING ACTION FROM:
action 1, numVisits=56300, meanQ=7.135957, numObservations: 4
action 3, numVisits=70, meanQ=4.755670, numObservations: 3
action -1, numVisits=6749, meanQ=0.192992, numObservations: 1
action 0, numVisits=8, meanQ=-2.126225, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.558047 0.814489 0.511748 0.757811 0.646139 0.826654 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 277
Initial state: 0 0.570602 0.885552 0.524826 0.87685 0.179827 0.426616 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 151929 episodes
GETTING ACTION FROM:
action 1, numVisits=151897, meanQ=4.652898, numObservations: 4
action -1, numVisits=20, meanQ=2.981980, numObservations: 1
action 2, numVisits=7, meanQ=1.711443, numObservations: 3
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.570602 0.885552 0.524826 0.87685 0.179827 0.426616 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.538653 0.801546 0.0628106 0.415399 0.566285 0.866391 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169413 episodes
GETTING ACTION FROM:
action 2, numVisits=169407, meanQ=5.072545, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.538653 0.801546 0.0628106 0.415399 0.566285 0.866391 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27850, meanQ=8.318229, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29134 episodes
GETTING ACTION FROM:
action 1, numVisits=50222, meanQ=7.348526, numObservations: 4
action 0, numVisits=6706, meanQ=0.377854, numObservations: 1
action 3, numVisits=55, meanQ=-0.200870, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=4, meanQ=-98.187805, numObservations: 1
action: 1
Next state: 0 0.538653 0.801546 0.0628106 0.415399 0.566285 0.866391 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=596, meanQ=8.416535, numObservations: 4
action 0, numVisits=362, meanQ=6.860746, numObservations: 1
action 2, numVisits=3, meanQ=4.996667, numObservations: 2
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 41357 episodes
GETTING ACTION FROM:
action 3, numVisits=742, meanQ=8.077690, numObservations: 4
action 2, numVisits=3, meanQ=4.996667, numObservations: 2
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action 0, numVisits=41573, meanQ=-1.591147, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.538653 0.801546 0.0628106 0.415399 0.566285 0.866391 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 279
Initial state: 0 0.229832 0.784767 0.671782 0.84791 0.615388 0.839401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97474 episodes
GETTING ACTION FROM:
action 0, numVisits=97467, meanQ=3.001120, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.229832 0.784767 0.671782 0.84791 0.615388 0.839401 w: 1
Observation: 0 0 0.716462 0 0.799213 0 0.801289 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=73396, meanQ=3.891874, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 164585 episodes
GETTING ACTION FROM:
action 2, numVisits=237977, meanQ=4.484454, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=4, meanQ=-2.997475, numObservations: 2
action 3, numVisits=2, meanQ=-3.505000, numObservations: 2
action: 2
Next state: 0 0.229832 0.784767 0.671782 0.84791 0.615388 0.839401 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=14541, meanQ=3.046781, numObservations: 1
action 3, numVisits=14, meanQ=1.144307, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 204621 episodes
GETTING ACTION FROM:
action 3, numVisits=203443, meanQ=5.736572, numObservations: 4
action -1, numVisits=15733, meanQ=2.756247, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.229832 0.784767 0.671782 0.84791 0.615388 0.839401 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 280
Initial state: 0 0.687916 0.838147 0.406092 0.910669 0.537518 0.855126 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167450 episodes
GETTING ACTION FROM:
action 2, numVisits=167432, meanQ=4.941260, numObservations: 5
action 1, numVisits=13, meanQ=1.307700, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.687916 0.838147 0.406092 0.910669 0.537518 0.855126 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1560, meanQ=4.792412, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 32404 episodes
GETTING ACTION FROM:
action 3, numVisits=21971, meanQ=5.712773, numObservations: 4
action -1, numVisits=11979, meanQ=-0.426379, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=16, meanQ=-3.273298, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.687916 0.838147 0.406092 0.910669 0.537518 0.855126 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 281
Initial state: 0 0.593448 0.815807 0.427799 0.280852 0.638923 0.824138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164575 episodes
GETTING ACTION FROM:
action 1, numVisits=164569, meanQ=4.939795, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.593448 0.815807 0.427799 0.280852 0.638923 0.824138 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 282
Initial state: 0 0.284216 0.989005 0.599129 0.882787 0.510434 0.80218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167578 episodes
GETTING ACTION FROM:
action 1, numVisits=167496, meanQ=4.956564, numObservations: 4
action -1, numVisits=62, meanQ=4.058971, numObservations: 1
action 3, numVisits=17, meanQ=3.117653, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.284216 0.989005 0.599129 0.882787 0.510434 0.80218 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12194, meanQ=4.844781, numObservations: 4
action 0, numVisits=49, meanQ=3.989056, numObservations: 1
action -1, numVisits=22, meanQ=3.578313, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 208523 episodes
GETTING ACTION FROM:
action 2, numVisits=220716, meanQ=5.721498, numObservations: 4
action 0, numVisits=49, meanQ=3.989056, numObservations: 1
action -1, numVisits=23, meanQ=3.590595, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.284216 0.989005 0.599129 0.882787 0.510434 0.80218 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 283
Initial state: 0 0.538862 0.897956 0.583379 0.855127 0.446902 0.739547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167972 episodes
GETTING ACTION FROM:
action 2, numVisits=167964, meanQ=4.997308, numObservations: 4
action 1, numVisits=3, meanQ=0.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.538862 0.897956 0.583379 0.855127 0.446902 0.739547 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 284
Initial state: 0 0.532792 0.899547 0.528865 0.816729 0.934449 0.430594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167332 episodes
GETTING ACTION FROM:
action 2, numVisits=167312, meanQ=4.929490, numObservations: 5
action -1, numVisits=15, meanQ=3.077743, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.532792 0.899547 0.528865 0.816729 0.934449 0.430594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 285
Initial state: 0 0.533146 0.8339 0.440355 0.35533 0.644314 0.864934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167466 episodes
GETTING ACTION FROM:
action 2, numVisits=167451, meanQ=4.909323, numObservations: 3
action 1, numVisits=6, meanQ=1.166683, numObservations: 3
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.533146 0.8339 0.440355 0.35533 0.644314 0.864934 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27576, meanQ=8.334861, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 37617 episodes
GETTING ACTION FROM:
action 1, numVisits=60597, meanQ=7.154442, numObservations: 4
action 0, numVisits=4575, meanQ=0.102905, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=20, meanQ=-2.200475, numObservations: 1
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 1
Next state: 1 0.533146 0.8339 0.440355 0.35533 0.644314 0.864934 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 286
Initial state: 0 0.411743 0.99051 0.608598 0.887504 0.590612 0.81684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97866 episodes
GETTING ACTION FROM:
action -1, numVisits=97859, meanQ=2.838749, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.411743 0.99051 0.608598 0.887504 0.590612 0.81684 w: 1
Observation: 0 0.399915 0 0.677634 0 0.612151 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=97830, meanQ=4.906333, numObservations: 4
action 3, numVisits=23, meanQ=1.954787, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 167352 episodes
GETTING ACTION FROM:
action 1, numVisits=265180, meanQ=5.040757, numObservations: 4
action 3, numVisits=23, meanQ=1.954787, numObservations: 4
action 2, numVisits=3, meanQ=-0.700000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.411743 0.99051 0.608598 0.887504 0.590612 0.81684 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=2401, meanQ=3.953747, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 32505 episodes
GETTING ACTION FROM:
action 2, numVisits=27014, meanQ=5.576829, numObservations: 5
action 3, numVisits=46, meanQ=3.414526, numObservations: 3
action 1, numVisits=5, meanQ=3.180000, numObservations: 3
action -1, numVisits=7741, meanQ=0.838101, numObservations: 1
action 0, numVisits=107, meanQ=0.325375, numObservations: 2
action: 2
Next state: 1 0.411743 0.99051 0.608598 0.887504 0.590612 0.81684 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 287
Initial state: 0 0.0636624 0.201873 0.564288 0.808143 0.668861 0.83941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168000 episodes
GETTING ACTION FROM:
action 1, numVisits=167967, meanQ=5.048642, numObservations: 5
action 3, numVisits=16, meanQ=2.874375, numObservations: 4
action 2, numVisits=13, meanQ=2.846154, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0636624 0.201873 0.564288 0.808143 0.668861 0.83941 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=19100, meanQ=8.531385, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 17277 episodes
GETTING ACTION FROM:
action 2, numVisits=24332, meanQ=7.990362, numObservations: 3
action 3, numVisits=76, meanQ=5.423181, numObservations: 4
action -1, numVisits=11924, meanQ=0.410655, numObservations: 1
action 0, numVisits=48, meanQ=-1.161880, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0636624 0.201873 0.564288 0.808143 0.668861 0.83941 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 288
Initial state: 0 0.0162573 0.825913 0.585806 0.827118 0.59222 0.805563 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159312 episodes
GETTING ACTION FROM:
action 1, numVisits=159259, meanQ=4.866425, numObservations: 5
action 0, numVisits=38, meanQ=3.702131, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action 3, numVisits=6, meanQ=0.166667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0162573 0.825913 0.585806 0.827118 0.59222 0.805563 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3967, meanQ=7.718179, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 36024 episodes
GETTING ACTION FROM:
action 2, numVisits=26700, meanQ=6.189173, numObservations: 4
action -1, numVisits=13290, meanQ=0.058291, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 0, numVisits=2, meanQ=-197.062417, numObservations: 1
action: 2
Next state: 1 0.0162573 0.825913 0.585806 0.827118 0.59222 0.805563 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 289
Initial state: 0 0.178352 0.995122 0.52783 0.879939 0.601217 0.830096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158836 episodes
GETTING ACTION FROM:
action 1, numVisits=158790, meanQ=4.853234, numObservations: 3
action 0, numVisits=42, meanQ=3.776645, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.178352 0.995122 0.52783 0.879939 0.601217 0.830096 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=11593, meanQ=3.419600, numObservations: 1
action -1, numVisits=31, meanQ=2.093169, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 205742 episodes
GETTING ACTION FROM:
action 2, numVisits=205743, meanQ=5.998231, numObservations: 4
action 0, numVisits=11593, meanQ=3.419600, numObservations: 1
action -1, numVisits=31, meanQ=2.093169, numObservations: 1
action 1, numVisits=2, meanQ=-3.505000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.178352 0.995122 0.52783 0.879939 0.601217 0.830096 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 290
Initial state: 0 0.596154 0.896338 0.635189 0.870051 0.862085 0.493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167932 episodes
GETTING ACTION FROM:
action 1, numVisits=167863, meanQ=5.018916, numObservations: 4
action -1, numVisits=62, meanQ=4.146883, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.596154 0.896338 0.635189 0.870051 0.862085 0.493 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 291
Initial state: 0 0.583687 0.881965 0.525505 0.809585 0.521074 0.20019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90445 episodes
GETTING ACTION FROM:
action 0, numVisits=90440, meanQ=4.897260, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.583687 0.881965 0.525505 0.809585 0.521074 0.20019 w: 1
Observation: 0 0 0.910062 0 0.72515 0 0.251533 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23718, meanQ=8.298996, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 170565 episodes
GETTING ACTION FROM:
action 2, numVisits=194281, meanQ=5.688200, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.583687 0.881965 0.525505 0.809585 0.521074 0.20019 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 292
Initial state: 0 0.44554 0.4285 0.629023 0.848814 0.684316 0.873057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 149586 episodes
GETTING ACTION FROM:
action 2, numVisits=149571, meanQ=4.631954, numObservations: 4
action 3, numVisits=9, meanQ=0.557800, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.44554 0.4285 0.629023 0.848814 0.684316 0.873057 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 293
Initial state: 0 0.0951363 0.50448 0.522197 0.804553 0.68546 0.810189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167629 episodes
GETTING ACTION FROM:
action 2, numVisits=167619, meanQ=5.098684, numObservations: 4
action 3, numVisits=5, meanQ=-0.002000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0951363 0.50448 0.522197 0.804553 0.68546 0.810189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 294
Initial state: 0 0.593517 0.870929 0.538737 0.888076 0.0972458 0.600026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168646 episodes
GETTING ACTION FROM:
action 1, numVisits=168590, meanQ=5.043652, numObservations: 4
action 0, numVisits=44, meanQ=3.964775, numObservations: 1
action 2, numVisits=9, meanQ=2.333344, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.593517 0.870929 0.538737 0.888076 0.0972458 0.600026 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 295
Initial state: 0 0.50558 0.822875 0.291216 0.85914 0.689444 0.824182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167401 episodes
GETTING ACTION FROM:
action 2, numVisits=167372, meanQ=5.017362, numObservations: 4
action -1, numVisits=22, meanQ=3.551488, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.50558 0.822875 0.291216 0.85914 0.689444 0.824182 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8274, meanQ=7.876795, numObservations: 3
action 1, numVisits=31, meanQ=6.225171, numObservations: 3
action 2, numVisits=3, meanQ=2.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 26842 episodes
GETTING ACTION FROM:
action 3, numVisits=27191, meanQ=6.564036, numObservations: 3
action 1, numVisits=203, meanQ=5.572461, numObservations: 4
action 2, numVisits=21, meanQ=5.238095, numObservations: 4
action 0, numVisits=7419, meanQ=0.220728, numObservations: 1
action -1, numVisits=318, meanQ=-0.091604, numObservations: 1
action: 3
Next state: 1 0.50558 0.822875 0.291216 0.85914 0.689444 0.824182 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 296
Initial state: 0 0.522396 0.835176 0.738758 0.192571 0.505185 0.878787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 99071 episodes
GETTING ACTION FROM:
action -1, numVisits=99044, meanQ=2.910718, numObservations: 1
action 1, numVisits=23, meanQ=1.343483, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.522396 0.835176 0.738758 0.192571 0.505185 0.878787 w: 1
Observation: 0 0.580884 0 0.688334 0 0.421217 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=98964, meanQ=4.983608, numObservations: 4
action 0, numVisits=56, meanQ=4.079460, numObservations: 2
action 1, numVisits=17, meanQ=2.881176, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 167400 episodes
GETTING ACTION FROM:
action 3, numVisits=266356, meanQ=4.809213, numObservations: 4
action 0, numVisits=64, meanQ=3.931678, numObservations: 2
action 1, numVisits=17, meanQ=2.881176, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.522396 0.835176 0.738758 0.192571 0.505185 0.878787 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 297
Initial state: 0 0.920085 0.474339 0.63473 0.806525 0.604642 0.882185 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168078 episodes
GETTING ACTION FROM:
action 1, numVisits=168040, meanQ=5.011827, numObservations: 3
action 0, numVisits=34, meanQ=3.824319, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.920085 0.474339 0.63473 0.806525 0.604642 0.882185 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 298
Initial state: 0 0.8238 0.196632 0.674886 0.873168 0.661719 0.8085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167725 episodes
GETTING ACTION FROM:
action 1, numVisits=167703, meanQ=5.008164, numObservations: 5
action 2, numVisits=12, meanQ=1.750008, numObservations: 4
action 3, numVisits=6, meanQ=1.166683, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.8238 0.196632 0.674886 0.873168 0.661719 0.8085 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 299
Initial state: 0 0.64177 0.87803 0.657918 0.86508 0.210957 0.64572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167580 episodes
GETTING ACTION FROM:
action 2, numVisits=167574, meanQ=5.009752, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.64177 0.87803 0.657918 0.86508 0.210957 0.64572 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 300
Initial state: 0 0.841084 0.912371 0.588872 0.822557 0.591775 0.851537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167528 episodes
GETTING ACTION FROM:
action 1, numVisits=167495, meanQ=5.122178, numObservations: 4
action -1, numVisits=26, meanQ=3.731757, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.841084 0.912371 0.588872 0.822557 0.591775 0.851537 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 301
Initial state: 0 0.673246 0.832471 0.503331 0.825251 0.203448 0.983215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158398 episodes
GETTING ACTION FROM:
action 2, numVisits=155761, meanQ=4.854202, numObservations: 4
action -1, numVisits=2633, meanQ=3.447385, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.673246 0.832471 0.503331 0.825251 0.203448 0.983215 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 302
Initial state: 0 0.169711 0.688006 0.697349 0.853609 0.577752 0.865752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167504 episodes
GETTING ACTION FROM:
action 2, numVisits=167477, meanQ=5.005358, numObservations: 3
action 0, numVisits=22, meanQ=3.482851, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.169711 0.688006 0.697349 0.853609 0.577752 0.865752 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27430, meanQ=8.318422, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 32542 episodes
GETTING ACTION FROM:
action 1, numVisits=38183, meanQ=7.706681, numObservations: 4
action 2, numVisits=12, meanQ=4.908333, numObservations: 4
action -1, numVisits=21710, meanQ=0.059483, numObservations: 1
action 0, numVisits=67, meanQ=-0.914549, numObservations: 2
action 3, numVisits=5, meanQ=-1.471527, numObservations: 2
action: 1
Next state: 0 0.169711 0.688006 0.697349 0.853609 0.577752 0.865752 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=525, meanQ=8.441048, numObservations: 3
action 0, numVisits=111, meanQ=6.838649, numObservations: 1
action 2, numVisits=8, meanQ=5.997500, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 26421 episodes
GETTING ACTION FROM:
action 3, numVisits=13297, meanQ=6.127814, numObservations: 3
action 2, numVisits=8, meanQ=5.997500, numObservations: 4
action 0, numVisits=13471, meanQ=-1.682519, numObservations: 2
action -1, numVisits=291, meanQ=-2.003742, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.169711 0.688006 0.697349 0.853609 0.577752 0.865752 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 303
Initial state: 0 0.621043 0.850705 0.530737 0.37283 0.643255 0.837068 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160406 episodes
GETTING ACTION FROM:
action 1, numVisits=160312, meanQ=4.833341, numObservations: 3
action 0, numVisits=51, meanQ=3.838214, numObservations: 1
action -1, numVisits=36, meanQ=3.682695, numObservations: 1
action 3, numVisits=5, meanQ=-0.002000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.621043 0.850705 0.530737 0.37283 0.643255 0.837068 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 304
Initial state: 0 0.836888 0.653379 0.525833 0.899522 0.533698 0.842075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167484 episodes
GETTING ACTION FROM:
action 3, numVisits=167478, meanQ=4.980805, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.836888 0.653379 0.525833 0.899522 0.533698 0.842075 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 305
Initial state: 0 0.551409 0.815823 0.12645 0.174502 0.683866 0.897406 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167883 episodes
GETTING ACTION FROM:
action 2, numVisits=167877, meanQ=4.973425, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.551409 0.815823 0.12645 0.174502 0.683866 0.897406 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4237, meanQ=7.599842, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 35180 episodes
GETTING ACTION FROM:
action 1, numVisits=32996, meanQ=6.254191, numObservations: 5
action 2, numVisits=34, meanQ=6.087944, numObservations: 4
action 0, numVisits=6379, meanQ=0.144198, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action -1, numVisits=10, meanQ=-40.417453, numObservations: 1
action: 1
Next state: 1 0.551409 0.815823 0.12645 0.174502 0.683866 0.897406 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 306
Initial state: 0 0.655549 0.878365 0.591759 0.872079 0.746811 0.283274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168262 episodes
GETTING ACTION FROM:
action 3, numVisits=168254, meanQ=5.006793, numObservations: 3
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.655549 0.878365 0.591759 0.872079 0.746811 0.283274 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 307
Initial state: 0 0.613619 0.873861 0.586646 0.813587 0.5994 0.515373 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166122 episodes
GETTING ACTION FROM:
action 3, numVisits=166116, meanQ=5.007393, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.613619 0.873861 0.586646 0.813587 0.5994 0.515373 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 308
Initial state: 0 0.78376 0.310915 0.629138 0.809315 0.583136 0.815413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165701 episodes
GETTING ACTION FROM:
action 3, numVisits=165695, meanQ=4.929382, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.78376 0.310915 0.629138 0.809315 0.583136 0.815413 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 309
Initial state: 0 0.453784 0.819467 0.500937 0.805506 0.662057 0.889403 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167139 episodes
GETTING ACTION FROM:
action 1, numVisits=167016, meanQ=4.979665, numObservations: 4
action -1, numVisits=86, meanQ=4.236627, numObservations: 1
action 2, numVisits=34, meanQ=3.643826, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.453784 0.819467 0.500937 0.805506 0.662057 0.889403 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 310
Initial state: 0 0.676681 0.82218 0.372772 0.970222 0.568413 0.84764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168805 episodes
GETTING ACTION FROM:
action 3, numVisits=168101, meanQ=5.001297, numObservations: 4
action 2, numVisits=695, meanQ=4.683557, numObservations: 5
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.676681 0.82218 0.372772 0.970222 0.568413 0.84764 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=12352, meanQ=5.482581, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 184982 episodes
GETTING ACTION FROM:
action 3, numVisits=197330, meanQ=5.109478, numObservations: 5
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.676681 0.82218 0.372772 0.970222 0.568413 0.84764 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 311
Initial state: 0 0.576831 0.850864 0.518714 0.837675 0.205995 0.952716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169108 episodes
GETTING ACTION FROM:
action 2, numVisits=169073, meanQ=5.011550, numObservations: 4
action 0, numVisits=29, meanQ=3.709077, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.576831 0.850864 0.518714 0.837675 0.205995 0.952716 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 312
Initial state: 0 0.54477 0.809901 0.975068 0.4724 0.683168 0.81162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167898 episodes
GETTING ACTION FROM:
action 2, numVisits=167797, meanQ=5.014410, numObservations: 4
action 3, numVisits=96, meanQ=4.272153, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.54477 0.809901 0.975068 0.4724 0.683168 0.81162 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 313
Initial state: 0 0.0143288 0.693715 0.657112 0.83919 0.560568 0.841067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168534 episodes
GETTING ACTION FROM:
action 1, numVisits=168405, meanQ=5.005963, numObservations: 5
action 0, numVisits=69, meanQ=4.166004, numObservations: 1
action -1, numVisits=21, meanQ=3.422898, numObservations: 1
action 2, numVisits=37, meanQ=3.334597, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 0 0.0143288 0.693715 0.657112 0.83919 0.560568 0.841067 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23636, meanQ=8.439460, numObservations: 5
action 3, numVisits=55, meanQ=7.509098, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 35209 episodes
GETTING ACTION FROM:
action 2, numVisits=52774, meanQ=7.076593, numObservations: 5
action 3, numVisits=145, meanQ=5.895313, numObservations: 3
action 1, numVisits=5, meanQ=5.780000, numObservations: 3
action -1, numVisits=4227, meanQ=0.272527, numObservations: 1
action 0, numVisits=1752, meanQ=0.167038, numObservations: 1
action: 2
Next state: 1 0.0143288 0.693715 0.657112 0.83919 0.560568 0.841067 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 314
Initial state: 0 0.533124 0.836695 0.636977 0.892721 0.213229 0.154958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168198 episodes
GETTING ACTION FROM:
action 3, numVisits=168192, meanQ=5.049702, numObservations: 5
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.533124 0.836695 0.636977 0.892721 0.213229 0.154958 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23420, meanQ=8.413471, numObservations: 3
action 1, numVisits=9, meanQ=4.555556, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22885 episodes
GETTING ACTION FROM:
action 2, numVisits=41484, meanQ=7.451065, numObservations: 3
action 1, numVisits=32, meanQ=4.634641, numObservations: 5
action 0, numVisits=4673, meanQ=0.088046, numObservations: 1
action -1, numVisits=127, meanQ=-0.466241, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.533124 0.836695 0.636977 0.892721 0.213229 0.154958 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 315
Initial state: 0 0.540788 0.871724 0.549039 0.889465 0.446527 0.204436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169373 episodes
GETTING ACTION FROM:
action 2, numVisits=169313, meanQ=5.030759, numObservations: 5
action -1, numVisits=56, meanQ=4.107168, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.540788 0.871724 0.549039 0.889465 0.446527 0.204436 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 316
Initial state: 0 0.5375 0.85571 0.509818 0.07252 0.686446 0.850543 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168376 episodes
GETTING ACTION FROM:
action 3, numVisits=168267, meanQ=4.968113, numObservations: 4
action -1, numVisits=49, meanQ=3.980228, numObservations: 1
action 0, numVisits=47, meanQ=3.955321, numObservations: 1
action 2, numVisits=12, meanQ=2.916667, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.5375 0.85571 0.509818 0.07252 0.686446 0.850543 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 317
Initial state: 0 0.650812 0.8003 0.208337 0.93707 0.626984 0.829492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168353 episodes
GETTING ACTION FROM:
action 1, numVisits=168335, meanQ=5.005961, numObservations: 5
action 3, numVisits=8, meanQ=1.623763, numObservations: 2
action 2, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.650812 0.8003 0.208337 0.93707 0.626984 0.829492 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 318
Initial state: 0 0.695244 0.811245 0.625941 0.806422 0.0546962 0.718596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166283 episodes
GETTING ACTION FROM:
action 2, numVisits=166271, meanQ=4.921961, numObservations: 4
action 3, numVisits=7, meanQ=0.428571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.695244 0.811245 0.625941 0.806422 0.0546962 0.718596 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 319
Initial state: 0 0.519447 0.874619 0.67619 0.822443 0.896345 0.326599 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167797 episodes
GETTING ACTION FROM:
action 1, numVisits=167740, meanQ=5.026130, numObservations: 5
action 0, numVisits=28, meanQ=3.661015, numObservations: 1
action -1, numVisits=26, meanQ=3.614149, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.519447 0.874619 0.67619 0.822443 0.896345 0.326599 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 320
Initial state: 0 0.667155 0.810543 0.619746 0.841067 0.967761 0.72009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131884 episodes
GETTING ACTION FROM:
action 1, numVisits=79557, meanQ=5.016537, numObservations: 5
action -1, numVisits=52323, meanQ=2.940262, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.667155 0.810543 0.619746 0.841067 0.967761 0.72009 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 321
Initial state: 0 0.591618 0.889996 0.534187 0.849003 0.251591 0.40924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167278 episodes
GETTING ACTION FROM:
action 1, numVisits=167226, meanQ=4.967697, numObservations: 5
action -1, numVisits=30, meanQ=3.713604, numObservations: 1
action 3, numVisits=19, meanQ=3.268421, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.591618 0.889996 0.534187 0.849003 0.251591 0.40924 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 322
Initial state: 0 0.26317 0.0938855 0.522824 0.855519 0.657454 0.868812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 150525 episodes
GETTING ACTION FROM:
action 2, numVisits=125902, meanQ=5.021393, numObservations: 4
action -1, numVisits=23718, meanQ=3.080980, numObservations: 1
action 0, numVisits=903, meanQ=2.910499, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.26317 0.0938855 0.522824 0.855519 0.657454 0.868812 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 323
Initial state: 0 0.635726 0.815217 0.31698 0.239512 0.678701 0.898945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 101824 episodes
GETTING ACTION FROM:
action 0, numVisits=101817, meanQ=5.795377, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.635726 0.815217 0.31698 0.239512 0.678701 0.898945 w: 1
Observation: 0 0 0.779196 0 0.227422 0 0.814421 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=59895, meanQ=7.718151, numObservations: 5
action 2, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 164832 episodes
GETTING ACTION FROM:
action 1, numVisits=224724, meanQ=5.640242, numObservations: 5
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.635726 0.815217 0.31698 0.239512 0.678701 0.898945 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 324
Initial state: 0 0.693078 0.848094 0.553056 0.8932 0.635228 0.148112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164119 episodes
GETTING ACTION FROM:
action 3, numVisits=164013, meanQ=5.023550, numObservations: 5
action -1, numVisits=82, meanQ=4.271038, numObservations: 1
action 0, numVisits=20, meanQ=3.481984, numObservations: 1
action 1, numVisits=3, meanQ=0.663333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.693078 0.848094 0.553056 0.8932 0.635228 0.148112 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 325
Initial state: 0 0.653348 0.824431 0.529469 0.837849 0.278214 0.552004 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161480 episodes
GETTING ACTION FROM:
action 2, numVisits=156778, meanQ=5.045499, numObservations: 4
action -1, numVisits=4698, meanQ=3.027553, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.653348 0.824431 0.529469 0.837849 0.278214 0.552004 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 326
Initial state: 0 0.527814 0.88618 0.384095 0.359905 0.660487 0.828948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154496 episodes
GETTING ACTION FROM:
action 1, numVisits=154451, meanQ=4.783737, numObservations: 4
action -1, numVisits=33, meanQ=3.592242, numObservations: 1
action 2, numVisits=9, meanQ=2.002244, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.527814 0.88618 0.384095 0.359905 0.660487 0.828948 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 327
Initial state: 0 0.558046 0.878681 0.561923 0.831903 0.490598 0.382305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163881 episodes
GETTING ACTION FROM:
action 1, numVisits=162138, meanQ=5.026276, numObservations: 4
action 2, numVisits=1696, meanQ=4.867547, numObservations: 4
action -1, numVisits=43, meanQ=3.973308, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.558046 0.878681 0.561923 0.831903 0.490598 0.382305 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 328
Initial state: 0 0.571808 0.838105 0.54729 0.874611 0.711409 0.953017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163942 episodes
GETTING ACTION FROM:
action 3, numVisits=163609, meanQ=4.990770, numObservations: 5
action 2, numVisits=207, meanQ=4.502691, numObservations: 4
action 0, numVisits=101, meanQ=4.308394, numObservations: 1
action -1, numVisits=24, meanQ=3.439159, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.571808 0.838105 0.54729 0.874611 0.711409 0.953017 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 329
Initial state: 0 0.579228 0.863525 0.152317 0.0630978 0.696303 0.873092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163374 episodes
GETTING ACTION FROM:
action 2, numVisits=163299, meanQ=4.961676, numObservations: 5
action 0, numVisits=66, meanQ=4.094171, numObservations: 1
action 1, numVisits=6, meanQ=0.836683, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.579228 0.863525 0.152317 0.0630978 0.696303 0.873092 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22795, meanQ=8.450932, numObservations: 4
action 1, numVisits=12, meanQ=5.831675, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 40567 episodes
GETTING ACTION FROM:
action 3, numVisits=22797, meanQ=8.450773, numObservations: 4
action 1, numVisits=118, meanQ=6.167799, numObservations: 4
action -1, numVisits=40459, meanQ=0.176488, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-194.622019, numObservations: 1
action: 3
Next state: 1 0.579228 0.863525 0.152317 0.0630978 0.696303 0.873092 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 330
Initial state: 0 0.646808 0.865141 0.517104 0.822687 0.499593 0.402425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163689 episodes
GETTING ACTION FROM:
action 3, numVisits=163660, meanQ=4.926386, numObservations: 4
action 0, numVisits=25, meanQ=3.545993, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.646808 0.865141 0.517104 0.822687 0.499593 0.402425 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26467, meanQ=8.334203, numObservations: 4
action 1, numVisits=153, meanQ=7.792551, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30389 episodes
GETTING ACTION FROM:
action 2, numVisits=49859, meanQ=7.144633, numObservations: 4
action 1, numVisits=1720, meanQ=6.289140, numObservations: 5
action 0, numVisits=5425, meanQ=0.171058, numObservations: 3
action -1, numVisits=7, meanQ=-2.287100, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.646808 0.865141 0.517104 0.822687 0.499593 0.402425 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 331
Initial state: 0 0.609833 0.881813 0.534252 0.833563 0.348553 0.606968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163601 episodes
GETTING ACTION FROM:
action 1, numVisits=163594, meanQ=4.928134, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.609833 0.881813 0.534252 0.833563 0.348553 0.606968 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 332
Initial state: 0 0.527365 0.881472 0.685224 0.482749 0.698973 0.880495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162295 episodes
GETTING ACTION FROM:
action 3, numVisits=162285, meanQ=4.936864, numObservations: 5
action 1, numVisits=3, meanQ=0.333333, numObservations: 3
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.527365 0.881472 0.685224 0.482749 0.698973 0.880495 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 333
Initial state: 0 0.645488 0.812398 0.639411 0.801602 0.967122 0.151224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155838 episodes
GETTING ACTION FROM:
action 2, numVisits=155785, meanQ=4.811810, numObservations: 4
action -1, numVisits=48, meanQ=3.801015, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.645488 0.812398 0.639411 0.801602 0.967122 0.151224 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 334
Initial state: 0 0.5431 0.804813 0.81814 0.367397 0.686769 0.864299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96414 episodes
GETTING ACTION FROM:
action 0, numVisits=96409, meanQ=2.942477, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.5431 0.804813 0.81814 0.367397 0.686769 0.864299 w: 1
Observation: 0 0 0.900315 0 0.376452 0 0.841608 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=96388, meanQ=4.948884, numObservations: 3
action 1, numVisits=14, meanQ=1.570000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 169302 episodes
GETTING ACTION FROM:
action 3, numVisits=265683, meanQ=4.931951, numObservations: 3
action 1, numVisits=15, meanQ=1.198667, numObservations: 3
action 2, numVisits=8, meanQ=-0.125000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.5431 0.804813 0.81814 0.367397 0.686769 0.864299 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 335
Initial state: 0 0.673323 0.824299 0.668419 0.890161 0.379677 0.438417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 102106 episodes
GETTING ACTION FROM:
action 0, numVisits=102100, meanQ=5.917822, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.673323 0.824299 0.668419 0.890161 0.379677 0.438417 w: 1
Observation: 0 0 0.853134 0 0.799714 0 0.516522 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=30109, meanQ=8.253725, numObservations: 4
action 2, numVisits=11, meanQ=5.363636, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 166714 episodes
GETTING ACTION FROM:
action 1, numVisits=196811, meanQ=5.555092, numObservations: 4
action 2, numVisits=21, meanQ=4.046667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.673323 0.824299 0.668419 0.890161 0.379677 0.438417 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 336
Initial state: 0 0.505861 0.847213 0.601717 0.886674 0.196724 0.334689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163660 episodes
GETTING ACTION FROM:
action 3, numVisits=163654, meanQ=5.003147, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.505861 0.847213 0.601717 0.886674 0.196724 0.334689 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=23037, meanQ=8.379477, numObservations: 4
action 2, numVisits=6, meanQ=4.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29353 episodes
GETTING ACTION FROM:
action 1, numVisits=48326, meanQ=7.150096, numObservations: 4
action 2, numVisits=416, meanQ=6.430014, numObservations: 5
action -1, numVisits=3654, meanQ=0.174088, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-196.307778, numObservations: 1
action: 1
Next state: 1 0.505861 0.847213 0.601717 0.886674 0.196724 0.334689 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 337
Initial state: 0 0.542973 0.817443 0.552537 0.849098 0.897194 0.582693 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162116 episodes
GETTING ACTION FROM:
action 1, numVisits=162074, meanQ=4.926895, numObservations: 5
action -1, numVisits=37, meanQ=3.790205, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.542973 0.817443 0.552537 0.849098 0.897194 0.582693 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 338
Initial state: 0 0.618992 0.892162 0.500574 0.819182 0.239261 0.461479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156993 episodes
GETTING ACTION FROM:
action 2, numVisits=156959, meanQ=4.892257, numObservations: 5
action -1, numVisits=30, meanQ=3.592560, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.618992 0.892162 0.500574 0.819182 0.239261 0.461479 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 339
Initial state: 0 0.629584 0.843666 0.602374 0.846775 0.485475 0.513112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160532 episodes
GETTING ACTION FROM:
action 3, numVisits=155264, meanQ=5.013318, numObservations: 4
action -1, numVisits=5264, meanQ=3.059281, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.629584 0.843666 0.602374 0.846775 0.485475 0.513112 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=21641, meanQ=8.431429, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 31246 episodes
GETTING ACTION FROM:
action 2, numVisits=47775, meanQ=7.245986, numObservations: 3
action 0, numVisits=5104, meanQ=0.154375, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=9, meanQ=-2.112200, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.629584 0.843666 0.602374 0.846775 0.485475 0.513112 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 340
Initial state: 0 0.564871 0.829502 0.503417 0.814965 0.2409 0.75451 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164264 episodes
GETTING ACTION FROM:
action 2, numVisits=164203, meanQ=5.020658, numObservations: 4
action -1, numVisits=57, meanQ=4.102767, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.564871 0.829502 0.503417 0.814965 0.2409 0.75451 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 341
Initial state: 0 0.293941 0.0289379 0.684143 0.822568 0.604371 0.896887 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162630 episodes
GETTING ACTION FROM:
action 1, numVisits=162560, meanQ=4.966262, numObservations: 5
action 0, numVisits=38, meanQ=3.839551, numObservations: 1
action -1, numVisits=19, meanQ=3.359043, numObservations: 1
action 3, numVisits=12, meanQ=2.833350, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.293941 0.0289379 0.684143 0.822568 0.604371 0.896887 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=22387, meanQ=8.416366, numObservations: 5
action 3, numVisits=4, meanQ=2.497525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30864 episodes
GETTING ACTION FROM:
action 2, numVisits=45635, meanQ=7.321561, numObservations: 5
action 3, numVisits=5, meanQ=0.805941, numObservations: 3
action 0, numVisits=7608, meanQ=0.273040, numObservations: 2
action -1, numVisits=9, meanQ=-2.112200, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.293941 0.0289379 0.684143 0.822568 0.604371 0.896887 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 342
Initial state: 0 0.697578 0.871786 0.529418 0.680522 0.583973 0.883616 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163952 episodes
GETTING ACTION FROM:
action 2, numVisits=163936, meanQ=5.017805, numObservations: 4
action 3, numVisits=10, meanQ=2.790000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.697578 0.871786 0.529418 0.680522 0.583973 0.883616 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11883, meanQ=5.588382, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
Sampled 13903 episodes
GETTING ACTION FROM:
action 2, numVisits=11884, meanQ=5.588119, numObservations: 4
action -1, numVisits=13883, meanQ=-0.366799, numObservations: 1
action 1, numVisits=19, meanQ=-0.682864, numObservations: 3
action 3, numVisits=4, meanQ=-4.002500, numObservations: 2
action 0, numVisits=4, meanQ=-4.475000, numObservations: 1
action: 2
Next state: 2 0.697578 0.871786 0.529418 0.680522 0.583973 0.883616 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 343
Initial state: 0 0.503364 0.802572 0.720307 0.491974 0.585733 0.810298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96679 episodes
GETTING ACTION FROM:
action -1, numVisits=96674, meanQ=2.901784, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.503364 0.802572 0.720307 0.491974 0.585733 0.810298 w: 1
Observation: 0 0.519031 0 0.701899 0 0.555922 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=96667, meanQ=4.989688, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 163980 episodes
GETTING ACTION FROM:
action 2, numVisits=260075, meanQ=5.123310, numObservations: 5
action 1, numVisits=572, meanQ=4.725569, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 2 0.503364 0.802572 0.720307 0.491974 0.585733 0.810298 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 344
Initial state: 0 0.226745 0.329115 0.587188 0.806812 0.672972 0.832138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157463 episodes
GETTING ACTION FROM:
action 2, numVisits=157456, meanQ=4.963053, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.226745 0.329115 0.587188 0.806812 0.672972 0.832138 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 345
Initial state: 0 0.691357 0.859706 0.618008 0.809782 0.688461 0.206535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163902 episodes
GETTING ACTION FROM:
action 1, numVisits=163896, meanQ=4.968362, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.691357 0.859706 0.618008 0.809782 0.688461 0.206535 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 346
Initial state: 0 0.611825 0.588718 0.608341 0.851045 0.629739 0.85311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164141 episodes
GETTING ACTION FROM:
action 3, numVisits=164125, meanQ=4.958426, numObservations: 5
action 1, numVisits=11, meanQ=2.453636, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.611825 0.588718 0.608341 0.851045 0.629739 0.85311 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 347
Initial state: 0 0.67064 0.402874 0.598669 0.869295 0.503477 0.833578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164006 episodes
GETTING ACTION FROM:
action 1, numVisits=163999, meanQ=4.927982, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.67064 0.402874 0.598669 0.869295 0.503477 0.833578 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 348
Initial state: 0 0.594438 0.886152 0.933599 0.514015 0.668008 0.805088 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162183 episodes
GETTING ACTION FROM:
action 3, numVisits=162160, meanQ=4.941788, numObservations: 4
action 1, numVisits=7, meanQ=2.117157, numObservations: 2
action 2, numVisits=12, meanQ=1.750008, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.594438 0.886152 0.933599 0.514015 0.668008 0.805088 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 349
Initial state: 0 0.677612 0.826936 0.626061 0.819234 0.873044 0.929189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160278 episodes
GETTING ACTION FROM:
action 1, numVisits=155494, meanQ=4.952211, numObservations: 5
action 0, numVisits=4689, meanQ=3.031600, numObservations: 1
action -1, numVisits=88, meanQ=2.489359, numObservations: 1
action 3, numVisits=6, meanQ=0.166667, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.677612 0.826936 0.626061 0.819234 0.873044 0.929189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 350
Initial state: 0 0.641681 0.164021 0.69742 0.886878 0.66953 0.867993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163801 episodes
GETTING ACTION FROM:
action 1, numVisits=160403, meanQ=4.943154, numObservations: 4
action 2, numVisits=3376, meanQ=4.788843, numObservations: 5
action -1, numVisits=19, meanQ=3.364036, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.641681 0.164021 0.69742 0.886878 0.66953 0.867993 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 351
Initial state: 0 0.681331 0.880116 0.280948 0.973526 0.593544 0.885244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165887 episodes
GETTING ACTION FROM:
action 2, numVisits=165833, meanQ=4.962620, numObservations: 3
action -1, numVisits=47, meanQ=3.957632, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.681331 0.880116 0.280948 0.973526 0.593544 0.885244 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12317, meanQ=4.741777, numObservations: 3
action 0, numVisits=48, meanQ=3.886592, numObservations: 1
action 2, numVisits=41, meanQ=3.633668, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 206288 episodes
GETTING ACTION FROM:
action 1, numVisits=218603, meanQ=6.070935, numObservations: 3
action 0, numVisits=50, meanQ=3.751126, numObservations: 1
action 2, numVisits=41, meanQ=3.633668, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.681331 0.880116 0.280948 0.973526 0.593544 0.885244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=3560, meanQ=6.746024, numObservations: 4
action 2, numVisits=1974, meanQ=4.276604, numObservations: 4
action -1, numVisits=59, meanQ=3.659109, numObservations: 1
action 1, numVisits=6, meanQ=1.331683, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 212112 episodes
GETTING ACTION FROM:
action 3, numVisits=215660, meanQ=6.138962, numObservations: 4
action 2, numVisits=1974, meanQ=4.276604, numObservations: 4
action -1, numVisits=71, meanQ=2.702640, numObservations: 1
action 1, numVisits=6, meanQ=1.331683, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.681331 0.880116 0.280948 0.973526 0.593544 0.885244 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 352
Initial state: 0 0.669085 0.674246 0.590787 0.842854 0.578661 0.889954 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165640 episodes
GETTING ACTION FROM:
action 1, numVisits=165584, meanQ=4.930444, numObservations: 5
action -1, numVisits=27, meanQ=3.547258, numObservations: 1
action 3, numVisits=21, meanQ=2.143829, numObservations: 3
action 2, numVisits=6, meanQ=0.166667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.669085 0.674246 0.590787 0.842854 0.578661 0.889954 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8372, meanQ=7.754791, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 33681 episodes
GETTING ACTION FROM:
action 2, numVisits=36830, meanQ=6.442468, numObservations: 5
action 0, numVisits=5223, meanQ=0.158173, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=2, meanQ=-198.128660, numObservations: 1
action: 2
Next state: 1 0.669085 0.674246 0.590787 0.842854 0.578661 0.889954 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 353
Initial state: 0 0.0441286 0.356349 0.603054 0.867374 0.506364 0.894254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165746 episodes
GETTING ACTION FROM:
action 2, numVisits=165721, meanQ=4.925375, numObservations: 5
action -1, numVisits=21, meanQ=3.422067, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.0441286 0.356349 0.603054 0.867374 0.506364 0.894254 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=10105, meanQ=4.706633, numObservations: 5
action -1, numVisits=2176, meanQ=2.816062, numObservations: 1
action 0, numVisits=128, meanQ=2.440390, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 208616 episodes
GETTING ACTION FROM:
action 1, numVisits=208584, meanQ=6.011301, numObservations: 4
action 3, numVisits=10105, meanQ=4.706633, numObservations: 5
action 2, numVisits=34, meanQ=4.174121, numObservations: 4
action -1, numVisits=2176, meanQ=2.816062, numObservations: 1
action 0, numVisits=128, meanQ=2.440390, numObservations: 1
action: 1
Next state: 0 0.0441286 0.356349 0.603054 0.867374 0.506364 0.894254 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=3294, meanQ=8.300636, numObservations: 4
action 2, numVisits=6, meanQ=2.333350, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 22303 episodes
GETTING ACTION FROM:
action 3, numVisits=4843, meanQ=7.487326, numObservations: 4
action 2, numVisits=6, meanQ=2.333350, numObservations: 2
action 0, numVisits=14046, meanQ=-1.686635, numObservations: 1
action -1, numVisits=6710, meanQ=-1.717463, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0441286 0.356349 0.603054 0.867374 0.506364 0.894254 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 354
Initial state: 0 0.573941 0.850696 0.421164 0.900906 0.529671 0.838499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167860 episodes
GETTING ACTION FROM:
action 3, numVisits=167798, meanQ=5.005402, numObservations: 5
action 0, numVisits=36, meanQ=3.841265, numObservations: 1
action -1, numVisits=23, meanQ=3.539815, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.573941 0.850696 0.421164 0.900906 0.529671 0.838499 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=12460, meanQ=5.576898, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 188288 episodes
GETTING ACTION FROM:
action 3, numVisits=200741, meanQ=5.012500, numObservations: 5
action 0, numVisits=7, meanQ=1.960000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.573941 0.850696 0.421164 0.900906 0.529671 0.838499 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 355
Initial state: 0 0.635973 0.893646 0.830649 0.0494688 0.662517 0.868142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167757 episodes
GETTING ACTION FROM:
action 1, numVisits=167672, meanQ=5.028283, numObservations: 4
action -1, numVisits=51, meanQ=4.070996, numObservations: 1
action 3, numVisits=30, meanQ=2.929673, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.635973 0.893646 0.830649 0.0494688 0.662517 0.868142 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 356
Initial state: 0 0.524499 0.815573 0.377167 0.302543 0.585851 0.844146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167311 episodes
GETTING ACTION FROM:
action 1, numVisits=167305, meanQ=4.911941, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.524499 0.815573 0.377167 0.302543 0.585851 0.844146 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 357
Initial state: 0 0.535205 0.851128 0.612915 0.853028 0.463872 0.942547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166848 episodes
GETTING ACTION FROM:
action 1, numVisits=166779, meanQ=4.984571, numObservations: 5
action -1, numVisits=65, meanQ=4.138139, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.535205 0.851128 0.612915 0.853028 0.463872 0.942547 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 358
Initial state: 0 0.598411 0.89343 0.974317 0.17595 0.64217 0.856421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166550 episodes
GETTING ACTION FROM:
action 3, numVisits=166236, meanQ=4.924462, numObservations: 5
action -1, numVisits=109, meanQ=4.248101, numObservations: 1
action 1, numVisits=141, meanQ=4.235613, numObservations: 5
action 2, numVisits=62, meanQ=3.781777, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.598411 0.89343 0.974317 0.17595 0.64217 0.856421 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8391, meanQ=7.797105, numObservations: 4
action 1, numVisits=10, meanQ=5.799000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 20940 episodes
GETTING ACTION FROM:
action 2, numVisits=24206, meanQ=6.351887, numObservations: 4
action 1, numVisits=15, meanQ=2.318351, numObservations: 3
action -1, numVisits=5066, meanQ=0.189684, numObservations: 1
action 0, numVisits=56, meanQ=-0.661276, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.598411 0.89343 0.974317 0.17595 0.64217 0.856421 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 359
Initial state: 0 0.621523 0.810732 0.265813 0.447082 0.570297 0.811822 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164658 episodes
GETTING ACTION FROM:
action 1, numVisits=160407, meanQ=4.990905, numObservations: 5
action 0, numVisits=4234, meanQ=2.998967, numObservations: 1
action 2, numVisits=14, meanQ=1.365743, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.621523 0.810732 0.265813 0.447082 0.570297 0.811822 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 360
Initial state: 0 0.648136 0.841377 0.570708 0.1475 0.65357 0.87333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158711 episodes
GETTING ACTION FROM:
action 3, numVisits=158701, meanQ=4.869437, numObservations: 4
action 1, numVisits=5, meanQ=1.622000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.648136 0.841377 0.570708 0.1475 0.65357 0.87333 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 361
Initial state: 0 0.689367 0.882501 0.735436 0.0125061 0.694415 0.820873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167747 episodes
GETTING ACTION FROM:
action 3, numVisits=167653, meanQ=5.056017, numObservations: 4
action -1, numVisits=40, meanQ=3.954335, numObservations: 1
action 0, numVisits=25, meanQ=3.559286, numObservations: 1
action 2, numVisits=28, meanQ=3.215007, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.689367 0.882501 0.735436 0.0125061 0.694415 0.820873 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 362
Initial state: 0 0.664644 0.802243 0.00231074 0.958411 0.587549 0.895998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167282 episodes
GETTING ACTION FROM:
action 2, numVisits=167231, meanQ=4.935721, numObservations: 4
action 3, numVisits=46, meanQ=3.621963, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.664644 0.802243 0.00231074 0.958411 0.587549 0.895998 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1554, meanQ=4.424110, numObservations: 5
action 2, numVisits=16, meanQ=2.625637, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 42087 episodes
GETTING ACTION FROM:
action 3, numVisits=19325, meanQ=5.934585, numObservations: 4
action 1, numVisits=24313, meanQ=5.677098, numObservations: 5
action 2, numVisits=16, meanQ=2.625637, numObservations: 2
action 0, numVisits=4, meanQ=-98.555064, numObservations: 1
action -1, numVisits=2, meanQ=-198.595494, numObservations: 1
action: 3
Next state: 1 0.664644 0.802243 0.00231074 0.958411 0.587549 0.895998 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 363
Initial state: 0 0.505612 0.874808 0.0566098 0.855649 0.616936 0.831111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95897 episodes
GETTING ACTION FROM:
action -1, numVisits=95892, meanQ=2.833915, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.505612 0.874808 0.0566098 0.855649 0.616936 0.831111 w: 1
Observation: 0 0.543022 0 0.141231 0 0.60398 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=95858, meanQ=4.910153, numObservations: 3
action -1, numVisits=21, meanQ=3.361146, numObservations: 1
action 3, numVisits=9, meanQ=2.332244, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 156251 episodes
GETTING ACTION FROM:
action 2, numVisits=252108, meanQ=4.795144, numObservations: 3
action -1, numVisits=22, meanQ=3.251642, numObservations: 1
action 3, numVisits=9, meanQ=2.332244, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.505612 0.874808 0.0566098 0.855649 0.616936 0.831111 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=29506, meanQ=8.333102, numObservations: 4
action 1, numVisits=14360, meanQ=8.312390, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 28165 episodes
GETTING ACTION FROM:
action 3, numVisits=42290, meanQ=7.640213, numObservations: 4
action 1, numVisits=25703, meanQ=7.253814, numObservations: 5
action 2, numVisits=7, meanQ=3.427157, numObservations: 3
action -1, numVisits=3995, meanQ=0.393347, numObservations: 1
action 0, numVisits=39, meanQ=-0.603846, numObservations: 1
action: 3
Next state: 1 0.505612 0.874808 0.0566098 0.855649 0.616936 0.831111 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 364
Initial state: 0 0.519348 0.878704 0.476145 0.923913 0.619147 0.843344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166066 episodes
GETTING ACTION FROM:
action 3, numVisits=165885, meanQ=4.987804, numObservations: 4
action 0, numVisits=91, meanQ=4.271298, numObservations: 1
action -1, numVisits=47, meanQ=3.951212, numObservations: 1
action 2, numVisits=42, meanQ=3.396193, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.519348 0.878704 0.476145 0.923913 0.619147 0.843344 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 365
Initial state: 0 0.264684 0.334768 0.621441 0.84065 0.506238 0.835357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167202 episodes
GETTING ACTION FROM:
action 2, numVisits=167196, meanQ=4.951495, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.264684 0.334768 0.621441 0.84065 0.506238 0.835357 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4289, meanQ=7.755158, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 36728 episodes
GETTING ACTION FROM:
action 1, numVisits=29977, meanQ=6.235775, numObservations: 5
action 3, numVisits=7796, meanQ=5.304676, numObservations: 3
action -1, numVisits=3242, meanQ=-0.406893, numObservations: 1
action 0, numVisits=6, meanQ=-4.088543, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.264684 0.334768 0.621441 0.84065 0.506238 0.835357 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 366
Initial state: 0 0.282181 0.185695 0.55827 0.856403 0.587616 0.85949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167971 episodes
GETTING ACTION FROM:
action 2, numVisits=167935, meanQ=5.028978, numObservations: 4
action -1, numVisits=21, meanQ=3.440372, numObservations: 1
action 3, numVisits=12, meanQ=1.833333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.282181 0.185695 0.55827 0.856403 0.587616 0.85949 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 367
Initial state: 0 0.557814 0.824382 0.676754 0.876737 0.276096 0.316228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160111 episodes
GETTING ACTION FROM:
action 1, numVisits=160064, meanQ=4.838647, numObservations: 5
action 0, numVisits=24, meanQ=3.420114, numObservations: 1
action 2, numVisits=20, meanQ=2.776500, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.557814 0.824382 0.676754 0.876737 0.276096 0.316228 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 368
Initial state: 0 0.633965 0.800237 0.20759 0.213379 0.644231 0.818109 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159113 episodes
GETTING ACTION FROM:
action 2, numVisits=159106, meanQ=4.861557, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.633965 0.800237 0.20759 0.213379 0.644231 0.818109 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7740, meanQ=7.838581, numObservations: 4
action 1, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 19041 episodes
GETTING ACTION FROM:
action 3, numVisits=9949, meanQ=7.427475, numObservations: 4
action -1, numVisits=16824, meanQ=0.073975, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=8, meanQ=-3.237500, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.633965 0.800237 0.20759 0.213379 0.644231 0.818109 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 369
Initial state: 0 0.363253 0.568857 0.640232 0.835486 0.681591 0.883385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167650 episodes
GETTING ACTION FROM:
action 2, numVisits=167643, meanQ=4.993868, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.363253 0.568857 0.640232 0.835486 0.681591 0.883385 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 370
Initial state: 0 0.393019 0.249228 0.592935 0.896905 0.505157 0.849681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168220 episodes
GETTING ACTION FROM:
action 3, numVisits=167225, meanQ=5.184649, numObservations: 5
action -1, numVisits=990, meanQ=2.613568, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.393019 0.249228 0.592935 0.896905 0.505157 0.849681 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 371
Initial state: 0 0.579745 0.0896154 0.506368 0.810113 0.512357 0.826913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167621 episodes
GETTING ACTION FROM:
action 3, numVisits=167615, meanQ=4.978255, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.579745 0.0896154 0.506368 0.810113 0.512357 0.826913 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 372
Initial state: 0 0.332425 0.911094 0.599334 0.853242 0.596446 0.888489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168686 episodes
GETTING ACTION FROM:
action 1, numVisits=168660, meanQ=5.021787, numObservations: 4
action 0, numVisits=20, meanQ=3.418718, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.332425 0.911094 0.599334 0.853242 0.596446 0.888489 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12321, meanQ=5.552500, numObservations: 4
action 3, numVisits=13, meanQ=3.446154, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 185491 episodes
GETTING ACTION FROM:
action 1, numVisits=197796, meanQ=4.874637, numObservations: 4
action 3, numVisits=25, meanQ=3.352804, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action: 1
Next state: 1 0.332425 0.911094 0.599334 0.853242 0.596446 0.888489 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 373
Initial state: 0 0.719253 0.728768 0.532207 0.896674 0.619351 0.805099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158767 episodes
GETTING ACTION FROM:
action 1, numVisits=158748, meanQ=4.842940, numObservations: 5
action 3, numVisits=14, meanQ=2.856436, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.719253 0.728768 0.532207 0.896674 0.619351 0.805099 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 374
Initial state: 0 0.55458 0.879238 0.563975 0.838295 0.319675 0.764296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168525 episodes
GETTING ACTION FROM:
action 3, numVisits=168472, meanQ=5.022624, numObservations: 5
action 0, numVisits=44, meanQ=3.940034, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=3, meanQ=0.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.55458 0.879238 0.563975 0.838295 0.319675 0.764296 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23749, meanQ=8.414562, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 27532 episodes
GETTING ACTION FROM:
action 2, numVisits=23790, meanQ=8.408454, numObservations: 4
action -1, numVisits=25720, meanQ=0.273959, numObservations: 1
action 0, numVisits=1772, meanQ=0.157099, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.55458 0.879238 0.563975 0.838295 0.319675 0.764296 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 375
Initial state: 0 0.604562 0.831378 0.733105 0.602222 0.589623 0.805395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159596 episodes
GETTING ACTION FROM:
action 1, numVisits=159570, meanQ=4.873952, numObservations: 5
action 0, numVisits=14, meanQ=3.011722, numObservations: 1
action 3, numVisits=9, meanQ=0.998889, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.604562 0.831378 0.733105 0.602222 0.589623 0.805395 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 376
Initial state: 0 0.659924 0.84123 0.868661 0.574941 0.515364 0.833866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168017 episodes
GETTING ACTION FROM:
action 2, numVisits=167846, meanQ=4.997335, numObservations: 3
action 0, numVisits=70, meanQ=4.175472, numObservations: 1
action -1, numVisits=42, meanQ=3.941932, numObservations: 1
action 1, numVisits=57, meanQ=3.863165, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 0 0.659924 0.84123 0.868661 0.574941 0.515364 0.833866 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12428, meanQ=5.574461, numObservations: 4
action 1, numVisits=59, meanQ=3.150512, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 33086 episodes
GETTING ACTION FROM:
action 3, numVisits=7579, meanQ=6.169956, numObservations: 5
action 2, numVisits=12428, meanQ=5.574461, numObservations: 4
action 1, numVisits=59, meanQ=3.150512, numObservations: 5
action 0, numVisits=25501, meanQ=0.371403, numObservations: 1
action -1, numVisits=9, meanQ=-1.890000, numObservations: 1
action: 3
Next state: 1 0.659924 0.84123 0.868661 0.574941 0.515364 0.833866 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 377
Initial state: 0 0.296683 0.380642 0.69107 0.807701 0.688149 0.897974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165496 episodes
GETTING ACTION FROM:
action 3, numVisits=165366, meanQ=5.023558, numObservations: 4
action 0, numVisits=102, meanQ=4.344224, numObservations: 1
action -1, numVisits=25, meanQ=3.608404, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.296683 0.380642 0.69107 0.807701 0.688149 0.897974 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 378
Initial state: 0 0.636378 0.808762 0.627813 0.819702 0.0364618 0.273584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166910 episodes
GETTING ACTION FROM:
action 3, numVisits=166881, meanQ=5.028417, numObservations: 4
action -1, numVisits=25, meanQ=3.637980, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.636378 0.808762 0.627813 0.819702 0.0364618 0.273584 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27288, meanQ=8.324375, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46849 episodes
GETTING ACTION FROM:
action 1, numVisits=41409, meanQ=7.491124, numObservations: 3
action 3, numVisits=31, meanQ=6.225487, numObservations: 5
action 2, numVisits=26186, meanQ=6.023571, numObservations: 4
action 0, numVisits=6511, meanQ=0.183898, numObservations: 2
action -1, numVisits=5, meanQ=-77.660681, numObservations: 1
action: 1
Next state: 1 0.636378 0.808762 0.627813 0.819702 0.0364618 0.273584 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 379
Initial state: 0 0.670782 0.836596 0.548788 0.803989 0.0117186 0.940108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167946 episodes
GETTING ACTION FROM:
action 1, numVisits=167901, meanQ=5.149261, numObservations: 4
action -1, numVisits=41, meanQ=4.069488, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.670782 0.836596 0.548788 0.803989 0.0117186 0.940108 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 380
Initial state: 0 0.683065 0.805531 0.587316 0.807571 0.0474082 0.99563 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167646 episodes
GETTING ACTION FROM:
action 3, numVisits=167634, meanQ=5.025798, numObservations: 3
action 1, numVisits=7, meanQ=1.428571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.683065 0.805531 0.587316 0.807571 0.0474082 0.99563 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 381
Initial state: 0 0.660076 0.882585 0.327352 0.613949 0.673676 0.857213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167050 episodes
GETTING ACTION FROM:
action 3, numVisits=167032, meanQ=4.995794, numObservations: 4
action 2, numVisits=9, meanQ=1.886667, numObservations: 5
action 1, numVisits=5, meanQ=-0.002000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.660076 0.882585 0.327352 0.613949 0.673676 0.857213 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 382
Initial state: 0 0.528086 0.832148 0.438268 0.92663 0.526515 0.865448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160169 episodes
GETTING ACTION FROM:
action 1, numVisits=159200, meanQ=4.886754, numObservations: 4
action 3, numVisits=842, meanQ=4.535210, numObservations: 4
action 0, numVisits=118, meanQ=4.254380, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.528086 0.832148 0.438268 0.92663 0.526515 0.865448 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 383
Initial state: 0 0.558578 0.885531 0.981662 0.173374 0.548136 0.835435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167873 episodes
GETTING ACTION FROM:
action 3, numVisits=167853, meanQ=5.025841, numObservations: 4
action 2, numVisits=8, meanQ=0.625012, numObservations: 3
action 1, numVisits=8, meanQ=-0.125000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.558578 0.885531 0.981662 0.173374 0.548136 0.835435 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 384
Initial state: 0 0.655005 0.840032 0.440082 0.566875 0.589925 0.862864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167713 episodes
GETTING ACTION FROM:
action 3, numVisits=167667, meanQ=4.986925, numObservations: 5
action -1, numVisits=41, meanQ=3.885471, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.655005 0.840032 0.440082 0.566875 0.589925 0.862864 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 385
Initial state: 0 0.675844 0.873518 0.140185 0.543624 0.501954 0.878292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98524 episodes
GETTING ACTION FROM:
action -1, numVisits=98514, meanQ=2.904585, numObservations: 1
action 3, numVisits=6, meanQ=-0.481667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.675844 0.873518 0.140185 0.543624 0.501954 0.878292 w: 1
Observation: 0 0.715601 0 0.234437 0 0.533021 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=98505, meanQ=4.957291, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 168045 episodes
GETTING ACTION FROM:
action 2, numVisits=266545, meanQ=4.829009, numObservations: 5
action 1, numVisits=8, meanQ=1.476250, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.675844 0.873518 0.140185 0.543624 0.501954 0.878292 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=36912, meanQ=8.376399, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 28863 episodes
GETTING ACTION FROM:
action 3, numVisits=36935, meanQ=8.376662, numObservations: 5
action 1, numVisits=28831, meanQ=5.972950, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=11, meanQ=-35.765490, numObservations: 1
action 0, numVisits=2, meanQ=-196.771516, numObservations: 1
action: 3
Next state: 1 0.675844 0.873518 0.140185 0.543624 0.501954 0.878292 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 386
Initial state: 0 0.602207 0.833192 0.102803 0.120977 0.612943 0.818175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168304 episodes
GETTING ACTION FROM:
action 1, numVisits=168236, meanQ=5.015264, numObservations: 3
action 0, numVisits=29, meanQ=3.674499, numObservations: 1
action 3, numVisits=36, meanQ=2.186400, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.602207 0.833192 0.102803 0.120977 0.612943 0.818175 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 387
Initial state: 0 0.653596 0.864278 0.633448 0.809455 0.958079 0.431569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166836 episodes
GETTING ACTION FROM:
action 2, numVisits=166827, meanQ=4.953359, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.653596 0.864278 0.633448 0.809455 0.958079 0.431569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 388
Initial state: 0 0.515966 0.877864 0.625034 0.870847 0.301551 0.634799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167526 episodes
GETTING ACTION FROM:
action 1, numVisits=167519, meanQ=5.001364, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.515966 0.877864 0.625034 0.870847 0.301551 0.634799 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 389
Initial state: 0 0.647559 0.894826 0.910828 0.740259 0.607468 0.809289 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163882 episodes
GETTING ACTION FROM:
action 3, numVisits=158107, meanQ=5.025233, numObservations: 5
action -1, numVisits=5769, meanQ=3.084610, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.647559 0.894826 0.910828 0.740259 0.607468 0.809289 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11517, meanQ=5.550347, numObservations: 4
action 2, numVisits=42, meanQ=4.424048, numObservations: 4
action 1, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 201965 episodes
GETTING ACTION FROM:
action 2, numVisits=140389, meanQ=6.032411, numObservations: 5
action 3, numVisits=73125, meanQ=5.185286, numObservations: 4
action 1, numVisits=13, meanQ=3.146154, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 2 0.647559 0.894826 0.910828 0.740259 0.607468 0.809289 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 390
Initial state: 0 0.539412 0.801163 0.884591 0.708675 0.64381 0.841375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168052 episodes
GETTING ACTION FROM:
action 3, numVisits=167974, meanQ=4.948999, numObservations: 3
action -1, numVisits=72, meanQ=4.125533, numObservations: 1
action 2, numVisits=3, meanQ=0.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.539412 0.801163 0.884591 0.708675 0.64381 0.841375 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 391
Initial state: 0 0.618044 0.885344 0.510189 0.83398 0.665883 0.0700522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167407 episodes
GETTING ACTION FROM:
action 2, numVisits=167386, meanQ=4.945508, numObservations: 4
action -1, numVisits=13, meanQ=2.989890, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.618044 0.885344 0.510189 0.83398 0.665883 0.0700522 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 392
Initial state: 0 0.511317 0.810221 0.635452 0.818763 0.555067 0.718701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159793 episodes
GETTING ACTION FROM:
action 1, numVisits=159702, meanQ=4.873285, numObservations: 4
action -1, numVisits=87, meanQ=4.124428, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.511317 0.810221 0.635452 0.818763 0.555067 0.718701 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 393
Initial state: 0 0.509782 0.810568 0.542002 0.867851 0.440979 0.675017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166649 episodes
GETTING ACTION FROM:
action 1, numVisits=166597, meanQ=4.955354, numObservations: 5
action -1, numVisits=37, meanQ=3.802858, numObservations: 1
action 2, numVisits=12, meanQ=2.415842, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.509782 0.810568 0.542002 0.867851 0.440979 0.675017 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 394
Initial state: 0 0.990562 0.877101 0.508883 0.899433 0.604264 0.841049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167221 episodes
GETTING ACTION FROM:
action 3, numVisits=167167, meanQ=4.960535, numObservations: 4
action -1, numVisits=49, meanQ=3.958522, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.990562 0.877101 0.508883 0.899433 0.604264 0.841049 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 395
Initial state: 0 0.63104 0.815168 0.431985 0.305271 0.612247 0.87304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167603 episodes
GETTING ACTION FROM:
action 2, numVisits=164166, meanQ=4.977976, numObservations: 4
action 1, numVisits=3407, meanQ=4.736347, numObservations: 5
action -1, numVisits=14, meanQ=3.022264, numObservations: 1
action 3, numVisits=14, meanQ=2.569293, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.63104 0.815168 0.431985 0.305271 0.612247 0.87304 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=18599, meanQ=8.530040, numObservations: 3
action 1, numVisits=115, meanQ=7.956266, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 23538 episodes
GETTING ACTION FROM:
action 3, numVisits=31936, meanQ=7.522217, numObservations: 4
action 1, numVisits=521, meanQ=6.319320, numObservations: 5
action 2, numVisits=8, meanQ=3.248763, numObservations: 2
action 0, numVisits=5497, meanQ=0.159198, numObservations: 1
action -1, numVisits=4293, meanQ=0.084004, numObservations: 1
action: 3
Next state: 1 0.63104 0.815168 0.431985 0.305271 0.612247 0.87304 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 396
Initial state: 0 0.523199 0.897363 0.669267 0.837284 0.206222 0.495559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97694 episodes
GETTING ACTION FROM:
action -1, numVisits=97678, meanQ=2.847716, numObservations: 1
action 2, numVisits=9, meanQ=0.111122, numObservations: 2
action 1, numVisits=4, meanQ=-2.500000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.523199 0.897363 0.669267 0.837284 0.206222 0.495559 w: 1
Observation: 0 0.61094 0 0.721948 0 0.176954 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=97669, meanQ=4.881621, numObservations: 5
action 3, numVisits=3, meanQ=-0.329967, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 163872 episodes
GETTING ACTION FROM:
action 1, numVisits=261532, meanQ=4.694292, numObservations: 5
action 2, numVisits=10, meanQ=1.700010, numObservations: 3
action 3, numVisits=3, meanQ=-0.329967, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.523199 0.897363 0.669267 0.837284 0.206222 0.495559 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 397
Initial state: 0 0.665723 0.848641 0.570497 0.875161 0.495277 0.623032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168392 episodes
GETTING ACTION FROM:
action 1, numVisits=168365, meanQ=5.022615, numObservations: 4
action -1, numVisits=16, meanQ=2.965036, numObservations: 1
action 3, numVisits=6, meanQ=1.166683, numObservations: 3
action 2, numVisits=3, meanQ=-2.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.665723 0.848641 0.570497 0.875161 0.495277 0.623032 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 398
Initial state: 0 0.0660457 0.670675 0.677722 0.805376 0.519638 0.838719 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 103827 episodes
GETTING ACTION FROM:
action 0, numVisits=103822, meanQ=5.567914, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0660457 0.670675 0.677722 0.805376 0.519638 0.838719 w: 1
Observation: 0 0 0.591379 0 0.798116 0 0.871056 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=25692, meanQ=8.400853, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 173255 episodes
GETTING ACTION FROM:
action 3, numVisits=198934, meanQ=5.766456, numObservations: 4
action -1, numVisits=13, meanQ=3.825864, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0660457 0.670675 0.677722 0.805376 0.519638 0.838719 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 399
Initial state: 0 0.820572 0.925023 0.502726 0.81015 0.614633 0.839885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167302 episodes
GETTING ACTION FROM:
action 1, numVisits=167296, meanQ=4.975135, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.820572 0.925023 0.502726 0.81015 0.614633 0.839885 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 400
Initial state: 0 0.611815 0.84577 0.554509 0.841155 0.777053 0.674929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161057 episodes
GETTING ACTION FROM:
action 2, numVisits=150000, meanQ=5.016600, numObservations: 5
action -1, numVisits=8732, meanQ=3.136618, numObservations: 1
action 0, numVisits=2323, meanQ=3.075292, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.611815 0.84577 0.554509 0.841155 0.777053 0.674929 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 401
Initial state: 0 0.650654 0.872559 0.868337 0.632364 0.520209 0.847176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165028 episodes
GETTING ACTION FROM:
action 2, numVisits=164990, meanQ=4.942720, numObservations: 4
action 0, numVisits=25, meanQ=3.493830, numObservations: 1
action -1, numVisits=10, meanQ=2.752505, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.650654 0.872559 0.868337 0.632364 0.520209 0.847176 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 402
Initial state: 0 0.571071 0.811977 0.58008 0.873194 0.842726 0.147679 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165212 episodes
GETTING ACTION FROM:
action 3, numVisits=165184, meanQ=4.946719, numObservations: 4
action -1, numVisits=23, meanQ=3.489838, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.571071 0.811977 0.58008 0.873194 0.842726 0.147679 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 403
Initial state: 0 0.545003 0.863071 0.642946 0.807599 0.526918 0.446238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167496 episodes
GETTING ACTION FROM:
action 2, numVisits=167488, meanQ=4.969748, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.545003 0.863071 0.642946 0.807599 0.526918 0.446238 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 404
Initial state: 0 0.765465 0.674254 0.62272 0.812125 0.695346 0.807975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165883 episodes
GETTING ACTION FROM:
action 2, numVisits=164118, meanQ=4.957281, numObservations: 5
action -1, numVisits=1756, meanQ=2.735783, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.765465 0.674254 0.62272 0.812125 0.695346 0.807975 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 405
Initial state: 0 0.686304 0.844858 0.520583 0.818427 0.449196 0.68446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167581 episodes
GETTING ACTION FROM:
action 3, numVisits=167510, meanQ=4.969583, numObservations: 3
action -1, numVisits=28, meanQ=3.657695, numObservations: 1
action 2, numVisits=35, meanQ=3.412574, numObservations: 3
action 1, numVisits=6, meanQ=1.498333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.686304 0.844858 0.520583 0.818427 0.449196 0.68446 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27496, meanQ=8.297621, numObservations: 4
action 2, numVisits=50, meanQ=7.310600, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 45285 episodes
GETTING ACTION FROM:
action 1, numVisits=60640, meanQ=7.138063, numObservations: 4
action 2, numVisits=269, meanQ=6.215576, numObservations: 4
action -1, numVisits=11912, meanQ=0.121369, numObservations: 1
action 0, numVisits=12, meanQ=-2.543160, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.686304 0.844858 0.520583 0.818427 0.449196 0.68446 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 406
Initial state: 0 0.62317 0.810191 0.0881367 0.682021 0.53294 0.845274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167219 episodes
GETTING ACTION FROM:
action 2, numVisits=166844, meanQ=5.036698, numObservations: 5
action -1, numVisits=285, meanQ=3.032926, numObservations: 1
action 0, numVisits=86, meanQ=2.787597, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 0 0.62317 0.810191 0.0881367 0.682021 0.53294 0.845274 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=19077, meanQ=8.514877, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 36817 episodes
GETTING ACTION FROM:
action 3, numVisits=51064, meanQ=6.970537, numObservations: 4
action -1, numVisits=4820, meanQ=0.347861, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=11, meanQ=-2.000900, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.62317 0.810191 0.0881367 0.682021 0.53294 0.845274 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=177, meanQ=8.177025, numObservations: 3
action -1, numVisits=93, meanQ=6.824839, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 33802 episodes
GETTING ACTION FROM:
action 1, numVisits=21230, meanQ=6.284068, numObservations: 4
action -1, numVisits=10923, meanQ=-1.580634, numObservations: 1
action 0, numVisits=1920, meanQ=-1.670521, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.62317 0.810191 0.0881367 0.682021 0.53294 0.845274 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 407
Initial state: 0 0.102676 0.111025 0.587052 0.889952 0.618029 0.877871 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167882 episodes
GETTING ACTION FROM:
action 1, numVisits=167875, meanQ=5.006138, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.102676 0.111025 0.587052 0.889952 0.618029 0.877871 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=27643, meanQ=8.322381, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 53680 episodes
GETTING ACTION FROM:
action 2, numVisits=78669, meanQ=7.013125, numObservations: 4
action 3, numVisits=62, meanQ=4.869355, numObservations: 4
action -1, numVisits=2589, meanQ=-0.201184, numObservations: 1
action 0, numVisits=6, meanQ=-4.203962, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.102676 0.111025 0.587052 0.889952 0.618029 0.877871 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 408
Initial state: 0 0.670601 0.863807 0.182415 0.168042 0.544957 0.879498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168079 episodes
GETTING ACTION FROM:
action 2, numVisits=167928, meanQ=5.016237, numObservations: 5
action -1, numVisits=121, meanQ=4.397989, numObservations: 1
action 3, numVisits=27, meanQ=3.326296, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.670601 0.863807 0.182415 0.168042 0.544957 0.879498 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=19391, meanQ=8.541006, numObservations: 3
action 1, numVisits=4, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 44588 episodes
GETTING ACTION FROM:
action 3, numVisits=54575, meanQ=6.783750, numObservations: 3
action 1, numVisits=5909, meanQ=6.325838, numObservations: 3
action 2, numVisits=5, meanQ=2.598000, numObservations: 3
action -1, numVisits=1564, meanQ=-0.232997, numObservations: 1
action 0, numVisits=1933, meanQ=-0.272765, numObservations: 1
action: 3
Next state: 1 0.670601 0.863807 0.182415 0.168042 0.544957 0.879498 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 409
Initial state: 0 0.630634 0.814948 0.452908 0.655218 0.6769 0.882527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168033 episodes
GETTING ACTION FROM:
action 3, numVisits=167856, meanQ=5.022991, numObservations: 5
action 0, numVisits=173, meanQ=4.492361, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.630634 0.814948 0.452908 0.655218 0.6769 0.882527 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 410
Initial state: 0 0.116424 0.601777 0.567553 0.890561 0.611012 0.873054 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159350 episodes
GETTING ACTION FROM:
action 1, numVisits=159313, meanQ=4.816536, numObservations: 4
action -1, numVisits=32, meanQ=3.544710, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.116424 0.601777 0.567553 0.890561 0.611012 0.873054 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 411
Initial state: 0 0.559231 0.876596 0.761445 0.947321 0.650887 0.870433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166980 episodes
GETTING ACTION FROM:
action 3, numVisits=166951, meanQ=4.934422, numObservations: 4
action 0, numVisits=17, meanQ=3.226028, numObservations: 1
action 1, numVisits=9, meanQ=0.998889, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.559231 0.876596 0.761445 0.947321 0.650887 0.870433 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 412
Initial state: 0 0.536513 0.822085 0.558364 0.802454 0.417962 0.954182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168083 episodes
GETTING ACTION FROM:
action 1, numVisits=168077, meanQ=4.930444, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.536513 0.822085 0.558364 0.802454 0.417962 0.954182 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 413
Initial state: 0 0.891123 0.297255 0.577574 0.839533 0.539889 0.827683 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98785 episodes
GETTING ACTION FROM:
action -1, numVisits=98764, meanQ=2.923469, numObservations: 1
action 2, numVisits=13, meanQ=0.998469, numObservations: 4
action 3, numVisits=5, meanQ=-0.597980, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.891123 0.297255 0.577574 0.839533 0.539889 0.827683 w: 1
Observation: 0 0.938143 0 0.670674 0 0.575276 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=98727, meanQ=4.968071, numObservations: 5
action 0, numVisits=31, meanQ=3.755645, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 169031 episodes
GETTING ACTION FROM:
action 1, numVisits=267757, meanQ=5.024280, numObservations: 5
action 0, numVisits=32, meanQ=3.738982, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.891123 0.297255 0.577574 0.839533 0.539889 0.827683 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 414
Initial state: 0 0.674358 0.865012 0.684796 0.870822 0.973186 0.704735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167598 episodes
GETTING ACTION FROM:
action 1, numVisits=167592, meanQ=4.955323, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.674358 0.865012 0.684796 0.870822 0.973186 0.704735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 415
Initial state: 0 0.663686 0.844373 0.664438 0.858865 0.927433 0.695637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166541 episodes
GETTING ACTION FROM:
action 2, numVisits=166535, meanQ=4.941358, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.663686 0.844373 0.664438 0.858865 0.927433 0.695637 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 416
Initial state: 0 0.548138 0.801155 0.66709 0.833745 0.963045 0.135445 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98937 episodes
GETTING ACTION FROM:
action -1, numVisits=98930, meanQ=2.933509, numObservations: 1
action 0, numVisits=4, meanQ=-2.502425, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.548138 0.801155 0.66709 0.833745 0.963045 0.135445 w: 1
Observation: 0 0.508888 0 0.589485 0 0.911937 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=98923, meanQ=5.016011, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 168940 episodes
GETTING ACTION FROM:
action 3, numVisits=267860, meanQ=5.119748, numObservations: 5
action -1, numVisits=3, meanQ=0.966700, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 2 0.548138 0.801155 0.66709 0.833745 0.963045 0.135445 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 417
Initial state: 0 0.668649 0.850124 0.62425 0.101411 0.691848 0.875099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167259 episodes
GETTING ACTION FROM:
action 2, numVisits=167253, meanQ=4.975688, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.668649 0.850124 0.62425 0.101411 0.691848 0.875099 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23202, meanQ=8.438619, numObservations: 3
action 1, numVisits=10, meanQ=5.000010, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 33634 episodes
GETTING ACTION FROM:
action 3, numVisits=50584, meanQ=7.221213, numObservations: 3
action 1, numVisits=692, meanQ=5.828562, numObservations: 5
action -1, numVisits=5568, meanQ=0.235679, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=4, meanQ=-4.111482, numObservations: 1
action: 3
Next state: 1 0.668649 0.850124 0.62425 0.101411 0.691848 0.875099 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 418
Initial state: 0 0.549841 0.819807 0.991686 0.197994 0.677392 0.874009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167701 episodes
GETTING ACTION FROM:
action 2, numVisits=167665, meanQ=5.163929, numObservations: 4
action -1, numVisits=32, meanQ=3.945492, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.549841 0.819807 0.991686 0.197994 0.677392 0.874009 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 419
Initial state: 0 0.709506 0.594349 0.640609 0.825598 0.663911 0.875205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 114143 episodes
GETTING ACTION FROM:
action 1, numVisits=38364, meanQ=4.987583, numObservations: 5
action 0, numVisits=61719, meanQ=2.876547, numObservations: 1
action -1, numVisits=14051, meanQ=2.846971, numObservations: 1
action 3, numVisits=6, meanQ=0.166667, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action: 1
Next state: 2 0.709506 0.594349 0.640609 0.825598 0.663911 0.875205 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 420
Initial state: 0 0.672731 0.842698 0.732572 0.181566 0.511198 0.812437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167932 episodes
GETTING ACTION FROM:
action 2, numVisits=167925, meanQ=4.935505, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.672731 0.842698 0.732572 0.181566 0.511198 0.812437 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 421
Initial state: 0 0.934236 0.943398 0.549499 0.856563 0.503518 0.840513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165856 episodes
GETTING ACTION FROM:
action 3, numVisits=165845, meanQ=4.984653, numObservations: 4
action 2, numVisits=6, meanQ=-1.329983, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.934236 0.943398 0.549499 0.856563 0.503518 0.840513 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 422
Initial state: 0 0.920842 0.90071 0.503149 0.830206 0.513086 0.836387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167079 episodes
GETTING ACTION FROM:
action 3, numVisits=167016, meanQ=5.012174, numObservations: 3
action 0, numVisits=56, meanQ=4.082716, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.920842 0.90071 0.503149 0.830206 0.513086 0.836387 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 423
Initial state: 0 0.53422 0.856883 0.234904 0.596994 0.527886 0.857826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167755 episodes
GETTING ACTION FROM:
action 1, numVisits=167736, meanQ=5.042076, numObservations: 3
action 3, numVisits=14, meanQ=2.772150, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.53422 0.856883 0.234904 0.596994 0.527886 0.857826 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12289, meanQ=5.617855, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 185406 episodes
GETTING ACTION FROM:
action 1, numVisits=197692, meanQ=4.927945, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.53422 0.856883 0.234904 0.596994 0.527886 0.857826 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 424
Initial state: 0 0.277026 0.753436 0.551669 0.884919 0.623878 0.889162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 104727 episodes
GETTING ACTION FROM:
action 0, numVisits=104716, meanQ=5.942054, numObservations: 3
action 1, numVisits=7, meanQ=0.285743, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.277026 0.753436 0.551669 0.884919 0.623878 0.889162 w: 1
Observation: 0 0 0.671687 0 0.887498 0 0.914 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=34609, meanQ=8.023924, numObservations: 4
action 2, numVisits=8, meanQ=4.998750, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 162924 episodes
GETTING ACTION FROM:
action 3, numVisits=197461, meanQ=5.541965, numObservations: 4
action 2, numVisits=52, meanQ=4.417508, numObservations: 4
action -1, numVisits=28, meanQ=4.173533, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.277026 0.753436 0.551669 0.884919 0.623878 0.889162 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 425
Initial state: 0 0.55843 0.861976 0.775643 0.405998 0.578362 0.852818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 151013 episodes
GETTING ACTION FROM:
action 2, numVisits=150965, meanQ=4.636192, numObservations: 4
action 0, numVisits=44, meanQ=3.587979, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.55843 0.861976 0.775643 0.405998 0.578362 0.852818 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 426
Initial state: 0 0.650796 0.881478 0.506952 0.84126 0.698744 0.476301 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159359 episodes
GETTING ACTION FROM:
action 2, numVisits=159307, meanQ=4.812850, numObservations: 3
action -1, numVisits=48, meanQ=3.797467, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.650796 0.881478 0.506952 0.84126 0.698744 0.476301 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 427
Initial state: 0 0.417358 0.347063 0.581412 0.862018 0.552266 0.840533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167932 episodes
GETTING ACTION FROM:
action 2, numVisits=167924, meanQ=4.994125, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 1
action: 2
Next state: 1 0.417358 0.347063 0.581412 0.862018 0.552266 0.840533 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 428
Initial state: 0 0.678094 0.836279 0.593388 0.802912 0.36665 0.711238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96043 episodes
GETTING ACTION FROM:
action 0, numVisits=96038, meanQ=2.814911, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.678094 0.836279 0.593388 0.802912 0.36665 0.711238 w: 1
Observation: 0 0 0.920556 0 0.883962 0 0.63771 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=95960, meanQ=4.857146, numObservations: 4
action -1, numVisits=54, meanQ=3.945799, numObservations: 1
action 0, numVisits=16, meanQ=3.172912, numObservations: 2
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 162267 episodes
GETTING ACTION FROM:
action 3, numVisits=258225, meanQ=4.902152, numObservations: 4
action -1, numVisits=54, meanQ=3.945799, numObservations: 1
action 0, numVisits=17, meanQ=3.088753, numObservations: 2
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 3
Next state: 0 0.678094 0.836279 0.593388 0.802912 0.36665 0.711238 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=41719, meanQ=8.336749, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 27310 episodes
GETTING ACTION FROM:
action 1, numVisits=64607, meanQ=7.597083, numObservations: 4
action 2, numVisits=46, meanQ=4.825870, numObservations: 4
action 0, numVisits=4367, meanQ=0.272894, numObservations: 1
action -1, numVisits=12, meanQ=-2.084150, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.678094 0.836279 0.593388 0.802912 0.36665 0.711238 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 429
Initial state: 0 0.641663 0.896299 0.504473 0.833705 0.411587 0.177173 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167709 episodes
GETTING ACTION FROM:
action 1, numVisits=167703, meanQ=4.964840, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.641663 0.896299 0.504473 0.833705 0.411587 0.177173 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 430
Initial state: 0 0.650771 0.827211 0.531698 0.837399 0.351064 0.294611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168144 episodes
GETTING ACTION FROM:
action 1, numVisits=167620, meanQ=5.008555, numObservations: 5
action 3, numVisits=518, meanQ=4.644637, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.650771 0.827211 0.531698 0.837399 0.351064 0.294611 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 431
Initial state: 0 0.102335 0.677165 0.570665 0.884513 0.516277 0.87238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163043 episodes
GETTING ACTION FROM:
action 2, numVisits=155599, meanQ=4.946369, numObservations: 5
action -1, numVisits=7440, meanQ=2.913247, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.102335 0.677165 0.570665 0.884513 0.516277 0.87238 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 432
Initial state: 0 0.52709 0.887661 0.85126 0.134854 0.500199 0.881141 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166277 episodes
GETTING ACTION FROM:
action 1, numVisits=166194, meanQ=4.962384, numObservations: 4
action -1, numVisits=34, meanQ=3.734497, numObservations: 1
action 2, numVisits=46, meanQ=3.695004, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.52709 0.887661 0.85126 0.134854 0.500199 0.881141 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 433
Initial state: 0 0.613504 0.855567 0.690838 0.846069 0.549513 0.117525 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166463 episodes
GETTING ACTION FROM:
action 3, numVisits=166390, meanQ=4.981657, numObservations: 4
action -1, numVisits=37, meanQ=3.833879, numObservations: 1
action 0, numVisits=27, meanQ=3.649715, numObservations: 1
action 2, numVisits=8, meanQ=2.375000, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.613504 0.855567 0.690838 0.846069 0.549513 0.117525 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 434
Initial state: 0 0.54382 0.809542 0.603709 0.809566 0.474326 0.439883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167722 episodes
GETTING ACTION FROM:
action 1, numVisits=167649, meanQ=5.033392, numObservations: 5
action 0, numVisits=67, meanQ=4.186768, numObservations: 1
action 3, numVisits=3, meanQ=0.000033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.54382 0.809542 0.603709 0.809566 0.474326 0.439883 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 435
Initial state: 0 0.60063 0.866292 0.722372 0.300828 0.648563 0.88264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167766 episodes
GETTING ACTION FROM:
action 1, numVisits=167310, meanQ=4.947388, numObservations: 5
action -1, numVisits=449, meanQ=3.019701, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.60063 0.866292 0.722372 0.300828 0.648563 0.88264 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 436
Initial state: 0 0.693449 0.859869 0.65037 0.809691 0.77546 0.68445 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 71538 episodes
GETTING ACTION FROM:
action 0, numVisits=71529, meanQ=3.833301, numObservations: 1
action 3, numVisits=5, meanQ=-0.002000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.693449 0.859869 0.65037 0.809691 0.77546 0.68445 w: 1
Observation: 0 0 0.845302 0 0.826624 0 0.767433 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=71505, meanQ=5.904614, numObservations: 3
action 1, numVisits=15, meanQ=1.264013, numObservations: 4
action 2, numVisits=5, meanQ=-0.622000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 102130 episodes
GETTING ACTION FROM:
action 0, numVisits=173635, meanQ=5.906573, numObservations: 3
action 1, numVisits=15, meanQ=1.264013, numObservations: 4
action 2, numVisits=5, meanQ=-0.622000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.693449 0.859869 0.65037 0.809691 0.77546 0.68445 w: 1
Observation: 0 0 0.909544 0 0.880087 0 0.718051 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=53384, meanQ=8.083076, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 168718 episodes
GETTING ACTION FROM:
action 1, numVisits=222099, meanQ=5.825059, numObservations: 4
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.693449 0.859869 0.65037 0.809691 0.77546 0.68445 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 437
Initial state: 0 0.623571 0.889098 0.636196 0.276744 0.506908 0.858373 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98981 episodes
GETTING ACTION FROM:
action 0, numVisits=98971, meanQ=3.272592, numObservations: 2
action 2, numVisits=6, meanQ=0.331667, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.623571 0.889098 0.636196 0.276744 0.506908 0.858373 w: 1
Observation: 0 0 0.832006 0 0.179636 0 0.808184 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=77955, meanQ=4.157185, numObservations: 4
action 0, numVisits=136, meanQ=3.601215, numObservations: 1
action -1, numVisits=48, meanQ=3.195638, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 169269 episodes
GETTING ACTION FROM:
action 2, numVisits=247182, meanQ=4.911145, numObservations: 4
action 0, numVisits=137, meanQ=3.596580, numObservations: 1
action -1, numVisits=48, meanQ=3.195638, numObservations: 1
action 3, numVisits=41, meanQ=3.108293, numObservations: 4
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 2 0.623571 0.889098 0.636196 0.276744 0.506908 0.858373 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 438
Initial state: 0 0.630769 0.804185 0.206114 0.934864 0.658415 0.894689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167292 episodes
GETTING ACTION FROM:
action 3, numVisits=167274, meanQ=4.943330, numObservations: 5
action 2, numVisits=13, meanQ=2.846162, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.630769 0.804185 0.206114 0.934864 0.658415 0.894689 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 439
Initial state: 0 0.547911 0.6052 0.570911 0.892693 0.690949 0.869369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168117 episodes
GETTING ACTION FROM:
action 3, numVisits=168088, meanQ=5.008983, numObservations: 3
action 0, numVisits=25, meanQ=3.563318, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.547911 0.6052 0.570911 0.892693 0.690949 0.869369 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 440
Initial state: 0 0.684727 0.815853 0.654227 0.880763 0.698763 0.677962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166220 episodes
GETTING ACTION FROM:
action 3, numVisits=163964, meanQ=5.011526, numObservations: 4
action -1, numVisits=2249, meanQ=3.291273, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.684727 0.815853 0.654227 0.880763 0.698763 0.677962 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 441
Initial state: 0 0.627614 0.879642 0.301167 0.0517457 0.526211 0.885227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168212 episodes
GETTING ACTION FROM:
action 3, numVisits=168021, meanQ=4.937209, numObservations: 5
action 2, numVisits=125, meanQ=4.328409, numObservations: 5
action 1, numVisits=35, meanQ=3.732300, numObservations: 4
action -1, numVisits=23, meanQ=3.488599, numObservations: 1
action 0, numVisits=8, meanQ=2.205025, numObservations: 2
action: 3
Next state: 1 0.627614 0.879642 0.301167 0.0517457 0.526211 0.885227 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 442
Initial state: 0 0.632217 0.832259 0.565567 0.87806 0.213754 0.0190408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165108 episodes
GETTING ACTION FROM:
action 2, numVisits=160383, meanQ=5.019445, numObservations: 4
action 0, numVisits=4716, meanQ=3.028922, numObservations: 1
action 1, numVisits=6, meanQ=0.166667, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.632217 0.832259 0.565567 0.87806 0.213754 0.0190408 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 443
Initial state: 0 0.603985 0.81152 0.638718 0.814867 0.232091 0.352819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 148146 episodes
GETTING ACTION FROM:
action 1, numVisits=119331, meanQ=4.999855, numObservations: 5
action -1, numVisits=28733, meanQ=2.838423, numObservations: 1
action 0, numVisits=67, meanQ=2.084267, numObservations: 1
action 2, numVisits=14, meanQ=0.905014, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.603985 0.81152 0.638718 0.814867 0.232091 0.352819 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 444
Initial state: 0 0.623803 0.871275 0.180961 0.816367 0.505523 0.814858 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169062 episodes
GETTING ACTION FROM:
action 2, numVisits=169055, meanQ=5.056716, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.623803 0.871275 0.180961 0.816367 0.505523 0.814858 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 445
Initial state: 0 0.129432 0.0896896 0.616625 0.892028 0.591686 0.835014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157506 episodes
GETTING ACTION FROM:
action 1, numVisits=156650, meanQ=4.770698, numObservations: 5
action 0, numVisits=851, meanQ=1.019175, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.129432 0.0896896 0.616625 0.892028 0.591686 0.835014 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=18643, meanQ=8.432493, numObservations: 3
action 2, numVisits=3167, meanQ=8.375809, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 39046 episodes
GETTING ACTION FROM:
action 3, numVisits=21152, meanQ=8.115590, numObservations: 3
action 2, numVisits=27344, meanQ=6.576221, numObservations: 4
action 1, numVisits=5, meanQ=5.780000, numObservations: 2
action -1, numVisits=12347, meanQ=0.040136, numObservations: 1
action 0, numVisits=11, meanQ=-2.182700, numObservations: 1
action: 3
Next state: 1 0.129432 0.0896896 0.616625 0.892028 0.591686 0.835014 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 446
Initial state: 0 0.665632 0.85089 0.523818 0.834458 0.339459 0.956432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98901 episodes
GETTING ACTION FROM:
action 0, numVisits=98894, meanQ=2.934722, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 0
Next state: 0 0.665632 0.85089 0.523818 0.834458 0.339459 0.956432 w: 1
Observation: 0 0 0.879945 0 0.868365 0 0.881136 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=98883, meanQ=5.009659, numObservations: 4
action 3, numVisits=5, meanQ=-0.597980, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 168876 episodes
GETTING ACTION FROM:
action 1, numVisits=267755, meanQ=4.907911, numObservations: 4
action 2, numVisits=5, meanQ=1.198020, numObservations: 2
action 3, numVisits=5, meanQ=-0.597980, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.665632 0.85089 0.523818 0.834458 0.339459 0.956432 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 447
Initial state: 0 0.663535 0.838075 0.698564 0.505673 0.688395 0.84926 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159904 episodes
GETTING ACTION FROM:
action 3, numVisits=159894, meanQ=4.866637, numObservations: 5
action 2, numVisits=4, meanQ=0.750000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.663535 0.838075 0.698564 0.505673 0.688395 0.84926 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 448
Initial state: 0 0.649124 0.812409 0.210181 0.619455 0.690105 0.812046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167541 episodes
GETTING ACTION FROM:
action 3, numVisits=167488, meanQ=4.993877, numObservations: 5
action 2, numVisits=31, meanQ=1.649368, numObservations: 3
action 1, numVisits=18, meanQ=1.600556, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.649124 0.812409 0.210181 0.619455 0.690105 0.812046 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 449
Initial state: 0 0.605999 0.865472 0.669271 0.854985 0.254836 0.119105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165897 episodes
GETTING ACTION FROM:
action 1, numVisits=165852, meanQ=4.940303, numObservations: 5
action -1, numVisits=38, meanQ=3.683482, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.605999 0.865472 0.669271 0.854985 0.254836 0.119105 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 450
Initial state: 0 0.696763 0.800385 0.50508 0.88143 0.700776 0.448317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167092 episodes
GETTING ACTION FROM:
action 2, numVisits=167052, meanQ=5.162911, numObservations: 4
action 0, numVisits=35, meanQ=3.832375, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.696763 0.800385 0.50508 0.88143 0.700776 0.448317 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 451
Initial state: 0 0.664466 0.822101 0.244691 0.118968 0.553294 0.858471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165669 episodes
GETTING ACTION FROM:
action 1, numVisits=165623, meanQ=4.965878, numObservations: 5
action -1, numVisits=28, meanQ=3.600997, numObservations: 1
action 2, numVisits=15, meanQ=2.268007, numObservations: 4
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.664466 0.822101 0.244691 0.118968 0.553294 0.858471 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12243, meanQ=5.450190, numObservations: 3
action 2, numVisits=8, meanQ=2.746263, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 188797 episodes
GETTING ACTION FROM:
action 2, numVisits=7009, meanQ=6.029865, numObservations: 4
action 1, numVisits=194037, meanQ=5.197765, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.664466 0.822101 0.244691 0.118968 0.553294 0.858471 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=101, meanQ=7.406143, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 148829 episodes
GETTING ACTION FROM:
action 3, numVisits=147681, meanQ=6.366424, numObservations: 5
action 1, numVisits=1227, meanQ=6.344181, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=19, meanQ=-21.627491, numObservations: 1
action 0, numVisits=7, meanQ=-55.469654, numObservations: 1
action: 3
Next state: 1 0.664466 0.822101 0.244691 0.118968 0.553294 0.858471 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 452
Initial state: 0 0.647929 0.823336 0.530495 0.896975 0.332542 0.449344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167238 episodes
GETTING ACTION FROM:
action 1, numVisits=167225, meanQ=4.959425, numObservations: 4
action 2, numVisits=7, meanQ=0.570014, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.647929 0.823336 0.530495 0.896975 0.332542 0.449344 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12274, meanQ=4.746219, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 206188 episodes
GETTING ACTION FROM:
action 2, numVisits=218460, meanQ=5.903046, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=3, meanQ=-3.033333, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.647929 0.823336 0.530495 0.896975 0.332542 0.449344 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 453
Initial state: 0 0.364427 0.305263 0.504943 0.861706 0.595988 0.828766 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162390 episodes
GETTING ACTION FROM:
action 2, numVisits=162384, meanQ=4.916782, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.364427 0.305263 0.504943 0.861706 0.595988 0.828766 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 454
Initial state: 0 0.550041 0.832355 0.341336 0.919648 0.510314 0.831178 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167764 episodes
GETTING ACTION FROM:
action 1, numVisits=167753, meanQ=5.167297, numObservations: 4
action 3, numVisits=6, meanQ=0.166667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.550041 0.832355 0.341336 0.919648 0.510314 0.831178 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 455
Initial state: 0 0.621164 0.820318 0.776852 0.401265 0.690052 0.868495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98859 episodes
GETTING ACTION FROM:
action -1, numVisits=98854, meanQ=2.924971, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.621164 0.820318 0.776852 0.401265 0.690052 0.868495 w: 1
Observation: 0 0.571763 0 0.876535 0 0.656446 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=98819, meanQ=4.991596, numObservations: 5
action 0, numVisits=30, meanQ=3.735095, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 168415 episodes
GETTING ACTION FROM:
action 2, numVisits=267214, meanQ=5.044522, numObservations: 5
action 0, numVisits=31, meanQ=3.680577, numObservations: 1
action 1, numVisits=19, meanQ=3.420016, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-3.505000, numObservations: 2
action: 2
Next state: 2 0.621164 0.820318 0.776852 0.401265 0.690052 0.868495 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 456
Initial state: 0 0.980669 0.372366 0.542854 0.852482 0.502835 0.851958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168179 episodes
GETTING ACTION FROM:
action 1, numVisits=168103, meanQ=5.034878, numObservations: 3
action -1, numVisits=65, meanQ=4.187423, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.980669 0.372366 0.542854 0.852482 0.502835 0.851958 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 457
Initial state: 0 0.0470971 0.960292 0.695512 0.826844 0.630918 0.854845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98603 episodes
GETTING ACTION FROM:
action 0, numVisits=98597, meanQ=2.940062, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0470971 0.960292 0.695512 0.826844 0.630918 0.854845 w: 1
Observation: 0 0 1 0 0.838088 0 0.913054 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=98587, meanQ=5.008164, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 169468 episodes
GETTING ACTION FROM:
action 2, numVisits=268051, meanQ=5.038895, numObservations: 4
action 1, numVisits=7, meanQ=0.844286, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.0470971 0.960292 0.695512 0.826844 0.630918 0.854845 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 458
Initial state: 0 0.458749 0.197003 0.607932 0.844016 0.677237 0.822758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166824 episodes
GETTING ACTION FROM:
action 1, numVisits=166712, meanQ=4.987870, numObservations: 4
action 3, numVisits=69, meanQ=4.086820, numObservations: 4
action -1, numVisits=39, meanQ=3.818724, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.458749 0.197003 0.607932 0.844016 0.677237 0.822758 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23385, meanQ=8.404607, numObservations: 3
action 3, numVisits=11, meanQ=6.444545, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 38428 episodes
GETTING ACTION FROM:
action 2, numVisits=53570, meanQ=7.096454, numObservations: 3
action 3, numVisits=60, meanQ=4.545488, numObservations: 4
action -1, numVisits=8185, meanQ=0.047929, numObservations: 1
action 0, numVisits=11, meanQ=-1.910000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.458749 0.197003 0.607932 0.844016 0.677237 0.822758 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 459
Initial state: 0 0.584079 0.826412 0.535681 0.838837 0.176905 0.327795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166305 episodes
GETTING ACTION FROM:
action 1, numVisits=166297, meanQ=4.948708, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.584079 0.826412 0.535681 0.838837 0.176905 0.327795 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 460
Initial state: 0 0.0938751 0.42438 0.697129 0.830154 0.59779 0.810995 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166525 episodes
GETTING ACTION FROM:
action 3, numVisits=165622, meanQ=4.999704, numObservations: 4
action -1, numVisits=471, meanQ=3.119001, numObservations: 1
action 0, numVisits=430, meanQ=3.107803, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0938751 0.42438 0.697129 0.830154 0.59779 0.810995 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 461
Initial state: 0 0.62283 0.824748 0.379801 0.238442 0.613496 0.80487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167025 episodes
GETTING ACTION FROM:
action 3, numVisits=166985, meanQ=4.999321, numObservations: 4
action 1, numVisits=23, meanQ=2.953052, numObservations: 4
action 2, numVisits=13, meanQ=2.085385, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.62283 0.824748 0.379801 0.238442 0.613496 0.80487 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=12168, meanQ=5.487781, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 206992 episodes
GETTING ACTION FROM:
action 2, numVisits=206967, meanQ=6.118889, numObservations: 4
action 3, numVisits=12168, meanQ=5.487781, numObservations: 3
action 1, numVisits=26, meanQ=3.615385, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 0 0.62283 0.824748 0.379801 0.238442 0.613496 0.80487 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=3206, meanQ=8.370100, numObservations: 5
action 3, numVisits=5, meanQ=4.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 77551 episodes
GETTING ACTION FROM:
action 1, numVisits=3850, meanQ=7.989657, numObservations: 5
action 3, numVisits=111, meanQ=6.999010, numObservations: 3
action 0, numVisits=76440, meanQ=-1.615229, numObservations: 1
action -1, numVisits=363, meanQ=-1.944588, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.62283 0.824748 0.379801 0.238442 0.613496 0.80487 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 462
Initial state: 0 0.350189 0.198977 0.681899 0.886402 0.529038 0.834986 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157655 episodes
GETTING ACTION FROM:
action 1, numVisits=157523, meanQ=4.816815, numObservations: 4
action 3, numVisits=127, meanQ=3.262766, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.350189 0.198977 0.681899 0.886402 0.529038 0.834986 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25812, meanQ=8.326520, numObservations: 3
action 3, numVisits=101, meanQ=7.647826, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 28025 episodes
GETTING ACTION FROM:
action 2, numVisits=42863, meanQ=7.433519, numObservations: 3
action 3, numVisits=513, meanQ=6.213044, numObservations: 3
action -1, numVisits=6541, meanQ=0.178120, numObservations: 1
action 0, numVisits=4023, meanQ=0.148568, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.350189 0.198977 0.681899 0.886402 0.529038 0.834986 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 463
Initial state: 0 0.768975 0.165805 0.544716 0.820151 0.652309 0.873415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167619 episodes
GETTING ACTION FROM:
action 1, numVisits=167535, meanQ=4.973754, numObservations: 5
action 0, numVisits=60, meanQ=4.092783, numObservations: 1
action 3, numVisits=18, meanQ=3.166111, numObservations: 5
action 2, numVisits=4, meanQ=0.750000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.768975 0.165805 0.544716 0.820151 0.652309 0.873415 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 464
Initial state: 0 0.793918 0.0751434 0.678549 0.855566 0.685983 0.872842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168120 episodes
GETTING ACTION FROM:
action 2, numVisits=82030, meanQ=4.987689, numObservations: 4
action 1, numVisits=86055, meanQ=4.963993, numObservations: 4
action -1, numVisits=32, meanQ=3.751921, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.793918 0.0751434 0.678549 0.855566 0.685983 0.872842 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 465
Initial state: 0 0.592265 0.853194 0.15012 0.796747 0.572389 0.86003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168103 episodes
GETTING ACTION FROM:
action 2, numVisits=168086, meanQ=5.028303, numObservations: 4
action 0, numVisits=13, meanQ=3.107334, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.592265 0.853194 0.15012 0.796747 0.572389 0.86003 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=14777, meanQ=8.439303, numObservations: 4
action 1, numVisits=8523, meanQ=8.403498, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 38723 episodes
GETTING ACTION FROM:
action 3, numVisits=17132, meanQ=8.050875, numObservations: 4
action 1, numVisits=13656, meanQ=7.411298, numObservations: 4
action 0, numVisits=31210, meanQ=0.296730, numObservations: 1
action -1, numVisits=27, meanQ=-0.973333, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.592265 0.853194 0.15012 0.796747 0.572389 0.86003 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 466
Initial state: 0 0.655185 0.887319 0.826579 0.236683 0.591168 0.820443 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 113101 episodes
GETTING ACTION FROM:
action 0, numVisits=83340, meanQ=5.837499, numObservations: 3
action 3, numVisits=29625, meanQ=4.806175, numObservations: 4
action -1, numVisits=128, meanQ=4.269612, numObservations: 1
action 2, numVisits=7, meanQ=1.872857, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.655185 0.887319 0.826579 0.236683 0.591168 0.820443 w: 1
Observation: 0 0 0.961871 0 0.251008 0 0.852818 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=38827, meanQ=7.437372, numObservations: 4
action 3, numVisits=9, meanQ=1.445567, numObservations: 2
action 2, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 159320 episodes
GETTING ACTION FROM:
action 1, numVisits=198093, meanQ=5.394492, numObservations: 4
action 0, numVisits=54, meanQ=4.442640, numObservations: 1
action 3, numVisits=9, meanQ=1.445567, numObservations: 2
action 2, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.655185 0.887319 0.826579 0.236683 0.591168 0.820443 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 467
Initial state: 0 0.622243 0.225502 0.586898 0.820071 0.559228 0.866519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167341 episodes
GETTING ACTION FROM:
action 1, numVisits=167335, meanQ=4.925886, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.622243 0.225502 0.586898 0.820071 0.559228 0.866519 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 468
Initial state: 0 0.549632 0.884492 0.891088 0.307982 0.59705 0.821217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166396 episodes
GETTING ACTION FROM:
action 2, numVisits=166340, meanQ=4.897310, numObservations: 4
action 3, numVisits=48, meanQ=3.157090, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.549632 0.884492 0.891088 0.307982 0.59705 0.821217 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 469
Initial state: 0 0.625808 0.881918 0.537718 0.823364 0.121612 0.56662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161436 episodes
GETTING ACTION FROM:
action 3, numVisits=161430, meanQ=5.040061, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.625808 0.881918 0.537718 0.823364 0.121612 0.56662 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=22712, meanQ=8.427787, numObservations: 5
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 34296 episodes
GETTING ACTION FROM:
action 1, numVisits=50993, meanQ=6.919865, numObservations: 5
action 3, numVisits=31, meanQ=5.712903, numObservations: 3
action 2, numVisits=9, meanQ=1.665567, numObservations: 3
action 0, numVisits=5974, meanQ=0.272489, numObservations: 1
action -1, numVisits=6, meanQ=-65.636957, numObservations: 1
action: 1
Next state: 1 0.625808 0.881918 0.537718 0.823364 0.121612 0.56662 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 470
Initial state: 0 0.685763 0.878426 0.347877 0.255275 0.681441 0.821475 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167277 episodes
GETTING ACTION FROM:
action 3, numVisits=167108, meanQ=5.026812, numObservations: 5
action 1, numVisits=139, meanQ=4.383897, numObservations: 4
action 2, numVisits=26, meanQ=3.231931, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.685763 0.878426 0.347877 0.255275 0.681441 0.821475 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 471
Initial state: 0 0.350431 0.981258 0.666074 0.868029 0.539327 0.874951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168032 episodes
GETTING ACTION FROM:
action 3, numVisits=168006, meanQ=5.027456, numObservations: 4
action -1, numVisits=22, meanQ=3.546400, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.350431 0.981258 0.666074 0.868029 0.539327 0.874951 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 472
Initial state: 0 0.614222 0.807843 0.802406 0.520157 0.558543 0.85465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168576 episodes
GETTING ACTION FROM:
action 1, numVisits=168564, meanQ=5.036365, numObservations: 5
action 3, numVisits=7, meanQ=1.428571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.614222 0.807843 0.802406 0.520157 0.558543 0.85465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 473
Initial state: 0 0.269154 0.693794 0.524151 0.843725 0.510096 0.822343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169636 episodes
GETTING ACTION FROM:
action 1, numVisits=169630, meanQ=5.078748, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.269154 0.693794 0.524151 0.843725 0.510096 0.822343 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=28031, meanQ=8.361725, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 17547 episodes
GETTING ACTION FROM:
action 2, numVisits=37506, meanQ=7.740972, numObservations: 4
action 0, numVisits=7945, meanQ=-0.040811, numObservations: 1
action -1, numVisits=128, meanQ=-0.571174, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 2
Next state: 1 0.269154 0.693794 0.524151 0.843725 0.510096 0.822343 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 474
Initial state: 0 0.611533 0.858031 0.672959 0.848265 0.654317 0.576411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167016 episodes
GETTING ACTION FROM:
action 3, numVisits=166965, meanQ=4.960966, numObservations: 4
action 0, numVisits=32, meanQ=3.741726, numObservations: 1
action -1, numVisits=14, meanQ=3.043980, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.611533 0.858031 0.672959 0.848265 0.654317 0.576411 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23429, meanQ=8.433582, numObservations: 4
action 1, numVisits=35, meanQ=7.396863, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 38595 episodes
GETTING ACTION FROM:
action 2, numVisits=42689, meanQ=7.280544, numObservations: 4
action 1, numVisits=14065, meanQ=5.704419, numObservations: 4
action 0, numVisits=5305, meanQ=-0.884283, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-198.273059, numObservations: 1
action: 2
Next state: 1 0.611533 0.858031 0.672959 0.848265 0.654317 0.576411 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 475
Initial state: 0 0.394952 0.462443 0.554153 0.819744 0.550839 0.865934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166554 episodes
GETTING ACTION FROM:
action 3, numVisits=166440, meanQ=5.000388, numObservations: 5
action 0, numVisits=75, meanQ=4.204286, numObservations: 1
action 1, numVisits=36, meanQ=3.158614, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.394952 0.462443 0.554153 0.819744 0.550839 0.865934 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 476
Initial state: 0 0.876087 0.258846 0.606912 0.84551 0.591053 0.838848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165245 episodes
GETTING ACTION FROM:
action 3, numVisits=165190, meanQ=5.006851, numObservations: 5
action -1, numVisits=19, meanQ=3.421325, numObservations: 1
action 2, numVisits=20, meanQ=2.990500, numObservations: 3
action 1, numVisits=14, meanQ=2.502164, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.876087 0.258846 0.606912 0.84551 0.591053 0.838848 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 477
Initial state: 0 0.122357 0.75211 0.649332 0.824948 0.545348 0.840352 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167362 episodes
GETTING ACTION FROM:
action 2, numVisits=167222, meanQ=5.028032, numObservations: 4
action 0, numVisits=62, meanQ=4.129072, numObservations: 1
action -1, numVisits=51, meanQ=4.055829, numObservations: 1
action 1, numVisits=20, meanQ=3.349510, numObservations: 4
action 3, numVisits=7, meanQ=2.014286, numObservations: 3
action: 2
Next state: 1 0.122357 0.75211 0.649332 0.824948 0.545348 0.840352 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.528568 0.80787 0.269411 0.712952 0.586218 0.846056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160206 episodes
GETTING ACTION FROM:
action 1, numVisits=159973, meanQ=4.831542, numObservations: 4
action 0, numVisits=170, meanQ=4.303460, numObservations: 1
action -1, numVisits=26, meanQ=3.470898, numObservations: 1
action 2, numVisits=31, meanQ=3.354532, numObservations: 3
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action: 1
Next state: 1 0.528568 0.80787 0.269411 0.712952 0.586218 0.846056 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 479
Initial state: 0 0.619776 0.814214 0.673715 0.822806 0.548123 0.293916 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167619 episodes
GETTING ACTION FROM:
action 3, numVisits=167520, meanQ=4.973986, numObservations: 4
action 0, numVisits=88, meanQ=1.933156, numObservations: 1
action 1, numVisits=7, meanQ=0.145729, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.619776 0.814214 0.673715 0.822806 0.548123 0.293916 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12300, meanQ=4.909882, numObservations: 5
action -1, numVisits=65, meanQ=4.148900, numObservations: 1
action 0, numVisits=27, meanQ=3.733086, numObservations: 1
action 1, numVisits=12, meanQ=2.983333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
Sampled 33704 episodes
GETTING ACTION FROM:
action 2, numVisits=12300, meanQ=4.909882, numObservations: 5
action 1, numVisits=22, meanQ=3.250679, numObservations: 3
action -1, numVisits=33191, meanQ=-0.379431, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=595, meanQ=-1.215922, numObservations: 2
action: 2
Next state: 1 0.619776 0.814214 0.673715 0.822806 0.548123 0.293916 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 480
Initial state: 0 0.668951 0.874855 0.889043 0.859241 0.589802 0.802489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167224 episodes
GETTING ACTION FROM:
action 1, numVisits=166267, meanQ=4.984828, numObservations: 5
action 3, numVisits=902, meanQ=4.735691, numObservations: 4
action -1, numVisits=29, meanQ=3.676709, numObservations: 1
action 0, numVisits=20, meanQ=3.408455, numObservations: 1
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action: 1
Next state: 1 0.668951 0.874855 0.889043 0.859241 0.589802 0.802489 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 481
Initial state: 0 0.592491 0.912489 0.680434 0.815989 0.574116 0.842405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167001 episodes
GETTING ACTION FROM:
action 1, numVisits=166927, meanQ=4.978982, numObservations: 4
action -1, numVisits=39, meanQ=3.868037, numObservations: 1
action 0, numVisits=23, meanQ=3.450136, numObservations: 1
action 2, numVisits=11, meanQ=2.363636, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.592491 0.912489 0.680434 0.815989 0.574116 0.842405 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 482
Initial state: 0 0.901636 0.440073 0.588162 0.84464 0.615548 0.837951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167763 episodes
GETTING ACTION FROM:
action 3, numVisits=167757, meanQ=5.025415, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.901636 0.440073 0.588162 0.84464 0.615548 0.837951 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 483
Initial state: 0 0.51845 0.82645 0.513119 0.811165 0.480879 0.64641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167788 episodes
GETTING ACTION FROM:
action 2, numVisits=167782, meanQ=4.942791, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.51845 0.82645 0.513119 0.811165 0.480879 0.64641 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 484
Initial state: 0 0.177442 0.656176 0.677652 0.807551 0.601834 0.808275 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167182 episodes
GETTING ACTION FROM:
action 1, numVisits=167127, meanQ=5.016702, numObservations: 5
action 0, numVisits=47, meanQ=4.004229, numObservations: 1
action 3, numVisits=4, meanQ=0.750000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.177442 0.656176 0.677652 0.807551 0.601834 0.808275 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23146, meanQ=8.435503, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 20153 episodes
GETTING ACTION FROM:
action 2, numVisits=32896, meanQ=7.714161, numObservations: 4
action 0, numVisits=10391, meanQ=0.088803, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=12, meanQ=-2.084150, numObservations: 1
action: 2
Next state: 1 0.177442 0.656176 0.677652 0.807551 0.601834 0.808275 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 485
Initial state: 0 0.363693 0.168959 0.581707 0.855055 0.680542 0.817919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159205 episodes
GETTING ACTION FROM:
action 2, numVisits=159179, meanQ=4.777594, numObservations: 3
action 0, numVisits=22, meanQ=3.307944, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.363693 0.168959 0.581707 0.855055 0.680542 0.817919 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 486
Initial state: 0 0.642234 0.894683 0.752105 0.10683 0.588932 0.897089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 107085 episodes
GETTING ACTION FROM:
action 0, numVisits=99865, meanQ=5.973675, numObservations: 3
action 3, numVisits=7212, meanQ=4.879411, numObservations: 4
action 1, numVisits=5, meanQ=1.582000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.642234 0.894683 0.752105 0.10683 0.588932 0.897089 w: 1
Observation: 0 0 0.817685 0 0.0420452 0 0.937841 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32932, meanQ=8.066974, numObservations: 3
action 1, numVisits=5, meanQ=4.196000, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 169995 episodes
GETTING ACTION FROM:
action 3, numVisits=202875, meanQ=5.704091, numObservations: 3
action 0, numVisits=49, meanQ=4.714377, numObservations: 1
action 1, numVisits=7, meanQ=2.711429, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.642234 0.894683 0.752105 0.10683 0.588932 0.897089 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 487
Initial state: 0 0.313611 0.34457 0.584203 0.833207 0.635519 0.805904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167541 episodes
GETTING ACTION FROM:
action 3, numVisits=167535, meanQ=4.952971, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.313611 0.34457 0.584203 0.833207 0.635519 0.805904 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 488
Initial state: 0 0.686487 0.826657 0.52877 0.0942794 0.649794 0.879891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166231 episodes
GETTING ACTION FROM:
action 3, numVisits=165755, meanQ=4.996995, numObservations: 4
action -1, numVisits=367, meanQ=2.975224, numObservations: 1
action 0, numVisits=105, meanQ=2.743106, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.686487 0.826657 0.52877 0.0942794 0.649794 0.879891 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 489
Initial state: 0 0.104639 0.199985 0.672699 0.885669 0.666446 0.886887 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167958 episodes
GETTING ACTION FROM:
action 1, numVisits=167848, meanQ=4.995478, numObservations: 3
action -1, numVisits=50, meanQ=4.005147, numObservations: 1
action 2, numVisits=57, meanQ=3.851582, numObservations: 4
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.104639 0.199985 0.672699 0.885669 0.666446 0.886887 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27689, meanQ=8.284764, numObservations: 4
action 2, numVisits=4, meanQ=4.975000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 48198 episodes
GETTING ACTION FROM:
action 3, numVisits=68169, meanQ=6.865165, numObservations: 4
action 1, numVisits=7, meanQ=5.284300, numObservations: 2
action 2, numVisits=15, meanQ=2.743761, numObservations: 3
action 0, numVisits=7012, meanQ=0.204769, numObservations: 1
action -1, numVisits=691, meanQ=-0.219146, numObservations: 1
action: 3
Next state: 1 0.104639 0.199985 0.672699 0.885669 0.666446 0.886887 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 490
Initial state: 0 0.801167 0.922409 0.513738 0.80086 0.564917 0.896183 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167895 episodes
GETTING ACTION FROM:
action 3, numVisits=167869, meanQ=4.992967, numObservations: 5
action 0, numVisits=10, meanQ=2.488000, numObservations: 1
action 1, numVisits=11, meanQ=2.081818, numObservations: 2
action 2, numVisits=3, meanQ=0.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.801167 0.922409 0.513738 0.80086 0.564917 0.896183 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 491
Initial state: 0 0.569592 0.888702 0.606153 0.887356 0.175084 0.970934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164152 episodes
GETTING ACTION FROM:
action 3, numVisits=164127, meanQ=4.937568, numObservations: 3
action 0, numVisits=21, meanQ=3.385570, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.569592 0.888702 0.606153 0.887356 0.175084 0.970934 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=11878, meanQ=4.258926, numObservations: 3
action 2, numVisits=26, meanQ=2.531165, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 199542 episodes
GETTING ACTION FROM:
action 1, numVisits=211407, meanQ=5.875008, numObservations: 3
action 2, numVisits=36, meanQ=3.103342, numObservations: 4
action -1, numVisits=3, meanQ=-2.003300, numObservations: 1
action 0, numVisits=3, meanQ=-2.003300, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 1
Next state: 1 0.569592 0.888702 0.606153 0.887356 0.175084 0.970934 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 492
Initial state: 0 0.557094 0.857585 0.574061 0.833932 0.950196 0.762323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167995 episodes
GETTING ACTION FROM:
action 3, numVisits=167905, meanQ=5.003374, numObservations: 4
action -1, numVisits=86, meanQ=4.258562, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.557094 0.857585 0.574061 0.833932 0.950196 0.762323 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 493
Initial state: 0 0.716307 0.0445264 0.541904 0.831944 0.634198 0.861884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168012 episodes
GETTING ACTION FROM:
action 1, numVisits=167927, meanQ=4.984086, numObservations: 4
action -1, numVisits=75, meanQ=3.976298, numObservations: 1
action 2, numVisits=7, meanQ=2.285729, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.716307 0.0445264 0.541904 0.831944 0.634198 0.861884 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 494
Initial state: 0 0.568477 0.89341 0.234995 0.00617263 0.551634 0.887683 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168992 episodes
GETTING ACTION FROM:
action 1, numVisits=168984, meanQ=5.048760, numObservations: 5
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.568477 0.89341 0.234995 0.00617263 0.551634 0.887683 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 495
Initial state: 0 0.0928305 0.216897 0.658894 0.853327 0.554831 0.835265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168297 episodes
GETTING ACTION FROM:
action 3, numVisits=168290, meanQ=5.015758, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0928305 0.216897 0.658894 0.853327 0.554831 0.835265 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 496
Initial state: 0 0.559372 0.877445 0.258418 0.685748 0.609108 0.820347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75902 episodes
GETTING ACTION FROM:
action -1, numVisits=75895, meanQ=3.752987, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.559372 0.877445 0.258418 0.685748 0.609108 0.820347 w: 1
Observation: 0 0.599003 0 0.322557 0 0.588402 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=65065, meanQ=5.963436, numObservations: 3
action 3, numVisits=10825, meanQ=5.026115, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 103829 episodes
GETTING ACTION FROM:
action 0, numVisits=168894, meanQ=5.968977, numObservations: 3
action 3, numVisits=10825, meanQ=5.026115, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.559372 0.877445 0.258418 0.685748 0.609108 0.820347 w: 1
Observation: 0 0 0.826849 0 0.72187 0 0.727847 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=54557, meanQ=8.074181, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 167638 episodes
GETTING ACTION FROM:
action 1, numVisits=221729, meanQ=5.606873, numObservations: 4
action 3, numVisits=425, meanQ=5.273692, numObservations: 4
action 0, numVisits=29, meanQ=4.307919, numObservations: 1
action 2, numVisits=16, meanQ=3.221250, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.559372 0.877445 0.258418 0.685748 0.609108 0.820347 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 497
Initial state: 0 0.881255 0.499585 0.699777 0.816388 0.687858 0.82616 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168170 episodes
GETTING ACTION FROM:
action 2, numVisits=168164, meanQ=5.015757, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.881255 0.499585 0.699777 0.816388 0.687858 0.82616 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 498
Initial state: 0 0.387396 0.0943796 0.680394 0.899072 0.596282 0.874114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167708 episodes
GETTING ACTION FROM:
action 1, numVisits=167643, meanQ=4.934942, numObservations: 5
action -1, numVisits=26, meanQ=3.508485, numObservations: 1
action 3, numVisits=27, meanQ=2.986304, numObservations: 4
action 2, numVisits=10, meanQ=1.799000, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.387396 0.0943796 0.680394 0.899072 0.596282 0.874114 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23390, meanQ=8.403796, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 27102 episodes
GETTING ACTION FROM:
action 2, numVisits=41254, meanQ=7.300172, numObservations: 3
action 1, numVisits=4, meanQ=4.975000, numObservations: 3
action 3, numVisits=8, meanQ=2.498750, numObservations: 2
action 0, numVisits=9198, meanQ=0.249403, numObservations: 1
action -1, numVisits=33, meanQ=-0.890000, numObservations: 1
action: 2
Next state: 1 0.387396 0.0943796 0.680394 0.899072 0.596282 0.874114 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 499
Initial state: 0 0.0485442 0.965577 0.634255 0.899297 0.504538 0.860944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166803 episodes
GETTING ACTION FROM:
action 1, numVisits=166686, meanQ=4.921857, numObservations: 4
action -1, numVisits=113, meanQ=4.273505, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0485442 0.965577 0.634255 0.899297 0.504538 0.860944 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=12379, meanQ=4.592979, numObservations: 4
action 2, numVisits=9, meanQ=1.886667, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 203760 episodes
GETTING ACTION FROM:
action 3, numVisits=216116, meanQ=5.908750, numObservations: 4
action 1, numVisits=27, meanQ=3.326296, numObservations: 4
action 2, numVisits=9, meanQ=1.886667, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.0485442 0.965577 0.634255 0.899297 0.504538 0.860944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 500
Initial state: 0 0.485996 0.979669 0.656282 0.839984 0.544468 0.855629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165899 episodes
GETTING ACTION FROM:
action 1, numVisits=165854, meanQ=4.900040, numObservations: 3
action -1, numVisits=38, meanQ=3.785810, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.485996 0.979669 0.656282 0.839984 0.544468 0.855629 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12359, meanQ=4.723630, numObservations: 4
action -1, numVisits=65, meanQ=3.912950, numObservations: 1
action 3, numVisits=10, meanQ=2.201010, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 203823 episodes
GETTING ACTION FROM:
action 2, numVisits=216176, meanQ=5.724449, numObservations: 4
action -1, numVisits=71, meanQ=3.477893, numObservations: 1
action 3, numVisits=10, meanQ=2.201010, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.485996 0.979669 0.656282 0.839984 0.544468 0.855629 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=4538, meanQ=4.192554, numObservations: 1
action -1, numVisits=115, meanQ=2.924056, numObservations: 1
action 2, numVisits=5, meanQ=-1.402000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 214062 episodes
GETTING ACTION FROM:
action 3, numVisits=214050, meanQ=6.108587, numObservations: 5
action 0, numVisits=4547, meanQ=4.181778, numObservations: 1
action -1, numVisits=115, meanQ=2.924056, numObservations: 1
action 1, numVisits=5, meanQ=2.598000, numObservations: 2
action 2, numVisits=5, meanQ=-1.402000, numObservations: 2
action: 3
Next state: 1 0.485996 0.979669 0.656282 0.839984 0.544468 0.855629 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
