Run # 1
Initial state: 0 0.654647 0.84607 0.935594 0.971598 0.573208 0.832987 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53022 episodes
GETTING ACTION FROM:
action 3, numVisits=52965, meanQ=4.985843, numObservations: 4
action -1, numVisits=51, meanQ=4.058583, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.654647 0.84607 0.935594 0.971598 0.573208 0.832987 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.528392 0.81415 0.33322 0.515014 0.56319 0.850642 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32392 episodes
GETTING ACTION FROM:
action 0, numVisits=32381, meanQ=3.208911, numObservations: 2
action 3, numVisits=7, meanQ=0.428571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.528392 0.81415 0.33322 0.515014 0.56319 0.850642 w: 1
Observation: 0 0 0.738188 0 0.533553 0 0.948946 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2652, meanQ=8.419210, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55421 episodes
GETTING ACTION FROM:
action 3, numVisits=58037, meanQ=5.203813, numObservations: 4
action -1, numVisits=36, meanQ=4.122191, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.528392 0.81415 0.33322 0.515014 0.56319 0.850642 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 3
Initial state: 0 0.52092 0.84085 0.648074 0.805815 0.511612 0.399967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54713 episodes
GETTING ACTION FROM:
action 2, numVisits=45751, meanQ=5.027895, numObservations: 4
action 3, numVisits=8951, meanQ=4.983630, numObservations: 5
action 1, numVisits=7, meanQ=2.428571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.52092 0.84085 0.648074 0.805815 0.511612 0.399967 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 4
Initial state: 0 0.987174 0.412439 0.602149 0.834327 0.678983 0.873997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54703 episodes
GETTING ACTION FROM:
action 2, numVisits=54695, meanQ=5.142278, numObservations: 5
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.987174 0.412439 0.602149 0.834327 0.678983 0.873997 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 5
Initial state: 0 0.864052 0.239785 0.552893 0.835026 0.653884 0.861645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54877 episodes
GETTING ACTION FROM:
action 3, numVisits=54870, meanQ=5.054776, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.864052 0.239785 0.552893 0.835026 0.653884 0.861645 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 6
Initial state: 0 0.443955 0.188963 0.61391 0.880788 0.576331 0.895243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54558 episodes
GETTING ACTION FROM:
action 3, numVisits=54503, meanQ=4.992352, numObservations: 3
action 0, numVisits=49, meanQ=4.046909, numObservations: 1
action 2, numVisits=3, meanQ=0.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.443955 0.188963 0.61391 0.880788 0.576331 0.895243 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 7
Initial state: 0 0.657035 0.819366 0.550399 0.856522 0.465283 0.505839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54021 episodes
GETTING ACTION FROM:
action 2, numVisits=54014, meanQ=4.977960, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.657035 0.819366 0.550399 0.856522 0.465283 0.505839 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 8
Initial state: 0 0.563824 0.82772 0.552064 0.881948 0.946988 0.36913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54715 episodes
GETTING ACTION FROM:
action 2, numVisits=54709, meanQ=4.983695, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.563824 0.82772 0.552064 0.881948 0.946988 0.36913 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 9
Initial state: 0 0.650869 0.822766 0.479821 0.292034 0.520077 0.821222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54509 episodes
GETTING ACTION FROM:
action 1, numVisits=54494, meanQ=4.893240, numObservations: 4
action 2, numVisits=10, meanQ=1.397000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.650869 0.822766 0.479821 0.292034 0.520077 0.821222 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 10
Initial state: 0 0.662032 0.832178 0.126688 0.0577682 0.641362 0.839543 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51951 episodes
GETTING ACTION FROM:
action 2, numVisits=51945, meanQ=4.877077, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.662032 0.832178 0.126688 0.0577682 0.641362 0.839543 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8597, meanQ=8.293849, numObservations: 4
action 3, numVisits=11, meanQ=6.455464, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 17242 episodes
GETTING ACTION FROM:
action 1, numVisits=18925, meanQ=7.006645, numObservations: 4
action 3, numVisits=5990, meanQ=6.002235, numObservations: 3
action 2, numVisits=8, meanQ=4.512500, numObservations: 3
action -1, numVisits=734, meanQ=-0.294395, numObservations: 1
action 0, numVisits=197, meanQ=-0.608795, numObservations: 1
action: 1
Next state: 1 0.662032 0.832178 0.126688 0.0577682 0.641362 0.839543 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 11
Initial state: 0 0.0970874 0.130249 0.623663 0.863382 0.607178 0.884285 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33591 episodes
GETTING ACTION FROM:
action 0, numVisits=33582, meanQ=5.824155, numObservations: 2
action 1, numVisits=5, meanQ=-0.399980, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.0970874 0.130249 0.623663 0.863382 0.607178 0.884285 w: 1
Observation: 0 0 0.204641 0 0.872599 0 0.818987 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=14204, meanQ=7.925227, numObservations: 3
action 3, numVisits=5, meanQ=5.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55348 episodes
GETTING ACTION FROM:
action 2, numVisits=69497, meanQ=5.709249, numObservations: 3
action 3, numVisits=60, meanQ=4.660170, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0970874 0.130249 0.623663 0.863382 0.607178 0.884285 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 12
Initial state: 0 0.526442 0.886103 0.574016 0.858089 0.819876 0.664931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53531 episodes
GETTING ACTION FROM:
action 2, numVisits=53493, meanQ=5.006795, numObservations: 4
action 3, numVisits=33, meanQ=3.605161, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.526442 0.886103 0.574016 0.858089 0.819876 0.664931 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 13
Initial state: 0 0.6815 0.806423 0.809522 0.0347793 0.595657 0.870225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54386 episodes
GETTING ACTION FROM:
action 3, numVisits=54379, meanQ=4.928822, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.6815 0.806423 0.809522 0.0347793 0.595657 0.870225 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 14
Initial state: 0 0.542212 0.818851 0.604248 0.810885 0.919432 0.584709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54519 episodes
GETTING ACTION FROM:
action 2, numVisits=54510, meanQ=4.981546, numObservations: 4
action 3, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.542212 0.818851 0.604248 0.810885 0.919432 0.584709 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 15
Initial state: 0 0.539527 0.886717 0.657088 0.762578 0.574596 0.809868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53937 episodes
GETTING ACTION FROM:
action 3, numVisits=53914, meanQ=4.993405, numObservations: 3
action 0, numVisits=19, meanQ=3.445333, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.539527 0.886717 0.657088 0.762578 0.574596 0.809868 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7815, meanQ=8.346705, numObservations: 4
action 1, numVisits=1039, meanQ=8.194089, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 21547 episodes
GETTING ACTION FROM:
action 2, numVisits=20362, meanQ=6.969770, numObservations: 4
action 1, numVisits=9375, meanQ=6.146097, numObservations: 3
action -1, numVisits=646, meanQ=-1.290555, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=20, meanQ=-19.291540, numObservations: 1
action: 2
Next state: 2 0.539527 0.886717 0.657088 0.762578 0.574596 0.809868 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 16
Initial state: 0 0.694751 0.881108 0.647043 0.80539 0.382563 0.338308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54746 episodes
GETTING ACTION FROM:
action 2, numVisits=54624, meanQ=4.953730, numObservations: 5
action -1, numVisits=113, meanQ=4.280890, numObservations: 1
action 3, numVisits=6, meanQ=1.498333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.694751 0.881108 0.647043 0.80539 0.382563 0.338308 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 17
Initial state: 0 0.81868 0.211289 0.621273 0.805006 0.635006 0.80243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32135 episodes
GETTING ACTION FROM:
action -1, numVisits=32119, meanQ=2.993790, numObservations: 1
action 2, numVisits=12, meanQ=0.666667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.81868 0.211289 0.621273 0.805006 0.635006 0.80243 w: 1
Observation: 0 0.87636 0 0.606111 0 0.70288 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32065, meanQ=5.038584, numObservations: 4
action -1, numVisits=43, meanQ=4.079650, numObservations: 1
action 3, numVisits=7, meanQ=0.995714, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54397 episodes
GETTING ACTION FROM:
action 2, numVisits=86461, meanQ=5.133309, numObservations: 4
action -1, numVisits=44, meanQ=4.021468, numObservations: 1
action 3, numVisits=7, meanQ=0.995714, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.81868 0.211289 0.621273 0.805006 0.635006 0.80243 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=6387, meanQ=5.639468, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 60511 episodes
GETTING ACTION FROM:
action 2, numVisits=66896, meanQ=5.184330, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.81868 0.211289 0.621273 0.805006 0.635006 0.80243 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 18
Initial state: 0 0.905926 0.0290011 0.551608 0.860718 0.648176 0.85652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54636 episodes
GETTING ACTION FROM:
action 1, numVisits=54620, meanQ=4.942401, numObservations: 5
action 2, numVisits=10, meanQ=2.400000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.905926 0.0290011 0.551608 0.860718 0.648176 0.85652 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4138, meanQ=4.802163, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 23582 episodes
GETTING ACTION FROM:
action 3, numVisits=26566, meanQ=5.814210, numObservations: 5
action -1, numVisits=819, meanQ=-0.184753, numObservations: 1
action 0, numVisits=337, meanQ=-0.660438, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.905926 0.0290011 0.551608 0.860718 0.648176 0.85652 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 19
Initial state: 0 0.931702 0.396073 0.517977 0.887118 0.690886 0.894076 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54450 episodes
GETTING ACTION FROM:
action 3, numVisits=54412, meanQ=4.958873, numObservations: 4
action -1, numVisits=33, meanQ=3.762413, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.931702 0.396073 0.517977 0.887118 0.690886 0.894076 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 20
Initial state: 0 0.353384 0.460827 0.589339 0.843644 0.552432 0.856638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54227 episodes
GETTING ACTION FROM:
action 1, numVisits=54058, meanQ=4.975928, numObservations: 4
action -1, numVisits=119, meanQ=4.381074, numObservations: 1
action 3, numVisits=33, meanQ=3.781818, numObservations: 3
action 0, numVisits=16, meanQ=3.315881, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.353384 0.460827 0.589339 0.843644 0.552432 0.856638 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7525, meanQ=8.457051, numObservations: 3
action 2, numVisits=6, meanQ=4.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 20455 episodes
GETTING ACTION FROM:
action 3, numVisits=20831, meanQ=6.668943, numObservations: 3
action 2, numVisits=7137, meanQ=5.961630, numObservations: 5
action 0, numVisits=14, meanQ=-2.000707, numObservations: 1
action -1, numVisits=6, meanQ=-6.378885, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.353384 0.460827 0.589339 0.843644 0.552432 0.856638 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 21
Initial state: 0 0.765516 0.835151 0.598883 0.866039 0.669529 0.835873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48897 episodes
GETTING ACTION FROM:
action 1, numVisits=48828, meanQ=4.595152, numObservations: 4
action 0, numVisits=65, meanQ=3.561432, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.765516 0.835151 0.598883 0.866039 0.669529 0.835873 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.616234 0.825021 0.51956 0.306564 0.582285 0.824607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54364 episodes
GETTING ACTION FROM:
action 2, numVisits=54337, meanQ=5.009782, numObservations: 5
action -1, numVisits=14, meanQ=3.227648, numObservations: 1
action 1, numVisits=9, meanQ=2.333333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.616234 0.825021 0.51956 0.306564 0.582285 0.824607 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 23
Initial state: 0 0.53619 0.868642 0.521546 0.366234 0.512323 0.852209 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54509 episodes
GETTING ACTION FROM:
action 1, numVisits=54502, meanQ=5.146761, numObservations: 4
action -1, numVisits=3, meanQ=-2.996600, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.53619 0.868642 0.521546 0.366234 0.512323 0.852209 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 24
Initial state: 0 0.447101 0.417774 0.648202 0.819102 0.544765 0.811404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55119 episodes
GETTING ACTION FROM:
action 1, numVisits=55110, meanQ=5.056264, numObservations: 5
action 2, numVisits=4, meanQ=0.750000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.447101 0.417774 0.648202 0.819102 0.544765 0.811404 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7610, meanQ=8.427815, numObservations: 3
action 2, numVisits=15, meanQ=6.866000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 26738 episodes
GETTING ACTION FROM:
action 3, numVisits=16172, meanQ=7.183905, numObservations: 3
action 2, numVisits=17325, meanQ=6.224424, numObservations: 4
action 0, numVisits=859, meanQ=0.034168, numObservations: 1
action -1, numVisits=9, meanQ=-1.890000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.447101 0.417774 0.648202 0.819102 0.544765 0.811404 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=65, meanQ=7.706157, numObservations: 3
action 0, numVisits=19, meanQ=6.493158, numObservations: 1
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 49621 episodes
GETTING ACTION FROM:
action 2, numVisits=49227, meanQ=6.586406, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action 0, numVisits=400, meanQ=-1.262450, numObservations: 1
action -1, numVisits=80, meanQ=-1.665999, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.447101 0.417774 0.648202 0.819102 0.544765 0.811404 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 25
Initial state: 0 0.630375 0.893774 0.390325 0.446326 0.690581 0.817843 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54467 episodes
GETTING ACTION FROM:
action 1, numVisits=54375, meanQ=5.018126, numObservations: 3
action 2, numVisits=51, meanQ=4.118255, numObservations: 3
action 3, numVisits=37, meanQ=3.828384, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.630375 0.893774 0.390325 0.446326 0.690581 0.817843 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 26
Initial state: 0 0.581956 0.886888 0.14999 0.737054 0.611239 0.814075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54128 episodes
GETTING ACTION FROM:
action 3, numVisits=53907, meanQ=4.898011, numObservations: 5
action -1, numVisits=211, meanQ=2.751608, numObservations: 1
action 1, numVisits=6, meanQ=0.166667, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.581956 0.886888 0.14999 0.737054 0.611239 0.814075 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 27
Initial state: 0 0.613905 0.863403 0.131431 0.602827 0.533499 0.861616 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54651 episodes
GETTING ACTION FROM:
action 3, numVisits=54497, meanQ=4.921279, numObservations: 5
action 0, numVisits=150, meanQ=4.398114, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.613905 0.863403 0.131431 0.602827 0.533499 0.861616 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 28
Initial state: 0 0.572881 0.893104 0.638235 0.892288 0.850405 0.368003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54628 episodes
GETTING ACTION FROM:
action 3, numVisits=54616, meanQ=5.003956, numObservations: 5
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.572881 0.893104 0.638235 0.892288 0.850405 0.368003 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 29
Initial state: 0 0.528604 0.87949 0.508296 0.812071 0.19107 0.15584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51554 episodes
GETTING ACTION FROM:
action 1, numVisits=51527, meanQ=4.781870, numObservations: 4
action -1, numVisits=21, meanQ=3.296562, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.528604 0.87949 0.508296 0.812071 0.19107 0.15584 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=447, meanQ=5.630607, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 17113 episodes
GETTING ACTION FROM:
action 3, numVisits=14317, meanQ=5.796689, numObservations: 5
action 1, numVisits=471, meanQ=5.617582, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2767, meanQ=0.074098, numObservations: 1
action 0, numVisits=10, meanQ=-1.901000, numObservations: 1
action: 3
Next state: 2 0.528604 0.87949 0.508296 0.812071 0.19107 0.15584 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 30
Initial state: 0 0.673025 0.87604 0.255677 0.860898 0.597069 0.856929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31807 episodes
GETTING ACTION FROM:
action 0, numVisits=31796, meanQ=2.810913, numObservations: 1
action 3, numVisits=7, meanQ=-0.571414, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.673025 0.87604 0.255677 0.860898 0.597069 0.856929 w: 1
Observation: 0 0 0.863387 0 0.940841 0 0.859458 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31766, meanQ=4.907926, numObservations: 5
action 1, numVisits=14, meanQ=2.856436, numObservations: 3
action 2, numVisits=11, meanQ=2.255464, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 54119 episodes
GETTING ACTION FROM:
action 3, numVisits=85884, meanQ=4.841729, numObservations: 5
action 1, numVisits=15, meanQ=2.332680, numObservations: 3
action 2, numVisits=11, meanQ=2.255464, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.673025 0.87604 0.255677 0.860898 0.597069 0.856929 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 31
Initial state: 0 0.357642 0.917887 0.600264 0.856734 0.576911 0.835607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54663 episodes
GETTING ACTION FROM:
action 2, numVisits=54657, meanQ=4.959937, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.357642 0.917887 0.600264 0.856734 0.576911 0.835607 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 32
Initial state: 0 0.520165 0.874208 0.364877 0.731281 0.555784 0.807879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54629 episodes
GETTING ACTION FROM:
action 1, numVisits=54569, meanQ=4.890429, numObservations: 4
action 2, numVisits=55, meanQ=3.854376, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.520165 0.874208 0.364877 0.731281 0.555784 0.807879 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 33
Initial state: 0 0.637626 0.863724 0.570997 0.868423 0.327342 0.87962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54544 episodes
GETTING ACTION FROM:
action 3, numVisits=54493, meanQ=4.997171, numObservations: 3
action -1, numVisits=17, meanQ=3.385551, numObservations: 1
action 0, numVisits=20, meanQ=3.362904, numObservations: 1
action 2, numVisits=11, meanQ=2.718182, numObservations: 4
action 1, numVisits=3, meanQ=0.663333, numObservations: 3
action: 3
Next state: 0 0.637626 0.863724 0.570997 0.868423 0.327342 0.87962 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8964, meanQ=8.331078, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 25585 episodes
GETTING ACTION FROM:
action 1, numVisits=24018, meanQ=6.916432, numObservations: 4
action 2, numVisits=91, meanQ=3.437759, numObservations: 4
action -1, numVisits=10286, meanQ=-0.405359, numObservations: 1
action 0, numVisits=158, meanQ=-0.920650, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.637626 0.863724 0.570997 0.868423 0.327342 0.87962 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=882, meanQ=8.019959, numObservations: 4
action 1, numVisits=94, meanQ=7.890534, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 57035 episodes
GETTING ACTION FROM:
action 2, numVisits=57347, meanQ=6.187070, numObservations: 4
action 1, numVisits=649, meanQ=5.562407, numObservations: 4
action -1, numVisits=17, meanQ=-2.059400, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.637626 0.863724 0.570997 0.868423 0.327342 0.87962 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 34
Initial state: 0 0.657634 0.870802 0.818827 0.850128 0.617183 0.830041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54874 episodes
GETTING ACTION FROM:
action 3, numVisits=54739, meanQ=5.018173, numObservations: 4
action -1, numVisits=72, meanQ=4.257156, numObservations: 1
action 0, numVisits=61, meanQ=4.175562, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.657634 0.870802 0.818827 0.850128 0.617183 0.830041 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 35
Initial state: 0 0.413096 0.0255842 0.568348 0.801844 0.601175 0.807316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54813 episodes
GETTING ACTION FROM:
action 3, numVisits=54805, meanQ=4.948751, numObservations: 4
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.413096 0.0255842 0.568348 0.801844 0.601175 0.807316 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 36
Initial state: 0 0.500204 0.804342 0.883843 0.613728 0.601859 0.8614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31962 episodes
GETTING ACTION FROM:
action -1, numVisits=31874, meanQ=2.882797, numObservations: 1
action 0, numVisits=85, meanQ=2.219135, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.500204 0.804342 0.883843 0.613728 0.601859 0.8614 w: 1
Observation: 0 0.546484 0 0.878644 0 0.679763 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31862, meanQ=4.884664, numObservations: 3
action 3, numVisits=6, meanQ=-0.316667, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54252 episodes
GETTING ACTION FROM:
action 1, numVisits=86113, meanQ=4.945975, numObservations: 3
action 3, numVisits=6, meanQ=-0.316667, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 1
Next state: 1 0.500204 0.804342 0.883843 0.613728 0.601859 0.8614 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 37
Initial state: 0 0.509972 0.861954 0.186524 0.324865 0.696935 0.821187 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32054 episodes
GETTING ACTION FROM:
action -1, numVisits=32049, meanQ=2.947099, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.509972 0.861954 0.186524 0.324865 0.696935 0.821187 w: 1
Observation: 0 0.472345 0 0.279576 0 0.712278 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32026, meanQ=5.018837, numObservations: 5
action 2, numVisits=17, meanQ=0.512365, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55404 episodes
GETTING ACTION FROM:
action 1, numVisits=55405, meanQ=5.161843, numObservations: 3
action 3, numVisits=32026, meanQ=5.018837, numObservations: 5
action 2, numVisits=17, meanQ=0.512365, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.509972 0.861954 0.186524 0.324865 0.696935 0.821187 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 38
Initial state: 0 0.521386 0.962692 0.634745 0.822866 0.578289 0.825798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54066 episodes
GETTING ACTION FROM:
action 3, numVisits=53954, meanQ=5.032562, numObservations: 5
action -1, numVisits=61, meanQ=4.154366, numObservations: 1
action 0, numVisits=49, meanQ=4.057852, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.521386 0.962692 0.634745 0.822866 0.578289 0.825798 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 39
Initial state: 0 0.670843 0.819201 0.666978 0.835904 0.138886 0.946869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54370 episodes
GETTING ACTION FROM:
action 2, numVisits=54364, meanQ=4.932303, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.670843 0.819201 0.666978 0.835904 0.138886 0.946869 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 40
Initial state: 0 0.327874 0.177143 0.641122 0.892026 0.695749 0.858585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54589 episodes
GETTING ACTION FROM:
action 3, numVisits=54566, meanQ=5.003610, numObservations: 5
action 1, numVisits=18, meanQ=1.279472, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.327874 0.177143 0.641122 0.892026 0.695749 0.858585 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 41
Initial state: 0 0.559378 0.843178 0.698118 0.817822 0.227128 0.0900131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54422 episodes
GETTING ACTION FROM:
action 3, numVisits=54411, meanQ=4.952301, numObservations: 4
action 2, numVisits=6, meanQ=1.498333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.559378 0.843178 0.698118 0.817822 0.227128 0.0900131 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7707, meanQ=8.394114, numObservations: 5
action 1, numVisits=8, meanQ=5.748762, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 18661 episodes
GETTING ACTION FROM:
action 2, numVisits=24529, meanQ=6.689602, numObservations: 5
action 1, numVisits=121, meanQ=5.626531, numObservations: 4
action -1, numVisits=1636, meanQ=0.184535, numObservations: 1
action 0, numVisits=92, meanQ=-0.436948, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.559378 0.843178 0.698118 0.817822 0.227128 0.0900131 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 42
Initial state: 0 0.670185 0.813266 0.830266 0.490827 0.598202 0.873543 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52026 episodes
GETTING ACTION FROM:
action 3, numVisits=52019, meanQ=4.805801, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.670185 0.813266 0.830266 0.490827 0.598202 0.873543 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 43
Initial state: 0 0.632315 0.821976 0.559125 0.849998 0.432684 0.0986081 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32027 episodes
GETTING ACTION FROM:
action -1, numVisits=31971, meanQ=2.921997, numObservations: 1
action 1, numVisits=23, meanQ=1.388709, numObservations: 4
action 3, numVisits=17, meanQ=1.005882, numObservations: 3
action 2, numVisits=14, meanQ=0.641429, numObservations: 4
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: -1
Next state: 0 0.632315 0.821976 0.559125 0.849998 0.432684 0.0986081 w: 1
Observation: 0 0.676235 0 0.583 0 0.357402 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31934, meanQ=5.003182, numObservations: 4
action 1, numVisits=24, meanQ=3.249171, numObservations: 3
action -1, numVisits=9, meanQ=2.730000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55086 episodes
GETTING ACTION FROM:
action 2, numVisits=87019, meanQ=5.060316, numObservations: 4
action 1, numVisits=24, meanQ=3.249171, numObservations: 3
action -1, numVisits=10, meanQ=2.091670, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.632315 0.821976 0.559125 0.849998 0.432684 0.0986081 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 44
Initial state: 0 0.205531 0.407758 0.600041 0.894668 0.580855 0.855985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54634 episodes
GETTING ACTION FROM:
action 3, numVisits=54615, meanQ=5.012502, numObservations: 3
action 1, numVisits=8, meanQ=2.126275, numObservations: 2
action 2, numVisits=7, meanQ=1.428571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.205531 0.407758 0.600041 0.894668 0.580855 0.855985 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 45
Initial state: 0 0.695621 0.817996 0.259597 0.246933 0.541413 0.870839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54285 episodes
GETTING ACTION FROM:
action 2, numVisits=54232, meanQ=5.008923, numObservations: 5
action 0, numVisits=49, meanQ=4.083725, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.695621 0.817996 0.259597 0.246933 0.541413 0.870839 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6196, meanQ=8.555671, numObservations: 3
action 1, numVisits=3, meanQ=4.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 17551 episodes
GETTING ACTION FROM:
action 3, numVisits=18842, meanQ=6.672256, numObservations: 4
action 1, numVisits=10, meanQ=1.799000, numObservations: 3
action 0, numVisits=4892, meanQ=0.298326, numObservations: 1
action -1, numVisits=8, meanQ=-2.001238, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.695621 0.817996 0.259597 0.246933 0.541413 0.870839 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 46
Initial state: 0 0.940128 0.10977 0.650236 0.839078 0.506419 0.829261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54488 episodes
GETTING ACTION FROM:
action 1, numVisits=54457, meanQ=4.977668, numObservations: 5
action -1, numVisits=27, meanQ=3.674396, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.940128 0.10977 0.650236 0.839078 0.506419 0.829261 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3971, meanQ=5.479079, numObservations: 4
action 3, numVisits=6, meanQ=2.983333, numObservations: 3
action 2, numVisits=8, meanQ=2.498750, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 26818 episodes
GETTING ACTION FROM:
action 3, numVisits=18099, meanQ=5.866185, numObservations: 4
action 2, numVisits=7714, meanQ=5.846225, numObservations: 5
action 1, numVisits=3971, meanQ=5.479079, numObservations: 4
action 0, numVisits=1019, meanQ=0.248145, numObservations: 1
action -1, numVisits=2, meanQ=-197.564208, numObservations: 1
action: 3
Next state: 1 0.940128 0.10977 0.650236 0.839078 0.506419 0.829261 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 47
Initial state: 0 0.602649 0.886298 0.110659 0.564323 0.686512 0.848935 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54877 episodes
GETTING ACTION FROM:
action 2, numVisits=54798, meanQ=5.051507, numObservations: 5
action 0, numVisits=66, meanQ=4.259738, numObservations: 1
action 1, numVisits=7, meanQ=2.570000, numObservations: 2
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.602649 0.886298 0.110659 0.564323 0.686512 0.848935 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7829, meanQ=8.364397, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 20117 episodes
GETTING ACTION FROM:
action 3, numVisits=26926, meanQ=6.909967, numObservations: 5
action 1, numVisits=12, meanQ=2.037455, numObservations: 2
action 0, numVisits=1004, meanQ=0.157490, numObservations: 1
action -1, numVisits=8, meanQ=-2.126225, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.602649 0.886298 0.110659 0.564323 0.686512 0.848935 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 48
Initial state: 0 0.524855 0.892364 0.52475 0.803032 0.883215 0.940225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54637 episodes
GETTING ACTION FROM:
action 2, numVisits=54576, meanQ=5.002866, numObservations: 5
action -1, numVisits=55, meanQ=4.085445, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.524855 0.892364 0.52475 0.803032 0.883215 0.940225 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 49
Initial state: 0 0.550562 0.893649 0.53462 0.821497 0.899603 0.216537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51362 episodes
GETTING ACTION FROM:
action 1, numVisits=46720, meanQ=4.945823, numObservations: 4
action -1, numVisits=2332, meanQ=3.114159, numObservations: 1
action 0, numVisits=2275, meanQ=3.112754, numObservations: 1
action 3, numVisits=27, meanQ=1.995933, numObservations: 4
action 2, numVisits=8, meanQ=0.625012, numObservations: 3
action: 1
Next state: 1 0.550562 0.893649 0.53462 0.821497 0.899603 0.216537 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 50
Initial state: 0 0.597359 0.852407 0.193453 0.299852 0.575204 0.874802 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54361 episodes
GETTING ACTION FROM:
action 1, numVisits=50705, meanQ=4.995154, numObservations: 4
action 2, numVisits=3621, meanQ=4.906931, numObservations: 4
action 0, numVisits=25, meanQ=3.682244, numObservations: 1
action 3, numVisits=8, meanQ=1.863750, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.597359 0.852407 0.193453 0.299852 0.575204 0.874802 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 51
Initial state: 0 0.533332 0.855418 0.565036 0.820137 0.28704 0.490198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51222 episodes
GETTING ACTION FROM:
action 3, numVisits=46679, meanQ=4.982645, numObservations: 5
action -1, numVisits=4448, meanQ=2.921251, numObservations: 1
action 0, numVisits=93, meanQ=2.404395, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.533332 0.855418 0.565036 0.820137 0.28704 0.490198 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1120, meanQ=7.742139, numObservations: 3
action 1, numVisits=52, meanQ=6.845585, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 21293 episodes
GETTING ACTION FROM:
action 2, numVisits=1153, meanQ=7.715571, numObservations: 3
action 1, numVisits=21303, meanQ=6.053893, numObservations: 4
action 0, numVisits=9, meanQ=-2.112200, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.533332 0.855418 0.565036 0.820137 0.28704 0.490198 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 52
Initial state: 0 0.157601 0.990529 0.66551 0.87672 0.529137 0.823324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54336 episodes
GETTING ACTION FROM:
action 1, numVisits=54323, meanQ=5.108204, numObservations: 5
action 3, numVisits=8, meanQ=1.878775, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.157601 0.990529 0.66551 0.87672 0.529137 0.823324 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3613, meanQ=7.387885, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 59493 episodes
GETTING ACTION FROM:
action 1, numVisits=63104, meanQ=5.228862, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.157601 0.990529 0.66551 0.87672 0.529137 0.823324 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 53
Initial state: 0 0.668101 0.880205 0.5405 0.824992 0.321805 0.88266 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53800 episodes
GETTING ACTION FROM:
action 1, numVisits=53632, meanQ=4.951670, numObservations: 4
action -1, numVisits=161, meanQ=4.454354, numObservations: 1
action 3, numVisits=4, meanQ=0.750000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.668101 0.880205 0.5405 0.824992 0.321805 0.88266 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 54
Initial state: 0 0.631582 0.868669 0.815495 0.00626184 0.570767 0.861663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54394 episodes
GETTING ACTION FROM:
action 1, numVisits=54388, meanQ=4.917606, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.631582 0.868669 0.815495 0.00626184 0.570767 0.861663 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 55
Initial state: 0 0.283382 0.967533 0.590566 0.823519 0.615722 0.827397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54558 episodes
GETTING ACTION FROM:
action 2, numVisits=54520, meanQ=5.035706, numObservations: 3
action -1, numVisits=34, meanQ=3.919077, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.283382 0.967533 0.590566 0.823519 0.615722 0.827397 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3900, meanQ=5.552799, numObservations: 3
action 1, numVisits=8, meanQ=2.498750, numObservations: 3
action 3, numVisits=14, meanQ=2.135721, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 60048 episodes
GETTING ACTION FROM:
action 2, numVisits=63946, meanQ=5.189463, numObservations: 4
action 1, numVisits=8, meanQ=2.498750, numObservations: 3
action 3, numVisits=14, meanQ=2.135721, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.283382 0.967533 0.590566 0.823519 0.615722 0.827397 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 56
Initial state: 0 0.501404 0.838267 0.639959 0.821565 0.760028 0.289163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54953 episodes
GETTING ACTION FROM:
action 1, numVisits=54886, meanQ=5.072666, numObservations: 5
action 3, numVisits=45, meanQ=3.808000, numObservations: 3
action -1, numVisits=15, meanQ=3.169615, numObservations: 1
action 2, numVisits=5, meanQ=-0.399980, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.501404 0.838267 0.639959 0.821565 0.760028 0.289163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3409, meanQ=5.770308, numObservations: 4
action 3, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 59851 episodes
GETTING ACTION FROM:
action 1, numVisits=63253, meanQ=5.001033, numObservations: 4
action 3, numVisits=10, meanQ=2.598000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.501404 0.838267 0.639959 0.821565 0.760028 0.289163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 57
Initial state: 0 0.590793 0.878179 0.593567 0.828747 0.705078 0.150692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51740 episodes
GETTING ACTION FROM:
action 3, numVisits=51719, meanQ=4.898222, numObservations: 5
action 2, numVisits=16, meanQ=2.311894, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.590793 0.878179 0.593567 0.828747 0.705078 0.150692 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 58
Initial state: 0 0.563194 0.804244 0.6528 0.881686 0.379164 0.509512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52761 episodes
GETTING ACTION FROM:
action 2, numVisits=52755, meanQ=4.893145, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.563194 0.804244 0.6528 0.881686 0.379164 0.509512 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 59
Initial state: 0 0.608509 0.838662 0.624063 0.821777 0.720532 0.13408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54284 episodes
GETTING ACTION FROM:
action 2, numVisits=54275, meanQ=4.942544, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.608509 0.838662 0.624063 0.821777 0.720532 0.13408 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 60
Initial state: 0 0.523928 0.805411 0.650045 0.843125 0.855544 0.694672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54882 episodes
GETTING ACTION FROM:
action 1, numVisits=54867, meanQ=5.035849, numObservations: 4
action -1, numVisits=11, meanQ=2.949550, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.523928 0.805411 0.650045 0.843125 0.855544 0.694672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 61
Initial state: 0 0.54029 0.85293 0.628667 0.879891 0.257053 0.811379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54472 episodes
GETTING ACTION FROM:
action 1, numVisits=54454, meanQ=4.962453, numObservations: 5
action 2, numVisits=13, meanQ=2.998469, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.54029 0.85293 0.628667 0.879891 0.257053 0.811379 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 62
Initial state: 0 0.271242 0.0439462 0.565565 0.871015 0.689304 0.806248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54303 episodes
GETTING ACTION FROM:
action 1, numVisits=54288, meanQ=4.933580, numObservations: 5
action 3, numVisits=9, meanQ=1.666667, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.271242 0.0439462 0.565565 0.871015 0.689304 0.806248 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 63
Initial state: 0 0.541525 0.852435 0.573408 0.867954 0.720819 0.906188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54418 episodes
GETTING ACTION FROM:
action 3, numVisits=54370, meanQ=4.980918, numObservations: 4
action 1, numVisits=33, meanQ=3.697282, numObservations: 3
action 0, numVisits=12, meanQ=2.757256, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.541525 0.852435 0.573408 0.867954 0.720819 0.906188 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 64
Initial state: 0 0.629077 0.852776 0.896767 0.803422 0.587442 0.836354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52855 episodes
GETTING ACTION FROM:
action 3, numVisits=52798, meanQ=5.036028, numObservations: 5
action -1, numVisits=46, meanQ=4.075852, numObservations: 1
action 2, numVisits=8, meanQ=1.376263, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.629077 0.852776 0.896767 0.803422 0.587442 0.836354 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 65
Initial state: 0 0.931728 0.295044 0.668207 0.843518 0.67065 0.859074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54803 episodes
GETTING ACTION FROM:
action 1, numVisits=54514, meanQ=5.050622, numObservations: 4
action -1, numVisits=136, meanQ=4.484260, numObservations: 1
action 2, numVisits=134, meanQ=4.450300, numObservations: 4
action 3, numVisits=17, meanQ=2.935300, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.931728 0.295044 0.668207 0.843518 0.67065 0.859074 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 66
Initial state: 0 0.596354 0.819331 0.587964 0.853523 0.641523 0.500603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54358 episodes
GETTING ACTION FROM:
action 2, numVisits=54114, meanQ=4.953846, numObservations: 4
action -1, numVisits=226, meanQ=4.540941, numObservations: 1
action 1, numVisits=9, meanQ=1.901122, numObservations: 3
action 3, numVisits=7, meanQ=0.428586, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.596354 0.819331 0.587964 0.853523 0.641523 0.500603 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 67
Initial state: 0 0.168068 0.509304 0.631881 0.848269 0.548862 0.849648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54420 episodes
GETTING ACTION FROM:
action 3, numVisits=54413, meanQ=4.956105, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.168068 0.509304 0.631881 0.848269 0.548862 0.849648 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 68
Initial state: 0 0.775197 0.240408 0.534354 0.85471 0.652907 0.82623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54267 episodes
GETTING ACTION FROM:
action 3, numVisits=54261, meanQ=4.947665, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.775197 0.240408 0.534354 0.85471 0.652907 0.82623 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 69
Initial state: 0 0.844861 0.720439 0.570847 0.850786 0.689063 0.879986 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31363 episodes
GETTING ACTION FROM:
action 0, numVisits=31358, meanQ=2.853564, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.844861 0.720439 0.570847 0.850786 0.689063 0.879986 w: 1
Observation: 0 0 0.647155 0 0.905484 0 0.848735 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31351, meanQ=4.900042, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 54062 episodes
GETTING ACTION FROM:
action 3, numVisits=18480, meanQ=4.879221, numObservations: 4
action 1, numVisits=66934, meanQ=4.820145, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.844861 0.720439 0.570847 0.850786 0.689063 0.879986 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 70
Initial state: 0 0.214482 0.83552 0.614496 0.833874 0.606844 0.87928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54354 episodes
GETTING ACTION FROM:
action 2, numVisits=54220, meanQ=4.908138, numObservations: 5
action 0, numVisits=104, meanQ=4.287097, numObservations: 1
action 1, numVisits=21, meanQ=2.368100, numObservations: 3
action 3, numVisits=7, meanQ=2.285729, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.214482 0.83552 0.614496 0.833874 0.606844 0.87928 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 71
Initial state: 0 0.632643 0.808475 0.634101 0.895203 0.260966 0.321869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54420 episodes
GETTING ACTION FROM:
action 1, numVisits=54412, meanQ=4.960259, numObservations: 4
action -1, numVisits=3, meanQ=-2.996600, numObservations: 1
action 0, numVisits=3, meanQ=-2.996600, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.632643 0.808475 0.634101 0.895203 0.260966 0.321869 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 72
Initial state: 0 0.665339 0.832404 0.516076 0.830556 0.476688 0.0445909 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31106 episodes
GETTING ACTION FROM:
action -1, numVisits=31097, meanQ=2.900265, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.665339 0.832404 0.516076 0.830556 0.476688 0.0445909 w: 1
Observation: 0 0.601887 0 0.550425 0 0.435394 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30956, meanQ=4.865717, numObservations: 4
action -1, numVisits=122, meanQ=4.314639, numObservations: 1
action 0, numVisits=14, meanQ=3.046982, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 53047 episodes
GETTING ACTION FROM:
action 3, numVisits=84002, meanQ=5.044413, numObservations: 4
action -1, numVisits=123, meanQ=4.304036, numObservations: 1
action 0, numVisits=14, meanQ=3.046982, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.665339 0.832404 0.516076 0.830556 0.476688 0.0445909 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=12991, meanQ=8.237667, numObservations: 4
action 1, numVisits=34, meanQ=6.355888, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 41239 episodes
GETTING ACTION FROM:
action 2, numVisits=53770, meanQ=6.484932, numObservations: 4
action 1, numVisits=34, meanQ=6.355888, numObservations: 3
action -1, numVisits=269, meanQ=-0.958116, numObservations: 1
action 0, numVisits=193, meanQ=-1.027691, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.665339 0.832404 0.516076 0.830556 0.476688 0.0445909 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 73
Initial state: 0 0.678759 0.818121 0.520846 0.889089 0.968315 0.088736 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54859 episodes
GETTING ACTION FROM:
action 3, numVisits=54838, meanQ=5.062609, numObservations: 4
action 2, numVisits=16, meanQ=2.243750, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.678759 0.818121 0.520846 0.889089 0.968315 0.088736 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 74
Initial state: 0 0.673796 0.507416 0.649079 0.831902 0.534243 0.801483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54966 episodes
GETTING ACTION FROM:
action 3, numVisits=54958, meanQ=5.031182, numObservations: 5
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.673796 0.507416 0.649079 0.831902 0.534243 0.801483 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 75
Initial state: 0 0.479647 0.80388 0.688345 0.833547 0.6002 0.843096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54603 episodes
GETTING ACTION FROM:
action 1, numVisits=53987, meanQ=4.956519, numObservations: 4
action 3, numVisits=517, meanQ=4.637223, numObservations: 4
action -1, numVisits=96, meanQ=4.279439, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.479647 0.80388 0.688345 0.833547 0.6002 0.843096 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 76
Initial state: 0 0.640285 0.894002 0.673159 0.835673 0.42836 0.997791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51843 episodes
GETTING ACTION FROM:
action 3, numVisits=51808, meanQ=4.812166, numObservations: 5
action 0, numVisits=24, meanQ=3.398516, numObservations: 1
action 1, numVisits=8, meanQ=2.375000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.640285 0.894002 0.673159 0.835673 0.42836 0.997791 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1267, meanQ=7.578551, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 21789 episodes
GETTING ACTION FROM:
action 1, numVisits=5354, meanQ=6.481140, numObservations: 4
action 2, numVisits=16834, meanQ=6.031725, numObservations: 4
action 0, numVisits=579, meanQ=-0.074715, numObservations: 1
action -1, numVisits=292, meanQ=-0.169818, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.640285 0.894002 0.673159 0.835673 0.42836 0.997791 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 77
Initial state: 0 0.568394 0.80194 0.653299 0.80656 0.406481 0.0636619 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32035 episodes
GETTING ACTION FROM:
action 0, numVisits=32029, meanQ=2.951167, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.568394 0.80194 0.653299 0.80656 0.406481 0.0636619 w: 1
Observation: 0 0 0.719464 0 0.810112 0 0.0541573 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31989, meanQ=5.001304, numObservations: 4
action -1, numVisits=28, meanQ=3.801239, numObservations: 1
action 2, numVisits=8, meanQ=2.498750, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54185 episodes
GETTING ACTION FROM:
action 3, numVisits=86169, meanQ=4.769050, numObservations: 4
action -1, numVisits=32, meanQ=3.571361, numObservations: 1
action 2, numVisits=9, meanQ=1.886667, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.568394 0.80194 0.653299 0.80656 0.406481 0.0636619 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=12422, meanQ=8.399293, numObservations: 4
action 1, numVisits=4, meanQ=2.002525, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30367 episodes
GETTING ACTION FROM:
action 2, numVisits=42637, meanQ=6.711507, numObservations: 4
action 1, numVisits=11, meanQ=2.819100, numObservations: 3
action 0, numVisits=142, meanQ=0.685590, numObservations: 1
action -1, numVisits=5, meanQ=-1.802000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.568394 0.80194 0.653299 0.80656 0.406481 0.0636619 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 78
Initial state: 0 0.995966 0.740786 0.559129 0.840493 0.561893 0.886593 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54265 episodes
GETTING ACTION FROM:
action 1, numVisits=54257, meanQ=4.963254, numObservations: 4
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.995966 0.740786 0.559129 0.840493 0.561893 0.886593 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 79
Initial state: 0 0.471549 0.18398 0.604968 0.846995 0.654664 0.88966 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54579 episodes
GETTING ACTION FROM:
action 3, numVisits=54571, meanQ=5.005890, numObservations: 4
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.471549 0.18398 0.604968 0.846995 0.654664 0.88966 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 80
Initial state: 0 0.568861 0.815534 0.802925 0.376235 0.59883 0.824489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31926 episodes
GETTING ACTION FROM:
action 0, numVisits=31917, meanQ=2.883545, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.568861 0.815534 0.802925 0.376235 0.59883 0.824489 w: 1
Observation: 0 0 0.797833 0 0.323665 0 0.76469 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31905, meanQ=4.962807, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 54591 episodes
GETTING ACTION FROM:
action 1, numVisits=86491, meanQ=4.942442, numObservations: 5
action 2, numVisits=9, meanQ=0.998889, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.568861 0.815534 0.802925 0.376235 0.59883 0.824489 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 81
Initial state: 0 0.611495 0.820097 0.398346 0.778018 0.646589 0.861595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54414 episodes
GETTING ACTION FROM:
action 2, numVisits=54408, meanQ=4.943554, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.611495 0.820097 0.398346 0.778018 0.646589 0.861595 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7544, meanQ=8.422839, numObservations: 3
action 1, numVisits=10, meanQ=6.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 37676 episodes
GETTING ACTION FROM:
action 1, numVisits=44, meanQ=6.454095, numObservations: 4
action 3, numVisits=45079, meanQ=6.329410, numObservations: 3
action -1, numVisits=102, meanQ=-0.068529, numObservations: 1
action 0, numVisits=7, meanQ=-2.001414, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.611495 0.820097 0.398346 0.778018 0.646589 0.861595 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 82
Initial state: 0 0.539003 0.876476 0.588981 0.837479 0.461628 0.250122 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54986 episodes
GETTING ACTION FROM:
action 1, numVisits=54975, meanQ=5.018137, numObservations: 4
action 3, numVisits=6, meanQ=1.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.539003 0.876476 0.588981 0.837479 0.461628 0.250122 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 83
Initial state: 0 0.669895 0.80253 0.422324 0.733274 0.54251 0.850502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54675 episodes
GETTING ACTION FROM:
action 2, numVisits=54647, meanQ=4.931026, numObservations: 4
action -1, numVisits=17, meanQ=3.263880, numObservations: 1
action 1, numVisits=8, meanQ=2.375000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.669895 0.80253 0.422324 0.733274 0.54251 0.850502 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2657, meanQ=7.765254, numObservations: 3
action 3, numVisits=56, meanQ=7.066071, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 20822 episodes
GETTING ACTION FROM:
action 1, numVisits=6815, meanQ=6.554744, numObservations: 3
action 3, numVisits=15645, meanQ=6.187040, numObservations: 5
action 0, numVisits=1070, meanQ=0.448150, numObservations: 2
action -1, numVisits=7, meanQ=-1.858571, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.669895 0.80253 0.422324 0.733274 0.54251 0.850502 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 84
Initial state: 0 0.546886 0.842078 0.0379672 0.370866 0.560746 0.835561 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54561 episodes
GETTING ACTION FROM:
action 2, numVisits=54422, meanQ=4.909243, numObservations: 4
action -1, numVisits=135, meanQ=4.353785, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.546886 0.842078 0.0379672 0.370866 0.560746 0.835561 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8912, meanQ=8.277954, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 17453 episodes
GETTING ACTION FROM:
action 3, numVisits=26250, meanQ=6.591560, numObservations: 4
action 0, numVisits=102, meanQ=-1.030259, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=14, meanQ=-2.143550, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.546886 0.842078 0.0379672 0.370866 0.560746 0.835561 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 85
Initial state: 0 0.693844 0.804042 0.53265 0.870623 0.462387 0.553626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54438 episodes
GETTING ACTION FROM:
action 1, numVisits=54310, meanQ=5.056148, numObservations: 4
action -1, numVisits=109, meanQ=4.438657, numObservations: 1
action 0, numVisits=17, meanQ=3.448198, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.693844 0.804042 0.53265 0.870623 0.462387 0.553626 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 86
Initial state: 0 0.505507 0.865027 0.379581 0.406616 0.55215 0.892619 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53814 episodes
GETTING ACTION FROM:
action 2, numVisits=53770, meanQ=5.037254, numObservations: 4
action -1, numVisits=22, meanQ=3.596233, numObservations: 1
action 1, numVisits=19, meanQ=3.521584, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.505507 0.865027 0.379581 0.406616 0.55215 0.892619 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6205, meanQ=8.524040, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 21613 episodes
GETTING ACTION FROM:
action 3, numVisits=26330, meanQ=6.491583, numObservations: 4
action 1, numVisits=12, meanQ=2.144217, numObservations: 3
action 0, numVisits=1368, meanQ=-0.465379, numObservations: 1
action -1, numVisits=111, meanQ=-1.182349, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.505507 0.865027 0.379581 0.406616 0.55215 0.892619 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 87
Initial state: 0 0.0414934 0.64059 0.58031 0.814404 0.608622 0.82018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54348 episodes
GETTING ACTION FROM:
action 2, numVisits=54332, meanQ=4.981335, numObservations: 4
action 3, numVisits=9, meanQ=2.554444, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.0414934 0.64059 0.58031 0.814404 0.608622 0.82018 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 88
Initial state: 0 0.838723 0.651265 0.654191 0.894932 0.600874 0.845052 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54401 episodes
GETTING ACTION FROM:
action 1, numVisits=54394, meanQ=4.973053, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.838723 0.651265 0.654191 0.894932 0.600874 0.845052 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 89
Initial state: 0 0.88056 0.319271 0.543286 0.897648 0.541787 0.805128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53912 episodes
GETTING ACTION FROM:
action 2, numVisits=53878, meanQ=4.963367, numObservations: 4
action 1, numVisits=23, meanQ=3.391752, numObservations: 4
action 3, numVisits=7, meanQ=2.002871, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.88056 0.319271 0.543286 0.897648 0.541787 0.805128 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 90
Initial state: 0 0.544229 0.814709 0.489316 0.939406 0.564112 0.846411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 35931 episodes
GETTING ACTION FROM:
action 0, numVisits=29874, meanQ=5.869703, numObservations: 3
action 1, numVisits=6052, meanQ=4.815539, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.544229 0.814709 0.489316 0.939406 0.564112 0.846411 w: 1
Observation: 0 0 0.912486 0 0.958049 0 0.843537 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=11445, meanQ=7.702664, numObservations: 4
action 2, numVisits=7, meanQ=4.427143, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55989 episodes
GETTING ACTION FROM:
action 1, numVisits=67310, meanQ=5.866955, numObservations: 4
action 2, numVisits=131, meanQ=5.280137, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.544229 0.814709 0.489316 0.939406 0.564112 0.846411 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 91
Initial state: 0 0.639645 0.845188 0.596102 0.811915 0.333726 0.0861583 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31945 episodes
GETTING ACTION FROM:
action 0, numVisits=31938, meanQ=2.931004, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action: 0
Next state: 0 0.639645 0.845188 0.596102 0.811915 0.333726 0.0861583 w: 1
Observation: 0 0 0.844221 0 0.900156 0 0.176471 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31860, meanQ=4.990843, numObservations: 5
action -1, numVisits=73, meanQ=4.249355, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 54852 episodes
GETTING ACTION FROM:
action 2, numVisits=86711, meanQ=5.108186, numObservations: 5
action -1, numVisits=74, meanQ=4.228855, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.639645 0.845188 0.596102 0.811915 0.333726 0.0861583 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 92
Initial state: 0 0.527464 0.836534 0.596629 0.810064 0.165643 0.760619 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54383 episodes
GETTING ACTION FROM:
action 1, numVisits=54375, meanQ=5.101850, numObservations: 4
action 2, numVisits=3, meanQ=0.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.527464 0.836534 0.596629 0.810064 0.165643 0.760619 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 93
Initial state: 0 0.338145 0.472008 0.505855 0.844833 0.667442 0.877475 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50458 episodes
GETTING ACTION FROM:
action 3, numVisits=50415, meanQ=4.883072, numObservations: 4
action 0, numVisits=34, meanQ=3.745191, numObservations: 1
action 1, numVisits=6, meanQ=1.166683, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.338145 0.472008 0.505855 0.844833 0.667442 0.877475 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 94
Initial state: 0 0.171022 0.611503 0.608622 0.895209 0.581016 0.806161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52198 episodes
GETTING ACTION FROM:
action 2, numVisits=52121, meanQ=5.011950, numObservations: 5
action -1, numVisits=53, meanQ=4.101062, numObservations: 1
action 3, numVisits=21, meanQ=3.562390, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.171022 0.611503 0.608622 0.895209 0.581016 0.806161 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 95
Initial state: 0 0.603419 0.850143 0.651503 0.868951 0.292146 0.415391 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54732 episodes
GETTING ACTION FROM:
action 1, numVisits=54725, meanQ=4.977092, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.603419 0.850143 0.651503 0.868951 0.292146 0.415391 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 96
Initial state: 0 0.590752 0.821182 0.32632 0.681917 0.532653 0.807533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53488 episodes
GETTING ACTION FROM:
action 1, numVisits=53469, meanQ=4.944626, numObservations: 5
action 3, numVisits=9, meanQ=1.776667, numObservations: 3
action 2, numVisits=6, meanQ=1.166683, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.590752 0.821182 0.32632 0.681917 0.532653 0.807533 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 97
Initial state: 0 0.60012 0.822767 0.628269 0.860085 0.376709 0.187819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54513 episodes
GETTING ACTION FROM:
action 2, numVisits=54470, meanQ=4.949257, numObservations: 4
action 0, numVisits=34, meanQ=3.801933, numObservations: 1
action 3, numVisits=6, meanQ=0.836683, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.60012 0.822767 0.628269 0.860085 0.376709 0.187819 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 98
Initial state: 0 0.318317 0.0570723 0.50538 0.809611 0.608675 0.881262 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54230 episodes
GETTING ACTION FROM:
action 2, numVisits=54224, meanQ=4.918087, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.318317 0.0570723 0.50538 0.809611 0.608675 0.881262 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 99
Initial state: 0 0.500195 0.842548 0.260761 0.955179 0.657484 0.869706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54378 episodes
GETTING ACTION FROM:
action 1, numVisits=54372, meanQ=5.015346, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.500195 0.842548 0.260761 0.955179 0.657484 0.869706 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 100
Initial state: 0 0.634297 0.810277 0.309881 0.0305055 0.553411 0.893645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31868 episodes
GETTING ACTION FROM:
action -1, numVisits=31854, meanQ=2.908501, numObservations: 1
action 2, numVisits=8, meanQ=0.625012, numObservations: 3
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.634297 0.810277 0.309881 0.0305055 0.553411 0.893645 w: 1
Observation: 0 0.67727 0 0.263681 0 0.465328 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31787, meanQ=4.979795, numObservations: 5
action 2, numVisits=56, meanQ=1.952684, numObservations: 3
action 1, numVisits=6, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 55415 episodes
GETTING ACTION FROM:
action 3, numVisits=87202, meanQ=5.013526, numObservations: 5
action 2, numVisits=56, meanQ=1.952684, numObservations: 3
action 1, numVisits=6, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.634297 0.810277 0.309881 0.0305055 0.553411 0.893645 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 101
Initial state: 0 0.620961 0.861982 0.88882 0.238817 0.656715 0.833465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54561 episodes
GETTING ACTION FROM:
action 3, numVisits=54543, meanQ=5.049847, numObservations: 3
action 1, numVisits=13, meanQ=1.070000, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.620961 0.861982 0.88882 0.238817 0.656715 0.833465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 102
Initial state: 0 0.654908 0.849163 0.505921 0.0362733 0.564378 0.83019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53973 episodes
GETTING ACTION FROM:
action 2, numVisits=53967, meanQ=4.944546, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.654908 0.849163 0.505921 0.0362733 0.564378 0.83019 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 103
Initial state: 0 0.534789 0.865005 0.535827 0.840176 0.841453 0.635227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31937 episodes
GETTING ACTION FROM:
action -1, numVisits=31758, meanQ=2.808858, numObservations: 1
action 0, numVisits=170, meanQ=2.342405, numObservations: 1
action 1, numVisits=7, meanQ=-0.871429, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.534789 0.865005 0.535827 0.840176 0.841453 0.635227 w: 1
Observation: 0 0.60058 0 0.455385 0 0.924547 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31676, meanQ=4.906076, numObservations: 5
action 0, numVisits=56, meanQ=4.015070, numObservations: 1
action -1, numVisits=18, meanQ=3.395786, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=3, meanQ=0.330033, numObservations: 1
Sampled 54959 episodes
GETTING ACTION FROM:
action 3, numVisits=86634, meanQ=5.052781, numObservations: 5
action 0, numVisits=56, meanQ=4.015070, numObservations: 1
action -1, numVisits=19, meanQ=3.268039, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=3, meanQ=0.330033, numObservations: 1
action: 3
Next state: 2 0.534789 0.865005 0.535827 0.840176 0.841453 0.635227 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 104
Initial state: 0 0.601067 0.874996 0.120421 0.563231 0.609283 0.879357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54211 episodes
GETTING ACTION FROM:
action 1, numVisits=54146, meanQ=4.991339, numObservations: 5
action -1, numVisits=29, meanQ=3.782052, numObservations: 1
action 0, numVisits=24, meanQ=3.662138, numObservations: 1
action 2, numVisits=11, meanQ=1.998182, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.601067 0.874996 0.120421 0.563231 0.609283 0.879357 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 105
Initial state: 0 0.573834 0.849351 0.267164 0.671937 0.57307 0.872511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54758 episodes
GETTING ACTION FROM:
action 3, numVisits=54672, meanQ=5.021127, numObservations: 4
action -1, numVisits=43, meanQ=4.021369, numObservations: 1
action 0, numVisits=41, meanQ=3.996367, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.573834 0.849351 0.267164 0.671937 0.57307 0.872511 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4070, meanQ=5.592629, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 60696 episodes
GETTING ACTION FROM:
action 3, numVisits=64764, meanQ=4.917242, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.573834 0.849351 0.267164 0.671937 0.57307 0.872511 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 106
Initial state: 0 0.664341 0.870011 0.519474 0.810941 0.999007 0.970165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54652 episodes
GETTING ACTION FROM:
action 2, numVisits=54588, meanQ=4.991964, numObservations: 5
action -1, numVisits=44, meanQ=3.995339, numObservations: 1
action 3, numVisits=8, meanQ=2.375000, numObservations: 2
action 1, numVisits=10, meanQ=2.102010, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.664341 0.870011 0.519474 0.810941 0.999007 0.970165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 107
Initial state: 0 0.0648123 0.418685 0.604672 0.815977 0.609975 0.841627 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54231 episodes
GETTING ACTION FROM:
action 3, numVisits=54214, meanQ=4.952119, numObservations: 4
action 2, numVisits=12, meanQ=1.998333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.0648123 0.418685 0.604672 0.815977 0.609975 0.841627 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 108
Initial state: 0 0.654483 0.856171 0.524891 0.821169 0.384537 0.221445 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52210 episodes
GETTING ACTION FROM:
action 3, numVisits=52178, meanQ=4.868747, numObservations: 4
action -1, numVisits=28, meanQ=3.598032, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.654483 0.856171 0.524891 0.821169 0.384537 0.221445 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8524, meanQ=8.335787, numObservations: 4
action 2, numVisits=44, meanQ=7.406598, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 20192 episodes
GETTING ACTION FROM:
action 1, numVisits=20381, meanQ=6.896634, numObservations: 4
action 2, numVisits=7725, meanQ=5.920479, numObservations: 5
action 0, numVisits=645, meanQ=-0.322037, numObservations: 1
action -1, numVisits=11, meanQ=-2.182700, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.654483 0.856171 0.524891 0.821169 0.384537 0.221445 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 109
Initial state: 0 0.787412 0.714836 0.665345 0.878349 0.690145 0.852505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54696 episodes
GETTING ACTION FROM:
action 2, numVisits=54656, meanQ=4.979861, numObservations: 3
action -1, numVisits=33, meanQ=3.816082, numObservations: 1
action 3, numVisits=3, meanQ=0.663333, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.787412 0.714836 0.665345 0.878349 0.690145 0.852505 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 110
Initial state: 0 0.527547 0.832136 0.562222 0.915674 0.504783 0.836341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54249 episodes
GETTING ACTION FROM:
action 2, numVisits=54227, meanQ=4.893227, numObservations: 4
action 1, numVisits=10, meanQ=2.802010, numObservations: 3
action 3, numVisits=8, meanQ=1.863750, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.527547 0.832136 0.562222 0.915674 0.504783 0.836341 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 111
Initial state: 0 0.632759 0.882297 0.484392 0.303273 0.562996 0.839867 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54803 episodes
GETTING ACTION FROM:
action 3, numVisits=54796, meanQ=5.021029, numObservations: 5
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.632759 0.882297 0.484392 0.303273 0.562996 0.839867 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 112
Initial state: 0 0.515828 0.828972 0.509461 0.844395 0.702911 0.632795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54438 episodes
GETTING ACTION FROM:
action 2, numVisits=54391, meanQ=5.005451, numObservations: 4
action -1, numVisits=21, meanQ=3.433438, numObservations: 1
action 3, numVisits=20, meanQ=3.145505, numObservations: 3
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.515828 0.828972 0.509461 0.844395 0.702911 0.632795 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 113
Initial state: 0 0.639812 0.863861 0.646854 0.893374 0.861706 0.538368 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54840 episodes
GETTING ACTION FROM:
action 1, numVisits=54804, meanQ=5.032299, numObservations: 4
action -1, numVisits=31, meanQ=3.838257, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.639812 0.863861 0.646854 0.893374 0.861706 0.538368 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 114
Initial state: 0 0.406733 0.975964 0.658135 0.803879 0.695448 0.848585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54414 episodes
GETTING ACTION FROM:
action 1, numVisits=54379, meanQ=4.916792, numObservations: 4
action 0, numVisits=31, meanQ=3.736268, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.406733 0.975964 0.658135 0.803879 0.695448 0.848585 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3954, meanQ=4.652177, numObservations: 5
action -1, numVisits=89, meanQ=4.106740, numObservations: 1
action 1, numVisits=7, meanQ=0.995714, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 67755 episodes
GETTING ACTION FROM:
action 3, numVisits=71706, meanQ=5.565991, numObservations: 5
action -1, numVisits=92, meanQ=3.951127, numObservations: 1
action 1, numVisits=7, meanQ=0.995714, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.406733 0.975964 0.658135 0.803879 0.695448 0.848585 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 115
Initial state: 0 0.318027 0.25565 0.547705 0.862404 0.606455 0.855721 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54372 episodes
GETTING ACTION FROM:
action 2, numVisits=54361, meanQ=4.997922, numObservations: 5
action 1, numVisits=6, meanQ=1.498333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.318027 0.25565 0.547705 0.862404 0.606455 0.855721 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 116
Initial state: 0 0.683445 0.873428 0.513985 0.845886 0.575825 0.948869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53835 episodes
GETTING ACTION FROM:
action 2, numVisits=53202, meanQ=5.014167, numObservations: 5
action -1, numVisits=620, meanQ=2.729700, numObservations: 1
action 1, numVisits=10, meanQ=1.199000, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.683445 0.873428 0.513985 0.845886 0.575825 0.948869 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 117
Initial state: 0 0.0991673 0.145152 0.550545 0.892563 0.64853 0.827795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54718 episodes
GETTING ACTION FROM:
action 1, numVisits=54694, meanQ=5.024776, numObservations: 4
action 2, numVisits=18, meanQ=2.388339, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.0991673 0.145152 0.550545 0.892563 0.64853 0.827795 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5040, meanQ=8.259584, numObservations: 5
action 3, numVisits=3896, meanQ=8.251634, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 21553 episodes
GETTING ACTION FROM:
action 3, numVisits=13691, meanQ=6.883234, numObservations: 3
action 2, numVisits=16459, meanQ=6.562552, numObservations: 5
action -1, numVisits=336, meanQ=0.463155, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=5, meanQ=-6.650660, numObservations: 1
action: 3
Next state: 0 0.0991673 0.145152 0.550545 0.892563 0.64853 0.827795 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=37, meanQ=8.297030, numObservations: 3
action -1, numVisits=20, meanQ=6.514000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 50655 episodes
GETTING ACTION FROM:
action 3, numVisits=132, meanQ=6.477198, numObservations: 3
action 2, numVisits=50369, meanQ=5.959164, numObservations: 4
action -1, numVisits=210, meanQ=-0.807286, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=4, meanQ=-50.370885, numObservations: 1
action: 3
Next state: 1 0.0991673 0.145152 0.550545 0.892563 0.64853 0.827795 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 118
Initial state: 0 0.672033 0.889841 0.639324 0.835819 0.989278 0.407377 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54610 episodes
GETTING ACTION FROM:
action 2, numVisits=54561, meanQ=5.155917, numObservations: 4
action -1, numVisits=41, meanQ=4.128367, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.672033 0.889841 0.639324 0.835819 0.989278 0.407377 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 119
Initial state: 0 0.632706 0.827903 0.560779 0.353035 0.633603 0.854309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31912 episodes
GETTING ACTION FROM:
action -1, numVisits=31836, meanQ=2.927054, numObservations: 1
action 1, numVisits=46, meanQ=1.968920, numObservations: 4
action 2, numVisits=27, meanQ=1.597052, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: -1
Next state: 0 0.632706 0.827903 0.560779 0.353035 0.633603 0.854309 w: 1
Observation: 0 0.54358 0 0.515424 0 0.710103 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31593, meanQ=4.946151, numObservations: 4
action -1, numVisits=130, meanQ=4.411920, numObservations: 1
action 0, numVisits=97, meanQ=4.323375, numObservations: 1
action 3, numVisits=13, meanQ=1.298462, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
Sampled 54843 episodes
GETTING ACTION FROM:
action 2, numVisits=86413, meanQ=4.880936, numObservations: 4
action -1, numVisits=142, meanQ=4.324137, numObservations: 1
action 0, numVisits=108, meanQ=4.244449, numObservations: 1
action 3, numVisits=13, meanQ=1.298462, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 2 0.632706 0.827903 0.560779 0.353035 0.633603 0.854309 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 120
Initial state: 0 0.614752 0.870026 0.549398 0.873238 0.584696 0.458745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54712 episodes
GETTING ACTION FROM:
action 2, numVisits=54651, meanQ=5.038576, numObservations: 4
action -1, numVisits=52, meanQ=4.139599, numObservations: 1
action 3, numVisits=6, meanQ=1.166683, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.614752 0.870026 0.549398 0.873238 0.584696 0.458745 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 121
Initial state: 0 0.342723 0.565965 0.514601 0.822423 0.528229 0.85349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54410 episodes
GETTING ACTION FROM:
action 3, numVisits=54351, meanQ=4.940026, numObservations: 3
action 0, numVisits=51, meanQ=4.001421, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.342723 0.565965 0.514601 0.822423 0.528229 0.85349 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 122
Initial state: 0 0.696094 0.899151 0.616703 0.815857 0.478656 0.419301 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54294 episodes
GETTING ACTION FROM:
action 3, numVisits=54286, meanQ=4.989479, numObservations: 5
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.696094 0.899151 0.616703 0.815857 0.478656 0.419301 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1336, meanQ=7.768262, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 27555 episodes
GETTING ACTION FROM:
action 2, numVisits=27972, meanQ=6.044165, numObservations: 4
action -1, numVisits=843, meanQ=0.157331, numObservations: 1
action 0, numVisits=77, meanQ=-0.399423, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.696094 0.899151 0.616703 0.815857 0.478656 0.419301 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 123
Initial state: 0 0.55966 0.822756 0.417397 0.141154 0.656593 0.881728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54794 episodes
GETTING ACTION FROM:
action 1, numVisits=54773, meanQ=5.048027, numObservations: 4
action -1, numVisits=17, meanQ=3.359075, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.55966 0.822756 0.417397 0.141154 0.656593 0.881728 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 124
Initial state: 0 0.588119 0.882324 0.00361858 0.355867 0.657185 0.819417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54786 episodes
GETTING ACTION FROM:
action 1, numVisits=54734, meanQ=4.991289, numObservations: 4
action -1, numVisits=25, meanQ=3.580738, numObservations: 1
action 0, numVisits=21, meanQ=3.509269, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 0 0.588119 0.882324 0.00361858 0.355867 0.657185 0.819417 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3530, meanQ=5.994087, numObservations: 4
action 2, numVisits=7, meanQ=1.568600, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 60943 episodes
GETTING ACTION FROM:
action 1, numVisits=64471, meanQ=5.088559, numObservations: 5
action 2, numVisits=7, meanQ=1.568600, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.588119 0.882324 0.00361858 0.355867 0.657185 0.819417 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 125
Initial state: 0 0.510742 0.886306 0.642069 0.174955 0.594164 0.82492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54787 episodes
GETTING ACTION FROM:
action 1, numVisits=54781, meanQ=5.070689, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.510742 0.886306 0.642069 0.174955 0.594164 0.82492 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 126
Initial state: 0 0.689899 0.87143 0.542971 0.846352 0.403471 0.211569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54362 episodes
GETTING ACTION FROM:
action 3, numVisits=54353, meanQ=4.977626, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.689899 0.87143 0.542971 0.846352 0.403471 0.211569 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8877, meanQ=8.304193, numObservations: 4
action 1, numVisits=18, meanQ=6.443894, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22292 episodes
GETTING ACTION FROM:
action 2, numVisits=17694, meanQ=7.074083, numObservations: 4
action 1, numVisits=12748, meanQ=6.139683, numObservations: 3
action 0, numVisits=739, meanQ=-0.067527, numObservations: 3
action -1, numVisits=8, meanQ=-2.126225, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.689899 0.87143 0.542971 0.846352 0.403471 0.211569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 127
Initial state: 0 0.677947 0.845836 0.0781725 0.747528 0.510471 0.828967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31807 episodes
GETTING ACTION FROM:
action 0, numVisits=31795, meanQ=2.892254, numObservations: 1
action 1, numVisits=6, meanQ=-1.496633, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 0
Next state: 0 0.677947 0.845836 0.0781725 0.747528 0.510471 0.828967 w: 1
Observation: 0 0 0.824641 0 0.669613 0 0.780544 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31752, meanQ=4.947892, numObservations: 4
action 0, numVisits=35, meanQ=3.871642, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54838 episodes
GETTING ACTION FROM:
action 1, numVisits=86586, meanQ=4.794318, numObservations: 4
action 0, numVisits=39, meanQ=3.724423, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.677947 0.845836 0.0781725 0.747528 0.510471 0.828967 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 128
Initial state: 0 0.614357 0.82297 0.385171 0.756171 0.593117 0.863835 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54795 episodes
GETTING ACTION FROM:
action 1, numVisits=54789, meanQ=4.953125, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.614357 0.82297 0.385171 0.756171 0.593117 0.863835 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 129
Initial state: 0 0.641507 0.81696 0.61221 0.840606 0.741465 0.495841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53010 episodes
GETTING ACTION FROM:
action 2, numVisits=53004, meanQ=4.872154, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.641507 0.81696 0.61221 0.840606 0.741465 0.495841 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 130
Initial state: 0 0.678685 0.800822 0.645674 0.852196 0.465793 0.568526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33744 episodes
GETTING ACTION FROM:
action 0, numVisits=33727, meanQ=5.615088, numObservations: 3
action 2, numVisits=5, meanQ=0.802020, numObservations: 2
action 3, numVisits=8, meanQ=0.625012, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 0
Next state: 0 0.678685 0.800822 0.645674 0.852196 0.465793 0.568526 w: 1
Observation: 0 0 0.746895 0 0.942982 0 0.481752 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8705, meanQ=8.211096, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 56150 episodes
GETTING ACTION FROM:
action 1, numVisits=64833, meanQ=5.432920, numObservations: 4
action -1, numVisits=19, meanQ=3.838389, numObservations: 1
action 2, numVisits=5, meanQ=-0.002000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.678685 0.800822 0.645674 0.852196 0.465793 0.568526 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 131
Initial state: 0 0.51565 0.858387 0.689523 0.85696 0.052314 0.465194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51537 episodes
GETTING ACTION FROM:
action 2, numVisits=51452, meanQ=4.801160, numObservations: 4
action 1, numVisits=44, meanQ=3.582961, numObservations: 5
action 0, numVisits=30, meanQ=3.554517, numObservations: 1
action 3, numVisits=9, meanQ=2.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.51565 0.858387 0.689523 0.85696 0.052314 0.465194 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 132
Initial state: 0 0.57023 0.139669 0.646239 0.821734 0.67222 0.828945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54576 episodes
GETTING ACTION FROM:
action 1, numVisits=54515, meanQ=4.989981, numObservations: 5
action -1, numVisits=57, meanQ=4.119936, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.57023 0.139669 0.646239 0.821734 0.67222 0.828945 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 133
Initial state: 0 0.626485 0.884097 0.215683 0.85581 0.634597 0.800891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54527 episodes
GETTING ACTION FROM:
action 3, numVisits=54498, meanQ=5.013951, numObservations: 5
action 2, numVisits=24, meanQ=1.832921, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.626485 0.884097 0.215683 0.85581 0.634597 0.800891 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2412, meanQ=5.809624, numObservations: 4
action 2, numVisits=1602, meanQ=4.695261, numObservations: 4
action 1, numVisits=43, meanQ=3.875116, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 60282 episodes
GETTING ACTION FROM:
action 3, numVisits=62692, meanQ=5.339032, numObservations: 4
action 2, numVisits=1602, meanQ=4.695261, numObservations: 4
action 1, numVisits=43, meanQ=3.875116, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.626485 0.884097 0.215683 0.85581 0.634597 0.800891 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 134
Initial state: 0 0.575386 0.875794 0.66457 0.846816 0.41501 0.0217174 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54468 episodes
GETTING ACTION FROM:
action 1, numVisits=54453, meanQ=5.041925, numObservations: 5
action 2, numVisits=10, meanQ=2.400000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.575386 0.875794 0.66457 0.846816 0.41501 0.0217174 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 135
Initial state: 0 0.568141 0.535541 0.534116 0.852498 0.538882 0.815519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54340 episodes
GETTING ACTION FROM:
action 1, numVisits=54321, meanQ=5.006763, numObservations: 4
action 2, numVisits=14, meanQ=2.927857, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.568141 0.535541 0.534116 0.852498 0.538882 0.815519 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 136
Initial state: 0 0.361985 0.498563 0.548059 0.821655 0.592071 0.85708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54069 episodes
GETTING ACTION FROM:
action 3, numVisits=54063, meanQ=4.926080, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.361985 0.498563 0.548059 0.821655 0.592071 0.85708 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 137
Initial state: 0 0.688183 0.805363 0.690321 0.856639 0.945807 0.390351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53166 episodes
GETTING ACTION FROM:
action 3, numVisits=53160, meanQ=4.996486, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.688183 0.805363 0.690321 0.856639 0.945807 0.390351 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 138
Initial state: 0 0.386355 0.586598 0.677335 0.865957 0.6214 0.865769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49840 episodes
GETTING ACTION FROM:
action 2, numVisits=49825, meanQ=4.700580, numObservations: 5
action 0, numVisits=10, meanQ=2.488000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.386355 0.586598 0.677335 0.865957 0.6214 0.865769 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 139
Initial state: 0 0.636242 0.826112 0.935482 0.422295 0.683895 0.861212 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54330 episodes
GETTING ACTION FROM:
action 1, numVisits=54302, meanQ=4.946892, numObservations: 4
action 3, numVisits=23, meanQ=3.564357, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.636242 0.826112 0.935482 0.422295 0.683895 0.861212 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 140
Initial state: 0 0.610689 0.835124 0.0936017 0.448958 0.548851 0.879455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54519 episodes
GETTING ACTION FROM:
action 2, numVisits=54469, meanQ=4.992955, numObservations: 3
action 0, numVisits=44, meanQ=4.000489, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.610689 0.835124 0.0936017 0.448958 0.548851 0.879455 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8564, meanQ=8.305623, numObservations: 3
action 3, numVisits=375, meanQ=8.057147, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 25547 episodes
GETTING ACTION FROM:
action 3, numVisits=558, meanQ=7.637542, numObservations: 5
action 1, numVisits=33920, meanQ=6.569286, numObservations: 3
action -1, numVisits=5, meanQ=-1.802000, numObservations: 1
action 0, numVisits=5, meanQ=-1.802000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.610689 0.835124 0.0936017 0.448958 0.548851 0.879455 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 141
Initial state: 0 0.646417 0.824999 0.957978 0.4299 0.56214 0.856992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54861 episodes
GETTING ACTION FROM:
action 3, numVisits=54725, meanQ=5.023436, numObservations: 5
action 0, numVisits=67, meanQ=4.229322, numObservations: 1
action -1, numVisits=62, meanQ=4.195303, numObservations: 1
action 1, numVisits=6, meanQ=1.333333, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.646417 0.824999 0.957978 0.4299 0.56214 0.856992 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 142
Initial state: 0 0.431643 0.114792 0.57844 0.815361 0.542817 0.839164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53279 episodes
GETTING ACTION FROM:
action 1, numVisits=53038, meanQ=4.967591, numObservations: 4
action -1, numVisits=92, meanQ=4.284542, numObservations: 1
action 0, numVisits=57, meanQ=4.111446, numObservations: 1
action 3, numVisits=59, meanQ=2.756710, numObservations: 4
action 2, numVisits=33, meanQ=2.509400, numObservations: 5
action: 1
Next state: 2 0.431643 0.114792 0.57844 0.815361 0.542817 0.839164 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 143
Initial state: 0 0.590628 0.823183 0.961267 0.383627 0.663463 0.88736 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53848 episodes
GETTING ACTION FROM:
action 2, numVisits=53841, meanQ=4.959661, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.590628 0.823183 0.961267 0.383627 0.663463 0.88736 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 144
Initial state: 0 0.565956 0.878718 0.416704 0.61652 0.564795 0.851983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54226 episodes
GETTING ACTION FROM:
action 2, numVisits=54188, meanQ=5.098634, numObservations: 5
action -1, numVisits=17, meanQ=3.419504, numObservations: 1
action 0, numVisits=12, meanQ=2.946975, numObservations: 1
action 1, numVisits=7, meanQ=2.570000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 0 0.565956 0.878718 0.416704 0.61652 0.564795 0.851983 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3110, meanQ=7.667784, numObservations: 4
action 1, numVisits=36, meanQ=6.666114, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 15104 episodes
GETTING ACTION FROM:
action 3, numVisits=15927, meanQ=6.228605, numObservations: 4
action 1, numVisits=125, meanQ=2.604541, numObservations: 4
action -1, numVisits=2185, meanQ=-0.385499, numObservations: 1
action 0, numVisits=15, meanQ=-2.000660, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.565956 0.878718 0.416704 0.61652 0.564795 0.851983 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 145
Initial state: 0 0.460024 0.517173 0.543521 0.874249 0.521881 0.802938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55009 episodes
GETTING ACTION FROM:
action 2, numVisits=54977, meanQ=5.121159, numObservations: 4
action 3, numVisits=27, meanQ=3.481863, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.460024 0.517173 0.543521 0.874249 0.521881 0.802938 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 146
Initial state: 0 0.518295 0.843058 0.472289 0.519266 0.620406 0.805161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54671 episodes
GETTING ACTION FROM:
action 3, numVisits=54652, meanQ=5.145034, numObservations: 4
action 1, numVisits=14, meanQ=2.357143, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.518295 0.843058 0.472289 0.519266 0.620406 0.805161 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 147
Initial state: 0 0.442837 0.542524 0.569679 0.835456 0.658361 0.812446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54493 episodes
GETTING ACTION FROM:
action 3, numVisits=54484, meanQ=4.916287, numObservations: 3
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.442837 0.542524 0.569679 0.835456 0.658361 0.812446 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 148
Initial state: 0 0.546674 0.80165 0.00684895 0.165891 0.580415 0.832981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31997 episodes
GETTING ACTION FROM:
action -1, numVisits=31989, meanQ=3.021285, numObservations: 1
action 1, numVisits=4, meanQ=-0.999975, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.546674 0.80165 0.00684895 0.165891 0.580415 0.832981 w: 1
Observation: 0 0.496596 0 0.0583175 0 0.618521 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=29045, meanQ=5.010570, numObservations: 4
action 1, numVisits=2938, meanQ=4.917353, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55001 episodes
GETTING ACTION FROM:
action 2, numVisits=84037, meanQ=5.052894, numObservations: 4
action 1, numVisits=2946, meanQ=4.919989, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-3.505000, numObservations: 2
action: 2
Next state: 0 0.546674 0.80165 0.00684895 0.165891 0.580415 0.832981 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=11278, meanQ=8.410975, numObservations: 4
action 1, numVisits=132, meanQ=7.917957, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 19841 episodes
GETTING ACTION FROM:
action 3, numVisits=30315, meanQ=7.233651, numObservations: 4
action 1, numVisits=771, meanQ=6.171589, numObservations: 4
action -1, numVisits=162, meanQ=0.371111, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=5, meanQ=-74.020633, numObservations: 1
action: 3
Next state: 1 0.546674 0.80165 0.00684895 0.165891 0.580415 0.832981 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 149
Initial state: 0 0.510245 0.833257 0.158438 0.064481 0.559679 0.883918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54613 episodes
GETTING ACTION FROM:
action 3, numVisits=54522, meanQ=4.951826, numObservations: 5
action -1, numVisits=55, meanQ=4.064209, numObservations: 1
action 1, numVisits=33, meanQ=2.966982, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.510245 0.833257 0.158438 0.064481 0.559679 0.883918 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 150
Initial state: 0 0.871272 0.478381 0.510863 0.80945 0.546509 0.827382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51682 episodes
GETTING ACTION FROM:
action 2, numVisits=50970, meanQ=4.889322, numObservations: 5
action 3, numVisits=548, meanQ=4.402342, numObservations: 4
action 1, numVisits=85, meanQ=4.173298, numObservations: 5
action 0, numVisits=77, meanQ=4.155839, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.871272 0.478381 0.510863 0.80945 0.546509 0.827382 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 151
Initial state: 0 0.550125 0.891377 0.746039 0.625348 0.646192 0.813596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54261 episodes
GETTING ACTION FROM:
action 3, numVisits=53675, meanQ=4.956768, numObservations: 5
action 1, numVisits=275, meanQ=4.545151, numObservations: 5
action 2, numVisits=245, meanQ=4.516846, numObservations: 4
action -1, numVisits=64, meanQ=4.111747, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.550125 0.891377 0.746039 0.625348 0.646192 0.813596 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4027, meanQ=5.017247, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67429 episodes
GETTING ACTION FROM:
action 1, numVisits=71455, meanQ=5.838811, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.550125 0.891377 0.746039 0.625348 0.646192 0.813596 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 152
Initial state: 0 0.578215 0.822548 0.603464 0.840775 0.842979 0.291744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54348 episodes
GETTING ACTION FROM:
action 2, numVisits=54342, meanQ=4.932468, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.578215 0.822548 0.603464 0.840775 0.842979 0.291744 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 153
Initial state: 0 0.383117 0.731533 0.694472 0.802961 0.503087 0.892457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54900 episodes
GETTING ACTION FROM:
action 2, numVisits=54874, meanQ=4.981870, numObservations: 4
action -1, numVisits=21, meanQ=3.457804, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.383117 0.731533 0.694472 0.802961 0.503087 0.892457 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 154
Initial state: 0 0.599989 0.845984 0.422813 0.344852 0.697905 0.879437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54680 episodes
GETTING ACTION FROM:
action 3, numVisits=54663, meanQ=4.927056, numObservations: 4
action 2, numVisits=12, meanQ=1.750008, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.599989 0.845984 0.422813 0.344852 0.697905 0.879437 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4146, meanQ=4.735013, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 68003 episodes
GETTING ACTION FROM:
action 2, numVisits=72147, meanQ=6.076009, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.599989 0.845984 0.422813 0.344852 0.697905 0.879437 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1885, meanQ=7.963030, numObservations: 3
action 1, numVisits=42, meanQ=7.090481, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 30845 episodes
GETTING ACTION FROM:
action 3, numVisits=28614, meanQ=6.384361, numObservations: 4
action 1, numVisits=4148, meanQ=5.876565, numObservations: 4
action -1, numVisits=6, meanQ=-1.835000, numObservations: 1
action 0, numVisits=6, meanQ=-1.835000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.599989 0.845984 0.422813 0.344852 0.697905 0.879437 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 155
Initial state: 0 0.243296 0.932952 0.562605 0.897757 0.684789 0.815098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54336 episodes
GETTING ACTION FROM:
action 3, numVisits=54205, meanQ=4.982701, numObservations: 3
action 1, numVisits=94, meanQ=4.311861, numObservations: 4
action 0, numVisits=32, meanQ=3.757811, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.243296 0.932952 0.562605 0.897757 0.684789 0.815098 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 156
Initial state: 0 0.69062 0.890033 0.648807 0.581495 0.652158 0.889252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54552 episodes
GETTING ACTION FROM:
action 3, numVisits=54518, meanQ=5.009068, numObservations: 5
action 0, numVisits=25, meanQ=3.698444, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.69062 0.890033 0.648807 0.581495 0.652158 0.889252 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 157
Initial state: 0 0.51438 0.816611 0.55262 0.849602 0.478655 0.218153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52042 episodes
GETTING ACTION FROM:
action 2, numVisits=52009, meanQ=4.830533, numObservations: 4
action 3, numVisits=19, meanQ=2.927900, numObservations: 3
action 1, numVisits=10, meanQ=2.281010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.51438 0.816611 0.55262 0.849602 0.478655 0.218153 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8535, meanQ=8.310297, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21574 episodes
GETTING ACTION FROM:
action 1, numVisits=28408, meanQ=6.486387, numObservations: 4
action -1, numVisits=1692, meanQ=0.222819, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=9, meanQ=-1.890000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.51438 0.816611 0.55262 0.849602 0.478655 0.218153 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 158
Initial state: 0 0.670691 0.831271 0.779016 0.0752403 0.677928 0.824795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32157 episodes
GETTING ACTION FROM:
action -1, numVisits=27385, meanQ=3.130838, numObservations: 1
action 0, numVisits=4759, meanQ=3.076359, numObservations: 1
action 3, numVisits=8, meanQ=0.113762, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.670691 0.831271 0.779016 0.0752403 0.677928 0.824795 w: 1
Observation: 0 0.690408 0 0.684351 0 0.753164 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=27378, meanQ=5.080790, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55437 episodes
GETTING ACTION FROM:
action 2, numVisits=82814, meanQ=5.050181, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 2
Next state: 0 0.670691 0.831271 0.779016 0.0752403 0.677928 0.824795 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=5056, meanQ=5.488757, numObservations: 4
action 1, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 20206 episodes
GETTING ACTION FROM:
action 3, numVisits=19620, meanQ=5.988489, numObservations: 4
action 2, numVisits=5056, meanQ=5.488757, numObservations: 4
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=584, meanQ=-0.764694, numObservations: 1
action 0, numVisits=4, meanQ=-93.022989, numObservations: 1
action: 3
Next state: 1 0.670691 0.831271 0.779016 0.0752403 0.677928 0.824795 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 159
Initial state: 0 0.571074 0.858164 0.586393 0.830592 0.146553 0.0725511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54677 episodes
GETTING ACTION FROM:
action 2, numVisits=54671, meanQ=5.034401, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.571074 0.858164 0.586393 0.830592 0.146553 0.0725511 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 160
Initial state: 0 0.732556 0.595931 0.67861 0.866215 0.557073 0.89127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32262 episodes
GETTING ACTION FROM:
action -1, numVisits=32257, meanQ=2.896881, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.732556 0.595931 0.67861 0.866215 0.557073 0.89127 w: 1
Observation: 0 0.797642 0 0.653966 0 0.461179 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32178, meanQ=4.984353, numObservations: 5
action -1, numVisits=69, meanQ=4.219057, numObservations: 1
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55689 episodes
GETTING ACTION FROM:
action 1, numVisits=87866, meanQ=5.070211, numObservations: 5
action -1, numVisits=70, meanQ=4.205922, numObservations: 1
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.732556 0.595931 0.67861 0.866215 0.557073 0.89127 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 161
Initial state: 0 0.690831 0.842766 0.669124 0.877388 0.00268506 0.286408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54332 episodes
GETTING ACTION FROM:
action 2, numVisits=54295, meanQ=4.992589, numObservations: 4
action -1, numVisits=22, meanQ=3.554830, numObservations: 1
action 0, numVisits=13, meanQ=2.870729, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.690831 0.842766 0.669124 0.877388 0.00268506 0.286408 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 162
Initial state: 0 0.540255 0.821079 0.0632468 0.451047 0.600721 0.815389 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54707 episodes
GETTING ACTION FROM:
action 3, numVisits=54701, meanQ=5.008247, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.540255 0.821079 0.0632468 0.451047 0.600721 0.815389 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 163
Initial state: 0 0.612815 0.838072 0.557447 0.861723 0.43302 0.498853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 45437 episodes
GETTING ACTION FROM:
action 2, numVisits=32268, meanQ=4.938484, numObservations: 4
action 0, numVisits=13165, meanQ=2.993270, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.612815 0.838072 0.557447 0.861723 0.43302 0.498853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 164
Initial state: 0 0.59058 0.896372 0.264085 0.306195 0.61197 0.882888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53788 episodes
GETTING ACTION FROM:
action 3, numVisits=53709, meanQ=4.994809, numObservations: 4
action 0, numVisits=75, meanQ=4.243429, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.59058 0.896372 0.264085 0.306195 0.61197 0.882888 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 165
Initial state: 0 0.640093 0.880416 0.640046 0.838343 0.984117 0.192537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54780 episodes
GETTING ACTION FROM:
action 2, numVisits=54761, meanQ=4.974433, numObservations: 3
action 3, numVisits=12, meanQ=3.081675, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.640093 0.880416 0.640046 0.838343 0.984117 0.192537 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 166
Initial state: 0 0.508297 0.889408 0.927163 0.01094 0.655024 0.83967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54586 episodes
GETTING ACTION FROM:
action 3, numVisits=54572, meanQ=5.027901, numObservations: 4
action 1, numVisits=8, meanQ=2.375000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.508297 0.889408 0.927163 0.01094 0.655024 0.83967 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 167
Initial state: 0 0.566361 0.880155 0.51961 0.0203218 0.6547 0.896935 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54899 episodes
GETTING ACTION FROM:
action 2, numVisits=54810, meanQ=5.013228, numObservations: 5
action 0, numVisits=85, meanQ=4.257616, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.566361 0.880155 0.51961 0.0203218 0.6547 0.896935 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 168
Initial state: 0 0.63765 0.893185 0.881635 0.0318404 0.622499 0.807699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54730 episodes
GETTING ACTION FROM:
action 3, numVisits=54621, meanQ=5.145536, numObservations: 5
action -1, numVisits=73, meanQ=4.399090, numObservations: 1
action 0, numVisits=25, meanQ=3.730222, numObservations: 1
action 2, numVisits=10, meanQ=2.499000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.63765 0.893185 0.881635 0.0318404 0.622499 0.807699 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 169
Initial state: 0 0.590108 0.846818 0.653423 0.855019 0.579736 0.306001 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54283 episodes
GETTING ACTION FROM:
action 2, numVisits=54277, meanQ=4.917403, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.590108 0.846818 0.653423 0.855019 0.579736 0.306001 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 170
Initial state: 0 0.546745 0.860117 0.706031 0.93258 0.596614 0.803126 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54127 episodes
GETTING ACTION FROM:
action 2, numVisits=53919, meanQ=4.957522, numObservations: 4
action 0, numVisits=113, meanQ=4.132041, numObservations: 1
action 1, numVisits=81, meanQ=3.818760, numObservations: 4
action 3, numVisits=12, meanQ=2.999167, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.546745 0.860117 0.706031 0.93258 0.596614 0.803126 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 171
Initial state: 0 0.670961 0.834005 0.535393 0.872364 0.167823 0.65221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54456 episodes
GETTING ACTION FROM:
action 1, numVisits=54435, meanQ=5.025354, numObservations: 5
action -1, numVisits=17, meanQ=3.420109, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.670961 0.834005 0.535393 0.872364 0.167823 0.65221 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 172
Initial state: 0 0.622613 0.888886 0.681404 0.851672 0.533163 0.696669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31991 episodes
GETTING ACTION FROM:
action 0, numVisits=31977, meanQ=2.837587, numObservations: 1
action 2, numVisits=10, meanQ=0.300010, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.622613 0.888886 0.681404 0.851672 0.533163 0.696669 w: 1
Observation: 0 0 0.843382 0 0.758915 0 0.665485 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31967, meanQ=4.958417, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 55122 episodes
GETTING ACTION FROM:
action 1, numVisits=87088, meanQ=5.099878, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.622613 0.888886 0.681404 0.851672 0.533163 0.696669 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 173
Initial state: 0 0.648387 0.838423 0.738034 0.152403 0.584858 0.842928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54604 episodes
GETTING ACTION FROM:
action 1, numVisits=53504, meanQ=4.998784, numObservations: 4
action 2, numVisits=1091, meanQ=4.753157, numObservations: 4
action 3, numVisits=5, meanQ=0.802020, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.648387 0.838423 0.738034 0.152403 0.584858 0.842928 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 174
Initial state: 0 0.562943 0.894054 0.443238 0.643853 0.577817 0.850696 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 37810 episodes
GETTING ACTION FROM:
action 2, numVisits=13605, meanQ=5.003130, numObservations: 5
action -1, numVisits=24199, meanQ=2.930323, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.562943 0.894054 0.443238 0.643853 0.577817 0.850696 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 175
Initial state: 0 0.572179 0.803118 0.671369 0.0708038 0.594544 0.86448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54478 episodes
GETTING ACTION FROM:
action 1, numVisits=54433, meanQ=5.005315, numObservations: 4
action -1, numVisits=36, meanQ=3.907713, numObservations: 1
action 2, numVisits=6, meanQ=0.836683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.572179 0.803118 0.671369 0.0708038 0.594544 0.86448 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 176
Initial state: 0 0.670466 0.841517 0.679173 0.898819 0.428846 0.879792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51563 episodes
GETTING ACTION FROM:
action 3, numVisits=51518, meanQ=4.761790, numObservations: 5
action -1, numVisits=30, meanQ=3.565993, numObservations: 1
action 2, numVisits=12, meanQ=2.415842, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.670466 0.841517 0.679173 0.898819 0.428846 0.879792 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2547, meanQ=7.839942, numObservations: 4
action 2, numVisits=9, meanQ=5.876667, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 24675 episodes
GETTING ACTION FROM:
action 1, numVisits=26049, meanQ=6.351938, numObservations: 4
action 2, numVisits=666, meanQ=5.808447, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action 0, numVisits=345, meanQ=0.321421, numObservations: 1
action -1, numVisits=173, meanQ=-0.635206, numObservations: 1
action: 1
Next state: 1 0.670466 0.841517 0.679173 0.898819 0.428846 0.879792 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 177
Initial state: 0 0.663558 0.871326 0.179231 0.362453 0.518041 0.859352 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53700 episodes
GETTING ACTION FROM:
action 3, numVisits=53651, meanQ=4.964751, numObservations: 3
action 0, numVisits=45, meanQ=3.951530, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.663558 0.871326 0.179231 0.362453 0.518041 0.859352 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 178
Initial state: 0 0.580728 0.852248 0.343336 0.723894 0.631631 0.852152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54225 episodes
GETTING ACTION FROM:
action 1, numVisits=53815, meanQ=4.973517, numObservations: 4
action 3, numVisits=402, meanQ=4.643550, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.580728 0.852248 0.343336 0.723894 0.631631 0.852152 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 179
Initial state: 0 0.565419 0.830228 0.753757 0.356591 0.60364 0.804384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54682 episodes
GETTING ACTION FROM:
action 3, numVisits=54676, meanQ=4.988378, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.565419 0.830228 0.753757 0.356591 0.60364 0.804384 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 180
Initial state: 0 0.727515 0.787076 0.57193 0.837545 0.621844 0.860255 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54534 episodes
GETTING ACTION FROM:
action 2, numVisits=54498, meanQ=5.161529, numObservations: 4
action 0, numVisits=15, meanQ=3.299652, numObservations: 1
action 3, numVisits=17, meanQ=3.175888, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.727515 0.787076 0.57193 0.837545 0.621844 0.860255 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3756, meanQ=7.322017, numObservations: 4
action 1, numVisits=21, meanQ=4.618105, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 66470 episodes
GETTING ACTION FROM:
action 1, numVisits=57435, meanQ=6.156172, numObservations: 5
action 2, numVisits=12812, meanQ=5.409750, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.727515 0.787076 0.57193 0.837545 0.621844 0.860255 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 181
Initial state: 0 0.530348 0.54531 0.614803 0.881842 0.526201 0.893119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53404 episodes
GETTING ACTION FROM:
action 1, numVisits=53336, meanQ=5.049116, numObservations: 4
action -1, numVisits=28, meanQ=3.750212, numObservations: 1
action 0, numVisits=17, meanQ=3.369567, numObservations: 1
action 3, numVisits=22, meanQ=2.545918, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.530348 0.54531 0.614803 0.881842 0.526201 0.893119 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 182
Initial state: 0 0.59722 0.807865 0.564633 0.812745 0.45136 0.451476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54077 episodes
GETTING ACTION FROM:
action 2, numVisits=54019, meanQ=5.024284, numObservations: 5
action -1, numVisits=38, meanQ=3.950913, numObservations: 1
action 3, numVisits=17, meanQ=2.822941, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.59722 0.807865 0.564633 0.812745 0.45136 0.451476 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.518727 0.824107 0.694265 0.863709 0.943424 0.909836 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53857 episodes
GETTING ACTION FROM:
action 3, numVisits=53825, meanQ=4.947742, numObservations: 5
action 0, numVisits=28, meanQ=3.700720, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.518727 0.824107 0.694265 0.863709 0.943424 0.909836 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 184
Initial state: 0 0.421558 0.194286 0.531399 0.813036 0.5794 0.874783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54398 episodes
GETTING ACTION FROM:
action 1, numVisits=54385, meanQ=5.048928, numObservations: 4
action 2, numVisits=8, meanQ=1.352500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.421558 0.194286 0.531399 0.813036 0.5794 0.874783 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 185
Initial state: 0 0.523941 0.865952 0.519887 0.840434 0.122957 0.992537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54580 episodes
GETTING ACTION FROM:
action 3, numVisits=54574, meanQ=5.171869, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.523941 0.865952 0.519887 0.840434 0.122957 0.992537 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3570, meanQ=7.440318, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 60310 episodes
GETTING ACTION FROM:
action 3, numVisits=63878, meanQ=4.723819, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.523941 0.865952 0.519887 0.840434 0.122957 0.992537 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 186
Initial state: 0 0.662325 0.819201 0.61159 0.864619 0.934028 0.725253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50801 episodes
GETTING ACTION FROM:
action 3, numVisits=45493, meanQ=5.014997, numObservations: 4
action -1, numVisits=5302, meanQ=3.340390, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.662325 0.819201 0.61159 0.864619 0.934028 0.725253 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 187
Initial state: 0 0.599087 0.834225 0.689189 0.888511 0.427961 0.562387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51821 episodes
GETTING ACTION FROM:
action 1, numVisits=51812, meanQ=4.848429, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.599087 0.834225 0.689189 0.888511 0.427961 0.562387 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 188
Initial state: 0 0.553952 0.829737 0.134321 0.587801 0.582776 0.809051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31899 episodes
GETTING ACTION FROM:
action -1, numVisits=31892, meanQ=2.871666, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.553952 0.829737 0.134321 0.587801 0.582776 0.809051 w: 1
Observation: 0 0.604183 0 0.0540777 0 0.569482 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31772, meanQ=4.926000, numObservations: 4
action -1, numVisits=110, meanQ=4.340571, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 54923 episodes
GETTING ACTION FROM:
action 2, numVisits=86690, meanQ=4.914212, numObservations: 4
action -1, numVisits=115, meanQ=4.305421, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.553952 0.829737 0.134321 0.587801 0.582776 0.809051 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=13459, meanQ=8.341422, numObservations: 3
action 3, numVisits=996, meanQ=8.151736, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 35696 episodes
GETTING ACTION FROM:
action 1, numVisits=43500, meanQ=6.896674, numObservations: 3
action 3, numVisits=6647, meanQ=6.383558, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.553952 0.829737 0.134321 0.587801 0.582776 0.809051 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 189
Initial state: 0 0.64703 0.825636 0.934179 0.00161697 0.682917 0.883034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54535 episodes
GETTING ACTION FROM:
action 3, numVisits=54495, meanQ=4.999966, numObservations: 4
action 1, numVisits=31, meanQ=3.762265, numObservations: 4
action 2, numVisits=5, meanQ=-0.002000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.64703 0.825636 0.934179 0.00161697 0.682917 0.883034 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4096, meanQ=5.647576, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 61694 episodes
GETTING ACTION FROM:
action 3, numVisits=65788, meanQ=4.988370, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.64703 0.825636 0.934179 0.00161697 0.682917 0.883034 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1380, meanQ=6.582656, numObservations: 4
action 1, numVisits=37, meanQ=5.431900, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 69332 episodes
GETTING ACTION FROM:
action 2, numVisits=70577, meanQ=5.989398, numObservations: 4
action 1, numVisits=172, meanQ=5.462909, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.64703 0.825636 0.934179 0.00161697 0.682917 0.883034 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 190
Initial state: 0 0.3395 0.773583 0.601251 0.879451 0.61961 0.887039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51537 episodes
GETTING ACTION FROM:
action 2, numVisits=51487, meanQ=4.804645, numObservations: 4
action 0, numVisits=46, meanQ=3.773336, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.3395 0.773583 0.601251 0.879451 0.61961 0.887039 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 191
Initial state: 0 0.515738 0.864389 0.926647 0.0160858 0.612431 0.889414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54207 episodes
GETTING ACTION FROM:
action 3, numVisits=54198, meanQ=4.989613, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=4, meanQ=-2.500000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.515738 0.864389 0.926647 0.0160858 0.612431 0.889414 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 192
Initial state: 0 0.75979 0.652074 0.675791 0.838222 0.581372 0.873236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54238 episodes
GETTING ACTION FROM:
action 1, numVisits=54179, meanQ=4.969835, numObservations: 4
action 2, numVisits=47, meanQ=3.017030, numObservations: 4
action 0, numVisits=9, meanQ=2.730000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.75979 0.652074 0.675791 0.838222 0.581372 0.873236 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 193
Initial state: 0 0.519585 0.841076 0.520854 0.814955 0.435564 0.608907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33238 episodes
GETTING ACTION FROM:
action 0, numVisits=33233, meanQ=4.217878, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.519585 0.841076 0.520854 0.814955 0.435564 0.608907 w: 1
Observation: 0 0 0.815711 0 0.811623 0 0.558225 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=27358, meanQ=6.715975, numObservations: 4
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 54713 episodes
GETTING ACTION FROM:
action 2, numVisits=82008, meanQ=5.705344, numObservations: 4
action -1, numVisits=64, meanQ=4.851562, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.519585 0.841076 0.520854 0.814955 0.435564 0.608907 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 194
Initial state: 0 0.819047 0.369107 0.504004 0.823287 0.519334 0.881436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54565 episodes
GETTING ACTION FROM:
action 2, numVisits=54558, meanQ=4.952800, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.819047 0.369107 0.504004 0.823287 0.519334 0.881436 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 195
Initial state: 0 0.58004 0.864808 0.801763 0.98325 0.62049 0.859578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54331 episodes
GETTING ACTION FROM:
action 3, numVisits=54270, meanQ=5.005877, numObservations: 3
action 2, numVisits=54, meanQ=3.345378, numObservations: 4
action 1, numVisits=3, meanQ=0.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.58004 0.864808 0.801763 0.98325 0.62049 0.859578 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 196
Initial state: 0 0.526668 0.882179 0.655758 0.37374 0.540093 0.836179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 37109 episodes
GETTING ACTION FROM:
action 0, numVisits=27716, meanQ=5.880606, numObservations: 3
action 2, numVisits=9389, meanQ=4.976039, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.526668 0.882179 0.655758 0.37374 0.540093 0.836179 w: 1
Observation: 0 0 0.869192 0 0.345501 0 0.846025 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7832, meanQ=8.304848, numObservations: 5
action 1, numVisits=4, meanQ=4.975000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 56407 episodes
GETTING ACTION FROM:
action 3, numVisits=64220, meanQ=5.491391, numObservations: 5
action 1, numVisits=21, meanQ=3.462381, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.526668 0.882179 0.655758 0.37374 0.540093 0.836179 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 197
Initial state: 0 0.557745 0.825694 0.447184 0.576239 0.576347 0.846694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53734 episodes
GETTING ACTION FROM:
action 3, numVisits=53710, meanQ=4.906869, numObservations: 4
action 1, numVisits=16, meanQ=2.939387, numObservations: 3
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.557745 0.825694 0.447184 0.576239 0.576347 0.846694 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 198
Initial state: 0 0.57156 0.85845 0.545796 0.844374 0.609468 0.636662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53551 episodes
GETTING ACTION FROM:
action 3, numVisits=53514, meanQ=4.893533, numObservations: 5
action -1, numVisits=31, meanQ=3.642225, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=3, meanQ=-3.296667, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.57156 0.85845 0.545796 0.844374 0.609468 0.636662 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 199
Initial state: 0 0.53329 0.833442 0.676664 0.887032 0.35516 0.63545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54414 episodes
GETTING ACTION FROM:
action 1, numVisits=54408, meanQ=4.974680, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.53329 0.833442 0.676664 0.887032 0.35516 0.63545 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 200
Initial state: 0 0.505755 0.831494 0.501593 0.886603 0.443941 0.590455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31398 episodes
GETTING ACTION FROM:
action -1, numVisits=31378, meanQ=2.860920, numObservations: 1
action 1, numVisits=16, meanQ=0.625012, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.505755 0.831494 0.501593 0.886603 0.443941 0.590455 w: 1
Observation: 0 0.485886 0 0.564936 0 0.418494 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31279, meanQ=4.888598, numObservations: 5
action 0, numVisits=47, meanQ=3.960424, numObservations: 1
action -1, numVisits=38, meanQ=3.835233, numObservations: 1
action 1, numVisits=9, meanQ=1.886667, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
Sampled 53745 episodes
GETTING ACTION FROM:
action 2, numVisits=85023, meanQ=4.995577, numObservations: 5
action 0, numVisits=48, meanQ=3.932864, numObservations: 1
action -1, numVisits=38, meanQ=3.835233, numObservations: 1
action 1, numVisits=9, meanQ=1.886667, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action: 2
Next state: 1 0.505755 0.831494 0.501593 0.886603 0.443941 0.590455 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 201
Initial state: 0 0.576488 0.844292 0.609247 0.80958 0.237935 0.0366346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51839 episodes
GETTING ACTION FROM:
action 3, numVisits=51819, meanQ=4.900309, numObservations: 5
action 2, numVisits=14, meanQ=2.427857, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.576488 0.844292 0.609247 0.80958 0.237935 0.0366346 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6029, meanQ=8.503151, numObservations: 3
action 1, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11853 episodes
GETTING ACTION FROM:
action 2, numVisits=17874, meanQ=6.884388, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=5, meanQ=-7.845134, numObservations: 1
action 0, numVisits=4, meanQ=-90.177189, numObservations: 1
action: 2
Next state: 0 0.576488 0.844292 0.609247 0.80958 0.237935 0.0366346 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=51, meanQ=7.974906, numObservations: 3
action -1, numVisits=26, meanQ=6.605385, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 28213 episodes
GETTING ACTION FROM:
action 2, numVisits=51, meanQ=7.974906, numObservations: 3
action 1, numVisits=19182, meanQ=6.293053, numObservations: 4
action -1, numVisits=9040, meanQ=-1.703618, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=19, meanQ=-11.928980, numObservations: 1
action: 2
Next state: 1 0.576488 0.844292 0.609247 0.80958 0.237935 0.0366346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 202
Initial state: 0 0.694343 0.854661 0.915314 0.99774 0.648292 0.810587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54173 episodes
GETTING ACTION FROM:
action 2, numVisits=54167, meanQ=4.912750, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.694343 0.854661 0.915314 0.99774 0.648292 0.810587 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 203
Initial state: 0 0.631199 0.868238 0.371953 0.379765 0.606747 0.804897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54234 episodes
GETTING ACTION FROM:
action 3, numVisits=54163, meanQ=4.951398, numObservations: 5
action 0, numVisits=60, meanQ=4.110596, numObservations: 1
action 2, numVisits=8, meanQ=1.376263, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.631199 0.868238 0.371953 0.379765 0.606747 0.804897 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 204
Initial state: 0 0.517825 0.828054 0.674071 0.850957 0.380083 0.907223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54801 episodes
GETTING ACTION FROM:
action 3, numVisits=54737, meanQ=5.056450, numObservations: 3
action -1, numVisits=29, meanQ=3.849776, numObservations: 1
action 2, numVisits=24, meanQ=3.450008, numObservations: 3
action 0, numVisits=10, meanQ=2.783193, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.517825 0.828054 0.674071 0.850957 0.380083 0.907223 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3950, meanQ=5.556236, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 60956 episodes
GETTING ACTION FROM:
action 3, numVisits=64904, meanQ=4.886414, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.517825 0.828054 0.674071 0.850957 0.380083 0.907223 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1609, meanQ=6.044981, numObservations: 5
action 2, numVisits=3, meanQ=2.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 68672 episodes
GETTING ACTION FROM:
action 1, numVisits=70280, meanQ=6.001661, numObservations: 5
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.517825 0.828054 0.674071 0.850957 0.380083 0.907223 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 205
Initial state: 0 0.874581 0.411565 0.60337 0.845147 0.656247 0.864379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51963 episodes
GETTING ACTION FROM:
action 1, numVisits=51957, meanQ=4.785635, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.874581 0.411565 0.60337 0.845147 0.656247 0.864379 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 206
Initial state: 0 0.173965 0.0360132 0.678514 0.884306 0.691837 0.816689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54233 episodes
GETTING ACTION FROM:
action 1, numVisits=54218, meanQ=4.967257, numObservations: 5
action 3, numVisits=10, meanQ=2.300010, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.173965 0.0360132 0.678514 0.884306 0.691837 0.816689 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 207
Initial state: 0 0.390203 0.473997 0.594362 0.80563 0.525072 0.829287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51438 episodes
GETTING ACTION FROM:
action 2, numVisits=51339, meanQ=4.758719, numObservations: 5
action 0, numVisits=59, meanQ=3.909296, numObservations: 2
action -1, numVisits=37, meanQ=3.678077, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.390203 0.473997 0.594362 0.80563 0.525072 0.829287 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 208
Initial state: 0 0.603838 0.812512 0.428323 0.255983 0.65071 0.811262 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54512 episodes
GETTING ACTION FROM:
action 2, numVisits=54503, meanQ=4.978839, numObservations: 5
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.603838 0.812512 0.428323 0.255983 0.65071 0.811262 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6124, meanQ=8.518614, numObservations: 3
action 3, numVisits=14, meanQ=6.992143, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 28398 episodes
GETTING ACTION FROM:
action 1, numVisits=22548, meanQ=6.709660, numObservations: 4
action 3, numVisits=11132, meanQ=5.812642, numObservations: 3
action 0, numVisits=586, meanQ=0.143857, numObservations: 1
action -1, numVisits=272, meanQ=-0.262034, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.603838 0.812512 0.428323 0.255983 0.65071 0.811262 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 209
Initial state: 0 0.504616 0.887851 0.962389 0.0446072 0.536899 0.814312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53301 episodes
GETTING ACTION FROM:
action 3, numVisits=53295, meanQ=4.976768, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.504616 0.887851 0.962389 0.0446072 0.536899 0.814312 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 210
Initial state: 0 0.321089 0.510022 0.516957 0.8176 0.608768 0.885242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52102 episodes
GETTING ACTION FROM:
action 2, numVisits=52075, meanQ=4.808163, numObservations: 4
action 0, numVisits=21, meanQ=3.284423, numObservations: 1
action 3, numVisits=3, meanQ=0.000033, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.321089 0.510022 0.516957 0.8176 0.608768 0.885242 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 211
Initial state: 0 0.121053 0.844615 0.593256 0.818506 0.533639 0.808895 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54585 episodes
GETTING ACTION FROM:
action 2, numVisits=54534, meanQ=4.965465, numObservations: 5
action -1, numVisits=26, meanQ=3.654340, numObservations: 1
action 0, numVisits=18, meanQ=3.396977, numObservations: 1
action 3, numVisits=6, meanQ=0.816667, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.121053 0.844615 0.593256 0.818506 0.533639 0.808895 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 212
Initial state: 0 0.0620024 0.367863 0.631161 0.851538 0.542664 0.877672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55223 episodes
GETTING ACTION FROM:
action 2, numVisits=55203, meanQ=5.057797, numObservations: 5
action -1, numVisits=15, meanQ=3.345355, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.0620024 0.367863 0.631161 0.851538 0.542664 0.877672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 213
Initial state: 0 0.420749 0.487222 0.504031 0.840164 0.657707 0.876363 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54777 episodes
GETTING ACTION FROM:
action 3, numVisits=50318, meanQ=4.988565, numObservations: 5
action 1, numVisits=4454, meanQ=4.912425, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.420749 0.487222 0.504031 0.840164 0.657707 0.876363 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 214
Initial state: 0 0.577631 0.864192 0.290061 0.28653 0.671689 0.839744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54980 episodes
GETTING ACTION FROM:
action 1, numVisits=54966, meanQ=5.023762, numObservations: 5
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action 3, numVisits=5, meanQ=-0.200000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.577631 0.864192 0.290061 0.28653 0.671689 0.839744 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 215
Initial state: 0 0.690243 0.854369 0.793177 0.427785 0.650366 0.837101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54313 episodes
GETTING ACTION FROM:
action 3, numVisits=54302, meanQ=4.935583, numObservations: 5
action 2, numVisits=5, meanQ=1.198020, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.690243 0.854369 0.793177 0.427785 0.650366 0.837101 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4139, meanQ=4.724277, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67447 episodes
GETTING ACTION FROM:
action 2, numVisits=71584, meanQ=6.033083, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.690243 0.854369 0.793177 0.427785 0.650366 0.837101 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 216
Initial state: 0 0.639689 0.84238 0.535669 0.819022 0.527148 0.761142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31861 episodes
GETTING ACTION FROM:
action 0, numVisits=31854, meanQ=2.951295, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.639689 0.84238 0.535669 0.819022 0.527148 0.761142 w: 1
Observation: 0 0 0.889098 0 0.764552 0 0.687531 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31288, meanQ=5.004816, numObservations: 4
action 3, numVisits=475, meanQ=4.593353, numObservations: 5
action 0, numVisits=87, meanQ=4.326786, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55223 episodes
GETTING ACTION FROM:
action 1, numVisits=86510, meanQ=5.116050, numObservations: 4
action 3, numVisits=475, meanQ=4.593353, numObservations: 5
action 0, numVisits=88, meanQ=4.320953, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.639689 0.84238 0.535669 0.819022 0.527148 0.761142 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 217
Initial state: 0 0.530263 0.850249 0.524695 0.826024 0.303982 0.502058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54450 episodes
GETTING ACTION FROM:
action 2, numVisits=54438, meanQ=5.019467, numObservations: 3
action 1, numVisits=7, meanQ=0.428571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.530263 0.850249 0.524695 0.826024 0.303982 0.502058 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 218
Initial state: 0 0.624046 0.861085 0.707807 0.861212 0.652245 0.849889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54782 episodes
GETTING ACTION FROM:
action 2, numVisits=54764, meanQ=5.025255, numObservations: 4
action 1, numVisits=12, meanQ=2.158333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.624046 0.861085 0.707807 0.861212 0.652245 0.849889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 219
Initial state: 0 0.67909 0.888186 0.982157 0.599924 0.623835 0.843055 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53960 episodes
GETTING ACTION FROM:
action 3, numVisits=53947, meanQ=4.895197, numObservations: 5
action 2, numVisits=8, meanQ=1.623762, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.67909 0.888186 0.982157 0.599924 0.623835 0.843055 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 220
Initial state: 0 0.56025 0.189948 0.54272 0.80006 0.600485 0.891709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54715 episodes
GETTING ACTION FROM:
action 2, numVisits=54681, meanQ=4.924638, numObservations: 3
action 3, numVisits=18, meanQ=3.110567, numObservations: 4
action -1, numVisits=13, meanQ=2.746923, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.56025 0.189948 0.54272 0.80006 0.600485 0.891709 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 221
Initial state: 0 0.549686 0.882442 0.699405 0.828339 0.325565 0.18395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31978 episodes
GETTING ACTION FROM:
action -1, numVisits=31955, meanQ=2.880237, numObservations: 1
action 1, numVisits=12, meanQ=0.673333, numObservations: 4
action 2, numVisits=8, meanQ=0.377513, numObservations: 4
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: -1
Next state: 0 0.549686 0.882442 0.699405 0.828339 0.325565 0.18395 w: 1
Observation: 0 0.506597 0 0.705975 0 0.247262 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31894, meanQ=4.966034, numObservations: 4
action 0, numVisits=40, meanQ=3.908582, numObservations: 1
action 3, numVisits=17, meanQ=3.347059, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55440 episodes
GETTING ACTION FROM:
action 1, numVisits=87333, meanQ=4.997418, numObservations: 4
action 0, numVisits=41, meanQ=3.870690, numObservations: 1
action 3, numVisits=17, meanQ=3.347059, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.549686 0.882442 0.699405 0.828339 0.325565 0.18395 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 222
Initial state: 0 0.647333 0.438211 0.506622 0.868968 0.572837 0.870827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53315 episodes
GETTING ACTION FROM:
action 3, numVisits=53242, meanQ=5.019048, numObservations: 3
action -1, numVisits=63, meanQ=4.204411, numObservations: 1
action 1, numVisits=7, meanQ=1.428571, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.647333 0.438211 0.506622 0.868968 0.572837 0.870827 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 223
Initial state: 0 0.510439 0.818873 0.394916 0.528544 0.623987 0.86801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53957 episodes
GETTING ACTION FROM:
action 1, numVisits=53924, meanQ=4.933306, numObservations: 5
action -1, numVisits=22, meanQ=3.525706, numObservations: 1
action 3, numVisits=8, meanQ=1.500012, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.510439 0.818873 0.394916 0.528544 0.623987 0.86801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 224
Initial state: 0 0.541925 0.865472 0.339045 0.618847 0.535269 0.804768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32060 episodes
GETTING ACTION FROM:
action -1, numVisits=31819, meanQ=2.960876, numObservations: 1
action 0, numVisits=235, meanQ=2.576523, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.541925 0.865472 0.339045 0.618847 0.535269 0.804768 w: 1
Observation: 0 0.52475 0 0.256922 0 0.592524 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31523, meanQ=4.949047, numObservations: 5
action 3, numVisits=165, meanQ=4.449638, numObservations: 5
action 0, numVisits=68, meanQ=4.195109, numObservations: 1
action -1, numVisits=61, meanQ=4.151613, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54618 episodes
GETTING ACTION FROM:
action 1, numVisits=86136, meanQ=4.994741, numObservations: 5
action 3, numVisits=165, meanQ=4.449638, numObservations: 5
action 0, numVisits=71, meanQ=4.177819, numObservations: 1
action -1, numVisits=63, meanQ=4.139003, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.541925 0.865472 0.339045 0.618847 0.535269 0.804768 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 225
Initial state: 0 0.618282 0.843771 0.665029 0.848064 0.639228 0.322595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54381 episodes
GETTING ACTION FROM:
action 3, numVisits=54327, meanQ=4.995173, numObservations: 5
action 0, numVisits=22, meanQ=3.610061, numObservations: 1
action -1, numVisits=20, meanQ=3.474609, numObservations: 1
action 2, numVisits=7, meanQ=1.428571, numObservations: 3
action 1, numVisits=5, meanQ=1.198020, numObservations: 3
action: 3
Next state: 0 0.618282 0.843771 0.665029 0.848064 0.639228 0.322595 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7608, meanQ=8.411295, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 16774 episodes
GETTING ACTION FROM:
action 2, numVisits=23070, meanQ=6.560295, numObservations: 5
action 1, numVisits=461, meanQ=5.610428, numObservations: 4
action -1, numVisits=846, meanQ=-1.469473, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=9, meanQ=-40.925927, numObservations: 1
action: 2
Next state: 1 0.618282 0.843771 0.665029 0.848064 0.639228 0.322595 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 226
Initial state: 0 0.664029 0.800432 0.300562 0.30085 0.527602 0.806691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54553 episodes
GETTING ACTION FROM:
action 1, numVisits=54495, meanQ=4.932425, numObservations: 4
action 0, numVisits=53, meanQ=4.052196, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.664029 0.800432 0.300562 0.30085 0.527602 0.806691 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4085, meanQ=5.530418, numObservations: 4
action 3, numVisits=5, meanQ=1.820000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 60715 episodes
GETTING ACTION FROM:
action 1, numVisits=64798, meanQ=4.904947, numObservations: 4
action 3, numVisits=5, meanQ=1.820000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.664029 0.800432 0.300562 0.30085 0.527602 0.806691 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 227
Initial state: 0 0.564182 0.822311 0.402494 0.488713 0.554023 0.829104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54447 episodes
GETTING ACTION FROM:
action 2, numVisits=54423, meanQ=5.012101, numObservations: 4
action 0, numVisits=18, meanQ=3.469225, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.564182 0.822311 0.402494 0.488713 0.554023 0.829104 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2759, meanQ=7.771496, numObservations: 5
action 3, numVisits=41, meanQ=6.897563, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 28309 episodes
GETTING ACTION FROM:
action 1, numVisits=28401, meanQ=6.338947, numObservations: 5
action 3, numVisits=50, meanQ=5.676002, numObservations: 3
action 0, numVisits=2588, meanQ=0.423737, numObservations: 1
action -1, numVisits=72, meanQ=-0.253750, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.564182 0.822311 0.402494 0.488713 0.554023 0.829104 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 228
Initial state: 0 0.564844 0.835867 0.629946 0.89834 0.374658 0.867388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54604 episodes
GETTING ACTION FROM:
action 2, numVisits=54598, meanQ=5.031797, numObservations: 5
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.564844 0.835867 0.629946 0.89834 0.374658 0.867388 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 229
Initial state: 0 0.603502 0.892942 0.524812 0.82219 0.585643 0.76863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54761 episodes
GETTING ACTION FROM:
action 2, numVisits=54750, meanQ=5.043618, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=3, meanQ=0.000033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.603502 0.892942 0.524812 0.82219 0.585643 0.76863 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 230
Initial state: 0 0.64924 0.832433 0.0378047 0.0613308 0.640069 0.896344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50028 episodes
GETTING ACTION FROM:
action 2, numVisits=44679, meanQ=4.903295, numObservations: 5
action -1, numVisits=5331, meanQ=2.808861, numObservations: 1
action 1, numVisits=15, meanQ=1.334013, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.64924 0.832433 0.0378047 0.0613308 0.640069 0.896344 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1096, meanQ=7.767851, numObservations: 3
action 1, numVisits=4, meanQ=4.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 20266 episodes
GETTING ACTION FROM:
action 3, numVisits=10669, meanQ=5.951787, numObservations: 3
action 0, numVisits=9905, meanQ=-0.294820, numObservations: 1
action -1, numVisits=789, meanQ=-0.714708, numObservations: 1
action 1, numVisits=5, meanQ=-2.252861, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.64924 0.832433 0.0378047 0.0613308 0.640069 0.896344 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 231
Initial state: 0 0.600928 0.821837 0.620492 0.866101 0.864628 0.960064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54638 episodes
GETTING ACTION FROM:
action 1, numVisits=54538, meanQ=5.010515, numObservations: 5
action -1, numVisits=66, meanQ=4.219726, numObservations: 1
action 0, numVisits=32, meanQ=3.809213, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.600928 0.821837 0.620492 0.866101 0.864628 0.960064 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 232
Initial state: 0 0.635747 0.828779 0.733677 0.261334 0.528299 0.873145 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54450 episodes
GETTING ACTION FROM:
action 2, numVisits=54423, meanQ=4.908087, numObservations: 5
action 0, numVisits=23, meanQ=3.536390, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.635747 0.828779 0.733677 0.261334 0.528299 0.873145 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 233
Initial state: 0 0.798868 0.679561 0.619407 0.834228 0.540571 0.895483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54800 episodes
GETTING ACTION FROM:
action 3, numVisits=54735, meanQ=5.051092, numObservations: 4
action 2, numVisits=49, meanQ=4.109186, numObservations: 4
action 1, numVisits=12, meanQ=2.999175, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.798868 0.679561 0.619407 0.834228 0.540571 0.895483 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 234
Initial state: 0 0.29972 0.744223 0.695605 0.84689 0.670263 0.882572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54548 episodes
GETTING ACTION FROM:
action 3, numVisits=54390, meanQ=5.015726, numObservations: 4
action 2, numVisits=152, meanQ=3.906897, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.29972 0.744223 0.695605 0.84689 0.670263 0.882572 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 235
Initial state: 0 0.358807 0.988497 0.622334 0.878991 0.597626 0.809459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51454 episodes
GETTING ACTION FROM:
action 3, numVisits=51361, meanQ=4.783761, numObservations: 4
action -1, numVisits=88, meanQ=4.099230, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.358807 0.988497 0.622334 0.878991 0.597626 0.809459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 236
Initial state: 0 0.297898 0.259011 0.617717 0.845688 0.565112 0.832688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31959 episodes
GETTING ACTION FROM:
action 0, numVisits=31946, meanQ=2.931499, numObservations: 1
action 3, numVisits=6, meanQ=0.166667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=4, meanQ=-2.500000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.297898 0.259011 0.617717 0.845688 0.565112 0.832688 w: 1
Observation: 0 0 0.329347 0 0.944096 0 0.859012 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31929, meanQ=4.973235, numObservations: 3
action 3, numVisits=11, meanQ=2.453636, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54624 episodes
GETTING ACTION FROM:
action 1, numVisits=86551, meanQ=4.907343, numObservations: 3
action 3, numVisits=11, meanQ=2.453636, numObservations: 4
action 2, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.297898 0.259011 0.617717 0.845688 0.565112 0.832688 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=14098, meanQ=8.316550, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 24882 episodes
GETTING ACTION FROM:
action 3, numVisits=38893, meanQ=7.014375, numObservations: 4
action 0, numVisits=47, meanQ=-0.651915, numObservations: 1
action -1, numVisits=42, meanQ=-0.703571, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.297898 0.259011 0.617717 0.845688 0.565112 0.832688 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 237
Initial state: 0 0.690339 0.884273 0.511481 0.832806 0.763606 0.454075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54332 episodes
GETTING ACTION FROM:
action 3, numVisits=54283, meanQ=4.946769, numObservations: 4
action 0, numVisits=29, meanQ=3.694384, numObservations: 1
action 1, numVisits=16, meanQ=2.993756, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.690339 0.884273 0.511481 0.832806 0.763606 0.454075 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 238
Initial state: 0 0.638041 0.852756 0.191689 0.152959 0.60446 0.877898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53797 episodes
GETTING ACTION FROM:
action 3, numVisits=53765, meanQ=4.914580, numObservations: 5
action -1, numVisits=21, meanQ=3.487341, numObservations: 1
action 2, numVisits=8, meanQ=2.375000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.638041 0.852756 0.191689 0.152959 0.60446 0.877898 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 239
Initial state: 0 0.572507 0.83485 0.579963 0.875048 0.467661 0.339688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30730 episodes
GETTING ACTION FROM:
action 0, numVisits=30716, meanQ=2.758262, numObservations: 1
action 2, numVisits=8, meanQ=-0.125000, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.572507 0.83485 0.579963 0.875048 0.467661 0.339688 w: 1
Observation: 0 0 0.895671 0 0.934975 0 0.282904 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=30656, meanQ=4.826186, numObservations: 4
action 1, numVisits=53, meanQ=3.776987, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 51327 episodes
GETTING ACTION FROM:
action 2, numVisits=81974, meanQ=4.705650, numObservations: 4
action 1, numVisits=61, meanQ=3.739185, numObservations: 4
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.572507 0.83485 0.579963 0.875048 0.467661 0.339688 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 240
Initial state: 0 0.601413 0.89318 0.574745 0.810169 0.957068 0.337329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54601 episodes
GETTING ACTION FROM:
action 3, numVisits=54498, meanQ=4.982586, numObservations: 4
action -1, numVisits=31, meanQ=3.805243, numObservations: 1
action 0, numVisits=32, meanQ=3.797957, numObservations: 1
action 2, numVisits=29, meanQ=2.952762, numObservations: 3
action 1, numVisits=11, meanQ=2.363636, numObservations: 2
action: 3
Next state: 2 0.601413 0.89318 0.574745 0.810169 0.957068 0.337329 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 241
Initial state: 0 0.087525 0.293143 0.68087 0.897818 0.551055 0.820467 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54586 episodes
GETTING ACTION FROM:
action 3, numVisits=54552, meanQ=5.011088, numObservations: 4
action -1, numVisits=30, meanQ=3.761856, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.087525 0.293143 0.68087 0.897818 0.551055 0.820467 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 242
Initial state: 0 0.578217 0.879099 0.949939 0.557355 0.534327 0.832337 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54155 episodes
GETTING ACTION FROM:
action 3, numVisits=54148, meanQ=4.965359, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.578217 0.879099 0.949939 0.557355 0.534327 0.832337 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 243
Initial state: 0 0.504728 0.834696 0.690362 0.864199 0.786958 0.245113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31986 episodes
GETTING ACTION FROM:
action -1, numVisits=31697, meanQ=3.035356, numObservations: 1
action 0, numVisits=284, meanQ=2.688580, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.504728 0.834696 0.690362 0.864199 0.786958 0.245113 w: 1
Observation: 0 0.481843 0 0.686319 0 0.87431 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31690, meanQ=5.014295, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55576 episodes
GETTING ACTION FROM:
action 2, numVisits=87260, meanQ=4.983465, numObservations: 5
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.504728 0.834696 0.690362 0.864199 0.786958 0.245113 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 244
Initial state: 0 0.599319 0.898641 0.627315 0.828033 0.321258 0.0823062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 37814 episodes
GETTING ACTION FROM:
action 0, numVisits=27137, meanQ=5.676110, numObservations: 2
action 3, numVisits=10670, meanQ=5.022019, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.599319 0.898641 0.627315 0.828033 0.321258 0.0823062 w: 1
Observation: 0 0 0.868087 0 0.875295 0 0.0709059 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=20216, meanQ=7.524969, numObservations: 4
action 2, numVisits=14, meanQ=4.700714, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55465 episodes
GETTING ACTION FROM:
action 1, numVisits=75666, meanQ=5.664856, numObservations: 4
action 2, numVisits=27, meanQ=4.390000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.599319 0.898641 0.627315 0.828033 0.321258 0.0823062 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 245
Initial state: 0 0.661907 0.820331 0.544019 0.83794 0.426129 0.0295674 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54811 episodes
GETTING ACTION FROM:
action 2, numVisits=54805, meanQ=5.234070, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.661907 0.820331 0.544019 0.83794 0.426129 0.0295674 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 246
Initial state: 0 0.641705 0.877308 0.3694 0.626535 0.672334 0.815985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54775 episodes
GETTING ACTION FROM:
action 1, numVisits=54765, meanQ=4.979664, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.641705 0.877308 0.3694 0.626535 0.672334 0.815985 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 247
Initial state: 0 0.635635 0.814898 0.274198 0.789793 0.554446 0.870851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54691 episodes
GETTING ACTION FROM:
action 3, numVisits=54629, meanQ=5.026544, numObservations: 4
action -1, numVisits=39, meanQ=3.987368, numObservations: 1
action 0, numVisits=21, meanQ=3.549132, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.635635 0.814898 0.274198 0.789793 0.554446 0.870851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 248
Initial state: 0 0.664418 0.839566 0.678982 0.893866 0.24015 0.327724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54650 episodes
GETTING ACTION FROM:
action 2, numVisits=53903, meanQ=4.998785, numObservations: 4
action 1, numVisits=700, meanQ=4.661169, numObservations: 3
action 0, numVisits=33, meanQ=3.876374, numObservations: 1
action 3, numVisits=12, meanQ=2.075008, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.664418 0.839566 0.678982 0.893866 0.24015 0.327724 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 249
Initial state: 0 0.67742 0.812552 0.152405 0.646386 0.617763 0.845312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54386 episodes
GETTING ACTION FROM:
action 2, numVisits=54350, meanQ=4.991443, numObservations: 5
action 3, numVisits=31, meanQ=3.662581, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.67742 0.812552 0.152405 0.646386 0.617763 0.845312 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6163, meanQ=8.550316, numObservations: 3
action 3, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 20917 episodes
GETTING ACTION FROM:
action 1, numVisits=13179, meanQ=7.058477, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=13899, meanQ=-0.263537, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=3, meanQ=-121.666585, numObservations: 1
action: 1
Next state: 1 0.67742 0.812552 0.152405 0.646386 0.617763 0.845312 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 250
Initial state: 0 0.30552 0.914116 0.698211 0.87235 0.662294 0.863224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54394 episodes
GETTING ACTION FROM:
action 3, numVisits=54360, meanQ=4.973833, numObservations: 4
action -1, numVisits=24, meanQ=3.632631, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action 2, numVisits=5, meanQ=-0.399980, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.30552 0.914116 0.698211 0.87235 0.662294 0.863224 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4100, meanQ=5.579395, numObservations: 3
action 1, numVisits=16, meanQ=3.748750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55206 episodes
GETTING ACTION FROM:
action 3, numVisits=59273, meanQ=5.343877, numObservations: 3
action 1, numVisits=47, meanQ=4.146596, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.30552 0.914116 0.698211 0.87235 0.662294 0.863224 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 251
Initial state: 0 0.590028 0.821328 0.720126 0.452748 0.6228 0.839038 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52868 episodes
GETTING ACTION FROM:
action 3, numVisits=50936, meanQ=4.916539, numObservations: 5
action -1, numVisits=1912, meanQ=2.764489, numObservations: 1
action 1, numVisits=17, meanQ=1.001188, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.590028 0.821328 0.720126 0.452748 0.6228 0.839038 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 252
Initial state: 0 0.644961 0.80163 0.750983 0.417696 0.594233 0.858096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54753 episodes
GETTING ACTION FROM:
action 2, numVisits=54629, meanQ=5.061853, numObservations: 5
action 0, numVisits=62, meanQ=4.203371, numObservations: 1
action -1, numVisits=44, meanQ=4.043738, numObservations: 1
action 1, numVisits=17, meanQ=1.649429, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.644961 0.80163 0.750983 0.417696 0.594233 0.858096 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 253
Initial state: 0 0.203743 0.291549 0.601348 0.806863 0.505883 0.870257 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51899 episodes
GETTING ACTION FROM:
action 1, numVisits=51861, meanQ=4.864853, numObservations: 4
action -1, numVisits=26, meanQ=3.549696, numObservations: 1
action 3, numVisits=6, meanQ=1.333333, numObservations: 3
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.203743 0.291549 0.601348 0.806863 0.505883 0.870257 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8525, meanQ=8.272949, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 16418 episodes
GETTING ACTION FROM:
action 3, numVisits=23256, meanQ=7.127677, numObservations: 3
action 2, numVisits=12, meanQ=2.999167, numObservations: 3
action -1, numVisits=1501, meanQ=0.237881, numObservations: 1
action 0, numVisits=178, meanQ=-0.168101, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.203743 0.291549 0.601348 0.806863 0.505883 0.870257 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=701, meanQ=8.303244, numObservations: 3
action 0, numVisits=275, meanQ=6.881200, numObservations: 1
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-190.081650, numObservations: 1
Sampled 34803 episodes
GETTING ACTION FROM:
action 3, numVisits=4800, meanQ=6.189277, numObservations: 4
action 2, numVisits=19831, meanQ=5.791287, numObservations: 3
action 0, numVisits=11150, meanQ=-1.437165, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-190.081650, numObservations: 1
action: 3
Next state: 1 0.203743 0.291549 0.601348 0.806863 0.505883 0.870257 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 254
Initial state: 0 0.686768 0.837252 0.594535 0.844788 0.554309 0.525759 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54516 episodes
GETTING ACTION FROM:
action 2, numVisits=54363, meanQ=4.963697, numObservations: 4
action 3, numVisits=137, meanQ=4.358932, numObservations: 3
action 0, numVisits=13, meanQ=3.101546, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.686768 0.837252 0.594535 0.844788 0.554309 0.525759 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 255
Initial state: 0 0.577398 0.852269 0.963708 0.677873 0.524231 0.853472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54076 episodes
GETTING ACTION FROM:
action 1, numVisits=54018, meanQ=4.994489, numObservations: 4
action -1, numVisits=54, meanQ=4.105897, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.577398 0.852269 0.963708 0.677873 0.524231 0.853472 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 256
Initial state: 0 0.503209 0.846094 0.57301 0.808734 0.932612 0.634716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54726 episodes
GETTING ACTION FROM:
action 3, numVisits=54712, meanQ=5.009985, numObservations: 4
action 2, numVisits=8, meanQ=-0.125000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.503209 0.846094 0.57301 0.808734 0.932612 0.634716 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=931, meanQ=8.428436, numObservations: 4
action 1, numVisits=6663, meanQ=8.348973, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 15379 episodes
GETTING ACTION FROM:
action 1, numVisits=14213, meanQ=7.098849, numObservations: 4
action 2, numVisits=7443, meanQ=6.597072, numObservations: 4
action 0, numVisits=1299, meanQ=0.277991, numObservations: 1
action -1, numVisits=20, meanQ=-1.059500, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.503209 0.846094 0.57301 0.808734 0.932612 0.634716 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 257
Initial state: 0 0.648993 0.84975 0.583311 0.865023 0.570236 0.96659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54718 episodes
GETTING ACTION FROM:
action 3, numVisits=54706, meanQ=4.988270, numObservations: 4
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=6, meanQ=-3.001667, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.648993 0.84975 0.583311 0.865023 0.570236 0.96659 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 258
Initial state: 0 0.845748 0.385862 0.536124 0.832703 0.528833 0.807505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54187 episodes
GETTING ACTION FROM:
action 3, numVisits=54179, meanQ=4.943163, numObservations: 4
action 2, numVisits=3, meanQ=0.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.845748 0.385862 0.536124 0.832703 0.528833 0.807505 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 259
Initial state: 0 0.701028 0.196124 0.687342 0.846981 0.555897 0.841143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31854 episodes
GETTING ACTION FROM:
action 0, numVisits=31847, meanQ=2.815599, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.701028 0.196124 0.687342 0.846981 0.555897 0.841143 w: 1
Observation: 0 0 0.280291 0 0.778091 0 0.78809 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31820, meanQ=4.896290, numObservations: 4
action 1, numVisits=12, meanQ=2.998350, numObservations: 3
action 2, numVisits=10, meanQ=2.598000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 55681 episodes
GETTING ACTION FROM:
action 1, numVisits=54314, meanQ=5.129629, numObservations: 3
action 3, numVisits=33199, meanQ=4.887806, numObservations: 4
action 2, numVisits=10, meanQ=2.598000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.701028 0.196124 0.687342 0.846981 0.555897 0.841143 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=3893, meanQ=4.449194, numObservations: 4
action -1, numVisits=68, meanQ=3.198648, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29277 episodes
GETTING ACTION FROM:
action 3, numVisits=30951, meanQ=5.981007, numObservations: 4
action 0, numVisits=1184, meanQ=0.084502, numObservations: 2
action -1, numVisits=1102, meanQ=-0.174404, numObservations: 1
action 2, numVisits=4, meanQ=-2.502475, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.701028 0.196124 0.687342 0.846981 0.555897 0.841143 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 260
Initial state: 0 0.573344 0.852005 0.833902 0.580947 0.517771 0.818474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54459 episodes
GETTING ACTION FROM:
action 2, numVisits=54434, meanQ=4.952974, numObservations: 4
action 1, numVisits=20, meanQ=3.207515, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.573344 0.852005 0.833902 0.580947 0.517771 0.818474 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 261
Initial state: 0 0.617122 0.86556 0.267836 0.073542 0.660102 0.827384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53866 episodes
GETTING ACTION FROM:
action 2, numVisits=53850, meanQ=4.931647, numObservations: 4
action -1, numVisits=12, meanQ=3.004673, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.617122 0.86556 0.267836 0.073542 0.660102 0.827384 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7543, meanQ=8.422658, numObservations: 3
action 1, numVisits=4, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 24193 episodes
GETTING ACTION FROM:
action 3, numVisits=31728, meanQ=6.717256, numObservations: 3
action 1, numVisits=4, meanQ=2.995000, numObservations: 2
action 0, numVisits=8, meanQ=-2.001238, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.695388, numObservations: 1
action: 3
Next state: 1 0.617122 0.86556 0.267836 0.073542 0.660102 0.827384 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 262
Initial state: 0 0.597881 0.894792 0.369381 0.957443 0.638852 0.801329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53066 episodes
GETTING ACTION FROM:
action 3, numVisits=53060, meanQ=4.987858, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.597881 0.894792 0.369381 0.957443 0.638852 0.801329 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 263
Initial state: 0 0.689598 0.896203 0.576275 0.817753 0.346715 0.339932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54457 episodes
GETTING ACTION FROM:
action 2, numVisits=54451, meanQ=4.963512, numObservations: 5
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.689598 0.896203 0.576275 0.817753 0.346715 0.339932 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.591153 0.870706 0.84711 0.395972 0.63122 0.809756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54617 episodes
GETTING ACTION FROM:
action 2, numVisits=54611, meanQ=5.008669, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.591153 0.870706 0.84711 0.395972 0.63122 0.809756 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 265
Initial state: 0 0.623957 0.292376 0.673951 0.846711 0.607837 0.84561 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48730 episodes
GETTING ACTION FROM:
action 2, numVisits=44807, meanQ=4.778134, numObservations: 5
action 0, numVisits=3919, meanQ=2.976211, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.623957 0.292376 0.673951 0.846711 0.607837 0.84561 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 266
Initial state: 0 0.551664 0.883606 0.602124 0.81111 0.602739 0.134808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51008 episodes
GETTING ACTION FROM:
action 1, numVisits=50898, meanQ=4.757552, numObservations: 4
action 0, numVisits=100, meanQ=4.087840, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.551664 0.883606 0.602124 0.81111 0.602739 0.134808 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 267
Initial state: 0 0.130414 0.00053637 0.524999 0.896392 0.649445 0.804889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54242 episodes
GETTING ACTION FROM:
action 2, numVisits=54098, meanQ=4.970953, numObservations: 4
action 0, numVisits=88, meanQ=4.281038, numObservations: 1
action -1, numVisits=54, meanQ=4.086547, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.130414 0.00053637 0.524999 0.896392 0.649445 0.804889 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 268
Initial state: 0 0.503045 0.815082 0.550138 0.792201 0.607352 0.875016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54479 episodes
GETTING ACTION FROM:
action 1, numVisits=54467, meanQ=4.976210, numObservations: 5
action 3, numVisits=7, meanQ=1.428571, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.503045 0.815082 0.550138 0.792201 0.607352 0.875016 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 269
Initial state: 0 0.64785 0.886916 0.406022 0.808751 0.689414 0.826795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54779 episodes
GETTING ACTION FROM:
action 2, numVisits=54730, meanQ=4.945991, numObservations: 4
action -1, numVisits=35, meanQ=3.835926, numObservations: 1
action 3, numVisits=10, meanQ=2.400000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.64785 0.886916 0.406022 0.808751 0.689414 0.826795 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 270
Initial state: 0 0.514833 0.802094 0.618618 0.861554 0.311352 0.3359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31771 episodes
GETTING ACTION FROM:
action 0, numVisits=31766, meanQ=2.822111, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.514833 0.802094 0.618618 0.861554 0.311352 0.3359 w: 1
Observation: 0 0 0.879103 0 0.803067 0 0.25958 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31626, meanQ=4.943146, numObservations: 5
action -1, numVisits=97, meanQ=4.242203, numObservations: 1
action 1, numVisits=37, meanQ=2.083519, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 54447 episodes
GETTING ACTION FROM:
action 2, numVisits=86072, meanQ=4.893140, numObservations: 5
action -1, numVisits=98, meanQ=4.233819, numObservations: 1
action 1, numVisits=37, meanQ=2.083519, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.514833 0.802094 0.618618 0.861554 0.311352 0.3359 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 271
Initial state: 0 0.681 0.811894 0.580016 0.830414 0.188754 0.0329088 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54593 episodes
GETTING ACTION FROM:
action 1, numVisits=54540, meanQ=4.903832, numObservations: 5
action -1, numVisits=44, meanQ=3.922917, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.681 0.811894 0.580016 0.830414 0.188754 0.0329088 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 272
Initial state: 0 0.653954 0.833584 0.551196 0.809235 0.936524 0.903317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54736 episodes
GETTING ACTION FROM:
action 2, numVisits=54679, meanQ=4.990878, numObservations: 5
action -1, numVisits=26, meanQ=3.693786, numObservations: 1
action 1, numVisits=28, meanQ=3.568225, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.653954 0.833584 0.551196 0.809235 0.936524 0.903317 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 273
Initial state: 0 0.605899 0.802837 0.484806 0.137349 0.527518 0.814382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50213 episodes
GETTING ACTION FROM:
action 1, numVisits=49893, meanQ=4.693041, numObservations: 5
action -1, numVisits=315, meanQ=4.341782, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.605899 0.802837 0.484806 0.137349 0.527518 0.814382 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3755, meanQ=4.681133, numObservations: 4
action 3, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67773 episodes
GETTING ACTION FROM:
action 2, numVisits=71525, meanQ=5.841646, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action 3, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.605899 0.802837 0.484806 0.137349 0.527518 0.814382 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2212, meanQ=7.970211, numObservations: 4
action 3, numVisits=4, meanQ=4.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 53569 episodes
GETTING ACTION FROM:
action 1, numVisits=7804, meanQ=6.597021, numObservations: 5
action 3, numVisits=44750, meanQ=6.278075, numObservations: 4
action -1, numVisits=2184, meanQ=-1.735215, numObservations: 1
action 0, numVisits=1049, meanQ=-1.793116, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.605899 0.802837 0.484806 0.137349 0.527518 0.814382 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 274
Initial state: 0 0.595916 0.859517 0.916258 0.65075 0.520716 0.883089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54294 episodes
GETTING ACTION FROM:
action 3, numVisits=54137, meanQ=4.962467, numObservations: 3
action -1, numVisits=153, meanQ=4.431291, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.595916 0.859517 0.916258 0.65075 0.520716 0.883089 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3972, meanQ=4.816086, numObservations: 4
action 1, numVisits=25, meanQ=3.239200, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 66939 episodes
GETTING ACTION FROM:
action 2, numVisits=70909, meanQ=5.728437, numObservations: 4
action 1, numVisits=25, meanQ=3.239200, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 2 0.595916 0.859517 0.916258 0.65075 0.520716 0.883089 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 275
Initial state: 0 0.591537 0.871897 0.315106 0.380273 0.542779 0.821213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31861 episodes
GETTING ACTION FROM:
action -1, numVisits=29078, meanQ=2.907244, numObservations: 1
action 0, numVisits=2780, meanQ=2.722413, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.591537 0.871897 0.315106 0.380273 0.542779 0.821213 w: 1
Observation: 0 0.59059 0 0.336784 0 0.449379 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=29046, meanQ=5.022812, numObservations: 4
action 2, numVisits=26, meanQ=2.231546, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 53786 episodes
GETTING ACTION FROM:
action 1, numVisits=82831, meanQ=5.013598, numObservations: 4
action 2, numVisits=26, meanQ=2.231546, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-4.994950, numObservations: 1
action: 1
Next state: 1 0.591537 0.871897 0.315106 0.380273 0.542779 0.821213 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 276
Initial state: 0 0.553542 0.888045 0.980291 0.507417 0.636458 0.88134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52133 episodes
GETTING ACTION FROM:
action 1, numVisits=52122, meanQ=4.917620, numObservations: 3
action 3, numVisits=6, meanQ=2.166700, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.553542 0.888045 0.980291 0.507417 0.636458 0.88134 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 277
Initial state: 0 0.57472 0.821458 0.655093 0.874928 0.229775 0.509862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54345 episodes
GETTING ACTION FROM:
action 2, numVisits=54288, meanQ=4.899855, numObservations: 5
action 0, numVisits=51, meanQ=3.984059, numObservations: 1
action 1, numVisits=3, meanQ=0.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.57472 0.821458 0.655093 0.874928 0.229775 0.509862 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.66029 0.880671 0.598463 0.827443 0.802277 0.51108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51681 episodes
GETTING ACTION FROM:
action 1, numVisits=51582, meanQ=4.801754, numObservations: 5
action -1, numVisits=44, meanQ=3.716021, numObservations: 1
action 3, numVisits=29, meanQ=3.339317, numObservations: 3
action 0, numVisits=20, meanQ=3.239456, numObservations: 1
action 2, numVisits=6, meanQ=1.498333, numObservations: 3
action: 1
Next state: 1 0.66029 0.880671 0.598463 0.827443 0.802277 0.51108 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 279
Initial state: 0 0.67646 0.8144 0.676221 0.849848 0.804226 0.745672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32001 episodes
GETTING ACTION FROM:
action 0, numVisits=31967, meanQ=2.977420, numObservations: 1
action 2, numVisits=30, meanQ=1.430680, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.67646 0.8144 0.676221 0.849848 0.804226 0.745672 w: 1
Observation: 0 0 0.894798 0 0.93669 0 0.772742 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31838, meanQ=4.992000, numObservations: 4
action 1, numVisits=114, meanQ=4.341921, numObservations: 5
action 2, numVisits=10, meanQ=2.598000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 54549 episodes
GETTING ACTION FROM:
action 3, numVisits=86385, meanQ=4.955130, numObservations: 4
action 1, numVisits=114, meanQ=4.341921, numObservations: 5
action 2, numVisits=12, meanQ=2.333342, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.67646 0.8144 0.676221 0.849848 0.804226 0.745672 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 280
Initial state: 0 0.540396 0.852042 0.631343 0.850629 0.12544 0.398694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29766 episodes
GETTING ACTION FROM:
action 0, numVisits=29753, meanQ=4.299972, numObservations: 2
action 1, numVisits=6, meanQ=-1.000000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.540396 0.852042 0.631343 0.850629 0.12544 0.398694 w: 1
Observation: 0 0 0.772233 0 0.896468 0 0.386164 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=6974, meanQ=5.665029, numObservations: 1
action 2, numVisits=9879, meanQ=4.994859, numObservations: 5
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 42081 episodes
GETTING ACTION FROM:
action 2, numVisits=34435, meanQ=4.774049, numObservations: 5
action -1, numVisits=24498, meanQ=4.753520, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.540396 0.852042 0.631343 0.850629 0.12544 0.398694 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 281
Initial state: 0 0.611357 0.820223 0.824802 0.54513 0.551094 0.875199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54351 episodes
GETTING ACTION FROM:
action 2, numVisits=54270, meanQ=5.032062, numObservations: 5
action 0, numVisits=67, meanQ=4.233529, numObservations: 1
action 3, numVisits=9, meanQ=2.443344, numObservations: 2
action 1, numVisits=3, meanQ=0.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.611357 0.820223 0.824802 0.54513 0.551094 0.875199 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 282
Initial state: 0 0.572493 0.861843 0.544715 0.856959 0.479538 0.210784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54212 episodes
GETTING ACTION FROM:
action 3, numVisits=54183, meanQ=4.996751, numObservations: 5
action -1, numVisits=24, meanQ=3.634606, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.572493 0.861843 0.544715 0.856959 0.479538 0.210784 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7679, meanQ=8.413562, numObservations: 4
action 2, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 38592 episodes
GETTING ACTION FROM:
action 1, numVisits=45363, meanQ=6.616450, numObservations: 5
action 2, numVisits=104, meanQ=2.141327, numObservations: 5
action -1, numVisits=677, meanQ=-0.106855, numObservations: 1
action 0, numVisits=132, meanQ=-0.441141, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.572493 0.861843 0.544715 0.856959 0.479538 0.210784 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 283
Initial state: 0 0.995032 0.870699 0.690483 0.836202 0.615267 0.847531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54523 episodes
GETTING ACTION FROM:
action 2, numVisits=54436, meanQ=5.015268, numObservations: 4
action 0, numVisits=74, meanQ=4.163077, numObservations: 1
action 3, numVisits=7, meanQ=1.701443, numObservations: 2
action 1, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.995032 0.870699 0.690483 0.836202 0.615267 0.847531 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 284
Initial state: 0 0.512882 0.807302 0.0924841 0.0642649 0.549884 0.894723 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52323 episodes
GETTING ACTION FROM:
action 3, numVisits=49038, meanQ=4.952304, numObservations: 4
action -1, numVisits=3281, meanQ=2.941096, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.512882 0.807302 0.0924841 0.0642649 0.549884 0.894723 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 285
Initial state: 0 0.589444 0.835253 0.662781 0.357048 0.568342 0.806171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54792 episodes
GETTING ACTION FROM:
action 2, numVisits=54785, meanQ=4.992017, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.589444 0.835253 0.662781 0.357048 0.568342 0.806171 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 286
Initial state: 0 0.548507 0.824597 0.66543 0.870117 0.371761 0.64747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32000 episodes
GETTING ACTION FROM:
action -1, numVisits=31995, meanQ=2.898658, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.548507 0.824597 0.66543 0.870117 0.371761 0.64747 w: 1
Observation: 0 0.549688 0 0.641616 0 0.302645 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31936, meanQ=4.971963, numObservations: 4
action -1, numVisits=32, meanQ=3.841777, numObservations: 1
action 0, numVisits=24, meanQ=3.607992, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54468 episodes
GETTING ACTION FROM:
action 3, numVisits=86400, meanQ=4.965455, numObservations: 4
action -1, numVisits=35, meanQ=3.819241, numObservations: 1
action 0, numVisits=25, meanQ=3.514333, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.548507 0.824597 0.66543 0.870117 0.371761 0.64747 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=15000, meanQ=8.297683, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 21233 episodes
GETTING ACTION FROM:
action 1, numVisits=23757, meanQ=7.396315, numObservations: 5
action 2, numVisits=10985, meanQ=5.871838, numObservations: 4
action -1, numVisits=1479, meanQ=0.169432, numObservations: 1
action 0, numVisits=15, meanQ=-1.406660, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.548507 0.824597 0.66543 0.870117 0.371761 0.64747 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 287
Initial state: 0 0.573122 0.86635 0.612866 0.878857 0.0548373 0.579392 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51316 episodes
GETTING ACTION FROM:
action 2, numVisits=51289, meanQ=4.777244, numObservations: 3
action 0, numVisits=17, meanQ=3.078339, numObservations: 1
action 3, numVisits=7, meanQ=0.428571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.573122 0.86635 0.612866 0.878857 0.0548373 0.579392 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 288
Initial state: 0 0.627255 0.821619 0.598334 0.0880388 0.577227 0.896608 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54446 episodes
GETTING ACTION FROM:
action 1, numVisits=19950, meanQ=5.075828, numObservations: 4
action 3, numVisits=34360, meanQ=4.995731, numObservations: 4
action 2, numVisits=84, meanQ=4.088218, numObservations: 5
action -1, numVisits=43, meanQ=4.044263, numObservations: 1
action 0, numVisits=9, meanQ=2.730000, numObservations: 1
action: 1
Next state: 1 0.627255 0.821619 0.598334 0.0880388 0.577227 0.896608 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 289
Initial state: 0 0.510601 0.868603 0.690462 0.808864 0.704879 0.554145 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54323 episodes
GETTING ACTION FROM:
action 3, numVisits=54280, meanQ=4.934377, numObservations: 4
action -1, numVisits=27, meanQ=3.629543, numObservations: 1
action 2, numVisits=13, meanQ=2.460769, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.510601 0.868603 0.690462 0.808864 0.704879 0.554145 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 290
Initial state: 0 0.774253 0.782206 0.672119 0.859885 0.692594 0.878815 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31818 episodes
GETTING ACTION FROM:
action -1, numVisits=31813, meanQ=2.939292, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.774253 0.782206 0.672119 0.859885 0.692594 0.878815 w: 1
Observation: 0 0.713498 0 0.58763 0 0.659174 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31603, meanQ=4.979139, numObservations: 5
action 3, numVisits=120, meanQ=4.407982, numObservations: 5
action 0, numVisits=45, meanQ=4.029934, numObservations: 1
action -1, numVisits=40, meanQ=3.985419, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
Sampled 54525 episodes
GETTING ACTION FROM:
action 1, numVisits=86127, meanQ=5.086693, numObservations: 5
action 3, numVisits=120, meanQ=4.407982, numObservations: 5
action 0, numVisits=45, meanQ=4.029934, numObservations: 1
action -1, numVisits=41, meanQ=3.965874, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action: 1
Next state: 2 0.774253 0.782206 0.672119 0.859885 0.692594 0.878815 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 291
Initial state: 0 0.100285 0.990738 0.554462 0.80958 0.633047 0.871833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53776 episodes
GETTING ACTION FROM:
action 3, numVisits=53754, meanQ=4.979322, numObservations: 5
action 2, numVisits=17, meanQ=2.588841, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.100285 0.990738 0.554462 0.80958 0.633047 0.871833 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4015, meanQ=4.597987, numObservations: 4
action -1, numVisits=51, meanQ=3.861016, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 66069 episodes
GETTING ACTION FROM:
action 2, numVisits=70083, meanQ=5.647499, numObservations: 4
action -1, numVisits=52, meanQ=3.853638, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.100285 0.990738 0.554462 0.80958 0.633047 0.871833 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 292
Initial state: 0 0.735181 0.609318 0.679142 0.895669 0.578744 0.889967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31875 episodes
GETTING ACTION FROM:
action 0, numVisits=31870, meanQ=2.940329, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.735181 0.609318 0.679142 0.895669 0.578744 0.889967 w: 1
Observation: 0 0 0.653214 0 0.986117 0 0.960311 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31851, meanQ=5.007594, numObservations: 3
action 2, numVisits=10, meanQ=2.380010, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 54316 episodes
GETTING ACTION FROM:
action 3, numVisits=86139, meanQ=4.990180, numObservations: 3
action 1, numVisits=32, meanQ=3.550628, numObservations: 3
action 2, numVisits=10, meanQ=2.380010, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.735181 0.609318 0.679142 0.895669 0.578744 0.889967 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 293
Initial state: 0 0.596935 0.88732 0.619611 0.831831 0.404764 0.637179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53922 episodes
GETTING ACTION FROM:
action 2, numVisits=38474, meanQ=4.959703, numObservations: 4
action 1, numVisits=15432, meanQ=4.939339, numObservations: 4
action 3, numVisits=12, meanQ=2.658333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.596935 0.88732 0.619611 0.831831 0.404764 0.637179 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 294
Initial state: 0 0.593367 0.873002 0.58199 0.837421 0.339092 0.0700396 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 37093 episodes
GETTING ACTION FROM:
action 0, numVisits=28532, meanQ=5.790812, numObservations: 2
action 2, numVisits=8557, meanQ=4.942901, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.593367 0.873002 0.58199 0.837421 0.339092 0.0700396 w: 1
Observation: 0 0 0.804236 0 0.831152 0 0.160129 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10225, meanQ=8.003585, numObservations: 4
action 1, numVisits=70, meanQ=6.847573, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 55799 episodes
GETTING ACTION FROM:
action 2, numVisits=65575, meanQ=5.623243, numObservations: 4
action 1, numVisits=516, meanQ=5.350393, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.593367 0.873002 0.58199 0.837421 0.339092 0.0700396 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 295
Initial state: 0 0.597289 0.8286 0.324352 0.563486 0.698629 0.850694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54696 episodes
GETTING ACTION FROM:
action 1, numVisits=54548, meanQ=4.958239, numObservations: 4
action -1, numVisits=86, meanQ=4.256082, numObservations: 1
action 0, numVisits=32, meanQ=3.714830, numObservations: 1
action 3, numVisits=29, meanQ=2.619669, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.597289 0.8286 0.324352 0.563486 0.698629 0.850694 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 296
Initial state: 0 0.637238 0.824331 0.66127 0.0350257 0.515325 0.817954 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54650 episodes
GETTING ACTION FROM:
action 3, numVisits=54641, meanQ=5.024872, numObservations: 5
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.637238 0.824331 0.66127 0.0350257 0.515325 0.817954 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3801, meanQ=5.575198, numObservations: 4
action 2, numVisits=257, meanQ=5.279483, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67536 episodes
GETTING ACTION FROM:
action 2, numVisits=66892, meanQ=5.757642, numObservations: 4
action 3, numVisits=4700, meanQ=5.399738, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.637238 0.824331 0.66127 0.0350257 0.515325 0.817954 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 297
Initial state: 0 0.413603 0.457593 0.522392 0.881108 0.696226 0.858864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54348 episodes
GETTING ACTION FROM:
action 1, numVisits=54114, meanQ=4.999768, numObservations: 4
action 0, numVisits=201, meanQ=4.530121, numObservations: 1
action -1, numVisits=27, meanQ=3.661822, numObservations: 1
action 2, numVisits=5, meanQ=-0.978000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.413603 0.457593 0.522392 0.881108 0.696226 0.858864 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6479, meanQ=8.432728, numObservations: 5
action 2, numVisits=1109, meanQ=8.353340, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 19447 episodes
GETTING ACTION FROM:
action 3, numVisits=12354, meanQ=7.164771, numObservations: 5
action 2, numVisits=10837, meanQ=6.075189, numObservations: 5
action -1, numVisits=3839, meanQ=0.228338, numObservations: 1
action 0, numVisits=7, meanQ=-2.144257, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.413603 0.457593 0.522392 0.881108 0.696226 0.858864 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 298
Initial state: 0 0.596054 0.828129 0.183402 0.436595 0.633199 0.896563 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 42763 episodes
GETTING ACTION FROM:
action 1, numVisits=26019, meanQ=5.077768, numObservations: 5
action 0, numVisits=16705, meanQ=3.003930, numObservations: 1
action -1, numVisits=35, meanQ=1.963954, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.596054 0.828129 0.183402 0.436595 0.633199 0.896563 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 299
Initial state: 0 0.624742 0.888012 0.567269 0.815812 0.0522517 0.9474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54689 episodes
GETTING ACTION FROM:
action 3, numVisits=54683, meanQ=4.940407, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.624742 0.888012 0.567269 0.815812 0.0522517 0.9474 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3929, meanQ=4.843998, numObservations: 4
action 2, numVisits=4, meanQ=2.002525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67320 episodes
GETTING ACTION FROM:
action 1, numVisits=71248, meanQ=5.710776, numObservations: 4
action 2, numVisits=4, meanQ=2.002525, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.624742 0.888012 0.567269 0.815812 0.0522517 0.9474 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 300
Initial state: 0 0.519607 0.888516 0.36178 0.747964 0.61424 0.849464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54258 episodes
GETTING ACTION FROM:
action 3, numVisits=54250, meanQ=5.170486, numObservations: 5
action 2, numVisits=3, meanQ=0.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.519607 0.888516 0.36178 0.747964 0.61424 0.849464 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 301
Initial state: 0 0.656949 0.863624 0.622834 0.813898 0.479118 0.765744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31844 episodes
GETTING ACTION FROM:
action -1, numVisits=31835, meanQ=2.847505, numObservations: 1
action 3, numVisits=5, meanQ=-0.200000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.656949 0.863624 0.622834 0.813898 0.479118 0.765744 w: 1
Observation: 0 0.714653 0 0.674483 0 0.451595 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31827, meanQ=4.896231, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54632 episodes
GETTING ACTION FROM:
action 2, numVisits=86456, meanQ=5.090043, numObservations: 5
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-3.505000, numObservations: 2
action: 2
Next state: 1 0.656949 0.863624 0.622834 0.813898 0.479118 0.765744 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 302
Initial state: 0 0.649017 0.804964 0.342942 0.94397 0.640562 0.857965 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53140 episodes
GETTING ACTION FROM:
action 1, numVisits=53067, meanQ=5.002413, numObservations: 4
action 0, numVisits=65, meanQ=4.197324, numObservations: 1
action 2, numVisits=5, meanQ=1.398000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.649017 0.804964 0.342942 0.94397 0.640562 0.857965 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 303
Initial state: 0 0.535224 0.880305 0.653347 0.892571 0.692429 0.338189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54174 episodes
GETTING ACTION FROM:
action 2, numVisits=54168, meanQ=5.027191, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.535224 0.880305 0.653347 0.892571 0.692429 0.338189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 304
Initial state: 0 0.748153 0.781395 0.528597 0.84488 0.558758 0.81294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53988 episodes
GETTING ACTION FROM:
action 2, numVisits=53896, meanQ=5.016477, numObservations: 5
action 0, numVisits=54, meanQ=4.113326, numObservations: 1
action -1, numVisits=36, meanQ=3.916952, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.748153 0.781395 0.528597 0.84488 0.558758 0.81294 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4037, meanQ=5.672302, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 60565 episodes
GETTING ACTION FROM:
action 2, numVisits=64600, meanQ=5.072210, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.748153 0.781395 0.528597 0.84488 0.558758 0.81294 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1141, meanQ=6.085889, numObservations: 4
action 1, numVisits=8, meanQ=2.498750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 69718 episodes
GETTING ACTION FROM:
action 3, numVisits=70859, meanQ=6.005722, numObservations: 4
action 1, numVisits=8, meanQ=2.498750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.748153 0.781395 0.528597 0.84488 0.558758 0.81294 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=812, meanQ=8.087672, numObservations: 3
action 2, numVisits=175, meanQ=4.642450, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 70660 episodes
GETTING ACTION FROM:
action 1, numVisits=71472, meanQ=6.135590, numObservations: 3
action 2, numVisits=175, meanQ=4.642450, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.748153 0.781395 0.528597 0.84488 0.558758 0.81294 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -22.5537
Run # 305
Initial state: 0 0.664357 0.874478 0.50886 0.807885 0.728766 0.775756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54204 episodes
GETTING ACTION FROM:
action 1, numVisits=53830, meanQ=4.946874, numObservations: 5
action 2, numVisits=336, meanQ=4.600770, numObservations: 4
action 0, numVisits=35, meanQ=3.843148, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.664357 0.874478 0.50886 0.807885 0.728766 0.775756 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 306
Initial state: 0 0.565286 0.89582 0.697768 0.862165 0.764163 0.915514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54666 episodes
GETTING ACTION FROM:
action 1, numVisits=54628, meanQ=5.005809, numObservations: 4
action 0, numVisits=31, meanQ=3.827535, numObservations: 1
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.565286 0.89582 0.697768 0.862165 0.764163 0.915514 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 307
Initial state: 0 0.518094 0.8466 0.622342 0.855073 0.0311229 0.228232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54791 episodes
GETTING ACTION FROM:
action 1, numVisits=54761, meanQ=4.954589, numObservations: 4
action -1, numVisits=9, meanQ=2.730000, numObservations: 1
action 3, numVisits=16, meanQ=1.813756, numObservations: 3
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.518094 0.8466 0.622342 0.855073 0.0311229 0.228232 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 308
Initial state: 0 0.526856 0.818009 0.693061 0.600336 0.617096 0.817017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55239 episodes
GETTING ACTION FROM:
action 2, numVisits=55141, meanQ=5.030495, numObservations: 5
action -1, numVisits=60, meanQ=4.191046, numObservations: 1
action 0, numVisits=31, meanQ=3.801989, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.526856 0.818009 0.693061 0.600336 0.617096 0.817017 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 309
Initial state: 0 0.502432 0.804335 0.572469 0.80793 0.270669 0.464655 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54493 episodes
GETTING ACTION FROM:
action 3, numVisits=54487, meanQ=4.963331, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.502432 0.804335 0.572469 0.80793 0.270669 0.464655 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8867, meanQ=8.288895, numObservations: 5
action 1, numVisits=81, meanQ=7.414325, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 21929 episodes
GETTING ACTION FROM:
action 2, numVisits=18782, meanQ=6.922670, numObservations: 5
action 1, numVisits=10922, meanQ=5.957124, numObservations: 3
action 0, numVisits=553, meanQ=-0.003924, numObservations: 1
action -1, numVisits=622, meanQ=-0.716640, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.502432 0.804335 0.572469 0.80793 0.270669 0.464655 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=764, meanQ=8.297618, numObservations: 3
action 1, numVisits=9, meanQ=4.060167, numObservations: 2
action 0, numVisits=183, meanQ=2.002230, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=2, meanQ=-187.720677, numObservations: 1
Sampled 40694 episodes
GETTING ACTION FROM:
action 1, numVisits=7821, meanQ=6.323524, numObservations: 4
action 2, numVisits=32866, meanQ=5.715388, numObservations: 3
action 0, numVisits=963, meanQ=-1.098565, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=2, meanQ=-187.720677, numObservations: 1
action: 1
Next state: 1 0.502432 0.804335 0.572469 0.80793 0.270669 0.464655 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 310
Initial state: 0 0.742442 0.201935 0.643606 0.859224 0.550662 0.814806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54554 episodes
GETTING ACTION FROM:
action 2, numVisits=54543, meanQ=5.005687, numObservations: 4
action 1, numVisits=6, meanQ=2.333350, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.742442 0.201935 0.643606 0.859224 0.550662 0.814806 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 311
Initial state: 0 0.421035 0.655811 0.598871 0.894778 0.509604 0.848378 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54674 episodes
GETTING ACTION FROM:
action 3, numVisits=54558, meanQ=4.985193, numObservations: 4
action -1, numVisits=84, meanQ=4.267663, numObservations: 1
action 2, numVisits=27, meanQ=2.730000, numObservations: 4
action 1, numVisits=3, meanQ=0.663333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.421035 0.655811 0.598871 0.894778 0.509604 0.848378 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 312
Initial state: 0 0.553408 0.87307 0.120416 0.262333 0.693884 0.818468 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32035 episodes
GETTING ACTION FROM:
action -1, numVisits=32018, meanQ=2.914202, numObservations: 1
action 1, numVisits=13, meanQ=1.155392, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.553408 0.87307 0.120416 0.262333 0.693884 0.818468 w: 1
Observation: 0 0.502822 0 0.122167 0 0.603319 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31979, meanQ=4.976327, numObservations: 5
action 1, numVisits=33, meanQ=3.787279, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55319 episodes
GETTING ACTION FROM:
action 2, numVisits=87286, meanQ=5.175060, numObservations: 5
action 1, numVisits=45, meanQ=3.924893, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.553408 0.87307 0.120416 0.262333 0.693884 0.818468 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=12198, meanQ=8.418244, numObservations: 4
action 3, numVisits=9, meanQ=5.890011, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 15993 episodes
GETTING ACTION FROM:
action 1, numVisits=25308, meanQ=7.376064, numObservations: 4
action 3, numVisits=177, meanQ=5.106385, numObservations: 4
action -1, numVisits=2708, meanQ=0.171931, numObservations: 1
action 0, numVisits=9, meanQ=-1.890000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.553408 0.87307 0.120416 0.262333 0.693884 0.818468 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 313
Initial state: 0 0.607369 0.876153 0.537406 0.819454 0.494129 0.196825 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31039 episodes
GETTING ACTION FROM:
action -1, numVisits=31026, meanQ=2.841904, numObservations: 1
action 2, numVisits=9, meanQ=0.332222, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.607369 0.876153 0.537406 0.819454 0.494129 0.196825 w: 1
Observation: 0 0.617471 0 0.443554 0 0.535083 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31019, meanQ=4.916924, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 52545 episodes
GETTING ACTION FROM:
action 2, numVisits=83552, meanQ=4.897297, numObservations: 3
action 1, numVisits=13, meanQ=2.460769, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.607369 0.876153 0.537406 0.819454 0.494129 0.196825 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 314
Initial state: 0 0.611974 0.961398 0.526142 0.866892 0.615095 0.816582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54470 episodes
GETTING ACTION FROM:
action 3, numVisits=54463, meanQ=5.096711, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.611974 0.961398 0.526142 0.866892 0.615095 0.816582 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 315
Initial state: 0 0.0461135 0.549089 0.537302 0.894877 0.603182 0.864989 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54398 episodes
GETTING ACTION FROM:
action 3, numVisits=54378, meanQ=4.962120, numObservations: 4
action -1, numVisits=11, meanQ=2.949550, numObservations: 1
action 2, numVisits=6, meanQ=1.498333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.0461135 0.549089 0.537302 0.894877 0.603182 0.864989 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=480, meanQ=6.162204, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 17057 episodes
GETTING ACTION FROM:
action 3, numVisits=486, meanQ=6.147670, numObservations: 3
action 1, numVisits=583, meanQ=6.087435, numObservations: 4
action 2, numVisits=16146, meanQ=6.032641, numObservations: 4
action 0, numVisits=318, meanQ=-0.454197, numObservations: 1
action -1, numVisits=8, meanQ=-47.168113, numObservations: 1
action: 3
Next state: 1 0.0461135 0.549089 0.537302 0.894877 0.603182 0.864989 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 316
Initial state: 0 0.522456 0.895093 0.220306 0.237746 0.694956 0.813159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54389 episodes
GETTING ACTION FROM:
action 2, numVisits=54346, meanQ=4.995892, numObservations: 4
action -1, numVisits=39, meanQ=3.933340, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.522456 0.895093 0.220306 0.237746 0.694956 0.813159 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2716, meanQ=7.690322, numObservations: 5
action 1, numVisits=8, meanQ=5.501263, numObservations: 2
action 2, numVisits=4, meanQ=2.497525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 24736 episodes
GETTING ACTION FROM:
action 3, numVisits=20670, meanQ=6.238498, numObservations: 5
action 1, numVisits=4567, meanQ=5.665859, numObservations: 4
action 2, numVisits=4, meanQ=2.497525, numObservations: 2
action -1, numVisits=2210, meanQ=0.193679, numObservations: 1
action 0, numVisits=15, meanQ=-1.340000, numObservations: 1
action: 3
Next state: 1 0.522456 0.895093 0.220306 0.237746 0.694956 0.813159 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 317
Initial state: 0 0.687726 0.828531 0.643079 0.822358 0.927293 0.132202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54761 episodes
GETTING ACTION FROM:
action 2, numVisits=54751, meanQ=4.980409, numObservations: 5
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.687726 0.828531 0.643079 0.822358 0.927293 0.132202 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 318
Initial state: 0 0.57971 0.836844 0.5649 0.857839 0.265511 0.951986 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54571 episodes
GETTING ACTION FROM:
action 2, numVisits=54498, meanQ=5.116234, numObservations: 5
action -1, numVisits=69, meanQ=4.314935, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.57971 0.836844 0.5649 0.857839 0.265511 0.951986 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 319
Initial state: 0 0.416123 0.412106 0.504793 0.867898 0.615272 0.870944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54554 episodes
GETTING ACTION FROM:
action 1, numVisits=54529, meanQ=4.974205, numObservations: 4
action 0, numVisits=16, meanQ=3.041925, numObservations: 1
action 2, numVisits=6, meanQ=1.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.416123 0.412106 0.504793 0.867898 0.615272 0.870944 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7565, meanQ=8.402681, numObservations: 5
action 2, numVisits=7, meanQ=5.284300, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 23468 episodes
GETTING ACTION FROM:
action 3, numVisits=20655, meanQ=6.886042, numObservations: 5
action 2, numVisits=9445, meanQ=6.151685, numObservations: 4
action 0, numVisits=939, meanQ=-1.280059, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=3, meanQ=-5.300000, numObservations: 1
action: 3
Next state: 1 0.416123 0.412106 0.504793 0.867898 0.615272 0.870944 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 320
Initial state: 0 0.679677 0.83791 0.255997 0.170169 0.526094 0.835407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54182 episodes
GETTING ACTION FROM:
action 2, numVisits=54142, meanQ=4.971250, numObservations: 5
action 3, numVisits=35, meanQ=3.798014, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.679677 0.83791 0.255997 0.170169 0.526094 0.835407 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7668, meanQ=8.376497, numObservations: 4
action 3, numVisits=18, meanQ=6.667233, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 14195 episodes
GETTING ACTION FROM:
action 1, numVisits=19536, meanQ=6.949188, numObservations: 4
action 3, numVisits=36, meanQ=4.662286, numObservations: 3
action -1, numVisits=773, meanQ=0.270712, numObservations: 1
action 0, numVisits=1538, meanQ=-0.359920, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.679677 0.83791 0.255997 0.170169 0.526094 0.835407 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 321
Initial state: 0 0.683489 0.800869 0.0830367 0.160952 0.649544 0.886171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54318 episodes
GETTING ACTION FROM:
action 3, numVisits=54304, meanQ=4.969347, numObservations: 3
action 2, numVisits=4, meanQ=0.750000, numObservations: 1
action 1, numVisits=6, meanQ=0.166667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.683489 0.800869 0.0830367 0.160952 0.649544 0.886171 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 322
Initial state: 0 0.652228 0.806561 0.572066 0.841354 0.775919 0.770464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54650 episodes
GETTING ACTION FROM:
action 1, numVisits=54634, meanQ=5.128122, numObservations: 5
action 2, numVisits=11, meanQ=2.729109, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.652228 0.806561 0.572066 0.841354 0.775919 0.770464 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 323
Initial state: 0 0.203918 0.502286 0.634579 0.852182 0.631315 0.83996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54548 episodes
GETTING ACTION FROM:
action 2, numVisits=54516, meanQ=4.946860, numObservations: 5
action -1, numVisits=26, meanQ=3.592272, numObservations: 1
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.203918 0.502286 0.634579 0.852182 0.631315 0.83996 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 324
Initial state: 0 0.616246 0.823528 0.997162 0.21659 0.611224 0.863625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51866 episodes
GETTING ACTION FROM:
action 1, numVisits=51806, meanQ=4.871968, numObservations: 4
action 0, numVisits=31, meanQ=3.685848, numObservations: 1
action 2, numVisits=20, meanQ=3.250510, numObservations: 4
action 3, numVisits=7, meanQ=2.002871, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.616246 0.823528 0.997162 0.21659 0.611224 0.863625 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 325
Initial state: 0 0.97316 0.219015 0.687758 0.816612 0.651488 0.86175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31963 episodes
GETTING ACTION FROM:
action 0, numVisits=31951, meanQ=2.844360, numObservations: 1
action 2, numVisits=5, meanQ=-0.795980, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.97316 0.219015 0.687758 0.816612 0.651488 0.86175 w: 1
Observation: 0 0 0.25888 0 0.754785 0 0.913336 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31884, meanQ=4.963125, numObservations: 5
action -1, numVisits=33, meanQ=3.744100, numObservations: 1
action 0, numVisits=17, meanQ=3.274963, numObservations: 1
action 3, numVisits=14, meanQ=2.569293, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
Sampled 55512 episodes
GETTING ACTION FROM:
action 2, numVisits=87394, meanQ=4.863696, numObservations: 5
action -1, numVisits=34, meanQ=3.699541, numObservations: 1
action 0, numVisits=18, meanQ=3.253059, numObservations: 1
action 3, numVisits=14, meanQ=2.569293, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 1 0.97316 0.219015 0.687758 0.816612 0.651488 0.86175 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 326
Initial state: 0 0.68207 0.870786 0.58035 0.820929 0.553149 0.560617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54302 episodes
GETTING ACTION FROM:
action 1, numVisits=54260, meanQ=4.972364, numObservations: 3
action 0, numVisits=24, meanQ=3.638289, numObservations: 1
action -1, numVisits=13, meanQ=3.049083, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.68207 0.870786 0.58035 0.820929 0.553149 0.560617 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 327
Initial state: 0 0.624319 0.839925 0.546678 0.828422 0.397418 0.568311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54792 episodes
GETTING ACTION FROM:
action 2, numVisits=54711, meanQ=5.079208, numObservations: 4
action 0, numVisits=62, meanQ=4.262988, numObservations: 1
action -1, numVisits=14, meanQ=3.239948, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.624319 0.839925 0.546678 0.828422 0.397418 0.568311 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 328
Initial state: 0 0.230767 0.512153 0.549892 0.802934 0.51351 0.841807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54285 episodes
GETTING ACTION FROM:
action 2, numVisits=54272, meanQ=5.007372, numObservations: 4
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.230767 0.512153 0.549892 0.802934 0.51351 0.841807 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 329
Initial state: 0 0.643157 0.87017 0.323601 0.0480985 0.539348 0.800882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31820 episodes
GETTING ACTION FROM:
action 0, numVisits=31815, meanQ=2.915342, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.643157 0.87017 0.323601 0.0480985 0.539348 0.800882 w: 1
Observation: 0 0 0.858187 0 0.128452 0 0.76157 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31806, meanQ=4.944466, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 54992 episodes
GETTING ACTION FROM:
action 1, numVisits=86798, meanQ=4.993571, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.643157 0.87017 0.323601 0.0480985 0.539348 0.800882 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 330
Initial state: 0 0.53182 0.873713 0.616008 0.807937 0.809241 0.173707 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54799 episodes
GETTING ACTION FROM:
action 1, numVisits=54768, meanQ=5.019081, numObservations: 4
action -1, numVisits=23, meanQ=3.610070, numObservations: 1
action 3, numVisits=5, meanQ=0.802020, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.53182 0.873713 0.616008 0.807937 0.809241 0.173707 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 331
Initial state: 0 0.18458 0.170483 0.61265 0.815305 0.58775 0.878898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54717 episodes
GETTING ACTION FROM:
action 3, numVisits=54706, meanQ=5.035983, numObservations: 5
action -1, numVisits=4, meanQ=-2.502425, numObservations: 1
action 0, numVisits=4, meanQ=-2.502425, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.18458 0.170483 0.61265 0.815305 0.58775 0.878898 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 332
Initial state: 0 0.500612 0.898263 0.914998 0.439432 0.61464 0.860262 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54470 episodes
GETTING ACTION FROM:
action 3, numVisits=54384, meanQ=4.952782, numObservations: 4
action 0, numVisits=79, meanQ=4.204688, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.500612 0.898263 0.914998 0.439432 0.61464 0.860262 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 333
Initial state: 0 0.228195 0.663829 0.63868 0.824164 0.607219 0.822276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54410 episodes
GETTING ACTION FROM:
action 1, numVisits=54404, meanQ=4.910905, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.228195 0.663829 0.63868 0.824164 0.607219 0.822276 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6160, meanQ=8.527491, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 24664 episodes
GETTING ACTION FROM:
action 3, numVisits=21066, meanQ=6.950805, numObservations: 4
action 2, numVisits=8971, meanQ=5.653249, numObservations: 5
action -1, numVisits=475, meanQ=-0.991774, numObservations: 1
action 0, numVisits=316, meanQ=-1.058281, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.228195 0.663829 0.63868 0.824164 0.607219 0.822276 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 334
Initial state: 0 0.639197 0.861796 0.682591 0.892459 0.103874 0.770946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54123 episodes
GETTING ACTION FROM:
action 3, numVisits=54043, meanQ=4.921034, numObservations: 4
action -1, numVisits=42, meanQ=3.887182, numObservations: 1
action 0, numVisits=29, meanQ=3.619622, numObservations: 1
action 1, numVisits=8, meanQ=1.623762, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.639197 0.861796 0.682591 0.892459 0.103874 0.770946 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9190, meanQ=8.338975, numObservations: 5
action 2, numVisits=6, meanQ=4.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 35667 episodes
GETTING ACTION FROM:
action 1, numVisits=44378, meanQ=6.442052, numObservations: 5
action 0, numVisits=460, meanQ=-0.442271, numObservations: 1
action -1, numVisits=13, meanQ=-2.000762, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=14, meanQ=-21.115846, numObservations: 3
action: 1
Next state: 1 0.639197 0.861796 0.682591 0.892459 0.103874 0.770946 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 335
Initial state: 0 0.637615 0.853428 0.26408 0.351895 0.600938 0.808715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54614 episodes
GETTING ACTION FROM:
action 2, numVisits=53647, meanQ=4.946648, numObservations: 5
action 3, numVisits=541, meanQ=4.667010, numObservations: 5
action 1, numVisits=422, meanQ=4.637606, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.637615 0.853428 0.26408 0.351895 0.600938 0.808715 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7540, meanQ=8.351244, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 33254 episodes
GETTING ACTION FROM:
action 3, numVisits=35311, meanQ=6.588616, numObservations: 5
action 1, numVisits=2593, meanQ=5.889988, numObservations: 5
action 0, numVisits=2867, meanQ=0.209976, numObservations: 1
action -1, numVisits=27, meanQ=-0.973333, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.637615 0.853428 0.26408 0.351895 0.600938 0.808715 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 336
Initial state: 0 0.588534 0.825778 0.668265 0.109234 0.568681 0.885483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54525 episodes
GETTING ACTION FROM:
action 1, numVisits=54519, meanQ=4.930615, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.588534 0.825778 0.668265 0.109234 0.568681 0.885483 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 337
Initial state: 0 0.286115 0.222361 0.518789 0.841976 0.548917 0.867521 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54231 episodes
GETTING ACTION FROM:
action 2, numVisits=54225, meanQ=4.998005, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.286115 0.222361 0.518789 0.841976 0.548917 0.867521 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 338
Initial state: 0 0.2347 0.27132 0.595018 0.806431 0.637781 0.810389 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54476 episodes
GETTING ACTION FROM:
action 2, numVisits=54470, meanQ=4.952568, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.2347 0.27132 0.595018 0.806431 0.637781 0.810389 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 339
Initial state: 0 0.595493 0.815515 0.105999 0.41828 0.627622 0.855446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31384 episodes
GETTING ACTION FROM:
action 0, numVisits=30255, meanQ=2.916787, numObservations: 1
action -1, numVisits=1126, meanQ=1.586896, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.595493 0.815515 0.105999 0.41828 0.627622 0.855446 w: 1
Observation: 0 0 0.82997 0 0.461185 0 0.804008 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=30211, meanQ=4.980100, numObservations: 4
action -1, numVisits=23, meanQ=3.553326, numObservations: 1
action 1, numVisits=17, meanQ=2.647076, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55030 episodes
GETTING ACTION FROM:
action 2, numVisits=85240, meanQ=5.136543, numObservations: 4
action -1, numVisits=24, meanQ=3.468188, numObservations: 1
action 1, numVisits=17, meanQ=2.647076, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.595493 0.815515 0.105999 0.41828 0.627622 0.855446 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=13309, meanQ=8.303401, numObservations: 4
action 1, numVisits=46, meanQ=7.391309, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 17416 episodes
GETTING ACTION FROM:
action 3, numVisits=24064, meanQ=7.329999, numObservations: 4
action 1, numVisits=82, meanQ=6.390246, numObservations: 3
action -1, numVisits=6521, meanQ=0.055150, numObservations: 1
action 0, numVisits=106, meanQ=-0.536161, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.595493 0.815515 0.105999 0.41828 0.627622 0.855446 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 340
Initial state: 0 0.696501 0.627116 0.549043 0.835318 0.575654 0.821333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54461 episodes
GETTING ACTION FROM:
action 1, numVisits=54387, meanQ=4.920111, numObservations: 4
action -1, numVisits=59, meanQ=4.074084, numObservations: 1
action 0, numVisits=13, meanQ=2.724538, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.696501 0.627116 0.549043 0.835318 0.575654 0.821333 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6571, meanQ=8.426609, numObservations: 5
action 2, numVisits=1055, meanQ=8.313642, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 20923 episodes
GETTING ACTION FROM:
action 3, numVisits=14263, meanQ=6.817674, numObservations: 5
action 2, numVisits=13007, meanQ=6.145897, numObservations: 5
action -1, numVisits=1273, meanQ=0.009552, numObservations: 1
action 0, numVisits=8, meanQ=-2.126225, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.696501 0.627116 0.549043 0.835318 0.575654 0.821333 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 341
Initial state: 0 0.783006 0.169185 0.619204 0.815735 0.616146 0.857974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54112 episodes
GETTING ACTION FROM:
action 2, numVisits=54098, meanQ=4.967862, numObservations: 5
action 1, numVisits=9, meanQ=2.202222, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.783006 0.169185 0.619204 0.815735 0.616146 0.857974 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 342
Initial state: 0 0.626946 0.85069 0.888817 0.0716293 0.691927 0.890294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54091 episodes
GETTING ACTION FROM:
action 2, numVisits=54063, meanQ=4.959934, numObservations: 5
action -1, numVisits=20, meanQ=3.416285, numObservations: 1
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.626946 0.85069 0.888817 0.0716293 0.691927 0.890294 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2729, meanQ=7.895275, numObservations: 5
action 1, numVisits=8, meanQ=4.247513, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 16940 episodes
GETTING ACTION FROM:
action 3, numVisits=19649, meanQ=6.304878, numObservations: 5
action 1, numVisits=8, meanQ=4.247513, numObservations: 2
action -1, numVisits=11, meanQ=-2.091800, numObservations: 1
action 0, numVisits=11, meanQ=-2.091800, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.626946 0.85069 0.888817 0.0716293 0.691927 0.890294 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 343
Initial state: 0 0.581439 0.875633 0.0250218 0.949642 0.550864 0.818899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54640 episodes
GETTING ACTION FROM:
action 1, numVisits=54626, meanQ=5.057753, numObservations: 5
action 2, numVisits=7, meanQ=1.144314, numObservations: 3
action 3, numVisits=3, meanQ=-2.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.581439 0.875633 0.0250218 0.949642 0.550864 0.818899 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 344
Initial state: 0 0.554783 0.868855 0.60907 0.897682 0.525221 0.980237 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55161 episodes
GETTING ACTION FROM:
action 2, numVisits=55155, meanQ=5.030457, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.554783 0.868855 0.60907 0.897682 0.525221 0.980237 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 345
Initial state: 0 0.520699 0.8808 0.625204 0.838554 0.310349 0.598582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54420 episodes
GETTING ACTION FROM:
action 2, numVisits=54390, meanQ=4.942305, numObservations: 5
action 0, numVisits=24, meanQ=3.558258, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.520699 0.8808 0.625204 0.838554 0.310349 0.598582 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 346
Initial state: 0 0.0941129 0.977762 0.663768 0.889137 0.618605 0.825047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54564 episodes
GETTING ACTION FROM:
action 2, numVisits=54447, meanQ=4.923798, numObservations: 4
action 0, numVisits=110, meanQ=4.301863, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.0941129 0.977762 0.663768 0.889137 0.618605 0.825047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 347
Initial state: 0 0.591235 0.878376 0.287671 0.743671 0.596699 0.854773 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54414 episodes
GETTING ACTION FROM:
action 3, numVisits=54390, meanQ=4.991504, numObservations: 4
action 0, numVisits=18, meanQ=3.214938, numObservations: 1
action 1, numVisits=3, meanQ=0.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.591235 0.878376 0.287671 0.743671 0.596699 0.854773 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 348
Initial state: 0 0.39388 0.631167 0.634303 0.800341 0.548793 0.80361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54627 episodes
GETTING ACTION FROM:
action 3, numVisits=54570, meanQ=4.942750, numObservations: 5
action -1, numVisits=28, meanQ=3.670724, numObservations: 1
action 1, numVisits=23, meanQ=3.478265, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.39388 0.631167 0.634303 0.800341 0.548793 0.80361 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 349
Initial state: 0 0.645732 0.890215 0.00725513 0.239338 0.610447 0.823135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53797 episodes
GETTING ACTION FROM:
action 1, numVisits=52954, meanQ=4.976332, numObservations: 5
action 0, numVisits=838, meanQ=2.818244, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.645732 0.890215 0.00725513 0.239338 0.610447 0.823135 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 350
Initial state: 0 0.649203 0.842122 0.813094 0.0890144 0.605721 0.862814 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54709 episodes
GETTING ACTION FROM:
action 1, numVisits=54621, meanQ=5.020612, numObservations: 5
action 0, numVisits=84, meanQ=4.304193, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.649203 0.842122 0.813094 0.0890144 0.605721 0.862814 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4060, meanQ=5.449847, numObservations: 4
action 3, numVisits=13, meanQ=3.460769, numObservations: 2
action 2, numVisits=7, meanQ=2.711429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 60444 episodes
GETTING ACTION FROM:
action 1, numVisits=64460, meanQ=5.219388, numObservations: 4
action 3, numVisits=54, meanQ=4.182963, numObservations: 4
action 2, numVisits=7, meanQ=2.711429, numObservations: 2
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.649203 0.842122 0.813094 0.0890144 0.605721 0.862814 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 351
Initial state: 0 0.974888 0.961217 0.556778 0.886796 0.696514 0.802805 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54113 episodes
GETTING ACTION FROM:
action 3, numVisits=54074, meanQ=4.980308, numObservations: 5
action -1, numVisits=35, meanQ=3.825467, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.974888 0.961217 0.556778 0.886796 0.696514 0.802805 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 352
Initial state: 0 0.688959 0.204172 0.642894 0.818725 0.697909 0.850413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54482 episodes
GETTING ACTION FROM:
action 3, numVisits=54469, meanQ=4.965315, numObservations: 5
action 1, numVisits=8, meanQ=2.498750, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.688959 0.204172 0.642894 0.818725 0.697909 0.850413 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 353
Initial state: 0 0.696238 0.845996 0.717675 0.362617 0.60304 0.802216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54252 episodes
GETTING ACTION FROM:
action 3, numVisits=54243, meanQ=5.021798, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.696238 0.845996 0.717675 0.362617 0.60304 0.802216 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 354
Initial state: 0 0.064235 0.299747 0.576327 0.83617 0.551566 0.891577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54372 episodes
GETTING ACTION FROM:
action 1, numVisits=54366, meanQ=4.974102, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.064235 0.299747 0.576327 0.83617 0.551566 0.891577 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6264, meanQ=8.507863, numObservations: 3
action 2, numVisits=12, meanQ=6.667508, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 27667 episodes
GETTING ACTION FROM:
action 3, numVisits=31315, meanQ=6.520250, numObservations: 4
action 2, numVisits=2619, meanQ=5.887885, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=8, meanQ=-46.161787, numObservations: 1
action -1, numVisits=3, meanQ=-123.754805, numObservations: 1
action: 3
Next state: 1 0.064235 0.299747 0.576327 0.83617 0.551566 0.891577 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 355
Initial state: 0 0.147525 0.565283 0.521854 0.817333 0.667673 0.894008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54652 episodes
GETTING ACTION FROM:
action 1, numVisits=54626, meanQ=4.954186, numObservations: 4
action 2, numVisits=20, meanQ=3.240515, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.147525 0.565283 0.521854 0.817333 0.667673 0.894008 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7616, meanQ=8.401213, numObservations: 4
action 3, numVisits=12, meanQ=6.332500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29262 episodes
GETTING ACTION FROM:
action 3, numVisits=21, meanQ=6.523333, numObservations: 2
action 2, numVisits=36826, meanQ=5.948045, numObservations: 4
action -1, numVisits=43, meanQ=-0.342556, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-10.355261, numObservations: 1
action: 3
Next state: 1 0.147525 0.565283 0.521854 0.817333 0.667673 0.894008 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 356
Initial state: 0 0.522165 0.891782 0.158751 0.343916 0.525176 0.864843 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52004 episodes
GETTING ACTION FROM:
action 1, numVisits=51998, meanQ=5.004901, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.522165 0.891782 0.158751 0.343916 0.525176 0.864843 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 357
Initial state: 0 0.630794 0.888723 0.267765 0.516786 0.550918 0.84163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54453 episodes
GETTING ACTION FROM:
action 1, numVisits=54447, meanQ=4.983997, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.630794 0.888723 0.267765 0.516786 0.550918 0.84163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 358
Initial state: 0 0.535372 0.850998 0.777702 0.387129 0.515871 0.847657 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31870 episodes
GETTING ACTION FROM:
action 0, numVisits=31859, meanQ=2.930814, numObservations: 1
action 3, numVisits=6, meanQ=-2.331650, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.535372 0.850998 0.777702 0.387129 0.515871 0.847657 w: 1
Observation: 0 0 0.769753 0 0.426599 0 0.891065 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31852, meanQ=5.009767, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54579 episodes
GETTING ACTION FROM:
action 1, numVisits=86428, meanQ=4.974439, numObservations: 4
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-3.505000, numObservations: 2
action: 1
Next state: 1 0.535372 0.850998 0.777702 0.387129 0.515871 0.847657 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 359
Initial state: 0 0.554047 0.812049 0.51136 0.899392 0.624869 0.648479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54470 episodes
GETTING ACTION FROM:
action 2, numVisits=54464, meanQ=4.940522, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.554047 0.812049 0.51136 0.899392 0.624869 0.648479 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 360
Initial state: 0 0.784209 0.360429 0.676545 0.87138 0.519968 0.812818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53816 episodes
GETTING ACTION FROM:
action 1, numVisits=53792, meanQ=4.890899, numObservations: 4
action 0, numVisits=20, meanQ=3.286687, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.784209 0.360429 0.676545 0.87138 0.519968 0.812818 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 361
Initial state: 0 0.695827 0.828547 0.567728 0.888006 0.27724 0.634096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52837 episodes
GETTING ACTION FROM:
action 2, numVisits=52674, meanQ=4.883161, numObservations: 5
action 1, numVisits=132, meanQ=4.216849, numObservations: 4
action -1, numVisits=28, meanQ=3.583040, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.695827 0.828547 0.567728 0.888006 0.27724 0.634096 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 362
Initial state: 0 0.215005 0.495991 0.533098 0.815795 0.660214 0.800847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54472 episodes
GETTING ACTION FROM:
action 3, numVisits=54429, meanQ=4.993552, numObservations: 3
action -1, numVisits=31, meanQ=3.818797, numObservations: 1
action 2, numVisits=9, meanQ=2.223344, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.215005 0.495991 0.533098 0.815795 0.660214 0.800847 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 363
Initial state: 0 0.560315 0.801056 0.597376 0.868942 0.150309 0.117425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54302 episodes
GETTING ACTION FROM:
action 1, numVisits=54032, meanQ=5.009198, numObservations: 4
action 0, numVisits=121, meanQ=4.403446, numObservations: 1
action -1, numVisits=120, meanQ=4.395719, numObservations: 1
action 3, numVisits=18, meanQ=1.944450, numObservations: 3
action 2, numVisits=11, meanQ=1.445464, numObservations: 4
action: 1
Next state: 1 0.560315 0.801056 0.597376 0.868942 0.150309 0.117425 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 364
Initial state: 0 0.571358 0.859605 0.646524 0.8506 0.232651 0.484546 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54576 episodes
GETTING ACTION FROM:
action 2, numVisits=54550, meanQ=4.949823, numObservations: 5
action 3, numVisits=21, meanQ=3.429538, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.571358 0.859605 0.646524 0.8506 0.232651 0.484546 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 365
Initial state: 0 0.556488 0.817761 0.346455 0.0620291 0.620056 0.899009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54316 episodes
GETTING ACTION FROM:
action 3, numVisits=54256, meanQ=5.034616, numObservations: 5
action -1, numVisits=27, meanQ=3.713145, numObservations: 1
action 2, numVisits=23, meanQ=2.430448, numObservations: 3
action 1, numVisits=8, meanQ=1.863750, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.556488 0.817761 0.346455 0.0620291 0.620056 0.899009 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 366
Initial state: 0 0.597663 0.88722 0.564946 0.890339 0.812416 0.905426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54647 episodes
GETTING ACTION FROM:
action 2, numVisits=54566, meanQ=5.009642, numObservations: 3
action -1, numVisits=64, meanQ=4.193235, numObservations: 1
action 1, numVisits=14, meanQ=2.644293, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.597663 0.88722 0.564946 0.890339 0.812416 0.905426 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 367
Initial state: 0 0.639213 0.808533 0.544254 0.804377 0.457675 0.971451 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54631 episodes
GETTING ACTION FROM:
action 1, numVisits=54557, meanQ=5.008925, numObservations: 4
action 0, numVisits=47, meanQ=4.031676, numObservations: 1
action -1, numVisits=25, meanQ=3.697826, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.639213 0.808533 0.544254 0.804377 0.457675 0.971451 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 368
Initial state: 0 0.554218 0.839686 0.657651 0.805493 0.386898 0.247652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54447 episodes
GETTING ACTION FROM:
action 3, numVisits=54426, meanQ=4.970214, numObservations: 5
action 1, numVisits=16, meanQ=3.118125, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.554218 0.839686 0.657651 0.805493 0.386898 0.247652 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6093, meanQ=8.505268, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 17127 episodes
GETTING ACTION FROM:
action 1, numVisits=17572, meanQ=6.774069, numObservations: 3
action -1, numVisits=5644, meanQ=0.023850, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=6, meanQ=-59.842720, numObservations: 1
action: 1
Next state: 1 0.554218 0.839686 0.657651 0.805493 0.386898 0.247652 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 369
Initial state: 0 0.550546 0.842705 0.565829 0.646841 0.561326 0.829357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51700 episodes
GETTING ACTION FROM:
action 1, numVisits=51679, meanQ=4.836672, numObservations: 5
action -1, numVisits=16, meanQ=3.017561, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.550546 0.842705 0.565829 0.646841 0.561326 0.829357 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 370
Initial state: 0 0.570898 0.857196 0.627016 0.824609 0.4136 0.0491193 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54419 episodes
GETTING ACTION FROM:
action 3, numVisits=54413, meanQ=5.012448, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.570898 0.857196 0.627016 0.824609 0.4136 0.0491193 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8972, meanQ=8.334704, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 16029 episodes
GETTING ACTION FROM:
action 1, numVisits=24053, meanQ=6.884480, numObservations: 5
action 0, numVisits=945, meanQ=-0.354313, numObservations: 1
action -1, numVisits=5, meanQ=-3.980000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.570898 0.857196 0.627016 0.824609 0.4136 0.0491193 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 371
Initial state: 0 0.596408 0.820497 0.6221 0.896285 0.664912 0.588094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31932 episodes
GETTING ACTION FROM:
action -1, numVisits=17662, meanQ=3.007746, numObservations: 1
action 0, numVisits=14259, meanQ=3.002271, numObservations: 1
action 3, numVisits=9, meanQ=-0.210000, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.596408 0.820497 0.6221 0.896285 0.664912 0.588094 w: 1
Observation: 0 0.677072 0 0.654128 0 0.6381 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=17565, meanQ=5.017920, numObservations: 5
action 1, numVisits=91, meanQ=4.389935, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54991 episodes
GETTING ACTION FROM:
action 2, numVisits=72542, meanQ=5.146985, numObservations: 5
action 1, numVisits=91, meanQ=4.389935, numObservations: 4
action 3, numVisits=15, meanQ=3.400700, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.596408 0.820497 0.6221 0.896285 0.664912 0.588094 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 372
Initial state: 0 0.0764723 0.99087 0.51974 0.830102 0.6244 0.805809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54711 episodes
GETTING ACTION FROM:
action 1, numVisits=54705, meanQ=4.946363, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0764723 0.99087 0.51974 0.830102 0.6244 0.805809 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4063, meanQ=4.695261, numObservations: 5
action 3, numVisits=15, meanQ=3.126000, numObservations: 3
action 1, numVisits=3, meanQ=0.330033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 67448 episodes
GETTING ACTION FROM:
action 3, numVisits=67461, meanQ=6.024799, numObservations: 5
action 2, numVisits=4063, meanQ=4.695261, numObservations: 5
action 1, numVisits=3, meanQ=0.330033, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.0764723 0.99087 0.51974 0.830102 0.6244 0.805809 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 373
Initial state: 0 0.681638 0.836546 0.645467 0.863041 0.34834 0.460153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49082 episodes
GETTING ACTION FROM:
action 1, numVisits=49023, meanQ=4.572963, numObservations: 4
action -1, numVisits=53, meanQ=3.658246, numObservations: 1
action 3, numVisits=3, meanQ=0.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.681638 0.836546 0.645467 0.863041 0.34834 0.460153 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 374
Initial state: 0 0.630149 0.874175 0.383337 0.337155 0.506955 0.822724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54816 episodes
GETTING ACTION FROM:
action 2, numVisits=54810, meanQ=4.978195, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.630149 0.874175 0.383337 0.337155 0.506955 0.822724 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6198, meanQ=8.519482, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 21596 episodes
GETTING ACTION FROM:
action 1, numVisits=27748, meanQ=6.567135, numObservations: 4
action 3, numVisits=39, meanQ=5.681402, numObservations: 4
action 0, numVisits=7, meanQ=-2.144257, numObservations: 1
action -1, numVisits=4, meanQ=-4.475000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.630149 0.874175 0.383337 0.337155 0.506955 0.822724 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 375
Initial state: 0 0.53547 0.876566 0.556387 0.897636 0.255501 0.936433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54180 episodes
GETTING ACTION FROM:
action 3, numVisits=54162, meanQ=4.959387, numObservations: 4
action 2, numVisits=13, meanQ=2.546931, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.53547 0.876566 0.556387 0.897636 0.255501 0.936433 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3978, meanQ=4.724950, numObservations: 5
action 2, numVisits=18, meanQ=3.210556, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67452 episodes
GETTING ACTION FROM:
action 1, numVisits=71429, meanQ=5.731141, numObservations: 5
action 2, numVisits=18, meanQ=3.210556, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.53547 0.876566 0.556387 0.897636 0.255501 0.936433 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 376
Initial state: 0 0.541738 0.895528 0.647092 0.816663 0.488388 0.917167 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52202 episodes
GETTING ACTION FROM:
action 3, numVisits=52148, meanQ=4.839301, numObservations: 5
action -1, numVisits=43, meanQ=3.768509, numObservations: 1
action 1, numVisits=8, meanQ=2.375000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.541738 0.895528 0.647092 0.816663 0.488388 0.917167 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=777, meanQ=4.927706, numObservations: 4
action 0, numVisits=3124, meanQ=2.910631, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67786 episodes
GETTING ACTION FROM:
action 2, numVisits=68563, meanQ=6.277166, numObservations: 4
action 0, numVisits=3124, meanQ=2.910631, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.541738 0.895528 0.647092 0.816663 0.488388 0.917167 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 377
Initial state: 0 0.512047 0.827529 0.54546 0.861291 0.686295 0.162849 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54058 episodes
GETTING ACTION FROM:
action 3, numVisits=53964, meanQ=5.003461, numObservations: 5
action -1, numVisits=49, meanQ=4.079576, numObservations: 1
action 0, numVisits=43, meanQ=3.978658, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.512047 0.827529 0.54546 0.861291 0.686295 0.162849 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 378
Initial state: 0 0.529532 0.863552 0.621227 0.850678 0.893607 0.976495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54030 episodes
GETTING ACTION FROM:
action 2, numVisits=54024, meanQ=4.959565, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.529532 0.863552 0.621227 0.850678 0.893607 0.976495 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 379
Initial state: 0 0.608319 0.894242 0.315027 0.687285 0.647217 0.841226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54488 episodes
GETTING ACTION FROM:
action 3, numVisits=54361, meanQ=4.940986, numObservations: 3
action -1, numVisits=103, meanQ=4.304401, numObservations: 1
action 2, numVisits=13, meanQ=1.693854, numObservations: 4
action 1, numVisits=9, meanQ=1.666667, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.608319 0.894242 0.315027 0.687285 0.647217 0.841226 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 380
Initial state: 0 0.563198 0.520711 0.523586 0.822376 0.518843 0.856749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54489 episodes
GETTING ACTION FROM:
action 2, numVisits=54480, meanQ=4.892857, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=4, meanQ=-4.250000, numObservations: 3
action: 2
Next state: 1 0.563198 0.520711 0.523586 0.822376 0.518843 0.856749 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 381
Initial state: 0 0.245266 0.670348 0.549382 0.893155 0.680133 0.82691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54100 episodes
GETTING ACTION FROM:
action 1, numVisits=53961, meanQ=4.966789, numObservations: 5
action -1, numVisits=112, meanQ=4.155693, numObservations: 1
action 0, numVisits=24, meanQ=3.508322, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.245266 0.670348 0.549382 0.893155 0.680133 0.82691 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7450, meanQ=8.403148, numObservations: 4
action 3, numVisits=19, meanQ=6.998953, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22278 episodes
GETTING ACTION FROM:
action 2, numVisits=28132, meanQ=6.709744, numObservations: 4
action 3, numVisits=750, meanQ=5.777742, numObservations: 5
action -1, numVisits=770, meanQ=0.035286, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=97, meanQ=-3.681104, numObservations: 2
action: 2
Next state: 1 0.245266 0.670348 0.549382 0.893155 0.680133 0.82691 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 382
Initial state: 0 0.500459 0.671271 0.574246 0.897422 0.54752 0.804929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54258 episodes
GETTING ACTION FROM:
action 1, numVisits=54222, meanQ=4.927688, numObservations: 5
action 0, numVisits=32, meanQ=3.750232, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.500459 0.671271 0.574246 0.897422 0.54752 0.804929 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 383
Initial state: 0 0.473391 0.670941 0.608673 0.846348 0.601961 0.832829 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31049 episodes
GETTING ACTION FROM:
action -1, numVisits=31040, meanQ=2.837592, numObservations: 1
action 2, numVisits=5, meanQ=-3.000000, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.473391 0.670941 0.608673 0.846348 0.601961 0.832829 w: 1
Observation: 0 0.428104 0 0.701111 0 0.628009 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=30958, meanQ=4.796813, numObservations: 5
action -1, numVisits=62, meanQ=3.993338, numObservations: 1
action 3, numVisits=10, meanQ=1.997010, numObservations: 4
action 2, numVisits=7, meanQ=0.428571, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 52529 episodes
GETTING ACTION FROM:
action 1, numVisits=83486, meanQ=4.843382, numObservations: 5
action -1, numVisits=63, meanQ=3.951627, numObservations: 1
action 3, numVisits=10, meanQ=1.997010, numObservations: 4
action 2, numVisits=7, meanQ=0.428571, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.473391 0.670941 0.608673 0.846348 0.601961 0.832829 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=11807, meanQ=8.435341, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12457 episodes
GETTING ACTION FROM:
action 3, numVisits=23099, meanQ=7.174110, numObservations: 5
action 2, numVisits=39, meanQ=3.210352, numObservations: 4
action -1, numVisits=884, meanQ=-0.466214, numObservations: 1
action 0, numVisits=245, meanQ=-0.663663, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.473391 0.670941 0.608673 0.846348 0.601961 0.832829 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 384
Initial state: 0 0.123743 0.441995 0.540967 0.829844 0.560392 0.827746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50713 episodes
GETTING ACTION FROM:
action 2, numVisits=45769, meanQ=4.999091, numObservations: 5
action -1, numVisits=4940, meanQ=3.041629, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.123743 0.441995 0.540967 0.829844 0.560392 0.827746 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 385
Initial state: 0 0.607689 0.838265 0.605502 0.871151 0.0421419 0.565196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54533 episodes
GETTING ACTION FROM:
action 2, numVisits=54445, meanQ=5.175892, numObservations: 5
action 0, numVisits=81, meanQ=4.461526, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.607689 0.838265 0.605502 0.871151 0.0421419 0.565196 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 386
Initial state: 0 0.609018 0.864188 0.492691 0.829118 0.686072 0.854861 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53938 episodes
GETTING ACTION FROM:
action 3, numVisits=53804, meanQ=4.971386, numObservations: 4
action -1, numVisits=125, meanQ=4.299727, numObservations: 1
action 2, numVisits=6, meanQ=0.166667, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.609018 0.864188 0.492691 0.829118 0.686072 0.854861 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 387
Initial state: 0 0.633565 0.805324 0.685521 0.828118 0.780002 0.15767 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53889 episodes
GETTING ACTION FROM:
action 2, numVisits=53802, meanQ=4.939512, numObservations: 4
action 0, numVisits=83, meanQ=4.118310, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.633565 0.805324 0.685521 0.828118 0.780002 0.15767 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 388
Initial state: 0 0.514587 0.874107 0.69607 0.842238 0.976989 0.603346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54313 episodes
GETTING ACTION FROM:
action 1, numVisits=54250, meanQ=4.969379, numObservations: 5
action 0, numVisits=59, meanQ=1.625051, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.514587 0.874107 0.69607 0.842238 0.976989 0.603346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 389
Initial state: 0 0.602497 0.80254 0.917761 0.89402 0.584062 0.823356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54928 episodes
GETTING ACTION FROM:
action 2, numVisits=54922, meanQ=5.092955, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.602497 0.80254 0.917761 0.89402 0.584062 0.823356 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 390
Initial state: 0 0.696095 0.86686 0.0736259 0.576022 0.576205 0.859318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54451 episodes
GETTING ACTION FROM:
action 3, numVisits=22990, meanQ=5.034358, numObservations: 4
action 1, numVisits=31440, meanQ=4.971696, numObservations: 4
action 0, numVisits=18, meanQ=3.241751, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.696095 0.86686 0.0736259 0.576022 0.576205 0.859318 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 391
Initial state: 0 0.543189 0.816161 0.54724 0.837852 0.251559 0.211761 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53643 episodes
GETTING ACTION FROM:
action 2, numVisits=53434, meanQ=4.978057, numObservations: 5
action 0, numVisits=199, meanQ=4.434994, numObservations: 2
action 3, numVisits=7, meanQ=1.428586, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.543189 0.816161 0.54724 0.837852 0.251559 0.211761 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 392
Initial state: 0 0.34649 0.0921725 0.533599 0.881311 0.657861 0.801932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54616 episodes
GETTING ACTION FROM:
action 1, numVisits=54609, meanQ=5.075850, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.34649 0.0921725 0.533599 0.881311 0.657861 0.801932 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7493, meanQ=8.411309, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 22575 episodes
GETTING ACTION FROM:
action 2, numVisits=30017, meanQ=6.669295, numObservations: 4
action 3, numVisits=42, meanQ=4.767599, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=8, meanQ=-2.001238, numObservations: 1
action -1, numVisits=5, meanQ=-72.873704, numObservations: 1
action: 2
Next state: 0 0.34649 0.0921725 0.533599 0.881311 0.657861 0.801932 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=115, meanQ=8.115933, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-179.366748, numObservations: 1
Sampled 46649 episodes
GETTING ACTION FROM:
action 2, numVisits=271, meanQ=6.949566, numObservations: 4
action 3, numVisits=46494, meanQ=5.852855, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-179.366748, numObservations: 1
action: 2
Next state: 1 0.34649 0.0921725 0.533599 0.881311 0.657861 0.801932 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 393
Initial state: 0 0.503186 0.835184 0.323457 0.631639 0.663223 0.860435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31823 episodes
GETTING ACTION FROM:
action -1, numVisits=31818, meanQ=3.029342, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.503186 0.835184 0.323457 0.631639 0.663223 0.860435 w: 1
Observation: 0 0.476697 0 0.29169 0 0.749931 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31040, meanQ=5.102871, numObservations: 4
action 1, numVisits=770, meanQ=4.823315, numObservations: 5
action 2, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 53638 episodes
GETTING ACTION FROM:
action 3, numVisits=84302, meanQ=5.037057, numObservations: 4
action 1, numVisits=1137, meanQ=4.856797, numObservations: 5
action 2, numVisits=12, meanQ=2.581667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.503186 0.835184 0.323457 0.631639 0.663223 0.860435 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 394
Initial state: 0 0.626284 0.813466 0.385985 0.164645 0.633529 0.843658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54619 episodes
GETTING ACTION FROM:
action 3, numVisits=54593, meanQ=5.065486, numObservations: 5
action 1, numVisits=21, meanQ=2.808100, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.626284 0.813466 0.385985 0.164645 0.633529 0.843658 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 395
Initial state: 0 0.549012 0.840437 0.690295 0.881297 0.575756 0.994274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54328 episodes
GETTING ACTION FROM:
action 1, numVisits=54322, meanQ=5.052122, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.549012 0.840437 0.690295 0.881297 0.575756 0.994274 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 396
Initial state: 0 0.895854 0.000936355 0.614884 0.890594 0.675285 0.838636 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54519 episodes
GETTING ACTION FROM:
action 1, numVisits=54501, meanQ=5.054374, numObservations: 3
action 3, numVisits=13, meanQ=1.531538, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.895854 0.000936355 0.614884 0.890594 0.675285 0.838636 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 397
Initial state: 0 0.71762 0.136777 0.695241 0.833416 0.554739 0.858685 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52844 episodes
GETTING ACTION FROM:
action 2, numVisits=52667, meanQ=4.903071, numObservations: 4
action 0, numVisits=36, meanQ=3.823028, numObservations: 1
action 1, numVisits=98, meanQ=3.603985, numObservations: 5
action 3, numVisits=41, meanQ=3.241227, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.71762 0.136777 0.695241 0.833416 0.554739 0.858685 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=3211, meanQ=3.770117, numObservations: 1
action 1, numVisits=43, meanQ=2.200005, numObservations: 4
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67450 episodes
GETTING ACTION FROM:
action 1, numVisits=66815, meanQ=6.045458, numObservations: 4
action -1, numVisits=3889, meanQ=2.985021, numObservations: 1
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.71762 0.136777 0.695241 0.833416 0.554739 0.858685 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 398
Initial state: 0 0.651966 0.847315 0.624513 0.802636 0.180032 0.575601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55157 episodes
GETTING ACTION FROM:
action 3, numVisits=55038, meanQ=5.200050, numObservations: 5
action -1, numVisits=111, meanQ=4.558849, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.651966 0.847315 0.624513 0.802636 0.180032 0.575601 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6140, meanQ=8.526306, numObservations: 3
action 1, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 14838 episodes
GETTING ACTION FROM:
action 2, numVisits=17177, meanQ=6.918175, numObservations: 4
action 0, numVisits=3699, meanQ=-0.075135, numObservations: 3
action 1, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=104, meanQ=-0.845770, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.651966 0.847315 0.624513 0.802636 0.180032 0.575601 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 399
Initial state: 0 0.505115 0.887131 0.576908 0.816353 0.923308 0.178632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54122 episodes
GETTING ACTION FROM:
action 1, numVisits=54113, meanQ=4.935427, numObservations: 4
action -1, numVisits=4, meanQ=-2.502425, numObservations: 1
action 0, numVisits=3, meanQ=-2.996600, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.505115 0.887131 0.576908 0.816353 0.923308 0.178632 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 400
Initial state: 0 0.632836 0.883424 0.657845 0.829648 0.680598 0.0945981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33981 episodes
GETTING ACTION FROM:
action 0, numVisits=33779, meanQ=5.830372, numObservations: 3
action -1, numVisits=198, meanQ=3.272026, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.632836 0.883424 0.657845 0.829648 0.680598 0.0945981 w: 1
Observation: 0 0 0.947171 0 0.776167 0 0.16237 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8675, meanQ=8.429787, numObservations: 4
action 1, numVisits=25, meanQ=7.239200, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 56197 episodes
GETTING ACTION FROM:
action 2, numVisits=64777, meanQ=5.509763, numObservations: 4
action 1, numVisits=66, meanQ=4.577300, numObservations: 3
action -1, numVisits=40, meanQ=4.463683, numObservations: 1
action 0, numVisits=16, meanQ=3.762390, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.632836 0.883424 0.657845 0.829648 0.680598 0.0945981 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 401
Initial state: 0 0.221646 0.788209 0.612408 0.852002 0.6561 0.897794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54540 episodes
GETTING ACTION FROM:
action 2, numVisits=54502, meanQ=4.937769, numObservations: 5
action 0, numVisits=20, meanQ=3.415810, numObservations: 1
action 3, numVisits=15, meanQ=1.466667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.221646 0.788209 0.612408 0.852002 0.6561 0.897794 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 402
Initial state: 0 0.237459 0.537838 0.581155 0.824151 0.66437 0.877914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54124 episodes
GETTING ACTION FROM:
action 1, numVisits=54118, meanQ=4.938810, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.237459 0.537838 0.581155 0.824151 0.66437 0.877914 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7605, meanQ=8.215926, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 18054 episodes
GETTING ACTION FROM:
action 2, numVisits=15962, meanQ=6.842356, numObservations: 4
action 3, numVisits=12, meanQ=2.999167, numObservations: 3
action -1, numVisits=9683, meanQ=-0.536341, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=6, meanQ=-60.514385, numObservations: 1
action: 2
Next state: 1 0.237459 0.537838 0.581155 0.824151 0.66437 0.877914 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 403
Initial state: 0 0.528694 0.853245 0.672015 0.366536 0.629167 0.880951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54891 episodes
GETTING ACTION FROM:
action 2, numVisits=54826, meanQ=5.065630, numObservations: 4
action 1, numVisits=60, meanQ=4.042253, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.528694 0.853245 0.672015 0.366536 0.629167 0.880951 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 404
Initial state: 0 0.698713 0.898871 0.538371 0.812884 0.590945 0.0476364 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54842 episodes
GETTING ACTION FROM:
action 3, numVisits=54759, meanQ=5.031803, numObservations: 4
action -1, numVisits=76, meanQ=4.264511, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.698713 0.898871 0.538371 0.812884 0.590945 0.0476364 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 405
Initial state: 0 0.110389 0.974051 0.681657 0.880788 0.538032 0.872808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54136 episodes
GETTING ACTION FROM:
action 3, numVisits=54129, meanQ=4.917983, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.110389 0.974051 0.681657 0.880788 0.538032 0.872808 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 406
Initial state: 0 0.767338 0.51682 0.563532 0.809037 0.526907 0.854361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54900 episodes
GETTING ACTION FROM:
action 1, numVisits=54870, meanQ=5.125206, numObservations: 4
action 3, numVisits=23, meanQ=0.758696, numObservations: 3
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.767338 0.51682 0.563532 0.809037 0.526907 0.854361 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 407
Initial state: 0 0.58493 0.84375 0.670705 0.712272 0.5035 0.835038 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54701 episodes
GETTING ACTION FROM:
action 1, numVisits=54671, meanQ=4.996201, numObservations: 4
action -1, numVisits=24, meanQ=3.600919, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.58493 0.84375 0.670705 0.712272 0.5035 0.835038 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 408
Initial state: 0 0.592265 0.884278 0.613108 0.823165 0.444541 0.871835 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32117 episodes
GETTING ACTION FROM:
action 0, numVisits=30413, meanQ=2.986075, numObservations: 1
action -1, numVisits=1699, meanQ=2.866679, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.592265 0.884278 0.613108 0.823165 0.444541 0.871835 w: 1
Observation: 0 0 0.925817 0 0.921462 0 0.926235 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30356, meanQ=5.005247, numObservations: 5
action -1, numVisits=25, meanQ=3.717611, numObservations: 1
action 2, numVisits=23, meanQ=3.251748, numObservations: 4
action 1, numVisits=6, meanQ=1.663333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 56021 episodes
GETTING ACTION FROM:
action 3, numVisits=86371, meanQ=4.849389, numObservations: 5
action -1, numVisits=31, meanQ=3.638813, numObservations: 1
action 2, numVisits=23, meanQ=3.251748, numObservations: 4
action 1, numVisits=6, meanQ=1.663333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.592265 0.884278 0.613108 0.823165 0.444541 0.871835 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 409
Initial state: 0 0.500263 0.88491 0.631274 0.346675 0.563271 0.864221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55061 episodes
GETTING ACTION FROM:
action 2, numVisits=55014, meanQ=5.059002, numObservations: 4
action -1, numVisits=26, meanQ=3.733909, numObservations: 1
action 0, numVisits=15, meanQ=3.290781, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 2 0.500263 0.88491 0.631274 0.346675 0.563271 0.864221 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 410
Initial state: 0 0.618895 0.851093 0.633891 0.866566 0.613035 0.707454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54708 episodes
GETTING ACTION FROM:
action 2, numVisits=54691, meanQ=4.991152, numObservations: 4
action 3, numVisits=12, meanQ=0.918358, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.618895 0.851093 0.633891 0.866566 0.613035 0.707454 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 411
Initial state: 0 0.996926 0.252167 0.648601 0.847736 0.655668 0.822861 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54641 episodes
GETTING ACTION FROM:
action 1, numVisits=54561, meanQ=4.957323, numObservations: 4
action 0, numVisits=42, meanQ=3.933429, numObservations: 1
action -1, numVisits=29, meanQ=3.681848, numObservations: 1
action 2, numVisits=8, meanQ=1.500012, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.996926 0.252167 0.648601 0.847736 0.655668 0.822861 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 412
Initial state: 0 0.527736 0.816371 0.470867 0.192405 0.53155 0.873707 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54484 episodes
GETTING ACTION FROM:
action 3, numVisits=54463, meanQ=4.968039, numObservations: 4
action 2, numVisits=12, meanQ=1.750008, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.527736 0.816371 0.470867 0.192405 0.53155 0.873707 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 413
Initial state: 0 0.670987 0.885279 0.00615146 0.902734 0.589622 0.820763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50167 episodes
GETTING ACTION FROM:
action 3, numVisits=47488, meanQ=4.818411, numObservations: 4
action -1, numVisits=1725, meanQ=3.108907, numObservations: 1
action 0, numVisits=951, meanQ=3.062150, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.670987 0.885279 0.00615146 0.902734 0.589622 0.820763 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 414
Initial state: 0 0.688596 0.888845 0.515318 0.885741 0.779208 0.857817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54068 episodes
GETTING ACTION FROM:
action 2, numVisits=54052, meanQ=4.948024, numObservations: 5
action 1, numVisits=10, meanQ=2.400000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.688596 0.888845 0.515318 0.885741 0.779208 0.857817 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 415
Initial state: 0 0.585211 0.859314 0.0470225 0.36791 0.528442 0.831771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54193 episodes
GETTING ACTION FROM:
action 3, numVisits=54127, meanQ=4.927684, numObservations: 4
action -1, numVisits=40, meanQ=3.881799, numObservations: 1
action 1, numVisits=21, meanQ=3.285719, numObservations: 4
action 2, numVisits=3, meanQ=0.000033, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.585211 0.859314 0.0470225 0.36791 0.528442 0.831771 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 416
Initial state: 0 0.528833 0.856591 0.823738 0.377242 0.643501 0.879307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53138 episodes
GETTING ACTION FROM:
action 2, numVisits=53102, meanQ=4.808521, numObservations: 4
action -1, numVisits=23, meanQ=3.331697, numObservations: 1
action 3, numVisits=8, meanQ=0.873750, numObservations: 2
action 1, numVisits=3, meanQ=0.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.528833 0.856591 0.823738 0.377242 0.643501 0.879307 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1974, meanQ=4.482592, numObservations: 5
action -1, numVisits=1968, meanQ=2.771355, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29889 episodes
GETTING ACTION FROM:
action 3, numVisits=26099, meanQ=5.615295, numObservations: 4
action 1, numVisits=1974, meanQ=4.482592, numObservations: 5
action -1, numVisits=5752, meanQ=0.791658, numObservations: 1
action 0, numVisits=6, meanQ=-2.001650, numObservations: 1
action 2, numVisits=4, meanQ=-2.252500, numObservations: 2
action: 3
Next state: 1 0.528833 0.856591 0.823738 0.377242 0.643501 0.879307 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 417
Initial state: 0 0.689381 0.837974 0.284037 0.207545 0.543009 0.852989 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54275 episodes
GETTING ACTION FROM:
action 2, numVisits=54239, meanQ=4.946202, numObservations: 5
action 0, numVisits=24, meanQ=3.592809, numObservations: 1
action 1, numVisits=7, meanQ=1.428586, numObservations: 3
action 3, numVisits=3, meanQ=-0.659967, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.689381 0.837974 0.284037 0.207545 0.543009 0.852989 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7495, meanQ=8.335897, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 23714 episodes
GETTING ACTION FROM:
action 1, numVisits=21210, meanQ=6.915331, numObservations: 4
action 3, numVisits=8825, meanQ=6.376001, numObservations: 5
action 0, numVisits=1173, meanQ=0.187613, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=4, meanQ=-91.689470, numObservations: 1
action: 1
Next state: 1 0.689381 0.837974 0.284037 0.207545 0.543009 0.852989 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 418
Initial state: 0 0.582402 0.868796 0.603535 0.861254 0.960901 0.549006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54407 episodes
GETTING ACTION FROM:
action 2, numVisits=54401, meanQ=5.006458, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.582402 0.868796 0.603535 0.861254 0.960901 0.549006 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 419
Initial state: 0 0.946043 0.198803 0.624051 0.812282 0.533378 0.835309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54690 episodes
GETTING ACTION FROM:
action 2, numVisits=54679, meanQ=5.048321, numObservations: 4
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.946043 0.198803 0.624051 0.812282 0.533378 0.835309 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 420
Initial state: 0 0.681874 0.891281 0.980853 0.694742 0.536242 0.88608 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54458 episodes
GETTING ACTION FROM:
action 3, numVisits=54422, meanQ=4.973442, numObservations: 4
action 2, numVisits=28, meanQ=3.100000, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.681874 0.891281 0.980853 0.694742 0.536242 0.88608 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 421
Initial state: 0 0.505771 0.884244 0.954296 0.493693 0.641422 0.816155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54554 episodes
GETTING ACTION FROM:
action 2, numVisits=54520, meanQ=4.993967, numObservations: 5
action 0, numVisits=29, meanQ=3.641827, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.505771 0.884244 0.954296 0.493693 0.641422 0.816155 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 422
Initial state: 0 0.588524 0.504502 0.69792 0.858347 0.661838 0.886095 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54238 episodes
GETTING ACTION FROM:
action 3, numVisits=54200, meanQ=4.980315, numObservations: 4
action 1, numVisits=33, meanQ=3.575458, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.588524 0.504502 0.69792 0.858347 0.661838 0.886095 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 423
Initial state: 0 0.500008 0.741678 0.538875 0.821969 0.636811 0.895505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54883 episodes
GETTING ACTION FROM:
action 3, numVisits=54875, meanQ=5.023320, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.500008 0.741678 0.538875 0.821969 0.636811 0.895505 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 424
Initial state: 0 0.555401 0.833302 0.633188 0.864477 0.754012 0.724609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47200 episodes
GETTING ACTION FROM:
action 2, numVisits=36909, meanQ=4.998552, numObservations: 4
action 0, numVisits=10285, meanQ=2.949870, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.555401 0.833302 0.633188 0.864477 0.754012 0.724609 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 425
Initial state: 0 0.542456 0.861987 0.502415 0.877063 0.146916 0.0740239 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51412 episodes
GETTING ACTION FROM:
action 3, numVisits=51406, meanQ=4.773590, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.542456 0.861987 0.502415 0.877063 0.146916 0.0740239 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 426
Initial state: 0 0.621131 0.826211 0.576231 0.88948 0.93546 0.680642 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54622 episodes
GETTING ACTION FROM:
action 2, numVisits=54547, meanQ=5.131804, numObservations: 4
action -1, numVisits=36, meanQ=4.038249, numObservations: 1
action 0, numVisits=32, meanQ=3.909738, numObservations: 1
action 1, numVisits=5, meanQ=-0.002000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 1 0.621131 0.826211 0.576231 0.88948 0.93546 0.680642 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 427
Initial state: 0 0.662108 0.881997 0.613293 0.869348 0.765074 0.730844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55016 episodes
GETTING ACTION FROM:
action 2, numVisits=54985, meanQ=5.057500, numObservations: 3
action 0, numVisits=26, meanQ=3.766182, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.662108 0.881997 0.613293 0.869348 0.765074 0.730844 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 428
Initial state: 0 0.0750178 0.32782 0.68383 0.898106 0.662226 0.864399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32075 episodes
GETTING ACTION FROM:
action -1, numVisits=32067, meanQ=3.078808, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.0750178 0.32782 0.68383 0.898106 0.662226 0.864399 w: 1
Observation: 0 0.0714663 0 0.665564 0 0.576135 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32039, meanQ=5.124666, numObservations: 3
action 0, numVisits=19, meanQ=3.579372, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 55466 episodes
GETTING ACTION FROM:
action 1, numVisits=87504, meanQ=4.991780, numObservations: 3
action 0, numVisits=20, meanQ=3.448859, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0750178 0.32782 0.68383 0.898106 0.662226 0.864399 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=14180, meanQ=8.341570, numObservations: 5
action 3, numVisits=28, meanQ=7.071082, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 28808 episodes
GETTING ACTION FROM:
action 2, numVisits=40551, meanQ=7.110412, numObservations: 5
action 3, numVisits=1485, meanQ=5.964261, numObservations: 4
action 0, numVisits=684, meanQ=0.020526, numObservations: 1
action -1, numVisits=298, meanQ=-0.052099, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0750178 0.32782 0.68383 0.898106 0.662226 0.864399 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 429
Initial state: 0 0.416312 0.934434 0.620728 0.875864 0.633618 0.853724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30938 episodes
GETTING ACTION FROM:
action 0, numVisits=30933, meanQ=2.921099, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.416312 0.934434 0.620728 0.875864 0.633618 0.853724 w: 1
Observation: 0 0 0.906325 0 0.824791 0 0.825749 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=30915, meanQ=4.913155, numObservations: 4
action 1, numVisits=12, meanQ=0.150008, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 54480 episodes
GETTING ACTION FROM:
action 2, numVisits=85388, meanQ=4.963927, numObservations: 4
action 3, numVisits=8, meanQ=0.873750, numObservations: 3
action 1, numVisits=12, meanQ=0.150008, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.416312 0.934434 0.620728 0.875864 0.633618 0.853724 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 430
Initial state: 0 0.59463 0.886704 0.548305 0.843163 0.133169 0.905629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54017 episodes
GETTING ACTION FROM:
action 3, numVisits=54010, meanQ=4.968566, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.59463 0.886704 0.548305 0.843163 0.133169 0.905629 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4021, meanQ=5.332877, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 56145 episodes
GETTING ACTION FROM:
action 3, numVisits=60164, meanQ=4.989192, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.59463 0.886704 0.548305 0.843163 0.133169 0.905629 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1425, meanQ=5.445246, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 61784 episodes
GETTING ACTION FROM:
action 3, numVisits=63205, meanQ=4.922098, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=4, meanQ=0.475000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.59463 0.886704 0.548305 0.843163 0.133169 0.905629 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=1067, meanQ=8.260901, numObservations: 3
action 2, numVisits=22, meanQ=7.085914, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 70170 episodes
GETTING ACTION FROM:
action 2, numVisits=63646, meanQ=6.472928, numObservations: 4
action 1, numVisits=7613, meanQ=6.393033, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.59463 0.886704 0.548305 0.843163 0.133169 0.905629 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 431
Initial state: 0 0.628572 0.810075 0.693096 0.870676 0.518646 0.747279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32025 episodes
GETTING ACTION FROM:
action 0, numVisits=32020, meanQ=2.916348, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.628572 0.810075 0.693096 0.870676 0.518646 0.747279 w: 1
Observation: 0 0 0.798764 0 0.917746 0 0.71438 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=25196, meanQ=4.900780, numObservations: 4
action 1, numVisits=6812, meanQ=4.858160, numObservations: 3
action 2, numVisits=7, meanQ=2.144300, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 55137 episodes
GETTING ACTION FROM:
action 1, numVisits=58185, meanQ=5.092799, numObservations: 3
action 3, numVisits=28958, meanQ=4.890343, numObservations: 4
action 2, numVisits=9, meanQ=1.445567, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.628572 0.810075 0.693096 0.870676 0.518646 0.747279 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 432
Initial state: 0 0.502487 0.884314 0.916528 0.531514 0.504223 0.875714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54251 episodes
GETTING ACTION FROM:
action 3, numVisits=54243, meanQ=4.940042, numObservations: 4
action 2, numVisits=3, meanQ=0.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.502487 0.884314 0.916528 0.531514 0.504223 0.875714 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 433
Initial state: 0 0.546168 0.12461 0.544641 0.800633 0.683262 0.846804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53847 episodes
GETTING ACTION FROM:
action 3, numVisits=53454, meanQ=4.982166, numObservations: 3
action 0, numVisits=253, meanQ=1.620401, numObservations: 1
action -1, numVisits=135, meanQ=1.507243, numObservations: 1
action 2, numVisits=4, meanQ=-2.239950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.546168 0.12461 0.544641 0.800633 0.683262 0.846804 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 434
Initial state: 0 0.61651 0.80678 0.693493 0.881247 0.27552 0.636416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54624 episodes
GETTING ACTION FROM:
action 1, numVisits=54535, meanQ=4.984081, numObservations: 5
action 0, numVisits=49, meanQ=4.040810, numObservations: 1
action -1, numVisits=38, meanQ=3.922882, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.61651 0.80678 0.693493 0.881247 0.27552 0.636416 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 435
Initial state: 0 0.225375 0.910444 0.66588 0.825941 0.638421 0.853983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54677 episodes
GETTING ACTION FROM:
action 2, numVisits=54562, meanQ=4.949255, numObservations: 4
action -1, numVisits=111, meanQ=4.322183, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.225375 0.910444 0.66588 0.825941 0.638421 0.853983 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 436
Initial state: 0 0.841049 0.622328 0.675073 0.890341 0.695527 0.832859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54624 episodes
GETTING ACTION FROM:
action 2, numVisits=54618, meanQ=4.986246, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.841049 0.622328 0.675073 0.890341 0.695527 0.832859 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 437
Initial state: 0 0.429898 0.685945 0.505138 0.806049 0.562216 0.801706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31250 episodes
GETTING ACTION FROM:
action -1, numVisits=31214, meanQ=2.862008, numObservations: 1
action 3, numVisits=32, meanQ=1.646878, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.429898 0.685945 0.505138 0.806049 0.562216 0.801706 w: 1
Observation: 0 0.346815 0 0.573354 0 0.507904 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=24813, meanQ=4.926055, numObservations: 4
action 3, numVisits=6395, meanQ=4.815108, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 52410 episodes
GETTING ACTION FROM:
action 2, numVisits=76125, meanQ=4.845494, numObservations: 4
action 3, numVisits=7489, meanQ=4.774549, numObservations: 4
action 1, numVisits=5, meanQ=-0.002000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.429898 0.685945 0.505138 0.806049 0.562216 0.801706 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 438
Initial state: 0 0.0169839 0.538506 0.601403 0.820964 0.552406 0.855336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48830 episodes
GETTING ACTION FROM:
action 1, numVisits=48625, meanQ=4.595005, numObservations: 5
action -1, numVisits=201, meanQ=4.159440, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0169839 0.538506 0.601403 0.820964 0.552406 0.855336 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=6834, meanQ=6.157685, numObservations: 1
action 3, numVisits=4, meanQ=0.025000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8091 episodes
GETTING ACTION FROM:
action -1, numVisits=14924, meanQ=2.876241, numObservations: 1
action 3, numVisits=4, meanQ=0.025000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.0169839 0.538506 0.601403 0.820964 0.552406 0.855336 w: 1
Observation: 0 0.0470501 0 0.6102 0 0.527035 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=7227, meanQ=8.245084, numObservations: 4
action -1, numVisits=1675, meanQ=4.806150, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29409 episodes
GETTING ACTION FROM:
action 3, numVisits=14924, meanQ=6.917317, numObservations: 4
action 2, numVisits=18414, meanQ=6.133711, numObservations: 3
action -1, numVisits=4972, meanQ=1.348982, numObservations: 1
action 0, numVisits=4, meanQ=-2.002475, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0169839 0.538506 0.601403 0.820964 0.552406 0.855336 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8409
Run # 439
Initial state: 0 0.650869 0.811213 0.785561 0.573618 0.683596 0.860601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54660 episodes
GETTING ACTION FROM:
action 1, numVisits=54629, meanQ=4.984468, numObservations: 3
action -1, numVisits=27, meanQ=3.640724, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.650869 0.811213 0.785561 0.573618 0.683596 0.860601 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 440
Initial state: 0 0.580151 0.886221 0.573038 0.777411 0.641996 0.812245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33839 episodes
GETTING ACTION FROM:
action 0, numVisits=33834, meanQ=5.426668, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.580151 0.886221 0.573038 0.777411 0.641996 0.812245 w: 1
Observation: 0 0 0.939491 0 0.830512 0 0.810718 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13153, meanQ=7.491426, numObservations: 4
action 2, numVisits=49, meanQ=3.377336, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55421 episodes
GETTING ACTION FROM:
action 3, numVisits=68574, meanQ=5.485497, numObservations: 4
action 2, numVisits=49, meanQ=3.377336, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.580151 0.886221 0.573038 0.777411 0.641996 0.812245 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=659, meanQ=6.199830, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 15841 episodes
GETTING ACTION FROM:
action 3, numVisits=660, meanQ=6.197876, numObservations: 4
action 1, numVisits=11965, meanQ=6.017013, numObservations: 3
action 0, numVisits=3009, meanQ=0.256700, numObservations: 1
action -1, numVisits=871, meanQ=-0.207761, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.580151 0.886221 0.573038 0.777411 0.641996 0.812245 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 441
Initial state: 0 0.622571 0.887184 0.54666 0.827408 0.338165 0.365336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54534 episodes
GETTING ACTION FROM:
action 1, numVisits=54401, meanQ=4.946079, numObservations: 4
action 0, numVisits=56, meanQ=4.062309, numObservations: 1
action -1, numVisits=46, meanQ=3.978431, numObservations: 1
action 3, numVisits=28, meanQ=3.651082, numObservations: 5
action 2, numVisits=3, meanQ=0.663333, numObservations: 2
action: 1
Next state: 1 0.622571 0.887184 0.54666 0.827408 0.338165 0.365336 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 442
Initial state: 0 0.640742 0.821657 0.0811715 0.799594 0.579135 0.889885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54592 episodes
GETTING ACTION FROM:
action 3, numVisits=54518, meanQ=5.024445, numObservations: 5
action 0, numVisits=66, meanQ=4.214465, numObservations: 1
action 2, numVisits=5, meanQ=1.398000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.640742 0.821657 0.0811715 0.799594 0.579135 0.889885 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 443
Initial state: 0 0.418787 0.452404 0.603144 0.805058 0.644545 0.849948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54332 episodes
GETTING ACTION FROM:
action 1, numVisits=54310, meanQ=5.006224, numObservations: 3
action 0, numVisits=17, meanQ=3.403001, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.418787 0.452404 0.603144 0.805058 0.644545 0.849948 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8315, meanQ=8.312508, numObservations: 4
action 2, numVisits=642, meanQ=8.114933, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22307 episodes
GETTING ACTION FROM:
action 2, numVisits=676, meanQ=7.952347, numObservations: 3
action 3, numVisits=30562, meanQ=6.341698, numObservations: 4
action 0, numVisits=25, meanQ=-0.258392, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=3, meanQ=-122.620224, numObservations: 1
action: 2
Next state: 1 0.418787 0.452404 0.603144 0.805058 0.644545 0.849948 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 444
Initial state: 0 0.516677 0.867522 0.604557 0.803273 0.350621 0.0693706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 35146 episodes
GETTING ACTION FROM:
action 0, numVisits=23268, meanQ=5.238370, numObservations: 3
action 3, numVisits=11873, meanQ=5.059342, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.516677 0.867522 0.604557 0.803273 0.350621 0.0693706 w: 1
Observation: 0 0 0.945769 0 0.851512 0 0.014265 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8177, meanQ=8.042919, numObservations: 5
action 2, numVisits=7, meanQ=5.568571, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 56179 episodes
GETTING ACTION FROM:
action 1, numVisits=64321, meanQ=5.273845, numObservations: 5
action 0, numVisits=29, meanQ=3.986441, numObservations: 1
action 2, numVisits=13, meanQ=3.085392, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.516677 0.867522 0.604557 0.803273 0.350621 0.0693706 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 445
Initial state: 0 0.095654 0.115718 0.692269 0.862256 0.647996 0.844552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52081 episodes
GETTING ACTION FROM:
action 2, numVisits=52061, meanQ=5.051978, numObservations: 4
action -1, numVisits=15, meanQ=3.291422, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.095654 0.115718 0.692269 0.862256 0.647996 0.844552 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 446
Initial state: 0 0.663254 0.818442 0.164395 0.465194 0.531217 0.80249 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54614 episodes
GETTING ACTION FROM:
action 2, numVisits=54555, meanQ=5.107339, numObservations: 4
action 0, numVisits=55, meanQ=4.210837, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.663254 0.818442 0.164395 0.465194 0.531217 0.80249 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8819, meanQ=8.302777, numObservations: 3
action 3, numVisits=27, meanQ=6.921859, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 16468 episodes
GETTING ACTION FROM:
action 1, numVisits=15131, meanQ=7.226896, numObservations: 3
action 3, numVisits=8872, meanQ=6.138872, numObservations: 3
action -1, numVisits=1290, meanQ=-0.508845, numObservations: 1
action 0, numVisits=23, meanQ=-1.699987, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.663254 0.818442 0.164395 0.465194 0.531217 0.80249 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 447
Initial state: 0 0.555876 0.878619 0.661798 0.856134 0.712987 0.244094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54812 episodes
GETTING ACTION FROM:
action 3, numVisits=54742, meanQ=5.066922, numObservations: 5
action -1, numVisits=44, meanQ=4.086903, numObservations: 1
action 0, numVisits=21, meanQ=3.639827, numObservations: 1
action 1, numVisits=3, meanQ=0.663333, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 2 0.555876 0.878619 0.661798 0.856134 0.712987 0.244094 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 448
Initial state: 0 0.0302965 0.0527068 0.66348 0.871872 0.591283 0.806801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54261 episodes
GETTING ACTION FROM:
action 1, numVisits=54231, meanQ=4.928780, numObservations: 5
action 3, numVisits=24, meanQ=3.325846, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.0302965 0.0527068 0.66348 0.871872 0.591283 0.806801 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7656, meanQ=8.402481, numObservations: 5
action 2, numVisits=5, meanQ=2.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 15370 episodes
GETTING ACTION FROM:
action 3, numVisits=21659, meanQ=6.675748, numObservations: 5
action 2, numVisits=8, meanQ=-0.001250, numObservations: 3
action 0, numVisits=1172, meanQ=-0.446437, numObservations: 1
action -1, numVisits=194, meanQ=-0.842120, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.0302965 0.0527068 0.66348 0.871872 0.591283 0.806801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=553, meanQ=8.298454, numObservations: 3
action 2, numVisits=12, meanQ=5.158000, numObservations: 3
action -1, numVisits=264, meanQ=2.369965, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 58202 episodes
GETTING ACTION FROM:
action 3, numVisits=1422, meanQ=6.828551, numObservations: 5
action 2, numVisits=56732, meanQ=6.404246, numObservations: 3
action -1, numVisits=850, meanQ=-0.520485, numObservations: 1
action 0, numVisits=29, meanQ=-1.385859, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0302965 0.0527068 0.66348 0.871872 0.591283 0.806801 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 449
Initial state: 0 0.678615 0.855713 0.528176 0.839377 0.214517 0.0679394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54746 episodes
GETTING ACTION FROM:
action 1, numVisits=54688, meanQ=4.892503, numObservations: 4
action -1, numVisits=42, meanQ=3.870837, numObservations: 1
action 2, numVisits=13, meanQ=2.078485, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.678615 0.855713 0.528176 0.839377 0.214517 0.0679394 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 450
Initial state: 0 0.657831 0.805678 0.659624 0.880308 0.941893 0.460585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54512 episodes
GETTING ACTION FROM:
action 2, numVisits=54492, meanQ=4.922786, numObservations: 5
action 3, numVisits=13, meanQ=2.693100, numObservations: 3
action 1, numVisits=3, meanQ=-0.659967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.657831 0.805678 0.659624 0.880308 0.941893 0.460585 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 451
Initial state: 0 0.661638 0.814569 0.642933 0.867792 0.926109 0.663421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51537 episodes
GETTING ACTION FROM:
action 3, numVisits=51530, meanQ=4.845421, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.661638 0.814569 0.642933 0.867792 0.926109 0.663421 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 452
Initial state: 0 0.894171 0.214694 0.572988 0.889847 0.555925 0.814718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54496 episodes
GETTING ACTION FROM:
action 2, numVisits=54488, meanQ=4.922791, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.894171 0.214694 0.572988 0.889847 0.555925 0.814718 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 453
Initial state: 0 0.197152 0.12006 0.612295 0.818075 0.550716 0.858385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55049 episodes
GETTING ACTION FROM:
action 2, numVisits=55020, meanQ=5.156807, numObservations: 5
action 0, numVisits=25, meanQ=3.753941, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.197152 0.12006 0.612295 0.818075 0.550716 0.858385 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 454
Initial state: 0 0.627626 0.835909 0.513015 0.880107 0.760807 0.509354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54608 episodes
GETTING ACTION FROM:
action 2, numVisits=54597, meanQ=5.001683, numObservations: 5
action 1, numVisits=6, meanQ=1.498333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.627626 0.835909 0.513015 0.880107 0.760807 0.509354 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 455
Initial state: 0 0.566213 0.8158 0.633169 0.85059 0.278723 0.155656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54399 episodes
GETTING ACTION FROM:
action 2, numVisits=54338, meanQ=4.928915, numObservations: 4
action 1, numVisits=56, meanQ=4.037143, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.566213 0.8158 0.633169 0.85059 0.278723 0.155656 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 456
Initial state: 0 0.612859 0.874794 0.508118 0.80651 0.140695 0.0622606 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54595 episodes
GETTING ACTION FROM:
action 1, numVisits=54569, meanQ=5.016539, numObservations: 3
action 2, numVisits=21, meanQ=3.047143, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.612859 0.874794 0.508118 0.80651 0.140695 0.0622606 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 457
Initial state: 0 0.571862 0.820211 0.644525 0.820464 0.430479 0.158867 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48961 episodes
GETTING ACTION FROM:
action 2, numVisits=48948, meanQ=4.556454, numObservations: 4
action 1, numVisits=8, meanQ=2.250025, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.571862 0.820211 0.644525 0.820464 0.430479 0.158867 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 458
Initial state: 0 0.765794 0.936509 0.570456 0.840214 0.554467 0.80752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54392 episodes
GETTING ACTION FROM:
action 3, numVisits=54380, meanQ=5.013080, numObservations: 4
action 2, numVisits=6, meanQ=1.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.765794 0.936509 0.570456 0.840214 0.554467 0.80752 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 459
Initial state: 0 0.295936 0.508944 0.619898 0.822528 0.53312 0.808011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31904 episodes
GETTING ACTION FROM:
action 0, numVisits=31894, meanQ=2.908826, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=6, meanQ=-3.815000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.295936 0.508944 0.619898 0.822528 0.53312 0.808011 w: 1
Observation: 0 0 0.49753 0 0.752771 0 0.782938 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31887, meanQ=4.966785, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 54785 episodes
GETTING ACTION FROM:
action 2, numVisits=86240, meanQ=5.120745, numObservations: 4
action 1, numVisits=433, meanQ=4.680150, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.295936 0.508944 0.619898 0.822528 0.53312 0.808011 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 460
Initial state: 0 0.588912 0.843434 0.626374 0.887693 0.0240913 0.923127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54763 episodes
GETTING ACTION FROM:
action 1, numVisits=54717, meanQ=5.021598, numObservations: 4
action -1, numVisits=25, meanQ=3.663144, numObservations: 1
action 2, numVisits=18, meanQ=3.444444, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.588912 0.843434 0.626374 0.887693 0.0240913 0.923127 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 461
Initial state: 0 0.504932 0.853149 0.616764 0.88402 0.0924153 0.484839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32024 episodes
GETTING ACTION FROM:
action -1, numVisits=32015, meanQ=2.882137, numObservations: 1
action 2, numVisits=5, meanQ=-1.600000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.504932 0.853149 0.616764 0.88402 0.0924153 0.484839 w: 1
Observation: 0 0.458561 0 0.690969 0 0.00699497 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32002, meanQ=4.997940, numObservations: 5
action 2, numVisits=7, meanQ=2.427157, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 54928 episodes
GETTING ACTION FROM:
action 1, numVisits=86928, meanQ=5.106679, numObservations: 5
action 2, numVisits=9, meanQ=1.665567, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.504932 0.853149 0.616764 0.88402 0.0924153 0.484839 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 462
Initial state: 0 0.385698 0.0797923 0.588805 0.848661 0.634104 0.824464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54414 episodes
GETTING ACTION FROM:
action 2, numVisits=54316, meanQ=4.979270, numObservations: 4
action -1, numVisits=85, meanQ=4.275604, numObservations: 1
action 1, numVisits=10, meanQ=2.400000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.385698 0.0797923 0.588805 0.848661 0.634104 0.824464 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 463
Initial state: 0 0.6585 0.824148 0.160759 0.571433 0.596404 0.864896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54362 episodes
GETTING ACTION FROM:
action 2, numVisits=54285, meanQ=5.043403, numObservations: 4
action 0, numVisits=35, meanQ=3.899086, numObservations: 1
action -1, numVisits=30, meanQ=3.737007, numObservations: 1
action 3, numVisits=7, meanQ=1.711443, numObservations: 3
action 1, numVisits=5, meanQ=1.622000, numObservations: 2
action: 2
Next state: 0 0.6585 0.824148 0.160759 0.571433 0.596404 0.864896 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8829, meanQ=8.303850, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 17273 episodes
GETTING ACTION FROM:
action 3, numVisits=19737, meanQ=6.832526, numObservations: 4
action -1, numVisits=6320, meanQ=0.023234, numObservations: 1
action 0, numVisits=47, meanQ=-0.914232, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.6585 0.824148 0.160759 0.571433 0.596404 0.864896 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 464
Initial state: 0 0.583115 0.803187 0.53229 0.886405 0.786232 0.583236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 43560 episodes
GETTING ACTION FROM:
action 1, numVisits=27798, meanQ=5.009629, numObservations: 5
action 0, numVisits=15754, meanQ=2.943972, numObservations: 1
action 3, numVisits=5, meanQ=-0.213980, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.583115 0.803187 0.53229 0.886405 0.786232 0.583236 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 465
Initial state: 0 0.588631 0.823144 0.678638 0.814459 0.807796 0.489365 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54827 episodes
GETTING ACTION FROM:
action 2, numVisits=42940, meanQ=4.966911, numObservations: 3
action 3, numVisits=11648, meanQ=4.917139, numObservations: 4
action 1, numVisits=151, meanQ=4.362105, numObservations: 4
action 0, numVisits=53, meanQ=4.071611, numObservations: 1
action -1, numVisits=35, meanQ=3.842808, numObservations: 1
action: 2
Next state: 1 0.588631 0.823144 0.678638 0.814459 0.807796 0.489365 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 466
Initial state: 0 0.237255 0.0465395 0.546819 0.872589 0.655959 0.880126 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54672 episodes
GETTING ACTION FROM:
action 3, numVisits=54664, meanQ=4.902549, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.237255 0.0465395 0.546819 0.872589 0.655959 0.880126 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4190, meanQ=4.701696, numObservations: 5
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 67268 episodes
GETTING ACTION FROM:
action 2, numVisits=71455, meanQ=5.695074, numObservations: 5
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.237255 0.0465395 0.546819 0.872589 0.655959 0.880126 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 467
Initial state: 0 0.50995 0.831894 0.669345 0.809092 0.896798 0.117859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51484 episodes
GETTING ACTION FROM:
action 2, numVisits=51391, meanQ=4.869872, numObservations: 4
action -1, numVisits=46, meanQ=3.882735, numObservations: 1
action 0, numVisits=27, meanQ=3.589639, numObservations: 1
action 3, numVisits=18, meanQ=2.600572, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.50995 0.831894 0.669345 0.809092 0.896798 0.117859 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 468
Initial state: 0 0.529049 0.874476 0.452514 0.749968 0.698992 0.830728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51728 episodes
GETTING ACTION FROM:
action 3, numVisits=51632, meanQ=4.885095, numObservations: 5
action 0, numVisits=52, meanQ=3.991075, numObservations: 1
action -1, numVisits=32, meanQ=3.686965, numObservations: 1
action 1, numVisits=11, meanQ=1.445464, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.529049 0.874476 0.452514 0.749968 0.698992 0.830728 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 469
Initial state: 0 0.653316 0.859842 0.661591 0.837002 0.482393 0.638894 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54491 episodes
GETTING ACTION FROM:
action 2, numVisits=54416, meanQ=4.989775, numObservations: 4
action -1, numVisits=27, meanQ=3.697791, numObservations: 1
action 1, numVisits=43, meanQ=3.261108, numObservations: 3
action 3, numVisits=3, meanQ=-2.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.653316 0.859842 0.661591 0.837002 0.482393 0.638894 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 470
Initial state: 0 0.508111 0.251746 0.607955 0.832542 0.638724 0.826809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33902 episodes
GETTING ACTION FROM:
action 0, numVisits=33897, meanQ=5.894717, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.508111 0.251746 0.607955 0.832542 0.638724 0.826809 w: 1
Observation: 0 0 0.289814 0 0.867859 0 0.796871 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12934, meanQ=7.810502, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54354 episodes
GETTING ACTION FROM:
action 2, numVisits=67288, meanQ=5.780967, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.508111 0.251746 0.607955 0.832542 0.638724 0.826809 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 471
Initial state: 0 0.145558 0.959207 0.589693 0.866946 0.682969 0.895143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51818 episodes
GETTING ACTION FROM:
action 2, numVisits=51744, meanQ=4.895470, numObservations: 5
action -1, numVisits=41, meanQ=3.848642, numObservations: 1
action 0, numVisits=31, meanQ=3.726855, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.145558 0.959207 0.589693 0.866946 0.682969 0.895143 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 472
Initial state: 0 0.626806 0.831348 0.675614 0.838405 0.388661 0.699531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54418 episodes
GETTING ACTION FROM:
action 3, numVisits=54385, meanQ=4.982902, numObservations: 3
action 1, numVisits=27, meanQ=3.404081, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.626806 0.831348 0.675614 0.838405 0.388661 0.699531 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8918, meanQ=8.210772, numObservations: 5
action 2, numVisits=12, meanQ=6.332500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18421 episodes
GETTING ACTION FROM:
action 1, numVisits=12641, meanQ=7.506775, numObservations: 5
action 2, numVisits=13696, meanQ=5.816195, numObservations: 3
action -1, numVisits=1011, meanQ=-0.234355, numObservations: 1
action 0, numVisits=5, meanQ=-6.540065, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.626806 0.831348 0.675614 0.838405 0.388661 0.699531 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 473
Initial state: 0 0.652497 0.809748 0.309256 0.72573 0.50959 0.898238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53765 episodes
GETTING ACTION FROM:
action 2, numVisits=53729, meanQ=4.939795, numObservations: 5
action 0, numVisits=29, meanQ=3.710598, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.652497 0.809748 0.309256 0.72573 0.50959 0.898238 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6151, meanQ=8.542523, numObservations: 3
action 1, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 23919 episodes
GETTING ACTION FROM:
action 3, numVisits=29699, meanQ=6.473619, numObservations: 4
action 1, numVisits=11, meanQ=1.180918, numObservations: 3
action -1, numVisits=358, meanQ=0.093380, numObservations: 1
action 0, numVisits=7, meanQ=-2.001414, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.652497 0.809748 0.309256 0.72573 0.50959 0.898238 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 474
Initial state: 0 0.693182 0.864991 0.813636 0.739508 0.503302 0.821465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54693 episodes
GETTING ACTION FROM:
action 1, numVisits=54679, meanQ=5.062952, numObservations: 4
action 3, numVisits=7, meanQ=2.570000, numObservations: 3
action 2, numVisits=3, meanQ=0.663333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.693182 0.864991 0.813636 0.739508 0.503302 0.821465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 475
Initial state: 0 0.671117 0.883805 0.593779 0.870682 0.241006 0.671915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54362 episodes
GETTING ACTION FROM:
action 3, numVisits=54300, meanQ=5.000711, numObservations: 4
action 0, numVisits=58, meanQ=4.138390, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.671117 0.883805 0.593779 0.870682 0.241006 0.671915 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9180, meanQ=8.287133, numObservations: 3
action 2, numVisits=28, meanQ=7.071436, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 24484 episodes
GETTING ACTION FROM:
action 1, numVisits=33105, meanQ=6.702539, numObservations: 3
action 2, numVisits=132, meanQ=5.101141, numObservations: 4
action -1, numVisits=455, meanQ=0.369451, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-194.928903, numObservations: 1
action: 1
Next state: 1 0.671117 0.883805 0.593779 0.870682 0.241006 0.671915 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 476
Initial state: 0 0.99194 0.479329 0.556241 0.876159 0.539035 0.891456 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54338 episodes
GETTING ACTION FROM:
action 1, numVisits=54136, meanQ=4.999795, numObservations: 5
action -1, numVisits=196, meanQ=4.547840, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.99194 0.479329 0.556241 0.876159 0.539035 0.891456 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 477
Initial state: 0 0.212158 0.454706 0.61961 0.875362 0.501145 0.801801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54443 episodes
GETTING ACTION FROM:
action 3, numVisits=54317, meanQ=4.989605, numObservations: 5
action -1, numVisits=112, meanQ=1.695339, numObservations: 1
action 1, numVisits=7, meanQ=0.287157, numObservations: 3
action 2, numVisits=5, meanQ=-0.399980, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.212158 0.454706 0.61961 0.875362 0.501145 0.801801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.610786 0.876333 0.0432768 0.341553 0.698361 0.803848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31841 episodes
GETTING ACTION FROM:
action -1, numVisits=31753, meanQ=2.816116, numObservations: 1
action 0, numVisits=65, meanQ=2.052962, numObservations: 1
action 3, numVisits=15, meanQ=1.061347, numObservations: 2
action 1, numVisits=5, meanQ=-1.600000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action: -1
Next state: 0 0.610786 0.876333 0.0432768 0.341553 0.698361 0.803848 w: 1
Observation: 0 0.556828 0 0.0234719 0 0.740851 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31544, meanQ=4.855999, numObservations: 5
action 2, numVisits=148, meanQ=4.343515, numObservations: 5
action -1, numVisits=32, meanQ=3.748514, numObservations: 1
action 3, numVisits=26, meanQ=3.526927, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 54594 episodes
GETTING ACTION FROM:
action 1, numVisits=86087, meanQ=4.855934, numObservations: 5
action 2, numVisits=197, meanQ=4.378594, numObservations: 5
action -1, numVisits=34, meanQ=3.715929, numObservations: 1
action 3, numVisits=26, meanQ=3.526927, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.610786 0.876333 0.0432768 0.341553 0.698361 0.803848 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 479
Initial state: 0 0.536216 0.852983 0.821361 0.221477 0.671036 0.856916 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31909 episodes
GETTING ACTION FROM:
action -1, numVisits=31900, meanQ=2.869723, numObservations: 1
action 2, numVisits=5, meanQ=-1.600000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.536216 0.852983 0.821361 0.221477 0.671036 0.856916 w: 1
Observation: 0 0.618057 0 0.898125 0 0.613306 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31889, meanQ=4.945359, numObservations: 5
action 1, numVisits=5, meanQ=0.196000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 53804 episodes
GETTING ACTION FROM:
action 2, numVisits=85666, meanQ=5.008305, numObservations: 5
action 3, numVisits=28, meanQ=3.453575, numObservations: 4
action 1, numVisits=5, meanQ=0.196000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.536216 0.852983 0.821361 0.221477 0.671036 0.856916 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 480
Initial state: 0 0.108353 0.787393 0.547727 0.81697 0.518927 0.831597 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54618 episodes
GETTING ACTION FROM:
action 1, numVisits=54572, meanQ=5.027559, numObservations: 5
action 0, numVisits=27, meanQ=3.712720, numObservations: 1
action 2, numVisits=16, meanQ=2.374388, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.108353 0.787393 0.547727 0.81697 0.518927 0.831597 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7391, meanQ=8.382980, numObservations: 4
action 2, numVisits=87, meanQ=7.799083, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 26269 episodes
GETTING ACTION FROM:
action 3, numVisits=22501, meanQ=6.735940, numObservations: 4
action 2, numVisits=10045, meanQ=5.907266, numObservations: 5
action 0, numVisits=1196, meanQ=-0.360259, numObservations: 1
action -1, numVisits=7, meanQ=-5.647758, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.108353 0.787393 0.547727 0.81697 0.518927 0.831597 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 481
Initial state: 0 0.0227568 0.637916 0.521088 0.878508 0.685808 0.840437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52882 episodes
GETTING ACTION FROM:
action 3, numVisits=52865, meanQ=4.936622, numObservations: 4
action 1, numVisits=12, meanQ=2.251667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0227568 0.637916 0.521088 0.878508 0.685808 0.840437 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 482
Initial state: 0 0.54248 0.820899 0.500576 0.842349 0.87429 0.978246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54407 episodes
GETTING ACTION FROM:
action 2, numVisits=54147, meanQ=4.970575, numObservations: 5
action 0, numVisits=255, meanQ=2.282736, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.54248 0.820899 0.500576 0.842349 0.87429 0.978246 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 483
Initial state: 0 0.635526 0.0443599 0.576824 0.888433 0.571553 0.825768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54586 episodes
GETTING ACTION FROM:
action 3, numVisits=54534, meanQ=5.023766, numObservations: 4
action -1, numVisits=43, meanQ=3.980084, numObservations: 1
action 2, numVisits=6, meanQ=1.498333, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.635526 0.0443599 0.576824 0.888433 0.571553 0.825768 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 484
Initial state: 0 0.554575 0.878379 0.591024 0.85044 0.0428867 0.687589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54303 episodes
GETTING ACTION FROM:
action 2, numVisits=54274, meanQ=5.013180, numObservations: 4
action 0, numVisits=23, meanQ=3.588753, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.554575 0.878379 0.591024 0.85044 0.0428867 0.687589 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 485
Initial state: 0 0.528949 0.471616 0.509704 0.87209 0.682625 0.851231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55089 episodes
GETTING ACTION FROM:
action 2, numVisits=55005, meanQ=5.053879, numObservations: 4
action 1, numVisits=79, meanQ=4.285447, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.528949 0.471616 0.509704 0.87209 0.682625 0.851231 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 486
Initial state: 0 0.0416642 0.0235697 0.66328 0.889648 0.586794 0.812033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54771 episodes
GETTING ACTION FROM:
action 2, numVisits=54763, meanQ=5.022076, numObservations: 5
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.0416642 0.0235697 0.66328 0.889648 0.586794 0.812033 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 487
Initial state: 0 0.617875 0.837459 0.661509 0.853052 0.923019 0.86472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54374 episodes
GETTING ACTION FROM:
action 2, numVisits=54367, meanQ=5.008200, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.617875 0.837459 0.661509 0.853052 0.923019 0.86472 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 488
Initial state: 0 0.502139 0.857873 0.165734 0.267807 0.510581 0.820391 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54509 episodes
GETTING ACTION FROM:
action 2, numVisits=34789, meanQ=4.954685, numObservations: 5
action 1, numVisits=19594, meanQ=4.937253, numObservations: 4
action 0, numVisits=117, meanQ=4.371097, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.502139 0.857873 0.165734 0.267807 0.510581 0.820391 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4849, meanQ=8.406577, numObservations: 3
action 3, numVisits=9, meanQ=5.011111, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12741 episodes
GETTING ACTION FROM:
action 1, numVisits=16482, meanQ=6.732950, numObservations: 4
action 3, numVisits=15, meanQ=2.077646, numObservations: 2
action 0, numVisits=1097, meanQ=0.339171, numObservations: 1
action -1, numVisits=7, meanQ=-2.001414, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.502139 0.857873 0.165734 0.267807 0.510581 0.820391 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 489
Initial state: 0 0.623185 0.831449 0.53826 0.822736 0.793784 0.573204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54350 episodes
GETTING ACTION FROM:
action 2, numVisits=54343, meanQ=4.995437, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.623185 0.831449 0.53826 0.822736 0.793784 0.573204 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 490
Initial state: 0 0.593848 0.826364 0.558371 0.875902 0.119386 0.618477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54443 episodes
GETTING ACTION FROM:
action 3, numVisits=54413, meanQ=4.904854, numObservations: 5
action 2, numVisits=22, meanQ=3.500459, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.593848 0.826364 0.558371 0.875902 0.119386 0.618477 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7724, meanQ=8.386141, numObservations: 4
action 2, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29747 episodes
GETTING ACTION FROM:
action 1, numVisits=28280, meanQ=6.724939, numObservations: 4
action 2, numVisits=6727, meanQ=5.929593, numObservations: 5
action 0, numVisits=2462, meanQ=0.374066, numObservations: 1
action -1, numVisits=7, meanQ=-2.144257, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.593848 0.826364 0.558371 0.875902 0.119386 0.618477 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 491
Initial state: 0 0.606277 0.836449 0.600155 0.635122 0.611715 0.801622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54381 episodes
GETTING ACTION FROM:
action 2, numVisits=54374, meanQ=4.948791, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.606277 0.836449 0.600155 0.635122 0.611715 0.801622 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7525, meanQ=8.391295, numObservations: 4
action 1, numVisits=48, meanQ=7.498131, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 35540 episodes
GETTING ACTION FROM:
action 1, numVisits=82, meanQ=6.851467, numObservations: 3
action 3, numVisits=43022, meanQ=6.659621, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=9, meanQ=-1.890000, numObservations: 1
action -1, numVisits=2, meanQ=-8.949451, numObservations: 1
action: 1
Next state: 1 0.606277 0.836449 0.600155 0.635122 0.611715 0.801622 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 492
Initial state: 0 0.139503 0.148878 0.511974 0.871017 0.579504 0.819686 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51608 episodes
GETTING ACTION FROM:
action 2, numVisits=51355, meanQ=4.787821, numObservations: 3
action 3, numVisits=248, meanQ=4.351427, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.139503 0.148878 0.511974 0.871017 0.579504 0.819686 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 493
Initial state: 0 0.865663 0.359104 0.540872 0.853559 0.566139 0.803644 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54600 episodes
GETTING ACTION FROM:
action 3, numVisits=54592, meanQ=5.046039, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.865663 0.359104 0.540872 0.853559 0.566139 0.803644 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 494
Initial state: 0 0.565101 0.827031 0.769712 0.233075 0.521088 0.832753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54855 episodes
GETTING ACTION FROM:
action 2, numVisits=54804, meanQ=5.006939, numObservations: 5
action -1, numVisits=40, meanQ=3.954360, numObservations: 1
action 3, numVisits=8, meanQ=0.511250, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.565101 0.827031 0.769712 0.233075 0.521088 0.832753 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 495
Initial state: 0 0.532224 0.822075 0.590161 0.848074 0.87585 0.875121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51811 episodes
GETTING ACTION FROM:
action 1, numVisits=51803, meanQ=4.792153, numObservations: 5
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.532224 0.822075 0.590161 0.848074 0.87585 0.875121 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 496
Initial state: 0 0.574423 0.880419 0.566071 0.809799 0.959413 0.0910633 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50685 episodes
GETTING ACTION FROM:
action 3, numVisits=48866, meanQ=4.874374, numObservations: 4
action 0, numVisits=1807, meanQ=2.745777, numObservations: 1
action 1, numVisits=9, meanQ=0.001122, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.574423 0.880419 0.566071 0.809799 0.959413 0.0910633 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 497
Initial state: 0 0.423482 0.477865 0.632684 0.851171 0.595904 0.806462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31990 episodes
GETTING ACTION FROM:
action -1, numVisits=31985, meanQ=2.900381, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.423482 0.477865 0.632684 0.851171 0.595904 0.806462 w: 1
Observation: 0 0.444422 0 0.653185 0 0.543629 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31854, meanQ=4.969167, numObservations: 5
action 0, numVisits=91, meanQ=4.321556, numObservations: 1
action -1, numVisits=22, meanQ=3.593110, numObservations: 1
action 3, numVisits=11, meanQ=2.826364, numObservations: 4
action 2, numVisits=6, meanQ=1.015000, numObservations: 3
Sampled 54613 episodes
GETTING ACTION FROM:
action 1, numVisits=86466, meanQ=5.132026, numObservations: 5
action 0, numVisits=92, meanQ=4.314789, numObservations: 1
action -1, numVisits=22, meanQ=3.593110, numObservations: 1
action 3, numVisits=11, meanQ=2.826364, numObservations: 4
action 2, numVisits=6, meanQ=1.015000, numObservations: 3
action: 1
Next state: 0 0.423482 0.477865 0.632684 0.851171 0.595904 0.806462 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=10409, meanQ=8.506365, numObservations: 3
action 2, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 35734 episodes
GETTING ACTION FROM:
action 3, numVisits=46136, meanQ=6.372566, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=4, meanQ=-1.752500, numObservations: 1
action 0, numVisits=4, meanQ=-2.002475, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.423482 0.477865 0.632684 0.851171 0.595904 0.806462 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 498
Initial state: 0 0.59532 0.861498 0.377332 0.944044 0.611321 0.891747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54308 episodes
GETTING ACTION FROM:
action 1, numVisits=54204, meanQ=4.937698, numObservations: 4
action -1, numVisits=72, meanQ=4.131561, numObservations: 1
action 2, numVisits=29, meanQ=3.542076, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.59532 0.861498 0.377332 0.944044 0.611321 0.891747 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 499
Initial state: 0 0.535027 0.850206 0.631757 0.803786 0.235862 0.80305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54286 episodes
GETTING ACTION FROM:
action 3, numVisits=54270, meanQ=5.020624, numObservations: 5
action 0, numVisits=12, meanQ=2.805666, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.535027 0.850206 0.631757 0.803786 0.235862 0.80305 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1289, meanQ=7.900130, numObservations: 4
action 2, numVisits=21, meanQ=5.939048, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 26457 episodes
GETTING ACTION FROM:
action 1, numVisits=20603, meanQ=6.045253, numObservations: 4
action 2, numVisits=6184, meanQ=5.912384, numObservations: 5
action 0, numVisits=974, meanQ=0.178203, numObservations: 1
action -1, numVisits=8, meanQ=-2.001238, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.535027 0.850206 0.631757 0.803786 0.235862 0.80305 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 500
Initial state: 0 0.663676 0.878535 0.350426 0.199589 0.559291 0.800787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54870 episodes
GETTING ACTION FROM:
action 1, numVisits=54864, meanQ=4.972469, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.663676 0.878535 0.350426 0.199589 0.559291 0.800787 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
