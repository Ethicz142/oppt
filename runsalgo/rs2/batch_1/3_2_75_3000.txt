Run # 1
Initial state: 0 0.516877 0.841688 0.803219 0.728548 0.637059 0.810398 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162411 episodes
GETTING ACTION FROM:
action 3, numVisits=162384, meanQ=4.928712, numObservations: 4
action 0, numVisits=20, meanQ=3.174921, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.516877 0.841688 0.803219 0.728548 0.637059 0.810398 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.948391 0.623223 0.532948 0.861287 0.517055 0.85576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165962 episodes
GETTING ACTION FROM:
action 3, numVisits=165886, meanQ=5.015381, numObservations: 5
action 2, numVisits=63, meanQ=4.059302, numObservations: 4
action 1, numVisits=9, meanQ=1.776667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.948391 0.623223 0.532948 0.861287 0.517055 0.85576 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=754, meanQ=4.049824, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 24847 episodes
GETTING ACTION FROM:
action 3, numVisits=754, meanQ=4.049824, numObservations: 3
action 0, numVisits=24846, meanQ=-0.192549, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=3, meanQ=-130.714101, numObservations: 1
action: 3
Next state: 1 0.948391 0.623223 0.532948 0.861287 0.517055 0.85576 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 3
Initial state: 0 0.52659 0.824742 0.50901 0.765391 0.69454 0.849346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165018 episodes
GETTING ACTION FROM:
action 2, numVisits=165009, meanQ=5.027181, numObservations: 4
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.52659 0.824742 0.50901 0.765391 0.69454 0.849346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.670724 0.820492 0.517151 0.396428 0.618398 0.80913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165167 episodes
GETTING ACTION FROM:
action 3, numVisits=165062, meanQ=4.947176, numObservations: 5
action 0, numVisits=71, meanQ=4.120664, numObservations: 1
action -1, numVisits=32, meanQ=3.683841, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.670724 0.820492 0.517151 0.396428 0.618398 0.80913 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 5
Initial state: 0 0.65791 0.858939 0.792841 0.434198 0.653398 0.898374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165632 episodes
GETTING ACTION FROM:
action 1, numVisits=165422, meanQ=4.983124, numObservations: 4
action 0, numVisits=156, meanQ=4.431266, numObservations: 2
action -1, numVisits=50, meanQ=4.014803, numObservations: 1
action 2, numVisits=3, meanQ=0.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.65791 0.858939 0.792841 0.434198 0.653398 0.898374 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 6
Initial state: 0 0.514068 0.869119 0.576633 0.874115 0.937247 0.372694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166269 episodes
GETTING ACTION FROM:
action 3, numVisits=166091, meanQ=4.967537, numObservations: 4
action -1, numVisits=69, meanQ=4.140938, numObservations: 1
action 2, numVisits=52, meanQ=3.968465, numObservations: 3
action 0, numVisits=38, meanQ=3.826323, numObservations: 1
action 1, numVisits=19, meanQ=2.999495, numObservations: 5
action: 3
Next state: 2 0.514068 0.869119 0.576633 0.874115 0.937247 0.372694 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 7
Initial state: 0 0.55704 0.807439 0.228405 0.425696 0.576306 0.871866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166443 episodes
GETTING ACTION FROM:
action 1, numVisits=166368, meanQ=4.928690, numObservations: 4
action 0, numVisits=48, meanQ=3.897422, numObservations: 1
action -1, numVisits=17, meanQ=3.240761, numObservations: 1
action 2, numVisits=7, meanQ=2.285729, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 3
action: 1
Next state: 1 0.55704 0.807439 0.228405 0.425696 0.576306 0.871866 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 8
Initial state: 0 0.269076 0.0646214 0.553301 0.875932 0.577925 0.850787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166698 episodes
GETTING ACTION FROM:
action 3, numVisits=166664, meanQ=4.976298, numObservations: 3
action -1, numVisits=25, meanQ=3.571826, numObservations: 1
action 1, numVisits=6, meanQ=1.498333, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.269076 0.0646214 0.553301 0.875932 0.577925 0.850787 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 9
Initial state: 0 0.577154 0.88413 0.61197 0.813925 0.644927 0.0682834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167032 episodes
GETTING ACTION FROM:
action 1, numVisits=163421, meanQ=4.994004, numObservations: 4
action 3, numVisits=3580, meanQ=4.888377, numObservations: 4
action 0, numVisits=26, meanQ=3.612686, numObservations: 1
action 2, numVisits=3, meanQ=0.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.577154 0.88413 0.61197 0.813925 0.644927 0.0682834 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 10
Initial state: 0 0.530554 0.820443 0.65631 0.833347 0.198493 0.787704 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166829 episodes
GETTING ACTION FROM:
action 2, numVisits=166813, meanQ=5.156854, numObservations: 4
action 1, numVisits=9, meanQ=1.776667, numObservations: 3
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.530554 0.820443 0.65631 0.833347 0.198493 0.787704 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 11
Initial state: 0 0.542151 0.895098 0.560817 0.890759 0.472684 0.629884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166167 episodes
GETTING ACTION FROM:
action 1, numVisits=165738, meanQ=4.973891, numObservations: 4
action -1, numVisits=410, meanQ=3.005148, numObservations: 1
action 2, numVisits=16, meanQ=1.937500, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.542151 0.895098 0.560817 0.890759 0.472684 0.629884 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 12
Initial state: 0 0.677619 0.830299 0.877073 0.638166 0.561642 0.87177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167126 episodes
GETTING ACTION FROM:
action 1, numVisits=167101, meanQ=4.998671, numObservations: 4
action 0, numVisits=21, meanQ=3.475383, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.677619 0.830299 0.877073 0.638166 0.561642 0.87177 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 13
Initial state: 0 0.510294 0.879419 0.466182 0.312776 0.539601 0.860788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165104 episodes
GETTING ACTION FROM:
action 2, numVisits=165098, meanQ=4.990091, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.510294 0.879419 0.466182 0.312776 0.539601 0.860788 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22963, meanQ=8.400305, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 60380 episodes
GETTING ACTION FROM:
action 3, numVisits=47444, meanQ=6.952196, numObservations: 5
action 1, numVisits=35300, meanQ=5.889628, numObservations: 5
action -1, numVisits=599, meanQ=-1.220929, numObservations: 1
action 0, numVisits=3, meanQ=-5.300000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.510294 0.879419 0.466182 0.312776 0.539601 0.860788 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2199, meanQ=8.087689, numObservations: 4
action 3, numVisits=64, meanQ=6.675503, numObservations: 4
action -1, numVisits=4, meanQ=-2.502425, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-11.060460, numObservations: 1
Sampled 100699 episodes
GETTING ACTION FROM:
action 1, numVisits=15836, meanQ=6.275104, numObservations: 4
action 3, numVisits=87085, meanQ=5.441093, numObservations: 4
action -1, numVisits=45, meanQ=-2.044660, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-11.060460, numObservations: 1
action: 1
Next state: 1 0.510294 0.879419 0.466182 0.312776 0.539601 0.860788 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 14
Initial state: 0 0.627114 0.851195 0.646922 0.875589 0.552279 0.65484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166576 episodes
GETTING ACTION FROM:
action 1, numVisits=166510, meanQ=4.959886, numObservations: 3
action 0, numVisits=59, meanQ=4.070015, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.627114 0.851195 0.646922 0.875589 0.552279 0.65484 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 15
Initial state: 0 0.567864 0.897602 0.184046 0.998435 0.583214 0.873698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157407 episodes
GETTING ACTION FROM:
action 1, numVisits=157401, meanQ=4.807519, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.567864 0.897602 0.184046 0.998435 0.583214 0.873698 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 16
Initial state: 0 0.0357652 0.658931 0.647264 0.831187 0.596565 0.862195 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166780 episodes
GETTING ACTION FROM:
action 3, numVisits=166774, meanQ=4.963113, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.0357652 0.658931 0.647264 0.831187 0.596565 0.862195 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 17
Initial state: 0 0.695016 0.853929 0.643744 0.833238 0.484828 0.000699785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167261 episodes
GETTING ACTION FROM:
action 3, numVisits=167254, meanQ=5.184503, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.695016 0.853929 0.643744 0.833238 0.484828 0.000699785 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 18
Initial state: 0 0.352818 0.593019 0.566481 0.832288 0.642371 0.837428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166658 episodes
GETTING ACTION FROM:
action 1, numVisits=166649, meanQ=5.012929, numObservations: 4
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.352818 0.593019 0.566481 0.832288 0.642371 0.837428 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=27844, meanQ=8.291041, numObservations: 4
action 3, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 74327 episodes
GETTING ACTION FROM:
action 2, numVisits=85611, meanQ=6.774780, numObservations: 4
action 3, numVisits=13637, meanQ=6.046750, numObservations: 5
action -1, numVisits=2919, meanQ=0.237760, numObservations: 1
action 0, numVisits=9, meanQ=-2.112200, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.352818 0.593019 0.566481 0.832288 0.642371 0.837428 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 19
Initial state: 0 0.611943 0.887955 0.674508 0.874031 0.929109 0.0289379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96653 episodes
GETTING ACTION FROM:
action -1, numVisits=96648, meanQ=2.916301, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.611943 0.887955 0.674508 0.874031 0.929109 0.0289379 w: 1
Observation: 0 0.624265 0 0.637056 0 0.98838 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=96621, meanQ=4.962384, numObservations: 5
action 3, numVisits=19, meanQ=3.208953, numObservations: 3
action 2, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 163287 episodes
GETTING ACTION FROM:
action 1, numVisits=259898, meanQ=4.666143, numObservations: 5
action 3, numVisits=29, meanQ=3.136900, numObservations: 3
action 2, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.611943 0.887955 0.674508 0.874031 0.929109 0.0289379 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 20
Initial state: 0 0.530367 0.807734 0.682369 0.816014 0.398457 0.569083 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166394 episodes
GETTING ACTION FROM:
action 3, numVisits=166194, meanQ=4.969178, numObservations: 3
action 2, numVisits=112, meanQ=4.276788, numObservations: 4
action 0, numVisits=77, meanQ=4.175702, numObservations: 1
action 1, numVisits=9, meanQ=2.002244, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.530367 0.807734 0.682369 0.816014 0.398457 0.569083 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27361, meanQ=8.314390, numObservations: 4
action 2, numVisits=75, meanQ=7.578001, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 92406 episodes
GETTING ACTION FROM:
action 1, numVisits=118607, meanQ=6.550301, numObservations: 4
action 2, numVisits=178, meanQ=4.307796, numObservations: 3
action -1, numVisits=1054, meanQ=-0.408425, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=5, meanQ=-71.751887, numObservations: 1
action: 1
Next state: 0 0.530367 0.807734 0.682369 0.816014 0.398457 0.569083 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2142, meanQ=8.304913, numObservations: 3
action 2, numVisits=8, meanQ=7.498750, numObservations: 3
action -1, numVisits=1709, meanQ=6.905366, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 186550 episodes
GETTING ACTION FROM:
action 1, numVisits=2142, meanQ=8.304913, numObservations: 3
action 2, numVisits=182660, meanQ=6.375568, numObservations: 5
action -1, numVisits=5604, meanQ=1.009925, numObservations: 1
action 0, numVisits=4, meanQ=-2.002475, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.530367 0.807734 0.682369 0.816014 0.398457 0.569083 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 21
Initial state: 0 0.687658 0.872987 0.682411 0.895559 0.993847 0.805191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 103842 episodes
GETTING ACTION FROM:
action 0, numVisits=103820, meanQ=5.919622, numObservations: 3
action 3, numVisits=13, meanQ=0.922308, numObservations: 2
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.687658 0.872987 0.682411 0.895559 0.993847 0.805191 w: 1
Observation: 0 0 0.91247 0 0.936356 0 0.786104 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32858, meanQ=8.189003, numObservations: 5
action 2, numVisits=7, meanQ=5.568571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 168161 episodes
GETTING ACTION FROM:
action 1, numVisits=200931, meanQ=5.563242, numObservations: 5
action 2, numVisits=53, meanQ=4.610955, numObservations: 4
action 0, numVisits=42, meanQ=4.461223, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.687658 0.872987 0.682411 0.895559 0.993847 0.805191 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 22
Initial state: 0 0.694858 0.893693 0.0889488 0.622091 0.655642 0.860676 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159517 episodes
GETTING ACTION FROM:
action 1, numVisits=159460, meanQ=4.961639, numObservations: 3
action 0, numVisits=51, meanQ=3.951695, numObservations: 1
action 2, numVisits=3, meanQ=0.000033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.694858 0.893693 0.0889488 0.622091 0.655642 0.860676 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 23
Initial state: 0 0.726125 0.17736 0.677309 0.890691 0.632919 0.811468 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167022 episodes
GETTING ACTION FROM:
action 2, numVisits=164291, meanQ=5.047018, numObservations: 5
action 3, numVisits=2709, meanQ=4.763203, numObservations: 4
action 0, numVisits=19, meanQ=3.296617, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.726125 0.17736 0.677309 0.890691 0.632919 0.811468 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 24
Initial state: 0 0.0545011 0.205782 0.631764 0.814728 0.503029 0.877551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166274 episodes
GETTING ACTION FROM:
action 1, numVisits=166262, meanQ=4.979555, numObservations: 4
action 3, numVisits=7, meanQ=-0.014271, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0545011 0.205782 0.631764 0.814728 0.503029 0.877551 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27339, meanQ=8.315146, numObservations: 3
action 2, numVisits=12, meanQ=5.831675, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 65721 episodes
GETTING ACTION FROM:
action 3, numVisits=71645, meanQ=6.737442, numObservations: 3
action 2, numVisits=20785, meanQ=5.898302, numObservations: 4
action 0, numVisits=473, meanQ=-0.224212, numObservations: 1
action -1, numVisits=171, meanQ=-0.430270, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0545011 0.205782 0.631764 0.814728 0.503029 0.877551 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=2152, meanQ=8.374981, numObservations: 4
action -1, numVisits=707, meanQ=4.835454, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 139761 episodes
GETTING ACTION FROM:
action 2, numVisits=139576, meanQ=6.215443, numObservations: 4
action -1, numVisits=3030, meanQ=-0.181892, numObservations: 1
action 0, numVisits=14, meanQ=-1.929286, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.0545011 0.205782 0.631764 0.814728 0.503029 0.877551 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=149, meanQ=8.322819, numObservations: 3
action 2, numVisits=5, meanQ=5.000000, numObservations: 3
action -1, numVisits=414, meanQ=4.775693, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 187891 episodes
GETTING ACTION FROM:
action 3, numVisits=186586, meanQ=5.740794, numObservations: 4
action 2, numVisits=155, meanQ=4.696775, numObservations: 5
action -1, numVisits=1704, meanQ=-0.277727, numObservations: 1
action 0, numVisits=15, meanQ=-1.934000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0545011 0.205782 0.631764 0.814728 0.503029 0.877551 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 25
Initial state: 0 0.233693 0.732398 0.648493 0.867039 0.523751 0.824569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164754 episodes
GETTING ACTION FROM:
action 1, numVisits=164570, meanQ=4.978595, numObservations: 4
action -1, numVisits=138, meanQ=4.376088, numObservations: 1
action 0, numVisits=23, meanQ=3.400350, numObservations: 1
action 2, numVisits=22, meanQ=3.116823, numObservations: 4
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.233693 0.732398 0.648493 0.867039 0.523751 0.824569 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26248, meanQ=8.316688, numObservations: 5
action 3, numVisits=1129, meanQ=8.164808, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 29059 episodes
GETTING ACTION FROM:
action 2, numVisits=26392, meanQ=8.306107, numObservations: 5
action 3, numVisits=30022, meanQ=6.019718, numObservations: 3
action -1, numVisits=19, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=5, meanQ=-3.980000, numObservations: 1
action: 2
Next state: 0 0.233693 0.732398 0.648493 0.867039 0.523751 0.824569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=2015, meanQ=8.255746, numObservations: 3
action 3, numVisits=12, meanQ=6.332500, numObservations: 4
action -1, numVisits=2, meanQ=2.950000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 168568 episodes
GETTING ACTION FROM:
action 3, numVisits=158681, meanQ=6.147690, numObservations: 5
action 2, numVisits=11836, meanQ=6.005390, numObservations: 4
action -1, numVisits=53, meanQ=-1.645094, numObservations: 1
action 0, numVisits=28, meanQ=-1.964643, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.233693 0.732398 0.648493 0.867039 0.523751 0.824569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 26
Initial state: 0 0.789123 0.538946 0.671285 0.821062 0.565633 0.870678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 102953 episodes
GETTING ACTION FROM:
action 0, numVisits=102948, meanQ=5.907079, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.789123 0.538946 0.671285 0.821062 0.565633 0.870678 w: 1
Observation: 0 0 0.515001 0 0.900695 0 0.936121 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=30948, meanQ=8.273874, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 168138 episodes
GETTING ACTION FROM:
action 2, numVisits=199084, meanQ=5.550981, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.789123 0.538946 0.671285 0.821062 0.565633 0.870678 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 27
Initial state: 0 0.626041 0.8872 0.56816 0.814479 0.344657 0.563212 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165491 episodes
GETTING ACTION FROM:
action 1, numVisits=165414, meanQ=4.986427, numObservations: 4
action 0, numVisits=64, meanQ=4.117837, numObservations: 1
action 3, numVisits=5, meanQ=1.200000, numObservations: 4
action 2, numVisits=6, meanQ=1.166683, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.626041 0.8872 0.56816 0.814479 0.344657 0.563212 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 28
Initial state: 0 0.628853 0.85834 0.615245 0.893056 0.578584 0.556526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166439 episodes
GETTING ACTION FROM:
action 3, numVisits=166432, meanQ=4.909990, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.628853 0.85834 0.615245 0.893056 0.578584 0.556526 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 29
Initial state: 0 0.676039 0.879633 0.851888 0.581899 0.681237 0.833763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97123 episodes
GETTING ACTION FROM:
action 0, numVisits=97108, meanQ=2.969931, numObservations: 1
action 1, numVisits=11, meanQ=0.810000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.676039 0.879633 0.851888 0.581899 0.681237 0.833763 w: 1
Observation: 0 0 0.907701 0 0.574825 0 0.734442 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=97038, meanQ=4.984420, numObservations: 4
action 0, numVisits=33, meanQ=3.766910, numObservations: 1
action -1, numVisits=17, meanQ=3.237464, numObservations: 1
action 2, numVisits=9, meanQ=2.112244, numObservations: 3
action 1, numVisits=10, meanQ=1.798020, numObservations: 3
Sampled 167712 episodes
GETTING ACTION FROM:
action 3, numVisits=264749, meanQ=5.074096, numObservations: 4
action 0, numVisits=34, meanQ=3.712480, numObservations: 1
action -1, numVisits=17, meanQ=3.237464, numObservations: 1
action 2, numVisits=9, meanQ=2.112244, numObservations: 3
action 1, numVisits=10, meanQ=1.798020, numObservations: 3
action: 3
Next state: 1 0.676039 0.879633 0.851888 0.581899 0.681237 0.833763 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 30
Initial state: 0 0.629322 0.809873 0.516065 0.830179 0.153825 0.76264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166778 episodes
GETTING ACTION FROM:
action 2, numVisits=166762, meanQ=5.003853, numObservations: 5
action 1, numVisits=6, meanQ=2.003350, numObservations: 2
action 3, numVisits=6, meanQ=1.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.629322 0.809873 0.516065 0.830179 0.153825 0.76264 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 31
Initial state: 0 0.801863 0.990758 0.541479 0.839583 0.51534 0.829042 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165906 episodes
GETTING ACTION FROM:
action 3, numVisits=165858, meanQ=5.003995, numObservations: 5
action -1, numVisits=43, meanQ=3.960453, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.801863 0.990758 0.541479 0.839583 0.51534 0.829042 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 32
Initial state: 0 0.69431 0.85889 0.538003 0.820141 0.233665 0.491395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97952 episodes
GETTING ACTION FROM:
action -1, numVisits=97947, meanQ=2.976590, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.69431 0.85889 0.538003 0.820141 0.233665 0.491395 w: 1
Observation: 0 0.594329 0 0.541571 0 0.319174 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=97940, meanQ=5.015300, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 164850 episodes
GETTING ACTION FROM:
action 1, numVisits=262788, meanQ=4.892712, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 1
Next state: 1 0.69431 0.85889 0.538003 0.820141 0.233665 0.491395 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 33
Initial state: 0 0.56962 0.811294 0.64849 0.830598 0.711328 0.590265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162417 episodes
GETTING ACTION FROM:
action 1, numVisits=162332, meanQ=4.896283, numObservations: 4
action -1, numVisits=50, meanQ=3.878697, numObservations: 1
action 0, numVisits=32, meanQ=3.639249, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.56962 0.811294 0.64849 0.830598 0.711328 0.590265 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 34
Initial state: 0 0.576423 0.831386 0.549093 0.809671 0.0733676 0.516092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98215 episodes
GETTING ACTION FROM:
action -1, numVisits=98204, meanQ=2.936368, numObservations: 1
action 2, numVisits=7, meanQ=-0.428571, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.576423 0.831386 0.549093 0.809671 0.0733676 0.516092 w: 1
Observation: 0 0.498911 0 0.534399 0 0 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=98147, meanQ=4.999046, numObservations: 5
action -1, numVisits=52, meanQ=4.053162, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 167775 episodes
GETTING ACTION FROM:
action 1, numVisits=265921, meanQ=5.042435, numObservations: 5
action -1, numVisits=53, meanQ=4.025469, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.576423 0.831386 0.549093 0.809671 0.0733676 0.516092 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 35
Initial state: 0 0.461115 0.435297 0.517519 0.896237 0.577308 0.863152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98213 episodes
GETTING ACTION FROM:
action 0, numVisits=81765, meanQ=3.005846, numObservations: 1
action -1, numVisits=16445, meanQ=2.976680, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.461115 0.435297 0.517519 0.896237 0.577308 0.863152 w: 1
Observation: 0 0 0.419139 0 0.918294 0 0.892188 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=81666, meanQ=5.015140, numObservations: 5
action -1, numVisits=50, meanQ=4.074197, numObservations: 1
action 0, numVisits=44, meanQ=4.014424, numObservations: 1
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 167324 episodes
GETTING ACTION FROM:
action 3, numVisits=248974, meanQ=4.927824, numObservations: 5
action -1, numVisits=58, meanQ=3.998980, numObservations: 1
action 0, numVisits=49, meanQ=3.905684, numObservations: 1
action 2, numVisits=6, meanQ=-0.338333, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.461115 0.435297 0.517519 0.896237 0.577308 0.863152 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 36
Initial state: 0 0.575158 0.411381 0.623494 0.889728 0.610199 0.885147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166439 episodes
GETTING ACTION FROM:
action 1, numVisits=166373, meanQ=4.978279, numObservations: 4
action 0, numVisits=37, meanQ=3.849983, numObservations: 1
action -1, numVisits=25, meanQ=3.493185, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.575158 0.411381 0.623494 0.889728 0.610199 0.885147 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.443181 0.133379 0.587633 0.838685 0.653133 0.863066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158148 episodes
GETTING ACTION FROM:
action 2, numVisits=158001, meanQ=4.831595, numObservations: 5
action 0, numVisits=142, meanQ=4.261509, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.443181 0.133379 0.587633 0.838685 0.653133 0.863066 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 38
Initial state: 0 0.24884 0.699221 0.691621 0.893699 0.50359 0.866031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166587 episodes
GETTING ACTION FROM:
action 1, numVisits=166485, meanQ=4.993455, numObservations: 5
action 0, numVisits=95, meanQ=4.249508, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.24884 0.699221 0.691621 0.893699 0.50359 0.866031 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 39
Initial state: 0 0.144093 0.942764 0.540009 0.820147 0.660725 0.80325 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166028 episodes
GETTING ACTION FROM:
action 2, numVisits=166021, meanQ=4.995344, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.144093 0.942764 0.540009 0.820147 0.660725 0.80325 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 40
Initial state: 0 0.320406 0.120915 0.575652 0.843273 0.608218 0.802071 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158172 episodes
GETTING ACTION FROM:
action 3, numVisits=158109, meanQ=4.874088, numObservations: 4
action -1, numVisits=59, meanQ=3.966693, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.320406 0.120915 0.575652 0.843273 0.608218 0.802071 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 41
Initial state: 0 0.635391 0.834077 0.773462 0.426817 0.627865 0.807394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166033 episodes
GETTING ACTION FROM:
action 1, numVisits=165894, meanQ=4.952638, numObservations: 4
action 0, numVisits=102, meanQ=4.272287, numObservations: 1
action -1, numVisits=27, meanQ=3.567195, numObservations: 1
action 3, numVisits=8, meanQ=1.375025, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.635391 0.834077 0.773462 0.426817 0.627865 0.807394 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 42
Initial state: 0 0.50067 0.897247 0.710956 0.837564 0.537479 0.800603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 151873 episodes
GETTING ACTION FROM:
action 2, numVisits=151687, meanQ=4.724774, numObservations: 4
action 0, numVisits=175, meanQ=4.212139, numObservations: 1
action 1, numVisits=7, meanQ=0.428571, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.50067 0.897247 0.710956 0.837564 0.537479 0.800603 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 43
Initial state: 0 0.65132 0.833148 0.628164 0.82017 0.832522 0.0755302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162289 episodes
GETTING ACTION FROM:
action 1, numVisits=162271, meanQ=4.905378, numObservations: 4
action 3, numVisits=13, meanQ=0.454623, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.65132 0.833148 0.628164 0.82017 0.832522 0.0755302 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 44
Initial state: 0 0.605125 0.821045 0.276831 0.949009 0.645339 0.895258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165426 episodes
GETTING ACTION FROM:
action 3, numVisits=165411, meanQ=4.907041, numObservations: 4
action 1, numVisits=10, meanQ=1.693010, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.605125 0.821045 0.276831 0.949009 0.645339 0.895258 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 45
Initial state: 0 0.579604 0.816277 0.403495 0.553898 0.687148 0.859904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164828 episodes
GETTING ACTION FROM:
action 2, numVisits=164666, meanQ=4.935507, numObservations: 5
action 3, numVisits=72, meanQ=4.028889, numObservations: 3
action 0, numVisits=42, meanQ=3.855720, numObservations: 1
action -1, numVisits=29, meanQ=3.629112, numObservations: 1
action 1, numVisits=19, meanQ=3.104737, numObservations: 3
action: 2
Next state: 0 0.579604 0.816277 0.403495 0.553898 0.687148 0.859904 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=18062, meanQ=8.553915, numObservations: 3
action 3, numVisits=840, meanQ=8.380792, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 64674 episodes
GETTING ACTION FROM:
action 1, numVisits=43952, meanQ=7.087792, numObservations: 4
action 3, numVisits=37364, meanQ=6.019429, numObservations: 5
action 0, numVisits=2248, meanQ=-0.371658, numObservations: 1
action -1, numVisits=14, meanQ=-2.072129, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.579604 0.816277 0.403495 0.553898 0.687148 0.859904 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 46
Initial state: 0 0.637782 0.752574 0.55764 0.843228 0.623776 0.888466 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164459 episodes
GETTING ACTION FROM:
action 2, numVisits=164453, meanQ=4.946921, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.637782 0.752574 0.55764 0.843228 0.623776 0.888466 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 47
Initial state: 0 0.697492 0.845702 0.611219 0.816839 0.306442 0.720433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167224 episodes
GETTING ACTION FROM:
action 2, numVisits=167037, meanQ=5.000559, numObservations: 5
action 1, numVisits=153, meanQ=4.271885, numObservations: 4
action -1, numVisits=23, meanQ=3.564241, numObservations: 1
action 3, numVisits=9, meanQ=2.210000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.697492 0.845702 0.611219 0.816839 0.306442 0.720433 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 48
Initial state: 0 0.185301 0.132792 0.582636 0.840626 0.527468 0.81559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159715 episodes
GETTING ACTION FROM:
action 3, numVisits=159628, meanQ=4.939210, numObservations: 4
action 0, numVisits=82, meanQ=4.185249, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.185301 0.132792 0.582636 0.840626 0.527468 0.81559 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=11576, meanQ=3.666617, numObservations: 1
action 0, numVisits=68, meanQ=2.976015, numObservations: 1
action 1, numVisits=5, meanQ=-0.201980, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 183969 episodes
GETTING ACTION FROM:
action 3, numVisits=180463, meanQ=5.129085, numObservations: 4
action -1, numVisits=15060, meanQ=2.668280, numObservations: 1
action 0, numVisits=89, meanQ=2.029204, numObservations: 1
action 1, numVisits=5, meanQ=-0.201980, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 3
Next state: 1 0.185301 0.132792 0.582636 0.840626 0.527468 0.81559 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 49
Initial state: 0 0.754402 0.463509 0.524382 0.888342 0.516353 0.887356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165752 episodes
GETTING ACTION FROM:
action 3, numVisits=165745, meanQ=4.978573, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.754402 0.463509 0.524382 0.888342 0.516353 0.887356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10846, meanQ=4.916006, numObservations: 5
action 2, numVisits=1401, meanQ=4.781040, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 207084 episodes
GETTING ACTION FROM:
action 1, numVisits=217896, meanQ=6.073865, numObservations: 5
action 2, numVisits=1435, meanQ=4.808018, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.754402 0.463509 0.524382 0.888342 0.516353 0.887356 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 50
Initial state: 0 0.772547 0.691528 0.650553 0.858494 0.667877 0.824238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159161 episodes
GETTING ACTION FROM:
action 3, numVisits=149593, meanQ=5.007196, numObservations: 5
action 0, numVisits=9319, meanQ=2.810186, numObservations: 1
action -1, numVisits=247, meanQ=2.486734, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.772547 0.691528 0.650553 0.858494 0.667877 0.824238 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 51
Initial state: 0 0.355095 0.178994 0.652487 0.861931 0.628555 0.887005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167135 episodes
GETTING ACTION FROM:
action 2, numVisits=167066, meanQ=5.011253, numObservations: 5
action -1, numVisits=65, meanQ=4.161020, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.355095 0.178994 0.652487 0.861931 0.628555 0.887005 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 52
Initial state: 0 0.53185 0.874453 0.0849813 0.453253 0.630828 0.899885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 101001 episodes
GETTING ACTION FROM:
action 0, numVisits=100989, meanQ=5.752137, numObservations: 3
action 3, numVisits=6, meanQ=0.166667, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.53185 0.874453 0.0849813 0.453253 0.630828 0.899885 w: 1
Observation: 0 0 0.958652 0 0.374772 0 0.854164 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=29334, meanQ=8.318579, numObservations: 4
action 1, numVisits=29, meanQ=6.585176, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 169310 episodes
GETTING ACTION FROM:
action 3, numVisits=198535, meanQ=5.624456, numObservations: 4
action 1, numVisits=136, meanQ=4.954488, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.53185 0.874453 0.0849813 0.453253 0.630828 0.899885 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 53
Initial state: 0 0.750265 0.598474 0.565281 0.801774 0.540415 0.872319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165934 episodes
GETTING ACTION FROM:
action 1, numVisits=165927, meanQ=4.961276, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.750265 0.598474 0.565281 0.801774 0.540415 0.872319 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 54
Initial state: 0 0.670403 0.883651 0.536958 0.881792 0.866733 0.111169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157480 episodes
GETTING ACTION FROM:
action 1, numVisits=157414, meanQ=4.775863, numObservations: 4
action 2, numVisits=49, meanQ=3.713065, numObservations: 4
action 3, numVisits=13, meanQ=2.069238, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.670403 0.883651 0.536958 0.881792 0.866733 0.111169 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 55
Initial state: 0 0.634725 0.853314 0.852744 0.734052 0.517668 0.812663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165292 episodes
GETTING ACTION FROM:
action 3, numVisits=165282, meanQ=4.940681, numObservations: 3
action 2, numVisits=5, meanQ=1.198020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.634725 0.853314 0.852744 0.734052 0.517668 0.812663 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 56
Initial state: 0 0.122034 0.775293 0.517372 0.897679 0.601613 0.831426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98096 episodes
GETTING ACTION FROM:
action -1, numVisits=98091, meanQ=2.978398, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.122034 0.775293 0.517372 0.897679 0.601613 0.831426 w: 1
Observation: 0 0.184121 0 0.446065 0 0.700462 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=98042, meanQ=4.996623, numObservations: 4
action -1, numVisits=42, meanQ=3.966125, numObservations: 1
action 1, numVisits=3, meanQ=-2.966667, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 168454 episodes
GETTING ACTION FROM:
action 3, numVisits=266495, meanQ=5.290569, numObservations: 4
action -1, numVisits=43, meanQ=3.931799, numObservations: 1
action 1, numVisits=3, meanQ=-2.966667, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.122034 0.775293 0.517372 0.897679 0.601613 0.831426 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=19895, meanQ=5.902287, numObservations: 4
action 1, numVisits=14, meanQ=3.997864, numObservations: 3
action 2, numVisits=11, meanQ=3.725464, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 199239 episodes
GETTING ACTION FROM:
action 2, numVisits=148702, meanQ=5.946861, numObservations: 5
action 3, numVisits=70438, meanQ=5.528793, numObservations: 5
action 1, numVisits=17, meanQ=3.704124, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.122034 0.775293 0.517372 0.897679 0.601613 0.831426 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 57
Initial state: 0 0.137389 0.0721951 0.624677 0.875384 0.680282 0.820398 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166067 episodes
GETTING ACTION FROM:
action 1, numVisits=166036, meanQ=5.161280, numObservations: 4
action 0, numVisits=25, meanQ=3.743620, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.137389 0.0721951 0.624677 0.875384 0.680282 0.820398 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=19240, meanQ=8.512007, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 59773 episodes
GETTING ACTION FROM:
action 3, numVisits=59529, meanQ=6.986452, numObservations: 3
action 2, numVisits=18062, meanQ=5.985015, numObservations: 4
action -1, numVisits=1424, meanQ=-0.441975, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-196.141683, numObservations: 1
action: 3
Next state: 1 0.137389 0.0721951 0.624677 0.875384 0.680282 0.820398 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 58
Initial state: 0 0.560276 0.899693 0.694476 0.860855 0.793515 0.59669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165746 episodes
GETTING ACTION FROM:
action 2, numVisits=165540, meanQ=4.956847, numObservations: 4
action 0, numVisits=202, meanQ=4.470985, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.560276 0.899693 0.694476 0.860855 0.793515 0.59669 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 59
Initial state: 0 0.580373 0.87196 0.401454 0.0185759 0.616017 0.890285 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166724 episodes
GETTING ACTION FROM:
action 3, numVisits=166686, meanQ=5.042609, numObservations: 5
action -1, numVisits=22, meanQ=3.465051, numObservations: 1
action 1, numVisits=13, meanQ=2.846162, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.580373 0.87196 0.401454 0.0185759 0.616017 0.890285 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 60
Initial state: 0 0.544895 0.8635 0.668318 0.837298 0.97169 0.79006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165307 episodes
GETTING ACTION FROM:
action 3, numVisits=165160, meanQ=4.962833, numObservations: 5
action 0, numVisits=112, meanQ=4.298099, numObservations: 1
action 1, numVisits=27, meanQ=3.370000, numObservations: 2
action 2, numVisits=6, meanQ=1.333333, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.544895 0.8635 0.668318 0.837298 0.97169 0.79006 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23071, meanQ=8.352620, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 38160 episodes
GETTING ACTION FROM:
action 2, numVisits=61224, meanQ=6.697813, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=4, meanQ=-1.752500, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=4, meanQ=-6.707964, numObservations: 1
action: 2
Next state: 1 0.544895 0.8635 0.668318 0.837298 0.97169 0.79006 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 61
Initial state: 0 0.549587 0.891913 0.641553 0.893532 0.755986 0.0175359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165665 episodes
GETTING ACTION FROM:
action 2, numVisits=165656, meanQ=4.938199, numObservations: 4
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.549587 0.891913 0.641553 0.893532 0.755986 0.0175359 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 62
Initial state: 0 0.571821 0.877703 0.58493 0.804496 0.30472 0.197317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166565 episodes
GETTING ACTION FROM:
action 3, numVisits=166471, meanQ=4.973357, numObservations: 4
action 0, numVisits=44, meanQ=3.941542, numObservations: 1
action -1, numVisits=36, meanQ=3.780417, numObservations: 1
action 2, numVisits=13, meanQ=2.455392, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.571821 0.877703 0.58493 0.804496 0.30472 0.197317 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=21891, meanQ=8.318398, numObservations: 4
action 2, numVisits=5482, meanQ=8.263568, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 38292 episodes
GETTING ACTION FROM:
action 1, numVisits=53492, meanQ=7.085858, numObservations: 4
action 2, numVisits=11475, meanQ=6.832999, numObservations: 3
action 0, numVisits=652, meanQ=0.172822, numObservations: 1
action -1, numVisits=48, meanQ=-0.865625, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.571821 0.877703 0.58493 0.804496 0.30472 0.197317 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 63
Initial state: 0 0.603925 0.876503 0.546868 0.842021 0.49692 0.923492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164326 episodes
GETTING ACTION FROM:
action 3, numVisits=162983, meanQ=5.013859, numObservations: 4
action 0, numVisits=1336, meanQ=1.220064, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=2, meanQ=-5.489950, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 3
Next state: 0 0.603925 0.876503 0.546868 0.842021 0.49692 0.923492 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11820, meanQ=5.428836, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 186824 episodes
GETTING ACTION FROM:
action 3, numVisits=198644, meanQ=5.183419, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.603925 0.876503 0.546868 0.842021 0.49692 0.923492 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 64
Initial state: 0 0.544734 0.857917 0.473064 0.335356 0.545058 0.801903 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163392 episodes
GETTING ACTION FROM:
action 2, numVisits=163357, meanQ=4.909274, numObservations: 5
action -1, numVisits=25, meanQ=3.428049, numObservations: 1
action 3, numVisits=6, meanQ=1.498333, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.544734 0.857917 0.473064 0.335356 0.545058 0.801903 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8228, meanQ=7.782364, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 73860 episodes
GETTING ACTION FROM:
action 3, numVisits=50621, meanQ=6.213610, numObservations: 4
action 1, numVisits=26319, meanQ=6.074691, numObservations: 5
action -1, numVisits=5143, meanQ=0.453344, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=8, meanQ=-1.876250, numObservations: 1
action: 3
Next state: 1 0.544734 0.857917 0.473064 0.335356 0.545058 0.801903 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 65
Initial state: 0 0.23488 0.682558 0.653382 0.891023 0.579407 0.892747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156427 episodes
GETTING ACTION FROM:
action 3, numVisits=152828, meanQ=4.810562, numObservations: 4
action -1, numVisits=3595, meanQ=2.951449, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.23488 0.682558 0.653382 0.891023 0.579407 0.892747 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 66
Initial state: 0 0.678493 0.888815 0.145075 0.982025 0.546172 0.835912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165041 episodes
GETTING ACTION FROM:
action 1, numVisits=164964, meanQ=4.917448, numObservations: 5
action -1, numVisits=67, meanQ=4.072693, numObservations: 1
action 2, numVisits=7, meanQ=1.428571, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.678493 0.888815 0.145075 0.982025 0.546172 0.835912 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 67
Initial state: 0 0.619684 0.888409 0.755867 0.0673441 0.597073 0.865558 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97675 episodes
GETTING ACTION FROM:
action 0, numVisits=97668, meanQ=2.954831, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.619684 0.888409 0.755867 0.0673441 0.597073 0.865558 w: 1
Observation: 0 0 0.981781 0 0.0220704 0 0.850504 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=97646, meanQ=5.004606, numObservations: 5
action -1, numVisits=15, meanQ=3.237312, numObservations: 1
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 167199 episodes
GETTING ACTION FROM:
action 2, numVisits=264844, meanQ=5.150602, numObservations: 5
action -1, numVisits=16, meanQ=3.267529, numObservations: 1
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.619684 0.888409 0.755867 0.0673441 0.597073 0.865558 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 68
Initial state: 0 0.643423 0.852019 0.184116 0.254312 0.596972 0.893491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98327 episodes
GETTING ACTION FROM:
action -1, numVisits=98322, meanQ=3.030020, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.643423 0.852019 0.184116 0.254312 0.596972 0.893491 w: 1
Observation: 0 0.55925 0 0.110928 0 0.631224 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=98276, meanQ=5.029517, numObservations: 3
action -1, numVisits=36, meanQ=3.838593, numObservations: 1
action 1, numVisits=6, meanQ=0.650017, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 168192 episodes
GETTING ACTION FROM:
action 3, numVisits=266467, meanQ=4.996812, numObservations: 3
action -1, numVisits=37, meanQ=3.773796, numObservations: 1
action 1, numVisits=6, meanQ=0.650017, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.643423 0.852019 0.184116 0.254312 0.596972 0.893491 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 69
Initial state: 0 0.322524 0.663516 0.693824 0.858069 0.620584 0.810152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97325 episodes
GETTING ACTION FROM:
action -1, numVisits=97299, meanQ=2.974323, numObservations: 1
action 1, numVisits=22, meanQ=1.499100, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.322524 0.663516 0.693824 0.858069 0.620584 0.810152 w: 1
Observation: 0 0.241389 0 0.733872 0 0.565803 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=97292, meanQ=5.023820, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 166448 episodes
GETTING ACTION FROM:
action 2, numVisits=263739, meanQ=5.066478, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.322524 0.663516 0.693824 0.858069 0.620584 0.810152 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 70
Initial state: 0 0.558475 0.878391 0.674471 0.845611 0.864513 0.435733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105055 episodes
GETTING ACTION FROM:
action 0, numVisits=99748, meanQ=5.938375, numObservations: 3
action 2, numVisits=5303, meanQ=4.764872, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.558475 0.878391 0.674471 0.845611 0.864513 0.435733 w: 1
Observation: 0 0 0.869454 0 0.918624 0 0.417952 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=35896, meanQ=7.906862, numObservations: 4
action 3, numVisits=6, meanQ=4.996667, numObservations: 3
action 2, numVisits=5, meanQ=4.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 169441 episodes
GETTING ACTION FROM:
action 1, numVisits=205248, meanQ=5.714456, numObservations: 4
action 2, numVisits=53, meanQ=4.682645, numObservations: 4
action -1, numVisits=28, meanQ=4.357479, numObservations: 1
action 3, numVisits=19, meanQ=3.622116, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.558475 0.878391 0.674471 0.845611 0.864513 0.435733 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 71
Initial state: 0 0.666921 0.834634 0.6071 0.396963 0.567659 0.889046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166414 episodes
GETTING ACTION FROM:
action 2, numVisits=166359, meanQ=4.957995, numObservations: 4
action 3, numVisits=50, meanQ=3.961602, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.666921 0.834634 0.6071 0.396963 0.567659 0.889046 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 72
Initial state: 0 0.480512 0.345178 0.578481 0.832969 0.510848 0.825082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166618 episodes
GETTING ACTION FROM:
action 2, numVisits=166568, meanQ=5.028862, numObservations: 5
action 0, numVisits=46, meanQ=4.005814, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.480512 0.345178 0.578481 0.832969 0.510848 0.825082 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 73
Initial state: 0 0.67023 0.00328018 0.638712 0.859315 0.57186 0.826391 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165907 episodes
GETTING ACTION FROM:
action 2, numVisits=165888, meanQ=4.966791, numObservations: 4
action 0, numVisits=15, meanQ=3.156373, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.67023 0.00328018 0.638712 0.859315 0.57186 0.826391 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 74
Initial state: 0 0.564329 0.876192 0.685683 0.857472 0.121225 0.338881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166215 episodes
GETTING ACTION FROM:
action 2, numVisits=166119, meanQ=4.933610, numObservations: 4
action 0, numVisits=58, meanQ=4.039713, numObservations: 1
action -1, numVisits=32, meanQ=3.661983, numObservations: 1
action 3, numVisits=5, meanQ=1.198020, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.564329 0.876192 0.685683 0.857472 0.121225 0.338881 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 75
Initial state: 0 0.398996 0.926986 0.526967 0.854222 0.532147 0.888972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95258 episodes
GETTING ACTION FROM:
action -1, numVisits=95243, meanQ=2.913247, numObservations: 1
action 1, numVisits=11, meanQ=0.545455, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.398996 0.926986 0.526967 0.854222 0.532147 0.888972 w: 1
Observation: 0 0.458369 0 0.492327 0 0.583123 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=95233, meanQ=4.975943, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 159925 episodes
GETTING ACTION FROM:
action 1, numVisits=255151, meanQ=5.075973, numObservations: 5
action 2, numVisits=8, meanQ=1.623763, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.398996 0.926986 0.526967 0.854222 0.532147 0.888972 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 76
Initial state: 0 0.575579 0.86101 0.693247 0.8805 0.0498124 0.53288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166572 episodes
GETTING ACTION FROM:
action 2, numVisits=166537, meanQ=4.940350, numObservations: 4
action 0, numVisits=31, meanQ=3.703188, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.575579 0.86101 0.693247 0.8805 0.0498124 0.53288 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 77
Initial state: 0 0.693686 0.879861 0.846419 0.776725 0.61984 0.891465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166412 episodes
GETTING ACTION FROM:
action 3, numVisits=166352, meanQ=5.039712, numObservations: 4
action 2, numVisits=32, meanQ=3.738441, numObservations: 4
action -1, numVisits=15, meanQ=3.062050, numObservations: 1
action 1, numVisits=11, meanQ=2.826364, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.693686 0.879861 0.846419 0.776725 0.61984 0.891465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 78
Initial state: 0 0.697587 0.876081 0.467257 0.954414 0.64944 0.895147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166371 episodes
GETTING ACTION FROM:
action 3, numVisits=166297, meanQ=4.948332, numObservations: 5
action -1, numVisits=46, meanQ=3.906309, numObservations: 1
action 0, numVisits=21, meanQ=3.442546, numObservations: 1
action 1, numVisits=6, meanQ=1.333333, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.697587 0.876081 0.467257 0.954414 0.64944 0.895147 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 79
Initial state: 0 0.542941 0.877531 0.6422 0.850886 0.025729 0.243233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167119 episodes
GETTING ACTION FROM:
action 1, numVisits=167047, meanQ=4.995721, numObservations: 5
action 0, numVisits=50, meanQ=4.009580, numObservations: 1
action 3, numVisits=19, meanQ=2.632111, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.542941 0.877531 0.6422 0.850886 0.025729 0.243233 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 80
Initial state: 0 0.416965 0.708119 0.565153 0.830583 0.55962 0.851851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167005 episodes
GETTING ACTION FROM:
action 1, numVisits=166963, meanQ=5.034869, numObservations: 5
action -1, numVisits=38, meanQ=3.905205, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.416965 0.708119 0.565153 0.830583 0.55962 0.851851 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=10889, meanQ=8.534379, numObservations: 3
action 2, numVisits=8295, meanQ=8.521353, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 73021 episodes
GETTING ACTION FROM:
action 3, numVisits=60534, meanQ=6.654036, numObservations: 4
action 2, numVisits=31275, meanQ=6.441337, numObservations: 4
action 0, numVisits=389, meanQ=-0.179524, numObservations: 1
action -1, numVisits=9, meanQ=-2.112200, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.416965 0.708119 0.565153 0.830583 0.55962 0.851851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 81
Initial state: 0 0.536633 0.80268 0.795163 0.409136 0.64657 0.817128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165891 episodes
GETTING ACTION FROM:
action 1, numVisits=164662, meanQ=4.956537, numObservations: 5
action 0, numVisits=1144, meanQ=2.614433, numObservations: 1
action 3, numVisits=76, meanQ=2.073162, numObservations: 4
action 2, numVisits=7, meanQ=0.570014, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.536633 0.80268 0.795163 0.409136 0.64657 0.817128 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 82
Initial state: 0 0.622201 0.800131 0.283258 0.472934 0.652007 0.870041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166181 episodes
GETTING ACTION FROM:
action 3, numVisits=166175, meanQ=4.942813, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.622201 0.800131 0.283258 0.472934 0.652007 0.870041 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11988, meanQ=4.650585, numObservations: 5
action 0, numVisits=253, meanQ=4.282836, numObservations: 1
action -1, numVisits=21, meanQ=3.289989, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 201699 episodes
GETTING ACTION FROM:
action 2, numVisits=213683, meanQ=5.854536, numObservations: 5
action 0, numVisits=256, meanQ=4.232026, numObservations: 1
action -1, numVisits=22, meanQ=3.049535, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.622201 0.800131 0.283258 0.472934 0.652007 0.870041 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=3947, meanQ=8.281139, numObservations: 4
action 3, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 123206 episodes
GETTING ACTION FROM:
action 1, numVisits=123009, meanQ=6.513564, numObservations: 4
action 3, numVisits=8, meanQ=2.498750, numObservations: 2
action 0, numVisits=2958, meanQ=-1.566592, numObservations: 2
action -1, numVisits=1183, meanQ=-1.646019, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.622201 0.800131 0.283258 0.472934 0.652007 0.870041 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 83
Initial state: 0 0.52911 0.826167 0.293516 0.631949 0.698488 0.829397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164847 episodes
GETTING ACTION FROM:
action 3, numVisits=164811, meanQ=4.961533, numObservations: 4
action -1, numVisits=32, meanQ=3.684614, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.52911 0.826167 0.293516 0.631949 0.698488 0.829397 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 84
Initial state: 0 0.543286 0.832921 0.613631 0.852353 0.390903 0.593755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 112349 episodes
GETTING ACTION FROM:
action 1, numVisits=41878, meanQ=5.017967, numObservations: 5
action 0, numVisits=70447, meanQ=2.869497, numObservations: 1
action 3, numVisits=21, meanQ=1.280952, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.543286 0.832921 0.613631 0.852353 0.390903 0.593755 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 85
Initial state: 0 0.646497 0.821438 0.580491 0.801898 0.141563 0.480581 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165846 episodes
GETTING ACTION FROM:
action 3, numVisits=165802, meanQ=4.978829, numObservations: 4
action 0, numVisits=35, meanQ=3.815211, numObservations: 1
action 2, numVisits=6, meanQ=1.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.646497 0.821438 0.580491 0.801898 0.141563 0.480581 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=18896, meanQ=8.540963, numObservations: 3
action 2, numVisits=18, meanQ=6.887783, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46288 episodes
GETTING ACTION FROM:
action 1, numVisits=36660, meanQ=7.229912, numObservations: 4
action 2, numVisits=26126, meanQ=6.188932, numObservations: 5
action -1, numVisits=2404, meanQ=-0.317625, numObservations: 1
action 0, numVisits=14, meanQ=-2.072129, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.646497 0.821438 0.580491 0.801898 0.141563 0.480581 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 86
Initial state: 0 0.554214 0.861115 0.248272 0.481774 0.583423 0.859044 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168480 episodes
GETTING ACTION FROM:
action 1, numVisits=168315, meanQ=5.068734, numObservations: 4
action 3, numVisits=160, meanQ=4.524493, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.554214 0.861115 0.248272 0.481774 0.583423 0.859044 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 87
Initial state: 0 0.526243 0.883193 0.506419 0.889346 0.973278 0.292084 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 102322 episodes
GETTING ACTION FROM:
action 0, numVisits=102316, meanQ=5.157107, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.526243 0.883193 0.506419 0.889346 0.973278 0.292084 w: 1
Observation: 0 0 0.797942 0 0.844045 0 0.331502 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=39910, meanQ=6.294743, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 168199 episodes
GETTING ACTION FROM:
action 1, numVisits=208109, meanQ=5.134449, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.526243 0.883193 0.506419 0.889346 0.973278 0.292084 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 88
Initial state: 0 0.526397 0.808937 0.652199 0.828525 0.706231 0.061504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166341 episodes
GETTING ACTION FROM:
action 3, numVisits=166335, meanQ=4.967242, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.526397 0.808937 0.652199 0.828525 0.706231 0.061504 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 89
Initial state: 0 0.320388 0.0508768 0.636657 0.812747 0.636516 0.862603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166473 episodes
GETTING ACTION FROM:
action 2, numVisits=166381, meanQ=4.931917, numObservations: 4
action 0, numVisits=87, meanQ=4.196200, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.320388 0.0508768 0.636657 0.812747 0.636516 0.862603 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 90
Initial state: 0 0.657356 0.801805 0.843089 0.482956 0.675799 0.830183 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166347 episodes
GETTING ACTION FROM:
action 1, numVisits=166338, meanQ=4.937399, numObservations: 3
action 2, numVisits=3, meanQ=0.000033, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.657356 0.801805 0.843089 0.482956 0.675799 0.830183 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 91
Initial state: 0 0.931576 0.703953 0.661827 0.878005 0.580817 0.899789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165523 episodes
GETTING ACTION FROM:
action 2, numVisits=165509, meanQ=4.987129, numObservations: 5
action 1, numVisits=9, meanQ=0.888889, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.931576 0.703953 0.661827 0.878005 0.580817 0.899789 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 92
Initial state: 0 0.604141 0.816162 0.772822 0.951769 0.543218 0.800819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166419 episodes
GETTING ACTION FROM:
action 1, numVisits=166387, meanQ=4.954393, numObservations: 3
action -1, numVisits=23, meanQ=3.475021, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=3, meanQ=0.663333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.604141 0.816162 0.772822 0.951769 0.543218 0.800819 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 93
Initial state: 0 0.528361 0.866131 0.675513 0.835514 0.435343 0.526714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97627 episodes
GETTING ACTION FROM:
action -1, numVisits=97614, meanQ=2.947421, numObservations: 1
action 2, numVisits=9, meanQ=0.111111, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.528361 0.866131 0.675513 0.835514 0.435343 0.526714 w: 1
Observation: 0 0.506326 0 0.771388 0 0.500388 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=97605, meanQ=5.003851, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 165916 episodes
GETTING ACTION FROM:
action 2, numVisits=263503, meanQ=4.836432, numObservations: 5
action 3, numVisits=15, meanQ=1.933333, numObservations: 3
action 1, numVisits=7, meanQ=1.428571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.528361 0.866131 0.675513 0.835514 0.435343 0.526714 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 94
Initial state: 0 0.595909 0.849248 0.499691 0.101873 0.691673 0.868569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165773 episodes
GETTING ACTION FROM:
action 2, numVisits=165636, meanQ=4.924925, numObservations: 4
action -1, numVisits=77, meanQ=4.135211, numObservations: 1
action 0, numVisits=57, meanQ=4.008082, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.595909 0.849248 0.499691 0.101873 0.691673 0.868569 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=23460, meanQ=8.399118, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 98034 episodes
GETTING ACTION FROM:
action 1, numVisits=120927, meanQ=6.576281, numObservations: 3
action 3, numVisits=28, meanQ=4.285357, numObservations: 4
action 0, numVisits=526, meanQ=-0.307546, numObservations: 1
action -1, numVisits=17, meanQ=-2.059400, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.595909 0.849248 0.499691 0.101873 0.691673 0.868569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 95
Initial state: 0 0.217101 0.523145 0.567516 0.815925 0.62016 0.842979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158504 episodes
GETTING ACTION FROM:
action 2, numVisits=158462, meanQ=4.834413, numObservations: 4
action -1, numVisits=27, meanQ=3.457250, numObservations: 1
action 1, numVisits=12, meanQ=2.833350, numObservations: 4
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.217101 0.523145 0.567516 0.815925 0.62016 0.842979 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 96
Initial state: 0 0.796333 0.570944 0.539923 0.806087 0.630081 0.806359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167180 episodes
GETTING ACTION FROM:
action 3, numVisits=167123, meanQ=5.018706, numObservations: 4
action -1, numVisits=39, meanQ=3.912146, numObservations: 1
action 0, numVisits=16, meanQ=3.115904, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.796333 0.570944 0.539923 0.806087 0.630081 0.806359 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 97
Initial state: 0 0.947922 0.408184 0.548236 0.882236 0.659631 0.89047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158956 episodes
GETTING ACTION FROM:
action 2, numVisits=158915, meanQ=4.977714, numObservations: 4
action 0, numVisits=37, meanQ=3.765896, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.947922 0.408184 0.548236 0.882236 0.659631 0.89047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 98
Initial state: 0 0.327349 0.47417 0.574173 0.845987 0.579758 0.896876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166461 episodes
GETTING ACTION FROM:
action 2, numVisits=152692, meanQ=5.023090, numObservations: 4
action 3, numVisits=13764, meanQ=4.892467, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.327349 0.47417 0.574173 0.845987 0.579758 0.896876 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 99
Initial state: 0 0.133887 0.91842 0.638453 0.842693 0.541649 0.858689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166690 episodes
GETTING ACTION FROM:
action 1, numVisits=166633, meanQ=4.993664, numObservations: 5
action -1, numVisits=50, meanQ=4.017002, numObservations: 1
action 3, numVisits=3, meanQ=0.000033, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.133887 0.91842 0.638453 0.842693 0.541649 0.858689 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4128, meanQ=7.780305, numObservations: 3
action 1, numVisits=4, meanQ=2.995000, numObservations: 2
action 2, numVisits=4, meanQ=2.497525, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 71210 episodes
GETTING ACTION FROM:
action 3, numVisits=75330, meanQ=5.953310, numObservations: 3
action 1, numVisits=4, meanQ=2.995000, numObservations: 2
action 2, numVisits=4, meanQ=2.497525, numObservations: 1
action -1, numVisits=7, meanQ=-52.656218, numObservations: 1
action 0, numVisits=3, meanQ=-123.361166, numObservations: 1
action: 3
Next state: 1 0.133887 0.91842 0.638453 0.842693 0.541649 0.858689 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 100
Initial state: 0 0.568351 0.803165 0.659376 0.820291 0.766296 0.646581 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157735 episodes
GETTING ACTION FROM:
action 1, numVisits=157672, meanQ=4.869722, numObservations: 5
action 0, numVisits=51, meanQ=3.912179, numObservations: 1
action 2, numVisits=9, meanQ=1.101122, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.568351 0.803165 0.659376 0.820291 0.766296 0.646581 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 101
Initial state: 0 0.633556 0.868831 0.362555 0.409741 0.663661 0.870121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167132 episodes
GETTING ACTION FROM:
action 2, numVisits=167078, meanQ=5.002388, numObservations: 4
action -1, numVisits=50, meanQ=4.022183, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.633556 0.868831 0.362555 0.409741 0.663661 0.870121 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=19311, meanQ=8.509016, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 60848 episodes
GETTING ACTION FROM:
action 3, numVisits=32108, meanQ=7.481566, numObservations: 4
action 1, numVisits=47461, meanQ=6.355084, numObservations: 4
action -1, numVisits=589, meanQ=-1.042281, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=4, meanQ=-93.010592, numObservations: 1
action: 3
Next state: 1 0.633556 0.868831 0.362555 0.409741 0.663661 0.870121 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 102
Initial state: 0 0.6018 0.862816 0.94831 0.0558886 0.606814 0.868737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 152134 episodes
GETTING ACTION FROM:
action 3, numVisits=145946, meanQ=4.829535, numObservations: 4
action 0, numVisits=6184, meanQ=1.473719, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.6018 0.862816 0.94831 0.0558886 0.606814 0.868737 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 103
Initial state: 0 0.596968 0.816225 0.675102 0.876229 0.763234 0.815363 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164072 episodes
GETTING ACTION FROM:
action 2, numVisits=160515, meanQ=4.968561, numObservations: 5
action -1, numVisits=2754, meanQ=2.849916, numObservations: 1
action 0, numVisits=801, meanQ=2.756547, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.596968 0.816225 0.675102 0.876229 0.763234 0.815363 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 104
Initial state: 0 0.551512 0.878302 0.0263316 0.524749 0.674652 0.817205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167357 episodes
GETTING ACTION FROM:
action 1, numVisits=167263, meanQ=4.976538, numObservations: 4
action -1, numVisits=67, meanQ=4.125178, numObservations: 1
action 0, numVisits=25, meanQ=3.603139, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.551512 0.878302 0.0263316 0.524749 0.674652 0.817205 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 105
Initial state: 0 0.535065 0.821363 0.739564 0.610318 0.604116 0.814435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160769 episodes
GETTING ACTION FROM:
action 2, numVisits=160719, meanQ=4.823291, numObservations: 5
action -1, numVisits=37, meanQ=3.612664, numObservations: 1
action 3, numVisits=10, meanQ=1.903030, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.535065 0.821363 0.739564 0.610318 0.604116 0.814435 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 106
Initial state: 0 0.664707 0.741092 0.54159 0.847558 0.522696 0.854356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 71644 episodes
GETTING ACTION FROM:
action 0, numVisits=71633, meanQ=3.633678, numObservations: 1
action 2, numVisits=7, meanQ=0.571429, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.664707 0.741092 0.54159 0.847558 0.522696 0.854356 w: 1
Observation: 0 0 0.688177 0 0.857803 0 0.805715 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=71622, meanQ=5.775618, numObservations: 2
action 1, numVisits=5, meanQ=-0.201980, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 101532 episodes
GETTING ACTION FROM:
action 0, numVisits=173154, meanQ=5.809235, numObservations: 2
action 1, numVisits=5, meanQ=-0.201980, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.664707 0.741092 0.54159 0.847558 0.522696 0.854356 w: 1
Observation: 0 0 0.698221 0 0.875416 0 0.855268 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=110699, meanQ=7.827226, numObservations: 5
action 3, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 161141 episodes
GETTING ACTION FROM:
action 2, numVisits=271817, meanQ=5.988685, numObservations: 5
action 0, numVisits=19, meanQ=4.313052, numObservations: 1
action 3, numVisits=7, meanQ=2.711429, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.664707 0.741092 0.54159 0.847558 0.522696 0.854356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 107
Initial state: 0 0.0923183 0.803972 0.537295 0.871789 0.568317 0.829381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166374 episodes
GETTING ACTION FROM:
action 3, numVisits=166283, meanQ=5.022414, numObservations: 4
action -1, numVisits=79, meanQ=4.232477, numObservations: 1
action 1, numVisits=9, meanQ=1.666667, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0923183 0.803972 0.537295 0.871789 0.568317 0.829381 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 108
Initial state: 0 0.184293 0.773876 0.669477 0.895911 0.666262 0.854737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167113 episodes
GETTING ACTION FROM:
action 2, numVisits=166981, meanQ=5.038756, numObservations: 5
action -1, numVisits=61, meanQ=4.148506, numObservations: 1
action 0, numVisits=52, meanQ=4.080565, numObservations: 1
action 3, numVisits=10, meanQ=1.911010, numObservations: 3
action 1, numVisits=9, meanQ=1.768900, numObservations: 3
action: 2
Next state: 1 0.184293 0.773876 0.669477 0.895911 0.666262 0.854737 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 109
Initial state: 0 0.059802 0.563117 0.661343 0.859242 0.655888 0.869238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166568 episodes
GETTING ACTION FROM:
action 1, numVisits=166458, meanQ=4.964893, numObservations: 3
action -1, numVisits=88, meanQ=4.206941, numObservations: 1
action 2, numVisits=19, meanQ=3.257379, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.059802 0.563117 0.661343 0.859242 0.655888 0.869238 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27323, meanQ=8.311128, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 65602 episodes
GETTING ACTION FROM:
action 3, numVisits=92887, meanQ=6.434466, numObservations: 5
action -1, numVisits=37, meanQ=-0.073781, numObservations: 1
action 0, numVisits=5, meanQ=-2.001980, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.059802 0.563117 0.661343 0.859242 0.655888 0.869238 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 110
Initial state: 0 0.682803 0.896603 0.568026 0.898108 0.72213 0.70239 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166154 episodes
GETTING ACTION FROM:
action 3, numVisits=166060, meanQ=4.990466, numObservations: 5
action 0, numVisits=41, meanQ=3.903055, numObservations: 1
action -1, numVisits=17, meanQ=3.113622, numObservations: 1
action 2, numVisits=35, meanQ=2.791720, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.682803 0.896603 0.568026 0.898108 0.72213 0.70239 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 111
Initial state: 0 0.652433 0.832221 0.50273 0.897413 0.522577 0.30481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97492 episodes
GETTING ACTION FROM:
action -1, numVisits=97476, meanQ=3.125184, numObservations: 1
action 2, numVisits=12, meanQ=0.666675, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.652433 0.832221 0.50273 0.897413 0.522577 0.30481 w: 1
Observation: 0 0.725182 0 0.494596 0 0.506206 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=97435, meanQ=5.183031, numObservations: 5
action 0, numVisits=30, meanQ=3.933452, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 163952 episodes
GETTING ACTION FROM:
action 1, numVisits=261386, meanQ=5.225755, numObservations: 5
action 0, numVisits=31, meanQ=3.917636, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.652433 0.832221 0.50273 0.897413 0.522577 0.30481 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 112
Initial state: 0 0.616322 0.847684 0.916406 0.693737 0.538722 0.809909 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168091 episodes
GETTING ACTION FROM:
action 2, numVisits=168038, meanQ=5.063970, numObservations: 5
action 1, numVisits=46, meanQ=3.858702, numObservations: 4
action 3, numVisits=3, meanQ=0.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.616322 0.847684 0.916406 0.693737 0.538722 0.809909 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 113
Initial state: 0 0.950284 0.523675 0.522769 0.809583 0.694876 0.878691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163778 episodes
GETTING ACTION FROM:
action 3, numVisits=163750, meanQ=4.959460, numObservations: 5
action -1, numVisits=20, meanQ=3.318098, numObservations: 1
action 2, numVisits=5, meanQ=1.198020, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.950284 0.523675 0.522769 0.809583 0.694876 0.878691 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 114
Initial state: 0 0.591472 0.872789 0.0177616 0.124426 0.560107 0.861237 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97165 episodes
GETTING ACTION FROM:
action -1, numVisits=97124, meanQ=2.914263, numObservations: 1
action 1, numVisits=34, meanQ=1.694712, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=4, meanQ=-2.500000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.591472 0.872789 0.0177616 0.124426 0.560107 0.861237 w: 1
Observation: 0 0.683302 0 0.0643041 0 0.467765 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=97117, meanQ=4.954760, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 166479 episodes
GETTING ACTION FROM:
action 2, numVisits=263595, meanQ=4.847903, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-3.505000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.591472 0.872789 0.0177616 0.124426 0.560107 0.861237 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=37266, meanQ=8.401660, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 75057 episodes
GETTING ACTION FROM:
action 3, numVisits=56267, meanQ=7.628298, numObservations: 4
action 1, numVisits=52556, meanQ=6.319977, numObservations: 4
action 0, numVisits=3493, meanQ=0.135030, numObservations: 1
action -1, numVisits=10, meanQ=-2.000990, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.591472 0.872789 0.0177616 0.124426 0.560107 0.861237 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 115
Initial state: 0 0.617706 0.876815 0.503413 0.276862 0.644631 0.844666 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97381 episodes
GETTING ACTION FROM:
action 0, numVisits=97374, meanQ=2.887350, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.617706 0.876815 0.503413 0.276862 0.644631 0.844666 w: 1
Observation: 0 0 0.864729 0 0.305272 0 0.934388 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=97358, meanQ=4.937520, numObservations: 4
action 3, numVisits=10, meanQ=0.189000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 167068 episodes
GETTING ACTION FROM:
action 1, numVisits=264426, meanQ=4.864283, numObservations: 4
action 3, numVisits=10, meanQ=0.189000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.617706 0.876815 0.503413 0.276862 0.644631 0.844666 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 116
Initial state: 0 0.539834 0.813577 0.796664 0.438189 0.663976 0.826438 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167344 episodes
GETTING ACTION FROM:
action 1, numVisits=167267, meanQ=5.030850, numObservations: 4
action -1, numVisits=42, meanQ=3.928843, numObservations: 1
action 3, numVisits=32, meanQ=3.682509, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.539834 0.813577 0.796664 0.438189 0.663976 0.826438 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 117
Initial state: 0 0.907992 0.31665 0.557826 0.828362 0.504758 0.894183 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98308 episodes
GETTING ACTION FROM:
action -1, numVisits=98300, meanQ=2.949212, numObservations: 1
action 3, numVisits=4, meanQ=-0.999975, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.907992 0.31665 0.557826 0.828362 0.504758 0.894183 w: 1
Observation: 0 0.809774 0 0.616694 0 0.505199 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=98225, meanQ=5.024147, numObservations: 5
action -1, numVisits=48, meanQ=4.027959, numObservations: 1
action 1, numVisits=23, meanQ=3.438696, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 167524 episodes
GETTING ACTION FROM:
action 3, numVisits=265748, meanQ=5.150986, numObservations: 5
action -1, numVisits=49, meanQ=4.022528, numObservations: 1
action 1, numVisits=23, meanQ=3.438696, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.907992 0.31665 0.557826 0.828362 0.504758 0.894183 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 118
Initial state: 0 0.568775 0.824101 0.703672 0.957398 0.650356 0.879952 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166319 episodes
GETTING ACTION FROM:
action 1, numVisits=166298, meanQ=4.975819, numObservations: 4
action 0, numVisits=12, meanQ=1.079180, numObservations: 1
action 3, numVisits=5, meanQ=-0.200000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.568775 0.824101 0.703672 0.957398 0.650356 0.879952 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 119
Initial state: 0 0.595436 0.21226 0.616636 0.83525 0.584363 0.851498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165870 episodes
GETTING ACTION FROM:
action 3, numVisits=165855, meanQ=4.935635, numObservations: 4
action 1, numVisits=8, meanQ=1.500000, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.595436 0.21226 0.616636 0.83525 0.584363 0.851498 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 120
Initial state: 0 0.974848 0.670013 0.655375 0.840291 0.564571 0.822515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166283 episodes
GETTING ACTION FROM:
action 3, numVisits=165844, meanQ=5.172919, numObservations: 4
action 2, numVisits=434, meanQ=4.695658, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.974848 0.670013 0.655375 0.840291 0.564571 0.822515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11439, meanQ=7.106205, numObservations: 4
action 2, numVisits=14, meanQ=4.572157, numObservations: 2
action 1, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 186407 episodes
GETTING ACTION FROM:
action 3, numVisits=197840, meanQ=5.362092, numObservations: 5
action 2, numVisits=15, meanQ=3.534013, numObservations: 2
action 1, numVisits=6, meanQ=2.333333, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.974848 0.670013 0.655375 0.840291 0.564571 0.822515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 121
Initial state: 0 0.562537 0.869287 0.833185 0.584934 0.687746 0.862757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167006 episodes
GETTING ACTION FROM:
action 2, numVisits=166880, meanQ=4.978097, numObservations: 3
action 0, numVisits=117, meanQ=4.344855, numObservations: 1
action 3, numVisits=6, meanQ=1.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.562537 0.869287 0.833185 0.584934 0.687746 0.862757 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 122
Initial state: 0 0.632317 0.833016 0.836788 0.625778 0.627402 0.899875 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166079 episodes
GETTING ACTION FROM:
action 2, numVisits=166068, meanQ=5.047185, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.632317 0.833016 0.836788 0.625778 0.627402 0.899875 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 123
Initial state: 0 0.518094 0.882533 0.632868 0.890443 0.325853 0.00714087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 102201 episodes
GETTING ACTION FROM:
action 0, numVisits=102195, meanQ=5.791331, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.518094 0.882533 0.632868 0.890443 0.325853 0.00714087 w: 1
Observation: 0 0 0.95235 0 0.957536 0 0.0627703 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=28302, meanQ=8.322888, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 169175 episodes
GETTING ACTION FROM:
action 2, numVisits=197423, meanQ=5.453777, numObservations: 4
action -1, numVisits=39, meanQ=4.315600, numObservations: 1
action 0, numVisits=17, meanQ=3.722181, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.518094 0.882533 0.632868 0.890443 0.325853 0.00714087 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 124
Initial state: 0 0.65733 0.810929 0.69869 0.832949 0.964365 0.675704 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166965 episodes
GETTING ACTION FROM:
action 2, numVisits=166886, meanQ=4.976099, numObservations: 4
action -1, numVisits=62, meanQ=4.097086, numObservations: 1
action 1, numVisits=14, meanQ=1.857150, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.65733 0.810929 0.69869 0.832949 0.964365 0.675704 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 125
Initial state: 0 0.549116 0.848578 0.917265 0.985581 0.548858 0.861014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166594 episodes
GETTING ACTION FROM:
action 2, numVisits=166398, meanQ=4.975934, numObservations: 4
action 0, numVisits=122, meanQ=4.361455, numObservations: 1
action 3, numVisits=71, meanQ=4.014372, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.549116 0.848578 0.917265 0.985581 0.548858 0.861014 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 126
Initial state: 0 0.124212 0.699128 0.507483 0.813397 0.675549 0.885937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166250 episodes
GETTING ACTION FROM:
action 2, numVisits=166188, meanQ=5.138976, numObservations: 4
action -1, numVisits=40, meanQ=4.052419, numObservations: 1
action 0, numVisits=19, meanQ=3.511259, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.124212 0.699128 0.507483 0.813397 0.675549 0.885937 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 127
Initial state: 0 0.534491 0.819264 0.290945 0.112695 0.641029 0.815658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167110 episodes
GETTING ACTION FROM:
action 2, numVisits=167066, meanQ=5.019449, numObservations: 3
action -1, numVisits=32, meanQ=3.779183, numObservations: 1
action 1, numVisits=9, meanQ=1.776667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.534491 0.819264 0.290945 0.112695 0.641029 0.815658 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27640, meanQ=8.330843, numObservations: 3
action 1, numVisits=8, meanQ=5.748762, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 91557 episodes
GETTING ACTION FROM:
action 3, numVisits=73977, meanQ=6.833633, numObservations: 3
action 1, numVisits=44850, meanQ=6.396764, numObservations: 5
action -1, numVisits=374, meanQ=0.385000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=6, meanQ=-61.796711, numObservations: 1
action: 3
Next state: 1 0.534491 0.819264 0.290945 0.112695 0.641029 0.815658 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 128
Initial state: 0 0.636025 0.899187 0.525884 0.699262 0.526738 0.885794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165966 episodes
GETTING ACTION FROM:
action 2, numVisits=165960, meanQ=5.009686, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.636025 0.899187 0.525884 0.699262 0.526738 0.885794 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 129
Initial state: 0 0.669814 0.854663 0.0602597 0.0227319 0.561551 0.883806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167764 episodes
GETTING ACTION FROM:
action 1, numVisits=166473, meanQ=5.037426, numObservations: 5
action 2, numVisits=1222, meanQ=4.854104, numObservations: 4
action 0, numVisits=57, meanQ=4.122671, numObservations: 1
action -1, numVisits=9, meanQ=2.730000, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action: 1
Next state: 1 0.669814 0.854663 0.0602597 0.0227319 0.561551 0.883806 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 130
Initial state: 0 0.958033 0.44007 0.659512 0.862122 0.53923 0.884549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165518 episodes
GETTING ACTION FROM:
action 1, numVisits=165473, meanQ=4.940642, numObservations: 3
action 0, numVisits=41, meanQ=3.861535, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.958033 0.44007 0.659512 0.862122 0.53923 0.884549 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 131
Initial state: 0 0.671157 0.865273 0.518721 0.829904 0.95194 0.693955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167075 episodes
GETTING ACTION FROM:
action 1, numVisits=167008, meanQ=5.004833, numObservations: 5
action 0, numVisits=36, meanQ=3.850988, numObservations: 1
action 3, numVisits=27, meanQ=2.815189, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.671157 0.865273 0.518721 0.829904 0.95194 0.693955 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 132
Initial state: 0 0.398828 0.618374 0.589549 0.834436 0.538279 0.861209 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166478 episodes
GETTING ACTION FROM:
action 2, numVisits=166472, meanQ=5.157591, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.398828 0.618374 0.589549 0.834436 0.538279 0.861209 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 133
Initial state: 0 0.535926 0.866064 0.040911 0.755744 0.616703 0.897597 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165786 episodes
GETTING ACTION FROM:
action 1, numVisits=165567, meanQ=5.102024, numObservations: 4
action 2, numVisits=104, meanQ=4.324313, numObservations: 4
action 0, numVisits=74, meanQ=4.298833, numObservations: 1
action 3, numVisits=39, meanQ=3.995390, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.535926 0.866064 0.040911 0.755744 0.616703 0.897597 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 134
Initial state: 0 0.699053 0.816271 0.120052 0.458963 0.577031 0.867081 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163354 episodes
GETTING ACTION FROM:
action 3, numVisits=163320, meanQ=4.925843, numObservations: 5
action 0, numVisits=29, meanQ=3.615028, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.699053 0.816271 0.120052 0.458963 0.577031 0.867081 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 135
Initial state: 0 0.596792 0.842293 0.433067 0.175311 0.588264 0.823254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166035 episodes
GETTING ACTION FROM:
action 3, numVisits=165960, meanQ=5.024917, numObservations: 4
action 2, numVisits=30, meanQ=3.548337, numObservations: 4
action -1, numVisits=24, meanQ=3.493078, numObservations: 1
action 0, numVisits=17, meanQ=3.293508, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action: 3
Next state: 1 0.596792 0.842293 0.433067 0.175311 0.588264 0.823254 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 136
Initial state: 0 0.530237 0.817234 0.62705 0.859504 0.814923 0.906538 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166201 episodes
GETTING ACTION FROM:
action 3, numVisits=166192, meanQ=5.001428, numObservations: 4
action 0, numVisits=3, meanQ=-2.996600, numObservations: 1
action -1, numVisits=3, meanQ=-3.656600, numObservations: 1
action 1, numVisits=2, meanQ=-4.499950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.530237 0.817234 0.62705 0.859504 0.814923 0.906538 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 137
Initial state: 0 0.701453 0.973581 0.596581 0.887548 0.591217 0.819238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165313 episodes
GETTING ACTION FROM:
action 2, numVisits=165204, meanQ=4.978894, numObservations: 4
action 0, numVisits=29, meanQ=3.700370, numObservations: 1
action 3, numVisits=65, meanQ=3.453391, numObservations: 4
action 1, numVisits=13, meanQ=2.693854, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.701453 0.973581 0.596581 0.887548 0.591217 0.819238 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 138
Initial state: 0 0.692798 0.882412 0.588564 0.896664 0.0659015 0.0505739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166603 episodes
GETTING ACTION FROM:
action 1, numVisits=166582, meanQ=4.916287, numObservations: 4
action -1, numVisits=17, meanQ=3.056114, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.692798 0.882412 0.588564 0.896664 0.0659015 0.0505739 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 139
Initial state: 0 0.548287 0.837682 0.829109 0.534826 0.631527 0.802087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97902 episodes
GETTING ACTION FROM:
action -1, numVisits=97897, meanQ=2.937081, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.548287 0.837682 0.829109 0.534826 0.631527 0.802087 w: 1
Observation: 0 0.453806 0 0.889715 0 0.719975 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=97882, meanQ=4.979394, numObservations: 4
action 1, numVisits=9, meanQ=1.886667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 166974 episodes
GETTING ACTION FROM:
action 2, numVisits=264426, meanQ=4.998947, numObservations: 4
action 3, numVisits=431, meanQ=4.665687, numObservations: 4
action 1, numVisits=9, meanQ=1.886667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.548287 0.837682 0.829109 0.534826 0.631527 0.802087 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 140
Initial state: 0 0.598532 0.771767 0.551876 0.87882 0.681748 0.881452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167031 episodes
GETTING ACTION FROM:
action 2, numVisits=166899, meanQ=4.999320, numObservations: 4
action 0, numVisits=56, meanQ=4.085237, numObservations: 1
action 1, numVisits=72, meanQ=3.501807, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.598532 0.771767 0.551876 0.87882 0.681748 0.881452 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 141
Initial state: 0 0.575227 0.876344 0.0436618 0.249422 0.595612 0.87278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166781 episodes
GETTING ACTION FROM:
action 3, numVisits=166767, meanQ=4.974511, numObservations: 3
action 1, numVisits=8, meanQ=1.872500, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.575227 0.876344 0.0436618 0.249422 0.595612 0.87278 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 142
Initial state: 0 0.184623 0.382767 0.679525 0.801036 0.693374 0.895207 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164221 episodes
GETTING ACTION FROM:
action 2, numVisits=160944, meanQ=4.972390, numObservations: 4
action -1, numVisits=3273, meanQ=2.662621, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.184623 0.382767 0.679525 0.801036 0.693374 0.895207 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 143
Initial state: 0 0.38363 0.530508 0.542952 0.871927 0.658913 0.828985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 151147 episodes
GETTING ACTION FROM:
action 1, numVisits=151140, meanQ=4.683489, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.38363 0.530508 0.542952 0.871927 0.658913 0.828985 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=21011, meanQ=6.313256, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 22315 episodes
GETTING ACTION FROM:
action 0, numVisits=43326, meanQ=3.105170, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.38363 0.530508 0.542952 0.871927 0.658913 0.828985 w: 1
Observation: 0 0 0.515613 0 0.818733 0 0.746832 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=24230, meanQ=8.208486, numObservations: 5
action 0, numVisits=2435, meanQ=4.815786, numObservations: 1
action 2, numVisits=7, meanQ=4.427143, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 80822 episodes
GETTING ACTION FROM:
action 3, numVisits=99616, meanQ=6.370868, numObservations: 5
action 2, numVisits=13, meanQ=2.195707, numObservations: 2
action 0, numVisits=7863, meanQ=1.341309, numObservations: 1
action -1, numVisits=4, meanQ=-2.252450, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.38363 0.530508 0.542952 0.871927 0.658913 0.828985 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8409
Run # 144
Initial state: 0 0.623922 0.830849 0.507127 0.868876 0.253873 0.648294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166071 episodes
GETTING ACTION FROM:
action 2, numVisits=165994, meanQ=5.012672, numObservations: 4
action 0, numVisits=48, meanQ=4.026092, numObservations: 1
action 3, numVisits=26, meanQ=3.455015, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.623922 0.830849 0.507127 0.868876 0.253873 0.648294 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 145
Initial state: 0 0.308056 0.726063 0.674521 0.887462 0.504782 0.882762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167021 episodes
GETTING ACTION FROM:
action 2, numVisits=166980, meanQ=4.999179, numObservations: 5
action 0, numVisits=36, meanQ=3.835164, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.308056 0.726063 0.674521 0.887462 0.504782 0.882762 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 146
Initial state: 0 0.265415 0.102044 0.527833 0.869117 0.536018 0.821883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166982 episodes
GETTING ACTION FROM:
action 1, numVisits=166832, meanQ=4.979231, numObservations: 5
action -1, numVisits=102, meanQ=4.284297, numObservations: 1
action 0, numVisits=46, meanQ=3.952752, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.265415 0.102044 0.527833 0.869117 0.536018 0.821883 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23295, meanQ=8.420819, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 78411 episodes
GETTING ACTION FROM:
action 2, numVisits=66448, meanQ=6.851326, numObservations: 3
action 3, numVisits=35248, meanQ=6.246995, numObservations: 4
action 0, numVisits=11, meanQ=-2.000900, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-7.719470, numObservations: 1
action: 2
Next state: 1 0.265415 0.102044 0.527833 0.869117 0.536018 0.821883 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 147
Initial state: 0 0.522141 0.627266 0.528893 0.888356 0.530575 0.807591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166734 episodes
GETTING ACTION FROM:
action 1, numVisits=166667, meanQ=5.023786, numObservations: 4
action 2, numVisits=62, meanQ=3.932905, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.522141 0.627266 0.528893 0.888356 0.530575 0.807591 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 148
Initial state: 0 0.201921 0.285306 0.586485 0.832939 0.519323 0.878369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165396 episodes
GETTING ACTION FROM:
action 3, numVisits=165385, meanQ=4.946714, numObservations: 5
action 1, numVisits=6, meanQ=0.166667, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.201921 0.285306 0.586485 0.832939 0.519323 0.878369 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 149
Initial state: 0 0.610164 0.916435 0.627605 0.855245 0.551768 0.840519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165731 episodes
GETTING ACTION FROM:
action 1, numVisits=165667, meanQ=4.931088, numObservations: 4
action 0, numVisits=60, meanQ=4.040619, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.610164 0.916435 0.627605 0.855245 0.551768 0.840519 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 150
Initial state: 0 0.36491 0.208659 0.508444 0.878719 0.691731 0.815845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98037 episodes
GETTING ACTION FROM:
action 0, numVisits=98031, meanQ=2.984516, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.36491 0.208659 0.508444 0.878719 0.691731 0.815845 w: 1
Observation: 0 0 0.237875 0 0.849768 0 0.881278 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=98023, meanQ=5.020475, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 165805 episodes
GETTING ACTION FROM:
action 2, numVisits=263827, meanQ=5.103448, numObservations: 4
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.36491 0.208659 0.508444 0.878719 0.691731 0.815845 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 151
Initial state: 0 0.518869 0.857716 0.626164 0.851305 0.436872 0.190845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167438 episodes
GETTING ACTION FROM:
action 3, numVisits=167400, meanQ=5.019766, numObservations: 4
action -1, numVisits=30, meanQ=3.735220, numObservations: 1
action 1, numVisits=5, meanQ=1.622000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.518869 0.857716 0.626164 0.851305 0.436872 0.190845 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25198, meanQ=8.323388, numObservations: 5
action 1, numVisits=2381, meanQ=8.230104, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54615 episodes
GETTING ACTION FROM:
action 2, numVisits=55998, meanQ=7.029128, numObservations: 5
action 1, numVisits=10361, meanQ=6.383580, numObservations: 3
action 0, numVisits=15833, meanQ=0.320775, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=4, meanQ=-6.584375, numObservations: 1
action: 2
Next state: 1 0.518869 0.857716 0.626164 0.851305 0.436872 0.190845 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 152
Initial state: 0 0.456044 0.687693 0.656972 0.835821 0.575458 0.856512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157607 episodes
GETTING ACTION FROM:
action 3, numVisits=157552, meanQ=4.851066, numObservations: 4
action -1, numVisits=36, meanQ=3.655948, numObservations: 1
action 2, numVisits=16, meanQ=2.915631, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.456044 0.687693 0.656972 0.835821 0.575458 0.856512 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 153
Initial state: 0 0.673435 0.814895 0.498309 0.862505 0.605354 0.869803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165366 episodes
GETTING ACTION FROM:
action 1, numVisits=165360, meanQ=4.988943, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.673435 0.814895 0.498309 0.862505 0.605354 0.869803 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12148, meanQ=4.864470, numObservations: 5
action 1, numVisits=5, meanQ=1.396020, numObservations: 2
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 185848 episodes
GETTING ACTION FROM:
action 1, numVisits=185853, meanQ=5.233681, numObservations: 3
action 2, numVisits=12148, meanQ=4.864470, numObservations: 5
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.673435 0.814895 0.498309 0.862505 0.605354 0.869803 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=2579, meanQ=7.034538, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 212611 episodes
GETTING ACTION FROM:
action 2, numVisits=215190, meanQ=6.311657, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.673435 0.814895 0.498309 0.862505 0.605354 0.869803 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=1092, meanQ=8.278329, numObservations: 4
action 1, numVisits=5, meanQ=3.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46943 episodes
GETTING ACTION FROM:
action 3, numVisits=2875, meanQ=7.280496, numObservations: 4
action 1, numVisits=45154, meanQ=6.149027, numObservations: 3
action -1, numVisits=7, meanQ=-1.858571, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=6, meanQ=-5.600881, numObservations: 1
action: 3
Next state: 1 0.673435 0.814895 0.498309 0.862505 0.605354 0.869803 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 154
Initial state: 0 0.611009 0.873052 0.181554 0.978084 0.604636 0.861662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162804 episodes
GETTING ACTION FROM:
action 3, numVisits=162794, meanQ=4.964806, numObservations: 5
action 2, numVisits=5, meanQ=1.582000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.611009 0.873052 0.181554 0.978084 0.604636 0.861662 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 155
Initial state: 0 0.296739 0.472798 0.524068 0.882842 0.643231 0.827768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155928 episodes
GETTING ACTION FROM:
action 3, numVisits=155891, meanQ=4.788219, numObservations: 4
action 2, numVisits=32, meanQ=3.148131, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.296739 0.472798 0.524068 0.882842 0.643231 0.827768 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=11778, meanQ=2.968472, numObservations: 1
action 1, numVisits=6, meanQ=-2.331650, numObservations: 2
action 0, numVisits=3, meanQ=-2.996600, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 191461 episodes
GETTING ACTION FROM:
action 1, numVisits=161912, meanQ=6.313141, numObservations: 4
action -1, numVisits=41331, meanQ=0.298264, numObservations: 1
action 0, numVisits=5, meanQ=-2.597960, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.296739 0.472798 0.524068 0.882842 0.643231 0.827768 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2037, meanQ=8.036095, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 100369 episodes
GETTING ACTION FROM:
action 3, numVisits=102395, meanQ=6.067573, numObservations: 5
action 1, numVisits=7, meanQ=4.427143, numObservations: 4
action -1, numVisits=4, meanQ=-1.752500, numObservations: 1
action 0, numVisits=4, meanQ=-1.752500, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.296739 0.472798 0.524068 0.882842 0.643231 0.827768 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 156
Initial state: 0 0.669202 0.805997 0.760476 0.881644 0.560986 0.878977 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166790 episodes
GETTING ACTION FROM:
action 1, numVisits=166783, meanQ=4.971859, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.669202 0.805997 0.760476 0.881644 0.560986 0.878977 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 157
Initial state: 0 0.301592 0.243631 0.684858 0.810951 0.530619 0.82226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163835 episodes
GETTING ACTION FROM:
action 2, numVisits=163491, meanQ=4.900656, numObservations: 4
action 1, numVisits=338, meanQ=4.347411, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.301592 0.243631 0.684858 0.810951 0.530619 0.82226 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 158
Initial state: 0 0.582159 0.865344 0.605243 0.851489 0.758885 0.993866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162360 episodes
GETTING ACTION FROM:
action 3, numVisits=162173, meanQ=4.841809, numObservations: 4
action 2, numVisits=145, meanQ=4.166143, numObservations: 4
action -1, numVisits=39, meanQ=3.686465, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.582159 0.865344 0.605243 0.851489 0.758885 0.993866 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 159
Initial state: 0 0.66821 0.856813 0.613305 0.844243 0.43799 0.443698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167743 episodes
GETTING ACTION FROM:
action 2, numVisits=167654, meanQ=5.050637, numObservations: 4
action -1, numVisits=68, meanQ=4.192319, numObservations: 1
action 0, numVisits=19, meanQ=3.454610, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.66821 0.856813 0.613305 0.844243 0.43799 0.443698 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 160
Initial state: 0 0.500693 0.623517 0.628548 0.805909 0.639187 0.844387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166687 episodes
GETTING ACTION FROM:
action 2, numVisits=166673, meanQ=5.033074, numObservations: 4
action 3, numVisits=8, meanQ=1.500000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.500693 0.623517 0.628548 0.805909 0.639187 0.844387 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 161
Initial state: 0 0.582612 0.855282 0.50669 0.897773 0.965461 0.405487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160983 episodes
GETTING ACTION FROM:
action 1, numVisits=160935, meanQ=4.934685, numObservations: 5
action 0, numVisits=38, meanQ=3.686263, numObservations: 2
action 2, numVisits=7, meanQ=1.428571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.582612 0.855282 0.50669 0.897773 0.965461 0.405487 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 162
Initial state: 0 0.602361 0.867331 0.644013 0.851422 0.758919 0.880973 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165764 episodes
GETTING ACTION FROM:
action 3, numVisits=165758, meanQ=4.967393, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.602361 0.867331 0.644013 0.851422 0.758919 0.880973 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 163
Initial state: 0 0.51909 0.855905 0.125511 0.473419 0.55316 0.818974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97940 episodes
GETTING ACTION FROM:
action 0, numVisits=97924, meanQ=3.000077, numObservations: 1
action 1, numVisits=10, meanQ=0.789010, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.51909 0.855905 0.125511 0.473419 0.55316 0.818974 w: 1
Observation: 0 0 0.94988 0 0.569715 0 0.801846 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=97917, meanQ=5.021570, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 167812 episodes
GETTING ACTION FROM:
action 2, numVisits=241760, meanQ=5.249492, numObservations: 5
action 1, numVisits=23970, meanQ=4.998274, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.51909 0.855905 0.125511 0.473419 0.55316 0.818974 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=27230, meanQ=8.517467, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 27665 episodes
GETTING ACTION FROM:
action 3, numVisits=54892, meanQ=7.260221, numObservations: 4
action 1, numVisits=3, meanQ=0.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-192.790937, numObservations: 1
action: 3
Next state: 1 0.51909 0.855905 0.125511 0.473419 0.55316 0.818974 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 164
Initial state: 0 0.388296 0.123471 0.547386 0.822965 0.65381 0.869415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166448 episodes
GETTING ACTION FROM:
action 2, numVisits=166130, meanQ=4.964361, numObservations: 3
action -1, numVisits=158, meanQ=4.426302, numObservations: 1
action 0, numVisits=154, meanQ=4.417531, numObservations: 1
action 3, numVisits=5, meanQ=1.198020, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.388296 0.123471 0.547386 0.822965 0.65381 0.869415 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 165
Initial state: 0 0.660644 0.809983 0.00822824 0.254725 0.540437 0.891903 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166426 episodes
GETTING ACTION FROM:
action 2, numVisits=166367, meanQ=4.950846, numObservations: 5
action 0, numVisits=26, meanQ=3.491385, numObservations: 1
action -1, numVisits=22, meanQ=3.401888, numObservations: 1
action 3, numVisits=10, meanQ=2.499000, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.660644 0.809983 0.00822824 0.254725 0.540437 0.891903 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23291, meanQ=8.410921, numObservations: 4
action 1, numVisits=8, meanQ=5.748762, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 51774 episodes
GETTING ACTION FROM:
action 3, numVisits=62023, meanQ=6.857093, numObservations: 4
action 1, numVisits=12863, meanQ=5.657450, numObservations: 4
action 0, numVisits=180, meanQ=-0.149507, numObservations: 1
action -1, numVisits=9, meanQ=-1.890000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.660644 0.809983 0.00822824 0.254725 0.540437 0.891903 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 166
Initial state: 0 0.599872 0.824068 0.368099 0.272386 0.541196 0.842672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166895 episodes
GETTING ACTION FROM:
action 3, numVisits=166802, meanQ=4.996117, numObservations: 5
action -1, numVisits=54, meanQ=4.050891, numObservations: 1
action 0, numVisits=24, meanQ=3.548624, numObservations: 1
action 1, numVisits=12, meanQ=2.250842, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action: 3
Next state: 1 0.599872 0.824068 0.368099 0.272386 0.541196 0.842672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 167
Initial state: 0 0.114181 0.704084 0.568259 0.829006 0.530064 0.86704 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97732 episodes
GETTING ACTION FROM:
action 0, numVisits=97722, meanQ=2.844765, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.114181 0.704084 0.568259 0.829006 0.530064 0.86704 w: 1
Observation: 0 0 0.6832 0 0.902348 0 0.79983 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=97204, meanQ=4.921662, numObservations: 4
action 1, numVisits=512, meanQ=4.564295, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 168142 episodes
GETTING ACTION FROM:
action 3, numVisits=168143, meanQ=5.369359, numObservations: 5
action 2, numVisits=97204, meanQ=4.921662, numObservations: 4
action 1, numVisits=512, meanQ=4.564295, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.114181 0.704084 0.568259 0.829006 0.530064 0.86704 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 168
Initial state: 0 0.568762 0.898667 0.847642 0.777767 0.500881 0.854293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166308 episodes
GETTING ACTION FROM:
action 1, numVisits=166234, meanQ=5.175598, numObservations: 5
action 0, numVisits=69, meanQ=4.349075, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.568762 0.898667 0.847642 0.777767 0.500881 0.854293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 169
Initial state: 0 0.366136 0.119487 0.535897 0.852827 0.613146 0.866795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164026 episodes
GETTING ACTION FROM:
action 3, numVisits=163935, meanQ=4.957622, numObservations: 4
action 0, numVisits=46, meanQ=3.893700, numObservations: 1
action -1, numVisits=36, meanQ=3.776878, numObservations: 1
action 2, numVisits=8, meanQ=2.375000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.366136 0.119487 0.535897 0.852827 0.613146 0.866795 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 170
Initial state: 0 0.24267 0.608907 0.597824 0.828203 0.588763 0.862443 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165193 episodes
GETTING ACTION FROM:
action 1, numVisits=165187, meanQ=4.990636, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.24267 0.608907 0.597824 0.828203 0.588763 0.862443 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=18914, meanQ=8.518647, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 65561 episodes
GETTING ACTION FROM:
action 3, numVisits=84096, meanQ=6.623126, numObservations: 4
action 0, numVisits=368, meanQ=-0.470647, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=12, meanQ=-30.767404, numObservations: 1
action: 3
Next state: 1 0.24267 0.608907 0.597824 0.828203 0.588763 0.862443 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 171
Initial state: 0 0.653139 0.894797 0.321919 0.754621 0.693171 0.823473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165349 episodes
GETTING ACTION FROM:
action 3, numVisits=165294, meanQ=4.935480, numObservations: 3
action 0, numVisits=51, meanQ=3.967413, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.653139 0.894797 0.321919 0.754621 0.693171 0.823473 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 172
Initial state: 0 0.690235 0.843412 0.588389 0.896087 0.387036 0.205116 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166537 episodes
GETTING ACTION FROM:
action 2, numVisits=158741, meanQ=5.021484, numObservations: 5
action 3, numVisits=7681, meanQ=4.897805, numObservations: 5
action 1, numVisits=111, meanQ=4.313853, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.690235 0.843412 0.588389 0.896087 0.387036 0.205116 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 173
Initial state: 0 0.664034 0.871564 0.61281 0.856138 0.522489 0.471116 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166160 episodes
GETTING ACTION FROM:
action 1, numVisits=166148, meanQ=5.030192, numObservations: 5
action 2, numVisits=7, meanQ=2.002871, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.664034 0.871564 0.61281 0.856138 0.522489 0.471116 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12069, meanQ=5.510202, numObservations: 4
action 2, numVisits=15, meanQ=3.398667, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 184481 episodes
GETTING ACTION FROM:
action 1, numVisits=196548, meanQ=5.192959, numObservations: 5
action 2, numVisits=15, meanQ=3.398667, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.664034 0.871564 0.61281 0.856138 0.522489 0.471116 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=4777, meanQ=6.709811, numObservations: 4
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 211163 episodes
GETTING ACTION FROM:
action 2, numVisits=215938, meanQ=5.931011, numObservations: 4
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 0 0.664034 0.871564 0.61281 0.856138 0.522489 0.471116 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=426, meanQ=8.289279, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 104166 episodes
GETTING ACTION FROM:
action 2, numVisits=1132, meanQ=6.838465, numObservations: 5
action 1, numVisits=103451, meanQ=6.374479, numObservations: 4
action -1, numVisits=6, meanQ=-1.835000, numObservations: 1
action 0, numVisits=6, meanQ=-1.835000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.664034 0.871564 0.61281 0.856138 0.522489 0.471116 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 174
Initial state: 0 0.644336 0.83505 0.669744 0.804671 0.104427 0.13772 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167014 episodes
GETTING ACTION FROM:
action 2, numVisits=167003, meanQ=5.120758, numObservations: 4
action 1, numVisits=5, meanQ=1.198020, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.644336 0.83505 0.669744 0.804671 0.104427 0.13772 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 175
Initial state: 0 0.545862 0.870441 0.392216 0.648809 0.643021 0.816627 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167441 episodes
GETTING ACTION FROM:
action 1, numVisits=167303, meanQ=4.983709, numObservations: 3
action -1, numVisits=109, meanQ=4.325716, numObservations: 1
action 2, numVisits=16, meanQ=2.750006, numObservations: 4
action 3, numVisits=11, meanQ=2.628182, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.545862 0.870441 0.392216 0.648809 0.643021 0.816627 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 176
Initial state: 0 0.665316 0.891088 0.198114 0.227282 0.646927 0.84719 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161585 episodes
GETTING ACTION FROM:
action 2, numVisits=161562, meanQ=4.879211, numObservations: 4
action -1, numVisits=19, meanQ=3.242763, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.665316 0.891088 0.198114 0.227282 0.646927 0.84719 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=22545, meanQ=8.395817, numObservations: 5
action 3, numVisits=4, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 87685 episodes
GETTING ACTION FROM:
action 1, numVisits=63462, meanQ=6.791681, numObservations: 5
action 3, numVisits=46394, meanQ=6.247742, numObservations: 5
action -1, numVisits=370, meanQ=-0.218512, numObservations: 1
action 0, numVisits=10, meanQ=-1.901000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.665316 0.891088 0.198114 0.227282 0.646927 0.84719 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 177
Initial state: 0 0.00611574 0.172331 0.641041 0.885013 0.682429 0.835566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165205 episodes
GETTING ACTION FROM:
action 3, numVisits=165169, meanQ=4.918348, numObservations: 5
action 1, numVisits=30, meanQ=2.963000, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.00611574 0.172331 0.641041 0.885013 0.682429 0.835566 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12340, meanQ=4.606879, numObservations: 5
action 2, numVisits=12, meanQ=2.317500, numObservations: 3
action 3, numVisits=6, meanQ=1.331683, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 207638 episodes
GETTING ACTION FROM:
action 2, numVisits=207646, meanQ=6.130028, numObservations: 4
action 1, numVisits=12344, meanQ=4.606683, numObservations: 5
action 3, numVisits=6, meanQ=1.331683, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.00611574 0.172331 0.641041 0.885013 0.682429 0.835566 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 178
Initial state: 0 0.895309 0.748946 0.671425 0.894305 0.562165 0.843181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159250 episodes
GETTING ACTION FROM:
action 1, numVisits=158897, meanQ=5.016709, numObservations: 4
action 0, numVisits=183, meanQ=4.373683, numObservations: 1
action 3, numVisits=167, meanQ=4.301620, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.895309 0.748946 0.671425 0.894305 0.562165 0.843181 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 179
Initial state: 0 0.918505 0.532311 0.593966 0.844502 0.656132 0.877774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 103575 episodes
GETTING ACTION FROM:
action 0, numVisits=103566, meanQ=5.811844, numObservations: 2
action 2, numVisits=5, meanQ=-1.600000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.918505 0.532311 0.593966 0.844502 0.656132 0.877774 w: 1
Observation: 0 0 0.598093 0 0.789147 0 0.906784 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=33253, meanQ=8.213634, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 170460 episodes
GETTING ACTION FROM:
action 3, numVisits=203639, meanQ=5.369208, numObservations: 3
action 0, numVisits=74, meanQ=4.555348, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.918505 0.532311 0.593966 0.844502 0.656132 0.877774 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 180
Initial state: 0 0.630774 0.845553 0.745384 0.908132 0.688872 0.871889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95293 episodes
GETTING ACTION FROM:
action -1, numVisits=95286, meanQ=2.821784, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.630774 0.845553 0.745384 0.908132 0.688872 0.871889 w: 1
Observation: 0 0.680718 0 0.727866 0 0.67687 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=95260, meanQ=4.867261, numObservations: 4
action 3, numVisits=20, meanQ=3.294005, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 157426 episodes
GETTING ACTION FROM:
action 2, numVisits=157427, meanQ=4.916346, numObservations: 4
action 1, numVisits=95260, meanQ=4.867261, numObservations: 4
action 3, numVisits=20, meanQ=3.294005, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.630774 0.845553 0.745384 0.908132 0.688872 0.871889 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 181
Initial state: 0 0.167703 0.0650784 0.648037 0.825774 0.537406 0.820461 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165150 episodes
GETTING ACTION FROM:
action 1, numVisits=165142, meanQ=4.987078, numObservations: 5
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.167703 0.0650784 0.648037 0.825774 0.537406 0.820461 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4322, meanQ=7.756026, numObservations: 5
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 69639 episodes
GETTING ACTION FROM:
action 3, numVisits=43788, meanQ=6.036832, numObservations: 5
action 2, numVisits=27626, meanQ=5.704832, numObservations: 4
action 0, numVisits=2540, meanQ=0.013516, numObservations: 1
action -1, numVisits=11, meanQ=-1.910000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.167703 0.0650784 0.648037 0.825774 0.537406 0.820461 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 182
Initial state: 0 0.62088 0.854619 0.815141 0.0506288 0.606102 0.889564 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166755 episodes
GETTING ACTION FROM:
action 3, numVisits=166583, meanQ=5.019125, numObservations: 4
action -1, numVisits=63, meanQ=4.144773, numObservations: 1
action 1, numVisits=83, meanQ=3.978076, numObservations: 4
action 0, numVisits=24, meanQ=3.483173, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 1 0.62088 0.854619 0.815141 0.0506288 0.606102 0.889564 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.27303 0.192111 0.666567 0.895573 0.6763 0.8723 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166812 episodes
GETTING ACTION FROM:
action 1, numVisits=166775, meanQ=4.944036, numObservations: 4
action -1, numVisits=33, meanQ=3.741598, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.27303 0.192111 0.666567 0.895573 0.6763 0.8723 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26201, meanQ=8.286774, numObservations: 4
action 3, numVisits=1244, meanQ=8.099152, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 64673 episodes
GETTING ACTION FROM:
action 2, numVisits=51641, meanQ=7.178053, numObservations: 4
action 3, numVisits=40416, meanQ=6.033994, numObservations: 4
action -1, numVisits=58, meanQ=-0.647967, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=5, meanQ=-73.722586, numObservations: 1
action: 2
Next state: 1 0.27303 0.192111 0.666567 0.895573 0.6763 0.8723 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 184
Initial state: 0 0.648893 0.806127 0.507932 0.887821 0.0922419 0.8806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165508 episodes
GETTING ACTION FROM:
action 2, numVisits=165305, meanQ=4.939855, numObservations: 5
action 0, numVisits=188, meanQ=4.428334, numObservations: 2
action 1, numVisits=12, meanQ=2.915850, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.648893 0.806127 0.507932 0.887821 0.0922419 0.8806 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 185
Initial state: 0 0.681287 0.86475 0.532539 0.803098 0.233005 0.914126 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166571 episodes
GETTING ACTION FROM:
action 1, numVisits=166559, meanQ=4.928359, numObservations: 3
action 3, numVisits=7, meanQ=-0.014271, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.681287 0.86475 0.532539 0.803098 0.233005 0.914126 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 186
Initial state: 0 0.892735 0.331269 0.68973 0.823821 0.586834 0.830497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166082 episodes
GETTING ACTION FROM:
action 2, numVisits=166012, meanQ=5.147811, numObservations: 4
action 0, numVisits=48, meanQ=4.126599, numObservations: 2
action -1, numVisits=18, meanQ=3.510598, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.892735 0.331269 0.68973 0.823821 0.586834 0.830497 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11008, meanQ=7.378807, numObservations: 4
action 1, numVisits=12, meanQ=4.325000, numObservations: 3
action 3, numVisits=9, meanQ=3.887789, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 200957 episodes
GETTING ACTION FROM:
action 3, numVisits=168422, meanQ=5.973300, numObservations: 3
action 2, numVisits=43517, meanQ=5.683128, numObservations: 4
action 1, numVisits=45, meanQ=4.728889, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.892735 0.331269 0.68973 0.823821 0.586834 0.830497 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 187
Initial state: 0 0.292261 0.500373 0.577662 0.865061 0.528609 0.866169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165197 episodes
GETTING ACTION FROM:
action 3, numVisits=165094, meanQ=4.942599, numObservations: 5
action 0, numVisits=99, meanQ=4.246911, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.292261 0.500373 0.577662 0.865061 0.528609 0.866169 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 188
Initial state: 0 0.704141 0.978804 0.650591 0.891738 0.546788 0.815889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158470 episodes
GETTING ACTION FROM:
action 2, numVisits=158458, meanQ=4.872232, numObservations: 5
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.704141 0.978804 0.650591 0.891738 0.546788 0.815889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 189
Initial state: 0 0.559994 0.814397 0.403903 0.656423 0.671712 0.81526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166969 episodes
GETTING ACTION FROM:
action 3, numVisits=166873, meanQ=5.048352, numObservations: 4
action -1, numVisits=64, meanQ=4.175245, numObservations: 1
action 0, numVisits=20, meanQ=3.451096, numObservations: 1
action 2, numVisits=11, meanQ=2.909100, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.559994 0.814397 0.403903 0.656423 0.671712 0.81526 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 190
Initial state: 0 0.41493 0.926091 0.695436 0.839002 0.582725 0.818751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165899 episodes
GETTING ACTION FROM:
action 1, numVisits=165875, meanQ=5.007624, numObservations: 5
action 0, numVisits=16, meanQ=3.123467, numObservations: 1
action 2, numVisits=5, meanQ=-0.002000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.41493 0.926091 0.695436 0.839002 0.582725 0.818751 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12113, meanQ=5.577217, numObservations: 4
action 2, numVisits=5, meanQ=2.598000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 204191 episodes
GETTING ACTION FROM:
action 2, numVisits=197719, meanQ=6.022502, numObservations: 4
action 1, numVisits=18585, meanQ=5.356010, numObservations: 4
action -1, numVisits=6, meanQ=2.620000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.41493 0.926091 0.695436 0.839002 0.582725 0.818751 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=4105, meanQ=7.400932, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 212817 episodes
GETTING ACTION FROM:
action 2, numVisits=216920, meanQ=5.585318, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.41493 0.926091 0.695436 0.839002 0.582725 0.818751 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 191
Initial state: 0 0.394688 0.076671 0.634335 0.874621 0.51101 0.863332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166133 episodes
GETTING ACTION FROM:
action 3, numVisits=166097, meanQ=4.954258, numObservations: 4
action 0, numVisits=14, meanQ=3.061020, numObservations: 1
action 1, numVisits=10, meanQ=2.300010, numObservations: 3
action 2, numVisits=10, meanQ=1.700000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.394688 0.076671 0.634335 0.874621 0.51101 0.863332 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 192
Initial state: 0 0.42892 0.698202 0.684799 0.865612 0.553674 0.861228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160814 episodes
GETTING ACTION FROM:
action 3, numVisits=160597, meanQ=4.946667, numObservations: 4
action 0, numVisits=122, meanQ=4.318900, numObservations: 2
action -1, numVisits=85, meanQ=4.202963, numObservations: 1
action 2, numVisits=9, meanQ=1.776667, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.42892 0.698202 0.684799 0.865612 0.553674 0.861228 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 193
Initial state: 0 0.610429 0.818058 0.896133 0.616068 0.603326 0.810583 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157678 episodes
GETTING ACTION FROM:
action 3, numVisits=157643, meanQ=5.002394, numObservations: 5
action 1, numVisits=29, meanQ=3.021379, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.610429 0.818058 0.896133 0.616068 0.603326 0.810583 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=11562, meanQ=5.540706, numObservations: 3
action 1, numVisits=48, meanQ=2.328762, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 202222 episodes
GETTING ACTION FROM:
action 2, numVisits=194075, meanQ=5.845008, numObservations: 4
action 0, numVisits=19710, meanQ=3.235180, numObservations: 3
action 1, numVisits=48, meanQ=2.328762, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.610429 0.818058 0.896133 0.616068 0.603326 0.810583 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 194
Initial state: 0 0.606386 0.0694989 0.53045 0.837101 0.568828 0.890259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164976 episodes
GETTING ACTION FROM:
action 1, numVisits=164960, meanQ=4.955328, numObservations: 4
action 3, numVisits=7, meanQ=1.428571, numObservations: 2
action 2, numVisits=5, meanQ=0.802020, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.606386 0.0694989 0.53045 0.837101 0.568828 0.890259 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 195
Initial state: 0 0.279587 0.0918862 0.585285 0.891268 0.603476 0.854246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166020 episodes
GETTING ACTION FROM:
action 2, numVisits=166000, meanQ=5.022242, numObservations: 4
action -1, numVisits=14, meanQ=3.130380, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.279587 0.0918862 0.585285 0.891268 0.603476 0.854246 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 196
Initial state: 0 0.539026 0.823926 0.588946 0.80768 0.415655 0.504157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166668 episodes
GETTING ACTION FROM:
action 2, numVisits=166631, meanQ=5.023779, numObservations: 4
action 0, numVisits=33, meanQ=3.810449, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.539026 0.823926 0.588946 0.80768 0.415655 0.504157 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 197
Initial state: 0 0.503408 0.884071 0.509526 0.867827 0.16759 0.904179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167344 episodes
GETTING ACTION FROM:
action 2, numVisits=167258, meanQ=5.016042, numObservations: 3
action -1, numVisits=53, meanQ=4.065137, numObservations: 1
action 1, numVisits=28, meanQ=2.361789, numObservations: 4
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.503408 0.884071 0.509526 0.867827 0.16759 0.904179 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 198
Initial state: 0 0.535854 0.854575 0.859865 0.253218 0.675968 0.835415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166731 episodes
GETTING ACTION FROM:
action 2, numVisits=166721, meanQ=5.010146, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.535854 0.854575 0.859865 0.253218 0.675968 0.835415 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 199
Initial state: 0 0.241997 0.0672551 0.587426 0.808101 0.559037 0.897033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97474 episodes
GETTING ACTION FROM:
action -1, numVisits=97467, meanQ=2.932166, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.241997 0.0672551 0.587426 0.808101 0.559037 0.897033 w: 1
Observation: 0 0.166792 0 0.536134 0 0.621591 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=97404, meanQ=4.945617, numObservations: 4
action 0, numVisits=37, meanQ=3.806315, numObservations: 1
action 1, numVisits=22, meanQ=3.272277, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 166359 episodes
GETTING ACTION FROM:
action 2, numVisits=263762, meanQ=4.941314, numObservations: 4
action 0, numVisits=38, meanQ=3.777875, numObservations: 1
action 1, numVisits=22, meanQ=3.272277, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.241997 0.0672551 0.587426 0.808101 0.559037 0.897033 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 200
Initial state: 0 0.575045 0.824948 0.310195 0.749797 0.563617 0.841812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166049 episodes
GETTING ACTION FROM:
action 2, numVisits=159812, meanQ=5.129026, numObservations: 5
action 3, numVisits=4772, meanQ=4.962588, numObservations: 5
action 1, numVisits=1461, meanQ=4.873549, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.575045 0.824948 0.310195 0.749797 0.563617 0.841812 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=18182, meanQ=8.527302, numObservations: 3
action 1, numVisits=5, meanQ=4.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 74698 episodes
GETTING ACTION FROM:
action 3, numVisits=85717, meanQ=6.594762, numObservations: 4
action 1, numVisits=7090, meanQ=6.092733, numObservations: 5
action 0, numVisits=75, meanQ=0.357530, numObservations: 1
action -1, numVisits=5, meanQ=-2.001980, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.575045 0.824948 0.310195 0.749797 0.563617 0.841812 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 201
Initial state: 0 0.761084 0.672735 0.601996 0.824024 0.682621 0.883505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166414 episodes
GETTING ACTION FROM:
action 1, numVisits=166395, meanQ=4.996885, numObservations: 5
action 2, numVisits=14, meanQ=2.785721, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.761084 0.672735 0.601996 0.824024 0.682621 0.883505 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 202
Initial state: 0 0.578105 0.842366 0.678228 0.806232 0.761984 0.198179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166563 episodes
GETTING ACTION FROM:
action 3, numVisits=166553, meanQ=5.152643, numObservations: 4
action 1, numVisits=5, meanQ=-0.002000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.578105 0.842366 0.678228 0.806232 0.761984 0.198179 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 203
Initial state: 0 0.366577 0.450894 0.699516 0.829486 0.664553 0.802528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160568 episodes
GETTING ACTION FROM:
action 3, numVisits=160562, meanQ=4.859128, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.366577 0.450894 0.699516 0.829486 0.664553 0.802528 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 204
Initial state: 0 0.530946 0.837716 0.426487 0.472167 0.57912 0.819493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165229 episodes
GETTING ACTION FROM:
action 3, numVisits=165223, meanQ=4.912936, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.530946 0.837716 0.426487 0.472167 0.57912 0.819493 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 205
Initial state: 0 0.748544 0.825592 0.561786 0.879082 0.532637 0.809795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166262 episodes
GETTING ACTION FROM:
action 1, numVisits=166251, meanQ=4.938660, numObservations: 5
action 2, numVisits=6, meanQ=1.166683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.748544 0.825592 0.561786 0.879082 0.532637 0.809795 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 206
Initial state: 0 0.588145 0.832312 0.089976 0.326192 0.592424 0.861951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167248 episodes
GETTING ACTION FROM:
action 2, numVisits=167240, meanQ=5.028437, numObservations: 4
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.588145 0.832312 0.089976 0.326192 0.592424 0.861951 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27636, meanQ=8.310867, numObservations: 4
action 1, numVisits=54, meanQ=7.294819, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 69204 episodes
GETTING ACTION FROM:
action 3, numVisits=40761, meanQ=7.494765, numObservations: 4
action 1, numVisits=55476, meanQ=6.142177, numObservations: 3
action -1, numVisits=619, meanQ=0.045574, numObservations: 1
action 0, numVisits=40, meanQ=-1.338845, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.588145 0.832312 0.089976 0.326192 0.592424 0.861951 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 207
Initial state: 0 0.517178 0.800077 0.589171 0.840652 0.548677 0.747095 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165517 episodes
GETTING ACTION FROM:
action 1, numVisits=162501, meanQ=4.925706, numObservations: 4
action 3, numVisits=3009, meanQ=4.811085, numObservations: 4
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.517178 0.800077 0.589171 0.840652 0.548677 0.747095 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 208
Initial state: 0 0.507218 0.855294 0.375485 0.946818 0.652018 0.800478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167094 episodes
GETTING ACTION FROM:
action 3, numVisits=167036, meanQ=4.988228, numObservations: 3
action 0, numVisits=25, meanQ=3.604484, numObservations: 1
action 2, numVisits=19, meanQ=2.947905, numObservations: 4
action 1, numVisits=12, meanQ=2.085017, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.507218 0.855294 0.375485 0.946818 0.652018 0.800478 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 209
Initial state: 0 0.546568 0.891268 0.219071 0.234149 0.549241 0.869387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167398 episodes
GETTING ACTION FROM:
action 1, numVisits=167343, meanQ=5.039715, numObservations: 5
action -1, numVisits=38, meanQ=3.911291, numObservations: 1
action 0, numVisits=14, meanQ=2.854220, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.546568 0.891268 0.219071 0.234149 0.549241 0.869387 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12379, meanQ=5.665437, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 185914 episodes
GETTING ACTION FROM:
action 1, numVisits=198288, meanQ=5.103226, numObservations: 4
action -1, numVisits=5, meanQ=1.762000, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.546568 0.891268 0.219071 0.234149 0.549241 0.869387 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 210
Initial state: 0 0.60592 0.895892 0.511585 0.889337 0.391335 0.345791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165582 episodes
GETTING ACTION FROM:
action 2, numVisits=165506, meanQ=4.928868, numObservations: 3
action 0, numVisits=40, meanQ=3.783657, numObservations: 1
action -1, numVisits=29, meanQ=3.627626, numObservations: 1
action 3, numVisits=6, meanQ=1.331683, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.60592 0.895892 0.511585 0.889337 0.391335 0.345791 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 211
Initial state: 0 0.678389 0.815624 0.132043 0.920634 0.540433 0.811941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91068 episodes
GETTING ACTION FROM:
action -1, numVisits=91060, meanQ=2.662454, numObservations: 1
action 0, numVisits=3, meanQ=-3.656600, numObservations: 1
action 2, numVisits=2, meanQ=-4.499950, numObservations: 1
action 3, numVisits=2, meanQ=-7.500000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.678389 0.815624 0.132043 0.920634 0.540433 0.811941 w: 1
Observation: 0 0.767352 0 0.170142 0 0.622333 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=79969, meanQ=4.943525, numObservations: 5
action -1, numVisits=11076, meanQ=3.035705, numObservations: 1
action 2, numVisits=11, meanQ=0.990000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 160497 episodes
GETTING ACTION FROM:
action 1, numVisits=240421, meanQ=4.980785, numObservations: 5
action 3, numVisits=46, meanQ=3.647615, numObservations: 4
action -1, numVisits=11076, meanQ=3.035705, numObservations: 1
action 2, numVisits=11, meanQ=0.990000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.678389 0.815624 0.132043 0.920634 0.540433 0.811941 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=17398, meanQ=5.378876, numObservations: 2
action 2, numVisits=7, meanQ=0.711443, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 204445 episodes
GETTING ACTION FROM:
action 3, numVisits=194112, meanQ=5.747765, numObservations: 4
action 0, numVisits=27732, meanQ=3.348655, numObservations: 2
action 2, numVisits=7, meanQ=0.711443, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.678389 0.815624 0.132043 0.920634 0.540433 0.811941 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=667, meanQ=7.317127, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 40998 episodes
GETTING ACTION FROM:
action 2, numVisits=1908, meanQ=6.752703, numObservations: 4
action 1, numVisits=39713, meanQ=6.014338, numObservations: 5
action -1, numVisits=33, meanQ=-1.430000, numObservations: 1
action 0, numVisits=15, meanQ=-1.934000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.678389 0.815624 0.132043 0.920634 0.540433 0.811941 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -1.14771
Run # 212
Initial state: 0 0.378349 0.989673 0.540541 0.897468 0.598155 0.892582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162027 episodes
GETTING ACTION FROM:
action 3, numVisits=162021, meanQ=4.894847, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.378349 0.989673 0.540541 0.897468 0.598155 0.892582 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6236, meanQ=4.747478, numObservations: 4
action -1, numVisits=5601, meanQ=2.788114, numObservations: 1
action 1, numVisits=14, meanQ=1.280743, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 205892 episodes
GETTING ACTION FROM:
action 2, numVisits=212128, meanQ=5.547968, numObservations: 4
action -1, numVisits=5601, meanQ=2.788114, numObservations: 1
action 1, numVisits=14, meanQ=1.280743, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.378349 0.989673 0.540541 0.897468 0.598155 0.892582 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 213
Initial state: 0 0.613134 0.864238 0.0314965 0.319277 0.614741 0.853371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166532 episodes
GETTING ACTION FROM:
action 1, numVisits=166526, meanQ=5.014972, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.613134 0.864238 0.0314965 0.319277 0.614741 0.853371 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 214
Initial state: 0 0.570943 0.862459 0.939327 0.129203 0.504964 0.889882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165150 episodes
GETTING ACTION FROM:
action 3, numVisits=165144, meanQ=4.915287, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.570943 0.862459 0.939327 0.129203 0.504964 0.889882 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 215
Initial state: 0 0.523404 0.819131 0.534006 0.895202 0.107345 0.559751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166614 episodes
GETTING ACTION FROM:
action 1, numVisits=166574, meanQ=4.970554, numObservations: 3
action -1, numVisits=35, meanQ=3.757167, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.523404 0.819131 0.534006 0.895202 0.107345 0.559751 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 216
Initial state: 0 0.553563 0.874846 0.653793 0.821551 0.444504 0.431865 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166478 episodes
GETTING ACTION FROM:
action 2, numVisits=166468, meanQ=5.011011, numObservations: 5
action -1, numVisits=4, meanQ=-2.502425, numObservations: 1
action 0, numVisits=4, meanQ=-2.502425, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.553563 0.874846 0.653793 0.821551 0.444504 0.431865 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 217
Initial state: 0 0.628586 0.882315 0.514174 0.817802 0.165526 0.230666 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166548 episodes
GETTING ACTION FROM:
action 3, numVisits=166534, meanQ=5.029291, numObservations: 5
action 2, numVisits=9, meanQ=2.656667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.628586 0.882315 0.514174 0.817802 0.165526 0.230666 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=19195, meanQ=8.404748, numObservations: 4
action 1, numVisits=4007, meanQ=8.348500, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 68633 episodes
GETTING ACTION FROM:
action 1, numVisits=7816, meanQ=7.152332, numObservations: 5
action 2, numVisits=83175, meanQ=6.584107, numObservations: 4
action 0, numVisits=758, meanQ=0.187665, numObservations: 1
action -1, numVisits=88, meanQ=-0.267500, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.628586 0.882315 0.514174 0.817802 0.165526 0.230666 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 218
Initial state: 0 0.511101 0.886277 0.128217 0.799285 0.656826 0.837223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165436 episodes
GETTING ACTION FROM:
action 3, numVisits=165411, meanQ=4.960239, numObservations: 4
action -1, numVisits=19, meanQ=3.293207, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.511101 0.886277 0.128217 0.799285 0.656826 0.837223 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 219
Initial state: 0 0.617274 0.814864 0.651127 0.803898 0.897654 0.926634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97775 episodes
GETTING ACTION FROM:
action 0, numVisits=97762, meanQ=2.930251, numObservations: 1
action 3, numVisits=9, meanQ=0.667800, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.617274 0.814864 0.651127 0.803898 0.897654 0.926634 w: 1
Observation: 0 0 0.818678 0 0.81457 0 0.999071 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=97600, meanQ=4.957885, numObservations: 5
action -1, numVisits=147, meanQ=4.415868, numObservations: 1
action 1, numVisits=6, meanQ=1.015000, numObservations: 2
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 165593 episodes
GETTING ACTION FROM:
action 3, numVisits=263188, meanQ=4.959881, numObservations: 5
action -1, numVisits=152, meanQ=4.393626, numObservations: 1
action 1, numVisits=6, meanQ=1.015000, numObservations: 2
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.617274 0.814864 0.651127 0.803898 0.897654 0.926634 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 220
Initial state: 0 0.601652 0.896425 0.699154 0.816779 0.0830285 0.178962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95669 episodes
GETTING ACTION FROM:
action 0, numVisits=76716, meanQ=2.974489, numObservations: 1
action -1, numVisits=18948, meanQ=2.908374, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.601652 0.896425 0.699154 0.816779 0.0830285 0.178962 w: 1
Observation: 0 0 0.913385 0 0.747111 0 0.234024 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=76708, meanQ=5.061442, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 163123 episodes
GETTING ACTION FROM:
action 1, numVisits=239814, meanQ=5.119337, numObservations: 5
action 3, numVisits=18, meanQ=3.378344, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.601652 0.896425 0.699154 0.816779 0.0830285 0.178962 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 221
Initial state: 0 0.551327 0.841517 0.512856 0.880994 0.208557 0.409113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166834 episodes
GETTING ACTION FROM:
action 2, numVisits=166802, meanQ=5.042438, numObservations: 4
action -1, numVisits=22, meanQ=3.577026, numObservations: 1
action 3, numVisits=7, meanQ=0.854286, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.551327 0.841517 0.512856 0.880994 0.208557 0.409113 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 222
Initial state: 0 0.637755 0.864324 0.197856 0.93729 0.658153 0.857771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157110 episodes
GETTING ACTION FROM:
action 2, numVisits=157092, meanQ=4.863126, numObservations: 5
action 3, numVisits=13, meanQ=2.616938, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.637755 0.864324 0.197856 0.93729 0.658153 0.857771 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=11548, meanQ=3.563766, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 206392 episodes
GETTING ACTION FROM:
action 1, numVisits=205613, meanQ=6.199922, numObservations: 4
action 0, numVisits=12329, meanQ=3.285056, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.637755 0.864324 0.197856 0.93729 0.658153 0.857771 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 223
Initial state: 0 0.549985 0.850786 0.474841 0.797252 0.561138 0.844716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166554 episodes
GETTING ACTION FROM:
action 2, numVisits=166366, meanQ=4.970562, numObservations: 4
action 1, numVisits=96, meanQ=4.164689, numObservations: 3
action 0, numVisits=73, meanQ=4.164465, numObservations: 1
action -1, numVisits=18, meanQ=3.183986, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.549985 0.850786 0.474841 0.797252 0.561138 0.844716 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=18801, meanQ=8.537181, numObservations: 3
action 3, numVisits=13, meanQ=5.922323, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 60205 episodes
GETTING ACTION FROM:
action 1, numVisits=32700, meanQ=7.433383, numObservations: 3
action 3, numVisits=44459, meanQ=5.900929, numObservations: 5
action -1, numVisits=1851, meanQ=-0.199708, numObservations: 1
action 0, numVisits=11, meanQ=-2.091800, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.549985 0.850786 0.474841 0.797252 0.561138 0.844716 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 224
Initial state: 0 0.0955397 0.180199 0.54294 0.827287 0.564234 0.863262 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166376 episodes
GETTING ACTION FROM:
action 2, numVisits=166369, meanQ=4.997182, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0955397 0.180199 0.54294 0.827287 0.564234 0.863262 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 225
Initial state: 0 0.694793 0.824424 0.557818 0.889499 0.675727 0.49715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163521 episodes
GETTING ACTION FROM:
action 2, numVisits=163486, meanQ=4.939441, numObservations: 5
action -1, numVisits=31, meanQ=3.637445, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.694793 0.824424 0.557818 0.889499 0.675727 0.49715 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1540, meanQ=4.258897, numObservations: 5
action -1, numVisits=19, meanQ=2.865294, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 45497 episodes
GETTING ACTION FROM:
action 1, numVisits=28318, meanQ=5.717170, numObservations: 5
action 0, numVisits=18450, meanQ=-0.175933, numObservations: 1
action -1, numVisits=290, meanQ=-1.056700, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.694793 0.824424 0.557818 0.889499 0.675727 0.49715 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 226
Initial state: 0 0.652342 0.886372 0.516023 0.803371 0.0491516 0.334047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166387 episodes
GETTING ACTION FROM:
action 1, numVisits=166285, meanQ=4.926644, numObservations: 4
action -1, numVisits=81, meanQ=4.150127, numObservations: 1
action 2, numVisits=13, meanQ=2.846154, numObservations: 2
action 3, numVisits=6, meanQ=1.166683, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.652342 0.886372 0.516023 0.803371 0.0491516 0.334047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 227
Initial state: 0 0.681968 0.86623 0.694376 0.857852 0.785694 0.168496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166939 episodes
GETTING ACTION FROM:
action 1, numVisits=166932, meanQ=4.999790, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.681968 0.86623 0.694376 0.857852 0.785694 0.168496 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 228
Initial state: 0 0.522358 0.821535 0.689977 0.820059 0.212975 0.693468 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165166 episodes
GETTING ACTION FROM:
action 1, numVisits=164623, meanQ=4.953506, numObservations: 5
action 2, numVisits=461, meanQ=4.453610, numObservations: 5
action -1, numVisits=58, meanQ=3.907287, numObservations: 1
action 3, numVisits=22, meanQ=3.089550, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.522358 0.821535 0.689977 0.820059 0.212975 0.693468 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 229
Initial state: 0 0.603341 0.883706 0.90956 0.58918 0.672971 0.876072 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166120 episodes
GETTING ACTION FROM:
action 2, numVisits=166056, meanQ=4.977590, numObservations: 4
action 0, numVisits=50, meanQ=3.949064, numObservations: 1
action 3, numVisits=8, meanQ=2.375000, numObservations: 2
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.603341 0.883706 0.90956 0.58918 0.672971 0.876072 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 230
Initial state: 0 0.49934 0.79903 0.683061 0.806818 0.527743 0.802519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165822 episodes
GETTING ACTION FROM:
action 3, numVisits=165806, meanQ=4.929594, numObservations: 5
action 1, numVisits=7, meanQ=2.285729, numObservations: 3
action 2, numVisits=5, meanQ=1.198020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.49934 0.79903 0.683061 0.806818 0.527743 0.802519 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 231
Initial state: 0 0.531876 0.803796 0.571539 0.800841 0.956095 0.507435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165152 episodes
GETTING ACTION FROM:
action 1, numVisits=165094, meanQ=4.977780, numObservations: 4
action 0, numVisits=51, meanQ=4.002347, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.531876 0.803796 0.571539 0.800841 0.956095 0.507435 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 232
Initial state: 0 0.508303 0.831115 0.628611 0.0249906 0.631712 0.850929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160016 episodes
GETTING ACTION FROM:
action 2, numVisits=150254, meanQ=5.182985, numObservations: 4
action 0, numVisits=9755, meanQ=3.224984, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.508303 0.831115 0.628611 0.0249906 0.631712 0.850929 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 233
Initial state: 0 0.658857 0.848993 0.590496 0.80006 0.225462 0.231411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166501 episodes
GETTING ACTION FROM:
action 3, numVisits=166472, meanQ=4.959076, numObservations: 5
action -1, numVisits=25, meanQ=3.483468, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.658857 0.848993 0.590496 0.80006 0.225462 0.231411 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=23337, meanQ=8.403993, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 49666 episodes
GETTING ACTION FROM:
action 1, numVisits=71844, meanQ=6.758997, numObservations: 4
action 2, numVisits=87, meanQ=3.462434, numObservations: 4
action 0, numVisits=1057, meanQ=-0.556697, numObservations: 1
action -1, numVisits=19, meanQ=-1.947895, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.658857 0.848993 0.590496 0.80006 0.225462 0.231411 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 234
Initial state: 0 0.675102 0.823338 0.588769 0.829916 0.762972 0.313404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 109027 episodes
GETTING ACTION FROM:
action 0, numVisits=95789, meanQ=5.828507, numObservations: 3
action 1, numVisits=13216, meanQ=4.929113, numObservations: 4
action 2, numVisits=19, meanQ=2.622105, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.675102 0.823338 0.588769 0.829916 0.762972 0.313404 w: 1
Observation: 0 0 0.815267 0 0.739494 0 0.36945 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=34811, meanQ=7.832464, numObservations: 5
action 1, numVisits=27, meanQ=6.470370, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 170028 episodes
GETTING ACTION FROM:
action 2, numVisits=204658, meanQ=5.424347, numObservations: 5
action -1, numVisits=106, meanQ=4.752467, numObservations: 1
action 1, numVisits=102, meanQ=4.674922, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.675102 0.823338 0.588769 0.829916 0.762972 0.313404 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 235
Initial state: 0 0.615617 0.803468 0.740412 0.775773 0.546246 0.822614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166420 episodes
GETTING ACTION FROM:
action 2, numVisits=166413, meanQ=5.013769, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.615617 0.803468 0.740412 0.775773 0.546246 0.822614 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 236
Initial state: 0 0.560409 0.864662 0.627035 0.84296 0.81724 0.539791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166903 episodes
GETTING ACTION FROM:
action 1, numVisits=166873, meanQ=5.021895, numObservations: 4
action -1, numVisits=26, meanQ=3.556131, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.560409 0.864662 0.627035 0.84296 0.81724 0.539791 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 237
Initial state: 0 0.606794 0.899794 0.741639 0.93499 0.554499 0.826405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163829 episodes
GETTING ACTION FROM:
action 3, numVisits=162392, meanQ=5.028337, numObservations: 4
action 2, numVisits=1432, meanQ=4.856496, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.606794 0.899794 0.741639 0.93499 0.554499 0.826405 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 238
Initial state: 0 0.53178 0.884127 0.564455 0.837486 0.333207 0.0109346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166379 episodes
GETTING ACTION FROM:
action 3, numVisits=166359, meanQ=5.030152, numObservations: 3
action 2, numVisits=15, meanQ=2.866000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.53178 0.884127 0.564455 0.837486 0.333207 0.0109346 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 239
Initial state: 0 0.725786 0.0106515 0.652965 0.85952 0.500317 0.861363 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166072 episodes
GETTING ACTION FROM:
action 1, numVisits=166053, meanQ=4.986445, numObservations: 5
action 3, numVisits=11, meanQ=2.362745, numObservations: 3
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.725786 0.0106515 0.652965 0.85952 0.500317 0.861363 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 240
Initial state: 0 0.523295 0.809925 0.254374 0.369482 0.625734 0.897631 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166324 episodes
GETTING ACTION FROM:
action 1, numVisits=166243, meanQ=5.018748, numObservations: 4
action 0, numVisits=43, meanQ=3.957203, numObservations: 1
action -1, numVisits=36, meanQ=3.847970, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.523295 0.809925 0.254374 0.369482 0.625734 0.897631 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 241
Initial state: 0 0.515981 0.881533 0.586957 0.286813 0.644258 0.88086 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167196 episodes
GETTING ACTION FROM:
action 1, numVisits=167190, meanQ=5.159363, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.515981 0.881533 0.586957 0.286813 0.644258 0.88086 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 242
Initial state: 0 0.0794418 0.297725 0.683402 0.873994 0.514691 0.801774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166407 episodes
GETTING ACTION FROM:
action 3, numVisits=166387, meanQ=4.964411, numObservations: 5
action -1, numVisits=16, meanQ=3.209393, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.0794418 0.297725 0.683402 0.873994 0.514691 0.801774 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 243
Initial state: 0 0.695112 0.453277 0.551311 0.835158 0.557535 0.848159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166818 episodes
GETTING ACTION FROM:
action 2, numVisits=166675, meanQ=5.012016, numObservations: 4
action 0, numVisits=139, meanQ=4.429815, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.695112 0.453277 0.551311 0.835158 0.557535 0.848159 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 244
Initial state: 0 0.57462 0.881552 0.514403 0.814605 0.436283 0.266641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166411 episodes
GETTING ACTION FROM:
action 1, numVisits=166397, meanQ=5.020240, numObservations: 4
action 3, numVisits=9, meanQ=1.555567, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.57462 0.881552 0.514403 0.814605 0.436283 0.266641 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 245
Initial state: 0 0.683509 0.89854 0.622422 0.882613 0.964522 0.15522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166700 episodes
GETTING ACTION FROM:
action 2, numVisits=166683, meanQ=5.040141, numObservations: 4
action -1, numVisits=9, meanQ=2.730000, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.683509 0.89854 0.622422 0.882613 0.964522 0.15522 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 246
Initial state: 0 0.544649 0.880138 0.681738 0.837269 0.272056 0.248144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166690 episodes
GETTING ACTION FROM:
action 2, numVisits=166684, meanQ=5.128659, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.544649 0.880138 0.681738 0.837269 0.272056 0.248144 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 247
Initial state: 0 0.509153 0.85018 0.0200908 0.178704 0.555226 0.885306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166492 episodes
GETTING ACTION FROM:
action 1, numVisits=48031, meanQ=5.000133, numObservations: 5
action 3, numVisits=118410, meanQ=4.979069, numObservations: 5
action -1, numVisits=48, meanQ=4.002436, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.509153 0.85018 0.0200908 0.178704 0.555226 0.885306 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 248
Initial state: 0 0.570475 0.000772868 0.539147 0.850233 0.535306 0.828268 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98042 episodes
GETTING ACTION FROM:
action 0, numVisits=97898, meanQ=2.977247, numObservations: 1
action -1, numVisits=141, meanQ=2.427204, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.570475 0.000772868 0.539147 0.850233 0.535306 0.828268 w: 1
Observation: 0 0 0.0154211 0 0.910289 0 0.766259 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=97833, meanQ=5.031567, numObservations: 3
action -1, numVisits=49, meanQ=4.061685, numObservations: 1
action 3, numVisits=10, meanQ=2.598000, numObservations: 3
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 168757 episodes
GETTING ACTION FROM:
action 2, numVisits=266589, meanQ=5.220496, numObservations: 3
action -1, numVisits=50, meanQ=4.026383, numObservations: 1
action 3, numVisits=10, meanQ=2.598000, numObservations: 3
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.570475 0.000772868 0.539147 0.850233 0.535306 0.828268 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 249
Initial state: 0 0.499728 0.951907 0.65985 0.859739 0.605809 0.823155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164961 episodes
GETTING ACTION FROM:
action 1, numVisits=164906, meanQ=4.906633, numObservations: 5
action 0, numVisits=51, meanQ=3.684005, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.499728 0.951907 0.65985 0.859739 0.605809 0.823155 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12167, meanQ=4.589820, numObservations: 5
action 0, numVisits=35, meanQ=3.563809, numObservations: 1
action 3, numVisits=9, meanQ=1.432222, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 205842 episodes
GETTING ACTION FROM:
action 2, numVisits=218004, meanQ=5.862326, numObservations: 5
action 0, numVisits=40, meanQ=2.968075, numObservations: 1
action 3, numVisits=9, meanQ=1.432222, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.499728 0.951907 0.65985 0.859739 0.605809 0.823155 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 250
Initial state: 0 0.890578 0.749688 0.563945 0.882737 0.550149 0.893732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97530 episodes
GETTING ACTION FROM:
action -1, numVisits=97523, meanQ=2.893654, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.890578 0.749688 0.563945 0.882737 0.550149 0.893732 w: 1
Observation: 0 0.98939 0 0.663319 0 0.502531 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=97307, meanQ=4.980154, numObservations: 5
action 0, numVisits=211, meanQ=4.431123, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 163933 episodes
GETTING ACTION FROM:
action 2, numVisits=261239, meanQ=4.941571, numObservations: 5
action 0, numVisits=212, meanQ=4.426616, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.890578 0.749688 0.563945 0.882737 0.550149 0.893732 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 251
Initial state: 0 0.528917 0.852151 0.00940362 0.102908 0.690106 0.817724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166478 episodes
GETTING ACTION FROM:
action 2, numVisits=166213, meanQ=4.980475, numObservations: 4
action 0, numVisits=259, meanQ=2.278624, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.528917 0.852151 0.00940362 0.102908 0.690106 0.817724 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27153, meanQ=8.320869, numObservations: 3
action 1, numVisits=218, meanQ=7.899771, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 92764 episodes
GETTING ACTION FROM:
action 3, numVisits=114289, meanQ=6.668514, numObservations: 3
action 1, numVisits=2451, meanQ=6.328775, numObservations: 5
action -1, numVisits=3376, meanQ=0.406964, numObservations: 1
action 0, numVisits=21, meanQ=-1.104286, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.528917 0.852151 0.00940362 0.102908 0.690106 0.817724 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 252
Initial state: 0 0.616292 0.846321 0.856529 0.47656 0.591368 0.875809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164522 episodes
GETTING ACTION FROM:
action 1, numVisits=164458, meanQ=4.953033, numObservations: 4
action 0, numVisits=29, meanQ=3.671097, numObservations: 1
action 2, numVisits=23, meanQ=3.235652, numObservations: 4
action 3, numVisits=10, meanQ=2.189000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.616292 0.846321 0.856529 0.47656 0.591368 0.875809 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 253
Initial state: 0 0.596724 0.865011 0.597834 0.899945 0.47838 0.0962151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166226 episodes
GETTING ACTION FROM:
action 1, numVisits=166220, meanQ=5.007328, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.596724 0.865011 0.597834 0.899945 0.47838 0.0962151 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 254
Initial state: 0 0.578123 0.896033 0.577811 0.81681 0.157412 0.0284847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159055 episodes
GETTING ACTION FROM:
action 2, numVisits=159031, meanQ=4.923023, numObservations: 4
action 1, numVisits=19, meanQ=3.052637, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.578123 0.896033 0.577811 0.81681 0.157412 0.0284847 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 255
Initial state: 0 0.163954 0.471609 0.666787 0.895328 0.634217 0.89829 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167048 episodes
GETTING ACTION FROM:
action 1, numVisits=167013, meanQ=5.027435, numObservations: 3
action -1, numVisits=22, meanQ=3.518973, numObservations: 1
action 2, numVisits=10, meanQ=2.281010, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.163954 0.471609 0.666787 0.895328 0.634217 0.89829 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=27317, meanQ=8.326096, numObservations: 5
action 3, numVisits=23, meanQ=6.652183, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 85846 episodes
GETTING ACTION FROM:
action 2, numVisits=92545, meanQ=6.728712, numObservations: 5
action 3, numVisits=18160, meanQ=5.731557, numObservations: 4
action -1, numVisits=2477, meanQ=-0.685624, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=6, meanQ=-61.795799, numObservations: 1
action: 2
Next state: 1 0.163954 0.471609 0.666787 0.895328 0.634217 0.89829 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 256
Initial state: 0 0.446294 0.55497 0.580314 0.843075 0.625425 0.865694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166532 episodes
GETTING ACTION FROM:
action 1, numVisits=166523, meanQ=5.139374, numObservations: 5
action 3, numVisits=3, meanQ=0.663333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.446294 0.55497 0.580314 0.843075 0.625425 0.865694 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9862, meanQ=7.878843, numObservations: 5
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 71781 episodes
GETTING ACTION FROM:
action 3, numVisits=78488, meanQ=6.389398, numObservations: 5
action 2, numVisits=61, meanQ=3.814597, numObservations: 3
action -1, numVisits=3090, meanQ=0.431107, numObservations: 1
action 0, numVisits=8, meanQ=-2.126225, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.446294 0.55497 0.580314 0.843075 0.625425 0.865694 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 257
Initial state: 0 0.539136 0.835908 0.684837 0.834142 0.899638 0.699564 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 103657 episodes
GETTING ACTION FROM:
action 3, numVisits=13934, meanQ=5.005895, numObservations: 4
action -1, numVisits=89719, meanQ=2.935804, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.539136 0.835908 0.684837 0.834142 0.899638 0.699564 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 258
Initial state: 0 0.525776 0.629561 0.642332 0.882487 0.636038 0.848253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166375 episodes
GETTING ACTION FROM:
action 3, numVisits=166369, meanQ=4.953153, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.525776 0.629561 0.642332 0.882487 0.636038 0.848253 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 259
Initial state: 0 0.636901 0.856597 0.598604 0.809282 0.0938724 0.152462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166513 episodes
GETTING ACTION FROM:
action 1, numVisits=166301, meanQ=5.026908, numObservations: 5
action 0, numVisits=32, meanQ=3.807396, numObservations: 1
action 2, numVisits=177, meanQ=3.609608, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.636901 0.856597 0.598604 0.809282 0.0938724 0.152462 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 260
Initial state: 0 0.560936 0.860953 0.619392 0.856394 0.357711 0.781227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166222 episodes
GETTING ACTION FROM:
action 2, numVisits=166199, meanQ=4.961682, numObservations: 5
action -1, numVisits=19, meanQ=3.342684, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.560936 0.860953 0.619392 0.856394 0.357711 0.781227 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 261
Initial state: 0 0.40737 0.746826 0.622474 0.837653 0.679731 0.839491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166453 episodes
GETTING ACTION FROM:
action 1, numVisits=166435, meanQ=4.983648, numObservations: 4
action 0, numVisits=14, meanQ=3.113013, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.40737 0.746826 0.622474 0.837653 0.679731 0.839491 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23124, meanQ=8.408708, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 51741 episodes
GETTING ACTION FROM:
action 3, numVisits=73181, meanQ=6.748334, numObservations: 4
action 2, numVisits=11, meanQ=1.180918, numObservations: 3
action 0, numVisits=1598, meanQ=0.124963, numObservations: 2
action -1, numVisits=78, meanQ=-0.566596, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.40737 0.746826 0.622474 0.837653 0.679731 0.839491 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 262
Initial state: 0 0.594577 0.837278 0.814308 0.630258 0.571432 0.834928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158455 episodes
GETTING ACTION FROM:
action 1, numVisits=158421, meanQ=4.864068, numObservations: 3
action 2, numVisits=28, meanQ=1.761046, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.594577 0.837278 0.814308 0.630258 0.571432 0.834928 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 263
Initial state: 0 0.116098 0.269787 0.642596 0.889213 0.665961 0.827026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166738 episodes
GETTING ACTION FROM:
action 3, numVisits=166690, meanQ=5.010999, numObservations: 3
action 2, numVisits=38, meanQ=3.858687, numObservations: 3
action 1, numVisits=6, meanQ=1.166683, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.116098 0.269787 0.642596 0.889213 0.665961 0.827026 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.602322 0.446626 0.620056 0.812253 0.571681 0.825576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166658 episodes
GETTING ACTION FROM:
action 1, numVisits=166606, meanQ=5.033133, numObservations: 5
action 0, numVisits=48, meanQ=4.042122, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.602322 0.446626 0.620056 0.812253 0.571681 0.825576 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 265
Initial state: 0 0.652509 0.847375 0.573913 0.865979 0.0861467 0.316978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167434 episodes
GETTING ACTION FROM:
action 1, numVisits=167428, meanQ=5.048442, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.652509 0.847375 0.573913 0.865979 0.0861467 0.316978 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 266
Initial state: 0 0.919577 0.107839 0.687671 0.87811 0.592151 0.829695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98433 episodes
GETTING ACTION FROM:
action -1, numVisits=98428, meanQ=2.993468, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.919577 0.107839 0.687671 0.87811 0.592151 0.829695 w: 1
Observation: 0 0.819925 0 0.722121 0 0.50343 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=98398, meanQ=5.032624, numObservations: 5
action -1, numVisits=15, meanQ=3.193223, numObservations: 1
action 1, numVisits=11, meanQ=1.361818, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 169364 episodes
GETTING ACTION FROM:
action 3, numVisits=267761, meanQ=4.980825, numObservations: 5
action -1, numVisits=16, meanQ=3.132965, numObservations: 1
action 1, numVisits=11, meanQ=1.361818, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.919577 0.107839 0.687671 0.87811 0.592151 0.829695 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 267
Initial state: 0 0.523661 0.830047 0.637746 0.644334 0.693223 0.824003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98048 episodes
GETTING ACTION FROM:
action 0, numVisits=98043, meanQ=2.950110, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.523661 0.830047 0.637746 0.644334 0.693223 0.824003 w: 1
Observation: 0 0 0.87775 0 0.628435 0 0.916783 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=97809, meanQ=5.010856, numObservations: 5
action 2, numVisits=107, meanQ=4.343989, numObservations: 3
action 3, numVisits=106, meanQ=4.294571, numObservations: 4
action -1, numVisits=18, meanQ=3.395560, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 169129 episodes
GETTING ACTION FROM:
action 1, numVisits=266934, meanQ=4.993822, numObservations: 5
action 3, numVisits=106, meanQ=4.294571, numObservations: 4
action 2, numVisits=110, meanQ=4.224948, numObservations: 3
action -1, numVisits=19, meanQ=3.349110, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.523661 0.830047 0.637746 0.644334 0.693223 0.824003 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 268
Initial state: 0 0.955046 0.817195 0.626534 0.882561 0.663498 0.86698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163933 episodes
GETTING ACTION FROM:
action 3, numVisits=163879, meanQ=4.977922, numObservations: 5
action -1, numVisits=29, meanQ=3.611528, numObservations: 1
action 0, numVisits=20, meanQ=3.354234, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.955046 0.817195 0.626534 0.882561 0.663498 0.86698 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 269
Initial state: 0 0.586877 0.852868 0.610743 0.847622 0.642761 0.00323839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158072 episodes
GETTING ACTION FROM:
action 1, numVisits=158065, meanQ=4.815611, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.586877 0.852868 0.610743 0.847622 0.642761 0.00323839 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 270
Initial state: 0 0.581443 0.800825 0.572464 0.812808 0.284815 0.275271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166583 episodes
GETTING ACTION FROM:
action 1, numVisits=166569, meanQ=4.989921, numObservations: 4
action 2, numVisits=9, meanQ=2.223344, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.581443 0.800825 0.572464 0.812808 0.284815 0.275271 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 271
Initial state: 0 0.5647 0.810083 0.487805 0.613745 0.619867 0.812394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166068 episodes
GETTING ACTION FROM:
action 3, numVisits=165996, meanQ=4.913018, numObservations: 4
action -1, numVisits=67, meanQ=4.065483, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.5647 0.810083 0.487805 0.613745 0.619867 0.812394 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 272
Initial state: 0 0.533608 0.816659 0.0485273 0.601317 0.602141 0.808185 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158357 episodes
GETTING ACTION FROM:
action 3, numVisits=158310, meanQ=4.881239, numObservations: 4
action -1, numVisits=43, meanQ=3.813550, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.533608 0.816659 0.0485273 0.601317 0.602141 0.808185 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 273
Initial state: 0 0.545534 0.861144 0.0410554 0.694696 0.661576 0.855292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158461 episodes
GETTING ACTION FROM:
action 3, numVisits=158415, meanQ=4.850549, numObservations: 3
action 0, numVisits=42, meanQ=3.774180, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.545534 0.861144 0.0410554 0.694696 0.661576 0.855292 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 274
Initial state: 0 0.534778 0.821016 0.303333 0.577312 0.534624 0.885506 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165507 episodes
GETTING ACTION FROM:
action 3, numVisits=165478, meanQ=4.941559, numObservations: 4
action 0, numVisits=18, meanQ=3.126255, numObservations: 1
action 1, numVisits=6, meanQ=1.333333, numObservations: 3
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.534778 0.821016 0.303333 0.577312 0.534624 0.885506 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 275
Initial state: 0 0.829859 0.972035 0.534962 0.847434 0.567102 0.884664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166652 episodes
GETTING ACTION FROM:
action 3, numVisits=166572, meanQ=4.990786, numObservations: 3
action 0, numVisits=56, meanQ=4.041557, numObservations: 1
action -1, numVisits=12, meanQ=2.950008, numObservations: 1
action 1, numVisits=11, meanQ=2.363636, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.829859 0.972035 0.534962 0.847434 0.567102 0.884664 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 276
Initial state: 0 0.570583 0.815178 0.444631 0.653234 0.692029 0.830254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167309 episodes
GETTING ACTION FROM:
action 1, numVisits=167303, meanQ=5.002525, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.570583 0.815178 0.444631 0.653234 0.692029 0.830254 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 277
Initial state: 0 0.604324 0.895439 0.566706 0.819698 0.336361 0.422896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165539 episodes
GETTING ACTION FROM:
action 1, numVisits=165441, meanQ=4.949892, numObservations: 5
action 0, numVisits=53, meanQ=3.996296, numObservations: 1
action 3, numVisits=42, meanQ=3.543105, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.604324 0.895439 0.566706 0.819698 0.336361 0.422896 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.447187 0.375379 0.545628 0.890328 0.668839 0.832513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166637 episodes
GETTING ACTION FROM:
action 2, numVisits=166591, meanQ=4.922639, numObservations: 4
action 0, numVisits=34, meanQ=3.730041, numObservations: 1
action 1, numVisits=9, meanQ=2.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.447187 0.375379 0.545628 0.890328 0.668839 0.832513 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 279
Initial state: 0 0.387252 0.998521 0.622444 0.85271 0.66308 0.894893 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166033 episodes
GETTING ACTION FROM:
action 2, numVisits=166010, meanQ=4.983173, numObservations: 4
action 0, numVisits=18, meanQ=3.259664, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.387252 0.998521 0.622444 0.85271 0.66308 0.894893 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 280
Initial state: 0 0.730835 0.695643 0.665269 0.866045 0.564684 0.854484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165439 episodes
GETTING ACTION FROM:
action 1, numVisits=165390, meanQ=4.919023, numObservations: 4
action 2, numVisits=44, meanQ=3.700005, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.730835 0.695643 0.665269 0.866045 0.564684 0.854484 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 281
Initial state: 0 0.581003 0.898968 0.105791 0.999569 0.638171 0.872344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163486 episodes
GETTING ACTION FROM:
action 2, numVisits=163340, meanQ=4.968873, numObservations: 3
action -1, numVisits=94, meanQ=4.161063, numObservations: 1
action 0, numVisits=30, meanQ=3.624436, numObservations: 1
action 3, numVisits=12, meanQ=2.900833, numObservations: 4
action 1, numVisits=10, meanQ=2.499000, numObservations: 3
action: 2
Next state: 0 0.581003 0.898968 0.105791 0.999569 0.638171 0.872344 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7162, meanQ=5.784497, numObservations: 4
action -1, numVisits=4932, meanQ=2.739829, numObservations: 1
action 3, numVisits=7, meanQ=0.428571, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
Sampled 189840 episodes
GETTING ACTION FROM:
action 2, numVisits=197002, meanQ=5.172038, numObservations: 5
action -1, numVisits=4932, meanQ=2.739829, numObservations: 1
action 3, numVisits=7, meanQ=0.428571, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 0 0.581003 0.898968 0.105791 0.999569 0.638171 0.872344 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2450, meanQ=8.210276, numObservations: 4
action 3, numVisits=19, meanQ=6.683158, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 213158 episodes
GETTING ACTION FROM:
action 1, numVisits=215540, meanQ=6.384468, numObservations: 4
action 3, numVisits=87, meanQ=5.574484, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.581003 0.898968 0.105791 0.999569 0.638171 0.872344 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 282
Initial state: 0 0.569203 0.827452 0.320379 0.98778 0.527163 0.889435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167211 episodes
GETTING ACTION FROM:
action 3, numVisits=167142, meanQ=5.001939, numObservations: 4
action -1, numVisits=63, meanQ=4.122600, numObservations: 1
action 2, numVisits=3, meanQ=0.000033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.569203 0.827452 0.320379 0.98778 0.527163 0.889435 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 283
Initial state: 0 0.571574 0.854777 0.681687 0.867712 0.916827 0.974523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167690 episodes
GETTING ACTION FROM:
action 3, numVisits=167592, meanQ=5.039754, numObservations: 4
action -1, numVisits=78, meanQ=4.253687, numObservations: 1
action 0, numVisits=18, meanQ=3.178225, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.571574 0.854777 0.681687 0.867712 0.916827 0.974523 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 284
Initial state: 0 0.773127 0.727848 0.566085 0.857975 0.599913 0.865234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156440 episodes
GETTING ACTION FROM:
action 2, numVisits=156338, meanQ=4.803105, numObservations: 4
action 0, numVisits=98, meanQ=4.115431, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.773127 0.727848 0.566085 0.857975 0.599913 0.865234 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 285
Initial state: 0 0.66221 0.825248 0.603439 0.813682 0.86635 0.406225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165672 episodes
GETTING ACTION FROM:
action 3, numVisits=165664, meanQ=5.038636, numObservations: 4
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.66221 0.825248 0.603439 0.813682 0.86635 0.406225 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 286
Initial state: 0 0.591207 0.865984 0.147364 0.10956 0.686531 0.878194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165461 episodes
GETTING ACTION FROM:
action 2, numVisits=165448, meanQ=4.937527, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.591207 0.865984 0.147364 0.10956 0.686531 0.878194 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27398, meanQ=8.336204, numObservations: 3
action 1, numVisits=13, meanQ=5.460777, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 64811 episodes
GETTING ACTION FROM:
action 3, numVisits=91265, meanQ=6.570226, numObservations: 3
action 1, numVisits=296, meanQ=5.869914, numObservations: 5
action -1, numVisits=650, meanQ=-0.585750, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=13, meanQ=-4.189959, numObservations: 1
action: 3
Next state: 1 0.591207 0.865984 0.147364 0.10956 0.686531 0.878194 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 287
Initial state: 0 0.597359 0.839844 0.658864 0.808402 0.937364 0.176985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164339 episodes
GETTING ACTION FROM:
action 2, numVisits=164327, meanQ=4.921084, numObservations: 3
action 1, numVisits=7, meanQ=1.428571, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.597359 0.839844 0.658864 0.808402 0.937364 0.176985 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 288
Initial state: 0 0.856312 0.898462 0.502182 0.820853 0.625414 0.861113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165550 episodes
GETTING ACTION FROM:
action 1, numVisits=165522, meanQ=4.999463, numObservations: 5
action 2, numVisits=23, meanQ=0.693930, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.856312 0.898462 0.502182 0.820853 0.625414 0.861113 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 289
Initial state: 0 0.556222 0.827744 0.581774 0.872432 0.869582 0.415157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163704 episodes
GETTING ACTION FROM:
action 2, numVisits=162073, meanQ=4.992799, numObservations: 5
action 0, numVisits=1626, meanQ=1.304439, numObservations: 1
action 1, numVisits=2, meanQ=-3.505000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.556222 0.827744 0.581774 0.872432 0.869582 0.415157 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 290
Initial state: 0 0.675079 0.811158 0.423221 0.530426 0.629832 0.860506 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167012 episodes
GETTING ACTION FROM:
action 1, numVisits=166968, meanQ=4.993630, numObservations: 4
action 0, numVisits=39, meanQ=3.842792, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.675079 0.811158 0.423221 0.530426 0.629832 0.860506 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 291
Initial state: 0 0.560924 0.874436 0.822324 0.578627 0.519077 0.830937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165947 episodes
GETTING ACTION FROM:
action 2, numVisits=165873, meanQ=5.007914, numObservations: 5
action 0, numVisits=48, meanQ=4.017788, numObservations: 1
action 1, numVisits=23, meanQ=3.303483, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.560924 0.874436 0.822324 0.578627 0.519077 0.830937 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 292
Initial state: 0 0.13269 0.375163 0.610511 0.898789 0.582523 0.871824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166937 episodes
GETTING ACTION FROM:
action 2, numVisits=166868, meanQ=5.006438, numObservations: 5
action 0, numVisits=64, meanQ=4.135605, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.13269 0.375163 0.610511 0.898789 0.582523 0.871824 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 293
Initial state: 0 0.658997 0.885224 0.628764 0.595635 0.66397 0.868853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158952 episodes
GETTING ACTION FROM:
action 1, numVisits=158940, meanQ=4.874585, numObservations: 4
action 2, numVisits=7, meanQ=2.127143, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.658997 0.885224 0.628764 0.595635 0.66397 0.868853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 294
Initial state: 0 0.521853 0.85939 0.672939 0.188636 0.572969 0.863138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 103033 episodes
GETTING ACTION FROM:
action 0, numVisits=103027, meanQ=5.617936, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.521853 0.85939 0.672939 0.188636 0.572969 0.863138 w: 1
Observation: 0 0 0.852128 0 0.225127 0 0.942279 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=70958, meanQ=7.713646, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 165775 episodes
GETTING ACTION FROM:
action 1, numVisits=236733, meanQ=5.830919, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.521853 0.85939 0.672939 0.188636 0.572969 0.863138 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 295
Initial state: 0 0.731988 0.742231 0.689354 0.895847 0.627732 0.830169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165651 episodes
GETTING ACTION FROM:
action 3, numVisits=165345, meanQ=4.954059, numObservations: 5
action 2, numVisits=298, meanQ=4.420130, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.731988 0.742231 0.689354 0.895847 0.627732 0.830169 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 296
Initial state: 0 0.69504 0.803287 0.691262 0.0834545 0.500227 0.844149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166997 episodes
GETTING ACTION FROM:
action 3, numVisits=166968, meanQ=5.013021, numObservations: 4
action 0, numVisits=23, meanQ=3.551729, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.69504 0.803287 0.691262 0.0834545 0.500227 0.844149 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 297
Initial state: 0 0.398516 0.658635 0.502173 0.821578 0.599721 0.804387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166509 episodes
GETTING ACTION FROM:
action 1, numVisits=166503, meanQ=4.959736, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.398516 0.658635 0.502173 0.821578 0.599721 0.804387 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23275, meanQ=8.397503, numObservations: 5
action 2, numVisits=33, meanQ=7.115764, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 48313 episodes
GETTING ACTION FROM:
action 3, numVisits=55337, meanQ=6.833337, numObservations: 5
action 2, numVisits=14755, meanQ=5.779627, numObservations: 4
action -1, numVisits=1526, meanQ=-0.432845, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=5, meanQ=-74.616609, numObservations: 1
action: 3
Next state: 1 0.398516 0.658635 0.502173 0.821578 0.599721 0.804387 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 298
Initial state: 0 0.507489 0.537979 0.691609 0.867838 0.549127 0.806675 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165789 episodes
GETTING ACTION FROM:
action 3, numVisits=165750, meanQ=4.938746, numObservations: 4
action 1, numVisits=30, meanQ=2.287340, numObservations: 5
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.507489 0.537979 0.691609 0.867838 0.549127 0.806675 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 299
Initial state: 0 0.865748 0.768128 0.645678 0.859458 0.580747 0.880449 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166198 episodes
GETTING ACTION FROM:
action 2, numVisits=166034, meanQ=4.933505, numObservations: 4
action -1, numVisits=70, meanQ=4.100690, numObservations: 1
action 0, numVisits=55, meanQ=3.987903, numObservations: 1
action 3, numVisits=38, meanQ=3.684221, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.865748 0.768128 0.645678 0.859458 0.580747 0.880449 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12178, meanQ=4.649983, numObservations: 5
action 0, numVisits=134, meanQ=4.156822, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 207323 episodes
GETTING ACTION FROM:
action 1, numVisits=219499, meanQ=5.609323, numObservations: 5
action 0, numVisits=136, meanQ=4.109783, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.865748 0.768128 0.645678 0.859458 0.580747 0.880449 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 300
Initial state: 0 0.860733 0.583335 0.654494 0.888954 0.531483 0.882919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156429 episodes
GETTING ACTION FROM:
action 1, numVisits=156423, meanQ=4.867672, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.860733 0.583335 0.654494 0.888954 0.531483 0.882919 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 301
Initial state: 0 0.567314 0.832158 0.658714 0.873388 0.630686 0.638997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166558 episodes
GETTING ACTION FROM:
action 2, numVisits=166477, meanQ=5.020146, numObservations: 4
action 0, numVisits=27, meanQ=3.675798, numObservations: 1
action 1, numVisits=49, meanQ=3.104102, numObservations: 3
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.567314 0.832158 0.658714 0.873388 0.630686 0.638997 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 302
Initial state: 0 0.679167 0.843055 0.544762 0.874669 0.161371 0.114965 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167257 episodes
GETTING ACTION FROM:
action 1, numVisits=166813, meanQ=5.043393, numObservations: 5
action 2, numVisits=415, meanQ=4.702229, numObservations: 3
action 0, numVisits=26, meanQ=3.683565, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.679167 0.843055 0.544762 0.874669 0.161371 0.114965 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 303
Initial state: 0 0.535026 0.844719 0.972992 0.300379 0.621766 0.884089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166420 episodes
GETTING ACTION FROM:
action 1, numVisits=166409, meanQ=4.984104, numObservations: 5
action 3, numVisits=6, meanQ=1.498333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.535026 0.844719 0.972992 0.300379 0.621766 0.884089 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12402, meanQ=5.404719, numObservations: 3
action 3, numVisits=8, meanQ=1.485000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 183430 episodes
GETTING ACTION FROM:
action 1, numVisits=195830, meanQ=4.870295, numObservations: 4
action 3, numVisits=8, meanQ=1.485000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.535026 0.844719 0.972992 0.300379 0.621766 0.884089 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 304
Initial state: 0 0.581913 0.85539 0.504402 0.888013 0.914213 0.510317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97826 episodes
GETTING ACTION FROM:
action -1, numVisits=97821, meanQ=2.914474, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.581913 0.85539 0.504402 0.888013 0.914213 0.510317 w: 1
Observation: 0 0.631888 0 0.574207 0 0.835582 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=97787, meanQ=4.971920, numObservations: 5
action 0, numVisits=27, meanQ=3.659716, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 167477 episodes
GETTING ACTION FROM:
action 2, numVisits=265263, meanQ=5.098107, numObservations: 5
action 0, numVisits=28, meanQ=3.625718, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.581913 0.85539 0.504402 0.888013 0.914213 0.510317 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 305
Initial state: 0 0.576325 0.84942 0.147767 0.315764 0.672453 0.810469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97907 episodes
GETTING ACTION FROM:
action -1, numVisits=97902, meanQ=2.907735, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.576325 0.84942 0.147767 0.315764 0.672453 0.810469 w: 1
Observation: 0 0.643837 0 0.238227 0 0.720221 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=97494, meanQ=4.969567, numObservations: 5
action 1, numVisits=329, meanQ=4.578943, numObservations: 4
action 0, numVisits=71, meanQ=4.178156, numObservations: 1
action 2, numVisits=5, meanQ=-0.201980, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 166304 episodes
GETTING ACTION FROM:
action 3, numVisits=263796, meanQ=4.990725, numObservations: 5
action 1, numVisits=329, meanQ=4.578943, numObservations: 4
action 0, numVisits=73, meanQ=4.168170, numObservations: 1
action 2, numVisits=5, meanQ=-0.201980, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.576325 0.84942 0.147767 0.315764 0.672453 0.810469 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 306
Initial state: 0 0.643176 0.835849 0.0510425 0.867105 0.594815 0.806112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166235 episodes
GETTING ACTION FROM:
action 3, numVisits=166169, meanQ=4.979860, numObservations: 4
action 0, numVisits=37, meanQ=3.797711, numObservations: 1
action -1, numVisits=17, meanQ=3.105003, numObservations: 1
action 2, numVisits=10, meanQ=2.300010, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 1 0.643176 0.835849 0.0510425 0.867105 0.594815 0.806112 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 307
Initial state: 0 0.557474 0.824027 0.555025 0.827969 0.892471 0.48773 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 110991 episodes
GETTING ACTION FROM:
action 3, numVisits=31292, meanQ=4.959272, numObservations: 5
action 0, numVisits=79276, meanQ=2.978942, numObservations: 1
action -1, numVisits=400, meanQ=2.665547, numObservations: 1
action 1, numVisits=19, meanQ=1.058426, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 4
action: 3
Next state: 2 0.557474 0.824027 0.555025 0.827969 0.892471 0.48773 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 308
Initial state: 0 0.559286 0.825175 0.626984 0.846901 0.726571 0.954553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166624 episodes
GETTING ACTION FROM:
action 2, numVisits=166618, meanQ=4.939491, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.559286 0.825175 0.626984 0.846901 0.726571 0.954553 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 309
Initial state: 0 0.607636 0.887403 0.693612 0.853787 0.494359 0.759991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157088 episodes
GETTING ACTION FROM:
action 2, numVisits=157066, meanQ=4.830029, numObservations: 4
action 1, numVisits=17, meanQ=3.117647, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.607636 0.887403 0.693612 0.853787 0.494359 0.759991 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 310
Initial state: 0 0.519407 0.835167 0.277885 0.349509 0.694944 0.858024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165203 episodes
GETTING ACTION FROM:
action 2, numVisits=165138, meanQ=4.988024, numObservations: 5
action 1, numVisits=50, meanQ=3.961602, numObservations: 4
action 3, numVisits=11, meanQ=2.729100, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.519407 0.835167 0.277885 0.349509 0.694944 0.858024 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23295, meanQ=8.397930, numObservations: 3
action 1, numVisits=12, meanQ=5.831675, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 41811 episodes
GETTING ACTION FROM:
action 3, numVisits=64969, meanQ=7.050455, numObservations: 3
action 1, numVisits=141, meanQ=4.346570, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=8, meanQ=-45.079348, numObservations: 1
action 0, numVisits=2, meanQ=-192.227514, numObservations: 1
action: 3
Next state: 1 0.519407 0.835167 0.277885 0.349509 0.694944 0.858024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 311
Initial state: 0 0.882156 0.481181 0.610567 0.807922 0.565857 0.851018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163168 episodes
GETTING ACTION FROM:
action 1, numVisits=162001, meanQ=4.966724, numObservations: 5
action -1, numVisits=1040, meanQ=2.704890, numObservations: 1
action 0, numVisits=113, meanQ=2.366364, numObservations: 1
action 2, numVisits=12, meanQ=0.825850, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 2 0.882156 0.481181 0.610567 0.807922 0.565857 0.851018 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 312
Initial state: 0 0.591171 0.839419 0.10774 0.7585 0.538144 0.832073 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166972 episodes
GETTING ACTION FROM:
action 3, numVisits=166953, meanQ=5.016764, numObservations: 5
action -1, numVisits=10, meanQ=2.485195, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 1, numVisits=3, meanQ=0.000033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.591171 0.839419 0.10774 0.7585 0.538144 0.832073 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 313
Initial state: 0 0.0331479 0.990018 0.548101 0.832112 0.678268 0.853119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166167 episodes
GETTING ACTION FROM:
action 1, numVisits=166161, meanQ=4.968767, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0331479 0.990018 0.548101 0.832112 0.678268 0.853119 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12365, meanQ=4.763899, numObservations: 4
action 0, numVisits=43, meanQ=3.859941, numObservations: 1
action 1, numVisits=5, meanQ=-1.402000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 202865 episodes
GETTING ACTION FROM:
action 2, numVisits=215226, meanQ=5.606038, numObservations: 4
action 0, numVisits=47, meanQ=3.469668, numObservations: 1
action 1, numVisits=5, meanQ=-1.402000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.0331479 0.990018 0.548101 0.832112 0.678268 0.853119 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=2765, meanQ=5.386190, numObservations: 1
action 1, numVisits=2167, meanQ=4.411919, numObservations: 4
action 3, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 208899 episodes
GETTING ACTION FROM:
action 1, numVisits=210637, meanQ=6.538792, numObservations: 4
action 0, numVisits=3194, meanQ=4.432947, numObservations: 1
action 3, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0331479 0.990018 0.548101 0.832112 0.678268 0.853119 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=43, meanQ=7.790467, numObservations: 3
action 2, numVisits=22, meanQ=6.984095, numObservations: 2
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 202660 episodes
GETTING ACTION FROM:
action 1, numVisits=334, meanQ=6.465010, numObservations: 4
action 2, numVisits=6504, meanQ=6.024456, numObservations: 3
action 3, numVisits=195877, meanQ=5.732386, numObservations: 5
action -1, numVisits=7, meanQ=-1.858571, numObservations: 1
action 0, numVisits=7, meanQ=-1.858571, numObservations: 1
action: 1
Next state: 1 0.0331479 0.990018 0.548101 0.832112 0.678268 0.853119 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 314
Initial state: 0 0.590365 0.866439 0.598912 0.834709 0.13621 0.729804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166249 episodes
GETTING ACTION FROM:
action 3, numVisits=166241, meanQ=5.003682, numObservations: 4
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.590365 0.866439 0.598912 0.834709 0.13621 0.729804 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=23425, meanQ=8.405537, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 47423 episodes
GETTING ACTION FROM:
action 1, numVisits=33870, meanQ=7.726564, numObservations: 4
action 2, numVisits=36969, meanQ=5.805196, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=6, meanQ=-60.956649, numObservations: 1
action -1, numVisits=6, meanQ=-60.973329, numObservations: 1
action: 1
Next state: 1 0.590365 0.866439 0.598912 0.834709 0.13621 0.729804 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 315
Initial state: 0 0.541476 0.807468 0.633664 0.86367 0.638679 0.696379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165744 episodes
GETTING ACTION FROM:
action 1, numVisits=165667, meanQ=4.930552, numObservations: 4
action -1, numVisits=73, meanQ=4.130937, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.541476 0.807468 0.633664 0.86367 0.638679 0.696379 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 316
Initial state: 0 0.631944 0.893869 0.50928 0.822516 0.109763 0.22777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167109 episodes
GETTING ACTION FROM:
action 2, numVisits=167056, meanQ=5.007922, numObservations: 4
action 0, numVisits=24, meanQ=3.587359, numObservations: 1
action -1, numVisits=27, meanQ=3.554903, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.631944 0.893869 0.50928 0.822516 0.109763 0.22777 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 317
Initial state: 0 0.134467 0.437832 0.699367 0.860792 0.540161 0.848718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166515 episodes
GETTING ACTION FROM:
action 2, numVisits=166475, meanQ=4.998073, numObservations: 4
action 1, numVisits=35, meanQ=3.738011, numObservations: 4
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.134467 0.437832 0.699367 0.860792 0.540161 0.848718 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 318
Initial state: 0 0.697777 0.828162 0.581175 0.811841 0.0156853 0.704434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166326 episodes
GETTING ACTION FROM:
action 2, numVisits=166160, meanQ=4.953945, numObservations: 5
action 0, numVisits=160, meanQ=4.373089, numObservations: 1
action 1, numVisits=3, meanQ=0.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.697777 0.828162 0.581175 0.811841 0.0156853 0.704434 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 319
Initial state: 0 0.521535 0.830058 0.791684 0.979657 0.600218 0.801902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158326 episodes
GETTING ACTION FROM:
action 1, numVisits=158317, meanQ=4.820165, numObservations: 4
action 2, numVisits=3, meanQ=0.663333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.521535 0.830058 0.791684 0.979657 0.600218 0.801902 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 320
Initial state: 0 0.545192 0.881396 0.560268 0.815859 0.972598 0.688327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165266 episodes
GETTING ACTION FROM:
action 1, numVisits=165252, meanQ=4.927952, numObservations: 5
action 3, numVisits=9, meanQ=2.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.545192 0.881396 0.560268 0.815859 0.972598 0.688327 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 321
Initial state: 0 0.0449572 0.580136 0.655124 0.882441 0.52659 0.892594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166801 episodes
GETTING ACTION FROM:
action 2, numVisits=166745, meanQ=4.989712, numObservations: 4
action 3, numVisits=44, meanQ=3.359325, numObservations: 4
action 1, numVisits=8, meanQ=1.748750, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.0449572 0.580136 0.655124 0.882441 0.52659 0.892594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 322
Initial state: 0 0.0225783 0.804353 0.603963 0.892545 0.68326 0.877515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166246 episodes
GETTING ACTION FROM:
action 3, numVisits=166214, meanQ=4.974424, numObservations: 4
action -1, numVisits=18, meanQ=3.299503, numObservations: 1
action 2, numVisits=7, meanQ=1.844286, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.0225783 0.804353 0.603963 0.892545 0.68326 0.877515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 323
Initial state: 0 0.608707 0.891565 0.622311 0.885561 0.455255 0.908176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166116 episodes
GETTING ACTION FROM:
action 2, numVisits=166096, meanQ=4.971190, numObservations: 4
action 1, numVisits=15, meanQ=2.800667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.608707 0.891565 0.622311 0.885561 0.455255 0.908176 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 324
Initial state: 0 0.596969 0.8696 0.235387 0.989813 0.531947 0.811943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165750 episodes
GETTING ACTION FROM:
action 2, numVisits=165720, meanQ=4.956174, numObservations: 5
action -1, numVisits=26, meanQ=3.539705, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.596969 0.8696 0.235387 0.989813 0.531947 0.811943 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12318, meanQ=5.559543, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 187607 episodes
GETTING ACTION FROM:
action 2, numVisits=199923, meanQ=5.134632, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.596969 0.8696 0.235387 0.989813 0.531947 0.811943 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=3791, meanQ=6.306452, numObservations: 3
action 1, numVisits=35, meanQ=4.251431, numObservations: 4
action 2, numVisits=19, meanQ=3.631600, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 212665 episodes
GETTING ACTION FROM:
action 3, numVisits=216454, meanQ=5.866130, numObservations: 3
action 1, numVisits=35, meanQ=4.251431, numObservations: 4
action 2, numVisits=19, meanQ=3.631600, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.596969 0.8696 0.235387 0.989813 0.531947 0.811943 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 325
Initial state: 0 0.504693 0.879875 0.0242331 0.156939 0.67801 0.897152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165823 episodes
GETTING ACTION FROM:
action 2, numVisits=165785, meanQ=4.958181, numObservations: 4
action -1, numVisits=24, meanQ=3.542464, numObservations: 1
action 1, numVisits=11, meanQ=2.729100, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.504693 0.879875 0.0242331 0.156939 0.67801 0.897152 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=18834, meanQ=8.538939, numObservations: 3
action 3, numVisits=8, meanQ=5.501263, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 56067 episodes
GETTING ACTION FROM:
action 1, numVisits=74632, meanQ=6.567213, numObservations: 5
action 3, numVisits=33, meanQ=6.131877, numObservations: 4
action -1, numVisits=240, meanQ=0.417250, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=6, meanQ=-7.279681, numObservations: 1
action: 1
Next state: 1 0.504693 0.879875 0.0242331 0.156939 0.67801 0.897152 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 326
Initial state: 0 0.523421 0.881488 0.513229 0.813676 0.991199 0.830005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167347 episodes
GETTING ACTION FROM:
action 1, numVisits=167336, meanQ=5.189660, numObservations: 5
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.523421 0.881488 0.513229 0.813676 0.991199 0.830005 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 327
Initial state: 0 0.574494 0.813098 0.524415 0.855006 0.691075 0.105589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166185 episodes
GETTING ACTION FROM:
action 2, numVisits=166173, meanQ=4.983998, numObservations: 4
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 1, numVisits=3, meanQ=0.000033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.574494 0.813098 0.524415 0.855006 0.691075 0.105589 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 328
Initial state: 0 0.912334 0.571337 0.559354 0.803974 0.565656 0.897225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164861 episodes
GETTING ACTION FROM:
action 3, numVisits=164822, meanQ=5.014419, numObservations: 3
action 0, numVisits=32, meanQ=3.746872, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.912334 0.571337 0.559354 0.803974 0.565656 0.897225 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 329
Initial state: 0 0.593448 0.889866 0.594081 0.863978 0.0238344 0.818502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164705 episodes
GETTING ACTION FROM:
action 3, numVisits=164699, meanQ=4.934819, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.593448 0.889866 0.594081 0.863978 0.0238344 0.818502 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4059, meanQ=7.618146, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 31818 episodes
GETTING ACTION FROM:
action 1, numVisits=35867, meanQ=6.330065, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=7, meanQ=-0.585714, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.593448 0.889866 0.594081 0.863978 0.0238344 0.818502 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 330
Initial state: 0 0.520806 0.830869 0.624118 0.866706 0.34753 0.236568 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155475 episodes
GETTING ACTION FROM:
action 3, numVisits=155468, meanQ=4.777072, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.520806 0.830869 0.624118 0.866706 0.34753 0.236568 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=21723, meanQ=8.397165, numObservations: 5
action 1, numVisits=18, meanQ=6.216672, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 82312 episodes
GETTING ACTION FROM:
action 2, numVisits=54801, meanQ=6.987421, numObservations: 5
action 1, numVisits=45449, meanQ=6.158606, numObservations: 5
action 0, numVisits=3794, meanQ=0.218849, numObservations: 3
action -1, numVisits=11, meanQ=-2.000900, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.520806 0.830869 0.624118 0.866706 0.34753 0.236568 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 331
Initial state: 0 0.598879 0.850531 0.695179 0.886542 0.838314 0.487507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166113 episodes
GETTING ACTION FROM:
action 3, numVisits=166104, meanQ=5.030388, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.598879 0.850531 0.695179 0.886542 0.838314 0.487507 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 332
Initial state: 0 0.663021 0.878235 0.0783433 0.42565 0.677759 0.849643 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166630 episodes
GETTING ACTION FROM:
action 2, numVisits=166186, meanQ=4.916361, numObservations: 4
action 0, numVisits=152, meanQ=4.285709, numObservations: 1
action 1, numVisits=151, meanQ=4.269649, numObservations: 4
action -1, numVisits=140, meanQ=4.267069, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.663021 0.878235 0.0783433 0.42565 0.677759 0.849643 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23040, meanQ=8.413075, numObservations: 5
action 1, numVisits=9, meanQ=6.331111, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 49981 episodes
GETTING ACTION FROM:
action 3, numVisits=72984, meanQ=6.608347, numObservations: 5
action 1, numVisits=31, meanQ=4.999355, numObservations: 3
action -1, numVisits=11, meanQ=-2.091800, numObservations: 1
action 0, numVisits=6, meanQ=-6.379150, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.663021 0.878235 0.0783433 0.42565 0.677759 0.849643 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 333
Initial state: 0 0.617804 0.857934 0.520797 0.851542 0.853682 0.567088 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166149 episodes
GETTING ACTION FROM:
action 1, numVisits=166064, meanQ=4.953202, numObservations: 5
action 0, numVisits=68, meanQ=4.116721, numObservations: 1
action 3, numVisits=14, meanQ=1.428571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.617804 0.857934 0.520797 0.851542 0.853682 0.567088 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 334
Initial state: 0 0.685703 0.815919 0.512561 0.864515 0.487676 0.909856 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163735 episodes
GETTING ACTION FROM:
action 2, numVisits=163723, meanQ=4.863450, numObservations: 4
action 3, numVisits=7, meanQ=-1.428557, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.685703 0.815919 0.512561 0.864515 0.487676 0.909856 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 335
Initial state: 0 0.0350835 0.324353 0.546622 0.857937 0.560015 0.896994 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161870 episodes
GETTING ACTION FROM:
action 3, numVisits=161713, meanQ=4.901742, numObservations: 5
action 0, numVisits=134, meanQ=4.316170, numObservations: 1
action 2, numVisits=20, meanQ=2.699505, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.0350835 0.324353 0.546622 0.857937 0.560015 0.896994 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 336
Initial state: 0 0.384639 0.613991 0.694109 0.809073 0.565819 0.861755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167034 episodes
GETTING ACTION FROM:
action 1, numVisits=166910, meanQ=4.976130, numObservations: 3
action -1, numVisits=91, meanQ=4.256532, numObservations: 1
action 0, numVisits=27, meanQ=3.624468, numObservations: 1
action 3, numVisits=5, meanQ=0.604020, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.384639 0.613991 0.694109 0.809073 0.565819 0.861755 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27256, meanQ=8.303568, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 61047 episodes
GETTING ACTION FROM:
action 3, numVisits=87345, meanQ=6.809050, numObservations: 4
action 0, numVisits=941, meanQ=-0.578731, numObservations: 1
action -1, numVisits=16, meanQ=-2.063112, numObservations: 1
action 2, numVisits=5, meanQ=-2.093200, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.384639 0.613991 0.694109 0.809073 0.565819 0.861755 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 337
Initial state: 0 0.356554 0.212128 0.50102 0.859026 0.637972 0.845087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159224 episodes
GETTING ACTION FROM:
action 2, numVisits=159138, meanQ=4.874915, numObservations: 3
action 3, numVisits=54, meanQ=3.712228, numObservations: 4
action 0, numVisits=29, meanQ=3.548745, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.356554 0.212128 0.50102 0.859026 0.637972 0.845087 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 338
Initial state: 0 0.681097 0.824866 0.622545 0.897668 0.452455 0.651034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159303 episodes
GETTING ACTION FROM:
action 3, numVisits=159294, meanQ=4.869627, numObservations: 4
action 1, numVisits=4, meanQ=-0.999975, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.681097 0.824866 0.622545 0.897668 0.452455 0.651034 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26379, meanQ=8.288029, numObservations: 3
action 1, numVisits=25, meanQ=6.283600, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54770 episodes
GETTING ACTION FROM:
action 2, numVisits=53476, meanQ=7.121479, numObservations: 3
action 1, numVisits=26558, meanQ=5.841812, numObservations: 4
action 0, numVisits=641, meanQ=-0.712936, numObservations: 1
action -1, numVisits=501, meanQ=-0.748646, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.681097 0.824866 0.622545 0.897668 0.452455 0.651034 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 339
Initial state: 0 0.6305 0.826123 0.675146 0.86626 0.378663 0.068375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167038 episodes
GETTING ACTION FROM:
action 2, numVisits=166153, meanQ=5.018824, numObservations: 5
action 3, numVisits=802, meanQ=4.769863, numObservations: 5
action 0, numVisits=80, meanQ=4.248360, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.6305 0.826123 0.675146 0.86626 0.378663 0.068375 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12098, meanQ=5.542147, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 183841 episodes
GETTING ACTION FROM:
action 2, numVisits=195937, meanQ=4.689740, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.6305 0.826123 0.675146 0.86626 0.378663 0.068375 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 340
Initial state: 0 0.510191 0.898486 0.587066 0.880714 0.304424 0.749055 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160653 episodes
GETTING ACTION FROM:
action 1, numVisits=160645, meanQ=5.055157, numObservations: 5
action 2, numVisits=3, meanQ=0.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.510191 0.898486 0.587066 0.880714 0.304424 0.749055 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 341
Initial state: 0 0.694019 0.168491 0.535621 0.843072 0.57635 0.813021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157634 episodes
GETTING ACTION FROM:
action 3, numVisits=157486, meanQ=4.842366, numObservations: 4
action 0, numVisits=94, meanQ=4.127394, numObservations: 1
action -1, numVisits=36, meanQ=3.703169, numObservations: 1
action 1, numVisits=17, meanQ=2.352947, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.694019 0.168491 0.535621 0.843072 0.57635 0.813021 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 342
Initial state: 0 0.882925 0.764035 0.564895 0.868916 0.666063 0.843569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165337 episodes
GETTING ACTION FROM:
action 2, numVisits=165279, meanQ=5.017890, numObservations: 5
action 0, numVisits=40, meanQ=3.899052, numObservations: 1
action 3, numVisits=15, meanQ=1.532667, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.882925 0.764035 0.564895 0.868916 0.666063 0.843569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 343
Initial state: 0 0.693289 0.880084 0.223413 0.451523 0.581158 0.803907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166169 episodes
GETTING ACTION FROM:
action 3, numVisits=166126, meanQ=4.973369, numObservations: 4
action 0, numVisits=34, meanQ=3.789304, numObservations: 1
action 1, numVisits=6, meanQ=1.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.693289 0.880084 0.223413 0.451523 0.581158 0.803907 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 344
Initial state: 0 0.894443 0.622777 0.578048 0.839132 0.522948 0.835449 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166443 episodes
GETTING ACTION FROM:
action 1, numVisits=166367, meanQ=4.959185, numObservations: 4
action 0, numVisits=71, meanQ=4.147392, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.894443 0.622777 0.578048 0.839132 0.522948 0.835449 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=10243, meanQ=4.790477, numObservations: 5
action 2, numVisits=2093, meanQ=4.627494, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55616 episodes
GETTING ACTION FROM:
action 2, numVisits=20938, meanQ=5.870105, numObservations: 5
action 3, numVisits=44961, meanQ=5.564264, numObservations: 5
action 0, numVisits=2044, meanQ=-0.339111, numObservations: 1
action -1, numVisits=13, meanQ=-2.077677, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.894443 0.622777 0.578048 0.839132 0.522948 0.835449 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 345
Initial state: 0 0.197556 0.911872 0.653147 0.863619 0.502215 0.885799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166119 episodes
GETTING ACTION FROM:
action 2, numVisits=166112, meanQ=4.964165, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.197556 0.911872 0.653147 0.863619 0.502215 0.885799 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 346
Initial state: 0 0.203725 0.0555504 0.674015 0.869092 0.675064 0.800326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166222 episodes
GETTING ACTION FROM:
action 3, numVisits=166164, meanQ=4.960376, numObservations: 3
action 2, numVisits=27, meanQ=3.619267, numObservations: 4
action 0, numVisits=20, meanQ=3.291114, numObservations: 1
action 1, numVisits=9, meanQ=2.664444, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.203725 0.0555504 0.674015 0.869092 0.675064 0.800326 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 347
Initial state: 0 0.565683 0.331888 0.66733 0.838309 0.659473 0.812723 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166628 episodes
GETTING ACTION FROM:
action 2, numVisits=166605, meanQ=4.966680, numObservations: 5
action -1, numVisits=19, meanQ=3.375135, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.565683 0.331888 0.66733 0.838309 0.659473 0.812723 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 348
Initial state: 0 0.131153 0.0557657 0.602271 0.844052 0.642821 0.863176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166537 episodes
GETTING ACTION FROM:
action 1, numVisits=166509, meanQ=5.139997, numObservations: 5
action 0, numVisits=24, meanQ=3.735229, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.131153 0.0557657 0.602271 0.844052 0.642821 0.863176 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9587, meanQ=7.960720, numObservations: 3
action 3, numVisits=149, meanQ=7.437520, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 82619 episodes
GETTING ACTION FROM:
action 2, numVisits=26240, meanQ=6.572865, numObservations: 3
action 3, numVisits=63975, meanQ=5.844601, numObservations: 4
action -1, numVisits=2125, meanQ=-0.017685, numObservations: 1
action 0, numVisits=17, meanQ=-2.000582, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.131153 0.0557657 0.602271 0.844052 0.642821 0.863176 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 349
Initial state: 0 0.648463 0.852225 0.280342 0.138619 0.577329 0.889536 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164813 episodes
GETTING ACTION FROM:
action 1, numVisits=164511, meanQ=5.113512, numObservations: 5
action 3, numVisits=274, meanQ=4.654287, numObservations: 4
action -1, numVisits=25, meanQ=3.626587, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.648463 0.852225 0.280342 0.138619 0.577329 0.889536 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 350
Initial state: 0 0.550387 0.878984 0.52811 0.246484 0.606178 0.835164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 103850 episodes
GETTING ACTION FROM:
action 0, numVisits=103842, meanQ=5.954298, numObservations: 3
action 1, numVisits=3, meanQ=0.000033, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.550387 0.878984 0.52811 0.246484 0.606178 0.835164 w: 1
Observation: 0 0 0.881205 0 0.282285 0 0.753349 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=33194, meanQ=8.158248, numObservations: 4
action 1, numVisits=14, meanQ=5.855714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 166842 episodes
GETTING ACTION FROM:
action 3, numVisits=200024, meanQ=5.806485, numObservations: 4
action 1, numVisits=24, meanQ=4.332921, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.550387 0.878984 0.52811 0.246484 0.606178 0.835164 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 351
Initial state: 0 0.660348 0.824803 0.622868 0.854305 0.0718633 0.51228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167978 episodes
GETTING ACTION FROM:
action 3, numVisits=167927, meanQ=5.065324, numObservations: 5
action -1, numVisits=25, meanQ=3.693007, numObservations: 1
action 1, numVisits=23, meanQ=3.091309, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.660348 0.824803 0.622868 0.854305 0.0718633 0.51228 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8456, meanQ=7.760018, numObservations: 4
action 1, numVisits=8, meanQ=4.512500, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 49083 episodes
GETTING ACTION FROM:
action 2, numVisits=34564, meanQ=6.314052, numObservations: 4
action 1, numVisits=20567, meanQ=6.117191, numObservations: 3
action 3, numVisits=8, meanQ=4.998750, numObservations: 2
action -1, numVisits=2403, meanQ=-0.271483, numObservations: 1
action 0, numVisits=9, meanQ=-40.204305, numObservations: 1
action: 2
Next state: 1 0.660348 0.824803 0.622868 0.854305 0.0718633 0.51228 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 352
Initial state: 0 0.618823 0.878749 0.797037 0.533201 0.514394 0.801626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166498 episodes
GETTING ACTION FROM:
action 3, numVisits=166491, meanQ=4.994266, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.618823 0.878749 0.797037 0.533201 0.514394 0.801626 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 353
Initial state: 0 0.614112 0.849243 0.506893 0.841879 0.425367 0.551899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167023 episodes
GETTING ACTION FROM:
action 3, numVisits=166743, meanQ=4.993154, numObservations: 4
action 2, numVisits=227, meanQ=4.492177, numObservations: 4
action -1, numVisits=50, meanQ=3.981971, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.614112 0.849243 0.506893 0.841879 0.425367 0.551899 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=27450, meanQ=8.326502, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 65678 episodes
GETTING ACTION FROM:
action 2, numVisits=92960, meanQ=6.684395, numObservations: 4
action 1, numVisits=6, meanQ=0.637981, numObservations: 1
action -1, numVisits=161, meanQ=0.551863, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=5, meanQ=-5.486591, numObservations: 1
action: 2
Next state: 1 0.614112 0.849243 0.506893 0.841879 0.425367 0.551899 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 354
Initial state: 0 0.655372 0.886008 0.686285 0.85544 0.343761 0.459327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 166018 episodes
GETTING ACTION FROM:
action 3, numVisits=166005, meanQ=4.964674, numObservations: 3
action 1, numVisits=8, meanQ=0.997500, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.655372 0.886008 0.686285 0.85544 0.343761 0.459327 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=27137, meanQ=8.315603, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 84294 episodes
GETTING ACTION FROM:
action 2, numVisits=111197, meanQ=6.756268, numObservations: 4
action -1, numVisits=217, meanQ=0.755576, numObservations: 1
action 0, numVisits=19, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.655372 0.886008 0.686285 0.85544 0.343761 0.459327 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 355
Initial state: 0 0.609081 0.88949 0.575665 0.838614 0.254645 0.998865 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163816 episodes
GETTING ACTION FROM:
action 3, numVisits=163588, meanQ=4.957508, numObservations: 5
action 0, numVisits=115, meanQ=4.324520, numObservations: 1
action 1, numVisits=80, meanQ=4.056750, numObservations: 5
action -1, numVisits=32, meanQ=3.654916, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.609081 0.88949 0.575665 0.838614 0.254645 0.998865 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 356
Initial state: 0 0.500534 0.858546 0.949497 0.673332 0.599328 0.807071 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96970 episodes
GETTING ACTION FROM:
action -1, numVisits=96824, meanQ=2.894330, numObservations: 1
action 0, numVisits=139, meanQ=2.274055, numObservations: 2
action 2, numVisits=5, meanQ=-0.200000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.500534 0.858546 0.949497 0.673332 0.599328 0.807071 w: 1
Observation: 0 0.482736 0 0.881545 0 0.606462 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=96645, meanQ=4.953828, numObservations: 5
action -1, numVisits=169, meanQ=4.442775, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 166785 episodes
GETTING ACTION FROM:
action 3, numVisits=263429, meanQ=5.018792, numObservations: 5
action -1, numVisits=170, meanQ=4.437978, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.500534 0.858546 0.949497 0.673332 0.599328 0.807071 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 357
Initial state: 0 0.0145238 0.747902 0.654826 0.863944 0.56179 0.889328 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80950 episodes
GETTING ACTION FROM:
action 0, numVisits=80941, meanQ=4.420568, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 1
action: 0
Next state: 0 0.0145238 0.747902 0.654826 0.863944 0.56179 0.889328 w: 1
Observation: 0 0 0.789505 0 0.770096 0 0.947959 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=48510, meanQ=5.780861, numObservations: 1
action 1, numVisits=10, meanQ=1.191020, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 97328 episodes
GETTING ACTION FROM:
action -1, numVisits=145838, meanQ=5.031928, numObservations: 1
action 1, numVisits=10, meanQ=1.191020, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.0145238 0.747902 0.654826 0.863944 0.56179 0.889328 w: 1
Observation: 0 0.0890253 0 0.651802 0 0.607383 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=145831, meanQ=6.165267, numObservations: 5
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 163776 episodes
GETTING ACTION FROM:
action 2, numVisits=309579, meanQ=5.656508, numObservations: 5
action 0, numVisits=28, meanQ=4.296783, numObservations: 1
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0145238 0.747902 0.654826 0.863944 0.56179 0.889328 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 358
Initial state: 0 0.622099 0.800827 0.817331 0.406228 0.634612 0.807519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164782 episodes
GETTING ACTION FROM:
action 1, numVisits=164602, meanQ=4.907673, numObservations: 5
action 0, numVisits=134, meanQ=4.321559, numObservations: 1
action -1, numVisits=42, meanQ=3.854097, numObservations: 1
action 3, numVisits=3, meanQ=0.000033, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.622099 0.800827 0.817331 0.406228 0.634612 0.807519 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 359
Initial state: 0 0.612231 0.81309 0.4301 0.223162 0.619394 0.828823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163794 episodes
GETTING ACTION FROM:
action 2, numVisits=163761, meanQ=4.955580, numObservations: 5
action -1, numVisits=12, meanQ=2.729587, numObservations: 1
action 3, numVisits=14, meanQ=2.357143, numObservations: 3
action 1, numVisits=5, meanQ=1.198020, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.612231 0.81309 0.4301 0.223162 0.619394 0.828823 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12757, meanQ=8.524176, numObservations: 3
action 3, numVisits=5876, meanQ=8.496335, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 49637 episodes
GETTING ACTION FROM:
action 1, numVisits=31212, meanQ=6.841415, numObservations: 3
action 3, numVisits=21377, meanQ=6.650518, numObservations: 4
action -1, numVisits=11736, meanQ=-0.254725, numObservations: 1
action 0, numVisits=3947, meanQ=-0.436582, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.612231 0.81309 0.4301 0.223162 0.619394 0.828823 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 360
Initial state: 0 0.33507 0.787268 0.662449 0.81105 0.68153 0.819948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167201 episodes
GETTING ACTION FROM:
action 1, numVisits=167190, meanQ=5.042044, numObservations: 5
action 2, numVisits=6, meanQ=1.498333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.33507 0.787268 0.662449 0.81105 0.68153 0.819948 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23299, meanQ=8.403493, numObservations: 5
action 2, numVisits=6, meanQ=4.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 47008 episodes
GETTING ACTION FROM:
action 3, numVisits=51605, meanQ=7.236834, numObservations: 5
action 2, numVisits=15057, meanQ=5.821749, numObservations: 4
action -1, numVisits=3437, meanQ=0.133814, numObservations: 1
action 0, numVisits=216, meanQ=-0.575108, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.33507 0.787268 0.662449 0.81105 0.68153 0.819948 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 361
Initial state: 0 0.502979 0.809382 0.676451 0.845184 0.883637 0.622372 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162170 episodes
GETTING ACTION FROM:
action 3, numVisits=162076, meanQ=4.820854, numObservations: 4
action 1, numVisits=89, meanQ=4.042023, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.502979 0.809382 0.676451 0.845184 0.883637 0.622372 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 362
Initial state: 0 0.652006 0.87757 0.338294 0.420098 0.520839 0.877881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169475 episodes
GETTING ACTION FROM:
action 1, numVisits=169452, meanQ=4.963632, numObservations: 4
action 0, numVisits=19, meanQ=3.382679, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.652006 0.87757 0.338294 0.420098 0.520839 0.877881 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12611, meanQ=5.613865, numObservations: 3
action 3, numVisits=18, meanQ=3.554450, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 191233 episodes
GETTING ACTION FROM:
action 1, numVisits=203817, meanQ=5.015583, numObservations: 4
action 3, numVisits=43, meanQ=3.929770, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.652006 0.87757 0.338294 0.420098 0.520839 0.877881 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 363
Initial state: 0 0.698606 0.800303 0.614352 0.894589 0.350921 0.34243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170425 episodes
GETTING ACTION FROM:
action 3, numVisits=170415, meanQ=4.970592, numObservations: 4
action 1, numVisits=5, meanQ=-0.399980, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.698606 0.800303 0.614352 0.894589 0.350921 0.34243 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23718, meanQ=8.400991, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 65407 episodes
GETTING ACTION FROM:
action 3, numVisits=8, meanQ=6.987500, numObservations: 2
action 2, numVisits=61066, meanQ=6.898774, numObservations: 3
action 1, numVisits=27104, meanQ=6.033482, numObservations: 4
action -1, numVisits=940, meanQ=0.245383, numObservations: 1
action 0, numVisits=13, meanQ=-2.000762, numObservations: 1
action: 3
Next state: 0 0.698606 0.800303 0.614352 0.894589 0.350921 0.34243 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=9.000000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 121309 episodes
GETTING ACTION FROM:
action 2, numVisits=119911, meanQ=6.119901, numObservations: 4
action 3, numVisits=6, meanQ=3.500000, numObservations: 3
action 0, numVisits=1375, meanQ=-0.502400, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=16, meanQ=-2.000619, numObservations: 1
action: 2
Next state: 1 0.698606 0.800303 0.614352 0.894589 0.350921 0.34243 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 364
Initial state: 0 0.645944 0.826433 0.811174 0.115635 0.626481 0.847072 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170613 episodes
GETTING ACTION FROM:
action 3, numVisits=170607, meanQ=4.943718, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.645944 0.826433 0.811174 0.115635 0.626481 0.847072 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 365
Initial state: 0 0.690894 0.814086 0.087206 0.301235 0.610888 0.804797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171037 episodes
GETTING ACTION FROM:
action 2, numVisits=171031, meanQ=5.040856, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.690894 0.814086 0.087206 0.301235 0.610888 0.804797 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=24005, meanQ=8.417099, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55602 episodes
GETTING ACTION FROM:
action 3, numVisits=78018, meanQ=6.698725, numObservations: 4
action -1, numVisits=1480, meanQ=0.149905, numObservations: 1
action 0, numVisits=111, meanQ=-0.486661, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.690894 0.814086 0.087206 0.301235 0.610888 0.804797 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 366
Initial state: 0 0.69419 0.800745 0.233129 0.235713 0.646101 0.869364 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170787 episodes
GETTING ACTION FROM:
action 2, numVisits=170773, meanQ=5.055699, numObservations: 5
action 0, numVisits=4, meanQ=-2.502425, numObservations: 1
action 1, numVisits=5, meanQ=-3.000000, numObservations: 2
action 3, numVisits=3, meanQ=-3.296667, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.69419 0.800745 0.233129 0.235713 0.646101 0.869364 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=23842, meanQ=8.412926, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 52144 episodes
GETTING ACTION FROM:
action 1, numVisits=75955, meanQ=6.703405, numObservations: 5
action 3, numVisits=14, meanQ=5.285000, numObservations: 3
action 0, numVisits=11, meanQ=-2.000900, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=10, meanQ=-36.244579, numObservations: 1
action: 1
Next state: 1 0.69419 0.800745 0.233129 0.235713 0.646101 0.869364 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 367
Initial state: 0 0.563779 0.870174 0.794294 0.355359 0.562898 0.811229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171559 episodes
GETTING ACTION FROM:
action 1, numVisits=171553, meanQ=5.032926, numObservations: 5
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.563779 0.870174 0.794294 0.355359 0.562898 0.811229 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 368
Initial state: 0 0.55823 0.809232 0.0604172 0.975262 0.532268 0.818394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170750 episodes
GETTING ACTION FROM:
action 1, numVisits=169090, meanQ=5.011608, numObservations: 4
action 3, numVisits=1647, meanQ=4.843124, numObservations: 5
action 2, numVisits=9, meanQ=2.443344, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.55823 0.809232 0.0604172 0.975262 0.532268 0.818394 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 369
Initial state: 0 0.611274 0.870995 0.606498 0.892737 0.470415 0.498721 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170199 episodes
GETTING ACTION FROM:
action 1, numVisits=170193, meanQ=4.981219, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.611274 0.870995 0.606498 0.892737 0.470415 0.498721 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 370
Initial state: 0 0.544616 0.820872 0.655931 0.495902 0.609014 0.894792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169769 episodes
GETTING ACTION FROM:
action 3, numVisits=169747, meanQ=5.010071, numObservations: 5
action 0, numVisits=16, meanQ=3.160014, numObservations: 1
action 1, numVisits=3, meanQ=0.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.544616 0.820872 0.655931 0.495902 0.609014 0.894792 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 371
Initial state: 0 0.530561 0.885407 0.509225 0.824745 0.914798 0.418189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170338 episodes
GETTING ACTION FROM:
action 1, numVisits=170332, meanQ=4.953730, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.530561 0.885407 0.509225 0.824745 0.914798 0.418189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 372
Initial state: 0 0.077461 0.985901 0.677207 0.829976 0.541407 0.802196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171127 episodes
GETTING ACTION FROM:
action 3, numVisits=171048, meanQ=4.988467, numObservations: 3
action 0, numVisits=67, meanQ=4.146944, numObservations: 1
action 1, numVisits=9, meanQ=2.656667, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.077461 0.985901 0.677207 0.829976 0.541407 0.802196 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 373
Initial state: 0 0.556793 0.85259 0.670254 0.858575 0.124208 0.170135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162543 episodes
GETTING ACTION FROM:
action 1, numVisits=162533, meanQ=4.875967, numObservations: 3
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.556793 0.85259 0.670254 0.858575 0.124208 0.170135 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 374
Initial state: 0 0.679753 0.837482 0.85726 0.190314 0.620679 0.874393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170863 episodes
GETTING ACTION FROM:
action 1, numVisits=170773, meanQ=4.992447, numObservations: 4
action 0, numVisits=52, meanQ=4.028937, numObservations: 1
action -1, numVisits=36, meanQ=3.806104, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.679753 0.837482 0.85726 0.190314 0.620679 0.874393 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 375
Initial state: 0 0.0604184 0.619699 0.536946 0.897272 0.65395 0.836038 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170225 episodes
GETTING ACTION FROM:
action 2, numVisits=167218, meanQ=5.024390, numObservations: 5
action 1, numVisits=1303, meanQ=4.844977, numObservations: 4
action 3, numVisits=1604, meanQ=4.751467, numObservations: 5
action 0, numVisits=64, meanQ=4.150745, numObservations: 1
action -1, numVisits=36, meanQ=3.827431, numObservations: 1
action: 2
Next state: 1 0.0604184 0.619699 0.536946 0.897272 0.65395 0.836038 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 376
Initial state: 0 0.555005 0.813466 0.152948 0.242973 0.660776 0.839431 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169055 episodes
GETTING ACTION FROM:
action 1, numVisits=168425, meanQ=4.976487, numObservations: 5
action 3, numVisits=550, meanQ=4.554800, numObservations: 4
action -1, numVisits=70, meanQ=4.112710, numObservations: 1
action 2, numVisits=8, meanQ=2.373775, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.555005 0.813466 0.152948 0.242973 0.660776 0.839431 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 377
Initial state: 0 0.533663 0.861297 0.959149 0.374975 0.58019 0.844288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171551 episodes
GETTING ACTION FROM:
action 2, numVisits=171529, meanQ=4.992921, numObservations: 5
action 1, numVisits=17, meanQ=1.930006, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.533663 0.861297 0.959149 0.374975 0.58019 0.844288 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 378
Initial state: 0 0.529373 0.845217 0.511764 0.822851 0.872252 0.132514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171009 episodes
GETTING ACTION FROM:
action 1, numVisits=170946, meanQ=4.992770, numObservations: 4
action -1, numVisits=45, meanQ=3.969627, numObservations: 1
action 2, numVisits=15, meanQ=2.266680, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.529373 0.845217 0.511764 0.822851 0.872252 0.132514 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 379
Initial state: 0 0.618681 0.888092 0.67874 0.848269 0.291539 0.952041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171037 episodes
GETTING ACTION FROM:
action 3, numVisits=170992, meanQ=5.033636, numObservations: 4
action -1, numVisits=23, meanQ=3.579302, numObservations: 1
action 1, numVisits=19, meanQ=2.736321, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.618681 0.888092 0.67874 0.848269 0.291539 0.952041 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8611, meanQ=7.773158, numObservations: 4
action 1, numVisits=9, meanQ=4.775567, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55270 episodes
GETTING ACTION FROM:
action 2, numVisits=49163, meanQ=6.220473, numObservations: 4
action 1, numVisits=11381, meanQ=5.996578, numObservations: 4
action -1, numVisits=2910, meanQ=0.250804, numObservations: 1
action 0, numVisits=438, meanQ=-0.004178, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.618681 0.888092 0.67874 0.848269 0.291539 0.952041 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 380
Initial state: 0 0.50315 0.892791 0.669837 0.833047 0.0266302 0.443574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170503 episodes
GETTING ACTION FROM:
action 1, numVisits=170436, meanQ=4.962854, numObservations: 3
action -1, numVisits=62, meanQ=4.088905, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.50315 0.892791 0.669837 0.833047 0.0266302 0.443574 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 381
Initial state: 0 0.627862 0.857627 0.821781 0.855887 0.566364 0.880992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171344 episodes
GETTING ACTION FROM:
action 3, numVisits=171330, meanQ=5.056524, numObservations: 4
action 2, numVisits=6, meanQ=1.333333, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.627862 0.857627 0.821781 0.855887 0.566364 0.880992 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 382
Initial state: 0 0.504081 0.824358 0.637999 0.829635 0.829632 0.405638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170498 episodes
GETTING ACTION FROM:
action 1, numVisits=170198, meanQ=4.945427, numObservations: 5
action 0, numVisits=275, meanQ=2.803534, numObservations: 1
action 2, numVisits=21, meanQ=1.805248, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.504081 0.824358 0.637999 0.829635 0.829632 0.405638 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 383
Initial state: 0 0.604884 0.893066 0.940472 0.770415 0.672186 0.806748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170346 episodes
GETTING ACTION FROM:
action 2, numVisits=170208, meanQ=5.027673, numObservations: 4
action 3, numVisits=93, meanQ=4.065594, numObservations: 4
action -1, numVisits=34, meanQ=3.795382, numObservations: 1
action 1, numVisits=9, meanQ=2.443344, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.604884 0.893066 0.940472 0.770415 0.672186 0.806748 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 384
Initial state: 0 0.000326702 0.535597 0.614566 0.868038 0.61887 0.818614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170225 episodes
GETTING ACTION FROM:
action 2, numVisits=170141, meanQ=5.020217, numObservations: 5
action 0, numVisits=44, meanQ=3.947686, numObservations: 1
action -1, numVisits=38, meanQ=3.873619, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.000326702 0.535597 0.614566 0.868038 0.61887 0.818614 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 385
Initial state: 0 0.39646 0.324188 0.580216 0.859629 0.604666 0.887387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170594 episodes
GETTING ACTION FROM:
action 1, numVisits=170555, meanQ=4.943739, numObservations: 4
action 0, numVisits=35, meanQ=3.759574, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.39646 0.324188 0.580216 0.859629 0.604666 0.887387 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27745, meanQ=8.301365, numObservations: 3
action 2, numVisits=13, meanQ=6.537692, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 45281 episodes
GETTING ACTION FROM:
action 3, numVisits=69257, meanQ=7.039990, numObservations: 3
action 0, numVisits=3753, meanQ=-0.414856, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=27, meanQ=-8.037918, numObservations: 4
action -1, numVisits=4, meanQ=-92.712325, numObservations: 1
action: 3
Next state: 1 0.39646 0.324188 0.580216 0.859629 0.604666 0.887387 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 386
Initial state: 0 0.780449 0.727444 0.636251 0.866828 0.698561 0.879819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168798 episodes
GETTING ACTION FROM:
action 2, numVisits=168766, meanQ=4.956039, numObservations: 5
action 1, numVisits=22, meanQ=3.404105, numObservations: 4
action 3, numVisits=6, meanQ=2.003350, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.780449 0.727444 0.636251 0.866828 0.698561 0.879819 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 387
Initial state: 0 0.923931 0.958913 0.579021 0.860568 0.648113 0.851735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171484 episodes
GETTING ACTION FROM:
action 1, numVisits=171478, meanQ=5.019276, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.923931 0.958913 0.579021 0.860568 0.648113 0.851735 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 388
Initial state: 0 0.62791 0.819385 0.652292 0.864872 0.884579 0.354777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170521 episodes
GETTING ACTION FROM:
action 1, numVisits=170509, meanQ=4.959518, numObservations: 5
action 3, numVisits=7, meanQ=2.285729, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.62791 0.819385 0.652292 0.864872 0.884579 0.354777 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 389
Initial state: 0 0.640733 0.831104 0.503771 0.898405 0.961982 0.188989 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170793 episodes
GETTING ACTION FROM:
action 1, numVisits=170755, meanQ=4.991610, numObservations: 5
action -1, numVisits=34, meanQ=3.803865, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.640733 0.831104 0.503771 0.898405 0.961982 0.188989 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 390
Initial state: 0 0.668084 0.829522 0.181629 0.30391 0.567684 0.895181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170789 episodes
GETTING ACTION FROM:
action 2, numVisits=170783, meanQ=4.958046, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.668084 0.829522 0.181629 0.30391 0.567684 0.895181 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=19055, meanQ=8.528635, numObservations: 3
action 3, numVisits=294, meanQ=8.096069, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 64675 episodes
GETTING ACTION FROM:
action 1, numVisits=62915, meanQ=6.824962, numObservations: 5
action 3, numVisits=18594, meanQ=6.017219, numObservations: 4
action -1, numVisits=2447, meanQ=0.221532, numObservations: 1
action 0, numVisits=70, meanQ=-0.472713, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.668084 0.829522 0.181629 0.30391 0.567684 0.895181 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 391
Initial state: 0 0.320418 0.274479 0.605895 0.8607 0.680537 0.816591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170076 episodes
GETTING ACTION FROM:
action 2, numVisits=170070, meanQ=4.951830, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.320418 0.274479 0.605895 0.8607 0.680537 0.816591 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 392
Initial state: 0 0.669635 0.880283 0.577242 0.891837 0.00333465 0.515336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170549 episodes
GETTING ACTION FROM:
action 1, numVisits=170513, meanQ=4.996693, numObservations: 4
action -1, numVisits=31, meanQ=3.722148, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.669635 0.880283 0.577242 0.891837 0.00333465 0.515336 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 393
Initial state: 0 0.649894 0.859656 0.155284 0.761999 0.509679 0.846752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 100353 episodes
GETTING ACTION FROM:
action -1, numVisits=100344, meanQ=3.002877, numObservations: 1
action 3, numVisits=5, meanQ=-0.200000, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.649894 0.859656 0.155284 0.761999 0.509679 0.846752 w: 1
Observation: 0 0.584985 0 0.163339 0 0.596379 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=100305, meanQ=5.039185, numObservations: 4
action 0, numVisits=34, meanQ=3.873112, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 173393 episodes
GETTING ACTION FROM:
action 2, numVisits=273696, meanQ=5.041690, numObservations: 4
action 0, numVisits=36, meanQ=3.873712, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.649894 0.859656 0.155284 0.761999 0.509679 0.846752 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=36636, meanQ=8.415000, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 58745 episodes
GETTING ACTION FROM:
action 1, numVisits=78193, meanQ=7.101345, numObservations: 5
action 3, numVisits=16303, meanQ=5.809331, numObservations: 5
action 0, numVisits=882, meanQ=-0.396769, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=7, meanQ=-52.189765, numObservations: 1
action: 1
Next state: 1 0.649894 0.859656 0.155284 0.761999 0.509679 0.846752 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 394
Initial state: 0 0.581264 0.863658 0.575157 0.0273218 0.678446 0.807892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171237 episodes
GETTING ACTION FROM:
action 1, numVisits=171146, meanQ=5.017669, numObservations: 5
action 0, numVisits=58, meanQ=4.103230, numObservations: 1
action -1, numVisits=31, meanQ=3.776427, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.581264 0.863658 0.575157 0.0273218 0.678446 0.807892 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 395
Initial state: 0 0.780907 0.851679 0.564862 0.836844 0.656349 0.845768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170073 episodes
GETTING ACTION FROM:
action 2, numVisits=170067, meanQ=5.004518, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.780907 0.851679 0.564862 0.836844 0.656349 0.845768 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27963, meanQ=8.260083, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 51329 episodes
GETTING ACTION FROM:
action 1, numVisits=78676, meanQ=6.947441, numObservations: 4
action -1, numVisits=615, meanQ=0.232732, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=3, meanQ=-123.419849, numObservations: 1
action: 1
Next state: 2 0.780907 0.851679 0.564862 0.836844 0.656349 0.845768 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 396
Initial state: 0 0.15829 0.647793 0.578547 0.891443 0.619331 0.830057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171218 episodes
GETTING ACTION FROM:
action 3, numVisits=171113, meanQ=4.990425, numObservations: 4
action 2, numVisits=55, meanQ=4.030011, numObservations: 4
action -1, numVisits=40, meanQ=3.903447, numObservations: 1
action 1, numVisits=8, meanQ=2.498750, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.15829 0.647793 0.578547 0.891443 0.619331 0.830057 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 397
Initial state: 0 0.604774 0.873038 0.523845 0.837005 0.70441 0.361412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170513 episodes
GETTING ACTION FROM:
action 2, numVisits=170473, meanQ=4.989425, numObservations: 3
action 0, numVisits=28, meanQ=3.679821, numObservations: 1
action 3, numVisits=9, meanQ=2.664444, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.604774 0.873038 0.523845 0.837005 0.70441 0.361412 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 398
Initial state: 0 0.543411 0.897972 0.553672 0.242469 0.633237 0.853732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169751 episodes
GETTING ACTION FROM:
action 2, numVisits=169740, meanQ=5.017457, numObservations: 5
action 1, numVisits=6, meanQ=0.836683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.543411 0.897972 0.553672 0.242469 0.633237 0.853732 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=23253, meanQ=8.394658, numObservations: 4
action 3, numVisits=243, meanQ=8.011279, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 42839 episodes
GETTING ACTION FROM:
action 1, numVisits=53454, meanQ=7.059228, numObservations: 4
action 3, numVisits=12877, meanQ=6.254755, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=4, meanQ=-7.009138, numObservations: 1
action -1, numVisits=2, meanQ=-193.349371, numObservations: 1
action: 1
Next state: 1 0.543411 0.897972 0.553672 0.242469 0.633237 0.853732 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 399
Initial state: 0 0.412085 0.799926 0.553756 0.815029 0.523815 0.817949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 99865 episodes
GETTING ACTION FROM:
action 0, numVisits=99853, meanQ=2.985590, numObservations: 1
action 2, numVisits=8, meanQ=0.246263, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.412085 0.799926 0.553756 0.815029 0.523815 0.817949 w: 1
Observation: 0 0 0.737324 0 0.869439 0 0.830079 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=99744, meanQ=5.034494, numObservations: 4
action -1, numVisits=103, meanQ=4.380091, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 170806 episodes
GETTING ACTION FROM:
action 2, numVisits=270537, meanQ=4.917260, numObservations: 4
action -1, numVisits=116, meanQ=4.273347, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.412085 0.799926 0.553756 0.815029 0.523815 0.817949 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 400
Initial state: 0 0.698557 0.862068 0.503634 0.838805 0.199285 0.435293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170357 episodes
GETTING ACTION FROM:
action 3, numVisits=170302, meanQ=4.956832, numObservations: 4
action 0, numVisits=42, meanQ=3.880857, numObservations: 1
action 1, numVisits=7, meanQ=1.428571, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.698557 0.862068 0.503634 0.838805 0.199285 0.435293 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=27923, meanQ=8.323664, numObservations: 3
action 1, numVisits=4, meanQ=4.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 46842 episodes
GETTING ACTION FROM:
action 2, numVisits=72609, meanQ=7.031524, numObservations: 3
action 1, numVisits=8, meanQ=0.744511, numObservations: 4
action -1, numVisits=2149, meanQ=0.147683, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=5, meanQ=-73.882344, numObservations: 1
action: 2
Next state: 1 0.698557 0.862068 0.503634 0.838805 0.199285 0.435293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 401
Initial state: 0 0.00717853 0.589775 0.682348 0.852761 0.602847 0.896092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170261 episodes
GETTING ACTION FROM:
action 2, numVisits=170126, meanQ=4.965082, numObservations: 4
action -1, numVisits=70, meanQ=4.130581, numObservations: 1
action 0, numVisits=38, meanQ=3.806768, numObservations: 1
action 3, numVisits=22, meanQ=3.173641, numObservations: 3
action 1, numVisits=5, meanQ=1.398000, numObservations: 3
action: 2
Next state: 0 0.00717853 0.589775 0.682348 0.852761 0.602847 0.896092 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12409, meanQ=5.491416, numObservations: 4
action 3, numVisits=14, meanQ=3.563586, numObservations: 3
action 1, numVisits=14, meanQ=3.277143, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 213071 episodes
GETTING ACTION FROM:
action 3, numVisits=213083, meanQ=5.959889, numObservations: 4
action 2, numVisits=12409, meanQ=5.491416, numObservations: 4
action 1, numVisits=14, meanQ=3.277143, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.00717853 0.589775 0.682348 0.852761 0.602847 0.896092 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 402
Initial state: 0 0.260548 0.592052 0.544676 0.882053 0.674488 0.813047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 165503 episodes
GETTING ACTION FROM:
action 2, numVisits=165491, meanQ=4.860592, numObservations: 4
action 1, numVisits=6, meanQ=1.166683, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.260548 0.592052 0.544676 0.882053 0.674488 0.813047 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 403
Initial state: 0 0.430319 0.131085 0.615629 0.842968 0.560566 0.802484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169639 episodes
GETTING ACTION FROM:
action 1, numVisits=169571, meanQ=4.997797, numObservations: 4
action 0, numVisits=60, meanQ=4.108180, numObservations: 1
action 3, numVisits=5, meanQ=-0.002000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.430319 0.131085 0.615629 0.842968 0.560566 0.802484 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27785, meanQ=8.351526, numObservations: 4
action 2, numVisits=51, meanQ=7.470006, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 33492 episodes
GETTING ACTION FROM:
action 3, numVisits=61188, meanQ=7.064227, numObservations: 4
action 2, numVisits=83, meanQ=5.794825, numObservations: 3
action -1, numVisits=52, meanQ=-0.096154, numObservations: 1
action 0, numVisits=7, meanQ=-1.858571, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.430319 0.131085 0.615629 0.842968 0.560566 0.802484 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 404
Initial state: 0 0.502635 0.874335 0.725742 0.833839 0.665268 0.813571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 100492 episodes
GETTING ACTION FROM:
action -1, numVisits=100487, meanQ=2.934265, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.502635 0.874335 0.725742 0.833839 0.665268 0.813571 w: 1
Observation: 0 0.520217 0 0.742323 0 0.741289 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=100465, meanQ=4.987683, numObservations: 5
action 3, numVisits=16, meanQ=2.749388, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 170907 episodes
GETTING ACTION FROM:
action 2, numVisits=271262, meanQ=5.017046, numObservations: 5
action 1, numVisits=111, meanQ=4.301984, numObservations: 5
action 3, numVisits=16, meanQ=2.749388, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.502635 0.874335 0.725742 0.833839 0.665268 0.813571 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 405
Initial state: 0 0.311323 0.627399 0.550631 0.883196 0.609551 0.83056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168951 episodes
GETTING ACTION FROM:
action 2, numVisits=168889, meanQ=4.917788, numObservations: 4
action 0, numVisits=41, meanQ=3.814213, numObservations: 1
action -1, numVisits=19, meanQ=3.168698, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.311323 0.627399 0.550631 0.883196 0.609551 0.83056 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12215, meanQ=4.722215, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 210323 episodes
GETTING ACTION FROM:
action 3, numVisits=210324, meanQ=6.062947, numObservations: 5
action 1, numVisits=12215, meanQ=4.722215, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.311323 0.627399 0.550631 0.883196 0.609551 0.83056 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 406
Initial state: 0 0.636939 0.824817 0.547088 0.855831 0.892211 0.980309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171307 episodes
GETTING ACTION FROM:
action 3, numVisits=168752, meanQ=5.134608, numObservations: 4
action 1, numVisits=2533, meanQ=4.993873, numObservations: 5
action -1, numVisits=15, meanQ=3.286645, numObservations: 1
action 2, numVisits=5, meanQ=-0.002000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.636939 0.824817 0.547088 0.855831 0.892211 0.980309 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 407
Initial state: 0 0.88957 0.476549 0.676502 0.838966 0.562338 0.801337 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167975 episodes
GETTING ACTION FROM:
action 3, numVisits=167967, meanQ=4.974972, numObservations: 4
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.88957 0.476549 0.676502 0.838966 0.562338 0.801337 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 408
Initial state: 0 0.527655 0.89881 0.00455007 0.991296 0.562529 0.828202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170670 episodes
GETTING ACTION FROM:
action 3, numVisits=170574, meanQ=5.027025, numObservations: 3
action -1, numVisits=80, meanQ=4.247734, numObservations: 1
action 2, numVisits=12, meanQ=2.916667, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.527655 0.89881 0.00455007 0.991296 0.562529 0.828202 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 409
Initial state: 0 0.988321 0.332327 0.642117 0.861747 0.518765 0.805168 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163044 episodes
GETTING ACTION FROM:
action 3, numVisits=163033, meanQ=4.907654, numObservations: 4
action 2, numVisits=6, meanQ=0.166667, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.988321 0.332327 0.642117 0.861747 0.518765 0.805168 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 410
Initial state: 0 0.662656 0.896645 0.699662 0.635715 0.669945 0.828475 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168619 episodes
GETTING ACTION FROM:
action 1, numVisits=168527, meanQ=4.977024, numObservations: 4
action 0, numVisits=65, meanQ=4.124276, numObservations: 1
action 2, numVisits=24, meanQ=3.499179, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.662656 0.896645 0.699662 0.635715 0.669945 0.828475 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 411
Initial state: 0 0.919308 0.51011 0.616682 0.832878 0.51035 0.823807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169140 episodes
GETTING ACTION FROM:
action 3, numVisits=169016, meanQ=4.929460, numObservations: 5
action 0, numVisits=75, meanQ=4.134381, numObservations: 1
action 2, numVisits=41, meanQ=3.795371, numObservations: 4
action 1, numVisits=6, meanQ=0.166667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.919308 0.51011 0.616682 0.832878 0.51035 0.823807 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 412
Initial state: 0 0.503287 0.854148 0.67262 0.89894 0.307177 0.33392 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170412 episodes
GETTING ACTION FROM:
action 1, numVisits=170067, meanQ=4.960399, numObservations: 3
action 2, numVisits=264, meanQ=4.524891, numObservations: 4
action -1, numVisits=46, meanQ=3.944372, numObservations: 1
action 0, numVisits=33, meanQ=3.766487, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 1 0.503287 0.854148 0.67262 0.89894 0.307177 0.33392 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 413
Initial state: 0 0.313068 0.636687 0.635085 0.862154 0.636654 0.826128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169533 episodes
GETTING ACTION FROM:
action 3, numVisits=169495, meanQ=4.934460, numObservations: 5
action 1, numVisits=32, meanQ=2.650638, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.313068 0.636687 0.635085 0.862154 0.636654 0.826128 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 414
Initial state: 0 0.788074 0.421016 0.636248 0.878682 0.568813 0.848343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170132 episodes
GETTING ACTION FROM:
action 1, numVisits=170103, meanQ=4.983164, numObservations: 4
action -1, numVisits=13, meanQ=3.006757, numObservations: 1
action 2, numVisits=13, meanQ=2.460769, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.788074 0.421016 0.636248 0.878682 0.568813 0.848343 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 415
Initial state: 0 0.694383 0.774023 0.559202 0.848639 0.662978 0.860347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170495 episodes
GETTING ACTION FROM:
action 3, numVisits=170469, meanQ=4.963436, numObservations: 5
action -1, numVisits=21, meanQ=3.445408, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.694383 0.774023 0.559202 0.848639 0.662978 0.860347 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 416
Initial state: 0 0.624834 0.864939 0.49861 0.437023 0.515968 0.883292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171262 episodes
GETTING ACTION FROM:
action 1, numVisits=171238, meanQ=4.953041, numObservations: 3
action -1, numVisits=20, meanQ=3.336113, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.624834 0.864939 0.49861 0.437023 0.515968 0.883292 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 417
Initial state: 0 0.655275 0.848014 0.69981 0.860914 0.290467 0.000724084 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170675 episodes
GETTING ACTION FROM:
action 2, numVisits=170522, meanQ=5.020335, numObservations: 4
action 0, numVisits=126, meanQ=4.120769, numObservations: 1
action 1, numVisits=23, meanQ=3.260435, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.655275 0.848014 0.69981 0.860914 0.290467 0.000724084 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 418
Initial state: 0 0.663084 0.879075 0.548526 0.892578 0.895591 0.333456 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169931 episodes
GETTING ACTION FROM:
action 1, numVisits=169912, meanQ=4.949152, numObservations: 5
action 3, numVisits=8, meanQ=2.375000, numObservations: 3
action 2, numVisits=7, meanQ=2.002871, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.663084 0.879075 0.548526 0.892578 0.895591 0.333456 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 419
Initial state: 0 0.676692 0.871048 0.2852 0.620165 0.58945 0.833898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169816 episodes
GETTING ACTION FROM:
action 1, numVisits=169669, meanQ=4.975998, numObservations: 4
action -1, numVisits=89, meanQ=4.238677, numObservations: 1
action 0, numVisits=52, meanQ=4.024983, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.676692 0.871048 0.2852 0.620165 0.58945 0.833898 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 420
Initial state: 0 0.732995 0.340664 0.5504 0.868225 0.648003 0.852162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170372 episodes
GETTING ACTION FROM:
action 2, numVisits=170170, meanQ=5.030283, numObservations: 5
action -1, numVisits=157, meanQ=4.482619, numObservations: 1
action 0, numVisits=43, meanQ=3.979990, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.732995 0.340664 0.5504 0.868225 0.648003 0.852162 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 421
Initial state: 0 0.476994 0.231186 0.600132 0.893786 0.672131 0.829431 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168580 episodes
GETTING ACTION FROM:
action 3, numVisits=168573, meanQ=4.979531, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.476994 0.231186 0.600132 0.893786 0.672131 0.829431 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 422
Initial state: 0 0.555411 0.889478 0.580871 0.811243 0.497801 0.0887159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171376 episodes
GETTING ACTION FROM:
action 2, numVisits=171327, meanQ=5.036960, numObservations: 5
action -1, numVisits=43, meanQ=3.976629, numObservations: 1
action 1, numVisits=3, meanQ=0.000033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.555411 0.889478 0.580871 0.811243 0.497801 0.0887159 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 423
Initial state: 0 0.627126 0.800915 0.162103 0.972779 0.567986 0.827572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162620 episodes
GETTING ACTION FROM:
action 3, numVisits=162594, meanQ=4.873092, numObservations: 3
action -1, numVisits=22, meanQ=3.275066, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.627126 0.800915 0.162103 0.972779 0.567986 0.827572 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 424
Initial state: 0 0.690468 0.86744 0.564304 0.889603 0.477808 0.677438 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170718 episodes
GETTING ACTION FROM:
action 1, numVisits=170670, meanQ=4.947657, numObservations: 5
action -1, numVisits=43, meanQ=3.890420, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.690468 0.86744 0.564304 0.889603 0.477808 0.677438 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 425
Initial state: 0 0.677866 0.855593 0.588344 0.448697 0.551139 0.810852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167030 episodes
GETTING ACTION FROM:
action 3, numVisits=166971, meanQ=4.907424, numObservations: 5
action 0, numVisits=32, meanQ=3.670242, numObservations: 1
action 1, numVisits=15, meanQ=2.532000, numObservations: 3
action 2, numVisits=10, meanQ=1.700000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.677866 0.855593 0.588344 0.448697 0.551139 0.810852 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 426
Initial state: 0 0.569261 0.837768 0.657937 0.368601 0.586915 0.885308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170898 episodes
GETTING ACTION FROM:
action 3, numVisits=170890, meanQ=5.020848, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.569261 0.837768 0.657937 0.368601 0.586915 0.885308 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 427
Initial state: 0 0.640823 0.809154 0.872848 0.64672 0.652417 0.847859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169272 episodes
GETTING ACTION FROM:
action 1, numVisits=169218, meanQ=4.986452, numObservations: 4
action -1, numVisits=50, meanQ=4.004089, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.640823 0.809154 0.872848 0.64672 0.652417 0.847859 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=2505, meanQ=5.310091, numObservations: 3
action 2, numVisits=9901, meanQ=4.994731, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 211652 episodes
GETTING ACTION FROM:
action 2, numVisits=221363, meanQ=6.197658, numObservations: 5
action 0, numVisits=2695, meanQ=4.936258, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.640823 0.809154 0.872848 0.64672 0.652417 0.847859 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 428
Initial state: 0 0.571374 0.897834 0.628131 0.802293 0.373013 0.0390096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168611 episodes
GETTING ACTION FROM:
action 2, numVisits=168586, meanQ=4.931065, numObservations: 4
action 3, numVisits=20, meanQ=3.099005, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.571374 0.897834 0.628131 0.802293 0.373013 0.0390096 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 429
Initial state: 0 0.655261 0.815839 0.699787 0.864565 0.20515 0.3277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161325 episodes
GETTING ACTION FROM:
action 2, numVisits=161299, meanQ=4.896193, numObservations: 4
action 0, numVisits=20, meanQ=3.272613, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.655261 0.815839 0.699787 0.864565 0.20515 0.3277 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 430
Initial state: 0 0.175815 0.73485 0.525707 0.817639 0.543771 0.821101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170209 episodes
GETTING ACTION FROM:
action 2, numVisits=170203, meanQ=4.944165, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.175815 0.73485 0.525707 0.817639 0.543771 0.821101 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 431
Initial state: 0 0.507552 0.825286 0.667922 0.840903 0.728579 0.0792566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162514 episodes
GETTING ACTION FROM:
action 1, numVisits=162430, meanQ=4.879615, numObservations: 4
action -1, numVisits=58, meanQ=3.974084, numObservations: 1
action 3, numVisits=23, meanQ=3.197826, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.507552 0.825286 0.667922 0.840903 0.728579 0.0792566 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 432
Initial state: 0 0.630761 0.819938 0.656372 0.84528 0.471989 0.523771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170087 episodes
GETTING ACTION FROM:
action 3, numVisits=170080, meanQ=4.918476, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.630761 0.819938 0.656372 0.84528 0.471989 0.523771 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=23954, meanQ=8.416192, numObservations: 5
action 2, numVisits=11, meanQ=6.455464, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 52449 episodes
GETTING ACTION FROM:
action 1, numVisits=65742, meanQ=6.986120, numObservations: 5
action 2, numVisits=9759, meanQ=5.534565, numObservations: 4
action -1, numVisits=906, meanQ=-0.013455, numObservations: 1
action 0, numVisits=9, meanQ=-2.112200, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.630761 0.819938 0.656372 0.84528 0.471989 0.523771 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 433
Initial state: 0 0.694968 0.897648 0.558349 0.806815 0.193648 0.302517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 172140 episodes
GETTING ACTION FROM:
action 1, numVisits=172100, meanQ=5.060413, numObservations: 5
action -1, numVisits=36, meanQ=3.906860, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.694968 0.897648 0.558349 0.806815 0.193648 0.302517 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 434
Initial state: 0 0.392884 0.485751 0.696233 0.898584 0.568536 0.853764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 172081 episodes
GETTING ACTION FROM:
action 3, numVisits=172006, meanQ=5.076647, numObservations: 5
action -1, numVisits=48, meanQ=4.065370, numObservations: 1
action 1, numVisits=15, meanQ=3.125347, numObservations: 4
action 0, numVisits=10, meanQ=2.485195, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 0 0.392884 0.485751 0.696233 0.898584 0.568536 0.853764 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=10831, meanQ=5.888271, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 193046 episodes
GETTING ACTION FROM:
action 3, numVisits=203873, meanQ=5.220877, numObservations: 4
action -1, numVisits=4, meanQ=0.475000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.392884 0.485751 0.696233 0.898584 0.568536 0.853764 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 435
Initial state: 0 0.559371 0.899535 0.546986 0.344368 0.617738 0.86684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 100201 episodes
GETTING ACTION FROM:
action -1, numVisits=100196, meanQ=2.995850, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.559371 0.899535 0.546986 0.344368 0.617738 0.86684 w: 1
Observation: 0 0.591809 0 0.454427 0 0.559685 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=100159, meanQ=5.017965, numObservations: 4
action 1, numVisits=31, meanQ=3.768394, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 171988 episodes
GETTING ACTION FROM:
action 2, numVisits=272121, meanQ=5.089187, numObservations: 4
action 1, numVisits=31, meanQ=3.768394, numObservations: 3
action 3, numVisits=27, meanQ=3.646674, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.559371 0.899535 0.546986 0.344368 0.617738 0.86684 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 436
Initial state: 0 0.614962 0.876112 0.316082 0.751132 0.65095 0.88118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 105518 episodes
GETTING ACTION FROM:
action 0, numVisits=105192, meanQ=5.871107, numObservations: 3
action -1, numVisits=322, meanQ=3.533748, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.614962 0.876112 0.316082 0.751132 0.65095 0.88118 w: 1
Observation: 0 0 0.85111 0 0.753569 0 0.832849 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=28200, meanQ=8.208724, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 172989 episodes
GETTING ACTION FROM:
action 1, numVisits=201141, meanQ=5.537639, numObservations: 4
action -1, numVisits=48, meanQ=4.523213, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.614962 0.876112 0.316082 0.751132 0.65095 0.88118 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 437
Initial state: 0 0.693659 0.812936 0.51185 0.809749 0.0565025 0.991784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170244 episodes
GETTING ACTION FROM:
action 3, numVisits=170160, meanQ=4.986057, numObservations: 5
action -1, numVisits=80, meanQ=4.217521, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.693659 0.812936 0.51185 0.809749 0.0565025 0.991784 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4111, meanQ=7.834902, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 80729 episodes
GETTING ACTION FROM:
action 2, numVisits=18100, meanQ=6.493577, numObservations: 5
action 1, numVisits=66700, meanQ=6.136083, numObservations: 5
action 0, numVisits=37, meanQ=-0.528378, numObservations: 1
action -1, numVisits=7, meanQ=-1.858571, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.693659 0.812936 0.51185 0.809749 0.0565025 0.991784 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 438
Initial state: 0 0.766819 0.602442 0.574371 0.898045 0.591824 0.880481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 100311 episodes
GETTING ACTION FROM:
action -1, numVisits=100304, meanQ=3.000481, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.766819 0.602442 0.574371 0.898045 0.591824 0.880481 w: 1
Observation: 0 0.816772 0 0.668522 0 0.659338 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=100280, meanQ=5.036839, numObservations: 4
action 0, numVisits=19, meanQ=3.323052, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 171757 episodes
GETTING ACTION FROM:
action 3, numVisits=272036, meanQ=5.001933, numObservations: 4
action 0, numVisits=20, meanQ=3.105904, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.766819 0.602442 0.574371 0.898045 0.591824 0.880481 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 439
Initial state: 0 0.675058 0.879356 0.640828 0.391142 0.605764 0.889964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98205 episodes
GETTING ACTION FROM:
action 0, numVisits=98200, meanQ=3.023653, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.675058 0.879356 0.640828 0.391142 0.605764 0.889964 w: 1
Observation: 0 0 0.952544 0 0.427218 0 0.910449 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=25794, meanQ=8.320736, numObservations: 4
action 3, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 174870 episodes
GETTING ACTION FROM:
action 1, numVisits=200608, meanQ=5.689919, numObservations: 4
action -1, numVisits=55, meanQ=4.749659, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.675058 0.879356 0.640828 0.391142 0.605764 0.889964 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 440
Initial state: 0 0.609615 0.8234 0.829786 0.35367 0.536448 0.836218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170857 episodes
GETTING ACTION FROM:
action 2, numVisits=170828, meanQ=5.027756, numObservations: 5
action -1, numVisits=25, meanQ=3.533881, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.609615 0.8234 0.829786 0.35367 0.536448 0.836218 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 441
Initial state: 0 0.629151 0.857703 0.68549 0.842048 0.113365 0.0343834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168613 episodes
GETTING ACTION FROM:
action 2, numVisits=168557, meanQ=5.003281, numObservations: 4
action 1, numVisits=33, meanQ=3.515761, numObservations: 4
action 0, numVisits=14, meanQ=3.151152, numObservations: 1
action 3, numVisits=7, meanQ=2.144300, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.629151 0.857703 0.68549 0.842048 0.113365 0.0343834 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 442
Initial state: 0 0.795564 0.663272 0.520849 0.889106 0.629927 0.848799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153103 episodes
GETTING ACTION FROM:
action 3, numVisits=128980, meanQ=4.962967, numObservations: 5
action -1, numVisits=24115, meanQ=2.944650, numObservations: 1
action 2, numVisits=5, meanQ=-0.200000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.795564 0.663272 0.520849 0.889106 0.629927 0.848799 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 443
Initial state: 0 0.646045 0.838186 0.624132 0.858584 0.621275 0.941121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170910 episodes
GETTING ACTION FROM:
action 2, numVisits=170900, meanQ=5.192635, numObservations: 5
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.646045 0.838186 0.624132 0.858584 0.621275 0.941121 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 444
Initial state: 0 0.573289 0.856491 0.883464 0.58513 0.69488 0.807356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171386 episodes
GETTING ACTION FROM:
action 1, numVisits=171380, meanQ=4.993336, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.573289 0.856491 0.883464 0.58513 0.69488 0.807356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 445
Initial state: 0 0.895437 0.229799 0.626031 0.817764 0.568318 0.806822 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170052 episodes
GETTING ACTION FROM:
action 3, numVisits=160711, meanQ=5.153998, numObservations: 5
action 2, numVisits=9303, meanQ=4.792007, numObservations: 4
action 0, numVisits=19, meanQ=3.444682, numObservations: 1
action 1, numVisits=17, meanQ=3.058835, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.895437 0.229799 0.626031 0.817764 0.568318 0.806822 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=10687, meanQ=7.347377, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 190823 episodes
GETTING ACTION FROM:
action 3, numVisits=201508, meanQ=5.146972, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 0 0.895437 0.229799 0.626031 0.817764 0.568318 0.806822 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=4373, meanQ=6.423563, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 218546 episodes
GETTING ACTION FROM:
action 2, numVisits=222919, meanQ=6.333070, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.895437 0.229799 0.626031 0.817764 0.568318 0.806822 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 446
Initial state: 0 0.629322 0.86084 0.543573 0.898064 0.428997 0.178329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169607 episodes
GETTING ACTION FROM:
action 2, numVisits=169594, meanQ=4.978629, numObservations: 4
action 1, numVisits=7, meanQ=0.428571, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.629322 0.86084 0.543573 0.898064 0.428997 0.178329 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 447
Initial state: 0 0.512664 0.858408 0.559086 0.855254 0.632833 0.520456 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 172193 episodes
GETTING ACTION FROM:
action 2, numVisits=172187, meanQ=5.032650, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.512664 0.858408 0.559086 0.855254 0.632833 0.520456 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 448
Initial state: 0 0.574894 0.869128 0.624188 0.8874 0.768331 0.722221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170567 episodes
GETTING ACTION FROM:
action 2, numVisits=170559, meanQ=4.929240, numObservations: 5
action 1, numVisits=3, meanQ=0.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.574894 0.869128 0.624188 0.8874 0.768331 0.722221 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=12409, meanQ=4.743288, numObservations: 4
action -1, numVisits=47, meanQ=3.859837, numObservations: 1
action 2, numVisits=6, meanQ=1.331683, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 210928 episodes
GETTING ACTION FROM:
action 3, numVisits=223326, meanQ=5.872846, numObservations: 4
action -1, numVisits=58, meanQ=2.748489, numObservations: 1
action 2, numVisits=6, meanQ=1.331683, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.574894 0.869128 0.624188 0.8874 0.768331 0.722221 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 449
Initial state: 0 0.550509 0.876008 0.271156 0.892901 0.63397 0.824469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 104274 episodes
GETTING ACTION FROM:
action 0, numVisits=101512, meanQ=5.544869, numObservations: 2
action -1, numVisits=2755, meanQ=0.806713, numObservations: 1
action 2, numVisits=4, meanQ=-2.500000, numObservations: 2
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.550509 0.876008 0.271156 0.892901 0.63397 0.824469 w: 1
Observation: 0 0 0.783296 0 0.941618 0 0.875597 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=76401, meanQ=7.413690, numObservations: 4
action 1, numVisits=870, meanQ=5.212668, numObservations: 4
action 2, numVisits=11, meanQ=3.725464, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 173165 episodes
GETTING ACTION FROM:
action 3, numVisits=249550, meanQ=5.680394, numObservations: 4
action 1, numVisits=870, meanQ=5.212668, numObservations: 4
action 0, numVisits=14, meanQ=3.591006, numObservations: 1
action 2, numVisits=13, meanQ=2.998469, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.550509 0.876008 0.271156 0.892901 0.63397 0.824469 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=19303, meanQ=5.958739, numObservations: 4
action 1, numVisits=5, meanQ=2.598000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 191015 episodes
GETTING ACTION FROM:
action 3, numVisits=210256, meanQ=5.356353, numObservations: 4
action 1, numVisits=64, meanQ=4.249688, numObservations: 3
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.550509 0.876008 0.271156 0.892901 0.63397 0.824469 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 450
Initial state: 0 0.331697 0.216974 0.588976 0.891828 0.651675 0.873123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168985 episodes
GETTING ACTION FROM:
action 3, numVisits=168950, meanQ=4.962166, numObservations: 3
action 0, numVisits=21, meanQ=3.453498, numObservations: 1
action 2, numVisits=8, meanQ=1.625000, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.331697 0.216974 0.588976 0.891828 0.651675 0.873123 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12524, meanQ=4.727638, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 209776 episodes
GETTING ACTION FROM:
action 2, numVisits=222300, meanQ=5.530445, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.331697 0.216974 0.588976 0.891828 0.651675 0.873123 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 451
Initial state: 0 0.567546 0.822449 0.652099 0.896371 0.862216 0.615739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 100133 episodes
GETTING ACTION FROM:
action -1, numVisits=100126, meanQ=3.016760, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.567546 0.822449 0.652099 0.896371 0.862216 0.615739 w: 1
Observation: 0 0.535875 0 0.72232 0 0.765872 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=100119, meanQ=5.040717, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 171915 episodes
GETTING ACTION FROM:
action 1, numVisits=272033, meanQ=4.897266, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-3.505000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.567546 0.822449 0.652099 0.896371 0.862216 0.615739 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 452
Initial state: 0 0.0558316 0.157835 0.589007 0.868758 0.619796 0.867778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170699 episodes
GETTING ACTION FROM:
action 1, numVisits=170691, meanQ=5.038526, numObservations: 4
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0558316 0.157835 0.589007 0.868758 0.619796 0.867778 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23654, meanQ=8.425061, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 77048 episodes
GETTING ACTION FROM:
action 2, numVisits=100688, meanQ=6.710606, numObservations: 3
action -1, numVisits=14, meanQ=-2.000707, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.0558316 0.157835 0.589007 0.868758 0.619796 0.867778 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 453
Initial state: 0 0.610468 0.888825 0.558172 0.863451 0.230395 0.113056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169710 episodes
GETTING ACTION FROM:
action 1, numVisits=169597, meanQ=5.031757, numObservations: 3
action -1, numVisits=100, meanQ=4.341766, numObservations: 1
action 3, numVisits=9, meanQ=1.335567, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.610468 0.888825 0.558172 0.863451 0.230395 0.113056 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 454
Initial state: 0 0.56719 0.82043 0.558386 0.84411 0.987507 0.526402 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171100 episodes
GETTING ACTION FROM:
action 1, numVisits=171086, meanQ=5.004454, numObservations: 3
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action 3, numVisits=3, meanQ=0.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.56719 0.82043 0.558386 0.84411 0.987507 0.526402 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 455
Initial state: 0 0.522813 0.823517 0.528187 0.892034 0.792719 0.246112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170440 episodes
GETTING ACTION FROM:
action 1, numVisits=170414, meanQ=5.000377, numObservations: 5
action -1, numVisits=22, meanQ=3.494851, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.522813 0.823517 0.528187 0.892034 0.792719 0.246112 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 456
Initial state: 0 0.664976 0.33267 0.646279 0.83724 0.562463 0.842998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171007 episodes
GETTING ACTION FROM:
action 1, numVisits=170833, meanQ=5.014091, numObservations: 5
action 3, numVisits=101, meanQ=4.248158, numObservations: 3
action 0, numVisits=70, meanQ=4.194358, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.664976 0.33267 0.646279 0.83724 0.562463 0.842998 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 457
Initial state: 0 0.616847 0.810831 0.638404 0.814146 0.383996 0.163333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171612 episodes
GETTING ACTION FROM:
action 3, numVisits=171535, meanQ=5.012328, numObservations: 5
action -1, numVisits=69, meanQ=4.117729, numObservations: 1
action 2, numVisits=5, meanQ=-0.795980, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.616847 0.810831 0.638404 0.814146 0.383996 0.163333 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=23693, meanQ=8.403221, numObservations: 3
action 2, numVisits=275, meanQ=8.036780, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 57369 episodes
GETTING ACTION FROM:
action 1, numVisits=47432, meanQ=7.261331, numObservations: 3
action 2, numVisits=33123, meanQ=5.983095, numObservations: 5
action 0, numVisits=772, meanQ=-0.280324, numObservations: 1
action -1, numVisits=12, meanQ=-2.000825, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.616847 0.810831 0.638404 0.814146 0.383996 0.163333 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 458
Initial state: 0 0.682388 0.810541 0.62138 0.809927 0.837702 0.129803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171043 episodes
GETTING ACTION FROM:
action 2, numVisits=167956, meanQ=5.011872, numObservations: 5
action 1, numVisits=3081, meanQ=4.772867, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.682388 0.810541 0.62138 0.809927 0.837702 0.129803 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 459
Initial state: 0 0.637793 0.803665 0.619307 0.845091 0.283064 0.589257 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159935 episodes
GETTING ACTION FROM:
action 2, numVisits=159815, meanQ=4.790481, numObservations: 5
action 0, numVisits=111, meanQ=4.142139, numObservations: 1
action 1, numVisits=6, meanQ=1.498333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.637793 0.803665 0.619307 0.845091 0.283064 0.589257 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1401, meanQ=5.532956, numObservations: 4
action 3, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 37128 episodes
GETTING ACTION FROM:
action 3, numVisits=37112, meanQ=5.793746, numObservations: 5
action 2, numVisits=1401, meanQ=5.532956, numObservations: 4
action -1, numVisits=17, meanQ=-0.369412, numObservations: 1
action 0, numVisits=4, meanQ=-2.002475, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.637793 0.803665 0.619307 0.845091 0.283064 0.589257 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=9.000000, numObservations: 1
action -1, numVisits=480, meanQ=6.872854, numObservations: 1
action 1, numVisits=11, meanQ=5.760407, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-12.075595, numObservations: 1
Sampled 59514 episodes
GETTING ACTION FROM:
action 1, numVisits=56667, meanQ=6.111540, numObservations: 3
action 2, numVisits=5, meanQ=5.000000, numObservations: 2
action -1, numVisits=3321, meanQ=-0.392930, numObservations: 1
action 0, numVisits=15, meanQ=-2.000660, numObservations: 1
action 3, numVisits=1, meanQ=-12.075595, numObservations: 1
action: 1
Next state: 1 0.637793 0.803665 0.619307 0.845091 0.283064 0.589257 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 460
Initial state: 0 0.580591 0.860692 0.576407 0.805651 0.322888 0.779807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159353 episodes
GETTING ACTION FROM:
action 2, numVisits=143365, meanQ=5.003874, numObservations: 5
action -1, numVisits=15945, meanQ=3.021708, numObservations: 1
action 3, numVisits=40, meanQ=1.947008, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.580591 0.860692 0.576407 0.805651 0.322888 0.779807 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 461
Initial state: 0 0.666732 0.842407 0.648843 0.807334 0.10711 0.785237 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 100496 episodes
GETTING ACTION FROM:
action 0, numVisits=100482, meanQ=3.049699, numObservations: 1
action 2, numVisits=10, meanQ=-0.201000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.666732 0.842407 0.648843 0.807334 0.10711 0.785237 w: 1
Observation: 0 0 0.742967 0 0.8148 0 0.846956 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=100455, meanQ=5.132221, numObservations: 4
action -1, numVisits=22, meanQ=3.693363, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 172592 episodes
GETTING ACTION FROM:
action 2, numVisits=273044, meanQ=5.141037, numObservations: 4
action -1, numVisits=25, meanQ=3.725652, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.666732 0.842407 0.648843 0.807334 0.10711 0.785237 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 462
Initial state: 0 0.217189 0.777416 0.635505 0.806715 0.691705 0.813204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170611 episodes
GETTING ACTION FROM:
action 3, numVisits=114058, meanQ=4.986825, numObservations: 3
action 2, numVisits=56544, meanQ=4.966884, numObservations: 3
action 1, numVisits=5, meanQ=1.622000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.217189 0.777416 0.635505 0.806715 0.691705 0.813204 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 463
Initial state: 0 0.963039 0.431848 0.5342 0.804376 0.687335 0.8062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168749 episodes
GETTING ACTION FROM:
action 2, numVisits=168653, meanQ=4.927102, numObservations: 4
action 0, numVisits=48, meanQ=3.904068, numObservations: 1
action -1, numVisits=40, meanQ=3.831899, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.963039 0.431848 0.5342 0.804376 0.687335 0.8062 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 464
Initial state: 0 0.652394 0.898304 0.580713 0.844857 0.864648 0.943608 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 99827 episodes
GETTING ACTION FROM:
action -1, numVisits=99820, meanQ=2.921725, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.652394 0.898304 0.580713 0.844857 0.864648 0.943608 w: 1
Observation: 0 0.669553 0 0.624367 0 0.907212 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=99813, meanQ=4.968237, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 174009 episodes
GETTING ACTION FROM:
action 3, numVisits=174008, meanQ=5.234881, numObservations: 4
action 1, numVisits=99813, meanQ=4.968237, numObservations: 5
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.652394 0.898304 0.580713 0.844857 0.864648 0.943608 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 465
Initial state: 0 0.39778 0.457732 0.649454 0.817399 0.640391 0.855961 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169936 episodes
GETTING ACTION FROM:
action 2, numVisits=169903, meanQ=4.950252, numObservations: 4
action -1, numVisits=29, meanQ=3.593831, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.39778 0.457732 0.649454 0.817399 0.640391 0.855961 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 466
Initial state: 0 0.307315 0.252283 0.555419 0.802309 0.574859 0.894393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161925 episodes
GETTING ACTION FROM:
action 1, numVisits=161816, meanQ=4.901202, numObservations: 4
action 0, numVisits=39, meanQ=3.715394, numObservations: 1
action -1, numVisits=34, meanQ=3.689014, numObservations: 1
action 2, numVisits=35, meanQ=3.025434, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.307315 0.252283 0.555419 0.802309 0.574859 0.894393 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=15830, meanQ=8.322760, numObservations: 4
action 3, numVisits=10689, meanQ=8.302936, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 61434 episodes
GETTING ACTION FROM:
action 2, numVisits=45806, meanQ=6.810417, numObservations: 4
action 3, numVisits=40198, meanQ=6.611792, numObservations: 3
action -1, numVisits=1947, meanQ=-0.516005, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=4, meanQ=-92.430158, numObservations: 1
action: 2
Next state: 1 0.307315 0.252283 0.555419 0.802309 0.574859 0.894393 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 467
Initial state: 0 0.430454 0.186444 0.585897 0.87663 0.598189 0.831565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 99383 episodes
GETTING ACTION FROM:
action 0, numVisits=99378, meanQ=3.303416, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.430454 0.186444 0.585897 0.87663 0.598189 0.831565 w: 1
Observation: 0 0 0.163672 0 0.806884 0 0.917278 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=77866, meanQ=4.302584, numObservations: 5
action 3, numVisits=17, meanQ=2.411176, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 171916 episodes
GETTING ACTION FROM:
action 3, numVisits=171926, meanQ=5.069337, numObservations: 4
action 1, numVisits=77866, meanQ=4.302584, numObservations: 5
action 2, numVisits=8, meanQ=0.873750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.430454 0.186444 0.585897 0.87663 0.598189 0.831565 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 468
Initial state: 0 0.505187 0.893199 0.645851 0.853077 0.538786 0.74351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170064 episodes
GETTING ACTION FROM:
action 2, numVisits=170003, meanQ=5.008746, numObservations: 5
action 0, numVisits=47, meanQ=3.992368, numObservations: 1
action 3, numVisits=11, meanQ=1.445464, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.505187 0.893199 0.645851 0.853077 0.538786 0.74351 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 469
Initial state: 0 0.66277 0.811316 0.481585 0.031773 0.608848 0.857069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171240 episodes
GETTING ACTION FROM:
action 2, numVisits=171059, meanQ=5.012632, numObservations: 4
action 0, numVisits=146, meanQ=4.420365, numObservations: 1
action -1, numVisits=24, meanQ=3.603314, numObservations: 1
action 3, numVisits=10, meanQ=2.499000, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.66277 0.811316 0.481585 0.031773 0.608848 0.857069 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23135, meanQ=8.323308, numObservations: 4
action 1, numVisits=5130, meanQ=8.270813, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 75021 episodes
GETTING ACTION FROM:
action 3, numVisits=75037, meanQ=6.786363, numObservations: 4
action 1, numVisits=26618, meanQ=6.316545, numObservations: 4
action 0, numVisits=1631, meanQ=0.289565, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-187.349884, numObservations: 1
action: 3
Next state: 1 0.66277 0.811316 0.481585 0.031773 0.608848 0.857069 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 470
Initial state: 0 0.628552 0.867159 0.650509 0.897466 0.75642 0.916196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171504 episodes
GETTING ACTION FROM:
action 1, numVisits=171496, meanQ=5.031533, numObservations: 3
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.628552 0.867159 0.650509 0.897466 0.75642 0.916196 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 471
Initial state: 0 0.19171 0.616787 0.594817 0.872113 0.587426 0.822628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170863 episodes
GETTING ACTION FROM:
action 3, numVisits=170857, meanQ=5.022655, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.19171 0.616787 0.594817 0.872113 0.587426 0.822628 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 472
Initial state: 0 0.694832 0.883514 0.622565 0.897695 0.680248 0.139782 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171163 episodes
GETTING ACTION FROM:
action 1, numVisits=171154, meanQ=5.026131, numObservations: 5
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.694832 0.883514 0.622565 0.897695 0.680248 0.139782 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 473
Initial state: 0 0.631253 0.840468 0.357988 0.379514 0.6181 0.867456 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170519 episodes
GETTING ACTION FROM:
action 3, numVisits=170359, meanQ=4.986143, numObservations: 3
action -1, numVisits=98, meanQ=4.294464, numObservations: 1
action 2, numVisits=59, meanQ=3.516103, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.631253 0.840468 0.357988 0.379514 0.6181 0.867456 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12624, meanQ=4.872030, numObservations: 5
action 2, numVisits=13, meanQ=1.307700, numObservations: 3
action 3, numVisits=19, meanQ=1.200537, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 212251 episodes
GETTING ACTION FROM:
action 1, numVisits=224875, meanQ=5.653827, numObservations: 5
action 2, numVisits=13, meanQ=1.307700, numObservations: 3
action 3, numVisits=19, meanQ=1.200537, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.631253 0.840468 0.357988 0.379514 0.6181 0.867456 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 474
Initial state: 0 0.622997 0.854088 0.591348 0.895011 0.22696 0.302033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97479 episodes
GETTING ACTION FROM:
action -1, numVisits=97474, meanQ=2.874746, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.622997 0.854088 0.591348 0.895011 0.22696 0.302033 w: 1
Observation: 0 0.583937 0 0.492385 0 0.191965 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=97467, meanQ=4.902800, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 169300 episodes
GETTING ACTION FROM:
action 1, numVisits=169301, meanQ=5.072073, numObservations: 5
action 3, numVisits=97467, meanQ=4.902800, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.622997 0.854088 0.591348 0.895011 0.22696 0.302033 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 475
Initial state: 0 0.625913 0.335778 0.654747 0.885904 0.634945 0.864622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170759 episodes
GETTING ACTION FROM:
action 1, numVisits=170737, meanQ=5.009091, numObservations: 5
action 2, numVisits=17, meanQ=2.694712, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.625913 0.335778 0.654747 0.885904 0.634945 0.864622 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 476
Initial state: 0 0.623853 0.867631 0.64119 0.876586 0.140756 0.648384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170097 episodes
GETTING ACTION FROM:
action 3, numVisits=170056, meanQ=4.981675, numObservations: 4
action -1, numVisits=32, meanQ=3.732870, numObservations: 1
action 2, numVisits=6, meanQ=1.166683, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.623853 0.867631 0.64119 0.876586 0.140756 0.648384 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=23918, meanQ=8.395727, numObservations: 5
action 2, numVisits=14, meanQ=6.142864, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 60238 episodes
GETTING ACTION FROM:
action 1, numVisits=53604, meanQ=7.017028, numObservations: 5
action 2, numVisits=27896, meanQ=6.230039, numObservations: 3
action -1, numVisits=2633, meanQ=0.236802, numObservations: 1
action 0, numVisits=39, meanQ=-0.832308, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.623853 0.867631 0.64119 0.876586 0.140756 0.648384 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 477
Initial state: 0 0.695916 0.805821 0.690146 0.877556 0.423569 0.95487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170915 episodes
GETTING ACTION FROM:
action 3, numVisits=170841, meanQ=5.164353, numObservations: 4
action 1, numVisits=45, meanQ=3.989560, numObservations: 4
action -1, numVisits=16, meanQ=3.434197, numObservations: 1
action 2, numVisits=11, meanQ=2.999100, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.695916 0.805821 0.690146 0.877556 0.423569 0.95487 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11993, meanQ=7.185755, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 187457 episodes
GETTING ACTION FROM:
action 3, numVisits=199448, meanQ=4.954934, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.695916 0.805821 0.690146 0.877556 0.423569 0.95487 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=4183, meanQ=5.750927, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 193357 episodes
GETTING ACTION FROM:
action 3, numVisits=197536, meanQ=4.713263, numObservations: 4
action 0, numVisits=4, meanQ=0.475000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.695916 0.805821 0.690146 0.877556 0.423569 0.95487 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=2441, meanQ=7.552709, numObservations: 4
action 2, numVisits=10, meanQ=5.799000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 217183 episodes
GETTING ACTION FROM:
action 1, numVisits=219601, meanQ=6.084182, numObservations: 4
action 2, numVisits=33, meanQ=4.875758, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.695916 0.805821 0.690146 0.877556 0.423569 0.95487 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 478
Initial state: 0 0.649236 0.241509 0.631602 0.857246 0.678032 0.827631 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168180 episodes
GETTING ACTION FROM:
action 3, numVisits=168174, meanQ=4.895905, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.649236 0.241509 0.631602 0.857246 0.678032 0.827631 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 479
Initial state: 0 0.69233 0.896867 0.257511 0.771517 0.656721 0.807509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169362 episodes
GETTING ACTION FROM:
action 3, numVisits=169287, meanQ=4.919755, numObservations: 4
action 2, numVisits=70, meanQ=4.001079, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.69233 0.896867 0.257511 0.771517 0.656721 0.807509 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 480
Initial state: 0 0.575829 0.870924 0.577604 0.776045 0.65078 0.850078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171060 episodes
GETTING ACTION FROM:
action 2, numVisits=171018, meanQ=5.138675, numObservations: 4
action -1, numVisits=38, meanQ=3.982369, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.575829 0.870924 0.577604 0.776045 0.65078 0.850078 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 481
Initial state: 0 0.669206 0.814313 0.642749 0.898684 0.741114 0.459459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 100625 episodes
GETTING ACTION FROM:
action -1, numVisits=100618, meanQ=3.008848, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.669206 0.814313 0.642749 0.898684 0.741114 0.459459 w: 1
Observation: 0 0.756972 0 0.580822 0 0.733627 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=100608, meanQ=5.031751, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 174709 episodes
GETTING ACTION FROM:
action 1, numVisits=275314, meanQ=5.011957, numObservations: 3
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-3.505000, numObservations: 2
action: 1
Next state: 1 0.669206 0.814313 0.642749 0.898684 0.741114 0.459459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 482
Initial state: 0 0.677836 0.877826 0.663922 0.928887 0.624812 0.830181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 100287 episodes
GETTING ACTION FROM:
action -1, numVisits=100282, meanQ=3.122974, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.677836 0.877826 0.663922 0.928887 0.624812 0.830181 w: 1
Observation: 0 0.655621 0 0.725475 0 0.718394 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=99822, meanQ=5.157273, numObservations: 4
action 3, numVisits=453, meanQ=4.853029, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 174691 episodes
GETTING ACTION FROM:
action 2, numVisits=274506, meanQ=5.166053, numObservations: 4
action 3, numVisits=457, meanQ=4.829209, numObservations: 4
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.677836 0.877826 0.663922 0.928887 0.624812 0.830181 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 483
Initial state: 0 0.595189 0.845529 0.437562 0.352592 0.575698 0.890806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170105 episodes
GETTING ACTION FROM:
action 2, numVisits=169983, meanQ=4.976892, numObservations: 5
action 0, numVisits=101, meanQ=4.271696, numObservations: 1
action -1, numVisits=12, meanQ=2.585116, numObservations: 1
action 1, numVisits=8, meanQ=1.500000, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.595189 0.845529 0.437562 0.352592 0.575698 0.890806 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 484
Initial state: 0 0.256375 0.692394 0.667054 0.82124 0.674162 0.885286 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 100068 episodes
GETTING ACTION FROM:
action -1, numVisits=100063, meanQ=2.914149, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.256375 0.692394 0.667054 0.82124 0.674162 0.885286 w: 1
Observation: 0 0.270618 0 0.691216 0 0.69622 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=99975, meanQ=4.970985, numObservations: 5
action 0, numVisits=60, meanQ=4.107505, numObservations: 1
action -1, numVisits=22, meanQ=3.496820, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 172875 episodes
GETTING ACTION FROM:
action 2, numVisits=272849, meanQ=5.133375, numObservations: 5
action 0, numVisits=61, meanQ=4.096065, numObservations: 1
action -1, numVisits=22, meanQ=3.496820, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.256375 0.692394 0.667054 0.82124 0.674162 0.885286 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 485
Initial state: 0 0.690262 0.845752 0.637651 0.820287 0.122041 0.758653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170587 episodes
GETTING ACTION FROM:
action 1, numVisits=170571, meanQ=5.140148, numObservations: 5
action 3, numVisits=8, meanQ=2.375000, numObservations: 3
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.690262 0.845752 0.637651 0.820287 0.122041 0.758653 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 486
Initial state: 0 0.683984 0.882186 0.43457 0.851594 0.52378 0.891244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170861 episodes
GETTING ACTION FROM:
action 1, numVisits=170784, meanQ=5.024007, numObservations: 4
action 3, numVisits=67, meanQ=4.134630, numObservations: 4
action 2, numVisits=6, meanQ=1.498333, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.683984 0.882186 0.43457 0.851594 0.52378 0.891244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 487
Initial state: 0 0.520504 0.853263 0.0191372 0.133121 0.615544 0.869215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169289 episodes
GETTING ACTION FROM:
action 2, numVisits=169220, meanQ=4.943813, numObservations: 5
action 0, numVisits=65, meanQ=4.094987, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.520504 0.853263 0.0191372 0.133121 0.615544 0.869215 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=19241, meanQ=8.506377, numObservations: 3
action 3, numVisits=19, meanQ=7.103684, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 86742 episodes
GETTING ACTION FROM:
action 1, numVisits=56773, meanQ=6.922463, numObservations: 4
action 3, numVisits=46273, meanQ=6.258497, numObservations: 4
action -1, numVisits=2598, meanQ=-0.688017, numObservations: 1
action 0, numVisits=360, meanQ=-0.914570, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.520504 0.853263 0.0191372 0.133121 0.615544 0.869215 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 488
Initial state: 0 0.581306 0.815265 0.665145 0.83593 0.223669 0.68331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171503 episodes
GETTING ACTION FROM:
action 1, numVisits=171463, meanQ=5.024542, numObservations: 3
action -1, numVisits=36, meanQ=3.874892, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.581306 0.815265 0.665145 0.83593 0.223669 0.68331 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 489
Initial state: 0 0.873554 0.474136 0.656838 0.895664 0.583895 0.823868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170676 episodes
GETTING ACTION FROM:
action 1, numVisits=170531, meanQ=4.975048, numObservations: 4
action -1, numVisits=141, meanQ=4.394529, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.873554 0.474136 0.656838 0.895664 0.583895 0.823868 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 490
Initial state: 0 0.645591 0.820905 0.304723 0.228037 0.558453 0.847477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161141 episodes
GETTING ACTION FROM:
action 3, numVisits=161133, meanQ=4.851002, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.645591 0.820905 0.304723 0.228037 0.558453 0.847477 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 491
Initial state: 0 0.190892 0.716047 0.554151 0.858801 0.568311 0.838191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160581 episodes
GETTING ACTION FROM:
action 2, numVisits=160403, meanQ=4.767414, numObservations: 4
action 3, numVisits=173, meanQ=4.083112, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.190892 0.716047 0.554151 0.858801 0.568311 0.838191 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 492
Initial state: 0 0.983932 0.613207 0.693682 0.844126 0.616275 0.890596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170244 episodes
GETTING ACTION FROM:
action 3, numVisits=170235, meanQ=5.054971, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.983932 0.613207 0.693682 0.844126 0.616275 0.890596 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 493
Initial state: 0 0.578151 0.87364 0.911406 0.978079 0.608564 0.887967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96004 episodes
GETTING ACTION FROM:
action -1, numVisits=95985, meanQ=2.765958, numObservations: 1
action 3, numVisits=9, meanQ=-0.877778, numObservations: 2
action 2, numVisits=7, meanQ=-1.428571, numObservations: 4
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.578151 0.87364 0.911406 0.978079 0.608564 0.887967 w: 1
Observation: 0 0.595622 0 0.987024 0 0.536647 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=95968, meanQ=4.802726, numObservations: 4
action 1, numVisits=11, meanQ=1.727273, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 162912 episodes
GETTING ACTION FROM:
action 2, numVisits=258879, meanQ=4.951314, numObservations: 4
action 1, numVisits=11, meanQ=1.727273, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.578151 0.87364 0.911406 0.978079 0.608564 0.887967 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 494
Initial state: 0 0.568531 0.849796 0.669964 0.867627 0.286064 0.323319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163062 episodes
GETTING ACTION FROM:
action 3, numVisits=161573, meanQ=5.026025, numObservations: 5
action -1, numVisits=1485, meanQ=2.872700, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.568531 0.849796 0.669964 0.867627 0.286064 0.323319 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=18196, meanQ=8.540112, numObservations: 3
action 2, numVisits=11, meanQ=6.455464, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 57596 episodes
GETTING ACTION FROM:
action 1, numVisits=56844, meanQ=6.837792, numObservations: 4
action 2, numVisits=16990, meanQ=5.707845, numObservations: 5
action -1, numVisits=1756, meanQ=-0.253969, numObservations: 1
action 0, numVisits=215, meanQ=-0.573162, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.568531 0.849796 0.669964 0.867627 0.286064 0.323319 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1417, meanQ=8.534377, numObservations: 3
action 2, numVisits=11, meanQ=5.060166, numObservations: 3
action 0, numVisits=708, meanQ=5.058060, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 135873 episodes
GETTING ACTION FROM:
action 1, numVisits=2033, meanQ=7.618245, numObservations: 4
action 2, numVisits=125122, meanQ=5.547736, numObservations: 4
action 0, numVisits=10789, meanQ=-1.250460, numObservations: 3
action -1, numVisits=67, meanQ=-2.029996, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.568531 0.849796 0.669964 0.867627 0.286064 0.323319 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 495
Initial state: 0 0.559929 0.869474 0.797691 0.59986 0.606136 0.842149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168094 episodes
GETTING ACTION FROM:
action 2, numVisits=168082, meanQ=4.988869, numObservations: 5
action 1, numVisits=5, meanQ=1.398000, numObservations: 4
action 3, numVisits=3, meanQ=-0.659967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.559929 0.869474 0.797691 0.59986 0.606136 0.842149 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 496
Initial state: 0 0.263617 0.691983 0.533283 0.824794 0.553227 0.860032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 170691 episodes
GETTING ACTION FROM:
action 2, numVisits=169350, meanQ=5.012198, numObservations: 4
action 3, numVisits=1336, meanQ=4.828635, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.263617 0.691983 0.533283 0.824794 0.553227 0.860032 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 497
Initial state: 0 0.945275 0.14593 0.656351 0.80515 0.638504 0.885018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 168358 episodes
GETTING ACTION FROM:
action 2, numVisits=164433, meanQ=4.999899, numObservations: 5
action -1, numVisits=3912, meanQ=2.984596, numObservations: 1
action 1, numVisits=10, meanQ=1.192010, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.945275 0.14593 0.656351 0.80515 0.638504 0.885018 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 498
Initial state: 0 0.543599 0.868104 0.603065 0.768812 0.617504 0.834286 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 100288 episodes
GETTING ACTION FROM:
action -1, numVisits=100266, meanQ=2.849670, numObservations: 1
action 2, numVisits=13, meanQ=0.084615, numObservations: 4
action 1, numVisits=6, meanQ=-0.515000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.543599 0.868104 0.603065 0.768812 0.617504 0.834286 w: 1
Observation: 0 0.570273 0 0.552673 0 0.566681 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=100186, meanQ=4.924129, numObservations: 3
action -1, numVisits=75, meanQ=4.100750, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 172292 episodes
GETTING ACTION FROM:
action 2, numVisits=272477, meanQ=5.054058, numObservations: 3
action -1, numVisits=76, meanQ=4.084633, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.543599 0.868104 0.603065 0.768812 0.617504 0.834286 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 499
Initial state: 0 0.576453 0.820308 0.552775 0.893427 0.902882 0.891024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 171398 episodes
GETTING ACTION FROM:
action 1, numVisits=171349, meanQ=4.982186, numObservations: 5
action -1, numVisits=26, meanQ=3.621811, numObservations: 1
action 2, numVisits=20, meanQ=3.349510, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.576453 0.820308 0.552775 0.893427 0.902882 0.891024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 500
Initial state: 0 0.393022 0.491513 0.69335 0.819369 0.672775 0.813614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167258 episodes
GETTING ACTION FROM:
action 3, numVisits=161958, meanQ=5.006536, numObservations: 3
action 0, numVisits=5296, meanQ=3.060931, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.393022 0.491513 0.69335 0.819369 0.672775 0.813614 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11827, meanQ=5.610993, numObservations: 4
action 2, numVisits=14, meanQ=3.856429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 212886 episodes
GETTING ACTION FROM:
action 2, numVisits=207998, meanQ=5.745407, numObservations: 3
action 3, numVisits=16727, meanQ=5.461305, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.393022 0.491513 0.69335 0.819369 0.672775 0.813614 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
