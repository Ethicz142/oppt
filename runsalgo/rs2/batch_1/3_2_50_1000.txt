Run # 1
Initial state: 0 0.568291 0.848447 0.0844295 0.229535 0.660145 0.865792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53958 episodes
GETTING ACTION FROM:
action 3, numVisits=53952, meanQ=4.884315, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.568291 0.848447 0.0844295 0.229535 0.660145 0.865792 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.691416 0.816745 0.609234 0.0313196 0.65632 0.858733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55575 episodes
GETTING ACTION FROM:
action 1, numVisits=55569, meanQ=4.978197, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.691416 0.816745 0.609234 0.0313196 0.65632 0.858733 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 3
Initial state: 0 0.546848 0.87987 0.124006 0.253526 0.517397 0.803955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55094 episodes
GETTING ACTION FROM:
action 3, numVisits=54962, meanQ=4.881052, numObservations: 5
action -1, numVisits=61, meanQ=4.026071, numObservations: 1
action 0, numVisits=32, meanQ=3.679130, numObservations: 1
action 2, numVisits=34, meanQ=3.601474, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 1
action: 3
Next state: 1 0.546848 0.87987 0.124006 0.253526 0.517397 0.803955 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 4
Initial state: 0 0.366023 0.0131174 0.6882 0.840715 0.609784 0.865065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55480 episodes
GETTING ACTION FROM:
action 1, numVisits=55405, meanQ=4.994179, numObservations: 3
action 3, numVisits=45, meanQ=3.893113, numObservations: 4
action 0, numVisits=20, meanQ=3.496788, numObservations: 1
action 2, numVisits=8, meanQ=1.863750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.366023 0.0131174 0.6882 0.840715 0.609784 0.865065 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9103, meanQ=8.319497, numObservations: 4
action 3, numVisits=10, meanQ=5.799000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10383 episodes
GETTING ACTION FROM:
action 2, numVisits=13942, meanQ=7.498970, numObservations: 4
action 3, numVisits=189, meanQ=5.675045, numObservations: 3
action 0, numVisits=5352, meanQ=-0.255513, numObservations: 1
action -1, numVisits=13, meanQ=-30.455616, numObservations: 1
action 1, numVisits=3, meanQ=-128.061888, numObservations: 2
action: 2
Next state: 1 0.366023 0.0131174 0.6882 0.840715 0.609784 0.865065 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 5
Initial state: 0 0.435665 0.45811 0.547697 0.828705 0.647156 0.811292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55478 episodes
GETTING ACTION FROM:
action 3, numVisits=55471, meanQ=5.016900, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.435665 0.45811 0.547697 0.828705 0.647156 0.811292 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 6
Initial state: 0 0.647068 0.845583 0.672524 0.896407 0.480679 0.955046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54772 episodes
GETTING ACTION FROM:
action 2, numVisits=54766, meanQ=4.951614, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.647068 0.845583 0.672524 0.896407 0.480679 0.955046 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 7
Initial state: 0 0.542811 0.872386 0.619976 0.828048 0.909414 0.592732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53270 episodes
GETTING ACTION FROM:
action 1, numVisits=53263, meanQ=4.894970, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.542811 0.872386 0.619976 0.828048 0.909414 0.592732 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 8
Initial state: 0 0.523274 0.853654 0.618183 0.82238 0.41605 0.442799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32662 episodes
GETTING ACTION FROM:
action -1, numVisits=32650, meanQ=2.994703, numObservations: 1
action 3, numVisits=8, meanQ=0.625012, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.523274 0.853654 0.618183 0.82238 0.41605 0.442799 w: 1
Observation: 0 0.529075 0 0.567151 0 0.511667 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32563, meanQ=4.989025, numObservations: 4
action 0, numVisits=77, meanQ=4.249716, numObservations: 1
action 3, numVisits=6, meanQ=2.333350, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55708 episodes
GETTING ACTION FROM:
action 2, numVisits=88266, meanQ=4.947793, numObservations: 4
action 0, numVisits=79, meanQ=4.199073, numObservations: 1
action 3, numVisits=9, meanQ=1.878900, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.523274 0.853654 0.618183 0.82238 0.41605 0.442799 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 9
Initial state: 0 0.6195 0.850507 0.554093 0.862017 0.879307 0.25195 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55459 episodes
GETTING ACTION FROM:
action 1, numVisits=55427, meanQ=4.959081, numObservations: 4
action -1, numVisits=17, meanQ=3.348730, numObservations: 1
action 3, numVisits=12, meanQ=1.915833, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.6195 0.850507 0.554093 0.862017 0.879307 0.25195 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 10
Initial state: 0 0.568465 0.847271 0.036477 0.0810504 0.657441 0.864153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55484 episodes
GETTING ACTION FROM:
action 3, numVisits=55429, meanQ=4.979262, numObservations: 4
action 0, numVisits=48, meanQ=4.025058, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.568465 0.847271 0.036477 0.0810504 0.657441 0.864153 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 11
Initial state: 0 0.533898 0.846406 0.663514 0.866304 0.813215 0.663531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55413 episodes
GETTING ACTION FROM:
action 2, numVisits=55385, meanQ=4.945099, numObservations: 4
action 0, numVisits=24, meanQ=3.599283, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.533898 0.846406 0.663514 0.866304 0.813215 0.663531 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4040, meanQ=4.718863, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 69130 episodes
GETTING ACTION FROM:
action 3, numVisits=73169, meanQ=5.831642, numObservations: 5
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.533898 0.846406 0.663514 0.866304 0.813215 0.663531 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 12
Initial state: 0 0.643531 0.892175 0.547714 0.828905 0.963521 0.862879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55141 episodes
GETTING ACTION FROM:
action 1, numVisits=55109, meanQ=4.928648, numObservations: 5
action 3, numVisits=27, meanQ=2.592230, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.643531 0.892175 0.547714 0.828905 0.963521 0.862879 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 13
Initial state: 0 0.547658 0.849558 0.672592 0.819944 0.22148 0.539049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55419 episodes
GETTING ACTION FROM:
action 3, numVisits=55413, meanQ=5.016716, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.547658 0.849558 0.672592 0.819944 0.22148 0.539049 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3289, meanQ=8.528213, numObservations: 3
action 2, numVisits=3089, meanQ=8.523438, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10909 episodes
GETTING ACTION FROM:
action 2, numVisits=3089, meanQ=8.523438, numObservations: 3
action 1, numVisits=3611, meanQ=8.252248, numObservations: 5
action 0, numVisits=10584, meanQ=0.129004, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=5, meanQ=-78.172044, numObservations: 1
action: 2
Next state: 1 0.547658 0.849558 0.672592 0.819944 0.22148 0.539049 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 14
Initial state: 0 0.565567 0.891279 0.605164 0.876487 0.0159232 0.626645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53174 episodes
GETTING ACTION FROM:
action 1, numVisits=53168, meanQ=5.028635, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.565567 0.891279 0.605164 0.876487 0.0159232 0.626645 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 15
Initial state: 0 0.184096 0.36149 0.511332 0.89763 0.59582 0.870588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55449 episodes
GETTING ACTION FROM:
action 2, numVisits=55411, meanQ=4.926784, numObservations: 4
action 0, numVisits=29, meanQ=3.693569, numObservations: 1
action 1, numVisits=6, meanQ=1.498333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.184096 0.36149 0.511332 0.89763 0.59582 0.870588 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 16
Initial state: 0 0.747622 0.230339 0.500511 0.8051 0.648902 0.895338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32650 episodes
GETTING ACTION FROM:
action -1, numVisits=32639, meanQ=2.924237, numObservations: 1
action 3, numVisits=5, meanQ=-1.402000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 1
action: -1
Next state: 0 0.747622 0.230339 0.500511 0.8051 0.648902 0.895338 w: 1
Observation: 0 0.678584 0 0.532374 0 0.710559 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32523, meanQ=4.978632, numObservations: 4
action 0, numVisits=94, meanQ=4.339215, numObservations: 1
action 2, numVisits=18, meanQ=3.000017, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55039 episodes
GETTING ACTION FROM:
action 1, numVisits=87534, meanQ=4.676069, numObservations: 4
action 0, numVisits=122, meanQ=4.084567, numObservations: 1
action 2, numVisits=18, meanQ=3.000017, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.747622 0.230339 0.500511 0.8051 0.648902 0.895338 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 17
Initial state: 0 0.859702 0.911832 0.57706 0.821572 0.575318 0.834718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32695 episodes
GETTING ACTION FROM:
action -1, numVisits=32681, meanQ=2.756313, numObservations: 1
action 1, numVisits=10, meanQ=0.499000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.859702 0.911832 0.57706 0.821572 0.575318 0.834718 w: 1
Observation: 0 0.799762 0 0.617717 0 0.599725 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32672, meanQ=4.881374, numObservations: 4
action 3, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55852 episodes
GETTING ACTION FROM:
action 1, numVisits=88522, meanQ=5.064294, numObservations: 4
action 3, numVisits=4, meanQ=-0.999975, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-3.505000, numObservations: 2
action: 1
Next state: 1 0.859702 0.911832 0.57706 0.821572 0.575318 0.834718 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 18
Initial state: 0 0.722491 0.701108 0.558027 0.804418 0.68586 0.877459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47585 episodes
GETTING ACTION FROM:
action 2, numVisits=47576, meanQ=4.551830, numObservations: 4
action 1, numVisits=4, meanQ=-0.222500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.722491 0.701108 0.558027 0.804418 0.68586 0.877459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 19
Initial state: 0 0.623331 0.872199 0.596157 0.925518 0.560043 0.898665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55141 episodes
GETTING ACTION FROM:
action 2, numVisits=55103, meanQ=4.973952, numObservations: 4
action 0, numVisits=29, meanQ=3.643842, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.623331 0.872199 0.596157 0.925518 0.560043 0.898665 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 20
Initial state: 0 0.00617756 0.124793 0.509474 0.850912 0.570266 0.808969 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55322 episodes
GETTING ACTION FROM:
action 3, numVisits=55259, meanQ=4.911104, numObservations: 4
action 0, numVisits=59, meanQ=4.035772, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.00617756 0.124793 0.509474 0.850912 0.570266 0.808969 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 21
Initial state: 0 0.656377 0.891781 0.698573 0.881059 0.705617 0.164584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55672 episodes
GETTING ACTION FROM:
action 1, numVisits=55663, meanQ=4.964917, numObservations: 4
action 3, numVisits=4, meanQ=0.750000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.656377 0.891781 0.698573 0.881059 0.705617 0.164584 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 22
Initial state: 0 0.404575 0.617699 0.508954 0.896528 0.559013 0.878728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55695 episodes
GETTING ACTION FROM:
action 1, numVisits=55667, meanQ=4.992542, numObservations: 5
action 2, numVisits=22, meanQ=3.590014, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.404575 0.617699 0.508954 0.896528 0.559013 0.878728 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1412, meanQ=7.656214, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7524 episodes
GETTING ACTION FROM:
action 2, numVisits=5101, meanQ=6.544813, numObservations: 4
action -1, numVisits=3822, meanQ=0.149662, numObservations: 1
action 0, numVisits=14, meanQ=-1.435700, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.404575 0.617699 0.508954 0.896528 0.559013 0.878728 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 23
Initial state: 0 0.692619 0.823391 0.596818 0.877113 0.900087 0.448395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55388 episodes
GETTING ACTION FROM:
action 2, numVisits=55369, meanQ=4.952511, numObservations: 4
action 3, numVisits=14, meanQ=2.843571, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.692619 0.823391 0.596818 0.877113 0.900087 0.448395 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 24
Initial state: 0 0.997503 0.775392 0.52927 0.896723 0.553107 0.89386 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55154 episodes
GETTING ACTION FROM:
action 1, numVisits=55141, meanQ=4.975012, numObservations: 4
action 3, numVisits=7, meanQ=0.428571, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.997503 0.775392 0.52927 0.896723 0.553107 0.89386 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 25
Initial state: 0 0.565933 0.812812 0.362138 0.80164 0.66483 0.837315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55153 episodes
GETTING ACTION FROM:
action 2, numVisits=55103, meanQ=4.979656, numObservations: 5
action -1, numVisits=45, meanQ=1.974557, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.565933 0.812812 0.362138 0.80164 0.66483 0.837315 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1393, meanQ=7.902097, numObservations: 3
action 1, numVisits=9, meanQ=5.443333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 13070 episodes
GETTING ACTION FROM:
action 3, numVisits=3205, meanQ=6.660671, numObservations: 3
action 1, numVisits=6899, meanQ=5.797933, numObservations: 4
action 0, numVisits=4361, meanQ=0.106441, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=9, meanQ=-3.449195, numObservations: 1
action: 3
Next state: 1 0.565933 0.812812 0.362138 0.80164 0.66483 0.837315 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 26
Initial state: 0 0.667888 0.832103 0.53448 0.825457 0.806647 0.630989 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55266 episodes
GETTING ACTION FROM:
action 3, numVisits=55257, meanQ=4.974831, numObservations: 5
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.667888 0.832103 0.53448 0.825457 0.806647 0.630989 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.501214 0.893638 0.764346 0.541806 0.528138 0.848584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55586 episodes
GETTING ACTION FROM:
action 2, numVisits=55540, meanQ=4.988189, numObservations: 3
action 0, numVisits=31, meanQ=3.805494, numObservations: 1
action 1, numVisits=12, meanQ=2.333342, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.501214 0.893638 0.764346 0.541806 0.528138 0.848584 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 28
Initial state: 0 0.527475 0.840833 0.630173 0.862588 0.40939 0.649708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52579 episodes
GETTING ACTION FROM:
action 1, numVisits=52515, meanQ=4.812420, numObservations: 5
action 0, numVisits=60, meanQ=3.976319, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.527475 0.840833 0.630173 0.862588 0.40939 0.649708 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 29
Initial state: 0 0.107678 0.75872 0.537481 0.801474 0.648415 0.841055 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32609 episodes
GETTING ACTION FROM:
action 0, numVisits=30946, meanQ=3.399725, numObservations: 2
action -1, numVisits=1657, meanQ=2.686023, numObservations: 1
action 2, numVisits=4, meanQ=-0.752475, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.107678 0.75872 0.537481 0.801474 0.648415 0.841055 w: 1
Observation: 0 0 0.813182 0 0.841476 0 0.772906 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22978, meanQ=4.236827, numObservations: 4
action -1, numVisits=110, meanQ=3.656509, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 52316 episodes
GETTING ACTION FROM:
action 3, numVisits=75293, meanQ=4.749083, numObservations: 4
action -1, numVisits=111, meanQ=3.648710, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.107678 0.75872 0.537481 0.801474 0.648415 0.841055 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 30
Initial state: 0 0.549696 0.830487 0.549555 0.887325 0.993088 0.0370382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54722 episodes
GETTING ACTION FROM:
action 1, numVisits=54713, meanQ=4.988174, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.549696 0.830487 0.549555 0.887325 0.993088 0.0370382 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 31
Initial state: 0 0.2586 0.558662 0.677944 0.869765 0.647712 0.851713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55299 episodes
GETTING ACTION FROM:
action 3, numVisits=50542, meanQ=5.065958, numObservations: 5
action 1, numVisits=4597, meanQ=4.952987, numObservations: 5
action -1, numVisits=114, meanQ=4.428242, numObservations: 1
action 0, numVisits=45, meanQ=4.039095, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.2586 0.558662 0.677944 0.869765 0.647712 0.851713 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 32
Initial state: 0 0.21645 0.462209 0.502191 0.895553 0.602375 0.805428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54736 episodes
GETTING ACTION FROM:
action 3, numVisits=54700, meanQ=4.959377, numObservations: 4
action 0, numVisits=21, meanQ=3.497455, numObservations: 1
action -1, numVisits=10, meanQ=2.485195, numObservations: 1
action 1, numVisits=4, meanQ=-0.272500, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.21645 0.462209 0.502191 0.895553 0.602375 0.805428 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 33
Initial state: 0 0.485615 0.180695 0.51131 0.801763 0.657975 0.80491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55469 episodes
GETTING ACTION FROM:
action 1, numVisits=55463, meanQ=5.188171, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.485615 0.180695 0.51131 0.801763 0.657975 0.80491 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3600, meanQ=8.575709, numObservations: 3
action 2, numVisits=2791, meanQ=8.518279, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11658 episodes
GETTING ACTION FROM:
action 2, numVisits=3457, meanQ=7.954681, numObservations: 5
action 1, numVisits=12, meanQ=7.658333, numObservations: 3
action 3, numVisits=11008, meanQ=6.916394, numObservations: 4
action 0, numVisits=3570, meanQ=0.156087, numObservations: 1
action -1, numVisits=5, meanQ=-3.844010, numObservations: 1
action: 2
Next state: 0 0.485615 0.180695 0.51131 0.801763 0.657975 0.80491 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=176, meanQ=8.508751, numObservations: 3
action 2, numVisits=36, meanQ=7.991944, numObservations: 3
action -1, numVisits=18, meanQ=6.470000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10965 episodes
GETTING ACTION FROM:
action 2, numVisits=74, meanQ=7.158243, numObservations: 4
action 3, numVisits=1828, meanQ=6.378857, numObservations: 3
action -1, numVisits=9289, meanQ=-1.576887, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=5, meanQ=-75.878561, numObservations: 1
action: 2
Next state: 1 0.485615 0.180695 0.51131 0.801763 0.657975 0.80491 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 34
Initial state: 0 0.515164 0.81864 0.53335 0.820465 0.791818 0.0712658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55619 episodes
GETTING ACTION FROM:
action 1, numVisits=55610, meanQ=5.077709, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=3, meanQ=-3.296667, numObservations: 1
action: 1
Next state: 1 0.515164 0.81864 0.53335 0.820465 0.791818 0.0712658 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 35
Initial state: 0 0.0828261 0.140887 0.503729 0.81264 0.565541 0.859848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31806 episodes
GETTING ACTION FROM:
action 0, numVisits=31796, meanQ=2.782887, numObservations: 1
action 2, numVisits=6, meanQ=0.166667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0828261 0.140887 0.503729 0.81264 0.565541 0.859848 w: 1
Observation: 0 0 0.203872 0 0.77714 0 0.814452 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31782, meanQ=4.780689, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 53182 episodes
GETTING ACTION FROM:
action 1, numVisits=84963, meanQ=4.802062, numObservations: 4
action 3, numVisits=5, meanQ=1.780000, numObservations: 2
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0828261 0.140887 0.503729 0.81264 0.565541 0.859848 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=14028, meanQ=8.311671, numObservations: 3
action 2, numVisits=20, meanQ=6.900510, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 17032 episodes
GETTING ACTION FROM:
action 3, numVisits=29193, meanQ=7.351716, numObservations: 3
action 2, numVisits=73, meanQ=5.643772, numObservations: 5
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=1550, meanQ=0.299994, numObservations: 1
action -1, numVisits=264, meanQ=0.062500, numObservations: 1
action: 3
Next state: 1 0.0828261 0.140887 0.503729 0.81264 0.565541 0.859848 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 36
Initial state: 0 0.59159 0.914341 0.625627 0.821239 0.692671 0.895824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52850 episodes
GETTING ACTION FROM:
action 2, numVisits=52790, meanQ=4.822147, numObservations: 3
action -1, numVisits=27, meanQ=3.497764, numObservations: 1
action 0, numVisits=18, meanQ=3.160868, numObservations: 1
action 1, numVisits=11, meanQ=1.727273, numObservations: 4
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action: 2
Next state: 1 0.59159 0.914341 0.625627 0.821239 0.692671 0.895824 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 37
Initial state: 0 0.542264 0.885881 0.529095 0.865397 0.0777152 0.407283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55938 episodes
GETTING ACTION FROM:
action 3, numVisits=55915, meanQ=5.054651, numObservations: 4
action 0, numVisits=19, meanQ=3.275690, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.542264 0.885881 0.529095 0.865397 0.0777152 0.407283 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9019, meanQ=8.336083, numObservations: 4
action 1, numVisits=37, meanQ=7.215951, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11692 episodes
GETTING ACTION FROM:
action 2, numVisits=10463, meanQ=7.997276, numObservations: 4
action 1, numVisits=62, meanQ=6.224202, numObservations: 3
action 0, numVisits=10145, meanQ=0.145699, numObservations: 1
action -1, numVisits=80, meanQ=-0.522884, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.542264 0.885881 0.529095 0.865397 0.0777152 0.407283 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 38
Initial state: 0 0.640517 0.862156 0.0995158 0.119055 0.657783 0.89518 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32572 episodes
GETTING ACTION FROM:
action -1, numVisits=32567, meanQ=2.847569, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.640517 0.862156 0.0995158 0.119055 0.657783 0.89518 w: 1
Observation: 0 0.686453 0 0.171913 0 0.561605 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32475, meanQ=4.947401, numObservations: 4
action 0, numVisits=80, meanQ=4.224082, numObservations: 1
action 3, numVisits=6, meanQ=2.001700, numObservations: 2
action 2, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 55728 episodes
GETTING ACTION FROM:
action 1, numVisits=88199, meanQ=4.933544, numObservations: 4
action 0, numVisits=84, meanQ=4.216783, numObservations: 1
action 3, numVisits=6, meanQ=2.001700, numObservations: 2
action 2, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.640517 0.862156 0.0995158 0.119055 0.657783 0.89518 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 39
Initial state: 0 0.593283 0.815528 0.539457 0.878257 0.817373 0.573341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55140 episodes
GETTING ACTION FROM:
action 3, numVisits=55134, meanQ=5.020678, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.593283 0.815528 0.539457 0.878257 0.817373 0.573341 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.45101 0.213366 0.687649 0.874738 0.544457 0.85321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55402 episodes
GETTING ACTION FROM:
action 2, numVisits=55396, meanQ=4.967431, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.45101 0.213366 0.687649 0.874738 0.544457 0.85321 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 41
Initial state: 0 0.510836 0.841985 0.510493 0.81088 0.8315 0.0404591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47604 episodes
GETTING ACTION FROM:
action 3, numVisits=47483, meanQ=4.503386, numObservations: 4
action 0, numVisits=117, meanQ=3.911371, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.510836 0.841985 0.510493 0.81088 0.8315 0.0404591 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=3469, meanQ=3.381578, numObservations: 1
action 2, numVisits=35, meanQ=2.135154, numObservations: 4
action 3, numVisits=3, meanQ=-0.329967, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 14782 episodes
GETTING ACTION FROM:
action 2, numVisits=35, meanQ=2.135154, numObservations: 4
action -1, numVisits=18247, meanQ=0.429651, numObservations: 1
action 3, numVisits=3, meanQ=-0.329967, numObservations: 1
action 0, numVisits=5, meanQ=-2.397980, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action: 2
Next state: 1 0.510836 0.841985 0.510493 0.81088 0.8315 0.0404591 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 42
Initial state: 0 0.501081 0.855893 0.209735 0.7794 0.57602 0.825142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55710 episodes
GETTING ACTION FROM:
action 1, numVisits=55652, meanQ=4.987399, numObservations: 4
action 0, numVisits=27, meanQ=3.664917, numObservations: 1
action 2, numVisits=22, meanQ=3.414091, numObservations: 3
action 3, numVisits=7, meanQ=2.428571, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.501081 0.855893 0.209735 0.7794 0.57602 0.825142 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 43
Initial state: 0 0.258628 0.578959 0.669821 0.868599 0.665491 0.851159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55254 episodes
GETTING ACTION FROM:
action 1, numVisits=55204, meanQ=4.947741, numObservations: 3
action 0, numVisits=46, meanQ=3.970129, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.258628 0.578959 0.669821 0.868599 0.665491 0.851159 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9127, meanQ=8.296177, numObservations: 4
action 2, numVisits=6, meanQ=4.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 16754 episodes
GETTING ACTION FROM:
action 3, numVisits=22730, meanQ=6.910593, numObservations: 4
action 2, numVisits=167, meanQ=6.387217, numObservations: 4
action 0, numVisits=2981, meanQ=0.142717, numObservations: 3
action -1, numVisits=10, meanQ=-2.100980, numObservations: 1
action 1, numVisits=2, meanQ=-195.969998, numObservations: 1
action: 3
Next state: 1 0.258628 0.578959 0.669821 0.868599 0.665491 0.851159 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 44
Initial state: 0 0.639899 0.855482 0.851374 0.493354 0.593798 0.849868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55331 episodes
GETTING ACTION FROM:
action 3, numVisits=55260, meanQ=4.958130, numObservations: 3
action 0, numVisits=67, meanQ=4.169503, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.639899 0.855482 0.851374 0.493354 0.593798 0.849868 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 45
Initial state: 0 0.827795 0.723486 0.595259 0.899278 0.59787 0.899783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54131 episodes
GETTING ACTION FROM:
action 1, numVisits=54122, meanQ=4.861517, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.827795 0.723486 0.595259 0.899278 0.59787 0.899783 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 46
Initial state: 0 0.676227 0.839981 0.635136 0.857015 0.818225 0.303852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55131 episodes
GETTING ACTION FROM:
action 2, numVisits=55107, meanQ=5.012018, numObservations: 5
action 3, numVisits=14, meanQ=2.993579, numObservations: 2
action 1, numVisits=6, meanQ=1.506700, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.676227 0.839981 0.635136 0.857015 0.818225 0.303852 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 47
Initial state: 0 0.667855 0.822291 0.525164 0.807272 0.594992 0.7217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55483 episodes
GETTING ACTION FROM:
action 3, numVisits=55460, meanQ=5.161778, numObservations: 4
action 0, numVisits=19, meanQ=3.584894, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.667855 0.822291 0.525164 0.807272 0.594992 0.7217 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3773, meanQ=7.340212, numObservations: 4
action 2, numVisits=9, meanQ=4.108889, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 67937 episodes
GETTING ACTION FROM:
action 2, numVisits=59824, meanQ=5.828058, numObservations: 5
action 3, numVisits=11892, meanQ=5.777223, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 2
Next state: 1 0.667855 0.822291 0.525164 0.807272 0.594992 0.7217 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 48
Initial state: 0 0.669436 0.893132 0.841075 0.7598 0.567715 0.864584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55318 episodes
GETTING ACTION FROM:
action 2, numVisits=55229, meanQ=4.992508, numObservations: 4
action -1, numVisits=47, meanQ=3.976709, numObservations: 1
action 3, numVisits=30, meanQ=3.329350, numObservations: 3
action 1, numVisits=10, meanQ=2.499000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.669436 0.893132 0.841075 0.7598 0.567715 0.864584 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 49
Initial state: 0 0.683799 0.87661 0.666546 0.899231 0.307939 0.493002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55185 episodes
GETTING ACTION FROM:
action 3, numVisits=55130, meanQ=4.960276, numObservations: 5
action 0, numVisits=51, meanQ=4.043007, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.683799 0.87661 0.666546 0.899231 0.307939 0.493002 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6238, meanQ=8.486190, numObservations: 3
action 1, numVisits=9, meanQ=6.110011, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12134 episodes
GETTING ACTION FROM:
action 2, numVisits=15425, meanQ=7.104076, numObservations: 4
action 1, numVisits=180, meanQ=5.843725, numObservations: 4
action 0, numVisits=2761, meanQ=0.204100, numObservations: 1
action -1, numVisits=17, meanQ=-1.417647, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.683799 0.87661 0.666546 0.899231 0.307939 0.493002 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 50
Initial state: 0 0.434036 0.0132902 0.581692 0.86094 0.625648 0.837597 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53170 episodes
GETTING ACTION FROM:
action 1, numVisits=51656, meanQ=5.044646, numObservations: 5
action -1, numVisits=1507, meanQ=1.272849, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.434036 0.0132902 0.581692 0.86094 0.625648 0.837597 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7133, meanQ=8.417564, numObservations: 4
action 2, numVisits=7, meanQ=5.568571, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 11168 episodes
GETTING ACTION FROM:
action 3, numVisits=12735, meanQ=7.285376, numObservations: 4
action 2, numVisits=13, meanQ=2.536923, numObservations: 4
action 0, numVisits=5553, meanQ=0.201605, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=8, meanQ=-3.237500, numObservations: 1
action: 3
Next state: 0 0.434036 0.0132902 0.581692 0.86094 0.625648 0.837597 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=614, meanQ=8.208656, numObservations: 3
action 2, numVisits=23, meanQ=5.521313, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-192.804011, numObservations: 1
action 0, numVisits=2, meanQ=-192.814772, numObservations: 1
Sampled 51718 episodes
GETTING ACTION FROM:
action 3, numVisits=765, meanQ=7.683307, numObservations: 4
action 2, numVisits=51590, meanQ=6.156089, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-192.804011, numObservations: 1
action 0, numVisits=2, meanQ=-192.814772, numObservations: 1
action: 3
Next state: 1 0.434036 0.0132902 0.581692 0.86094 0.625648 0.837597 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 51
Initial state: 0 0.615871 0.865417 0.666934 0.88966 0.911376 0.462629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54247 episodes
GETTING ACTION FROM:
action 1, numVisits=54148, meanQ=4.858049, numObservations: 4
action -1, numVisits=93, meanQ=4.172824, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.615871 0.865417 0.666934 0.88966 0.911376 0.462629 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 52
Initial state: 0 0.603878 0.882947 0.599372 0.858543 0.344545 0.317304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33821 episodes
GETTING ACTION FROM:
action 0, numVisits=33816, meanQ=5.241525, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.603878 0.882947 0.599372 0.858543 0.344545 0.317304 w: 1
Observation: 0 0 0.949466 0 0.942919 0 0.217493 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16435, meanQ=6.857872, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 52385 episodes
GETTING ACTION FROM:
action 1, numVisits=68818, meanQ=5.286184, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-3.505000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 1
Next state: 1 0.603878 0.882947 0.599372 0.858543 0.344545 0.317304 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 53
Initial state: 0 0.628336 0.852193 0.257711 0.201991 0.613817 0.812137 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55095 episodes
GETTING ACTION FROM:
action 3, numVisits=55036, meanQ=4.972360, numObservations: 4
action -1, numVisits=37, meanQ=3.888296, numObservations: 1
action 2, numVisits=19, meanQ=2.791589, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.628336 0.852193 0.257711 0.201991 0.613817 0.812137 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 54
Initial state: 0 0.659186 0.846817 0.303532 0.110238 0.668017 0.892704 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55310 episodes
GETTING ACTION FROM:
action 2, numVisits=54985, meanQ=5.033889, numObservations: 5
action -1, numVisits=301, meanQ=2.123695, numObservations: 1
action 1, numVisits=17, meanQ=0.807653, numObservations: 3
action 3, numVisits=5, meanQ=-1.600000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.659186 0.846817 0.303532 0.110238 0.668017 0.892704 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6188, meanQ=8.516749, numObservations: 3
action 3, numVisits=60, meanQ=7.726170, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9658 episodes
GETTING ACTION FROM:
action 1, numVisits=12899, meanQ=7.120076, numObservations: 4
action 3, numVisits=892, meanQ=5.745033, numObservations: 4
action 0, numVisits=2113, meanQ=0.353885, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=4, meanQ=-4.475000, numObservations: 1
action: 1
Next state: 1 0.659186 0.846817 0.303532 0.110238 0.668017 0.892704 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 55
Initial state: 0 0.591804 0.802361 0.585071 0.0409678 0.52116 0.876915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55607 episodes
GETTING ACTION FROM:
action 1, numVisits=55515, meanQ=4.998284, numObservations: 5
action -1, numVisits=51, meanQ=4.067195, numObservations: 1
action 0, numVisits=38, meanQ=3.921019, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.591804 0.802361 0.585071 0.0409678 0.52116 0.876915 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 56
Initial state: 0 0.578903 0.863247 0.196748 0.0329661 0.698045 0.802898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32738 episodes
GETTING ACTION FROM:
action 0, numVisits=32719, meanQ=2.905500, numObservations: 1
action 1, numVisits=12, meanQ=0.501675, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=4, meanQ=-2.749975, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.578903 0.863247 0.196748 0.0329661 0.698045 0.802898 w: 1
Observation: 0 0 0.853443 0 0 0 0.856065 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32636, meanQ=4.958523, numObservations: 4
action -1, numVisits=39, meanQ=3.905561, numObservations: 1
action 0, numVisits=31, meanQ=3.778634, numObservations: 1
action 3, numVisits=10, meanQ=2.579000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
Sampled 56478 episodes
GETTING ACTION FROM:
action 1, numVisits=89113, meanQ=5.079043, numObservations: 4
action -1, numVisits=40, meanQ=3.887004, numObservations: 1
action 0, numVisits=31, meanQ=3.778634, numObservations: 1
action 3, numVisits=10, meanQ=2.579000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 1 0.578903 0.863247 0.196748 0.0329661 0.698045 0.802898 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 57
Initial state: 0 0.306153 0.562315 0.635015 0.874127 0.660252 0.825936 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52129 episodes
GETTING ACTION FROM:
action 3, numVisits=52070, meanQ=4.829938, numObservations: 5
action -1, numVisits=55, meanQ=3.945168, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.306153 0.562315 0.635015 0.874127 0.660252 0.825936 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 58
Initial state: 0 0.648705 0.822634 0.535692 0.889986 0.160837 0.00618384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55268 episodes
GETTING ACTION FROM:
action 1, numVisits=55182, meanQ=4.914860, numObservations: 4
action -1, numVisits=79, meanQ=4.190875, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.648705 0.822634 0.535692 0.889986 0.160837 0.00618384 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 59
Initial state: 0 0.65627 0.870873 0.515127 0.825204 0.472163 0.91758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52602 episodes
GETTING ACTION FROM:
action 3, numVisits=52477, meanQ=4.894204, numObservations: 4
action 0, numVisits=100, meanQ=4.192932, numObservations: 1
action -1, numVisits=15, meanQ=3.002502, numObservations: 1
action 2, numVisits=7, meanQ=1.428571, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action: 3
Next state: 0 0.65627 0.870873 0.515127 0.825204 0.472163 0.91758 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=3949, meanQ=4.686946, numObservations: 3
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 60904 episodes
GETTING ACTION FROM:
action 3, numVisits=58655, meanQ=5.253650, numObservations: 3
action 0, numVisits=6199, meanQ=2.825206, numObservations: 3
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.65627 0.870873 0.515127 0.825204 0.472163 0.91758 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 60
Initial state: 0 0.590706 0.809565 0.516458 0.867864 0.731896 0.0162928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55378 episodes
GETTING ACTION FROM:
action 3, numVisits=55346, meanQ=4.922808, numObservations: 3
action 2, numVisits=27, meanQ=3.066674, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.590706 0.809565 0.516458 0.867864 0.731896 0.0162928 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 61
Initial state: 0 0.525257 0.87728 0.642329 0.805456 0.438579 0.107264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55790 episodes
GETTING ACTION FROM:
action 1, numVisits=55765, meanQ=5.187308, numObservations: 5
action 3, numVisits=17, meanQ=3.118241, numObservations: 4
action 2, numVisits=4, meanQ=0.750000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.525257 0.87728 0.642329 0.805456 0.438579 0.107264 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 62
Initial state: 0 0.0893895 0.133572 0.5506 0.85094 0.538758 0.835398 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34356 episodes
GETTING ACTION FROM:
action 0, numVisits=34325, meanQ=5.691649, numObservations: 2
action 1, numVisits=21, meanQ=1.513810, numObservations: 4
action 3, numVisits=7, meanQ=0.854286, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0893895 0.133572 0.5506 0.85094 0.538758 0.835398 w: 1
Observation: 0 0 0.110763 0 0.920685 0 0.86852 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=14063, meanQ=8.245907, numObservations: 3
action 3, numVisits=8, meanQ=4.998750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 49845 episodes
GETTING ACTION FROM:
action 2, numVisits=63882, meanQ=5.540052, numObservations: 3
action 3, numVisits=20, meanQ=3.994000, numObservations: 4
action -1, numVisits=14, meanQ=3.280000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0893895 0.133572 0.5506 0.85094 0.538758 0.835398 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 63
Initial state: 0 0.586368 0.890727 0.666721 0.828668 0.770981 0.894075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55455 episodes
GETTING ACTION FROM:
action 2, numVisits=55408, meanQ=4.934831, numObservations: 3
action -1, numVisits=39, meanQ=3.848622, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.586368 0.890727 0.666721 0.828668 0.770981 0.894075 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4171, meanQ=4.775747, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 68689 episodes
GETTING ACTION FROM:
action 1, numVisits=72857, meanQ=6.070807, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.586368 0.890727 0.666721 0.828668 0.770981 0.894075 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 64
Initial state: 0 0.69751 0.842374 0.627541 0.863586 0.703412 0.278912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52700 episodes
GETTING ACTION FROM:
action 2, numVisits=52643, meanQ=4.902464, numObservations: 4
action -1, numVisits=18, meanQ=3.198800, numObservations: 1
action 3, numVisits=36, meanQ=3.196400, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.69751 0.842374 0.627541 0.863586 0.703412 0.278912 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 65
Initial state: 0 0.502179 0.871953 0.301219 0.760643 0.579 0.844334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55322 episodes
GETTING ACTION FROM:
action 2, numVisits=55315, meanQ=4.928385, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.502179 0.871953 0.301219 0.760643 0.579 0.844334 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9184, meanQ=8.357210, numObservations: 5
action 1, numVisits=23, meanQ=7.088270, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13494 episodes
GETTING ACTION FROM:
action 3, numVisits=21012, meanQ=7.031432, numObservations: 5
action 1, numVisits=294, meanQ=6.043702, numObservations: 4
action -1, numVisits=1394, meanQ=0.282539, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=3, meanQ=-128.281375, numObservations: 1
action: 3
Next state: 1 0.502179 0.871953 0.301219 0.760643 0.579 0.844334 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 66
Initial state: 0 0.5286 0.627579 0.507587 0.869196 0.692443 0.851874 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55430 episodes
GETTING ACTION FROM:
action 2, numVisits=55379, meanQ=5.001079, numObservations: 5
action 0, numVisits=47, meanQ=4.021483, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.5286 0.627579 0.507587 0.869196 0.692443 0.851874 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 67
Initial state: 0 0.562901 0.819201 0.383557 0.480701 0.629075 0.826634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52962 episodes
GETTING ACTION FROM:
action 1, numVisits=52950, meanQ=4.913232, numObservations: 5
action 2, numVisits=7, meanQ=2.428571, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.562901 0.819201 0.383557 0.480701 0.629075 0.826634 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 68
Initial state: 0 0.52584 0.840247 0.127064 0.232479 0.625469 0.815667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54999 episodes
GETTING ACTION FROM:
action 3, numVisits=54920, meanQ=4.902133, numObservations: 4
action -1, numVisits=65, meanQ=4.099835, numObservations: 1
action 1, numVisits=11, meanQ=1.636391, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.52584 0.840247 0.127064 0.232479 0.625469 0.815667 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 69
Initial state: 0 0.189074 0.130417 0.671331 0.840847 0.545488 0.857104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54603 episodes
GETTING ACTION FROM:
action 3, numVisits=54547, meanQ=4.983372, numObservations: 5
action -1, numVisits=44, meanQ=3.990202, numObservations: 1
action 1, numVisits=9, meanQ=2.554444, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.189074 0.130417 0.671331 0.840847 0.545488 0.857104 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 70
Initial state: 0 0.636118 0.875239 0.708243 0.725073 0.615766 0.870354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55327 episodes
GETTING ACTION FROM:
action 3, numVisits=55296, meanQ=5.041780, numObservations: 5
action 0, numVisits=16, meanQ=3.396284, numObservations: 1
action 2, numVisits=7, meanQ=2.428571, numObservations: 3
action 1, numVisits=6, meanQ=2.333333, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.636118 0.875239 0.708243 0.725073 0.615766 0.870354 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4262, meanQ=5.597109, numObservations: 4
action 2, numVisits=5, meanQ=2.598000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 68178 episodes
GETTING ACTION FROM:
action 2, numVisits=67477, meanQ=5.933307, numObservations: 4
action 3, numVisits=4965, meanQ=5.469796, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action: 2
Next state: 2 0.636118 0.875239 0.708243 0.725073 0.615766 0.870354 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 71
Initial state: 0 0.527267 0.827425 0.192384 0.413507 0.663043 0.838009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52945 episodes
GETTING ACTION FROM:
action 3, numVisits=52787, meanQ=5.009698, numObservations: 3
action -1, numVisits=152, meanQ=2.495241, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.527267 0.827425 0.192384 0.413507 0.663043 0.838009 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 72
Initial state: 0 0.540462 0.851035 0.531397 0.871277 0.475113 0.147371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55662 episodes
GETTING ACTION FROM:
action 2, numVisits=55656, meanQ=5.165978, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.540462 0.851035 0.531397 0.871277 0.475113 0.147371 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 73
Initial state: 0 0.52897 0.881907 0.816614 0.102897 0.617765 0.883754 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55292 episodes
GETTING ACTION FROM:
action 3, numVisits=55252, meanQ=5.015451, numObservations: 4
action 0, numVisits=34, meanQ=3.873285, numObservations: 1
action 1, numVisits=3, meanQ=0.663333, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.52897 0.881907 0.816614 0.102897 0.617765 0.883754 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 74
Initial state: 0 0.601494 0.877061 0.538693 0.890834 0.702163 0.767962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 37335 episodes
GETTING ACTION FROM:
action 0, numVisits=29738, meanQ=5.719689, numObservations: 2
action 1, numVisits=7582, meanQ=4.899594, numObservations: 5
action 2, numVisits=12, meanQ=1.332500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.601494 0.877061 0.538693 0.890834 0.702163 0.767962 w: 1
Observation: 0 0 0.865723 0 0.95584 0 0.794371 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=21922, meanQ=7.576971, numObservations: 4
action 1, numVisits=25, meanQ=4.818404, numObservations: 4
action 2, numVisits=9, meanQ=3.667789, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 57053 episodes
GETTING ACTION FROM:
action 3, numVisits=78955, meanQ=5.700525, numObservations: 4
action 1, numVisits=33, meanQ=4.496064, numObservations: 4
action -1, numVisits=11, meanQ=3.622840, numObservations: 1
action 2, numVisits=11, meanQ=3.545464, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.601494 0.877061 0.538693 0.890834 0.702163 0.767962 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 75
Initial state: 0 0.167443 0.280467 0.519425 0.880595 0.558851 0.832035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55832 episodes
GETTING ACTION FROM:
action 3, numVisits=55744, meanQ=5.036783, numObservations: 3
action 0, numVisits=67, meanQ=4.232626, numObservations: 1
action 1, numVisits=18, meanQ=1.936689, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.167443 0.280467 0.519425 0.880595 0.558851 0.832035 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4023, meanQ=5.515654, numObservations: 3
action 2, numVisits=10, meanQ=3.198010, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 62312 episodes
GETTING ACTION FROM:
action 3, numVisits=66333, meanQ=5.420258, numObservations: 3
action 2, numVisits=10, meanQ=3.198010, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.167443 0.280467 0.519425 0.880595 0.558851 0.832035 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 76
Initial state: 0 0.357333 0.613411 0.69088 0.865802 0.673484 0.815777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32514 episodes
GETTING ACTION FROM:
action 0, numVisits=32505, meanQ=2.922398, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.357333 0.613411 0.69088 0.865802 0.673484 0.815777 w: 1
Observation: 0 0 0.616266 0 0.766908 0 0.895199 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32481, meanQ=4.960046, numObservations: 5
action 2, numVisits=11, meanQ=2.633645, numObservations: 4
action 1, numVisits=8, meanQ=0.997500, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 55128 episodes
GETTING ACTION FROM:
action 3, numVisits=87602, meanQ=4.987170, numObservations: 5
action 2, numVisits=18, meanQ=3.220567, numObservations: 4
action 1, numVisits=8, meanQ=0.997500, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.357333 0.613411 0.69088 0.865802 0.673484 0.815777 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 77
Initial state: 0 0.590885 0.829719 0.540213 0.833388 0.75444 0.240298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55373 episodes
GETTING ACTION FROM:
action 2, numVisits=55367, meanQ=5.152372, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.590885 0.829719 0.540213 0.833388 0.75444 0.240298 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 78
Initial state: 0 0.950409 0.404331 0.529221 0.875568 0.613553 0.859922 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55445 episodes
GETTING ACTION FROM:
action 1, numVisits=55428, meanQ=5.165203, numObservations: 4
action 3, numVisits=12, meanQ=3.081675, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.950409 0.404331 0.529221 0.875568 0.613553 0.859922 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 79
Initial state: 0 0.576413 0.800232 0.341714 0.0978789 0.655839 0.839045 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55435 episodes
GETTING ACTION FROM:
action 1, numVisits=55391, meanQ=5.020509, numObservations: 3
action -1, numVisits=38, meanQ=3.933700, numObservations: 1
action 3, numVisits=3, meanQ=0.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.576413 0.800232 0.341714 0.0978789 0.655839 0.839045 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 80
Initial state: 0 0.534103 0.82195 0.892652 0.290644 0.607234 0.831193 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55872 episodes
GETTING ACTION FROM:
action 1, numVisits=55859, meanQ=5.050468, numObservations: 4
action 2, numVisits=5, meanQ=1.198020, numObservations: 2
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.534103 0.82195 0.892652 0.290644 0.607234 0.831193 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 81
Initial state: 0 0.656622 0.87015 0.55102 0.831953 0.0362339 0.919703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53127 episodes
GETTING ACTION FROM:
action 2, numVisits=49145, meanQ=5.030118, numObservations: 3
action 0, numVisits=3964, meanQ=2.980354, numObservations: 1
action 1, numVisits=13, meanQ=0.754623, numObservations: 2
action 3, numVisits=3, meanQ=-0.659967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.656622 0.87015 0.55102 0.831953 0.0362339 0.919703 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 82
Initial state: 0 0.495745 0.332339 0.582558 0.851285 0.546402 0.893598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55466 episodes
GETTING ACTION FROM:
action 1, numVisits=55411, meanQ=4.947942, numObservations: 4
action 0, numVisits=49, meanQ=4.014326, numObservations: 1
action 2, numVisits=3, meanQ=-0.659967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.495745 0.332339 0.582558 0.851285 0.546402 0.893598 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8978, meanQ=8.290214, numObservations: 5
action 2, numVisits=70, meanQ=7.589574, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 5914 episodes
GETTING ACTION FROM:
action 3, numVisits=11818, meanQ=7.802513, numObservations: 5
action 2, numVisits=107, meanQ=6.467292, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=3025, meanQ=0.059200, numObservations: 1
action 0, numVisits=11, meanQ=-2.000900, numObservations: 1
action: 3
Next state: 1 0.495745 0.332339 0.582558 0.851285 0.546402 0.893598 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 83
Initial state: 0 0.631475 0.82322 0.75406 0.408057 0.515378 0.848576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55575 episodes
GETTING ACTION FROM:
action 2, numVisits=55568, meanQ=5.003003, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.631475 0.82322 0.75406 0.408057 0.515378 0.848576 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 84
Initial state: 0 0.582143 0.858516 0.507145 0.814788 0.873024 0.67282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32745 episodes
GETTING ACTION FROM:
action 0, numVisits=27396, meanQ=3.010675, numObservations: 1
action -1, numVisits=5346, meanQ=2.961423, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.582143 0.858516 0.507145 0.814788 0.873024 0.67282 w: 1
Observation: 0 0 0.801532 0 0.83807 0 0.579336 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27051, meanQ=5.017392, numObservations: 3
action 3, numVisits=222, meanQ=4.533268, numObservations: 5
action 0, numVisits=92, meanQ=4.377270, numObservations: 1
action -1, numVisits=28, meanQ=3.801739, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
Sampled 56309 episodes
GETTING ACTION FROM:
action 1, numVisits=83359, meanQ=5.246929, numObservations: 3
action 3, numVisits=222, meanQ=4.533268, numObservations: 5
action 0, numVisits=93, meanQ=4.370326, numObservations: 1
action -1, numVisits=28, meanQ=3.801739, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.582143 0.858516 0.507145 0.814788 0.873024 0.67282 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 85
Initial state: 0 0.181118 0.170434 0.586246 0.862687 0.696445 0.856648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55488 episodes
GETTING ACTION FROM:
action 1, numVisits=55457, meanQ=4.931392, numObservations: 4
action 0, numVisits=22, meanQ=3.441790, numObservations: 1
action 3, numVisits=6, meanQ=1.498333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.181118 0.170434 0.586246 0.862687 0.696445 0.856648 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 86
Initial state: 0 0.679206 0.856639 0.520257 0.871256 0.130178 0.205975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55654 episodes
GETTING ACTION FROM:
action 1, numVisits=55648, meanQ=5.088164, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.679206 0.856639 0.520257 0.871256 0.130178 0.205975 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 87
Initial state: 0 0.632558 0.875595 0.432581 0.181931 0.606993 0.842566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55482 episodes
GETTING ACTION FROM:
action 1, numVisits=55462, meanQ=5.023640, numObservations: 4
action -1, numVisits=14, meanQ=3.058800, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.632558 0.875595 0.432581 0.181931 0.606993 0.842566 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 88
Initial state: 0 0.604899 0.820227 0.515532 0.814391 0.22329 0.307998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55429 episodes
GETTING ACTION FROM:
action 3, numVisits=55392, meanQ=5.129115, numObservations: 4
action -1, numVisits=31, meanQ=3.910782, numObservations: 1
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.604899 0.820227 0.515532 0.814391 0.22329 0.307998 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3342, meanQ=8.541467, numObservations: 3
action 2, numVisits=2869, meanQ=8.431384, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10992 episodes
GETTING ACTION FROM:
action 1, numVisits=7310, meanQ=7.283216, numObservations: 3
action 2, numVisits=5774, meanQ=7.036384, numObservations: 3
action -1, numVisits=3749, meanQ=0.317482, numObservations: 1
action 0, numVisits=371, meanQ=-0.281142, numObservations: 2
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 1
Next state: 1 0.604899 0.820227 0.515532 0.814391 0.22329 0.307998 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 89
Initial state: 0 0.656066 0.879979 0.149882 0.650752 0.515737 0.820501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55589 episodes
GETTING ACTION FROM:
action 2, numVisits=25095, meanQ=5.008655, numObservations: 5
action 1, numVisits=30481, meanQ=4.919975, numObservations: 4
action 3, numVisits=9, meanQ=1.666667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.656066 0.879979 0.149882 0.650752 0.515737 0.820501 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2798, meanQ=8.552406, numObservations: 3
action 3, numVisits=58, meanQ=7.691381, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11800 episodes
GETTING ACTION FROM:
action 1, numVisits=12175, meanQ=6.486900, numObservations: 5
action 3, numVisits=362, meanQ=5.755498, numObservations: 4
action 0, numVisits=2112, meanQ=0.211094, numObservations: 1
action -1, numVisits=9, meanQ=-2.112200, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.656066 0.879979 0.149882 0.650752 0.515737 0.820501 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 90
Initial state: 0 0.516928 0.8813 0.126071 0.340058 0.549971 0.818715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52913 episodes
GETTING ACTION FROM:
action 2, numVisits=52864, meanQ=4.830789, numObservations: 3
action -1, numVisits=33, meanQ=3.629827, numObservations: 1
action 0, numVisits=14, meanQ=2.805743, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.516928 0.8813 0.126071 0.340058 0.549971 0.818715 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8669, meanQ=8.253497, numObservations: 4
action 1, numVisits=20, meanQ=6.699505, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8811 episodes
GETTING ACTION FROM:
action 3, numVisits=13721, meanQ=7.391842, numObservations: 4
action 1, numVisits=69, meanQ=5.434465, numObservations: 4
action 2, numVisits=5, meanQ=2.598000, numObservations: 3
action 0, numVisits=3705, meanQ=0.299312, numObservations: 1
action -1, numVisits=3, meanQ=-4.435385, numObservations: 1
action: 3
Next state: 1 0.516928 0.8813 0.126071 0.340058 0.549971 0.818715 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 91
Initial state: 0 0.606295 0.889156 0.548527 0.819171 0.80779 0.284732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53665 episodes
GETTING ACTION FROM:
action 1, numVisits=51286, meanQ=4.915135, numObservations: 4
action 0, numVisits=2375, meanQ=2.828949, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.606295 0.889156 0.548527 0.819171 0.80779 0.284732 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 92
Initial state: 0 0.635248 0.857339 0.529744 0.812367 0.993495 0.427197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55247 episodes
GETTING ACTION FROM:
action 3, numVisits=54887, meanQ=5.008707, numObservations: 5
action 1, numVisits=342, meanQ=4.674930, numObservations: 5
action -1, numVisits=14, meanQ=2.853397, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.635248 0.857339 0.529744 0.812367 0.993495 0.427197 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 93
Initial state: 0 0.965295 0.918531 0.698759 0.842163 0.515688 0.806696 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55482 episodes
GETTING ACTION FROM:
action 2, numVisits=55475, meanQ=5.045105, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.965295 0.918531 0.698759 0.842163 0.515688 0.806696 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 94
Initial state: 0 0.663634 0.887509 0.763255 0.773372 0.588276 0.888471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55521 episodes
GETTING ACTION FROM:
action 1, numVisits=55510, meanQ=4.927295, numObservations: 4
action 2, numVisits=6, meanQ=0.518350, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.663634 0.887509 0.763255 0.773372 0.588276 0.888471 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 95
Initial state: 0 0.563457 0.899299 0.45566 0.889981 0.605486 0.898294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32650 episodes
GETTING ACTION FROM:
action -1, numVisits=32629, meanQ=2.919110, numObservations: 1
action 3, numVisits=5, meanQ=-0.002000, numObservations: 4
action 1, numVisits=10, meanQ=-0.220000, numObservations: 3
action 2, numVisits=4, meanQ=-3.244975, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: -1
Next state: 0 0.563457 0.899299 0.45566 0.889981 0.605486 0.898294 w: 1
Observation: 0 0.530331 0 0.544252 0 0.52001 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32620, meanQ=4.978406, numObservations: 4
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55525 episodes
GETTING ACTION FROM:
action 3, numVisits=88143, meanQ=5.106032, numObservations: 4
action -1, numVisits=3, meanQ=0.966700, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=4, meanQ=-2.502475, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.563457 0.899299 0.45566 0.889981 0.605486 0.898294 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 96
Initial state: 0 0.560516 0.827487 0.570151 0.858438 0.940598 0.907359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32818 episodes
GETTING ACTION FROM:
action -1, numVisits=32811, meanQ=2.958311, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.560516 0.827487 0.570151 0.858438 0.940598 0.907359 w: 1
Observation: 0 0.529864 0 0.538998 0 0.960201 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32680, meanQ=5.027989, numObservations: 4
action -1, numVisits=121, meanQ=2.207322, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 56749 episodes
GETTING ACTION FROM:
action 2, numVisits=89426, meanQ=5.096928, numObservations: 4
action 3, numVisits=9, meanQ=2.766667, numObservations: 2
action -1, numVisits=121, meanQ=2.207322, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.560516 0.827487 0.570151 0.858438 0.940598 0.907359 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 97
Initial state: 0 0.698018 0.884122 0.213947 0.392254 0.62051 0.866264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55442 episodes
GETTING ACTION FROM:
action 3, numVisits=55340, meanQ=4.980306, numObservations: 4
action 0, numVisits=65, meanQ=4.146248, numObservations: 1
action -1, numVisits=30, meanQ=3.734387, numObservations: 1
action 2, numVisits=3, meanQ=0.000033, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 0 0.698018 0.884122 0.213947 0.392254 0.62051 0.866264 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3999, meanQ=5.557396, numObservations: 4
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 61301 episodes
GETTING ACTION FROM:
action 3, numVisits=65290, meanQ=5.615839, numObservations: 4
action -1, numVisits=10, meanQ=3.445000, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.698018 0.884122 0.213947 0.392254 0.62051 0.866264 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 98
Initial state: 0 0.564908 0.858836 0.01513 0.799062 0.504732 0.858725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32625 episodes
GETTING ACTION FROM:
action 0, numVisits=32617, meanQ=2.847093, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=4, meanQ=-4.975000, numObservations: 3
action: 0
Next state: 0 0.564908 0.858836 0.01513 0.799062 0.504732 0.858725 w: 1
Observation: 0 0 0.919356 0 0.761218 0 0.848071 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32574, meanQ=4.956070, numObservations: 4
action -1, numVisits=32, meanQ=3.824398, numObservations: 1
action 3, numVisits=7, meanQ=0.428586, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 55868 episodes
GETTING ACTION FROM:
action 1, numVisits=88439, meanQ=4.862243, numObservations: 4
action -1, numVisits=35, meanQ=3.715824, numObservations: 1
action 3, numVisits=7, meanQ=0.428586, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.564908 0.858836 0.01513 0.799062 0.504732 0.858725 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 99
Initial state: 0 0.621982 0.859209 0.442724 0.82537 0.650658 0.834306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55056 episodes
GETTING ACTION FROM:
action 1, numVisits=54953, meanQ=4.939045, numObservations: 4
action 0, numVisits=95, meanQ=4.272890, numObservations: 1
action 3, numVisits=5, meanQ=1.198020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.621982 0.859209 0.442724 0.82537 0.650658 0.834306 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 100
Initial state: 0 0.12993 0.707974 0.567603 0.82848 0.670529 0.816535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50686 episodes
GETTING ACTION FROM:
action 3, numVisits=49515, meanQ=4.730544, numObservations: 4
action 2, numVisits=984, meanQ=4.413590, numObservations: 5
action 0, numVisits=143, meanQ=4.201760, numObservations: 1
action -1, numVisits=36, meanQ=3.596422, numObservations: 1
action 1, numVisits=8, meanQ=2.375000, numObservations: 4
action: 3
Next state: 1 0.12993 0.707974 0.567603 0.82848 0.670529 0.816535 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 101
Initial state: 0 0.696875 0.833918 0.105707 0.679075 0.512549 0.838097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54915 episodes
GETTING ACTION FROM:
action 2, numVisits=54909, meanQ=5.012241, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.696875 0.833918 0.105707 0.679075 0.512549 0.838097 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7785, meanQ=8.388506, numObservations: 3
action 3, numVisits=3, meanQ=4.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 16020 episodes
GETTING ACTION FROM:
action 1, numVisits=17005, meanQ=7.077211, numObservations: 3
action 3, numVisits=6798, meanQ=5.777446, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=5, meanQ=-78.151761, numObservations: 1
action -1, numVisits=2, meanQ=-195.953575, numObservations: 1
action: 1
Next state: 1 0.696875 0.833918 0.105707 0.679075 0.512549 0.838097 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 102
Initial state: 0 0.618865 0.866478 0.199916 0.234726 0.670864 0.800006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55509 episodes
GETTING ACTION FROM:
action 3, numVisits=55493, meanQ=5.019664, numObservations: 3
action 2, numVisits=8, meanQ=0.873750, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.618865 0.866478 0.199916 0.234726 0.670864 0.800006 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 103
Initial state: 0 0.51978 0.892017 0.119681 0.955419 0.515697 0.898945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55568 episodes
GETTING ACTION FROM:
action 3, numVisits=55545, meanQ=5.014146, numObservations: 3
action -1, numVisits=12, meanQ=3.084752, numObservations: 1
action 1, numVisits=8, meanQ=2.622513, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.51978 0.892017 0.119681 0.955419 0.515697 0.898945 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 104
Initial state: 0 0.300848 0.332248 0.615956 0.813992 0.619821 0.854816 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55226 episodes
GETTING ACTION FROM:
action 2, numVisits=55220, meanQ=4.942942, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.300848 0.332248 0.615956 0.813992 0.619821 0.854816 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 105
Initial state: 0 0.51048 0.858247 0.481312 0.407985 0.674603 0.818309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55365 episodes
GETTING ACTION FROM:
action 2, numVisits=55184, meanQ=4.951607, numObservations: 4
action 0, numVisits=109, meanQ=4.329940, numObservations: 1
action -1, numVisits=70, meanQ=4.176593, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.51048 0.858247 0.481312 0.407985 0.674603 0.818309 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7640, meanQ=8.393099, numObservations: 4
action 1, numVisits=10, meanQ=6.201010, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 13535 episodes
GETTING ACTION FROM:
action 3, numVisits=17821, meanQ=7.086373, numObservations: 4
action 1, numVisits=155, meanQ=5.843435, numObservations: 5
action 2, numVisits=6, meanQ=1.498333, numObservations: 3
action 0, numVisits=3200, meanQ=-0.317858, numObservations: 2
action -1, numVisits=6, meanQ=-65.020696, numObservations: 1
action: 3
Next state: 1 0.51048 0.858247 0.481312 0.407985 0.674603 0.818309 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 106
Initial state: 0 0.750531 0.0327938 0.518299 0.880393 0.697351 0.842877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50488 episodes
GETTING ACTION FROM:
action 3, numVisits=50409, meanQ=4.875555, numObservations: 4
action -1, numVisits=34, meanQ=3.741082, numObservations: 1
action 1, numVisits=33, meanQ=3.597582, numObservations: 4
action 2, numVisits=10, meanQ=2.299030, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.750531 0.0327938 0.518299 0.880393 0.697351 0.842877 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 107
Initial state: 0 0.621678 0.855549 0.692707 0.880181 0.321065 0.6781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55420 episodes
GETTING ACTION FROM:
action 2, numVisits=55414, meanQ=4.968780, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.621678 0.855549 0.692707 0.880181 0.321065 0.6781 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 108
Initial state: 0 0.623366 0.802621 0.961785 0.269308 0.698928 0.853248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55245 episodes
GETTING ACTION FROM:
action 1, numVisits=55187, meanQ=4.977840, numObservations: 5
action 0, numVisits=54, meanQ=4.098493, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.623366 0.802621 0.961785 0.269308 0.698928 0.853248 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 109
Initial state: 0 0.945368 0.143797 0.63007 0.80908 0.640347 0.886397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55357 episodes
GETTING ACTION FROM:
action 2, numVisits=55350, meanQ=4.986263, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.945368 0.143797 0.63007 0.80908 0.640347 0.886397 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 110
Initial state: 0 0.66772 0.817853 0.217451 0.981308 0.566276 0.865117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55276 episodes
GETTING ACTION FROM:
action 1, numVisits=55182, meanQ=4.977313, numObservations: 5
action -1, numVisits=54, meanQ=4.061026, numObservations: 1
action 0, numVisits=32, meanQ=3.790241, numObservations: 1
action 3, numVisits=7, meanQ=1.428571, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.66772 0.817853 0.217451 0.981308 0.566276 0.865117 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 111
Initial state: 0 0.673622 0.815667 0.419423 0.126795 0.618538 0.882041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54152 episodes
GETTING ACTION FROM:
action 2, numVisits=54115, meanQ=4.955140, numObservations: 3
action 1, numVisits=32, meanQ=3.417187, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.673622 0.815667 0.419423 0.126795 0.618538 0.882041 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8816, meanQ=8.266266, numObservations: 5
action 3, numVisits=81, meanQ=7.391362, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 15633 episodes
GETTING ACTION FROM:
action 1, numVisits=20922, meanQ=6.948945, numObservations: 5
action 3, numVisits=3600, meanQ=6.001991, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=6, meanQ=-64.847999, numObservations: 1
action 0, numVisits=4, meanQ=-96.231807, numObservations: 2
action: 1
Next state: 1 0.673622 0.815667 0.419423 0.126795 0.618538 0.882041 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 112
Initial state: 0 0.00987682 0.724043 0.538314 0.809493 0.557821 0.819686 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55184 episodes
GETTING ACTION FROM:
action 2, numVisits=55168, meanQ=4.949117, numObservations: 4
action 3, numVisits=11, meanQ=2.729100, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.00987682 0.724043 0.538314 0.809493 0.557821 0.819686 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 113
Initial state: 0 0.654008 0.808858 0.25437 0.940232 0.566123 0.811343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54667 episodes
GETTING ACTION FROM:
action 2, numVisits=54589, meanQ=4.935902, numObservations: 4
action -1, numVisits=72, meanQ=4.174217, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.654008 0.808858 0.25437 0.940232 0.566123 0.811343 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 114
Initial state: 0 0.522394 0.888341 0.552968 0.858838 0.769491 0.618129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55126 episodes
GETTING ACTION FROM:
action 2, numVisits=55029, meanQ=4.949255, numObservations: 5
action -1, numVisits=77, meanQ=4.221656, numObservations: 1
action 3, numVisits=17, meanQ=3.175888, numObservations: 5
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.522394 0.888341 0.552968 0.858838 0.769491 0.618129 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 115
Initial state: 0 0.607834 0.879633 0.284625 0.412571 0.699938 0.870556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55524 episodes
GETTING ACTION FROM:
action 1, numVisits=55488, meanQ=4.979435, numObservations: 4
action 0, numVisits=32, meanQ=3.786757, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.607834 0.879633 0.284625 0.412571 0.699938 0.870556 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 116
Initial state: 0 0.543002 0.800693 0.848545 0.621064 0.656306 0.872851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 38618 episodes
GETTING ACTION FROM:
action 1, numVisits=14477, meanQ=4.906175, numObservations: 4
action 0, numVisits=24123, meanQ=2.884584, numObservations: 1
action -1, numVisits=16, meanQ=1.244028, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.543002 0.800693 0.848545 0.621064 0.656306 0.872851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 117
Initial state: 0 0.664803 0.819549 0.57151 0.801956 0.388864 0.324227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55549 episodes
GETTING ACTION FROM:
action 3, numVisits=55543, meanQ=4.907201, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.664803 0.819549 0.57151 0.801956 0.388864 0.324227 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 118
Initial state: 0 0.587461 0.811527 0.441705 0.336222 0.681652 0.836332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55502 episodes
GETTING ACTION FROM:
action 1, numVisits=55346, meanQ=4.941918, numObservations: 5
action -1, numVisits=84, meanQ=4.204820, numObservations: 1
action 0, numVisits=65, meanQ=4.100150, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.587461 0.811527 0.441705 0.336222 0.681652 0.836332 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 119
Initial state: 0 0.85005 0.105828 0.645355 0.88537 0.665183 0.889207 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55238 episodes
GETTING ACTION FROM:
action 1, numVisits=55185, meanQ=4.981940, numObservations: 4
action 3, numVisits=20, meanQ=3.340500, numObservations: 4
action -1, numVisits=15, meanQ=3.299652, numObservations: 1
action 2, numVisits=16, meanQ=3.006250, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.85005 0.105828 0.645355 0.88537 0.665183 0.889207 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4077, meanQ=5.689553, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 3134 episodes
GETTING ACTION FROM:
action 1, numVisits=4077, meanQ=5.689553, numObservations: 4
action -1, numVisits=3120, meanQ=-0.023490, numObservations: 1
action 0, numVisits=16, meanQ=-1.443744, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.85005 0.105828 0.645355 0.88537 0.665183 0.889207 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 120
Initial state: 0 0.53084 0.296775 0.653237 0.88387 0.500656 0.876839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54777 episodes
GETTING ACTION FROM:
action 3, numVisits=54712, meanQ=5.022866, numObservations: 5
action 2, numVisits=59, meanQ=4.105668, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.53084 0.296775 0.653237 0.88387 0.500656 0.876839 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 121
Initial state: 0 0.607974 0.826446 0.667202 0.878835 0.548082 0.745066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54605 episodes
GETTING ACTION FROM:
action 2, numVisits=54570, meanQ=4.946220, numObservations: 5
action 1, numVisits=20, meanQ=2.845005, numObservations: 4
action 3, numVisits=11, meanQ=2.165464, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.607974 0.826446 0.667202 0.878835 0.548082 0.745066 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 122
Initial state: 0 0.524713 0.841096 0.994564 0.256576 0.638091 0.817195 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32674 episodes
GETTING ACTION FROM:
action 0, numVisits=23472, meanQ=3.087034, numObservations: 1
action -1, numVisits=9186, meanQ=3.061826, numObservations: 1
action 1, numVisits=14, meanQ=0.786443, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.524713 0.841096 0.994564 0.256576 0.638091 0.817195 w: 1
Observation: 0 0 0.890527 0 0.276079 0 0.75722 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23388, meanQ=5.080901, numObservations: 5
action -1, numVisits=52, meanQ=4.231425, numObservations: 1
action 0, numVisits=16, meanQ=3.527265, numObservations: 1
action 3, numVisits=8, meanQ=2.498750, numObservations: 3
action 1, numVisits=7, meanQ=2.144300, numObservations: 2
Sampled 55584 episodes
GETTING ACTION FROM:
action 2, numVisits=78964, meanQ=4.946434, numObservations: 5
action -1, numVisits=59, meanQ=4.078582, numObservations: 1
action 0, numVisits=17, meanQ=3.260302, numObservations: 1
action 3, numVisits=8, meanQ=2.498750, numObservations: 3
action 1, numVisits=7, meanQ=2.144300, numObservations: 2
action: 2
Next state: 2 0.524713 0.841096 0.994564 0.256576 0.638091 0.817195 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 123
Initial state: 0 0.40362 0.532216 0.693295 0.804289 0.611527 0.87269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52673 episodes
GETTING ACTION FROM:
action 2, numVisits=52532, meanQ=4.790796, numObservations: 3
action -1, numVisits=90, meanQ=4.075985, numObservations: 1
action 1, numVisits=40, meanQ=3.756500, numObservations: 4
action 3, numVisits=9, meanQ=2.223344, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.40362 0.532216 0.693295 0.804289 0.611527 0.87269 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 124
Initial state: 0 0.505285 0.868323 0.527831 0.822141 0.108724 0.277326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55215 episodes
GETTING ACTION FROM:
action 1, numVisits=55170, meanQ=5.066031, numObservations: 5
action 0, numVisits=32, meanQ=3.846766, numObservations: 1
action 2, numVisits=10, meanQ=2.189000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.505285 0.868323 0.527831 0.822141 0.108724 0.277326 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 125
Initial state: 0 0.603793 0.855262 0.299988 0.512591 0.624457 0.864749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55032 episodes
GETTING ACTION FROM:
action 1, numVisits=55025, meanQ=4.986855, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.603793 0.855262 0.299988 0.512591 0.624457 0.864749 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 126
Initial state: 0 0.699441 0.83841 0.050084 0.5012 0.554817 0.859612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55620 episodes
GETTING ACTION FROM:
action 1, numVisits=55608, meanQ=5.047276, numObservations: 4
action 3, numVisits=7, meanQ=2.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.699441 0.83841 0.050084 0.5012 0.554817 0.859612 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 127
Initial state: 0 0.118548 0.602806 0.627765 0.881495 0.646899 0.865792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55165 episodes
GETTING ACTION FROM:
action 2, numVisits=55146, meanQ=4.926815, numObservations: 4
action 3, numVisits=14, meanQ=2.650000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.118548 0.602806 0.627765 0.881495 0.646899 0.865792 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 128
Initial state: 0 0.517483 0.814607 0.434601 0.356478 0.615213 0.860821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54960 episodes
GETTING ACTION FROM:
action 2, numVisits=54935, meanQ=4.918890, numObservations: 3
action 3, numVisits=20, meanQ=0.095510, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.517483 0.814607 0.434601 0.356478 0.615213 0.860821 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9069, meanQ=8.340285, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12107 episodes
GETTING ACTION FROM:
action 1, numVisits=17699, meanQ=7.206045, numObservations: 4
action 3, numVisits=21, meanQ=3.666190, numObservations: 4
action 2, numVisits=6, meanQ=1.498333, numObservations: 3
action 0, numVisits=3446, meanQ=0.182539, numObservations: 1
action -1, numVisits=8, meanQ=-3.389599, numObservations: 1
action: 1
Next state: 1 0.517483 0.814607 0.434601 0.356478 0.615213 0.860821 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 129
Initial state: 0 0.915013 0.0059074 0.603095 0.854586 0.575265 0.875758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55429 episodes
GETTING ACTION FROM:
action 3, numVisits=55423, meanQ=5.001846, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.915013 0.0059074 0.603095 0.854586 0.575265 0.875758 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 130
Initial state: 0 0.539813 0.821855 0.627628 0.85161 0.808492 0.345099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55723 episodes
GETTING ACTION FROM:
action 3, numVisits=55702, meanQ=5.149968, numObservations: 4
action -1, numVisits=17, meanQ=3.421238, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.539813 0.821855 0.627628 0.85161 0.808492 0.345099 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 131
Initial state: 0 0.674226 0.893293 0.520379 0.899665 0.0182945 0.476057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55732 episodes
GETTING ACTION FROM:
action 2, numVisits=55666, meanQ=5.003714, numObservations: 4
action -1, numVisits=45, meanQ=3.958819, numObservations: 1
action 1, numVisits=18, meanQ=2.777228, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.674226 0.893293 0.520379 0.899665 0.0182945 0.476057 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 132
Initial state: 0 0.693624 0.891877 0.544377 0.843739 0.747013 0.0982933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55201 episodes
GETTING ACTION FROM:
action 3, numVisits=55138, meanQ=4.898278, numObservations: 4
action -1, numVisits=54, meanQ=3.988817, numObservations: 1
action 1, numVisits=6, meanQ=0.166667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.693624 0.891877 0.544377 0.843739 0.747013 0.0982933 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 133
Initial state: 0 0.518538 0.838027 0.514849 0.803558 0.894731 0.525891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55363 episodes
GETTING ACTION FROM:
action 3, numVisits=55292, meanQ=5.115840, numObservations: 5
action 1, numVisits=39, meanQ=3.985392, numObservations: 4
action 0, numVisits=26, meanQ=3.761307, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.518538 0.838027 0.514849 0.803558 0.894731 0.525891 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 134
Initial state: 0 0.722561 0.575924 0.680251 0.882182 0.611215 0.8137 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55674 episodes
GETTING ACTION FROM:
action 2, numVisits=55625, meanQ=4.950095, numObservations: 5
action -1, numVisits=43, meanQ=3.935846, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.722561 0.575924 0.680251 0.882182 0.611215 0.8137 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 135
Initial state: 0 0.205714 0.885589 0.509117 0.842693 0.646639 0.815064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52527 episodes
GETTING ACTION FROM:
action 3, numVisits=52521, meanQ=4.875663, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.205714 0.885589 0.509117 0.842693 0.646639 0.815064 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 136
Initial state: 0 0.63054 0.867433 0.554994 0.00372723 0.531966 0.833506 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50553 episodes
GETTING ACTION FROM:
action 2, numVisits=50494, meanQ=4.807665, numObservations: 4
action -1, numVisits=55, meanQ=2.228971, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.63054 0.867433 0.554994 0.00372723 0.531966 0.833506 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 137
Initial state: 0 0.681479 0.854804 0.345494 0.203587 0.676059 0.888124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54468 episodes
GETTING ACTION FROM:
action 3, numVisits=54462, meanQ=5.031162, numObservations: 5
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.681479 0.854804 0.345494 0.203587 0.676059 0.888124 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 138
Initial state: 0 0.560631 0.812019 0.558115 0.872883 0.684973 0.0368977 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55335 episodes
GETTING ACTION FROM:
action 3, numVisits=55327, meanQ=4.955564, numObservations: 4
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.560631 0.812019 0.558115 0.872883 0.684973 0.0368977 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7809, meanQ=8.392123, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 14713 episodes
GETTING ACTION FROM:
action 2, numVisits=20132, meanQ=7.002549, numObservations: 4
action 3, numVisits=4, meanQ=4.975000, numObservations: 2
action 1, numVisits=29, meanQ=4.447931, numObservations: 3
action -1, numVisits=2318, meanQ=0.068408, numObservations: 1
action 0, numVisits=44, meanQ=-1.014358, numObservations: 1
action: 2
Next state: 1 0.560631 0.812019 0.558115 0.872883 0.684973 0.0368977 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 139
Initial state: 0 0.366804 0.125646 0.558388 0.845541 0.518097 0.844346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55468 episodes
GETTING ACTION FROM:
action 2, numVisits=55459, meanQ=4.985256, numObservations: 5
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.366804 0.125646 0.558388 0.845541 0.518097 0.844346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 140
Initial state: 0 0.678766 0.887521 0.126023 0.592131 0.646368 0.826326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53144 episodes
GETTING ACTION FROM:
action 3, numVisits=53090, meanQ=4.851417, numObservations: 5
action 0, numVisits=25, meanQ=3.459879, numObservations: 1
action -1, numVisits=19, meanQ=3.324663, numObservations: 1
action 2, numVisits=7, meanQ=1.428571, numObservations: 2
action 1, numVisits=3, meanQ=0.333333, numObservations: 3
action: 3
Next state: 1 0.678766 0.887521 0.126023 0.592131 0.646368 0.826326 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 141
Initial state: 0 0.602122 0.831292 0.47688 0.725008 0.609392 0.845327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55599 episodes
GETTING ACTION FROM:
action 2, numVisits=55588, meanQ=4.966646, numObservations: 4
action 3, numVisits=6, meanQ=1.498333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.602122 0.831292 0.47688 0.725008 0.609392 0.845327 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9224, meanQ=8.286322, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12421 episodes
GETTING ACTION FROM:
action 1, numVisits=10638, meanQ=8.012720, numObservations: 4
action 2, numVisits=9, meanQ=5.766667, numObservations: 4
action 3, numVisits=25, meanQ=5.695424, numObservations: 4
action 0, numVisits=10973, meanQ=-0.229955, numObservations: 1
action -1, numVisits=4, meanQ=-96.700919, numObservations: 1
action: 1
Next state: 1 0.602122 0.831292 0.47688 0.725008 0.609392 0.845327 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 142
Initial state: 0 0.660895 0.866406 0.794255 0.747636 0.521141 0.889164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55563 episodes
GETTING ACTION FROM:
action 2, numVisits=55555, meanQ=4.952445, numObservations: 4
action 1, numVisits=3, meanQ=0.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.660895 0.866406 0.794255 0.747636 0.521141 0.889164 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 143
Initial state: 0 0.524651 0.81052 0.533205 0.680525 0.690582 0.83669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52713 episodes
GETTING ACTION FROM:
action 1, numVisits=52631, meanQ=4.819281, numObservations: 5
action 0, numVisits=73, meanQ=4.057502, numObservations: 1
action 2, numVisits=6, meanQ=0.836683, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.524651 0.81052 0.533205 0.680525 0.690582 0.83669 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2501, meanQ=7.778995, numObservations: 4
action 2, numVisits=46, meanQ=6.471743, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 15579 episodes
GETTING ACTION FROM:
action 3, numVisits=15505, meanQ=6.197724, numObservations: 4
action 2, numVisits=164, meanQ=5.300855, numObservations: 4
action -1, numVisits=2444, meanQ=-0.374951, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=14, meanQ=-1.929286, numObservations: 1
action: 3
Next state: 1 0.524651 0.81052 0.533205 0.680525 0.690582 0.83669 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 144
Initial state: 0 0.504827 0.869325 0.502072 0.857419 0.397379 0.852245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55262 episodes
GETTING ACTION FROM:
action 3, numVisits=55212, meanQ=5.044419, numObservations: 5
action 1, numVisits=40, meanQ=3.686507, numObservations: 3
action 2, numVisits=6, meanQ=1.166683, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.504827 0.869325 0.502072 0.857419 0.397379 0.852245 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1279, meanQ=7.920869, numObservations: 5
action 2, numVisits=20, meanQ=6.799000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10796 episodes
GETTING ACTION FROM:
action 1, numVisits=8891, meanQ=6.137574, numObservations: 5
action 2, numVisits=72, meanQ=4.958057, numObservations: 4
action 0, numVisits=3123, meanQ=0.305242, numObservations: 1
action -1, numVisits=11, meanQ=-2.091800, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.504827 0.869325 0.502072 0.857419 0.397379 0.852245 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 145
Initial state: 0 0.533161 0.812113 0.501194 0.838941 0.866344 0.485548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55460 episodes
GETTING ACTION FROM:
action 3, numVisits=55392, meanQ=4.967728, numObservations: 4
action -1, numVisits=64, meanQ=4.147170, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.533161 0.812113 0.501194 0.838941 0.866344 0.485548 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 146
Initial state: 0 0.510837 0.810742 0.686785 0.838341 0.0238915 0.932232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31510 episodes
GETTING ACTION FROM:
action -1, numVisits=31505, meanQ=2.804365, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.510837 0.810742 0.686785 0.838341 0.0238915 0.932232 w: 1
Observation: 0 0.553053 0 0.757019 0 0.102451 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31491, meanQ=4.878460, numObservations: 5
action 2, numVisits=8, meanQ=1.500000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 52445 episodes
GETTING ACTION FROM:
action 1, numVisits=83709, meanQ=4.689336, numObservations: 5
action 3, numVisits=228, meanQ=4.239571, numObservations: 4
action 2, numVisits=8, meanQ=1.500000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.510837 0.810742 0.686785 0.838341 0.0238915 0.932232 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 147
Initial state: 0 0.681161 0.884794 0.230951 0.171687 0.631289 0.826687 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55327 episodes
GETTING ACTION FROM:
action 2, numVisits=55308, meanQ=4.957179, numObservations: 5
action 3, numVisits=13, meanQ=2.683854, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.681161 0.884794 0.230951 0.171687 0.631289 0.826687 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7751, meanQ=8.370069, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9669 episodes
GETTING ACTION FROM:
action 1, numVisits=15385, meanQ=7.229881, numObservations: 3
action -1, numVisits=2027, meanQ=0.377553, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=2, meanQ=-3.505000, numObservations: 2
action 0, numVisits=7, meanQ=-56.300502, numObservations: 1
action: 1
Next state: 1 0.681161 0.884794 0.230951 0.171687 0.631289 0.826687 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 148
Initial state: 0 0.51238 0.86465 0.632114 0.847313 0.892434 0.329756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52945 episodes
GETTING ACTION FROM:
action 2, numVisits=52930, meanQ=4.870570, numObservations: 4
action 3, numVisits=8, meanQ=2.375000, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.51238 0.86465 0.632114 0.847313 0.892434 0.329756 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 149
Initial state: 0 0.536362 0.86852 0.0940815 0.126756 0.688156 0.843075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51268 episodes
GETTING ACTION FROM:
action 1, numVisits=51247, meanQ=4.876442, numObservations: 4
action 3, numVisits=16, meanQ=2.924375, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.536362 0.86852 0.0940815 0.126756 0.688156 0.843075 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=3742, meanQ=3.735390, numObservations: 2
action 2, numVisits=36, meanQ=1.943906, numObservations: 4
action 1, numVisits=19, meanQ=1.625263, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 61569 episodes
GETTING ACTION FROM:
action 1, numVisits=60571, meanQ=5.236287, numObservations: 3
action 0, numVisits=4759, meanQ=2.876697, numObservations: 2
action 2, numVisits=36, meanQ=1.943906, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.536362 0.86852 0.0940815 0.126756 0.688156 0.843075 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 150
Initial state: 0 0.598185 0.844811 0.108367 0.111086 0.676511 0.890092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55234 episodes
GETTING ACTION FROM:
action 2, numVisits=55098, meanQ=4.987792, numObservations: 5
action 3, numVisits=121, meanQ=4.404946, numObservations: 4
action 1, numVisits=11, meanQ=2.628182, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.598185 0.844811 0.108367 0.111086 0.676511 0.890092 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3135, meanQ=8.018929, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12676 episodes
GETTING ACTION FROM:
action 1, numVisits=11592, meanQ=6.596674, numObservations: 4
action 3, numVisits=363, meanQ=6.220604, numObservations: 3
action -1, numVisits=2944, meanQ=-0.074813, numObservations: 1
action 0, numVisits=914, meanQ=-0.175974, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 1
Next state: 1 0.598185 0.844811 0.108367 0.111086 0.676511 0.890092 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 151
Initial state: 0 0.523868 0.83245 0.60088 0.813807 0.279732 0.404804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54945 episodes
GETTING ACTION FROM:
action 3, numVisits=54924, meanQ=4.921914, numObservations: 5
action 2, numVisits=11, meanQ=2.627291, numObservations: 4
action 1, numVisits=6, meanQ=2.003350, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.523868 0.83245 0.60088 0.813807 0.279732 0.404804 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5354, meanQ=8.416267, numObservations: 4
action 1, numVisits=2247, meanQ=8.362993, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12566 episodes
GETTING ACTION FROM:
action 2, numVisits=13553, meanQ=7.141168, numObservations: 4
action 1, numVisits=4357, meanQ=7.101918, numObservations: 5
action 3, numVisits=8, meanQ=3.373750, numObservations: 3
action 0, numVisits=2241, meanQ=0.047401, numObservations: 2
action -1, numVisits=11, meanQ=-2.000900, numObservations: 1
action: 2
Next state: 1 0.523868 0.83245 0.60088 0.813807 0.279732 0.404804 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 152
Initial state: 0 0.565678 0.871439 0.246542 0.204411 0.670833 0.886277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55138 episodes
GETTING ACTION FROM:
action 2, numVisits=55130, meanQ=5.021198, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.565678 0.871439 0.246542 0.204411 0.670833 0.886277 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6116, meanQ=8.508441, numObservations: 3
action 3, numVisits=32, meanQ=7.428441, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7419 episodes
GETTING ACTION FROM:
action 1, numVisits=11719, meanQ=7.404308, numObservations: 4
action 3, numVisits=59, meanQ=5.534270, numObservations: 3
action -1, numVisits=1785, meanQ=0.585081, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=6, meanQ=-64.646798, numObservations: 1
action: 1
Next state: 0 0.565678 0.871439 0.246542 0.204411 0.670833 0.886277 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=39, meanQ=7.820259, numObservations: 3
action 1, numVisits=15, meanQ=6.333340, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 5529 episodes
GETTING ACTION FROM:
action 3, numVisits=506, meanQ=5.930811, numObservations: 3
action 2, numVisits=245, meanQ=5.902000, numObservations: 4
action 1, numVisits=30, meanQ=4.566670, numObservations: 4
action 0, numVisits=4725, meanQ=-1.468231, numObservations: 1
action -1, numVisits=82, meanQ=-2.036702, numObservations: 1
action: 3
Next state: 1 0.565678 0.871439 0.246542 0.204411 0.670833 0.886277 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 153
Initial state: 0 0.677413 0.854744 0.644995 0.862557 0.302401 0.0868074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54228 episodes
GETTING ACTION FROM:
action 3, numVisits=52790, meanQ=5.033642, numObservations: 3
action -1, numVisits=1432, meanQ=2.670951, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.677413 0.854744 0.644995 0.862557 0.302401 0.0868074 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5600, meanQ=8.291370, numObservations: 3
action 2, numVisits=3165, meanQ=8.247749, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11862 episodes
GETTING ACTION FROM:
action 1, numVisits=10570, meanQ=7.203926, numObservations: 3
action 2, numVisits=8061, meanQ=7.050379, numObservations: 4
action -1, numVisits=1885, meanQ=0.141761, numObservations: 1
action 0, numVisits=113, meanQ=-0.326637, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.677413 0.854744 0.644995 0.862557 0.302401 0.0868074 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 154
Initial state: 0 0.553724 0.860171 0.582612 0.383172 0.607908 0.828698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54518 episodes
GETTING ACTION FROM:
action 3, numVisits=54511, meanQ=4.919442, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.553724 0.860171 0.582612 0.383172 0.607908 0.828698 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 155
Initial state: 0 0.513819 0.888168 0.551517 0.846253 0.617074 0.189489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54810 episodes
GETTING ACTION FROM:
action 3, numVisits=54804, meanQ=4.951429, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.513819 0.888168 0.551517 0.846253 0.617074 0.189489 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 156
Initial state: 0 0.64915 0.817771 0.0460586 0.747579 0.654953 0.8313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54651 episodes
GETTING ACTION FROM:
action 2, numVisits=54642, meanQ=5.028774, numObservations: 5
action 1, numVisits=4, meanQ=0.750000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.64915 0.817771 0.0460586 0.747579 0.654953 0.8313 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2632, meanQ=7.908751, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13520 episodes
GETTING ACTION FROM:
action 3, numVisits=8029, meanQ=6.767726, numObservations: 3
action 1, numVisits=7, meanQ=1.594572, numObservations: 2
action -1, numVisits=8074, meanQ=0.260177, numObservations: 1
action 0, numVisits=46, meanQ=-0.647800, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.64915 0.817771 0.0460586 0.747579 0.654953 0.8313 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 157
Initial state: 0 0.43193 0.318357 0.658781 0.89502 0.650702 0.805782 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55027 episodes
GETTING ACTION FROM:
action 2, numVisits=54940, meanQ=4.950017, numObservations: 4
action -1, numVisits=83, meanQ=4.242237, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.43193 0.318357 0.658781 0.89502 0.650702 0.805782 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3933, meanQ=4.640153, numObservations: 5
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 69069 episodes
GETTING ACTION FROM:
action 1, numVisits=69070, meanQ=5.898824, numObservations: 4
action 3, numVisits=3933, meanQ=4.640153, numObservations: 5
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.43193 0.318357 0.658781 0.89502 0.650702 0.805782 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=810, meanQ=8.170391, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 15794 episodes
GETTING ACTION FROM:
action 3, numVisits=1301, meanQ=7.326651, numObservations: 4
action 2, numVisits=3, meanQ=0.663333, numObservations: 2
action -1, numVisits=8496, meanQ=-1.741896, numObservations: 1
action 0, numVisits=6807, meanQ=-1.751302, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.43193 0.318357 0.658781 0.89502 0.650702 0.805782 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 158
Initial state: 0 0.661096 0.842531 0.665536 0.805089 0.0430339 0.353553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55530 episodes
GETTING ACTION FROM:
action 2, numVisits=55479, meanQ=4.998751, numObservations: 5
action 0, numVisits=44, meanQ=4.026170, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.661096 0.842531 0.665536 0.805089 0.0430339 0.353553 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 159
Initial state: 0 0.54313 0.142091 0.566264 0.829461 0.605046 0.898592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52437 episodes
GETTING ACTION FROM:
action 2, numVisits=52308, meanQ=4.830976, numObservations: 5
action 0, numVisits=105, meanQ=4.207244, numObservations: 1
action 3, numVisits=21, meanQ=3.047143, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.54313 0.142091 0.566264 0.829461 0.605046 0.898592 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 160
Initial state: 0 0.483206 0.0788009 0.607499 0.835934 0.686479 0.846229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32671 episodes
GETTING ACTION FROM:
action 0, numVisits=32664, meanQ=2.901397, numObservations: 1
action -1, numVisits=4, meanQ=-2.502425, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.483206 0.0788009 0.607499 0.835934 0.686479 0.846229 w: 1
Observation: 0 0 0.094126 0 0.934444 0 0.78253 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32377, meanQ=4.938238, numObservations: 3
action 2, numVisits=197, meanQ=4.499819, numObservations: 4
action 3, numVisits=85, meanQ=4.230941, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 55304 episodes
GETTING ACTION FROM:
action 2, numVisits=25848, meanQ=5.217489, numObservations: 4
action 1, numVisits=62028, meanQ=4.910463, numObservations: 3
action 3, numVisits=87, meanQ=4.036345, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.483206 0.0788009 0.607499 0.835934 0.686479 0.846229 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 161
Initial state: 0 0.665036 0.819566 0.592464 0.897073 0.852289 0.768708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54722 episodes
GETTING ACTION FROM:
action 3, numVisits=54688, meanQ=4.919366, numObservations: 5
action 0, numVisits=23, meanQ=3.542825, numObservations: 1
action 2, numVisits=8, meanQ=2.375000, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.665036 0.819566 0.592464 0.897073 0.852289 0.768708 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 162
Initial state: 0 0.603024 0.832765 0.186533 0.168874 0.611232 0.896595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52955 episodes
GETTING ACTION FROM:
action 3, numVisits=52944, meanQ=5.074572, numObservations: 4
action 2, numVisits=6, meanQ=2.333333, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.603024 0.832765 0.186533 0.168874 0.611232 0.896595 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 163
Initial state: 0 0.681873 0.861796 0.123732 0.444394 0.691981 0.853193 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52317 episodes
GETTING ACTION FROM:
action 1, numVisits=51524, meanQ=4.799601, numObservations: 4
action -1, numVisits=786, meanQ=2.686229, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.681873 0.861796 0.123732 0.444394 0.691981 0.853193 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 164
Initial state: 0 0.380634 0.758443 0.560741 0.853924 0.653096 0.80876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55025 episodes
GETTING ACTION FROM:
action 2, numVisits=54968, meanQ=4.961741, numObservations: 5
action 1, numVisits=52, meanQ=3.416158, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.380634 0.758443 0.560741 0.853924 0.653096 0.80876 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 165
Initial state: 0 0.537816 0.825125 0.507201 0.842716 0.920772 0.460837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52506 episodes
GETTING ACTION FROM:
action 1, numVisits=52485, meanQ=4.864865, numObservations: 4
action 3, numVisits=16, meanQ=2.436875, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.537816 0.825125 0.507201 0.842716 0.920772 0.460837 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 166
Initial state: 0 0.238807 0.808768 0.512661 0.871391 0.607091 0.858973 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54948 episodes
GETTING ACTION FROM:
action 1, numVisits=54915, meanQ=4.896500, numObservations: 5
action -1, numVisits=28, meanQ=3.672157, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.238807 0.808768 0.512661 0.871391 0.607091 0.858973 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2643, meanQ=7.531064, numObservations: 4
action 2, numVisits=10, meanQ=5.410000, numObservations: 1
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 10783 episodes
GETTING ACTION FROM:
action 3, numVisits=11502, meanQ=6.535376, numObservations: 4
action 2, numVisits=131, meanQ=4.863990, numObservations: 4
action 0, numVisits=1722, meanQ=0.034042, numObservations: 1
action -1, numVisits=82, meanQ=-0.792683, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 3
Next state: 1 0.238807 0.808768 0.512661 0.871391 0.607091 0.858973 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 167
Initial state: 0 0.56781 0.819932 0.645977 0.260943 0.550395 0.824498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55527 episodes
GETTING ACTION FROM:
action 3, numVisits=55499, meanQ=5.033195, numObservations: 5
action -1, numVisits=24, meanQ=3.702736, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.56781 0.819932 0.645977 0.260943 0.550395 0.824498 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 168
Initial state: 0 0.96564 0.538686 0.583346 0.896281 0.575086 0.862242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55544 episodes
GETTING ACTION FROM:
action 3, numVisits=55426, meanQ=5.051814, numObservations: 4
action 2, numVisits=99, meanQ=4.286946, numObservations: 4
action 1, numVisits=15, meanQ=3.332013, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.96564 0.538686 0.583346 0.896281 0.575086 0.862242 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4164, meanQ=5.683601, numObservations: 3
action 1, numVisits=16, meanQ=4.000006, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 62354 episodes
GETTING ACTION FROM:
action 3, numVisits=66484, meanQ=5.331569, numObservations: 3
action 1, numVisits=27, meanQ=3.333337, numObservations: 3
action 2, numVisits=22, meanQ=2.999545, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.96564 0.538686 0.583346 0.896281 0.575086 0.862242 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 169
Initial state: 0 0.528538 0.880056 0.263034 0.730995 0.568626 0.868094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52164 episodes
GETTING ACTION FROM:
action 2, numVisits=52153, meanQ=4.849872, numObservations: 4
action 3, numVisits=4, meanQ=0.750000, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.528538 0.880056 0.263034 0.730995 0.568626 0.868094 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5926, meanQ=8.497599, numObservations: 3
action 1, numVisits=12, meanQ=6.667508, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12980 episodes
GETTING ACTION FROM:
action 3, numVisits=15370, meanQ=7.025046, numObservations: 5
action 1, numVisits=166, meanQ=5.932711, numObservations: 3
action 2, numVisits=3, meanQ=0.663333, numObservations: 3
action -1, numVisits=3171, meanQ=0.146714, numObservations: 1
action 0, numVisits=211, meanQ=-0.869023, numObservations: 1
action: 3
Next state: 0 0.528538 0.880056 0.263034 0.730995 0.568626 0.868094 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=435, meanQ=8.062343, numObservations: 3
action 3, numVisits=213, meanQ=6.504769, numObservations: 3
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.878712, numObservations: 1
Sampled 9580 episodes
GETTING ACTION FROM:
action 1, numVisits=847, meanQ=7.075676, numObservations: 4
action 3, numVisits=213, meanQ=6.504769, numObservations: 3
action 0, numVisits=9171, meanQ=-1.667952, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.878712, numObservations: 1
action: 1
Next state: 1 0.528538 0.880056 0.263034 0.730995 0.568626 0.868094 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 170
Initial state: 0 0.680774 0.827758 0.638604 0.834971 0.552174 0.0120591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55022 episodes
GETTING ACTION FROM:
action 2, numVisits=54981, meanQ=4.944005, numObservations: 5
action -1, numVisits=35, meanQ=3.821373, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.680774 0.827758 0.638604 0.834971 0.552174 0.0120591 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 171
Initial state: 0 0.520505 0.847752 0.0972103 0.678205 0.683308 0.845282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55600 episodes
GETTING ACTION FROM:
action 3, numVisits=55462, meanQ=5.036892, numObservations: 4
action -1, numVisits=104, meanQ=4.392251, numObservations: 1
action 0, numVisits=25, meanQ=3.734827, numObservations: 1
action 2, numVisits=8, meanQ=2.498750, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.520505 0.847752 0.0972103 0.678205 0.683308 0.845282 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 172
Initial state: 0 0.6271 0.833775 0.442223 0.309001 0.567437 0.869958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55495 episodes
GETTING ACTION FROM:
action 1, numVisits=55438, meanQ=5.017766, numObservations: 3
action 0, numVisits=37, meanQ=3.937676, numObservations: 1
action 2, numVisits=17, meanQ=2.235894, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.6271 0.833775 0.442223 0.309001 0.567437 0.869958 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 173
Initial state: 0 0.528859 0.897248 0.656442 0.889344 0.949821 0.132652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54805 episodes
GETTING ACTION FROM:
action 2, numVisits=54696, meanQ=4.900930, numObservations: 5
action 0, numVisits=102, meanQ=4.162262, numObservations: 1
action 3, numVisits=3, meanQ=0.333333, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.528859 0.897248 0.656442 0.889344 0.949821 0.132652 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 174
Initial state: 0 0.626009 0.897069 0.870211 0.0606203 0.601592 0.845773 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 39144 episodes
GETTING ACTION FROM:
action 1, numVisits=15417, meanQ=5.052866, numObservations: 5
action 0, numVisits=23473, meanQ=2.881837, numObservations: 1
action -1, numVisits=245, meanQ=2.517440, numObservations: 1
action 2, numVisits=8, meanQ=0.377512, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.626009 0.897069 0.870211 0.0606203 0.601592 0.845773 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 175
Initial state: 0 0.568857 0.873578 0.884807 0.400716 0.551107 0.869758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55562 episodes
GETTING ACTION FROM:
action 3, numVisits=29688, meanQ=4.998029, numObservations: 4
action 2, numVisits=25812, meanQ=4.994359, numObservations: 5
action -1, numVisits=58, meanQ=4.151805, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.568857 0.873578 0.884807 0.400716 0.551107 0.869758 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 176
Initial state: 0 0.664598 0.821101 0.515572 0.839075 0.256803 0.585415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55632 episodes
GETTING ACTION FROM:
action 3, numVisits=55570, meanQ=4.988185, numObservations: 3
action -1, numVisits=45, meanQ=4.004917, numObservations: 1
action 0, numVisits=9, meanQ=2.730000, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.664598 0.821101 0.515572 0.839075 0.256803 0.585415 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9208, meanQ=8.286401, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10896 episodes
GETTING ACTION FROM:
action 1, numVisits=14309, meanQ=7.307890, numObservations: 4
action 0, numVisits=5658, meanQ=0.213758, numObservations: 2
action -1, numVisits=137, meanQ=-0.389004, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 1
Next state: 1 0.664598 0.821101 0.515572 0.839075 0.256803 0.585415 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 177
Initial state: 0 0.568882 0.858113 0.562582 0.860004 0.870273 0.807645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55057 episodes
GETTING ACTION FROM:
action 2, numVisits=54998, meanQ=5.016339, numObservations: 5
action 0, numVisits=43, meanQ=4.020048, numObservations: 1
action 1, numVisits=13, meanQ=2.460769, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.568882 0.858113 0.562582 0.860004 0.870273 0.807645 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 178
Initial state: 0 0.594721 0.86044 0.635927 0.896869 0.127316 0.321865 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54540 episodes
GETTING ACTION FROM:
action 1, numVisits=53108, meanQ=4.979722, numObservations: 4
action -1, numVisits=1428, meanQ=3.392279, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.594721 0.86044 0.635927 0.896869 0.127316 0.321865 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3789, meanQ=4.819905, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 68643 episodes
GETTING ACTION FROM:
action 2, numVisits=68642, meanQ=5.787682, numObservations: 4
action 3, numVisits=3789, meanQ=4.819905, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 2
Next state: 0 0.594721 0.86044 0.635927 0.896869 0.127316 0.321865 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1226, meanQ=6.935640, numObservations: 5
action 2, numVisits=6, meanQ=3.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 70729 episodes
GETTING ACTION FROM:
action 3, numVisits=71937, meanQ=6.023966, numObservations: 5
action 2, numVisits=20, meanQ=4.399500, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 3
Next state: 0 0.594721 0.86044 0.635927 0.896869 0.127316 0.321865 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=166, meanQ=8.361965, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 49371 episodes
GETTING ACTION FROM:
action 1, numVisits=5970, meanQ=6.501551, numObservations: 5
action 2, numVisits=64, meanQ=5.374844, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=43345, meanQ=-1.933261, numObservations: 3
action -1, numVisits=159, meanQ=-4.326197, numObservations: 1
action: 1
Next state: 1 0.594721 0.86044 0.635927 0.896869 0.127316 0.321865 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 179
Initial state: 0 0.684853 0.803351 0.549347 0.824849 0.704429 0.373552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55445 episodes
GETTING ACTION FROM:
action 3, numVisits=55382, meanQ=5.011836, numObservations: 3
action 0, numVisits=33, meanQ=3.849930, numObservations: 1
action -1, numVisits=27, meanQ=3.719095, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.684853 0.803351 0.549347 0.824849 0.704429 0.373552 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 180
Initial state: 0 0.542799 0.861693 0.758898 0.204681 0.679111 0.813213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52374 episodes
GETTING ACTION FROM:
action 1, numVisits=47842, meanQ=4.976097, numObservations: 5
action -1, numVisits=4528, meanQ=3.017227, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.542799 0.861693 0.758898 0.204681 0.679111 0.813213 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 181
Initial state: 0 0.547995 0.851044 0.286159 0.0855814 0.668125 0.842523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55213 episodes
GETTING ACTION FROM:
action 1, numVisits=55201, meanQ=4.939464, numObservations: 3
action 2, numVisits=7, meanQ=2.428571, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.547995 0.851044 0.286159 0.0855814 0.668125 0.842523 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 182
Initial state: 0 0.732617 0.192944 0.570889 0.83193 0.634561 0.84312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53043 episodes
GETTING ACTION FROM:
action 2, numVisits=53034, meanQ=4.826408, numObservations: 4
action -1, numVisits=5, meanQ=-2.601920, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.732617 0.192944 0.570889 0.83193 0.634561 0.84312 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.889324 0.459047 0.500841 0.882938 0.522218 0.846313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54970 episodes
GETTING ACTION FROM:
action 2, numVisits=51974, meanQ=5.011403, numObservations: 5
action 1, numVisits=2949, meanQ=4.876064, numObservations: 5
action -1, numVisits=30, meanQ=3.756890, numObservations: 1
action 3, numVisits=15, meanQ=2.866000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.889324 0.459047 0.500841 0.882938 0.522218 0.846313 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 184
Initial state: 0 0.199722 0.697628 0.59349 0.866681 0.530418 0.821079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55348 episodes
GETTING ACTION FROM:
action 1, numVisits=55338, meanQ=5.040794, numObservations: 5
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.199722 0.697628 0.59349 0.866681 0.530418 0.821079 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 185
Initial state: 0 0.563662 0.844819 0.477731 0.777604 0.556222 0.893741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32520 episodes
GETTING ACTION FROM:
action -1, numVisits=32479, meanQ=2.938448, numObservations: 1
action 3, numVisits=37, meanQ=1.404881, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.563662 0.844819 0.477731 0.777604 0.556222 0.893741 w: 1
Observation: 0 0.566359 0 0.54584 0 0.593852 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32472, meanQ=4.960902, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55773 episodes
GETTING ACTION FROM:
action 3, numVisits=88227, meanQ=4.943102, numObservations: 4
action 2, numVisits=12, meanQ=2.175000, numObservations: 4
action 1, numVisits=8, meanQ=0.873750, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.563662 0.844819 0.477731 0.777604 0.556222 0.893741 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 186
Initial state: 0 0.558977 0.808269 0.552761 0.815469 0.0044406 0.691793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55343 episodes
GETTING ACTION FROM:
action 1, numVisits=55337, meanQ=5.172817, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.558977 0.808269 0.552761 0.815469 0.0044406 0.691793 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 187
Initial state: 0 0.659839 0.853109 0.396075 0.377935 0.685878 0.846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55365 episodes
GETTING ACTION FROM:
action 1, numVisits=55354, meanQ=4.921961, numObservations: 4
action 3, numVisits=6, meanQ=1.498333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.659839 0.853109 0.396075 0.377935 0.685878 0.846 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 188
Initial state: 0 0.556344 0.831669 0.560202 0.845116 0.342645 0.265716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55219 episodes
GETTING ACTION FROM:
action 1, numVisits=55179, meanQ=4.979561, numObservations: 5
action -1, numVisits=19, meanQ=3.483536, numObservations: 1
action 0, numVisits=19, meanQ=3.316788, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.556344 0.831669 0.560202 0.845116 0.342645 0.265716 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 189
Initial state: 0 0.550997 0.897291 0.553282 0.85466 0.0260167 0.972235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55300 episodes
GETTING ACTION FROM:
action 3, numVisits=55267, meanQ=4.952528, numObservations: 3
action 0, numVisits=23, meanQ=3.439262, numObservations: 1
action 2, numVisits=7, meanQ=2.002871, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.550997 0.897291 0.553282 0.85466 0.0260167 0.972235 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9146, meanQ=8.342762, numObservations: 4
action 2, numVisits=37, meanQ=7.157300, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 14691 episodes
GETTING ACTION FROM:
action 1, numVisits=18871, meanQ=7.053623, numObservations: 4
action 2, numVisits=2353, meanQ=6.312682, numObservations: 3
action -1, numVisits=2647, meanQ=-0.328739, numObservations: 1
action 0, numVisits=4, meanQ=-4.475000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 1
Next state: 1 0.550997 0.897291 0.553282 0.85466 0.0260167 0.972235 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 190
Initial state: 0 0.609358 0.873402 0.69792 0.852284 0.320143 0.200324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54964 episodes
GETTING ACTION FROM:
action 2, numVisits=54957, meanQ=4.917328, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.609358 0.873402 0.69792 0.852284 0.320143 0.200324 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 191
Initial state: 0 0.799858 0.742506 0.539227 0.823852 0.532806 0.835804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55272 episodes
GETTING ACTION FROM:
action 2, numVisits=55245, meanQ=5.029997, numObservations: 4
action -1, numVisits=22, meanQ=3.594157, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.799858 0.742506 0.539227 0.823852 0.532806 0.835804 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 192
Initial state: 0 0.926451 0.574482 0.625565 0.871459 0.661286 0.894634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55353 episodes
GETTING ACTION FROM:
action 1, numVisits=55281, meanQ=4.954107, numObservations: 4
action 0, numVisits=48, meanQ=3.991079, numObservations: 1
action 3, numVisits=10, meanQ=2.690010, numObservations: 4
action 2, numVisits=12, meanQ=2.498342, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.926451 0.574482 0.625565 0.871459 0.661286 0.894634 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 193
Initial state: 0 0.644353 0.897838 0.475558 0.678577 0.647045 0.849935 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55090 episodes
GETTING ACTION FROM:
action 2, numVisits=55064, meanQ=5.053953, numObservations: 4
action 0, numVisits=22, meanQ=3.518623, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.644353 0.897838 0.475558 0.678577 0.647045 0.849935 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7670, meanQ=8.358008, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11768 episodes
GETTING ACTION FROM:
action 3, numVisits=17271, meanQ=7.015476, numObservations: 4
action 1, numVisits=35, meanQ=5.375195, numObservations: 3
action 0, numVisits=2133, meanQ=0.080717, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-198.239935, numObservations: 1
action: 3
Next state: 0 0.644353 0.897838 0.475558 0.678577 0.647045 0.849935 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=51, meanQ=8.290786, numObservations: 3
action 3, numVisits=8, meanQ=5.997500, numObservations: 2
action -1, numVisits=27, meanQ=3.571737, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 15274 episodes
GETTING ACTION FROM:
action 1, numVisits=1622, meanQ=6.430789, numObservations: 3
action 3, numVisits=14, meanQ=2.998571, numObservations: 3
action 0, numVisits=11119, meanQ=-1.771532, numObservations: 1
action -1, numVisits=2605, meanQ=-1.834372, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 1
Next state: 1 0.644353 0.897838 0.475558 0.678577 0.647045 0.849935 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 194
Initial state: 0 0.606484 0.807775 0.568185 0.885168 0.938503 0.0820085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55329 episodes
GETTING ACTION FROM:
action 1, numVisits=54941, meanQ=5.032345, numObservations: 5
action -1, numVisits=384, meanQ=2.942493, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.606484 0.807775 0.568185 0.885168 0.938503 0.0820085 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 195
Initial state: 0 0.626889 0.841965 0.39562 0.912723 0.626166 0.889315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54747 episodes
GETTING ACTION FROM:
action 1, numVisits=54673, meanQ=4.902632, numObservations: 4
action 0, numVisits=70, meanQ=4.101830, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.626889 0.841965 0.39562 0.912723 0.626166 0.889315 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 196
Initial state: 0 0.967296 0.849276 0.558909 0.865046 0.594853 0.862671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51877 episodes
GETTING ACTION FROM:
action 1, numVisits=51871, meanQ=4.919710, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.967296 0.849276 0.558909 0.865046 0.594853 0.862671 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 197
Initial state: 0 0.685829 0.858951 0.535324 0.869072 0.491128 0.299786 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52685 episodes
GETTING ACTION FROM:
action 2, numVisits=52612, meanQ=4.768632, numObservations: 5
action 0, numVisits=69, meanQ=3.955975, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.685829 0.858951 0.535324 0.869072 0.491128 0.299786 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 198
Initial state: 0 0.671269 0.866205 0.59644 0.853407 0.309104 0.0150312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55278 episodes
GETTING ACTION FROM:
action 3, numVisits=55243, meanQ=4.976603, numObservations: 3
action 0, numVisits=30, meanQ=3.756695, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.671269 0.866205 0.59644 0.853407 0.309104 0.0150312 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9064, meanQ=8.285121, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11177 episodes
GETTING ACTION FROM:
action 2, numVisits=13551, meanQ=7.586984, numObservations: 4
action -1, numVisits=6687, meanQ=0.202665, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=5, meanQ=-78.271780, numObservations: 1
action: 2
Next state: 1 0.671269 0.866205 0.59644 0.853407 0.309104 0.0150312 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 199
Initial state: 0 0.683236 0.693922 0.610492 0.800336 0.665634 0.803322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55021 episodes
GETTING ACTION FROM:
action 3, numVisits=54960, meanQ=4.983929, numObservations: 5
action 0, numVisits=47, meanQ=3.874769, numObservations: 1
action 1, numVisits=9, meanQ=0.777800, numObservations: 4
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.683236 0.693922 0.610492 0.800336 0.665634 0.803322 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 200
Initial state: 0 0.589437 0.87282 0.20586 0.118179 0.527483 0.805276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32656 episodes
GETTING ACTION FROM:
action -1, numVisits=32528, meanQ=3.046907, numObservations: 1
action 0, numVisits=106, meanQ=2.450778, numObservations: 1
action 3, numVisits=20, meanQ=1.349510, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.589437 0.87282 0.20586 0.118179 0.527483 0.805276 w: 1
Observation: 0 0.664432 0 0.120379 0 0.487162 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32516, meanQ=5.139357, numObservations: 4
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 56171 episodes
GETTING ACTION FROM:
action 2, numVisits=88681, meanQ=5.164505, numObservations: 4
action 3, numVisits=11, meanQ=2.718182, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 0 0.589437 0.87282 0.20586 0.118179 0.527483 0.805276 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=9864, meanQ=8.520648, numObservations: 3
action 1, numVisits=7, meanQ=5.284300, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12488 episodes
GETTING ACTION FROM:
action 3, numVisits=19706, meanQ=7.104763, numObservations: 4
action 1, numVisits=26, meanQ=3.615008, numObservations: 4
action 0, numVisits=1261, meanQ=-0.384384, numObservations: 1
action -1, numVisits=1368, meanQ=-0.652645, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.589437 0.87282 0.20586 0.118179 0.527483 0.805276 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 201
Initial state: 0 0.532965 0.88828 0.55946 0.821794 0.900319 0.582617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55215 episodes
GETTING ACTION FROM:
action 3, numVisits=55209, meanQ=4.971502, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.532965 0.88828 0.55946 0.821794 0.900319 0.582617 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 202
Initial state: 0 0.544148 0.862557 0.626984 0.887701 0.183724 0.66244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54472 episodes
GETTING ACTION FROM:
action 2, numVisits=54353, meanQ=4.933398, numObservations: 4
action 0, numVisits=68, meanQ=4.115571, numObservations: 1
action -1, numVisits=45, meanQ=3.920034, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.544148 0.862557 0.626984 0.887701 0.183724 0.66244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 203
Initial state: 0 0.540565 0.867553 0.610245 0.885474 0.856519 0.00613147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32628 episodes
GETTING ACTION FROM:
action -1, numVisits=32623, meanQ=2.849329, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.540565 0.867553 0.610245 0.885474 0.856519 0.00613147 w: 1
Observation: 0 0.546937 0 0.629268 0 0.761425 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32560, meanQ=4.916970, numObservations: 5
action -1, numVisits=57, meanQ=4.087774, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54754 episodes
GETTING ACTION FROM:
action 1, numVisits=87310, meanQ=4.922354, numObservations: 5
action -1, numVisits=58, meanQ=4.049021, numObservations: 1
action 3, numVisits=4, meanQ=-0.025000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.540565 0.867553 0.610245 0.885474 0.856519 0.00613147 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 204
Initial state: 0 0.543684 0.837546 0.577875 0.882303 0.240264 0.356049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32470 episodes
GETTING ACTION FROM:
action 0, numVisits=25531, meanQ=2.955644, numObservations: 1
action -1, numVisits=6905, meanQ=2.918415, numObservations: 1
action 2, numVisits=32, meanQ=1.715953, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.543684 0.837546 0.577875 0.882303 0.240264 0.356049 w: 1
Observation: 0 0 0.802174 0 0.811111 0 0.354141 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25483, meanQ=4.963081, numObservations: 4
action 0, numVisits=33, meanQ=3.874760, numObservations: 1
action 3, numVisits=11, meanQ=2.784545, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 56008 episodes
GETTING ACTION FROM:
action 2, numVisits=81489, meanQ=4.796309, numObservations: 4
action 0, numVisits=35, meanQ=3.677775, numObservations: 1
action 3, numVisits=11, meanQ=2.784545, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.543684 0.837546 0.577875 0.882303 0.240264 0.356049 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 205
Initial state: 0 0.283492 0.9728 0.611693 0.856181 0.596312 0.82773 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55645 episodes
GETTING ACTION FROM:
action 2, numVisits=53727, meanQ=5.051228, numObservations: 4
action 1, numVisits=1788, meanQ=4.850592, numObservations: 4
action 0, numVisits=118, meanQ=4.455970, numObservations: 1
action 3, numVisits=10, meanQ=2.499000, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.283492 0.9728 0.611693 0.856181 0.596312 0.82773 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 206
Initial state: 0 0.675626 0.877195 0.571273 0.87013 0.920124 0.451204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52631 episodes
GETTING ACTION FROM:
action 3, numVisits=51440, meanQ=4.934386, numObservations: 4
action -1, numVisits=1182, meanQ=2.609229, numObservations: 1
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.675626 0.877195 0.571273 0.87013 0.920124 0.451204 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 207
Initial state: 0 0.693973 0.896574 0.280701 0.65481 0.542622 0.88273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55171 episodes
GETTING ACTION FROM:
action 2, numVisits=54974, meanQ=4.970471, numObservations: 5
action 0, numVisits=189, meanQ=4.513785, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.693973 0.896574 0.280701 0.65481 0.542622 0.88273 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6433, meanQ=8.421508, numObservations: 4
action 3, numVisits=1331, meanQ=8.330625, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10452 episodes
GETTING ACTION FROM:
action 1, numVisits=12163, meanQ=7.302978, numObservations: 4
action 3, numVisits=2407, meanQ=7.188475, numObservations: 4
action 0, numVisits=3621, meanQ=0.209931, numObservations: 2
action -1, numVisits=8, meanQ=-2.001238, numObservations: 1
action 2, numVisits=20, meanQ=-13.733321, numObservations: 2
action: 1
Next state: 1 0.693973 0.896574 0.280701 0.65481 0.542622 0.88273 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 208
Initial state: 0 0.997652 0.640847 0.692125 0.882246 0.673965 0.888689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52764 episodes
GETTING ACTION FROM:
action 3, numVisits=52755, meanQ=4.838363, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.997652 0.640847 0.692125 0.882246 0.673965 0.888689 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 209
Initial state: 0 0.0759428 0.41928 0.502304 0.880584 0.597775 0.824525 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55212 episodes
GETTING ACTION FROM:
action 1, numVisits=55071, meanQ=4.951273, numObservations: 4
action -1, numVisits=75, meanQ=4.212990, numObservations: 1
action 0, numVisits=48, meanQ=4.018026, numObservations: 1
action 2, numVisits=17, meanQ=3.335882, numObservations: 4
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0759428 0.41928 0.502304 0.880584 0.597775 0.824525 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5346, meanQ=8.326923, numObservations: 3
action 3, numVisits=3647, meanQ=8.246886, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12010 episodes
GETTING ACTION FROM:
action 2, numVisits=11418, meanQ=7.111479, numObservations: 3
action 3, numVisits=7295, meanQ=7.095835, numObservations: 4
action -1, numVisits=2290, meanQ=0.377729, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-4.086677, numObservations: 1
action: 2
Next state: 1 0.0759428 0.41928 0.502304 0.880584 0.597775 0.824525 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 210
Initial state: 0 0.913221 0.809797 0.534932 0.88629 0.51837 0.818599 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55350 episodes
GETTING ACTION FROM:
action 3, numVisits=55344, meanQ=4.943302, numObservations: 5
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.913221 0.809797 0.534932 0.88629 0.51837 0.818599 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 211
Initial state: 0 0.541489 0.85143 0.0956044 0.817023 0.622785 0.89599 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55738 episodes
GETTING ACTION FROM:
action 1, numVisits=55732, meanQ=4.932810, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.541489 0.85143 0.0956044 0.817023 0.622785 0.89599 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 212
Initial state: 0 0.156384 0.447263 0.606728 0.822223 0.667954 0.874818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55279 episodes
GETTING ACTION FROM:
action 3, numVisits=55197, meanQ=5.115888, numObservations: 4
action 1, numVisits=55, meanQ=3.970549, numObservations: 4
action -1, numVisits=24, meanQ=3.718230, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.156384 0.447263 0.606728 0.822223 0.667954 0.874818 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3646, meanQ=7.440349, numObservations: 4
action 2, numVisits=7, meanQ=4.427143, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 67804 episodes
GETTING ACTION FROM:
action 2, numVisits=57006, meanQ=5.801766, numObservations: 4
action 3, numVisits=14449, meanQ=5.525833, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.156384 0.447263 0.606728 0.822223 0.667954 0.874818 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 213
Initial state: 0 0.60315 0.8261 0.614614 0.835195 0.0947145 0.11882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31747 episodes
GETTING ACTION FROM:
action 0, numVisits=31620, meanQ=2.993819, numObservations: 1
action -1, numVisits=124, meanQ=2.451594, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.60315 0.8261 0.614614 0.835195 0.0947145 0.11882 w: 1
Observation: 0 0 0.819104 0 0.845368 0 0.0356209 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31602, meanQ=4.953473, numObservations: 3
action 2, numVisits=12, meanQ=2.999167, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 53333 episodes
GETTING ACTION FROM:
action 1, numVisits=84932, meanQ=5.020316, numObservations: 3
action 2, numVisits=12, meanQ=2.999167, numObservations: 3
action 3, numVisits=4, meanQ=-1.247475, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.60315 0.8261 0.614614 0.835195 0.0947145 0.11882 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 214
Initial state: 0 0.614053 0.0469628 0.507727 0.812011 0.550233 0.884777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55068 episodes
GETTING ACTION FROM:
action 3, numVisits=55060, meanQ=4.951123, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 3
Next state: 1 0.614053 0.0469628 0.507727 0.812011 0.550233 0.884777 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 215
Initial state: 0 0.659243 0.865272 0.0963646 0.0537331 0.611572 0.846819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55314 episodes
GETTING ACTION FROM:
action 1, numVisits=55242, meanQ=5.160325, numObservations: 4
action -1, numVisits=64, meanQ=4.326423, numObservations: 1
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action 3, numVisits=3, meanQ=0.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.659243 0.865272 0.0963646 0.0537331 0.611572 0.846819 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 216
Initial state: 0 0.0367367 0.294432 0.52837 0.864066 0.548044 0.808479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55450 episodes
GETTING ACTION FROM:
action 1, numVisits=55375, meanQ=4.902132, numObservations: 4
action -1, numVisits=71, meanQ=4.125328, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0367367 0.294432 0.52837 0.864066 0.548044 0.808479 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9079, meanQ=8.351132, numObservations: 5
action 3, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11626 episodes
GETTING ACTION FROM:
action 2, numVisits=17044, meanQ=7.090996, numObservations: 5
action 3, numVisits=1318, meanQ=6.300373, numObservations: 4
action 0, numVisits=2348, meanQ=0.448015, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-198.423673, numObservations: 1
action: 2
Next state: 0 0.0367367 0.294432 0.52837 0.864066 0.548044 0.808479 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=82, meanQ=7.396707, numObservations: 4
action 2, numVisits=28, meanQ=6.503575, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-7.851592, numObservations: 1
action -1, numVisits=2, meanQ=-191.777983, numObservations: 1
Sampled 5173 episodes
GETTING ACTION FROM:
action 3, numVisits=537, meanQ=6.131325, numObservations: 5
action 2, numVisits=33, meanQ=5.669700, numObservations: 3
action 0, numVisits=4715, meanQ=-1.627656, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-191.777983, numObservations: 1
action: 3
Next state: 1 0.0367367 0.294432 0.52837 0.864066 0.548044 0.808479 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 217
Initial state: 0 0.200157 0.00352773 0.593494 0.861952 0.66954 0.847473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55603 episodes
GETTING ACTION FROM:
action 3, numVisits=55551, meanQ=4.910249, numObservations: 3
action -1, numVisits=45, meanQ=3.897461, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.200157 0.00352773 0.593494 0.861952 0.66954 0.847473 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 218
Initial state: 0 0.444494 0.0401941 0.695472 0.852849 0.534944 0.815818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55532 episodes
GETTING ACTION FROM:
action 3, numVisits=51908, meanQ=5.001024, numObservations: 5
action 1, numVisits=3554, meanQ=4.886233, numObservations: 5
action -1, numVisits=43, meanQ=4.003510, numObservations: 1
action 0, numVisits=23, meanQ=3.618189, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action: 3
Next state: 1 0.444494 0.0401941 0.695472 0.852849 0.534944 0.815818 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 219
Initial state: 0 0.312905 0.295818 0.683291 0.807979 0.516971 0.840441 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55464 episodes
GETTING ACTION FROM:
action 2, numVisits=55368, meanQ=4.942734, numObservations: 5
action 0, numVisits=66, meanQ=4.130787, numObservations: 1
action -1, numVisits=28, meanQ=3.713266, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.312905 0.295818 0.683291 0.807979 0.516971 0.840441 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3770, meanQ=4.629018, numObservations: 5
action 2, numVisits=263, meanQ=4.356245, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67883 episodes
GETTING ACTION FROM:
action 3, numVisits=71636, meanQ=5.648793, numObservations: 5
action 2, numVisits=280, meanQ=4.337866, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.312905 0.295818 0.683291 0.807979 0.516971 0.840441 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 220
Initial state: 0 0.796816 0.0511515 0.542874 0.811659 0.553043 0.861075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55296 episodes
GETTING ACTION FROM:
action 1, numVisits=55221, meanQ=5.056717, numObservations: 4
action 0, numVisits=68, meanQ=4.277279, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.796816 0.0511515 0.542874 0.811659 0.553043 0.861075 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 221
Initial state: 0 0.686142 0.80515 0.50268 0.863889 0.178461 0.799374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53903 episodes
GETTING ACTION FROM:
action 3, numVisits=53329, meanQ=4.951658, numObservations: 5
action 2, numVisits=540, meanQ=4.677788, numObservations: 5
action 0, numVisits=29, meanQ=3.730130, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.686142 0.80515 0.50268 0.863889 0.178461 0.799374 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7529, meanQ=8.398281, numObservations: 5
action 2, numVisits=31, meanQ=7.258071, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 9160 episodes
GETTING ACTION FROM:
action 1, numVisits=15248, meanQ=7.223187, numObservations: 5
action 2, numVisits=168, meanQ=6.198633, numObservations: 3
action 0, numVisits=1297, meanQ=0.115860, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=9, meanQ=-44.017162, numObservations: 1
action: 1
Next state: 1 0.686142 0.80515 0.50268 0.863889 0.178461 0.799374 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 222
Initial state: 0 0.676583 0.84007 0.611229 0.863233 0.759319 0.929215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55519 episodes
GETTING ACTION FROM:
action 1, numVisits=55453, meanQ=4.980588, numObservations: 4
action -1, numVisits=59, meanQ=4.072646, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.676583 0.84007 0.611229 0.863233 0.759319 0.929215 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 223
Initial state: 0 0.663665 0.876388 0.186332 0.225833 0.598135 0.84604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55233 episodes
GETTING ACTION FROM:
action 2, numVisits=55224, meanQ=4.945553, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.663665 0.876388 0.186332 0.225833 0.598135 0.84604 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3312, meanQ=8.416766, numObservations: 4
action 3, numVisits=4335, meanQ=8.404339, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12510 episodes
GETTING ACTION FROM:
action 1, numVisits=5636, meanQ=7.556119, numObservations: 4
action 3, numVisits=11679, meanQ=6.711362, numObservations: 5
action -1, numVisits=2836, meanQ=0.271128, numObservations: 1
action 0, numVisits=8, meanQ=-2.001238, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.663665 0.876388 0.186332 0.225833 0.598135 0.84604 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 224
Initial state: 0 0.579067 0.8942 0.418138 0.90505 0.663154 0.878711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32575 episodes
GETTING ACTION FROM:
action 0, numVisits=32569, meanQ=2.930603, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.579067 0.8942 0.418138 0.90505 0.663154 0.878711 w: 1
Observation: 0 0 0.921227 0 0.88841 0 0.873529 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32489, meanQ=4.973223, numObservations: 4
action 0, numVisits=35, meanQ=3.903795, numObservations: 1
action 3, numVisits=36, meanQ=2.663339, numObservations: 4
action 1, numVisits=6, meanQ=1.331683, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 55302 episodes
GETTING ACTION FROM:
action 2, numVisits=87787, meanQ=4.893348, numObservations: 4
action 0, numVisits=39, meanQ=3.809783, numObservations: 1
action 3, numVisits=36, meanQ=2.663339, numObservations: 4
action 1, numVisits=6, meanQ=1.331683, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.579067 0.8942 0.418138 0.90505 0.663154 0.878711 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=6525, meanQ=5.437385, numObservations: 3
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 62593 episodes
GETTING ACTION FROM:
action 2, numVisits=69116, meanQ=5.112475, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.579067 0.8942 0.418138 0.90505 0.663154 0.878711 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1808, meanQ=5.141974, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 64180 episodes
GETTING ACTION FROM:
action 2, numVisits=65986, meanQ=5.132048, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.579067 0.8942 0.418138 0.90505 0.663154 0.878711 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=844, meanQ=8.021616, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 70664 episodes
GETTING ACTION FROM:
action 1, numVisits=71176, meanQ=5.934967, numObservations: 4
action 3, numVisits=332, meanQ=5.572229, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.579067 0.8942 0.418138 0.90505 0.663154 0.878711 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -5.11623
Run # 225
Initial state: 0 0.63361 0.703793 0.625265 0.819408 0.592772 0.841322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 56020 episodes
GETTING ACTION FROM:
action 1, numVisits=56014, meanQ=5.037482, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.63361 0.703793 0.625265 0.819408 0.592772 0.841322 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 226
Initial state: 0 0.573664 0.896968 0.602954 0.826423 0.236963 0.506985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32629 episodes
GETTING ACTION FROM:
action 0, numVisits=32624, meanQ=2.830514, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.573664 0.896968 0.602954 0.826423 0.236963 0.506985 w: 1
Observation: 0 0 0.903782 0 0.888089 0 0.409236 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32616, meanQ=4.876719, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55822 episodes
GETTING ACTION FROM:
action 2, numVisits=88431, meanQ=5.009542, numObservations: 3
action 3, numVisits=9, meanQ=1.212222, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.573664 0.896968 0.602954 0.826423 0.236963 0.506985 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 227
Initial state: 0 0.579804 0.874784 0.0977864 0.945043 0.682889 0.887252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55367 episodes
GETTING ACTION FROM:
action 3, numVisits=55360, meanQ=4.966121, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.579804 0.874784 0.0977864 0.945043 0.682889 0.887252 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3903, meanQ=4.690320, numObservations: 3
action 0, numVisits=109, meanQ=4.102279, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 69089 episodes
GETTING ACTION FROM:
action 1, numVisits=72981, meanQ=5.987930, numObservations: 3
action 0, numVisits=120, meanQ=3.591880, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.579804 0.874784 0.0977864 0.945043 0.682889 0.887252 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1452, meanQ=6.916260, numObservations: 4
action 2, numVisits=8, meanQ=2.498750, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 70833 episodes
GETTING ACTION FROM:
action 1, numVisits=72283, meanQ=5.924774, numObservations: 5
action 2, numVisits=8, meanQ=2.498750, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.579804 0.874784 0.0977864 0.945043 0.682889 0.887252 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 228
Initial state: 0 0.618307 0.845179 0.337423 0.448755 0.589461 0.815556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52857 episodes
GETTING ACTION FROM:
action 3, numVisits=52821, meanQ=4.909452, numObservations: 4
action -1, numVisits=31, meanQ=3.709029, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.618307 0.845179 0.337423 0.448755 0.589461 0.815556 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 229
Initial state: 0 0.5801 0.817205 0.841054 0.613387 0.612524 0.879728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32688 episodes
GETTING ACTION FROM:
action 0, numVisits=29748, meanQ=3.001763, numObservations: 1
action -1, numVisits=2937, meanQ=2.920168, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.5801 0.817205 0.841054 0.613387 0.612524 0.879728 w: 1
Observation: 0 0 0.849757 0 0.692056 0 0.809175 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=29705, meanQ=4.996529, numObservations: 3
action 0, numVisits=23, meanQ=3.647677, numObservations: 1
action 2, numVisits=16, meanQ=3.125013, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55926 episodes
GETTING ACTION FROM:
action 3, numVisits=85630, meanQ=5.118016, numObservations: 3
action 0, numVisits=24, meanQ=3.590901, numObservations: 1
action 2, numVisits=16, meanQ=3.125013, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.5801 0.817205 0.841054 0.613387 0.612524 0.879728 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 230
Initial state: 0 0.503148 0.813567 0.568756 0.861287 0.913729 0.0586541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55510 episodes
GETTING ACTION FROM:
action 1, numVisits=55464, meanQ=4.968556, numObservations: 4
action -1, numVisits=32, meanQ=3.782081, numObservations: 1
action 2, numVisits=11, meanQ=2.736364, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.503148 0.813567 0.568756 0.861287 0.913729 0.0586541 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 231
Initial state: 0 0.0528811 0.859756 0.529297 0.842573 0.522603 0.811074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55485 episodes
GETTING ACTION FROM:
action 2, numVisits=55473, meanQ=5.004008, numObservations: 5
action 3, numVisits=5, meanQ=1.398000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=3, meanQ=-3.296667, numObservations: 1
action: 2
Next state: 0 0.0528811 0.859756 0.529297 0.842573 0.522603 0.811074 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=525, meanQ=4.164766, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=6, meanQ=-0.669983, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 15491 episodes
GETTING ACTION FROM:
action 3, numVisits=12954, meanQ=5.510689, numObservations: 4
action 1, numVisits=10, meanQ=-0.064314, numObservations: 4
action -1, numVisits=3055, meanQ=-0.206010, numObservations: 1
action 2, numVisits=6, meanQ=-0.669983, numObservations: 3
action 0, numVisits=3, meanQ=-131.389123, numObservations: 1
action: 3
Next state: 1 0.0528811 0.859756 0.529297 0.842573 0.522603 0.811074 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 232
Initial state: 0 0.602996 0.854048 0.164205 0.728092 0.567417 0.836758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 39287 episodes
GETTING ACTION FROM:
action 0, numVisits=27021, meanQ=5.954594, numObservations: 3
action 3, numVisits=12257, meanQ=5.070487, numObservations: 5
action 2, numVisits=6, meanQ=2.500000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.602996 0.854048 0.164205 0.728092 0.567417 0.836758 w: 1
Observation: 0 0 0.95062 0 0.781075 0 0.861606 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9966, meanQ=7.769040, numObservations: 4
action 3, numVisits=7, meanQ=5.284300, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55759 episodes
GETTING ACTION FROM:
action 1, numVisits=65496, meanQ=5.525568, numObservations: 4
action 3, numVisits=188, meanQ=5.015860, numObservations: 3
action 0, numVisits=48, meanQ=4.561536, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.602996 0.854048 0.164205 0.728092 0.567417 0.836758 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 233
Initial state: 0 0.516283 0.885602 0.824917 0.265942 0.568263 0.872717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54543 episodes
GETTING ACTION FROM:
action 1, numVisits=53757, meanQ=4.959542, numObservations: 4
action 0, numVisits=691, meanQ=3.118578, numObservations: 1
action -1, numVisits=86, meanQ=2.758224, numObservations: 1
action 2, numVisits=8, meanQ=-0.125000, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.516283 0.885602 0.824917 0.265942 0.568263 0.872717 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 234
Initial state: 0 0.225654 0.000112931 0.689745 0.844576 0.57182 0.883149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32051 episodes
GETTING ACTION FROM:
action -1, numVisits=32042, meanQ=2.857446, numObservations: 1
action 3, numVisits=5, meanQ=-0.200000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.225654 0.000112931 0.689745 0.844576 0.57182 0.883149 w: 1
Observation: 0 0.15137 0 0.606442 0 0.581166 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31934, meanQ=4.859217, numObservations: 4
action 0, numVisits=83, meanQ=4.125120, numObservations: 1
action 2, numVisits=17, meanQ=2.527653, numObservations: 4
action 1, numVisits=5, meanQ=1.396020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 56126 episodes
GETTING ACTION FROM:
action 3, numVisits=88059, meanQ=4.885722, numObservations: 4
action 0, numVisits=84, meanQ=4.107760, numObservations: 1
action 2, numVisits=17, meanQ=2.527653, numObservations: 4
action 1, numVisits=5, meanQ=1.396020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.225654 0.000112931 0.689745 0.844576 0.57182 0.883149 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 235
Initial state: 0 0.653682 0.423381 0.64179 0.807909 0.554697 0.891182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55374 episodes
GETTING ACTION FROM:
action 1, numVisits=55099, meanQ=4.971103, numObservations: 3
action 3, numVisits=237, meanQ=4.516363, numObservations: 5
action 0, numVisits=34, meanQ=3.838106, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.653682 0.423381 0.64179 0.807909 0.554697 0.891182 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 236
Initial state: 0 0.371784 0.195196 0.556271 0.829286 0.663057 0.857312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53472 episodes
GETTING ACTION FROM:
action 2, numVisits=53456, meanQ=4.938364, numObservations: 5
action 1, numVisits=11, meanQ=2.346364, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.371784 0.195196 0.556271 0.829286 0.663057 0.857312 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 237
Initial state: 0 0.262314 0.119826 0.57937 0.880699 0.630732 0.800724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32692 episodes
GETTING ACTION FROM:
action 0, numVisits=32687, meanQ=2.966822, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.262314 0.119826 0.57937 0.880699 0.630732 0.800724 w: 1
Observation: 0 0 0.0866459 0 0.9441 0 0.739928 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32614, meanQ=5.070048, numObservations: 4
action -1, numVisits=39, meanQ=3.974075, numObservations: 1
action 0, numVisits=15, meanQ=3.348489, numObservations: 1
action 3, numVisits=9, meanQ=2.333333, numObservations: 1
action 2, numVisits=9, meanQ=1.218900, numObservations: 4
Sampled 55574 episodes
GETTING ACTION FROM:
action 1, numVisits=88185, meanQ=4.922679, numObservations: 4
action -1, numVisits=41, meanQ=3.876890, numObservations: 1
action 0, numVisits=16, meanQ=3.183592, numObservations: 1
action 3, numVisits=9, meanQ=2.333333, numObservations: 1
action 2, numVisits=9, meanQ=1.218900, numObservations: 4
action: 1
Next state: 2 0.262314 0.119826 0.57937 0.880699 0.630732 0.800724 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 238
Initial state: 0 0.522395 0.813322 0.415825 0.672505 0.671667 0.848363 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55447 episodes
GETTING ACTION FROM:
action 1, numVisits=55432, meanQ=4.931694, numObservations: 4
action 3, numVisits=10, meanQ=0.900020, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.522395 0.813322 0.415825 0.672505 0.671667 0.848363 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 239
Initial state: 0 0.719498 0.997708 0.576449 0.858298 0.598254 0.82412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52492 episodes
GETTING ACTION FROM:
action 3, numVisits=52485, meanQ=4.810655, numObservations: 4
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.719498 0.997708 0.576449 0.858298 0.598254 0.82412 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 240
Initial state: 0 0.644506 0.824098 0.718744 0.53685 0.591523 0.860834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55460 episodes
GETTING ACTION FROM:
action 1, numVisits=55417, meanQ=5.011767, numObservations: 5
action -1, numVisits=28, meanQ=3.751135, numObservations: 1
action 2, numVisits=12, meanQ=2.581667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.644506 0.824098 0.718744 0.53685 0.591523 0.860834 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 241
Initial state: 0 0.387542 0.802039 0.542827 0.894886 0.584182 0.884143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52485 episodes
GETTING ACTION FROM:
action 2, numVisits=52479, meanQ=4.847140, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.387542 0.802039 0.542827 0.894886 0.584182 0.884143 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 242
Initial state: 0 0.518591 0.812355 0.540549 0.832978 0.396136 0.982847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32535 episodes
GETTING ACTION FROM:
action -1, numVisits=32526, meanQ=2.840018, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=5, meanQ=-3.000000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.518591 0.812355 0.540549 0.832978 0.396136 0.982847 w: 1
Observation: 0 0.578355 0 0.462777 0 0.303996 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32518, meanQ=4.922651, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55701 episodes
GETTING ACTION FROM:
action 1, numVisits=88203, meanQ=5.012494, numObservations: 5
action 2, numVisits=18, meanQ=2.333339, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.518591 0.812355 0.540549 0.832978 0.396136 0.982847 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=6388, meanQ=5.399456, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 61781 episodes
GETTING ACTION FROM:
action 1, numVisits=68165, meanQ=5.310069, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.518591 0.812355 0.540549 0.832978 0.396136 0.982847 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 243
Initial state: 0 0.66781 0.600513 0.567365 0.851171 0.644346 0.820849 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55338 episodes
GETTING ACTION FROM:
action 2, numVisits=55332, meanQ=4.946974, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.66781 0.600513 0.567365 0.851171 0.644346 0.820849 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 244
Initial state: 0 0.745593 0.936369 0.628378 0.890156 0.589061 0.859306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55688 episodes
GETTING ACTION FROM:
action 1, numVisits=55682, meanQ=5.004349, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.745593 0.936369 0.628378 0.890156 0.589061 0.859306 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 245
Initial state: 0 0.545679 0.818444 0.606674 0.197772 0.529059 0.894472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 56125 episodes
GETTING ACTION FROM:
action 3, numVisits=56088, meanQ=5.010234, numObservations: 5
action 2, numVisits=30, meanQ=2.834347, numObservations: 4
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.545679 0.818444 0.606674 0.197772 0.529059 0.894472 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 246
Initial state: 0 0.975012 0.58043 0.512328 0.829711 0.599645 0.836913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31694 episodes
GETTING ACTION FROM:
action -1, numVisits=31247, meanQ=2.868480, numObservations: 1
action 0, numVisits=427, meanQ=2.592391, numObservations: 1
action 2, numVisits=16, meanQ=0.931250, numObservations: 4
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.975012 0.58043 0.512328 0.829711 0.599645 0.836913 w: 1
Observation: 0 0.933797 0 0.497301 0 0.577475 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31222, meanQ=4.902952, numObservations: 5
action 1, numVisits=15, meanQ=3.006673, numObservations: 3
action 3, numVisits=5, meanQ=1.396020, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 52696 episodes
GETTING ACTION FROM:
action 2, numVisits=83917, meanQ=4.966439, numObservations: 5
action 1, numVisits=15, meanQ=3.006673, numObservations: 3
action 3, numVisits=6, meanQ=0.330033, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.975012 0.58043 0.512328 0.829711 0.599645 0.836913 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 247
Initial state: 0 0.858337 0.189871 0.57293 0.895027 0.514946 0.863111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55372 episodes
GETTING ACTION FROM:
action 1, numVisits=55348, meanQ=4.860800, numObservations: 5
action -1, numVisits=19, meanQ=3.307103, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.858337 0.189871 0.57293 0.895027 0.514946 0.863111 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 248
Initial state: 0 0.648896 0.840356 0.0253823 0.336524 0.632435 0.818816 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 56059 episodes
GETTING ACTION FROM:
action 2, numVisits=56053, meanQ=5.062992, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.648896 0.840356 0.0253823 0.336524 0.632435 0.818816 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7600, meanQ=8.371489, numObservations: 5
action 1, numVisits=11, meanQ=6.090000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 14239 episodes
GETTING ACTION FROM:
action 3, numVisits=11778, meanQ=7.509095, numObservations: 5
action 1, numVisits=509, meanQ=6.263988, numObservations: 5
action -1, numVisits=9543, meanQ=0.108128, numObservations: 1
action 0, numVisits=22, meanQ=-2.450000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.648896 0.840356 0.0253823 0.336524 0.632435 0.818816 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 249
Initial state: 0 0.378073 0.526795 0.67152 0.880111 0.673766 0.847516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32722 episodes
GETTING ACTION FROM:
action 0, numVisits=32706, meanQ=2.933826, numObservations: 1
action 2, numVisits=12, meanQ=0.909167, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.378073 0.526795 0.67152 0.880111 0.673766 0.847516 w: 1
Observation: 0 0 0.504024 0 0.899842 0 0.824182 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32699, meanQ=4.991420, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55780 episodes
GETTING ACTION FROM:
action 3, numVisits=88467, meanQ=4.805337, numObservations: 4
action 2, numVisits=10, meanQ=1.199000, numObservations: 3
action 1, numVisits=4, meanQ=-0.752475, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.378073 0.526795 0.67152 0.880111 0.673766 0.847516 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 250
Initial state: 0 0.690476 0.868128 0.691576 0.83365 0.180737 0.74845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55893 episodes
GETTING ACTION FROM:
action 2, numVisits=55880, meanQ=5.013816, numObservations: 4
action 3, numVisits=8, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.690476 0.868128 0.691576 0.83365 0.180737 0.74845 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 251
Initial state: 0 0.5517 0.847374 0.130955 0.175445 0.668881 0.864552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 38512 episodes
GETTING ACTION FROM:
action 0, numVisits=28572, meanQ=5.914000, numObservations: 3
action 1, numVisits=9865, meanQ=4.995405, numObservations: 5
action -1, numVisits=38, meanQ=4.014749, numObservations: 1
action 2, numVisits=33, meanQ=3.605458, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action: 0
Next state: 0 0.5517 0.847374 0.130955 0.175445 0.668881 0.864552 w: 1
Observation: 0 0 0.819427 0 0.181691 0 0.947012 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9435, meanQ=7.989651, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 55566 episodes
GETTING ACTION FROM:
action 3, numVisits=64958, meanQ=5.473070, numObservations: 4
action 0, numVisits=42, meanQ=4.434730, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.5517 0.847374 0.130955 0.175445 0.668881 0.864552 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=4656, meanQ=5.142030, numObservations: 3
action 2, numVisits=14, meanQ=3.427150, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 68326 episodes
GETTING ACTION FROM:
action 1, numVisits=72980, meanQ=5.854398, numObservations: 3
action 2, numVisits=14, meanQ=3.427150, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.5517 0.847374 0.130955 0.175445 0.668881 0.864552 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 252
Initial state: 0 0.589465 0.795049 0.69616 0.81024 0.662926 0.821758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55169 episodes
GETTING ACTION FROM:
action 1, numVisits=55134, meanQ=4.938079, numObservations: 4
action -1, numVisits=31, meanQ=3.696872, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.589465 0.795049 0.69616 0.81024 0.662926 0.821758 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 253
Initial state: 0 0.651718 0.831235 0.527872 0.833474 0.891189 0.847525 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54824 episodes
GETTING ACTION FROM:
action 3, numVisits=54818, meanQ=4.950444, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.651718 0.831235 0.527872 0.833474 0.891189 0.847525 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 254
Initial state: 0 0.982234 0.222635 0.577712 0.804616 0.587708 0.810839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55410 episodes
GETTING ACTION FROM:
action 3, numVisits=55365, meanQ=4.970606, numObservations: 4
action -1, numVisits=29, meanQ=3.752645, numObservations: 1
action 1, numVisits=10, meanQ=2.300010, numObservations: 4
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.982234 0.222635 0.577712 0.804616 0.587708 0.810839 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 255
Initial state: 0 0.525409 0.83464 0.962184 0.195625 0.503395 0.811765 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52665 episodes
GETTING ACTION FROM:
action 3, numVisits=52590, meanQ=4.908694, numObservations: 4
action 2, numVisits=70, meanQ=3.905151, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.525409 0.83464 0.962184 0.195625 0.503395 0.811765 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 256
Initial state: 0 0.391608 0.708835 0.557061 0.817573 0.694333 0.888046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55457 episodes
GETTING ACTION FROM:
action 3, numVisits=55295, meanQ=5.014547, numObservations: 5
action -1, numVisits=149, meanQ=4.495841, numObservations: 1
action 1, numVisits=9, meanQ=2.664444, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.391608 0.708835 0.557061 0.817573 0.694333 0.888046 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 257
Initial state: 0 0.638397 0.858754 0.635339 0.845409 0.200717 0.435407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51910 episodes
GETTING ACTION FROM:
action 3, numVisits=47135, meanQ=4.961548, numObservations: 4
action -1, numVisits=4771, meanQ=3.031856, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.638397 0.858754 0.635339 0.845409 0.200717 0.435407 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7636, meanQ=8.338167, numObservations: 5
action 1, numVisits=9, meanQ=6.331111, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 15327 episodes
GETTING ACTION FROM:
action 2, numVisits=17385, meanQ=7.030274, numObservations: 5
action 1, numVisits=1618, meanQ=6.065904, numObservations: 3
action 3, numVisits=7, meanQ=5.284300, numObservations: 3
action 0, numVisits=3960, meanQ=0.243500, numObservations: 1
action -1, numVisits=5, meanQ=-78.261929, numObservations: 1
action: 2
Next state: 1 0.638397 0.858754 0.635339 0.845409 0.200717 0.435407 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 258
Initial state: 0 0.594359 0.876209 0.813883 0.463233 0.524923 0.871334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54926 episodes
GETTING ACTION FROM:
action 2, numVisits=54865, meanQ=4.924321, numObservations: 5
action -1, numVisits=31, meanQ=3.703931, numObservations: 1
action 1, numVisits=26, meanQ=3.150777, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.594359 0.876209 0.813883 0.463233 0.524923 0.871334 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 259
Initial state: 0 0.566497 0.856843 0.98522 0.881139 0.662236 0.828827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54892 episodes
GETTING ACTION FROM:
action 3, numVisits=54843, meanQ=4.953503, numObservations: 5
action -1, numVisits=32, meanQ=3.784475, numObservations: 1
action 2, numVisits=14, meanQ=0.857157, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.566497 0.856843 0.98522 0.881139 0.662236 0.828827 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 260
Initial state: 0 0.63927 0.827358 0.651877 0.87864 0.229784 0.431932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55793 episodes
GETTING ACTION FROM:
action 2, numVisits=55746, meanQ=5.061030, numObservations: 3
action -1, numVisits=42, meanQ=4.014876, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.63927 0.827358 0.651877 0.87864 0.229784 0.431932 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=496, meanQ=5.872390, numObservations: 3
action 1, numVisits=3, meanQ=2.333333, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 10739 episodes
GETTING ACTION FROM:
action 3, numVisits=6796, meanQ=6.158572, numObservations: 3
action 2, numVisits=500, meanQ=5.863231, numObservations: 4
action 0, numVisits=3935, meanQ=0.266811, numObservations: 1
action 1, numVisits=6, meanQ=-1.000000, numObservations: 3
action -1, numVisits=7, meanQ=-1.858571, numObservations: 1
action: 3
Next state: 0 0.63927 0.827358 0.651877 0.87864 0.229784 0.431932 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=9.000000, numObservations: 1
action 1, numVisits=30, meanQ=7.737701, numObservations: 3
action -1, numVisits=55, meanQ=6.766000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-7.885968, numObservations: 1
Sampled 7069 episodes
GETTING ACTION FROM:
action 1, numVisits=118, meanQ=6.814670, numObservations: 3
action 2, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=5943, meanQ=-1.503584, numObservations: 1
action 0, numVisits=1092, meanQ=-1.608370, numObservations: 2
action 3, numVisits=1, meanQ=-7.885968, numObservations: 1
action: 1
Next state: 1 0.63927 0.827358 0.651877 0.87864 0.229784 0.431932 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 261
Initial state: 0 0.57172 0.829047 0.156494 0.559575 0.688395 0.85724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55249 episodes
GETTING ACTION FROM:
action 1, numVisits=55228, meanQ=4.883291, numObservations: 4
action 3, numVisits=16, meanQ=0.006269, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.57172 0.829047 0.156494 0.559575 0.688395 0.85724 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 262
Initial state: 0 0.537548 0.866339 0.983264 0.777829 0.622447 0.803725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 43040 episodes
GETTING ACTION FROM:
action 1, numVisits=24769, meanQ=5.043290, numObservations: 4
action -1, numVisits=14345, meanQ=2.949206, numObservations: 1
action 0, numVisits=3917, meanQ=2.901396, numObservations: 1
action 3, numVisits=8, meanQ=0.750000, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.537548 0.866339 0.983264 0.777829 0.622447 0.803725 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 263
Initial state: 0 0.213049 0.0778337 0.691858 0.841131 0.522475 0.852332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55259 episodes
GETTING ACTION FROM:
action 3, numVisits=52421, meanQ=4.919187, numObservations: 4
action 2, numVisits=2830, meanQ=4.765456, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.213049 0.0778337 0.691858 0.841131 0.522475 0.852332 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.137952 0.577328 0.600317 0.842477 0.606655 0.855669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54943 episodes
GETTING ACTION FROM:
action 1, numVisits=54937, meanQ=4.917994, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.137952 0.577328 0.600317 0.842477 0.606655 0.855669 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6060, meanQ=8.523069, numObservations: 3
action 3, numVisits=82, meanQ=7.924516, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12157 episodes
GETTING ACTION FROM:
action 2, numVisits=15230, meanQ=6.953672, numObservations: 4
action 3, numVisits=655, meanQ=5.448073, numObservations: 4
action 1, numVisits=3, meanQ=0.663333, numObservations: 3
action 0, numVisits=2406, meanQ=0.006737, numObservations: 1
action -1, numVisits=8, meanQ=-2.251213, numObservations: 1
action: 2
Next state: 0 0.137952 0.577328 0.600317 0.842477 0.606655 0.855669 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=452, meanQ=8.577935, numObservations: 3
action 3, numVisits=50, meanQ=7.640006, numObservations: 3
action 0, numVisits=163, meanQ=3.540802, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 15997 episodes
GETTING ACTION FROM:
action 2, numVisits=4119, meanQ=5.952892, numObservations: 4
action 3, numVisits=3122, meanQ=5.930417, numObservations: 5
action 0, numVisits=7194, meanQ=-1.716861, numObservations: 1
action -1, numVisits=2229, meanQ=-1.776155, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.137952 0.577328 0.600317 0.842477 0.606655 0.855669 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 265
Initial state: 0 0.878636 0.273613 0.693306 0.83351 0.537402 0.855998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55480 episodes
GETTING ACTION FROM:
action 2, numVisits=55467, meanQ=4.942054, numObservations: 4
action 1, numVisits=7, meanQ=2.428571, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.878636 0.273613 0.693306 0.83351 0.537402 0.855998 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4139, meanQ=5.537675, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 63204 episodes
GETTING ACTION FROM:
action 2, numVisits=67341, meanQ=5.085301, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.878636 0.273613 0.693306 0.83351 0.537402 0.855998 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 266
Initial state: 0 0.529354 0.855104 0.0721173 0.367721 0.500047 0.816944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55437 episodes
GETTING ACTION FROM:
action 1, numVisits=55395, meanQ=4.910481, numObservations: 5
action 2, numVisits=21, meanQ=3.411438, numObservations: 3
action -1, numVisits=18, meanQ=3.132040, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.529354 0.855104 0.0721173 0.367721 0.500047 0.816944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 267
Initial state: 0 0.632748 0.875267 0.658451 0.869869 0.732096 0.713305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55031 episodes
GETTING ACTION FROM:
action 3, numVisits=55018, meanQ=4.968767, numObservations: 3
action 1, numVisits=6, meanQ=2.168350, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.632748 0.875267 0.658451 0.869869 0.732096 0.713305 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 268
Initial state: 0 0.508274 0.806664 0.798724 0.564059 0.515017 0.827489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55602 episodes
GETTING ACTION FROM:
action 2, numVisits=55442, meanQ=5.021753, numObservations: 5
action 3, numVisits=135, meanQ=4.355521, numObservations: 3
action 0, numVisits=21, meanQ=3.571206, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.508274 0.806664 0.798724 0.564059 0.515017 0.827489 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4150, meanQ=5.585963, numObservations: 3
action 1, numVisits=11, meanQ=2.808182, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 14892 episodes
GETTING ACTION FROM:
action 1, numVisits=12777, meanQ=6.240059, numObservations: 4
action 2, numVisits=4150, meanQ=5.585963, numObservations: 3
action 0, numVisits=2126, meanQ=-0.225181, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=2, meanQ=-198.544261, numObservations: 1
action: 1
Next state: 1 0.508274 0.806664 0.798724 0.564059 0.515017 0.827489 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 269
Initial state: 0 0.533352 0.850549 0.983397 0.0578603 0.506772 0.817793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55305 episodes
GETTING ACTION FROM:
action 1, numVisits=55297, meanQ=4.949451, numObservations: 4
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.533352 0.850549 0.983397 0.0578603 0.506772 0.817793 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4015, meanQ=4.571592, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 67568 episodes
GETTING ACTION FROM:
action 2, numVisits=71579, meanQ=5.551008, numObservations: 5
action 3, numVisits=6, meanQ=1.331683, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.533352 0.850549 0.983397 0.0578603 0.506772 0.817793 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 270
Initial state: 0 0.634588 0.828653 0.0495326 0.265627 0.573569 0.822001 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55302 episodes
GETTING ACTION FROM:
action 2, numVisits=55152, meanQ=5.045298, numObservations: 5
action -1, numVisits=127, meanQ=4.473987, numObservations: 1
action 3, numVisits=20, meanQ=1.649515, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.634588 0.828653 0.0495326 0.265627 0.573569 0.822001 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1659, meanQ=8.425078, numObservations: 4
action 1, numVisits=6073, meanQ=8.399159, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 14002 episodes
GETTING ACTION FROM:
action 1, numVisits=7099, meanQ=8.032691, numObservations: 3
action 3, numVisits=12592, meanQ=6.357840, numObservations: 5
action 0, numVisits=2038, meanQ=0.036835, numObservations: 1
action -1, numVisits=6, meanQ=-3.780983, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 1
Next state: 1 0.634588 0.828653 0.0495326 0.265627 0.573569 0.822001 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 271
Initial state: 0 0.631958 0.819838 0.593737 0.823356 0.628802 0.0335901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55600 episodes
GETTING ACTION FROM:
action 2, numVisits=55584, meanQ=4.995302, numObservations: 4
action 1, numVisits=11, meanQ=1.727282, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.631958 0.819838 0.593737 0.823356 0.628802 0.0335901 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 272
Initial state: 0 0.655036 0.814618 0.265956 0.897262 0.649283 0.878714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55161 episodes
GETTING ACTION FROM:
action 3, numVisits=55070, meanQ=4.999395, numObservations: 5
action 0, numVisits=41, meanQ=3.960366, numObservations: 1
action -1, numVisits=36, meanQ=3.909839, numObservations: 1
action 2, numVisits=13, meanQ=3.155400, numObservations: 5
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.655036 0.814618 0.265956 0.897262 0.649283 0.878714 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 273
Initial state: 0 0.606762 0.845634 0.429807 0.71082 0.608248 0.8483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54119 episodes
GETTING ACTION FROM:
action 1, numVisits=53130, meanQ=4.882978, numObservations: 5
action -1, numVisits=985, meanQ=3.310695, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.606762 0.845634 0.429807 0.71082 0.608248 0.8483 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 274
Initial state: 0 0.589282 0.8683 0.682796 0.878029 0.0214146 0.0157052 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32425 episodes
GETTING ACTION FROM:
action -1, numVisits=31813, meanQ=2.913070, numObservations: 1
action 0, numVisits=606, meanQ=1.372132, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.589282 0.8683 0.682796 0.878029 0.0214146 0.0157052 w: 1
Observation: 0 0.508503 0 0.747909 0 0.120153 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31774, meanQ=4.964812, numObservations: 4
action 1, numVisits=26, meanQ=3.600769, numObservations: 3
action 3, numVisits=8, meanQ=1.747513, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 55888 episodes
GETTING ACTION FROM:
action 2, numVisits=87657, meanQ=5.156933, numObservations: 4
action 1, numVisits=26, meanQ=3.600769, numObservations: 3
action 3, numVisits=13, meanQ=2.683854, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.589282 0.8683 0.682796 0.878029 0.0214146 0.0157052 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 275
Initial state: 0 0.659764 0.801317 0.79129 0.123127 0.672561 0.852834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55652 episodes
GETTING ACTION FROM:
action 2, numVisits=55644, meanQ=5.183081, numObservations: 5
action 1, numVisits=3, meanQ=-0.659967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.659764 0.801317 0.79129 0.123127 0.672561 0.852834 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 276
Initial state: 0 0.576797 0.887907 0.536727 0.82293 0.642475 0.716092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32727 episodes
GETTING ACTION FROM:
action -1, numVisits=32712, meanQ=3.081245, numObservations: 1
action 3, numVisits=7, meanQ=0.570014, numObservations: 3
action 2, numVisits=5, meanQ=-0.795980, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.576797 0.887907 0.536727 0.82293 0.642475 0.716092 w: 1
Observation: 0 0.66441 0 0.546212 0 0.631323 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32705, meanQ=5.084274, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 55200 episodes
GETTING ACTION FROM:
action 3, numVisits=87874, meanQ=5.118908, numObservations: 5
action 1, numVisits=32, meanQ=3.928128, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.576797 0.887907 0.536727 0.82293 0.642475 0.716092 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 277
Initial state: 0 0.574553 0.843097 0.607933 0.899875 0.071469 0.207318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55743 episodes
GETTING ACTION FROM:
action 1, numVisits=55735, meanQ=5.187292, numObservations: 5
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.574553 0.843097 0.607933 0.899875 0.071469 0.207318 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.67447 0.894744 0.517171 0.807935 0.024167 0.0949388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32746 episodes
GETTING ACTION FROM:
action 0, numVisits=32733, meanQ=3.048389, numObservations: 1
action 3, numVisits=7, meanQ=-0.571414, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 0
Next state: 0 0.67447 0.894744 0.517171 0.807935 0.024167 0.0949388 w: 1
Observation: 0 0 0.887493 0 0.799827 0 0.0873902 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32699, meanQ=5.103730, numObservations: 4
action 0, numVisits=25, meanQ=3.769375, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 55310 episodes
GETTING ACTION FROM:
action 1, numVisits=88008, meanQ=5.220504, numObservations: 4
action 0, numVisits=26, meanQ=3.634509, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.67447 0.894744 0.517171 0.807935 0.024167 0.0949388 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 279
Initial state: 0 0.560275 0.895457 0.516302 0.81238 0.407147 0.410613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52390 episodes
GETTING ACTION FROM:
action 2, numVisits=47797, meanQ=4.973682, numObservations: 4
action -1, numVisits=4589, meanQ=2.973698, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.560275 0.895457 0.516302 0.81238 0.407147 0.410613 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 280
Initial state: 0 0.645604 0.847208 0.562753 0.899211 0.134624 0.546878 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55552 episodes
GETTING ACTION FROM:
action 1, numVisits=55546, meanQ=4.989932, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.645604 0.847208 0.562753 0.899211 0.134624 0.546878 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 281
Initial state: 0 0.656978 0.886921 0.111723 0.406251 0.532678 0.843003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52988 episodes
GETTING ACTION FROM:
action 2, numVisits=52931, meanQ=4.930430, numObservations: 3
action -1, numVisits=52, meanQ=4.041597, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.656978 0.886921 0.111723 0.406251 0.532678 0.843003 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8776, meanQ=8.327852, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11641 episodes
GETTING ACTION FROM:
action 1, numVisits=15116, meanQ=7.332626, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=5296, meanQ=0.168803, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-4.318085, numObservations: 1
action: 1
Next state: 1 0.656978 0.886921 0.111723 0.406251 0.532678 0.843003 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 282
Initial state: 0 0.515294 0.893202 0.358064 0.906019 0.635231 0.861809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30033 episodes
GETTING ACTION FROM:
action 0, numVisits=29742, meanQ=5.196104, numObservations: 3
action -1, numVisits=282, meanQ=1.079835, numObservations: 1
action 2, numVisits=5, meanQ=-1.402000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.515294 0.893202 0.358064 0.906019 0.635231 0.861809 w: 1
Observation: 0 0 0.869231 0 0.900085 0 0.954506 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9770, meanQ=8.032611, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55988 episodes
GETTING ACTION FROM:
action 3, numVisits=65755, meanQ=5.433987, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.515294 0.893202 0.358064 0.906019 0.635231 0.861809 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 283
Initial state: 0 0.532366 0.895095 0.586646 0.824573 0.259159 0.224017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54295 episodes
GETTING ACTION FROM:
action 1, numVisits=54289, meanQ=4.881473, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.532366 0.895095 0.586646 0.824573 0.259159 0.224017 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 284
Initial state: 0 0.628468 0.875019 0.560188 0.860604 0.905881 0.0374353 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55501 episodes
GETTING ACTION FROM:
action 3, numVisits=55361, meanQ=4.985738, numObservations: 5
action -1, numVisits=119, meanQ=4.403256, numObservations: 1
action 0, numVisits=19, meanQ=3.480054, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.628468 0.875019 0.560188 0.860604 0.905881 0.0374353 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4079, meanQ=5.215838, numObservations: 4
action 1, numVisits=49, meanQ=3.802867, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 9880 episodes
GETTING ACTION FROM:
action 2, numVisits=5465, meanQ=6.018660, numObservations: 4
action 3, numVisits=4079, meanQ=5.215838, numObservations: 4
action 1, numVisits=49, meanQ=3.802867, numObservations: 4
action 0, numVisits=4416, meanQ=0.241848, numObservations: 1
action -1, numVisits=3, meanQ=-130.912202, numObservations: 1
action: 2
Next state: 1 0.628468 0.875019 0.560188 0.860604 0.905881 0.0374353 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 285
Initial state: 0 0.683669 0.873704 0.966129 0.902029 0.513907 0.860334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55310 episodes
GETTING ACTION FROM:
action 3, numVisits=54952, meanQ=5.028863, numObservations: 4
action -1, numVisits=200, meanQ=4.572374, numObservations: 1
action 0, numVisits=121, meanQ=4.438701, numObservations: 1
action 1, numVisits=31, meanQ=2.999684, numObservations: 5
action 2, numVisits=6, meanQ=1.498333, numObservations: 2
action: 3
Next state: 1 0.683669 0.873704 0.966129 0.902029 0.513907 0.860334 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 286
Initial state: 0 0.693073 0.848176 0.314079 0.756232 0.559357 0.802063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55288 episodes
GETTING ACTION FROM:
action 2, numVisits=55273, meanQ=4.992950, numObservations: 5
action 3, numVisits=10, meanQ=1.799000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.693073 0.848176 0.314079 0.756232 0.559357 0.802063 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7669, meanQ=8.386233, numObservations: 5
action 3, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9756 episodes
GETTING ACTION FROM:
action 1, numVisits=14681, meanQ=7.367234, numObservations: 5
action 3, numVisits=76, meanQ=1.088818, numObservations: 4
action 2, numVisits=3, meanQ=0.663333, numObservations: 3
action -1, numVisits=2580, meanQ=0.286593, numObservations: 1
action 0, numVisits=91, meanQ=-0.285144, numObservations: 1
action: 1
Next state: 1 0.693073 0.848176 0.314079 0.756232 0.559357 0.802063 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 287
Initial state: 0 0.608021 0.878857 0.145357 0.538582 0.650994 0.865488 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55256 episodes
GETTING ACTION FROM:
action 1, numVisits=55151, meanQ=4.975891, numObservations: 4
action 0, numVisits=100, meanQ=4.329656, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.608021 0.878857 0.145357 0.538582 0.650994 0.865488 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 288
Initial state: 0 0.836747 0.966135 0.696573 0.822116 0.574335 0.858414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55145 episodes
GETTING ACTION FROM:
action 2, numVisits=55128, meanQ=5.023444, numObservations: 5
action 3, numVisits=12, meanQ=1.915833, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.836747 0.966135 0.696573 0.822116 0.574335 0.858414 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 289
Initial state: 0 0.955916 0.260432 0.691699 0.820256 0.679409 0.850839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32485 episodes
GETTING ACTION FROM:
action 0, numVisits=32428, meanQ=2.936249, numObservations: 1
action -1, numVisits=48, meanQ=2.019550, numObservations: 1
action 3, numVisits=5, meanQ=-0.002000, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.955916 0.260432 0.691699 0.820256 0.679409 0.850839 w: 1
Observation: 0 0 0.166047 0 0.750086 0 0.912574 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32362, meanQ=4.930480, numObservations: 5
action 0, numVisits=37, meanQ=3.828493, numObservations: 1
action 1, numVisits=25, meanQ=3.632012, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55835 episodes
GETTING ACTION FROM:
action 2, numVisits=88188, meanQ=4.854250, numObservations: 5
action 0, numVisits=38, meanQ=3.766982, numObservations: 1
action 1, numVisits=27, meanQ=3.511126, numObservations: 3
action 3, numVisits=7, meanQ=1.427171, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.955916 0.260432 0.691699 0.820256 0.679409 0.850839 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 290
Initial state: 0 0.710791 0.463095 0.651031 0.8076 0.650045 0.832858 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32775 episodes
GETTING ACTION FROM:
action -1, numVisits=32770, meanQ=2.851257, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.710791 0.463095 0.651031 0.8076 0.650045 0.832858 w: 1
Observation: 0 0.743779 0 0.595948 0 0.645985 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32743, meanQ=4.950322, numObservations: 4
action 1, numVisits=21, meanQ=2.999529, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55540 episodes
GETTING ACTION FROM:
action 3, numVisits=88272, meanQ=4.807931, numObservations: 4
action 1, numVisits=31, meanQ=3.386784, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.710791 0.463095 0.651031 0.8076 0.650045 0.832858 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 291
Initial state: 0 0.670391 0.802794 0.953681 0.613221 0.642897 0.802047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55386 episodes
GETTING ACTION FROM:
action 3, numVisits=55378, meanQ=5.023599, numObservations: 5
action 2, numVisits=3, meanQ=-2.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.670391 0.802794 0.953681 0.613221 0.642897 0.802047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 292
Initial state: 0 0.60989 0.868553 0.506699 0.88787 0.873812 0.75312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55479 episodes
GETTING ACTION FROM:
action 3, numVisits=55433, meanQ=5.052256, numObservations: 4
action 0, numVisits=41, meanQ=4.036621, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.60989 0.868553 0.506699 0.88787 0.873812 0.75312 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 293
Initial state: 0 0.637598 0.850638 0.0121422 0.989308 0.579324 0.800498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55380 episodes
GETTING ACTION FROM:
action 3, numVisits=16770, meanQ=4.942403, numObservations: 4
action 2, numVisits=38353, meanQ=4.921766, numObservations: 4
action 0, numVisits=254, meanQ=4.539456, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.637598 0.850638 0.0121422 0.989308 0.579324 0.800498 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 294
Initial state: 0 0.540547 0.817452 0.141212 0.371822 0.575368 0.855455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55448 episodes
GETTING ACTION FROM:
action 3, numVisits=55441, meanQ=5.158798, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.540547 0.817452 0.141212 0.371822 0.575368 0.855455 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 295
Initial state: 0 0.558343 0.849471 0.567664 0.817633 0.829542 0.61817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32656 episodes
GETTING ACTION FROM:
action 0, numVisits=32426, meanQ=3.042930, numObservations: 1
action -1, numVisits=215, meanQ=2.638473, numObservations: 1
action 3, numVisits=11, meanQ=0.635464, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.558343 0.849471 0.567664 0.817633 0.829542 0.61817 w: 1
Observation: 0 0 0.810905 0 0.891213 0 0.538078 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32418, meanQ=5.098487, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55580 episodes
GETTING ACTION FROM:
action 1, numVisits=87990, meanQ=4.916317, numObservations: 3
action 3, numVisits=8, meanQ=1.623763, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.558343 0.849471 0.567664 0.817633 0.829542 0.61817 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 296
Initial state: 0 0.405145 0.974143 0.526129 0.850733 0.566115 0.894341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55347 episodes
GETTING ACTION FROM:
action 1, numVisits=54978, meanQ=5.011962, numObservations: 4
action 2, numVisits=311, meanQ=4.630754, numObservations: 3
action -1, numVisits=34, meanQ=3.873996, numObservations: 1
action 3, numVisits=22, meanQ=3.449550, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.405145 0.974143 0.526129 0.850733 0.566115 0.894341 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1363, meanQ=8.047920, numObservations: 3
action 2, numVisits=6, meanQ=3.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12251 episodes
GETTING ACTION FROM:
action 3, numVisits=1746, meanQ=7.505673, numObservations: 3
action 2, numVisits=223, meanQ=5.451031, numObservations: 4
action -1, numVisits=11639, meanQ=0.220629, numObservations: 1
action 0, numVisits=14, meanQ=-2.072129, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.405145 0.974143 0.526129 0.850733 0.566115 0.894341 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 297
Initial state: 0 0.646751 0.831883 0.891993 0.144174 0.527642 0.819591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55419 episodes
GETTING ACTION FROM:
action 1, numVisits=49693, meanQ=4.994199, numObservations: 4
action 3, numVisits=5721, meanQ=4.934250, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.646751 0.831883 0.891993 0.144174 0.527642 0.819591 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 298
Initial state: 0 0.606623 0.80627 0.5895 0.817986 0.636498 0.447863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52675 episodes
GETTING ACTION FROM:
action 2, numVisits=52642, meanQ=4.827241, numObservations: 4
action 3, numVisits=16, meanQ=3.175625, numObservations: 4
action -1, numVisits=14, meanQ=2.962531, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.606623 0.80627 0.5895 0.817986 0.636498 0.447863 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 299
Initial state: 0 0.507726 0.882653 0.669406 0.849506 0.85637 0.142669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55360 episodes
GETTING ACTION FROM:
action 2, numVisits=55285, meanQ=4.995865, numObservations: 4
action -1, numVisits=70, meanQ=4.216271, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.507726 0.882653 0.669406 0.849506 0.85637 0.142669 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2679, meanQ=7.914145, numObservations: 4
action 1, numVisits=12, meanQ=6.316667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8144 episodes
GETTING ACTION FROM:
action 3, numVisits=7428, meanQ=6.698056, numObservations: 4
action 1, numVisits=183, meanQ=6.071246, numObservations: 3
action -1, numVisits=3217, meanQ=0.407143, numObservations: 1
action 0, numVisits=3, meanQ=-5.233315, numObservations: 1
action 2, numVisits=7, meanQ=-49.680298, numObservations: 2
action: 3
Next state: 2 0.507726 0.882653 0.669406 0.849506 0.85637 0.142669 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 300
Initial state: 0 0.967727 0.263382 0.560925 0.825169 0.582778 0.876601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52263 episodes
GETTING ACTION FROM:
action 1, numVisits=47473, meanQ=5.025920, numObservations: 3
action 0, numVisits=4782, meanQ=3.032680, numObservations: 2
action 2, numVisits=5, meanQ=-0.002000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.967727 0.263382 0.560925 0.825169 0.582778 0.876601 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 301
Initial state: 0 0.639861 0.840744 0.544534 0.86033 0.0739599 0.792737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55517 episodes
GETTING ACTION FROM:
action 2, numVisits=55448, meanQ=4.970136, numObservations: 4
action 0, numVisits=40, meanQ=3.891578, numObservations: 1
action -1, numVisits=24, meanQ=3.626327, numObservations: 1
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.639861 0.840744 0.544534 0.86033 0.0739599 0.792737 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 302
Initial state: 0 0.642029 0.811788 0.517692 0.838351 0.946422 0.0888381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32735 episodes
GETTING ACTION FROM:
action -1, numVisits=32730, meanQ=2.906807, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.642029 0.811788 0.517692 0.838351 0.946422 0.0888381 w: 1
Observation: 0 0.706104 0 0.509595 0 0.858895 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32718, meanQ=4.997822, numObservations: 5
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 56297 episodes
GETTING ACTION FROM:
action 1, numVisits=89004, meanQ=4.986852, numObservations: 5
action 2, numVisits=10, meanQ=1.601010, numObservations: 4
action 3, numVisits=8, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.642029 0.811788 0.517692 0.838351 0.946422 0.0888381 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 303
Initial state: 0 0.141883 0.306178 0.578391 0.81502 0.543402 0.805998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55225 episodes
GETTING ACTION FROM:
action 1, numVisits=55207, meanQ=4.957291, numObservations: 3
action -1, numVisits=12, meanQ=3.043087, numObservations: 1
action 3, numVisits=3, meanQ=0.663333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.141883 0.306178 0.578391 0.81502 0.543402 0.805998 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8648, meanQ=8.356532, numObservations: 3
action 2, numVisits=463, meanQ=8.082920, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 13139 episodes
GETTING ACTION FROM:
action 3, numVisits=15761, meanQ=7.374265, numObservations: 3
action 2, numVisits=1036, meanQ=6.923253, numObservations: 4
action -1, numVisits=5450, meanQ=0.423048, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=5, meanQ=-76.096415, numObservations: 1
action: 3
Next state: 1 0.141883 0.306178 0.578391 0.81502 0.543402 0.805998 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 304
Initial state: 0 0.603443 0.889979 0.570792 0.85882 0.732973 0.60262 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32683 episodes
GETTING ACTION FROM:
action 0, numVisits=32673, meanQ=3.133256, numObservations: 1
action 2, numVisits=6, meanQ=0.166667, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.603443 0.889979 0.570792 0.85882 0.732973 0.60262 w: 1
Observation: 0 0 0.938084 0 0.923957 0 0.614765 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32645, meanQ=5.198948, numObservations: 4
action 3, numVisits=15, meanQ=3.253340, numObservations: 3
action 1, numVisits=8, meanQ=2.746263, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 55235 episodes
GETTING ACTION FROM:
action 2, numVisits=87878, meanQ=5.164408, numObservations: 4
action 3, numVisits=15, meanQ=3.253340, numObservations: 3
action 1, numVisits=10, meanQ=2.597020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.603443 0.889979 0.570792 0.85882 0.732973 0.60262 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 305
Initial state: 0 0.579978 0.801586 0.668159 0.79323 0.618124 0.826766 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 23991 episodes
GETTING ACTION FROM:
action 0, numVisits=23976, meanQ=3.702745, numObservations: 1
action 3, numVisits=10, meanQ=-1.078000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.579978 0.801586 0.668159 0.79323 0.618124 0.826766 w: 1
Observation: 0 0 0.790442 0 0.853979 0 0.909698 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=23964, meanQ=5.852378, numObservations: 3
action 2, numVisits=7, meanQ=-0.145714, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 33720 episodes
GETTING ACTION FROM:
action 0, numVisits=57684, meanQ=5.872693, numObservations: 3
action 2, numVisits=7, meanQ=-0.145714, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.579978 0.801586 0.668159 0.79323 0.618124 0.826766 w: 1
Observation: 0 0 0.76735 0 0.747323 0 0.752838 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=17692, meanQ=8.031119, numObservations: 5
action 3, numVisits=14, meanQ=6.284293, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54591 episodes
GETTING ACTION FROM:
action 1, numVisits=72255, meanQ=5.787137, numObservations: 5
action 3, numVisits=41, meanQ=4.698059, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.579978 0.801586 0.668159 0.79323 0.618124 0.826766 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 306
Initial state: 0 0.432944 0.87707 0.538174 0.823641 0.641388 0.852603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55120 episodes
GETTING ACTION FROM:
action 2, numVisits=54982, meanQ=4.866100, numObservations: 5
action 0, numVisits=66, meanQ=4.072298, numObservations: 1
action -1, numVisits=51, meanQ=3.948671, numObservations: 1
action 3, numVisits=20, meanQ=2.696505, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.432944 0.87707 0.538174 0.823641 0.641388 0.852603 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 307
Initial state: 0 0.655032 0.838115 0.571295 0.896337 0.114388 0.333596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55550 episodes
GETTING ACTION FROM:
action 1, numVisits=55541, meanQ=5.015375, numObservations: 5
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.655032 0.838115 0.571295 0.896337 0.114388 0.333596 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 308
Initial state: 0 0.587992 0.800496 0.960442 0.323834 0.533812 0.843229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52809 episodes
GETTING ACTION FROM:
action 1, numVisits=52726, meanQ=4.891809, numObservations: 5
action 3, numVisits=47, meanQ=3.797026, numObservations: 4
action -1, numVisits=33, meanQ=3.761434, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.587992 0.800496 0.960442 0.323834 0.533812 0.843229 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 309
Initial state: 0 0.575678 0.839241 0.0349518 0.0761042 0.608616 0.816475 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55220 episodes
GETTING ACTION FROM:
action 3, numVisits=55130, meanQ=4.963661, numObservations: 5
action -1, numVisits=81, meanQ=4.244706, numObservations: 1
action 1, numVisits=6, meanQ=1.166683, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.575678 0.839241 0.0349518 0.0761042 0.608616 0.816475 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 310
Initial state: 0 0.597291 0.84451 0.579901 0.895823 0.285892 0.960418 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54758 episodes
GETTING ACTION FROM:
action 2, numVisits=54686, meanQ=4.986363, numObservations: 5
action -1, numVisits=68, meanQ=4.194758, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.597291 0.84451 0.579901 0.895823 0.285892 0.960418 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 311
Initial state: 0 0.191967 0.209812 0.638091 0.832204 0.644423 0.846057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32211 episodes
GETTING ACTION FROM:
action 0, numVisits=32206, meanQ=2.909432, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.191967 0.209812 0.638091 0.832204 0.644423 0.846057 w: 1
Observation: 0 0 0.192241 0 0.739256 0 0.792223 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32073, meanQ=4.957262, numObservations: 4
action -1, numVisits=71, meanQ=4.201680, numObservations: 1
action 3, numVisits=56, meanQ=3.980536, numObservations: 4
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 55346 episodes
GETTING ACTION FROM:
action 2, numVisits=11889, meanQ=5.293534, numObservations: 4
action 1, numVisits=75495, meanQ=4.839114, numObservations: 4
action -1, numVisits=85, meanQ=4.132022, numObservations: 1
action 3, numVisits=80, meanQ=3.984000, numObservations: 4
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.191967 0.209812 0.638091 0.832204 0.644423 0.846057 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 312
Initial state: 0 0.632697 0.854905 0.698799 0.831452 0.42284 0.115404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55193 episodes
GETTING ACTION FROM:
action 2, numVisits=55178, meanQ=4.988397, numObservations: 4
action 1, numVisits=10, meanQ=2.399010, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.632697 0.854905 0.698799 0.831452 0.42284 0.115404 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 313
Initial state: 0 0.771851 0.43582 0.537784 0.883039 0.601321 0.850484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55209 episodes
GETTING ACTION FROM:
action 2, numVisits=55049, meanQ=4.937095, numObservations: 5
action 1, numVisits=78, meanQ=4.053851, numObservations: 4
action 0, numVisits=56, meanQ=4.031942, numObservations: 1
action -1, numVisits=25, meanQ=3.514217, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.771851 0.43582 0.537784 0.883039 0.601321 0.850484 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 314
Initial state: 0 0.602626 0.849965 0.599212 0.828226 0.398031 0.274288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54834 episodes
GETTING ACTION FROM:
action 2, numVisits=54783, meanQ=4.915410, numObservations: 4
action 0, numVisits=46, meanQ=3.919727, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.602626 0.849965 0.599212 0.828226 0.398031 0.274288 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 315
Initial state: 0 0.0185546 0.0335754 0.661749 0.823608 0.662154 0.841455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55557 episodes
GETTING ACTION FROM:
action 2, numVisits=55550, meanQ=4.990938, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.0185546 0.0335754 0.661749 0.823608 0.662154 0.841455 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 316
Initial state: 0 0.676576 0.887424 0.122408 0.964701 0.687782 0.811288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55254 episodes
GETTING ACTION FROM:
action 3, numVisits=55248, meanQ=4.988769, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.676576 0.887424 0.122408 0.964701 0.687782 0.811288 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 317
Initial state: 0 0.591806 0.853472 0.696738 0.866291 0.111957 0.153881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54990 episodes
GETTING ACTION FROM:
action 3, numVisits=54908, meanQ=4.932593, numObservations: 4
action 0, numVisits=77, meanQ=4.182229, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.591806 0.853472 0.696738 0.866291 0.111957 0.153881 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8943, meanQ=8.272122, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11077 episodes
GETTING ACTION FROM:
action 2, numVisits=12096, meanQ=7.680657, numObservations: 4
action 1, numVisits=45, meanQ=4.642222, numObservations: 4
action -1, numVisits=7867, meanQ=-0.019375, numObservations: 1
action 0, numVisits=16, meanQ=-2.063112, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.591806 0.853472 0.696738 0.866291 0.111957 0.153881 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 318
Initial state: 0 0.391296 0.480119 0.645869 0.817164 0.647838 0.89487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54747 episodes
GETTING ACTION FROM:
action 3, numVisits=54738, meanQ=4.956624, numObservations: 5
action 2, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.391296 0.480119 0.645869 0.817164 0.647838 0.89487 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 319
Initial state: 0 0.271375 0.123556 0.593546 0.876283 0.662944 0.83683 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32699 episodes
GETTING ACTION FROM:
action 0, numVisits=32694, meanQ=2.985621, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.271375 0.123556 0.593546 0.876283 0.662944 0.83683 w: 1
Observation: 0 0 0.0371637 0 0.907026 0 0.836121 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32687, meanQ=5.041929, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55153 episodes
GETTING ACTION FROM:
action 1, numVisits=87831, meanQ=5.092475, numObservations: 3
action 3, numVisits=10, meanQ=1.099010, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.271375 0.123556 0.593546 0.876283 0.662944 0.83683 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=15066, meanQ=8.317680, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 13374 episodes
GETTING ACTION FROM:
action 2, numVisits=25979, meanQ=7.425412, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2456, meanQ=0.350029, numObservations: 1
action 0, numVisits=3, meanQ=-5.300000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 0 0.271375 0.123556 0.593546 0.876283 0.662944 0.83683 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=1181, meanQ=8.298046, numObservations: 3
action 0, numVisits=170, meanQ=6.863412, numObservations: 1
action 2, numVisits=13, meanQ=6.238462, numObservations: 3
action -1, numVisits=67, meanQ=3.677666, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 18676 episodes
GETTING ACTION FROM:
action 3, numVisits=13438, meanQ=6.338528, numObservations: 4
action 2, numVisits=13, meanQ=6.238462, numObservations: 3
action 0, numVisits=5686, meanQ=-1.261766, numObservations: 1
action -1, numVisits=970, meanQ=-1.383329, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.271375 0.123556 0.593546 0.876283 0.662944 0.83683 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -1.14771
Run # 320
Initial state: 0 0.608885 0.879218 0.67339 0.84974 0.831561 0.982932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55692 episodes
GETTING ACTION FROM:
action 2, numVisits=53588, meanQ=5.003283, numObservations: 3
action 1, numVisits=2099, meanQ=4.781148, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.608885 0.879218 0.67339 0.84974 0.831561 0.982932 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 321
Initial state: 0 0.999997 0.209605 0.514415 0.810509 0.640927 0.838977 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55456 episodes
GETTING ACTION FROM:
action 3, numVisits=55431, meanQ=4.981598, numObservations: 5
action -1, numVisits=16, meanQ=3.296425, numObservations: 1
action 1, numVisits=6, meanQ=1.498333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.999997 0.209605 0.514415 0.810509 0.640927 0.838977 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 322
Initial state: 0 0.516846 0.843681 0.175993 0.0903751 0.63721 0.815533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32582 episodes
GETTING ACTION FROM:
action -1, numVisits=32572, meanQ=2.840200, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=4, meanQ=-4.002500, numObservations: 3
action 2, numVisits=3, meanQ=-4.333333, numObservations: 1
action: -1
Next state: 0 0.516846 0.843681 0.175993 0.0903751 0.63721 0.815533 w: 1
Observation: 0 0.422667 0 0.27132 0 0.562504 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32465, meanQ=4.968024, numObservations: 4
action 1, numVisits=99, meanQ=3.921522, numObservations: 5
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 54627 episodes
GETTING ACTION FROM:
action 3, numVisits=87089, meanQ=5.045257, numObservations: 4
action 1, numVisits=99, meanQ=3.921522, numObservations: 5
action 2, numVisits=5, meanQ=1.198020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=3, meanQ=-2.333300, numObservations: 2
action: 3
Next state: 1 0.516846 0.843681 0.175993 0.0903751 0.63721 0.815533 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 323
Initial state: 0 0.542373 0.80878 0.265449 0.133979 0.565676 0.899163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54565 episodes
GETTING ACTION FROM:
action 1, numVisits=54490, meanQ=5.004622, numObservations: 4
action -1, numVisits=35, meanQ=3.856254, numObservations: 1
action 0, numVisits=31, meanQ=3.713488, numObservations: 1
action 3, numVisits=8, meanQ=0.873750, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.542373 0.80878 0.265449 0.133979 0.565676 0.899163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 324
Initial state: 0 0.0510204 0.237534 0.67969 0.858116 0.664119 0.860207 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54878 episodes
GETTING ACTION FROM:
action 1, numVisits=54761, meanQ=4.942711, numObservations: 3
action -1, numVisits=59, meanQ=4.081986, numObservations: 1
action 2, numVisits=37, meanQ=3.614597, numObservations: 3
action 3, numVisits=19, meanQ=3.305800, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0510204 0.237534 0.67969 0.858116 0.664119 0.860207 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7843, meanQ=8.299183, numObservations: 4
action 3, numVisits=1222, meanQ=8.184467, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8516 episodes
GETTING ACTION FROM:
action 2, numVisits=11850, meanQ=7.563356, numObservations: 4
action 3, numVisits=2648, meanQ=6.852279, numObservations: 3
action 1, numVisits=2, meanQ=0.950000, numObservations: 1
action 0, numVisits=3077, meanQ=0.273429, numObservations: 1
action -1, numVisits=7, meanQ=-2.001414, numObservations: 1
action: 2
Next state: 1 0.0510204 0.237534 0.67969 0.858116 0.664119 0.860207 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 325
Initial state: 0 0.121437 0.111842 0.592323 0.859719 0.611341 0.84502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55041 episodes
GETTING ACTION FROM:
action 1, numVisits=55031, meanQ=5.014326, numObservations: 3
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.121437 0.111842 0.592323 0.859719 0.611341 0.84502 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 326
Initial state: 0 0.658005 0.851662 0.198387 0.664041 0.554516 0.826971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34453 episodes
GETTING ACTION FROM:
action 0, numVisits=34338, meanQ=5.502581, numObservations: 3
action -1, numVisits=38, meanQ=2.356991, numObservations: 1
action 3, numVisits=36, meanQ=2.181394, numObservations: 3
action 1, numVisits=37, meanQ=2.071089, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action: 0
Next state: 0 0.658005 0.851662 0.198387 0.664041 0.554516 0.826971 w: 1
Observation: 0 0 0.832514 0 0.746835 0 0.893657 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10193, meanQ=8.140512, numObservations: 4
action 2, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55860 episodes
GETTING ACTION FROM:
action 1, numVisits=66049, meanQ=5.352156, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.658005 0.851662 0.198387 0.664041 0.554516 0.826971 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 327
Initial state: 0 0.125051 0.612162 0.609645 0.820195 0.555137 0.829079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55346 episodes
GETTING ACTION FROM:
action 3, numVisits=55071, meanQ=5.031332, numObservations: 4
action -1, numVisits=271, meanQ=2.960825, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.125051 0.612162 0.609645 0.820195 0.555137 0.829079 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 328
Initial state: 0 0.521108 0.848789 0.292389 0.754184 0.648405 0.874366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55884 episodes
GETTING ACTION FROM:
action 1, numVisits=55872, meanQ=5.014250, numObservations: 4
action 2, numVisits=7, meanQ=2.285729, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.521108 0.848789 0.292389 0.754184 0.648405 0.874366 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 329
Initial state: 0 0.690086 0.819866 0.918922 0.712601 0.681116 0.828133 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55091 episodes
GETTING ACTION FROM:
action 2, numVisits=54175, meanQ=5.066733, numObservations: 4
action 0, numVisits=813, meanQ=2.510510, numObservations: 1
action -1, numVisits=97, meanQ=2.161812, numObservations: 1
action 3, numVisits=5, meanQ=-0.002000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.690086 0.819866 0.918922 0.712601 0.681116 0.828133 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 330
Initial state: 0 0.526183 0.879682 0.516999 0.816988 0.809522 0.504039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55050 episodes
GETTING ACTION FROM:
action 1, numVisits=54886, meanQ=4.961237, numObservations: 3
action -1, numVisits=157, meanQ=4.455191, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.526183 0.879682 0.516999 0.816988 0.809522 0.504039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 331
Initial state: 0 0.0154507 0.307584 0.565313 0.885245 0.681812 0.837507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55423 episodes
GETTING ACTION FROM:
action 2, numVisits=55362, meanQ=5.004795, numObservations: 5
action -1, numVisits=57, meanQ=4.120296, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0154507 0.307584 0.565313 0.885245 0.681812 0.837507 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 332
Initial state: 0 0.233638 0.553275 0.627689 0.87364 0.683983 0.803163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54172 episodes
GETTING ACTION FROM:
action 3, numVisits=54164, meanQ=4.932924, numObservations: 5
action 2, numVisits=3, meanQ=0.663333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.233638 0.553275 0.627689 0.87364 0.683983 0.803163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 333
Initial state: 0 0.421389 0.239858 0.672029 0.839996 0.672533 0.886281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55785 episodes
GETTING ACTION FROM:
action 2, numVisits=55710, meanQ=5.009326, numObservations: 3
action 3, numVisits=70, meanQ=4.188290, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.421389 0.239858 0.672029 0.839996 0.672533 0.886281 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 334
Initial state: 0 0.0414545 0.981858 0.578443 0.813854 0.532144 0.874375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32445 episodes
GETTING ACTION FROM:
action 0, numVisits=32440, meanQ=2.935978, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0414545 0.981858 0.578443 0.813854 0.532144 0.874375 w: 1
Observation: 0 0 0.974306 0 0.890176 0 0.894167 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32432, meanQ=4.970951, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55624 episodes
GETTING ACTION FROM:
action 2, numVisits=88052, meanQ=4.927487, numObservations: 4
action 1, numVisits=5, meanQ=1.820000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.0414545 0.981858 0.578443 0.813854 0.532144 0.874375 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 335
Initial state: 0 0.238066 0.363961 0.605542 0.883113 0.501852 0.872988 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31829 episodes
GETTING ACTION FROM:
action 0, numVisits=31809, meanQ=2.949231, numObservations: 1
action 2, numVisits=11, meanQ=0.730027, numObservations: 2
action 3, numVisits=6, meanQ=-0.999983, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.238066 0.363961 0.605542 0.883113 0.501852 0.872988 w: 1
Observation: 0 0 0.417933 0 0.824443 0 0.947398 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31792, meanQ=4.965537, numObservations: 4
action 2, numVisits=11, meanQ=2.452745, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 53080 episodes
GETTING ACTION FROM:
action 3, numVisits=84864, meanQ=4.874430, numObservations: 4
action 2, numVisits=14, meanQ=1.498586, numObservations: 3
action 1, numVisits=6, meanQ=1.001683, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.238066 0.363961 0.605542 0.883113 0.501852 0.872988 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 336
Initial state: 0 0.543647 0.826922 0.570249 0.608561 0.534297 0.856362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55414 episodes
GETTING ACTION FROM:
action 1, numVisits=55399, meanQ=5.000362, numObservations: 5
action 3, numVisits=10, meanQ=2.889000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.543647 0.826922 0.570249 0.608561 0.534297 0.856362 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 337
Initial state: 0 0.696134 0.896257 0.813662 0.255467 0.552964 0.872832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54467 episodes
GETTING ACTION FROM:
action 3, numVisits=53818, meanQ=4.926543, numObservations: 5
action 0, numVisits=643, meanQ=2.738334, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.696134 0.896257 0.813662 0.255467 0.552964 0.872832 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 338
Initial state: 0 0.68443 0.837965 0.726123 0.601551 0.565511 0.870647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55428 episodes
GETTING ACTION FROM:
action 3, numVisits=55389, meanQ=5.019275, numObservations: 3
action 1, numVisits=25, meanQ=2.399208, numObservations: 4
action 2, numVisits=10, meanQ=1.799000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.68443 0.837965 0.726123 0.601551 0.565511 0.870647 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 339
Initial state: 0 0.513103 0.897095 0.408603 0.40831 0.682515 0.822811 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55051 episodes
GETTING ACTION FROM:
action 3, numVisits=55021, meanQ=5.003018, numObservations: 5
action 0, numVisits=13, meanQ=3.125142, numObservations: 1
action 2, numVisits=11, meanQ=2.362745, numObservations: 3
action 1, numVisits=4, meanQ=-0.222500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.513103 0.897095 0.408603 0.40831 0.682515 0.822811 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7707, meanQ=8.401439, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12435 episodes
GETTING ACTION FROM:
action 1, numVisits=15662, meanQ=7.117771, numObservations: 4
action 2, numVisits=31, meanQ=5.386774, numObservations: 4
action -1, numVisits=4422, meanQ=0.306861, numObservations: 1
action 0, numVisits=30, meanQ=-1.109330, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.513103 0.897095 0.408603 0.40831 0.682515 0.822811 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 340
Initial state: 0 0.828029 0.567897 0.560652 0.881843 0.65308 0.869196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55601 episodes
GETTING ACTION FROM:
action 1, numVisits=55544, meanQ=4.953613, numObservations: 3
action -1, numVisits=47, meanQ=3.959952, numObservations: 1
action 2, numVisits=7, meanQ=2.428571, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.828029 0.567897 0.560652 0.881843 0.65308 0.869196 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 341
Initial state: 0 0.195811 0.184807 0.536018 0.801413 0.664313 0.862483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55051 episodes
GETTING ACTION FROM:
action 2, numVisits=54985, meanQ=4.996561, numObservations: 5
action 0, numVisits=56, meanQ=3.978005, numObservations: 1
action 3, numVisits=6, meanQ=1.498333, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.195811 0.184807 0.536018 0.801413 0.664313 0.862483 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 342
Initial state: 0 0.0527555 0.0867459 0.628101 0.8365 0.670546 0.818075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55314 episodes
GETTING ACTION FROM:
action 2, numVisits=55308, meanQ=4.928868, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0527555 0.0867459 0.628101 0.8365 0.670546 0.818075 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 343
Initial state: 0 0.546132 0.860352 0.594503 0.81662 0.454922 0.823931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52180 episodes
GETTING ACTION FROM:
action 3, numVisits=51213, meanQ=4.841636, numObservations: 5
action 0, numVisits=425, meanQ=3.105303, numObservations: 1
action -1, numVisits=533, meanQ=3.100124, numObservations: 1
action 1, numVisits=8, meanQ=0.625012, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.546132 0.860352 0.594503 0.81662 0.454922 0.823931 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1234, meanQ=7.901265, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8138 episodes
GETTING ACTION FROM:
action 2, numVisits=7017, meanQ=6.175706, numObservations: 4
action 0, numVisits=2337, meanQ=0.177407, numObservations: 1
action -1, numVisits=18, meanQ=-1.505550, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.546132 0.860352 0.594503 0.81662 0.454922 0.823931 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=172, meanQ=7.320493, numObservations: 5
action 2, numVisits=19, meanQ=6.454211, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 19787 episodes
GETTING ACTION FROM:
action 1, numVisits=9846, meanQ=6.011181, numObservations: 5
action 2, numVisits=91, meanQ=5.688242, numObservations: 4
action 0, numVisits=6583, meanQ=-1.612904, numObservations: 1
action -1, numVisits=3462, meanQ=-1.631970, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.546132 0.860352 0.594503 0.81662 0.454922 0.823931 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 344
Initial state: 0 0.570844 0.865747 0.970382 0.426482 0.671769 0.870237 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55296 episodes
GETTING ACTION FROM:
action 3, numVisits=54715, meanQ=5.025114, numObservations: 5
action -1, numVisits=574, meanQ=3.036402, numObservations: 1
action 2, numVisits=4, meanQ=-0.502500, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.570844 0.865747 0.970382 0.426482 0.671769 0.870237 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 345
Initial state: 0 0.732258 0.982581 0.672084 0.828312 0.642257 0.833963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55032 episodes
GETTING ACTION FROM:
action 3, numVisits=54935, meanQ=4.897175, numObservations: 5
action 0, numVisits=93, meanQ=4.226751, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.732258 0.982581 0.672084 0.828312 0.642257 0.833963 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 346
Initial state: 0 0.61127 0.823653 0.784052 0.474299 0.69513 0.860554 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55495 episodes
GETTING ACTION FROM:
action 3, numVisits=55487, meanQ=5.006773, numObservations: 5
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.61127 0.823653 0.784052 0.474299 0.69513 0.860554 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 347
Initial state: 0 0.391051 0.148448 0.622425 0.873852 0.672018 0.811889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53258 episodes
GETTING ACTION FROM:
action 2, numVisits=53190, meanQ=5.059658, numObservations: 5
action 3, numVisits=49, meanQ=3.961024, numObservations: 5
action 0, numVisits=16, meanQ=3.407834, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.391051 0.148448 0.622425 0.873852 0.672018 0.811889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 348
Initial state: 0 0.449135 0.740413 0.694249 0.829859 0.605064 0.826383 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55569 episodes
GETTING ACTION FROM:
action 3, numVisits=55415, meanQ=5.041970, numObservations: 3
action -1, numVisits=139, meanQ=4.497851, numObservations: 1
action 2, numVisits=12, meanQ=2.916667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.449135 0.740413 0.694249 0.829859 0.605064 0.826383 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 349
Initial state: 0 0.633986 0.834579 0.608905 0.838691 0.193074 0.202704 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52374 episodes
GETTING ACTION FROM:
action 1, numVisits=52342, meanQ=4.750996, numObservations: 5
action 2, numVisits=20, meanQ=2.783005, numObservations: 4
action 3, numVisits=8, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.633986 0.834579 0.608905 0.838691 0.193074 0.202704 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 350
Initial state: 0 0.936134 0.0839687 0.558484 0.886165 0.692835 0.816998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54691 episodes
GETTING ACTION FROM:
action 2, numVisits=54675, meanQ=4.947616, numObservations: 3
action 1, numVisits=7, meanQ=2.014286, numObservations: 2
action 3, numVisits=5, meanQ=1.582000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.936134 0.0839687 0.558484 0.886165 0.692835 0.816998 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 351
Initial state: 0 0.767329 0.590826 0.533195 0.870243 0.505096 0.891888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 38375 episodes
GETTING ACTION FROM:
action 0, numVisits=28102, meanQ=5.893280, numObservations: 3
action 1, numVisits=10231, meanQ=5.006514, numObservations: 4
action -1, numVisits=40, meanQ=4.094468, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.767329 0.590826 0.533195 0.870243 0.505096 0.891888 w: 1
Observation: 0 0 0.50049 0 0.775848 0 0.894983 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8279, meanQ=8.178786, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 56232 episodes
GETTING ACTION FROM:
action 3, numVisits=64509, meanQ=5.547354, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.767329 0.590826 0.533195 0.870243 0.505096 0.891888 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 352
Initial state: 0 0.675978 0.847991 0.213887 0.366114 0.567226 0.848003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55672 episodes
GETTING ACTION FROM:
action 1, numVisits=55609, meanQ=4.968179, numObservations: 3
action 2, numVisits=58, meanQ=3.691383, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.675978 0.847991 0.213887 0.366114 0.567226 0.848003 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 353
Initial state: 0 0.493224 0.957332 0.69158 0.87896 0.500931 0.882566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55389 episodes
GETTING ACTION FROM:
action 3, numVisits=55373, meanQ=5.052481, numObservations: 4
action 0, numVisits=9, meanQ=2.730000, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.493224 0.957332 0.69158 0.87896 0.500931 0.882566 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 354
Initial state: 0 0.681692 0.80791 0.632119 0.859624 0.726739 0.578377 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50943 episodes
GETTING ACTION FROM:
action 2, numVisits=50810, meanQ=4.870494, numObservations: 5
action -1, numVisits=55, meanQ=3.997183, numObservations: 1
action 1, numVisits=50, meanQ=3.882772, numObservations: 3
action 0, numVisits=27, meanQ=3.541653, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.681692 0.80791 0.632119 0.859624 0.726739 0.578377 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 355
Initial state: 0 0.658221 0.838059 0.604405 0.863598 0.160703 0.250401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55142 episodes
GETTING ACTION FROM:
action 3, numVisits=55092, meanQ=5.013053, numObservations: 5
action -1, numVisits=26, meanQ=3.699118, numObservations: 1
action 2, numVisits=21, meanQ=3.285719, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.658221 0.838059 0.604405 0.863598 0.160703 0.250401 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 356
Initial state: 0 0.7669 0.775098 0.612887 0.860615 0.63495 0.818724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55005 episodes
GETTING ACTION FROM:
action 3, numVisits=54988, meanQ=4.933540, numObservations: 3
action -1, numVisits=13, meanQ=2.945367, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.7669 0.775098 0.612887 0.860615 0.63495 0.818724 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 357
Initial state: 0 0.366704 0.900869 0.561263 0.844298 0.608636 0.893137 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55023 episodes
GETTING ACTION FROM:
action 1, numVisits=54970, meanQ=4.965395, numObservations: 4
action 3, numVisits=45, meanQ=3.936896, numObservations: 4
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.366704 0.900869 0.561263 0.844298 0.608636 0.893137 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3975, meanQ=5.512774, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 61306 episodes
GETTING ACTION FROM:
action 1, numVisits=65278, meanQ=5.202345, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.366704 0.900869 0.561263 0.844298 0.608636 0.893137 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1401, meanQ=6.628611, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 70763 episodes
GETTING ACTION FROM:
action 2, numVisits=72163, meanQ=6.453825, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-3.505000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.366704 0.900869 0.561263 0.844298 0.608636 0.893137 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 358
Initial state: 0 0.168605 0.0373438 0.550324 0.824646 0.658138 0.841099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55270 episodes
GETTING ACTION FROM:
action 2, numVisits=55179, meanQ=4.973805, numObservations: 5
action 0, numVisits=79, meanQ=4.136247, numObservations: 1
action 3, numVisits=6, meanQ=1.663333, numObservations: 2
action 1, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.168605 0.0373438 0.550324 0.824646 0.658138 0.841099 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 359
Initial state: 0 0.681487 0.87132 0.219488 0.117385 0.603135 0.835689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55939 episodes
GETTING ACTION FROM:
action 2, numVisits=55822, meanQ=5.204720, numObservations: 5
action 0, numVisits=81, meanQ=4.447409, numObservations: 1
action -1, numVisits=34, meanQ=4.008599, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.681487 0.87132 0.219488 0.117385 0.603135 0.835689 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6232, meanQ=8.491988, numObservations: 3
action 3, numVisits=97, meanQ=7.880003, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 13571 episodes
GETTING ACTION FROM:
action 1, numVisits=14318, meanQ=7.039470, numObservations: 4
action 3, numVisits=1364, meanQ=6.416701, numObservations: 4
action 0, numVisits=4212, meanQ=0.195767, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=8, meanQ=-3.237500, numObservations: 1
action: 1
Next state: 1 0.681487 0.87132 0.219488 0.117385 0.603135 0.835689 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 360
Initial state: 0 0.798411 0.764149 0.632542 0.835645 0.661333 0.804699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55296 episodes
GETTING ACTION FROM:
action 1, numVisits=55270, meanQ=4.916028, numObservations: 4
action 0, numVisits=22, meanQ=3.506750, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.798411 0.764149 0.632542 0.835645 0.661333 0.804699 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 361
Initial state: 0 0.621648 0.884194 0.628915 0.845019 0.685009 0.305129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52958 episodes
GETTING ACTION FROM:
action 3, numVisits=50909, meanQ=5.071769, numObservations: 4
action -1, numVisits=2042, meanQ=1.400356, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 3
Next state: 2 0.621648 0.884194 0.628915 0.845019 0.685009 0.305129 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 362
Initial state: 0 0.853441 0.0032997 0.644941 0.837033 0.633846 0.852528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55184 episodes
GETTING ACTION FROM:
action 3, numVisits=55131, meanQ=4.939657, numObservations: 4
action -1, numVisits=40, meanQ=3.879329, numObservations: 1
action 2, numVisits=8, meanQ=1.500000, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.853441 0.0032997 0.644941 0.837033 0.633846 0.852528 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 363
Initial state: 0 0.514182 0.857705 0.487707 0.972324 0.513482 0.879022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52642 episodes
GETTING ACTION FROM:
action 3, numVisits=52635, meanQ=4.989085, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.514182 0.857705 0.487707 0.972324 0.513482 0.879022 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 364
Initial state: 0 0.10871 0.741343 0.65504 0.809521 0.649179 0.843455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32718 episodes
GETTING ACTION FROM:
action 0, numVisits=32711, meanQ=3.085379, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.10871 0.741343 0.65504 0.809521 0.649179 0.843455 w: 1
Observation: 0 0 0.715858 0 0.814862 0 0.866384 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32617, meanQ=5.175915, numObservations: 5
action 1, numVisits=80, meanQ=3.642005, numObservations: 5
action 3, numVisits=9, meanQ=2.553344, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 56163 episodes
GETTING ACTION FROM:
action 2, numVisits=88779, meanQ=4.909036, numObservations: 5
action 1, numVisits=80, meanQ=3.642005, numObservations: 5
action 3, numVisits=10, meanQ=1.798020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.10871 0.741343 0.65504 0.809521 0.649179 0.843455 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 365
Initial state: 0 0.58877 0.82569 0.402327 0.463665 0.561142 0.868676 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34623 episodes
GETTING ACTION FROM:
action 0, numVisits=34598, meanQ=5.898873, numObservations: 3
action 1, numVisits=17, meanQ=1.641776, numObservations: 3
action 2, numVisits=4, meanQ=0.750000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.58877 0.82569 0.402327 0.463665 0.561142 0.868676 w: 1
Observation: 0 0 0.852178 0 0.377527 0 0.881119 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11091, meanQ=8.186635, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55736 episodes
GETTING ACTION FROM:
action 3, numVisits=66825, meanQ=5.488062, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.58877 0.82569 0.402327 0.463665 0.561142 0.868676 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 366
Initial state: 0 0.68283 0.885769 0.644188 0.808767 0.0411364 0.82287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55496 episodes
GETTING ACTION FROM:
action 3, numVisits=55472, meanQ=5.011159, numObservations: 3
action 0, numVisits=16, meanQ=3.202274, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.68283 0.885769 0.644188 0.808767 0.0411364 0.82287 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9150, meanQ=8.320634, numObservations: 5
action 2, numVisits=32, meanQ=7.308753, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 14159 episodes
GETTING ACTION FROM:
action 1, numVisits=18997, meanQ=7.205867, numObservations: 5
action 2, numVisits=95, meanQ=5.731791, numObservations: 4
action 0, numVisits=4148, meanQ=0.270217, numObservations: 1
action -1, numVisits=102, meanQ=-0.309597, numObservations: 1
action 3, numVisits=2, meanQ=-3.505000, numObservations: 2
action: 1
Next state: 1 0.68283 0.885769 0.644188 0.808767 0.0411364 0.82287 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 367
Initial state: 0 0.272593 0.657503 0.524874 0.883156 0.511673 0.864286 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32717 episodes
GETTING ACTION FROM:
action 0, numVisits=32707, meanQ=3.021406, numObservations: 1
action 1, numVisits=6, meanQ=0.166667, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.272593 0.657503 0.524874 0.883156 0.511673 0.864286 w: 1
Observation: 0 0 0.748811 0 0.845347 0 0.808727 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32699, meanQ=5.020148, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55240 episodes
GETTING ACTION FROM:
action 3, numVisits=55241, meanQ=5.064210, numObservations: 5
action 2, numVisits=32699, meanQ=5.020148, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.272593 0.657503 0.524874 0.883156 0.511673 0.864286 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 368
Initial state: 0 0.66452 0.879511 0.622849 0.859412 0.738224 0.837394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55365 episodes
GETTING ACTION FROM:
action 3, numVisits=55340, meanQ=5.113639, numObservations: 4
action 2, numVisits=14, meanQ=1.644300, numObservations: 3
action 1, numVisits=7, meanQ=1.285743, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.66452 0.879511 0.622849 0.859412 0.738224 0.837394 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 369
Initial state: 0 0.537341 0.864896 0.664776 0.820027 0.315311 0.54744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 39448 episodes
GETTING ACTION FROM:
action 1, numVisits=16663, meanQ=4.968275, numObservations: 4
action 0, numVisits=21925, meanQ=2.957888, numObservations: 1
action -1, numVisits=843, meanQ=2.782445, numObservations: 1
action 3, numVisits=16, meanQ=0.686888, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.537341 0.864896 0.664776 0.820027 0.315311 0.54744 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 370
Initial state: 0 0.959797 0.488265 0.671164 0.847442 0.649878 0.865634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55592 episodes
GETTING ACTION FROM:
action 3, numVisits=55586, meanQ=5.056522, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.959797 0.488265 0.671164 0.847442 0.649878 0.865634 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 371
Initial state: 0 0.688664 0.898571 0.745564 0.7198 0.679194 0.868662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32861 episodes
GETTING ACTION FROM:
action -1, numVisits=32255, meanQ=3.129516, numObservations: 1
action 0, numVisits=596, meanQ=2.901204, numObservations: 1
action 2, numVisits=6, meanQ=0.166667, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.688664 0.898571 0.745564 0.7198 0.679194 0.868662 w: 1
Observation: 0 0.696136 0 0.763075 0 0.649599 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32130, meanQ=5.161996, numObservations: 5
action 0, numVisits=78, meanQ=4.446167, numObservations: 1
action -1, numVisits=30, meanQ=3.971680, numObservations: 1
action 1, numVisits=13, meanQ=3.151538, numObservations: 3
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
Sampled 55519 episodes
GETTING ACTION FROM:
action 3, numVisits=87648, meanQ=5.184895, numObservations: 5
action 0, numVisits=79, meanQ=4.421719, numObservations: 1
action -1, numVisits=30, meanQ=3.971680, numObservations: 1
action 1, numVisits=13, meanQ=3.151538, numObservations: 3
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action: 3
Next state: 1 0.688664 0.898571 0.745564 0.7198 0.679194 0.868662 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 372
Initial state: 0 0.66212 0.861237 0.353697 0.800846 0.534283 0.878745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55155 episodes
GETTING ACTION FROM:
action 3, numVisits=55053, meanQ=5.057907, numObservations: 5
action -1, numVisits=60, meanQ=4.187772, numObservations: 1
action 0, numVisits=32, meanQ=3.865290, numObservations: 1
action 2, numVisits=8, meanQ=2.375000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 1 0.66212 0.861237 0.353697 0.800846 0.534283 0.878745 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 373
Initial state: 0 0.535595 0.84558 0.611766 0.876983 0.972731 0.520856 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55106 episodes
GETTING ACTION FROM:
action 1, numVisits=55064, meanQ=4.891652, numObservations: 5
action -1, numVisits=38, meanQ=3.784385, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.535595 0.84558 0.611766 0.876983 0.972731 0.520856 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 374
Initial state: 0 0.572684 0.805406 0.63515 0.811115 0.0403653 0.302021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55550 episodes
GETTING ACTION FROM:
action 1, numVisits=55508, meanQ=5.143498, numObservations: 4
action -1, numVisits=38, meanQ=4.059716, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.572684 0.805406 0.63515 0.811115 0.0403653 0.302021 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 375
Initial state: 0 0.52801 0.893017 0.630877 0.892302 0.910567 0.420838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55405 episodes
GETTING ACTION FROM:
action 1, numVisits=55385, meanQ=5.000786, numObservations: 4
action 2, numVisits=15, meanQ=2.667347, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.52801 0.893017 0.630877 0.892302 0.910567 0.420838 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4183, meanQ=5.389943, numObservations: 4
action 2, numVisits=8, meanQ=2.498750, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
Sampled 67694 episodes
GETTING ACTION FROM:
action 2, numVisits=57430, meanQ=6.073487, numObservations: 5
action 1, numVisits=14453, meanQ=5.166919, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 2
Next state: 1 0.52801 0.893017 0.630877 0.892302 0.910567 0.420838 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 376
Initial state: 0 0.679012 0.838466 0.291224 0.514991 0.575148 0.803206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54836 episodes
GETTING ACTION FROM:
action 1, numVisits=54830, meanQ=4.930995, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.679012 0.838466 0.291224 0.514991 0.575148 0.803206 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 377
Initial state: 0 0.685341 0.81661 0.656796 0.860619 0.0350193 0.151119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32863 episodes
GETTING ACTION FROM:
action -1, numVisits=32856, meanQ=2.968402, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.685341 0.81661 0.656796 0.860619 0.0350193 0.151119 w: 1
Observation: 0 0.636514 0 0.583406 0 0.0561156 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32634, meanQ=5.032593, numObservations: 3
action -1, numVisits=85, meanQ=4.333775, numObservations: 1
action 1, numVisits=77, meanQ=4.224157, numObservations: 3
action 2, numVisits=57, meanQ=3.969828, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 55724 episodes
GETTING ACTION FROM:
action 3, numVisits=88278, meanQ=4.927793, numObservations: 3
action 1, numVisits=147, meanQ=4.341119, numObservations: 4
action -1, numVisits=95, meanQ=4.245394, numObservations: 1
action 2, numVisits=57, meanQ=3.969828, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.685341 0.81661 0.656796 0.860619 0.0350193 0.151119 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=11657, meanQ=8.315813, numObservations: 5
action 2, numVisits=2720, meanQ=8.312101, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9660 episodes
GETTING ACTION FROM:
action 1, numVisits=16447, meanQ=7.515900, numObservations: 5
action 2, numVisits=5251, meanQ=7.219579, numObservations: 3
action -1, numVisits=2339, meanQ=0.175545, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-4.678420, numObservations: 1
action: 1
Next state: 1 0.685341 0.81661 0.656796 0.860619 0.0350193 0.151119 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 378
Initial state: 0 0.652679 0.878712 0.5227 0.827906 0.973414 0.543205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52984 episodes
GETTING ACTION FROM:
action 1, numVisits=52944, meanQ=5.048536, numObservations: 4
action 2, numVisits=35, meanQ=1.453451, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.652679 0.878712 0.5227 0.827906 0.973414 0.543205 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=3384, meanQ=5.097609, numObservations: 1
action 2, numVisits=341, meanQ=3.541397, numObservations: 5
action 3, numVisits=6, meanQ=0.981667, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8213 episodes
GETTING ACTION FROM:
action 2, numVisits=341, meanQ=3.541397, numObservations: 5
action -1, numVisits=11594, meanQ=1.276864, numObservations: 1
action 3, numVisits=6, meanQ=0.981667, numObservations: 3
action 0, numVisits=4, meanQ=-1.752500, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.652679 0.878712 0.5227 0.827906 0.973414 0.543205 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 379
Initial state: 0 0.957413 0.75866 0.608886 0.822999 0.660386 0.846508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55102 episodes
GETTING ACTION FROM:
action 2, numVisits=55064, meanQ=4.948973, numObservations: 5
action 0, numVisits=33, meanQ=3.794611, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.957413 0.75866 0.608886 0.822999 0.660386 0.846508 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4009, meanQ=4.720817, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 68366 episodes
GETTING ACTION FROM:
action 3, numVisits=72348, meanQ=5.908590, numObservations: 4
action 2, numVisits=20, meanQ=2.000005, numObservations: 5
action 1, numVisits=7, meanQ=0.428571, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 3
Next state: 1 0.957413 0.75866 0.608886 0.822999 0.660386 0.846508 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 380
Initial state: 0 0.206264 0.889555 0.677914 0.818962 0.583942 0.840086 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55445 episodes
GETTING ACTION FROM:
action 1, numVisits=55393, meanQ=5.002752, numObservations: 3
action 0, numVisits=30, meanQ=3.807292, numObservations: 1
action 3, numVisits=17, meanQ=3.048241, numObservations: 4
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.206264 0.889555 0.677914 0.818962 0.583942 0.840086 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9147, meanQ=8.305763, numObservations: 3
action 2, numVisits=4, meanQ=2.002525, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11266 episodes
GETTING ACTION FROM:
action 3, numVisits=15770, meanQ=7.349477, numObservations: 3
action 1, numVisits=9, meanQ=6.110011, numObservations: 3
action 2, numVisits=331, meanQ=5.275774, numObservations: 5
action 0, numVisits=4259, meanQ=0.253592, numObservations: 2
action -1, numVisits=51, meanQ=-0.757647, numObservations: 1
action: 3
Next state: 1 0.206264 0.889555 0.677914 0.818962 0.583942 0.840086 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 381
Initial state: 0 0.555341 0.897015 0.696802 0.816003 0.824518 0.422949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55170 episodes
GETTING ACTION FROM:
action 3, numVisits=55071, meanQ=5.096611, numObservations: 5
action -1, numVisits=38, meanQ=4.043353, numObservations: 1
action 1, numVisits=30, meanQ=3.744667, numObservations: 4
action 2, numVisits=29, meanQ=3.590003, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.555341 0.897015 0.696802 0.816003 0.824518 0.422949 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 382
Initial state: 0 0.225198 0.135094 0.511129 0.838844 0.688869 0.872967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55437 episodes
GETTING ACTION FROM:
action 3, numVisits=55357, meanQ=5.017568, numObservations: 5
action -1, numVisits=76, meanQ=4.273429, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.225198 0.135094 0.511129 0.838844 0.688869 0.872967 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 383
Initial state: 0 0.0718901 0.693682 0.505096 0.891334 0.53315 0.82006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32608 episodes
GETTING ACTION FROM:
action -1, numVisits=32599, meanQ=2.980045, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action: -1
Next state: 0 0.0718901 0.693682 0.505096 0.891334 0.53315 0.82006 w: 1
Observation: 0 0.109093 0 0.478324 0 0.436045 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32234, meanQ=4.968817, numObservations: 4
action 3, numVisits=269, meanQ=4.568563, numObservations: 5
action 1, numVisits=77, meanQ=4.257382, numObservations: 3
action 0, numVisits=16, meanQ=3.346009, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 55051 episodes
GETTING ACTION FROM:
action 2, numVisits=87280, meanQ=4.960517, numObservations: 4
action 3, numVisits=269, meanQ=4.568563, numObservations: 5
action 1, numVisits=81, meanQ=4.173209, numObservations: 3
action 0, numVisits=17, meanQ=3.182833, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.0718901 0.693682 0.505096 0.891334 0.53315 0.82006 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 384
Initial state: 0 0.613401 0.800439 0.582462 0.642588 0.514133 0.809078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55491 episodes
GETTING ACTION FROM:
action 2, numVisits=55480, meanQ=5.052889, numObservations: 4
action 1, numVisits=6, meanQ=1.498333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.613401 0.800439 0.582462 0.642588 0.514133 0.809078 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 385
Initial state: 0 0.604381 0.859806 0.375901 0.624795 0.593325 0.824475 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51699 episodes
GETTING ACTION FROM:
action 2, numVisits=46547, meanQ=4.954624, numObservations: 3
action 0, numVisits=5134, meanQ=3.052941, numObservations: 1
action 1, numVisits=10, meanQ=0.900020, numObservations: 3
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.604381 0.859806 0.375901 0.624795 0.593325 0.824475 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 386
Initial state: 0 0.554311 0.887084 0.61491 0.815576 0.0696907 0.183743 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52458 episodes
GETTING ACTION FROM:
action 3, numVisits=52244, meanQ=4.872235, numObservations: 5
action -1, numVisits=134, meanQ=4.319585, numObservations: 1
action 0, numVisits=78, meanQ=4.151733, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.554311 0.887084 0.61491 0.815576 0.0696907 0.183743 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7269, meanQ=8.405272, numObservations: 3
action 1, numVisits=20, meanQ=6.999510, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11016 episodes
GETTING ACTION FROM:
action 2, numVisits=11195, meanQ=7.554867, numObservations: 3
action 1, numVisits=252, meanQ=5.242653, numObservations: 3
action 3, numVisits=2, meanQ=0.950000, numObservations: 1
action 0, numVisits=6856, meanQ=0.384895, numObservations: 1
action -1, numVisits=3, meanQ=-131.487601, numObservations: 1
action: 2
Next state: 1 0.554311 0.887084 0.61491 0.815576 0.0696907 0.183743 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 387
Initial state: 0 0.179693 0.237254 0.616878 0.893007 0.621931 0.862474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32603 episodes
GETTING ACTION FROM:
action 0, numVisits=32596, meanQ=2.948547, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.179693 0.237254 0.616878 0.893007 0.621931 0.862474 w: 1
Observation: 0 0 0.301466 0 0.911571 0 0.765228 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32589, meanQ=4.982924, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 54278 episodes
GETTING ACTION FROM:
action 2, numVisits=86862, meanQ=4.785164, numObservations: 3
action 3, numVisits=6, meanQ=-0.834983, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.179693 0.237254 0.616878 0.893007 0.621931 0.862474 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 388
Initial state: 0 0.609522 0.839336 0.58855 0.839761 0.596959 0.501871 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55157 episodes
GETTING ACTION FROM:
action 1, numVisits=55151, meanQ=5.144778, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.609522 0.839336 0.58855 0.839761 0.596959 0.501871 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 389
Initial state: 0 0.695569 0.853345 0.501567 0.832023 0.498485 0.960955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55285 episodes
GETTING ACTION FROM:
action 1, numVisits=55195, meanQ=4.961929, numObservations: 5
action -1, numVisits=80, meanQ=4.209444, numObservations: 1
action 3, numVisits=7, meanQ=2.428571, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.695569 0.853345 0.501567 0.832023 0.498485 0.960955 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 390
Initial state: 0 0.563287 0.897742 0.66733 0.82295 0.476442 0.706509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54905 episodes
GETTING ACTION FROM:
action 3, numVisits=54898, meanQ=4.889622, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.563287 0.897742 0.66733 0.82295 0.476442 0.706509 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7774, meanQ=8.381340, numObservations: 3
action 1, numVisits=44, meanQ=7.363186, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12688 episodes
GETTING ACTION FROM:
action 2, numVisits=15119, meanQ=7.123591, numObservations: 4
action 1, numVisits=221, meanQ=5.077194, numObservations: 4
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=4994, meanQ=0.253568, numObservations: 1
action -1, numVisits=172, meanQ=-0.184049, numObservations: 1
action: 2
Next state: 1 0.563287 0.897742 0.66733 0.82295 0.476442 0.706509 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 391
Initial state: 0 0.617335 0.819845 0.88495 0.426783 0.534465 0.849985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55484 episodes
GETTING ACTION FROM:
action 3, numVisits=50598, meanQ=5.058400, numObservations: 3
action 2, numVisits=4881, meanQ=4.991148, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.617335 0.819845 0.88495 0.426783 0.534465 0.849985 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 392
Initial state: 0 0.719951 0.371201 0.566466 0.81925 0.561996 0.852079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54871 episodes
GETTING ACTION FROM:
action 1, numVisits=54768, meanQ=5.118947, numObservations: 4
action 0, numVisits=70, meanQ=4.305581, numObservations: 3
action -1, numVisits=21, meanQ=3.695826, numObservations: 1
action 2, numVisits=9, meanQ=1.776667, numObservations: 2
action 3, numVisits=3, meanQ=0.663333, numObservations: 2
action: 1
Next state: 2 0.719951 0.371201 0.566466 0.81925 0.561996 0.852079 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 393
Initial state: 0 0.660998 0.869411 0.971658 0.122694 0.691996 0.872906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53549 episodes
GETTING ACTION FROM:
action 1, numVisits=53407, meanQ=4.884528, numObservations: 4
action 0, numVisits=102, meanQ=4.256379, numObservations: 1
action 2, numVisits=36, meanQ=3.793061, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.660998 0.869411 0.971658 0.122694 0.691996 0.872906 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 394
Initial state: 0 0.559536 0.801222 0.676089 0.888395 0.977428 0.638946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54126 episodes
GETTING ACTION FROM:
action 2, numVisits=54065, meanQ=4.943747, numObservations: 3
action 0, numVisits=57, meanQ=4.075503, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.559536 0.801222 0.676089 0.888395 0.977428 0.638946 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 395
Initial state: 0 0.580322 0.834062 0.749834 0.512424 0.63787 0.838448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54802 episodes
GETTING ACTION FROM:
action 3, numVisits=54731, meanQ=4.935074, numObservations: 5
action 0, numVisits=43, meanQ=3.897364, numObservations: 1
action 1, numVisits=18, meanQ=1.606683, numObservations: 2
action 2, numVisits=8, meanQ=0.873750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.580322 0.834062 0.749834 0.512424 0.63787 0.838448 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 396
Initial state: 0 0.783364 0.262124 0.65692 0.847256 0.658491 0.85419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34588 episodes
GETTING ACTION FROM:
action 0, numVisits=34561, meanQ=5.841682, numObservations: 3
action 2, numVisits=23, meanQ=1.569578, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.783364 0.262124 0.65692 0.847256 0.658491 0.85419 w: 1
Observation: 0 0 0.302019 0 0.876367 0 0.846962 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=14420, meanQ=7.577263, numObservations: 5
action 3, numVisits=7, meanQ=2.711429, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 54901 episodes
GETTING ACTION FROM:
action 2, numVisits=69319, meanQ=5.641084, numObservations: 5
action 3, numVisits=7, meanQ=2.711429, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.783364 0.262124 0.65692 0.847256 0.658491 0.85419 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=5397, meanQ=6.013404, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 59552 episodes
GETTING ACTION FROM:
action 2, numVisits=64947, meanQ=5.612598, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.783364 0.262124 0.65692 0.847256 0.658491 0.85419 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 397
Initial state: 0 0.666592 0.831146 0.825926 0.993975 0.594188 0.834533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55363 episodes
GETTING ACTION FROM:
action 3, numVisits=55329, meanQ=5.002411, numObservations: 5
action 0, numVisits=18, meanQ=3.369460, numObservations: 1
action 2, numVisits=10, meanQ=2.882000, numObservations: 2
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.666592 0.831146 0.825926 0.993975 0.594188 0.834533 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 398
Initial state: 0 0.0675733 0.543393 0.512545 0.801509 0.690487 0.822577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54543 episodes
GETTING ACTION FROM:
action 1, numVisits=54365, meanQ=4.922991, numObservations: 5
action 0, numVisits=172, meanQ=4.164165, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.0675733 0.543393 0.512545 0.801509 0.690487 0.822577 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 399
Initial state: 0 0.63415 0.855322 0.293409 0.57798 0.57433 0.805065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55258 episodes
GETTING ACTION FROM:
action 3, numVisits=55241, meanQ=5.064325, numObservations: 4
action 2, numVisits=11, meanQ=1.271818, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.63415 0.855322 0.293409 0.57798 0.57433 0.805065 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 400
Initial state: 0 0.0819604 0.137403 0.511414 0.816192 0.562219 0.894444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31644 episodes
GETTING ACTION FROM:
action -1, numVisits=31637, meanQ=2.785894, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.0819604 0.137403 0.511414 0.816192 0.562219 0.894444 w: 1
Observation: 0 0.0437142 0 0.472726 0 0.65124 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31628, meanQ=4.820381, numObservations: 5
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 52609 episodes
GETTING ACTION FROM:
action 1, numVisits=84146, meanQ=4.959313, numObservations: 5
action 2, numVisits=91, meanQ=4.130667, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.0819604 0.137403 0.511414 0.816192 0.562219 0.894444 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=12141, meanQ=8.399508, numObservations: 4
action 3, numVisits=19, meanQ=6.998953, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10994 episodes
GETTING ACTION FROM:
action 2, numVisits=12141, meanQ=8.399508, numObservations: 4
action 3, numVisits=243, meanQ=5.709630, numObservations: 5
action 0, numVisits=1146, meanQ=0.109864, numObservations: 2
action -1, numVisits=9626, meanQ=-0.213227, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.0819604 0.137403 0.511414 0.816192 0.562219 0.894444 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=116, meanQ=8.184140, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8291 episodes
GETTING ACTION FROM:
action 3, numVisits=384, meanQ=6.961407, numObservations: 5
action -1, numVisits=7478, meanQ=-1.692596, numObservations: 1
action 0, numVisits=547, meanQ=-1.884168, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0819604 0.137403 0.511414 0.816192 0.562219 0.894444 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -1.14771
Run # 401
Initial state: 0 0.829777 0.755514 0.511461 0.874284 0.591417 0.885324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55344 episodes
GETTING ACTION FROM:
action 1, numVisits=55238, meanQ=4.956002, numObservations: 3
action -1, numVisits=68, meanQ=4.149538, numObservations: 1
action 0, numVisits=31, meanQ=3.783854, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action: 1
Next state: 2 0.829777 0.755514 0.511461 0.874284 0.591417 0.885324 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 402
Initial state: 0 0.704113 0.513156 0.537948 0.878723 0.60366 0.827718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32553 episodes
GETTING ACTION FROM:
action -1, numVisits=32539, meanQ=2.941070, numObservations: 1
action 3, numVisits=10, meanQ=0.790000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.704113 0.513156 0.537948 0.878723 0.60366 0.827718 w: 1
Observation: 0 0.609061 0 0.563289 0 0.647214 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32504, meanQ=4.956764, numObservations: 4
action -1, numVisits=27, meanQ=3.688943, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55780 episodes
GETTING ACTION FROM:
action 1, numVisits=88283, meanQ=5.052641, numObservations: 4
action -1, numVisits=28, meanQ=3.636806, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.704113 0.513156 0.537948 0.878723 0.60366 0.827718 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 403
Initial state: 0 0.972471 0.900696 0.555618 0.842385 0.663511 0.801295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32689 episodes
GETTING ACTION FROM:
action -1, numVisits=32669, meanQ=2.898684, numObservations: 1
action 1, numVisits=16, meanQ=0.876269, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.972471 0.900696 0.555618 0.842385 0.663511 0.801295 w: 1
Observation: 0 0.907384 0 0.6314 0 0.734311 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32661, meanQ=4.949748, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55408 episodes
GETTING ACTION FROM:
action 2, numVisits=88061, meanQ=4.805548, numObservations: 4
action 1, numVisits=8, meanQ=1.623763, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action: 2
Next state: 1 0.972471 0.900696 0.555618 0.842385 0.663511 0.801295 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 404
Initial state: 0 0.123365 0.761829 0.577098 0.830048 0.570564 0.81141 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55127 episodes
GETTING ACTION FROM:
action 1, numVisits=55040, meanQ=4.998328, numObservations: 4
action 0, numVisits=46, meanQ=3.868241, numObservations: 1
action -1, numVisits=39, meanQ=3.809489, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.123365 0.761829 0.577098 0.830048 0.570564 0.81141 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9193, meanQ=8.316228, numObservations: 4
action 3, numVisits=24, meanQ=6.822087, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11054 episodes
GETTING ACTION FROM:
action 2, numVisits=17806, meanQ=7.140821, numObservations: 4
action 3, numVisits=137, meanQ=5.301315, numObservations: 3
action -1, numVisits=2311, meanQ=0.295738, numObservations: 1
action 0, numVisits=19, meanQ=-1.741558, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.123365 0.761829 0.577098 0.830048 0.570564 0.81141 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 405
Initial state: 0 0.601881 0.809165 0.17567 0.829088 0.563785 0.841594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 38150 episodes
GETTING ACTION FROM:
action 0, numVisits=29117, meanQ=5.872527, numObservations: 3
action 3, numVisits=9029, meanQ=4.962251, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.601881 0.809165 0.17567 0.829088 0.563785 0.841594 w: 1
Observation: 0 0 0.902452 0 0.915168 0 0.889454 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10050, meanQ=7.952639, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 56751 episodes
GETTING ACTION FROM:
action 2, numVisits=66753, meanQ=5.438767, numObservations: 4
action -1, numVisits=48, meanQ=4.468270, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.601881 0.809165 0.17567 0.829088 0.563785 0.841594 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 406
Initial state: 0 0.504565 0.882313 0.0613493 0.722863 0.516391 0.815511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52761 episodes
GETTING ACTION FROM:
action 3, numVisits=52735, meanQ=4.798077, numObservations: 5
action 2, numVisits=21, meanQ=1.952400, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.504565 0.882313 0.0613493 0.722863 0.516391 0.815511 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=3916, meanQ=3.053208, numObservations: 1
action 2, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 62157 episodes
GETTING ACTION FROM:
action 3, numVisits=61991, meanQ=4.961123, numObservations: 4
action 0, numVisits=4083, meanQ=2.893284, numObservations: 1
action 2, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.504565 0.882313 0.0613493 0.722863 0.516391 0.815511 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 407
Initial state: 0 0.589727 0.842762 0.877754 0.0388837 0.535065 0.859104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32754 episodes
GETTING ACTION FROM:
action -1, numVisits=32738, meanQ=2.948803, numObservations: 1
action 2, numVisits=10, meanQ=-0.108990, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.589727 0.842762 0.877754 0.0388837 0.535065 0.859104 w: 1
Observation: 0 0.686217 0 0.908384 0 0.464944 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32688, meanQ=4.921102, numObservations: 5
action -1, numVisits=44, meanQ=3.966671, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 56643 episodes
GETTING ACTION FROM:
action 3, numVisits=89328, meanQ=4.924713, numObservations: 5
action -1, numVisits=45, meanQ=3.919106, numObservations: 1
action 1, numVisits=3, meanQ=-0.370000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.589727 0.842762 0.877754 0.0388837 0.535065 0.859104 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 408
Initial state: 0 0.599911 0.878975 0.589993 0.810382 0.406474 0.308626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32673 episodes
GETTING ACTION FROM:
action 0, numVisits=32654, meanQ=3.259183, numObservations: 2
action 2, numVisits=15, meanQ=1.326007, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.599911 0.878975 0.589993 0.810382 0.406474 0.308626 w: 1
Observation: 0 0 0.851484 0 0.794654 0 0.21465 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=29119, meanQ=4.627183, numObservations: 4
action -1, numVisits=58, meanQ=3.807309, numObservations: 1
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 55094 episodes
GETTING ACTION FROM:
action 2, numVisits=84212, meanQ=4.823486, numObservations: 4
action -1, numVisits=59, meanQ=3.799509, numObservations: 1
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.599911 0.878975 0.589993 0.810382 0.406474 0.308626 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 409
Initial state: 0 0.76933 0.758647 0.687041 0.836962 0.517391 0.862235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55550 episodes
GETTING ACTION FROM:
action 1, numVisits=55543, meanQ=5.135234, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.76933 0.758647 0.687041 0.836962 0.517391 0.862235 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 410
Initial state: 0 0.512682 0.893653 0.626304 0.950482 0.583606 0.894256 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54885 episodes
GETTING ACTION FROM:
action 3, numVisits=54879, meanQ=4.947320, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.512682 0.893653 0.626304 0.950482 0.583606 0.894256 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 411
Initial state: 0 0.672352 0.895365 0.802639 0.537607 0.508128 0.846382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54985 episodes
GETTING ACTION FROM:
action 3, numVisits=54941, meanQ=4.938431, numObservations: 5
action 1, numVisits=36, meanQ=3.855556, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.672352 0.895365 0.802639 0.537607 0.508128 0.846382 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 412
Initial state: 0 0.63292 0.897248 0.697928 0.848715 0.397006 0.117807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54997 episodes
GETTING ACTION FROM:
action 1, numVisits=54939, meanQ=4.961215, numObservations: 4
action 0, numVisits=49, meanQ=3.995293, numObservations: 1
action 3, numVisits=6, meanQ=2.166700, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.63292 0.897248 0.697928 0.848715 0.397006 0.117807 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 413
Initial state: 0 0.572508 0.807789 0.934361 0.546656 0.601587 0.813861 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55788 episodes
GETTING ACTION FROM:
action 2, numVisits=55722, meanQ=5.204458, numObservations: 5
action -1, numVisits=44, meanQ=4.194185, numObservations: 1
action 3, numVisits=19, meanQ=2.570005, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.572508 0.807789 0.934361 0.546656 0.601587 0.813861 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 414
Initial state: 0 0.531593 0.879795 0.544011 0.867664 0.0524503 0.157549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55828 episodes
GETTING ACTION FROM:
action 2, numVisits=55818, meanQ=5.003291, numObservations: 4
action 1, numVisits=5, meanQ=1.000020, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.531593 0.879795 0.544011 0.867664 0.0524503 0.157549 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3857, meanQ=5.430460, numObservations: 4
action 1, numVisits=119, meanQ=3.616005, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 61249 episodes
GETTING ACTION FROM:
action 2, numVisits=65103, meanQ=5.305841, numObservations: 4
action 1, numVisits=119, meanQ=3.616005, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.531593 0.879795 0.544011 0.867664 0.0524503 0.157549 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 415
Initial state: 0 0.573043 0.891874 0.631228 0.865596 0.671607 0.408958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54791 episodes
GETTING ACTION FROM:
action 1, numVisits=54751, meanQ=4.948020, numObservations: 5
action -1, numVisits=36, meanQ=3.825219, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.573043 0.891874 0.631228 0.865596 0.671607 0.408958 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 416
Initial state: 0 0.54461 0.840728 0.548325 0.8997 0.171355 0.00361029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55160 episodes
GETTING ACTION FROM:
action 1, numVisits=55060, meanQ=4.908295, numObservations: 4
action 0, numVisits=96, meanQ=4.236959, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.54461 0.840728 0.548325 0.8997 0.171355 0.00361029 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 417
Initial state: 0 0.667299 0.877365 0.665893 0.888618 0.773171 0.388625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55681 episodes
GETTING ACTION FROM:
action 2, numVisits=48414, meanQ=5.040270, numObservations: 5
action 3, numVisits=7258, meanQ=4.980720, numObservations: 5
action 1, numVisits=5, meanQ=-0.200000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.667299 0.877365 0.665893 0.888618 0.773171 0.388625 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 418
Initial state: 0 0.902011 0.0990672 0.547088 0.809247 0.523335 0.883745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54855 episodes
GETTING ACTION FROM:
action 3, numVisits=54771, meanQ=4.931674, numObservations: 5
action 0, numVisits=65, meanQ=2.105365, numObservations: 1
action 1, numVisits=16, meanQ=1.561888, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.902011 0.0990672 0.547088 0.809247 0.523335 0.883745 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 419
Initial state: 0 0.581725 0.873849 0.554367 0.885473 0.594667 0.41089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55232 episodes
GETTING ACTION FROM:
action 1, numVisits=55196, meanQ=5.048735, numObservations: 5
action 2, numVisits=20, meanQ=2.396010, numObservations: 4
action 3, numVisits=12, meanQ=1.844175, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.581725 0.873849 0.554367 0.885473 0.594667 0.41089 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 420
Initial state: 0 0.0248318 0.567949 0.50782 0.834791 0.579075 0.831688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55332 episodes
GETTING ACTION FROM:
action 1, numVisits=55290, meanQ=4.929653, numObservations: 3
action 0, numVisits=27, meanQ=3.638175, numObservations: 1
action 2, numVisits=12, meanQ=2.833350, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0248318 0.567949 0.50782 0.834791 0.579075 0.831688 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7009, meanQ=8.354500, numObservations: 5
action 3, numVisits=2157, meanQ=8.291529, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11809 episodes
GETTING ACTION FROM:
action 2, numVisits=12463, meanQ=7.179592, numObservations: 5
action 3, numVisits=4324, meanQ=7.163857, numObservations: 4
action -1, numVisits=4041, meanQ=0.000089, numObservations: 1
action 0, numVisits=149, meanQ=-0.498456, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0248318 0.567949 0.50782 0.834791 0.579075 0.831688 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 421
Initial state: 0 0.468877 0.21625 0.532299 0.84055 0.593731 0.871189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55460 episodes
GETTING ACTION FROM:
action 2, numVisits=55421, meanQ=4.930275, numObservations: 4
action -1, numVisits=26, meanQ=3.622451, numObservations: 1
action 3, numVisits=9, meanQ=1.776667, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.468877 0.21625 0.532299 0.84055 0.593731 0.871189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 422
Initial state: 0 0.653251 0.890954 0.537747 0.864838 0.755231 0.0383032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55168 episodes
GETTING ACTION FROM:
action 2, numVisits=55035, meanQ=4.887360, numObservations: 5
action 0, numVisits=74, meanQ=4.119967, numObservations: 1
action -1, numVisits=56, meanQ=3.990070, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.653251 0.890954 0.537747 0.864838 0.755231 0.0383032 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 423
Initial state: 0 0.653437 0.868725 0.753557 0.589783 0.575489 0.806699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55601 episodes
GETTING ACTION FROM:
action 1, numVisits=55591, meanQ=4.992984, numObservations: 4
action 2, numVisits=5, meanQ=-0.200000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.653437 0.868725 0.753557 0.589783 0.575489 0.806699 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 424
Initial state: 0 0.676565 0.840779 0.0385285 0.501652 0.622203 0.802296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31775 episodes
GETTING ACTION FROM:
action -1, numVisits=31765, meanQ=2.766916, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: -1
Next state: 0 0.676565 0.840779 0.0385285 0.501652 0.622203 0.802296 w: 1
Observation: 0 0.665991 0 0.113101 0 0.523149 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31706, meanQ=4.874903, numObservations: 4
action -1, numVisits=44, meanQ=3.845801, numObservations: 1
action 1, numVisits=10, meanQ=2.399010, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 53475 episodes
GETTING ACTION FROM:
action 3, numVisits=85180, meanQ=4.897744, numObservations: 4
action -1, numVisits=45, meanQ=3.799143, numObservations: 1
action 1, numVisits=10, meanQ=2.399010, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.676565 0.840779 0.0385285 0.501652 0.622203 0.802296 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 425
Initial state: 0 0.567747 0.892302 0.654967 0.868824 0.637194 0.181307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32560 episodes
GETTING ACTION FROM:
action -1, numVisits=32554, meanQ=2.833560, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.567747 0.892302 0.654967 0.868824 0.637194 0.181307 w: 1
Observation: 0 0.505574 0 0.724357 0 0.714047 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32538, meanQ=4.851088, numObservations: 4
action 2, numVisits=8, meanQ=2.498750, numObservations: 4
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 54875 episodes
GETTING ACTION FROM:
action 1, numVisits=87410, meanQ=4.926798, numObservations: 4
action 2, numVisits=10, meanQ=2.399010, numObservations: 4
action 3, numVisits=4, meanQ=-0.752475, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.567747 0.892302 0.654967 0.868824 0.637194 0.181307 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=6294, meanQ=4.647267, numObservations: 4
action 1, numVisits=13, meanQ=0.993085, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67979 episodes
GETTING ACTION FROM:
action 3, numVisits=67980, meanQ=6.265188, numObservations: 4
action 2, numVisits=6294, meanQ=4.647267, numObservations: 4
action 1, numVisits=13, meanQ=0.993085, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.567747 0.892302 0.654967 0.868824 0.637194 0.181307 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=1247, meanQ=8.235408, numObservations: 3
action 2, numVisits=10, meanQ=6.598000, numObservations: 2
action 3, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 25644 episodes
GETTING ACTION FROM:
action 1, numVisits=1482, meanQ=7.928380, numObservations: 3
action 2, numVisits=15039, meanQ=6.117307, numObservations: 5
action 3, numVisits=12, meanQ=4.000000, numObservations: 4
action -1, numVisits=6373, meanQ=-1.638368, numObservations: 1
action 0, numVisits=4000, meanQ=-1.660952, numObservations: 2
action: 1
Next state: 0 0.567747 0.892302 0.654967 0.868824 0.637194 0.181307 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=88, meanQ=8.063867, numObservations: 4
action 1, numVisits=3, meanQ=4.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 20535 episodes
GETTING ACTION FROM:
action 2, numVisits=1243, meanQ=6.351170, numObservations: 4
action 1, numVisits=5, meanQ=2.598000, numObservations: 2
action 0, numVisits=13264, meanQ=-1.752799, numObservations: 1
action -1, numVisits=6116, meanQ=-1.783260, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.567747 0.892302 0.654967 0.868824 0.637194 0.181307 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -5.11623
Run # 426
Initial state: 0 0.825233 0.372073 0.63568 0.852427 0.583788 0.830343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55195 episodes
GETTING ACTION FROM:
action 1, numVisits=55130, meanQ=4.886374, numObservations: 4
action 0, numVisits=59, meanQ=4.041867, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.825233 0.372073 0.63568 0.852427 0.583788 0.830343 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 427
Initial state: 0 0.93923 0.332449 0.640075 0.840603 0.595489 0.897048 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55498 episodes
GETTING ACTION FROM:
action 3, numVisits=55442, meanQ=5.009715, numObservations: 5
action -1, numVisits=52, meanQ=4.106506, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.93923 0.332449 0.640075 0.840603 0.595489 0.897048 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 428
Initial state: 0 0.971492 0.0886704 0.632456 0.83728 0.520355 0.832946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50607 episodes
GETTING ACTION FROM:
action 3, numVisits=47568, meanQ=4.779671, numObservations: 3
action -1, numVisits=3035, meanQ=2.902161, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.971492 0.0886704 0.632456 0.83728 0.520355 0.832946 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 429
Initial state: 0 0.542849 0.819826 0.653384 0.828214 0.968776 0.273924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55153 episodes
GETTING ACTION FROM:
action 2, numVisits=55116, meanQ=4.943231, numObservations: 4
action 3, numVisits=32, meanQ=3.647503, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.542849 0.819826 0.653384 0.828214 0.968776 0.273924 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3974, meanQ=4.850350, numObservations: 3
action 2, numVisits=10, meanQ=2.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67721 episodes
GETTING ACTION FROM:
action 3, numVisits=71687, meanQ=5.796822, numObservations: 3
action 2, numVisits=14, meanQ=1.570000, numObservations: 2
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.542849 0.819826 0.653384 0.828214 0.968776 0.273924 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 430
Initial state: 0 0.674131 0.838987 0.0606738 0.402663 0.694853 0.883925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50265 episodes
GETTING ACTION FROM:
action 3, numVisits=50154, meanQ=4.730631, numObservations: 5
action 1, numVisits=81, meanQ=3.952593, numObservations: 5
action -1, numVisits=24, meanQ=3.320542, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.674131 0.838987 0.0606738 0.402663 0.694853 0.883925 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 431
Initial state: 0 0.620802 0.876314 0.531558 0.834756 0.037365 0.344673 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55589 episodes
GETTING ACTION FROM:
action 2, numVisits=55549, meanQ=5.028227, numObservations: 4
action 0, numVisits=32, meanQ=3.866767, numObservations: 1
action 1, numVisits=4, meanQ=-0.222500, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.620802 0.876314 0.531558 0.834756 0.037365 0.344673 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 432
Initial state: 0 0.277008 0.65915 0.689544 0.876672 0.526895 0.853349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53963 episodes
GETTING ACTION FROM:
action 2, numVisits=53928, meanQ=4.909962, numObservations: 4
action 0, numVisits=26, meanQ=3.621737, numObservations: 1
action 1, numVisits=5, meanQ=1.000020, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.277008 0.65915 0.689544 0.876672 0.526895 0.853349 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 433
Initial state: 0 0.553803 0.837501 0.627687 0.842095 0.353246 0.319935 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54887 episodes
GETTING ACTION FROM:
action 2, numVisits=48700, meanQ=4.971066, numObservations: 4
action 1, numVisits=6094, meanQ=4.911476, numObservations: 4
action 3, numVisits=89, meanQ=4.242729, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.553803 0.837501 0.627687 0.842095 0.353246 0.319935 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=472, meanQ=4.832675, numObservations: 3
action 2, numVisits=28, meanQ=3.415718, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 12582 episodes
GETTING ACTION FROM:
action 1, numVisits=9966, meanQ=5.884853, numObservations: 3
action 2, numVisits=37, meanQ=4.122976, numObservations: 3
action 3, numVisits=45, meanQ=3.545955, numObservations: 4
action 0, numVisits=3037, meanQ=0.250563, numObservations: 1
action -1, numVisits=3, meanQ=-5.300000, numObservations: 1
action: 1
Next state: 0 0.553803 0.837501 0.627687 0.842095 0.353246 0.319935 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=14, meanQ=6.142864, numObservations: 2
action 1, numVisits=12, meanQ=5.331667, numObservations: 2
action -1, numVisits=187, meanQ=4.487253, numObservations: 1
action 3, numVisits=4, meanQ=4.000000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 13309 episodes
GETTING ACTION FROM:
action 3, numVisits=178, meanQ=6.342697, numObservations: 4
action 1, numVisits=19, meanQ=4.577895, numObservations: 3
action 2, numVisits=22, meanQ=4.454550, numObservations: 3
action -1, numVisits=8882, meanQ=-1.567461, numObservations: 1
action 0, numVisits=4426, meanQ=-1.597381, numObservations: 1
action: 3
Next state: 0 0.553803 0.837501 0.627687 0.842095 0.353246 0.319935 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28698 episodes
GETTING ACTION FROM:
action 2, numVisits=1190, meanQ=6.134378, numObservations: 4
action 3, numVisits=55, meanQ=4.636364, numObservations: 4
action 1, numVisits=19, meanQ=3.736842, numObservations: 3
action 0, numVisits=14874, meanQ=-1.893440, numObservations: 1
action -1, numVisits=12560, meanQ=-1.900570, numObservations: 1
action: 2
Next state: 1 0.553803 0.837501 0.627687 0.842095 0.353246 0.319935 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 434
Initial state: 0 0.615786 0.829546 0.992781 0.0444602 0.681233 0.84322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53383 episodes
GETTING ACTION FROM:
action 1, numVisits=49611, meanQ=5.031328, numObservations: 4
action -1, numVisits=3671, meanQ=2.963803, numObservations: 1
action 0, numVisits=91, meanQ=2.445143, numObservations: 1
action 2, numVisits=9, meanQ=0.667800, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.615786 0.829546 0.992781 0.0444602 0.681233 0.84322 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 435
Initial state: 0 0.644261 0.844547 0.503478 0.802835 0.251381 0.738244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55209 episodes
GETTING ACTION FROM:
action 2, numVisits=55199, meanQ=4.950142, numObservations: 5
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.644261 0.844547 0.503478 0.802835 0.251381 0.738244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 436
Initial state: 0 0.240919 0.560529 0.63649 0.809177 0.644153 0.826944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32459 episodes
GETTING ACTION FROM:
action -1, numVisits=18789, meanQ=2.950273, numObservations: 1
action 0, numVisits=13667, meanQ=2.942025, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.240919 0.560529 0.63649 0.809177 0.644153 0.826944 w: 1
Observation: 0 0.311067 0 0.629142 0 0.702193 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=18758, meanQ=5.022689, numObservations: 5
action -1, numVisits=18, meanQ=3.540618, numObservations: 1
action 1, numVisits=6, meanQ=1.331683, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 56240 episodes
GETTING ACTION FROM:
action 3, numVisits=74997, meanQ=4.966739, numObservations: 5
action -1, numVisits=19, meanQ=3.413219, numObservations: 1
action 1, numVisits=6, meanQ=1.331683, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.240919 0.560529 0.63649 0.809177 0.644153 0.826944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 437
Initial state: 0 0.516526 0.874477 0.633834 0.864063 0.906711 0.307983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34247 episodes
GETTING ACTION FROM:
action 0, numVisits=34241, meanQ=5.353643, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.516526 0.874477 0.633834 0.864063 0.906711 0.307983 w: 1
Observation: 0 0 0.870912 0 0.821067 0 0.374316 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9088, meanQ=8.290551, numObservations: 5
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 57289 episodes
GETTING ACTION FROM:
action 1, numVisits=66374, meanQ=5.570807, numObservations: 5
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.516526 0.874477 0.633834 0.864063 0.906711 0.307983 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 438
Initial state: 0 0.549913 0.838666 0.91663 0.112223 0.673137 0.818609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 34489 episodes
GETTING ACTION FROM:
action 0, numVisits=34400, meanQ=5.611570, numObservations: 2
action -1, numVisits=85, meanQ=2.733314, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.549913 0.838666 0.91663 0.112223 0.673137 0.818609 w: 1
Observation: 0 0 0.923009 0 0.12986 0 0.898814 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23768, meanQ=7.602280, numObservations: 4
action 2, numVisits=1465, meanQ=4.424194, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 56296 episodes
GETTING ACTION FROM:
action 3, numVisits=80063, meanQ=6.173632, numObservations: 4
action 2, numVisits=1465, meanQ=4.424194, numObservations: 4
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.549913 0.838666 0.91663 0.112223 0.673137 0.818609 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 439
Initial state: 0 0.812141 0.0226167 0.551995 0.810193 0.515643 0.8398 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55186 episodes
GETTING ACTION FROM:
action 1, numVisits=55112, meanQ=4.892317, numObservations: 5
action -1, numVisits=65, meanQ=4.064800, numObservations: 1
action 2, numVisits=6, meanQ=0.331667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.812141 0.0226167 0.551995 0.810193 0.515643 0.8398 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 440
Initial state: 0 0.510795 0.806625 0.249704 0.175874 0.624889 0.879841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55232 episodes
GETTING ACTION FROM:
action 1, numVisits=55226, meanQ=4.929520, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.510795 0.806625 0.249704 0.175874 0.624889 0.879841 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 441
Initial state: 0 0.511324 0.860386 0.139428 0.0897784 0.656726 0.825798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55010 episodes
GETTING ACTION FROM:
action 3, numVisits=54995, meanQ=5.094724, numObservations: 5
action 2, numVisits=6, meanQ=1.498333, numObservations: 2
action 1, numVisits=5, meanQ=1.000020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.511324 0.860386 0.139428 0.0897784 0.656726 0.825798 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 442
Initial state: 0 0.346964 0.0270674 0.613925 0.835874 0.695722 0.846916 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55474 episodes
GETTING ACTION FROM:
action 1, numVisits=55437, meanQ=4.958456, numObservations: 5
action 0, numVisits=27, meanQ=3.674990, numObservations: 1
action 3, numVisits=7, meanQ=0.428571, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.346964 0.0270674 0.613925 0.835874 0.695722 0.846916 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2331, meanQ=8.534819, numObservations: 3
action 2, numVisits=3965, meanQ=8.475707, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 16157 episodes
GETTING ACTION FROM:
action 2, numVisits=10692, meanQ=6.945517, numObservations: 4
action 3, numVisits=9542, meanQ=6.743574, numObservations: 3
action -1, numVisits=2217, meanQ=-0.349730, numObservations: 1
action 0, numVisits=3, meanQ=-5.300000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 2
Next state: 1 0.346964 0.0270674 0.613925 0.835874 0.695722 0.846916 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 443
Initial state: 0 0.540919 0.888559 0.625776 0.863363 0.435872 0.619747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32601 episodes
GETTING ACTION FROM:
action -1, numVisits=32583, meanQ=2.827736, numObservations: 1
action 2, numVisits=12, meanQ=0.925833, numObservations: 4
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.540919 0.888559 0.625776 0.863363 0.435872 0.619747 w: 1
Observation: 0 0.5447 0 0.646926 0 0.443202 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32522, meanQ=4.904574, numObservations: 5
action -1, numVisits=53, meanQ=4.038310, numObservations: 1
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 55523 episodes
GETTING ACTION FROM:
action 3, numVisits=88044, meanQ=4.932363, numObservations: 5
action -1, numVisits=54, meanQ=4.027220, numObservations: 1
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.540919 0.888559 0.625776 0.863363 0.435872 0.619747 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=11327, meanQ=8.385346, numObservations: 4
action 2, numVisits=802, meanQ=8.221391, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10401 episodes
GETTING ACTION FROM:
action 1, numVisits=18107, meanQ=7.557286, numObservations: 4
action 2, numVisits=2195, meanQ=6.829125, numObservations: 5
action -1, numVisits=2221, meanQ=0.431540, numObservations: 1
action 0, numVisits=9, meanQ=-1.890000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.540919 0.888559 0.625776 0.863363 0.435872 0.619747 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1009, meanQ=8.192708, numObservations: 3
action 1, numVisits=57, meanQ=1.135378, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.952614, numObservations: 1
Sampled 14463 episodes
GETTING ACTION FROM:
action 2, numVisits=6476, meanQ=6.566734, numObservations: 3
action 1, numVisits=57, meanQ=1.135378, numObservations: 3
action -1, numVisits=8998, meanQ=-1.644841, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.952614, numObservations: 1
action: 2
Next state: 0 0.540919 0.888559 0.625776 0.863363 0.435872 0.619747 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=53, meanQ=8.245098, numObservations: 3
action 0, numVisits=27, meanQ=6.616667, numObservations: 1
action 2, numVisits=5, meanQ=6.598000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 64012 episodes
GETTING ACTION FROM:
action 1, numVisits=1377, meanQ=6.242484, numObservations: 5
action 2, numVisits=52, meanQ=4.922885, numObservations: 4
action 3, numVisits=8, meanQ=2.498750, numObservations: 3
action 0, numVisits=34075, meanQ=-1.950551, numObservations: 1
action -1, numVisits=28588, meanQ=-1.954497, numObservations: 1
action: 1
Next state: 1 0.540919 0.888559 0.625776 0.863363 0.435872 0.619747 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -5.11623
Run # 444
Initial state: 0 0.664866 0.841151 0.577244 0.801106 0.667877 0.116376 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52851 episodes
GETTING ACTION FROM:
action 3, numVisits=52674, meanQ=4.862926, numObservations: 4
action 0, numVisits=137, meanQ=2.757216, numObservations: 1
action 2, numVisits=32, meanQ=2.153450, numObservations: 4
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.664866 0.841151 0.577244 0.801106 0.667877 0.116376 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7353, meanQ=8.372845, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8209 episodes
GETTING ACTION FROM:
action 2, numVisits=13947, meanQ=7.300399, numObservations: 4
action 1, numVisits=6, meanQ=0.171250, numObservations: 3
action 0, numVisits=1602, meanQ=-0.132413, numObservations: 1
action -1, numVisits=11, meanQ=-2.000900, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.664866 0.841151 0.577244 0.801106 0.667877 0.116376 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=594, meanQ=8.324318, numObservations: 4
action 0, numVisits=138, meanQ=4.817631, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-193.851198, numObservations: 1
Sampled 13040 episodes
GETTING ACTION FROM:
action 1, numVisits=594, meanQ=8.324318, numObservations: 4
action 2, numVisits=1171, meanQ=5.952425, numObservations: 5
action 0, numVisits=12008, meanQ=-1.634572, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-193.851198, numObservations: 1
action: 1
Next state: 1 0.664866 0.841151 0.577244 0.801106 0.667877 0.116376 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 445
Initial state: 0 0.522302 0.889973 0.876653 0.000141396 0.572539 0.829269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52714 episodes
GETTING ACTION FROM:
action 3, numVisits=52690, meanQ=4.854896, numObservations: 4
action 1, numVisits=19, meanQ=3.053158, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.522302 0.889973 0.876653 0.000141396 0.572539 0.829269 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 446
Initial state: 0 0.70435 0.542452 0.670337 0.834818 0.620937 0.832121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53091 episodes
GETTING ACTION FROM:
action 2, numVisits=53081, meanQ=4.898144, numObservations: 5
action 1, numVisits=5, meanQ=-0.795980, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.70435 0.542452 0.670337 0.834818 0.620937 0.832121 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 447
Initial state: 0 0.967049 0.8278 0.585982 0.875612 0.500138 0.832247 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55132 episodes
GETTING ACTION FROM:
action 3, numVisits=55121, meanQ=5.034721, numObservations: 5
action 2, numVisits=6, meanQ=0.816667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.967049 0.8278 0.585982 0.875612 0.500138 0.832247 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 448
Initial state: 0 0.52197 0.837535 0.404558 0.40844 0.676866 0.840785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32048 episodes
GETTING ACTION FROM:
action 0, numVisits=32031, meanQ=2.965628, numObservations: 3
action 3, numVisits=9, meanQ=0.111111, numObservations: 3
action 1, numVisits=5, meanQ=-0.200000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.52197 0.837535 0.404558 0.40844 0.676866 0.840785 w: 1
Observation: 0 0 0.885193 0 0.458853 0 0.868194 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=658, meanQ=8.246349, numObservations: 4
action 3, numVisits=26, meanQ=6.923085, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 57111 episodes
GETTING ACTION FROM:
action 1, numVisits=57213, meanQ=5.184439, numObservations: 4
action 3, numVisits=537, meanQ=4.920424, numObservations: 5
action -1, numVisits=45, meanQ=4.204830, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.52197 0.837535 0.404558 0.40844 0.676866 0.840785 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 449
Initial state: 0 0.566168 0.886804 0.398051 0.47992 0.524778 0.895979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55163 episodes
GETTING ACTION FROM:
action 3, numVisits=53187, meanQ=4.943897, numObservations: 4
action 2, numVisits=1820, meanQ=4.704876, numObservations: 5
action 1, numVisits=152, meanQ=4.135552, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.566168 0.886804 0.398051 0.47992 0.524778 0.895979 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 450
Initial state: 0 0.501308 0.865135 0.605229 0.895249 0.90547 0.107426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55180 episodes
GETTING ACTION FROM:
action 2, numVisits=55147, meanQ=5.020055, numObservations: 4
action -1, numVisits=27, meanQ=3.708056, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.501308 0.865135 0.605229 0.895249 0.90547 0.107426 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 451
Initial state: 0 0.596383 0.815088 0.63502 0.849498 0.77513 0.0423644 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55301 episodes
GETTING ACTION FROM:
action 2, numVisits=55295, meanQ=4.919640, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.596383 0.815088 0.63502 0.849498 0.77513 0.0423644 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 452
Initial state: 0 0.532677 0.870946 0.136374 0.721875 0.528457 0.884113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55505 episodes
GETTING ACTION FROM:
action 2, numVisits=55384, meanQ=4.980193, numObservations: 4
action -1, numVisits=82, meanQ=4.263710, numObservations: 1
action 0, numVisits=25, meanQ=3.679823, numObservations: 1
action 3, numVisits=13, meanQ=2.770008, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.532677 0.870946 0.136374 0.721875 0.528457 0.884113 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8931, meanQ=8.339681, numObservations: 3
action 1, numVisits=16, meanQ=6.748125, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11826 episodes
GETTING ACTION FROM:
action 3, numVisits=8972, meanQ=8.333242, numObservations: 3
action 1, numVisits=220, meanQ=6.171364, numObservations: 5
action -1, numVisits=10909, meanQ=0.197075, numObservations: 1
action 0, numVisits=672, meanQ=-0.011175, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action: 3
Next state: 1 0.532677 0.870946 0.136374 0.721875 0.528457 0.884113 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 453
Initial state: 0 0.545546 0.835104 0.565699 0.800795 0.895841 0.312142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55059 episodes
GETTING ACTION FROM:
action 3, numVisits=54237, meanQ=4.994326, numObservations: 4
action -1, numVisits=794, meanQ=2.654745, numObservations: 1
action 2, numVisits=24, meanQ=1.538342, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.545546 0.835104 0.565699 0.800795 0.895841 0.312142 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3890, meanQ=5.266459, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 13363 episodes
GETTING ACTION FROM:
action 1, numVisits=11752, meanQ=6.311153, numObservations: 4
action 3, numVisits=3890, meanQ=5.266459, numObservations: 3
action 0, numVisits=1609, meanQ=-0.466854, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=5, meanQ=-77.952470, numObservations: 1
action: 1
Next state: 1 0.545546 0.835104 0.565699 0.800795 0.895841 0.312142 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 454
Initial state: 0 0.3115 0.222152 0.645268 0.89754 0.534029 0.83638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32696 episodes
GETTING ACTION FROM:
action 0, numVisits=32685, meanQ=2.927733, numObservations: 1
action 1, numVisits=4, meanQ=-0.999975, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.3115 0.222152 0.645268 0.89754 0.534029 0.83638 w: 1
Observation: 0 0 0.25668 0 0.967268 0 0.740405 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32583, meanQ=4.970824, numObservations: 3
action -1, numVisits=94, meanQ=4.315770, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55989 episodes
GETTING ACTION FROM:
action 3, numVisits=88558, meanQ=4.878600, numObservations: 3
action -1, numVisits=108, meanQ=4.245100, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.3115 0.222152 0.645268 0.89754 0.534029 0.83638 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=6427, meanQ=5.559909, numObservations: 4
action 2, numVisits=5, meanQ=0.998040, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 68534 episodes
GETTING ACTION FROM:
action 2, numVisits=68535, meanQ=5.904067, numObservations: 5
action 3, numVisits=6427, meanQ=5.559909, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.3115 0.222152 0.645268 0.89754 0.534029 0.83638 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 455
Initial state: 0 0.619652 0.865784 0.95167 0.386642 0.618795 0.899735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55434 episodes
GETTING ACTION FROM:
action 1, numVisits=55340, meanQ=4.989845, numObservations: 4
action 2, numVisits=85, meanQ=4.108004, numObservations: 5
action 3, numVisits=5, meanQ=1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.619652 0.865784 0.95167 0.386642 0.618795 0.899735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 456
Initial state: 0 0.758849 0.155086 0.515736 0.844731 0.565934 0.888338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52815 episodes
GETTING ACTION FROM:
action 3, numVisits=52809, meanQ=4.837864, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.758849 0.155086 0.515736 0.844731 0.565934 0.888338 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 457
Initial state: 0 0.72841 0.740224 0.69495 0.842733 0.501124 0.852775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32747 episodes
GETTING ACTION FROM:
action -1, numVisits=32742, meanQ=2.859263, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.72841 0.740224 0.69495 0.842733 0.501124 0.852775 w: 1
Observation: 0 0.663534 0 0.680646 0 0.404787 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32735, meanQ=4.964742, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 55799 episodes
GETTING ACTION FROM:
action 2, numVisits=88531, meanQ=4.977485, numObservations: 5
action -1, numVisits=3, meanQ=0.966700, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.72841 0.740224 0.69495 0.842733 0.501124 0.852775 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 458
Initial state: 0 0.389383 0.0982145 0.640985 0.822069 0.530832 0.888188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55464 episodes
GETTING ACTION FROM:
action 3, numVisits=55387, meanQ=5.010414, numObservations: 4
action 2, numVisits=71, meanQ=4.075638, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.389383 0.0982145 0.640985 0.822069 0.530832 0.888188 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 459
Initial state: 0 0.659725 0.865165 0.532074 0.376289 0.523312 0.861595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55495 episodes
GETTING ACTION FROM:
action 3, numVisits=55465, meanQ=4.943712, numObservations: 3
action -1, numVisits=16, meanQ=3.207971, numObservations: 1
action 2, numVisits=11, meanQ=2.718182, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.659725 0.865165 0.532074 0.376289 0.523312 0.861595 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 460
Initial state: 0 0.573368 0.844212 0.615318 0.744565 0.647969 0.841592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55482 episodes
GETTING ACTION FROM:
action 3, numVisits=55476, meanQ=4.928848, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.573368 0.844212 0.615318 0.744565 0.647969 0.841592 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 461
Initial state: 0 0.335902 0.450428 0.617935 0.840504 0.61288 0.842742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52551 episodes
GETTING ACTION FROM:
action 2, numVisits=52545, meanQ=5.044072, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.335902 0.450428 0.617935 0.840504 0.61288 0.842742 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 462
Initial state: 0 0.54182 0.897843 0.649591 0.852099 0.939324 0.404877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31654 episodes
GETTING ACTION FROM:
action -1, numVisits=31627, meanQ=2.804439, numObservations: 1
action 3, numVisits=23, meanQ=1.466104, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.54182 0.897843 0.649591 0.852099 0.939324 0.404877 w: 1
Observation: 0 0.577758 0 0.562256 0 0.938967 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31431, meanQ=4.827882, numObservations: 5
action -1, numVisits=133, meanQ=4.292521, numObservations: 1
action 0, numVisits=55, meanQ=3.969081, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 52587 episodes
GETTING ACTION FROM:
action 1, numVisits=83974, meanQ=4.750286, numObservations: 5
action -1, numVisits=170, meanQ=4.248121, numObservations: 1
action 0, numVisits=60, meanQ=3.893707, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action: 1
Next state: 1 0.54182 0.897843 0.649591 0.852099 0.939324 0.404877 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 463
Initial state: 0 0.963324 0.525847 0.645411 0.866785 0.539944 0.886338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52687 episodes
GETTING ACTION FROM:
action 1, numVisits=52621, meanQ=4.791129, numObservations: 5
action 0, numVisits=49, meanQ=3.839915, numObservations: 1
action -1, numVisits=15, meanQ=2.988564, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.963324 0.525847 0.645411 0.866785 0.539944 0.886338 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 464
Initial state: 0 0.561882 0.830705 0.58481 0.864613 0.792277 0.646365 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52113 episodes
GETTING ACTION FROM:
action 3, numVisits=46871, meanQ=5.187882, numObservations: 5
action -1, numVisits=4177, meanQ=3.048183, numObservations: 1
action 0, numVisits=1056, meanQ=2.910764, numObservations: 1
action 1, numVisits=8, meanQ=0.997500, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.561882 0.830705 0.58481 0.864613 0.792277 0.646365 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 465
Initial state: 0 0.595662 0.875686 0.505612 0.838528 0.770034 0.173014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55400 episodes
GETTING ACTION FROM:
action 3, numVisits=55382, meanQ=5.022713, numObservations: 4
action 2, numVisits=8, meanQ=2.498750, numObservations: 3
action 1, numVisits=6, meanQ=1.166683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.595662 0.875686 0.505612 0.838528 0.770034 0.173014 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 466
Initial state: 0 0.38606 0.0302301 0.566682 0.882227 0.542079 0.889743 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32767 episodes
GETTING ACTION FROM:
action 0, numVisits=32757, meanQ=2.879208, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=5, meanQ=-3.000000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.38606 0.0302301 0.566682 0.882227 0.542079 0.889743 w: 1
Observation: 0 0 0.0556009 0 0.833611 0 0.824122 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32745, meanQ=4.940722, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 55522 episodes
GETTING ACTION FROM:
action 1, numVisits=88260, meanQ=4.924665, numObservations: 5
action 3, numVisits=8, meanQ=-0.125000, numObservations: 2
action 2, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.38606 0.0302301 0.566682 0.882227 0.542079 0.889743 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 467
Initial state: 0 0.596148 0.867582 0.388017 0.380789 0.522866 0.837776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55482 episodes
GETTING ACTION FROM:
action 1, numVisits=55466, meanQ=5.016160, numObservations: 3
action 3, numVisits=11, meanQ=2.362745, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.596148 0.867582 0.388017 0.380789 0.522866 0.837776 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 468
Initial state: 0 0.646437 0.801574 0.48174 0.156459 0.692782 0.845557 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55154 episodes
GETTING ACTION FROM:
action 2, numVisits=55146, meanQ=4.961458, numObservations: 4
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.646437 0.801574 0.48174 0.156459 0.692782 0.845557 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 469
Initial state: 0 0.594082 0.825956 0.657672 0.879297 0.817824 0.640338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53473 episodes
GETTING ACTION FROM:
action 3, numVisits=53129, meanQ=4.909805, numObservations: 4
action 0, numVisits=337, meanQ=1.500619, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=4, meanQ=-2.252500, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.594082 0.825956 0.657672 0.879297 0.817824 0.640338 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 470
Initial state: 0 0.664682 0.816143 0.966034 0.503404 0.687288 0.824945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54659 episodes
GETTING ACTION FROM:
action 2, numVisits=54650, meanQ=4.949753, numObservations: 3
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.664682 0.816143 0.966034 0.503404 0.687288 0.824945 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 471
Initial state: 0 0.507674 0.850113 0.565652 0.886976 0.387427 0.336182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55549 episodes
GETTING ACTION FROM:
action 2, numVisits=55506, meanQ=5.059469, numObservations: 4
action 0, numVisits=37, meanQ=3.954247, numObservations: 1
action 1, numVisits=3, meanQ=0.000033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.507674 0.850113 0.565652 0.886976 0.387427 0.336182 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 472
Initial state: 0 0.85199 0.586379 0.681679 0.879971 0.563739 0.808778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54497 episodes
GETTING ACTION FROM:
action 3, numVisits=54488, meanQ=4.954224, numObservations: 5
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.85199 0.586379 0.681679 0.879971 0.563739 0.808778 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 473
Initial state: 0 0.654786 0.818323 0.00900291 0.983761 0.599144 0.88995 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55232 episodes
GETTING ACTION FROM:
action 2, numVisits=55176, meanQ=4.975666, numObservations: 4
action 0, numVisits=40, meanQ=3.939521, numObservations: 1
action -1, numVisits=11, meanQ=2.877550, numObservations: 1
action 3, numVisits=4, meanQ=0.750000, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.654786 0.818323 0.00900291 0.983761 0.599144 0.88995 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4079, meanQ=5.551195, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 62168 episodes
GETTING ACTION FROM:
action 2, numVisits=66222, meanQ=4.649620, numObservations: 4
action 1, numVisits=23, meanQ=2.913043, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action: 2
Next state: 0 0.654786 0.818323 0.00900291 0.983761 0.599144 0.88995 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=8442, meanQ=8.457156, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 25060 episodes
GETTING ACTION FROM:
action 1, numVisits=31353, meanQ=6.907523, numObservations: 3
action 3, numVisits=402, meanQ=6.301552, numObservations: 3
action -1, numVisits=1727, meanQ=-0.808222, numObservations: 1
action 0, numVisits=23, meanQ=-2.043904, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 1
Next state: 1 0.654786 0.818323 0.00900291 0.983761 0.599144 0.88995 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 474
Initial state: 0 0.737086 0.584275 0.651036 0.80686 0.598759 0.824838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55369 episodes
GETTING ACTION FROM:
action 2, numVisits=55278, meanQ=4.996038, numObservations: 4
action -1, numVisits=84, meanQ=4.296335, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.737086 0.584275 0.651036 0.80686 0.598759 0.824838 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 475
Initial state: 0 0.572861 0.814793 0.567798 0.0996893 0.547411 0.816884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54523 episodes
GETTING ACTION FROM:
action 1, numVisits=54511, meanQ=4.934587, numObservations: 5
action 3, numVisits=7, meanQ=2.285729, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.572861 0.814793 0.567798 0.0996893 0.547411 0.816884 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 476
Initial state: 0 0.294875 0.214983 0.63051 0.853261 0.694576 0.808025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54812 episodes
GETTING ACTION FROM:
action 3, numVisits=54795, meanQ=4.880297, numObservations: 5
action 1, numVisits=9, meanQ=2.002244, numObservations: 4
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.294875 0.214983 0.63051 0.853261 0.694576 0.808025 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 477
Initial state: 0 0.0841881 0.735816 0.573967 0.825028 0.691954 0.871307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55636 episodes
GETTING ACTION FROM:
action 3, numVisits=55609, meanQ=5.023684, numObservations: 3
action -1, numVisits=23, meanQ=3.602048, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0841881 0.735816 0.573967 0.825028 0.691954 0.871307 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.655162 0.806092 0.605852 0.852388 0.960699 0.124827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54999 episodes
GETTING ACTION FROM:
action 2, numVisits=54890, meanQ=4.876655, numObservations: 5
action 0, numVisits=98, meanQ=4.222511, numObservations: 1
action 3, numVisits=7, meanQ=1.428571, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.655162 0.806092 0.605852 0.852388 0.960699 0.124827 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 479
Initial state: 0 0.25637 0.472826 0.516963 0.854246 0.517075 0.864564 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54372 episodes
GETTING ACTION FROM:
action 1, numVisits=53374, meanQ=4.971086, numObservations: 4
action -1, numVisits=957, meanQ=3.123341, numObservations: 1
action 0, numVisits=39, meanQ=2.418957, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.25637 0.472826 0.516963 0.854246 0.517075 0.864564 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6075, meanQ=8.463854, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12934 episodes
GETTING ACTION FROM:
action 2, numVisits=7921, meanQ=7.835787, numObservations: 5
action 3, numVisits=48, meanQ=5.833125, numObservations: 4
action 1, numVisits=5, meanQ=5.780000, numObservations: 3
action -1, numVisits=10985, meanQ=0.325531, numObservations: 1
action 0, numVisits=54, meanQ=-0.549750, numObservations: 1
action: 2
Next state: 1 0.25637 0.472826 0.516963 0.854246 0.517075 0.864564 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 480
Initial state: 0 0.695336 0.830027 0.123314 0.612038 0.668615 0.858407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55799 episodes
GETTING ACTION FROM:
action 1, numVisits=55764, meanQ=5.109307, numObservations: 5
action 3, numVisits=29, meanQ=3.746903, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.695336 0.830027 0.123314 0.612038 0.668615 0.858407 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 481
Initial state: 0 0.576565 0.868092 0.687727 0.812055 0.75075 0.445721 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55350 episodes
GETTING ACTION FROM:
action 2, numVisits=55283, meanQ=5.018739, numObservations: 5
action 0, numVisits=54, meanQ=4.137475, numObservations: 1
action 1, numVisits=10, meanQ=2.299030, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.576565 0.868092 0.687727 0.812055 0.75075 0.445721 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 482
Initial state: 0 0.682065 0.810374 0.206905 0.478731 0.556368 0.889174 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32715 episodes
GETTING ACTION FROM:
action 0, numVisits=20518, meanQ=3.069826, numObservations: 1
action -1, numVisits=12194, meanQ=3.056449, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.682065 0.810374 0.206905 0.478731 0.556368 0.889174 w: 1
Observation: 0 0 0.787259 0 0.556352 0 0.893441 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=20497, meanQ=5.076118, numObservations: 5
action 3, numVisits=12, meanQ=2.333333, numObservations: 2
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 55264 episodes
GETTING ACTION FROM:
action 2, numVisits=75739, meanQ=4.997535, numObservations: 5
action 1, numVisits=26, meanQ=3.569623, numObservations: 3
action 3, numVisits=12, meanQ=2.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.682065 0.810374 0.206905 0.478731 0.556368 0.889174 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=3747, meanQ=8.408831, numObservations: 3
action 3, numVisits=6915, meanQ=8.390446, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12856 episodes
GETTING ACTION FROM:
action 1, numVisits=5450, meanQ=7.684743, numObservations: 3
action 3, numVisits=16449, meanQ=7.017742, numObservations: 4
action 2, numVisits=11, meanQ=4.817282, numObservations: 3
action -1, numVisits=1604, meanQ=0.200770, numObservations: 1
action 0, numVisits=7, meanQ=-2.287100, numObservations: 1
action: 1
Next state: 1 0.682065 0.810374 0.206905 0.478731 0.556368 0.889174 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 483
Initial state: 0 0.422684 0.155821 0.549713 0.848324 0.527982 0.846566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55624 episodes
GETTING ACTION FROM:
action 1, numVisits=55607, meanQ=5.090208, numObservations: 4
action 2, numVisits=7, meanQ=2.285729, numObservations: 3
action 3, numVisits=6, meanQ=1.166683, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.422684 0.155821 0.549713 0.848324 0.527982 0.846566 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6218, meanQ=8.491765, numObservations: 3
action 2, numVisits=11, meanQ=6.635464, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 15002 episodes
GETTING ACTION FROM:
action 3, numVisits=8647, meanQ=7.843720, numObservations: 4
action 2, numVisits=144, meanQ=6.660979, numObservations: 4
action -1, numVisits=12433, meanQ=-0.128978, numObservations: 1
action 0, numVisits=9, meanQ=-2.223300, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.422684 0.155821 0.549713 0.848324 0.527982 0.846566 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 484
Initial state: 0 0.432316 0.566442 0.672803 0.840707 0.654801 0.852194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51693 episodes
GETTING ACTION FROM:
action 2, numVisits=45747, meanQ=5.008496, numObservations: 4
action -1, numVisits=5935, meanQ=3.092569, numObservations: 1
action 1, numVisits=7, meanQ=0.285743, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.432316 0.566442 0.672803 0.840707 0.654801 0.852194 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 485
Initial state: 0 0.572331 0.817462 0.520754 0.841994 0.220945 0.0246483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55690 episodes
GETTING ACTION FROM:
action 1, numVisits=55623, meanQ=4.950714, numObservations: 4
action 0, numVisits=28, meanQ=3.677618, numObservations: 1
action -1, numVisits=26, meanQ=3.617138, numObservations: 1
action 2, numVisits=7, meanQ=1.260000, numObservations: 3
action 3, numVisits=6, meanQ=0.166667, numObservations: 3
action: 1
Next state: 1 0.572331 0.817462 0.520754 0.841994 0.220945 0.0246483 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 486
Initial state: 0 0.513221 0.896518 0.52974 0.876576 0.912717 0.776189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32672 episodes
GETTING ACTION FROM:
action -1, numVisits=32667, meanQ=2.954395, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.513221 0.896518 0.52974 0.876576 0.912717 0.776189 w: 1
Observation: 0 0.515297 0 0.517401 0 0.843318 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32655, meanQ=5.030374, numObservations: 5
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55232 episodes
GETTING ACTION FROM:
action 1, numVisits=87878, meanQ=4.974881, numObservations: 5
action 3, numVisits=15, meanQ=3.047333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.513221 0.896518 0.52974 0.876576 0.912717 0.776189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 487
Initial state: 0 0.500948 0.875521 0.464295 0.755544 0.530812 0.888628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53102 episodes
GETTING ACTION FROM:
action 1, numVisits=53050, meanQ=4.895339, numObservations: 3
action -1, numVisits=22, meanQ=3.497483, numObservations: 1
action 2, numVisits=26, meanQ=2.988846, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.500948 0.875521 0.464295 0.755544 0.530812 0.888628 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 488
Initial state: 0 0.640746 0.83724 0.619941 0.805978 0.843496 0.431532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55522 episodes
GETTING ACTION FROM:
action 3, numVisits=55484, meanQ=4.990273, numObservations: 5
action -1, numVisits=31, meanQ=3.699828, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.640746 0.83724 0.619941 0.805978 0.843496 0.431532 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 489
Initial state: 0 0.458071 0.70447 0.69768 0.816063 0.523277 0.85713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55563 episodes
GETTING ACTION FROM:
action 2, numVisits=55478, meanQ=4.974007, numObservations: 3
action -1, numVisits=81, meanQ=4.261919, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.458071 0.70447 0.69768 0.816063 0.523277 0.85713 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 490
Initial state: 0 0.6119 0.667639 0.680088 0.895167 0.614712 0.863992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52384 episodes
GETTING ACTION FROM:
action 3, numVisits=52337, meanQ=4.858282, numObservations: 5
action 2, numVisits=39, meanQ=3.508990, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.6119 0.667639 0.680088 0.895167 0.614712 0.863992 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 491
Initial state: 0 0.514911 0.850741 0.104933 0.352542 0.562288 0.864891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55309 episodes
GETTING ACTION FROM:
action 3, numVisits=55303, meanQ=5.191929, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.514911 0.850741 0.104933 0.352542 0.562288 0.864891 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 492
Initial state: 0 0.665273 0.815768 0.656037 0.887989 0.857739 0.777791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 35555 episodes
GETTING ACTION FROM:
action 1, numVisits=7455, meanQ=4.958197, numObservations: 5
action -1, numVisits=28096, meanQ=2.809815, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.665273 0.815768 0.656037 0.887989 0.857739 0.777791 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 493
Initial state: 0 0.555948 0.87758 0.567838 0.868241 0.370263 0.447217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55744 episodes
GETTING ACTION FROM:
action 3, numVisits=55728, meanQ=5.077917, numObservations: 4
action 2, numVisits=9, meanQ=1.555567, numObservations: 4
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.555948 0.87758 0.567838 0.868241 0.370263 0.447217 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9155, meanQ=8.300913, numObservations: 3
action 1, numVisits=7, meanQ=5.284300, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 14948 episodes
GETTING ACTION FROM:
action 2, numVisits=9247, meanQ=8.268920, numObservations: 3
action 1, numVisits=47, meanQ=4.196895, numObservations: 4
action -1, numVisits=14805, meanQ=0.320030, numObservations: 1
action 0, numVisits=13, meanQ=-1.923846, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.555948 0.87758 0.567838 0.868241 0.370263 0.447217 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=728, meanQ=8.193365, numObservations: 4
action 2, numVisits=16, meanQ=6.999375, numObservations: 3
action -1, numVisits=3, meanQ=4.270000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 22043 episodes
GETTING ACTION FROM:
action 1, numVisits=922, meanQ=7.967233, numObservations: 4
action 2, numVisits=49, meanQ=6.714082, numObservations: 3
action 0, numVisits=14307, meanQ=-1.664949, numObservations: 1
action -1, numVisits=7513, meanQ=-1.690337, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.555948 0.87758 0.567838 0.868241 0.370263 0.447217 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 494
Initial state: 0 0.52366 0.825348 0.854933 0.158054 0.572514 0.81919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55086 episodes
GETTING ACTION FROM:
action 2, numVisits=55065, meanQ=4.951966, numObservations: 5
action 3, numVisits=16, meanQ=-0.187494, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.52366 0.825348 0.854933 0.158054 0.572514 0.81919 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 495
Initial state: 0 0.591899 0.387595 0.524619 0.878967 0.599265 0.872747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55043 episodes
GETTING ACTION FROM:
action 2, numVisits=55006, meanQ=4.885556, numObservations: 4
action 0, numVisits=17, meanQ=3.297074, numObservations: 1
action 1, numVisits=17, meanQ=1.813535, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.591899 0.387595 0.524619 0.878967 0.599265 0.872747 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 496
Initial state: 0 0.369152 0.428735 0.577687 0.847618 0.502465 0.864485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54922 episodes
GETTING ACTION FROM:
action 1, numVisits=54915, meanQ=4.987456, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.369152 0.428735 0.577687 0.847618 0.502465 0.864485 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7641, meanQ=8.418424, numObservations: 4
action 2, numVisits=9, meanQ=6.331111, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11493 episodes
GETTING ACTION FROM:
action 3, numVisits=17521, meanQ=7.030663, numObservations: 4
action 2, numVisits=195, meanQ=5.133128, numObservations: 5
action 0, numVisits=1414, meanQ=-0.557871, numObservations: 1
action -1, numVisits=15, meanQ=-2.200640, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.369152 0.428735 0.577687 0.847618 0.502465 0.864485 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=623, meanQ=8.394620, numObservations: 3
action 0, numVisits=118, meanQ=6.842881, numObservations: 1
action 2, numVisits=4, meanQ=5.997500, numObservations: 2
action -1, numVisits=90, meanQ=3.575883, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9464 episodes
GETTING ACTION FROM:
action 3, numVisits=690, meanQ=8.184547, numObservations: 5
action 2, numVisits=10, meanQ=3.799000, numObservations: 2
action 0, numVisits=7713, meanQ=-1.460397, numObservations: 1
action -1, numVisits=1886, meanQ=-1.535461, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.369152 0.428735 0.577687 0.847618 0.502465 0.864485 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 497
Initial state: 0 0.568128 0.80176 0.239503 0.0206439 0.515399 0.821529 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55591 episodes
GETTING ACTION FROM:
action 2, numVisits=55579, meanQ=4.995680, numObservations: 4
action 3, numVisits=3, meanQ=0.663333, numObservations: 2
action 1, numVisits=5, meanQ=0.604020, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.568128 0.80176 0.239503 0.0206439 0.515399 0.821529 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 498
Initial state: 0 0.610897 0.868712 0.324857 0.428217 0.691633 0.837995 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54406 episodes
GETTING ACTION FROM:
action 3, numVisits=54324, meanQ=4.892992, numObservations: 5
action 1, numVisits=48, meanQ=3.888344, numObservations: 3
action 0, numVisits=25, meanQ=3.585271, numObservations: 1
action 2, numVisits=7, meanQ=0.428571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.610897 0.868712 0.324857 0.428217 0.691633 0.837995 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=506, meanQ=3.872046, numObservations: 1
action 2, numVisits=13, meanQ=1.460008, numObservations: 2
action 3, numVisits=8, meanQ=0.501263, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 10833 episodes
GETTING ACTION FROM:
action 1, numVisits=116, meanQ=5.270822, numObservations: 5
action 2, numVisits=13, meanQ=1.460008, numObservations: 2
action 3, numVisits=8, meanQ=0.501263, numObservations: 2
action 0, numVisits=6451, meanQ=0.198994, numObservations: 1
action -1, numVisits=4775, meanQ=0.116228, numObservations: 1
action: 1
Next state: 1 0.610897 0.868712 0.324857 0.428217 0.691633 0.837995 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 499
Initial state: 0 0.655792 0.840882 0.293231 0.59708 0.658415 0.824419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55657 episodes
GETTING ACTION FROM:
action 1, numVisits=55613, meanQ=4.962748, numObservations: 5
action 0, numVisits=36, meanQ=3.838024, numObservations: 1
action 3, numVisits=5, meanQ=-0.200000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.655792 0.840882 0.293231 0.59708 0.658415 0.824419 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 500
Initial state: 0 0.520387 0.81519 0.779991 0.29024 0.637662 0.832341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55261 episodes
GETTING ACTION FROM:
action 2, numVisits=55111, meanQ=4.987935, numObservations: 4
action -1, numVisits=57, meanQ=4.129075, numObservations: 1
action 3, numVisits=66, meanQ=3.760020, numObservations: 5
action 0, numVisits=26, meanQ=3.595502, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.520387 0.81519 0.779991 0.29024 0.637662 0.832341 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
