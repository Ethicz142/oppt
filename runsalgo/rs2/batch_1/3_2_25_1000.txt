Run # 1
Initial state: 0 0.547345 0.892569 0.845797 0.780856 0.620158 0.828758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31002 episodes
GETTING ACTION FROM:
action 0, numVisits=30958, meanQ=2.844337, numObservations: 1
action 3, numVisits=36, meanQ=1.605289, numObservations: 5
action 1, numVisits=4, meanQ=-0.502500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 0
Next state: 0 0.547345 0.892569 0.845797 0.780856 0.620158 0.828758 w: 1
Observation: 0 0 0.959923 0 0.705541 0 0.906443 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=30924, meanQ=4.895761, numObservations: 4
action 3, numVisits=24, meanQ=3.574171, numObservations: 4
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 52339 episodes
GETTING ACTION FROM:
action 2, numVisits=83260, meanQ=4.941741, numObservations: 4
action 3, numVisits=24, meanQ=3.574171, numObservations: 4
action 1, numVisits=7, meanQ=-1.428571, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.547345 0.892569 0.845797 0.780856 0.620158 0.828758 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 2
Initial state: 0 0.671597 0.809698 0.918063 0.792711 0.503866 0.854253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32727 episodes
GETTING ACTION FROM:
action -1, numVisits=32716, meanQ=2.814051, numObservations: 1
action 3, numVisits=7, meanQ=0.287157, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.671597 0.809698 0.918063 0.792711 0.503866 0.854253 w: 1
Observation: 0 0.688876 0 0.85604 0 0.558556 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32654, meanQ=4.864278, numObservations: 5
action -1, numVisits=55, meanQ=4.002885, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55229 episodes
GETTING ACTION FROM:
action 3, numVisits=87854, meanQ=4.860042, numObservations: 5
action -1, numVisits=56, meanQ=3.973491, numObservations: 1
action 2, numVisits=29, meanQ=3.610690, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.671597 0.809698 0.918063 0.792711 0.503866 0.854253 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 3
Initial state: 0 0.597103 0.886681 0.545261 0.8091 0.232525 0.0371247 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55535 episodes
GETTING ACTION FROM:
action 1, numVisits=55523, meanQ=5.132184, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.597103 0.886681 0.545261 0.8091 0.232525 0.0371247 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 4
Initial state: 0 0.827989 0.607367 0.537697 0.873381 0.614894 0.834326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54610 episodes
GETTING ACTION FROM:
action 2, numVisits=54566, meanQ=5.072094, numObservations: 5
action 0, numVisits=32, meanQ=3.725233, numObservations: 1
action 3, numVisits=8, meanQ=1.755025, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.827989 0.607367 0.537697 0.873381 0.614894 0.834326 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 5
Initial state: 0 0.0824675 0.41576 0.620856 0.822621 0.52983 0.819581 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53215 episodes
GETTING ACTION FROM:
action 3, numVisits=52621, meanQ=4.856342, numObservations: 5
action -1, numVisits=582, meanQ=2.681497, numObservations: 1
action 2, numVisits=8, meanQ=0.750000, numObservations: 3
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.0824675 0.41576 0.620856 0.822621 0.52983 0.819581 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 6
Initial state: 0 0.677797 0.813274 0.539193 0.827587 0.487238 0.657092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53137 episodes
GETTING ACTION FROM:
action 2, numVisits=53106, meanQ=4.864376, numObservations: 5
action 0, numVisits=12, meanQ=2.970313, numObservations: 1
action 1, numVisits=12, meanQ=1.833333, numObservations: 4
action 3, numVisits=5, meanQ=-0.200000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.677797 0.813274 0.539193 0.827587 0.487238 0.657092 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 7
Initial state: 0 0.564105 0.828412 0.687195 0.552139 0.535503 0.819791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32770 episodes
GETTING ACTION FROM:
action 0, numVisits=32755, meanQ=3.007859, numObservations: 1
action 2, numVisits=8, meanQ=-0.001250, numObservations: 3
action 1, numVisits=4, meanQ=-0.272500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.564105 0.828412 0.687195 0.552139 0.535503 0.819791 w: 1
Observation: 0 0 0.883421 0 0.464674 0 0.777437 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32748, meanQ=5.035339, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 56525 episodes
GETTING ACTION FROM:
action 3, numVisits=89257, meanQ=5.002189, numObservations: 4
action 1, numVisits=17, meanQ=3.335882, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.564105 0.828412 0.687195 0.552139 0.535503 0.819791 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 8
Initial state: 0 0.627903 0.882899 0.684453 0.830854 0.376951 0.226214 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54065 episodes
GETTING ACTION FROM:
action 3, numVisits=54041, meanQ=4.972638, numObservations: 4
action 0, numVisits=20, meanQ=3.463684, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.627903 0.882899 0.684453 0.830854 0.376951 0.226214 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7528, meanQ=8.393537, numObservations: 4
action 1, numVisits=7, meanQ=5.284300, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2601 episodes
GETTING ACTION FROM:
action 2, numVisits=7528, meanQ=8.393537, numObservations: 4
action 1, numVisits=22, meanQ=5.090459, numObservations: 3
action 0, numVisits=2073, meanQ=0.158133, numObservations: 1
action -1, numVisits=514, meanQ=-0.056595, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.627903 0.882899 0.684453 0.830854 0.376951 0.226214 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 9
Initial state: 0 0.0777703 0.556141 0.532428 0.882247 0.615025 0.834792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53876 episodes
GETTING ACTION FROM:
action 3, numVisits=53870, meanQ=5.017650, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.0777703 0.556141 0.532428 0.882247 0.615025 0.834792 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 10
Initial state: 0 0.55468 0.885855 0.68694 0.811727 0.662682 0.162891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53726 episodes
GETTING ACTION FROM:
action 2, numVisits=53649, meanQ=4.981054, numObservations: 4
action -1, numVisits=63, meanQ=4.119281, numObservations: 1
action 1, numVisits=11, meanQ=1.361818, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.55468 0.885855 0.68694 0.811727 0.662682 0.162891 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 11
Initial state: 0 0.733884 0.502874 0.573399 0.856552 0.596122 0.832972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53817 episodes
GETTING ACTION FROM:
action 2, numVisits=53805, meanQ=5.124961, numObservations: 5
action 1, numVisits=6, meanQ=2.003350, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.733884 0.502874 0.573399 0.856552 0.596122 0.832972 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 12
Initial state: 0 0.633697 0.889364 0.635872 0.863615 0.408198 0.68959 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54556 episodes
GETTING ACTION FROM:
action 1, numVisits=54223, meanQ=4.950320, numObservations: 5
action 2, numVisits=267, meanQ=4.532504, numObservations: 3
action 0, numVisits=61, meanQ=4.117701, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.633697 0.889364 0.635872 0.863615 0.408198 0.68959 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 13
Initial state: 0 0.19868 0.786505 0.558925 0.802662 0.626905 0.805892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54532 episodes
GETTING ACTION FROM:
action 2, numVisits=53869, meanQ=5.016563, numObservations: 4
action 1, numVisits=658, meanQ=4.764144, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.19868 0.786505 0.558925 0.802662 0.626905 0.805892 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 14
Initial state: 0 0.279729 0.401548 0.635388 0.806254 0.624392 0.847973 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51387 episodes
GETTING ACTION FROM:
action 1, numVisits=51310, meanQ=4.773294, numObservations: 5
action -1, numVisits=54, meanQ=3.901980, numObservations: 1
action 3, numVisits=20, meanQ=3.250510, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.279729 0.401548 0.635388 0.806254 0.624392 0.847973 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1221, meanQ=7.837186, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6150 episodes
GETTING ACTION FROM:
action 2, numVisits=1237, meanQ=7.812300, numObservations: 4
action 3, numVisits=8, meanQ=3.373750, numObservations: 2
action 1, numVisits=4, meanQ=2.747500, numObservations: 3
action -1, numVisits=6118, meanQ=0.168516, numObservations: 1
action 0, numVisits=8, meanQ=-2.126225, numObservations: 1
action: 2
Next state: 0 0.279729 0.401548 0.635388 0.806254 0.624392 0.847973 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=89, meanQ=7.777980, numObservations: 4
action -1, numVisits=2, meanQ=2.950000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 13339 episodes
GETTING ACTION FROM:
action 1, numVisits=74, meanQ=7.297164, numObservations: 3
action 2, numVisits=37, meanQ=6.513243, numObservations: 4
action 3, numVisits=236, meanQ=6.471358, numObservations: 4
action -1, numVisits=6087, meanQ=-1.655850, numObservations: 1
action 0, numVisits=6999, meanQ=-1.661230, numObservations: 1
action: 1
Next state: 0 0.279729 0.401548 0.635388 0.806254 0.624392 0.847973 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17739 episodes
GETTING ACTION FROM:
action 2, numVisits=207, meanQ=6.101449, numObservations: 4
action 3, numVisits=640, meanQ=5.993086, numObservations: 5
action 1, numVisits=72, meanQ=5.429306, numObservations: 4
action 0, numVisits=16787, meanQ=-1.833778, numObservations: 1
action -1, numVisits=34, meanQ=-13.097883, numObservations: 1
action: 2
Next state: 1 0.279729 0.401548 0.635388 0.806254 0.624392 0.847973 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 15
Initial state: 0 0.691465 0.888591 0.373862 0.789169 0.509763 0.823789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54369 episodes
GETTING ACTION FROM:
action 2, numVisits=54363, meanQ=4.905262, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.691465 0.888591 0.373862 0.789169 0.509763 0.823789 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3536, meanQ=8.500057, numObservations: 3
action 3, numVisits=2648, meanQ=8.495667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3384 episodes
GETTING ACTION FROM:
action 3, numVisits=2855, meanQ=8.334068, numObservations: 4
action 1, numVisits=4034, meanQ=8.260173, numObservations: 4
action 2, numVisits=3, meanQ=4.996667, numObservations: 2
action 0, numVisits=2677, meanQ=0.309873, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.691465 0.888591 0.373862 0.789169 0.509763 0.823789 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 16
Initial state: 0 0.571659 0.899425 0.518256 0.837049 0.408734 0.901053 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50996 episodes
GETTING ACTION FROM:
action 1, numVisits=46405, meanQ=4.878884, numObservations: 5
action 0, numVisits=4580, meanQ=3.020804, numObservations: 1
action 2, numVisits=7, meanQ=0.854286, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.571659 0.899425 0.518256 0.837049 0.408734 0.901053 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 17
Initial state: 0 0.695091 0.885527 0.686529 0.861648 0.726596 0.510585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54247 episodes
GETTING ACTION FROM:
action 1, numVisits=54230, meanQ=4.948274, numObservations: 4
action 3, numVisits=12, meanQ=1.250833, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.695091 0.885527 0.686529 0.861648 0.726596 0.510585 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 18
Initial state: 0 0.523885 0.785293 0.620617 0.811973 0.597837 0.826394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54031 episodes
GETTING ACTION FROM:
action 3, numVisits=54017, meanQ=4.989058, numObservations: 5
action 1, numVisits=8, meanQ=0.750000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.523885 0.785293 0.620617 0.811973 0.597837 0.826394 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 19
Initial state: 0 0.575576 0.674936 0.57126 0.818574 0.668534 0.826044 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54115 episodes
GETTING ACTION FROM:
action 1, numVisits=54085, meanQ=4.940312, numObservations: 5
action -1, numVisits=21, meanQ=3.109115, numObservations: 1
action 2, numVisits=6, meanQ=1.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.575576 0.674936 0.57126 0.818574 0.668534 0.826044 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 20
Initial state: 0 0.542803 0.867684 0.820915 0.812268 0.528359 0.805238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54166 episodes
GETTING ACTION FROM:
action 2, numVisits=54138, meanQ=4.981300, numObservations: 4
action -1, numVisits=24, meanQ=3.535608, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.542803 0.867684 0.820915 0.812268 0.528359 0.805238 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 21
Initial state: 0 0.641712 0.82926 0.624362 0.417099 0.537748 0.812687 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53916 episodes
GETTING ACTION FROM:
action 2, numVisits=53909, meanQ=4.987669, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.641712 0.82926 0.624362 0.417099 0.537748 0.812687 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3901, meanQ=5.376005, numObservations: 4
action 3, numVisits=8, meanQ=2.498750, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 60337 episodes
GETTING ACTION FROM:
action 2, numVisits=64148, meanQ=5.585411, numObservations: 4
action 1, numVisits=73, meanQ=4.613837, numObservations: 4
action 3, numVisits=22, meanQ=3.722727, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 2
Next state: 2 0.641712 0.82926 0.624362 0.417099 0.537748 0.812687 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 22
Initial state: 0 0.131139 0.133218 0.696581 0.867877 0.523079 0.867716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54441 episodes
GETTING ACTION FROM:
action 3, numVisits=54435, meanQ=5.001384, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.131139 0.133218 0.696581 0.867877 0.523079 0.867716 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 23
Initial state: 0 0.650825 0.81522 0.184098 0.62743 0.632379 0.816448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53247 episodes
GETTING ACTION FROM:
action 2, numVisits=51256, meanQ=5.025849, numObservations: 5
action 0, numVisits=1981, meanQ=2.949161, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-5.489950, numObservations: 1
action: 2
Next state: 0 0.650825 0.81522 0.184098 0.62743 0.632379 0.816448 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1267, meanQ=7.645192, numObservations: 5
action 1, numVisits=5, meanQ=3.402020, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8149 episodes
GETTING ACTION FROM:
action 3, numVisits=1267, meanQ=7.645192, numObservations: 5
action 1, numVisits=6, meanQ=1.001683, numObservations: 1
action -1, numVisits=8141, meanQ=0.134319, numObservations: 1
action 0, numVisits=9, meanQ=-1.890000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.650825 0.81522 0.184098 0.62743 0.632379 0.816448 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 24
Initial state: 0 0.599545 0.865506 0.148702 0.709565 0.661865 0.864471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54755 episodes
GETTING ACTION FROM:
action 2, numVisits=54748, meanQ=5.030964, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.599545 0.865506 0.148702 0.709565 0.661865 0.864471 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7697, meanQ=8.383948, numObservations: 5
action 1, numVisits=3, meanQ=4.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2108 episodes
GETTING ACTION FROM:
action 3, numVisits=7697, meanQ=8.383948, numObservations: 5
action 1, numVisits=13, meanQ=3.925707, numObservations: 3
action 2, numVisits=2, meanQ=0.950000, numObservations: 1
action 0, numVisits=1903, meanQ=0.425838, numObservations: 1
action -1, numVisits=196, meanQ=0.096173, numObservations: 1
action: 3
Next state: 0 0.599545 0.865506 0.148702 0.709565 0.661865 0.864471 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=627, meanQ=8.371949, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 14906 episodes
GETTING ACTION FROM:
action 1, numVisits=752, meanQ=7.891239, numObservations: 3
action 2, numVisits=144, meanQ=6.874931, numObservations: 3
action 0, numVisits=10087, meanQ=-1.692607, numObservations: 1
action -1, numVisits=4551, meanQ=-1.723731, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 1
Next state: 1 0.599545 0.865506 0.148702 0.709565 0.661865 0.864471 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 25
Initial state: 0 0.404329 0.787028 0.677588 0.859472 0.588341 0.828758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51611 episodes
GETTING ACTION FROM:
action 2, numVisits=51605, meanQ=4.842829, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.404329 0.787028 0.677588 0.859472 0.588341 0.828758 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 26
Initial state: 0 0.467428 0.221846 0.69236 0.887616 0.568593 0.893732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53511 episodes
GETTING ACTION FROM:
action 1, numVisits=53454, meanQ=4.947508, numObservations: 4
action -1, numVisits=48, meanQ=2.053537, numObservations: 1
action 2, numVisits=6, meanQ=0.836683, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.467428 0.221846 0.69236 0.887616 0.568593 0.893732 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1360, meanQ=7.639409, numObservations: 4
action 2, numVisits=11, meanQ=5.363636, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 5305 episodes
GETTING ACTION FROM:
action 3, numVisits=1360, meanQ=7.639409, numObservations: 4
action 2, numVisits=30, meanQ=5.213255, numObservations: 3
action -1, numVisits=5279, meanQ=0.167348, numObservations: 1
action 0, numVisits=8, meanQ=-1.876250, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 3
Next state: 1 0.467428 0.221846 0.69236 0.887616 0.568593 0.893732 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 27
Initial state: 0 0.586864 0.835232 0.560283 0.877079 0.257382 0.685375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52024 episodes
GETTING ACTION FROM:
action 2, numVisits=52000, meanQ=4.897221, numObservations: 3
action 3, numVisits=19, meanQ=3.104737, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.586864 0.835232 0.560283 0.877079 0.257382 0.685375 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 28
Initial state: 0 0.657819 0.867932 0.783722 0.821801 0.622347 0.836385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51229 episodes
GETTING ACTION FROM:
action 2, numVisits=51182, meanQ=4.928647, numObservations: 5
action 0, numVisits=41, meanQ=3.897396, numObservations: 1
action 3, numVisits=3, meanQ=0.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.657819 0.867932 0.783722 0.821801 0.622347 0.836385 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 29
Initial state: 0 0.0865978 0.291996 0.554819 0.864571 0.641911 0.818963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51740 episodes
GETTING ACTION FROM:
action 1, numVisits=51730, meanQ=4.827537, numObservations: 5
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0865978 0.291996 0.554819 0.864571 0.641911 0.818963 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7237, meanQ=8.393795, numObservations: 4
action 3, numVisits=6, meanQ=4.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2996 episodes
GETTING ACTION FROM:
action 2, numVisits=7237, meanQ=8.393795, numObservations: 4
action 3, numVisits=11, meanQ=3.479066, numObservations: 5
action -1, numVisits=2989, meanQ=0.176410, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-5.873235, numObservations: 1
action: 2
Next state: 1 0.0865978 0.291996 0.554819 0.864571 0.641911 0.818963 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 30
Initial state: 0 0.677559 0.892366 0.610095 0.877743 0.293685 0.977148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52152 episodes
GETTING ACTION FROM:
action 2, numVisits=51956, meanQ=4.877357, numObservations: 4
action 0, numVisits=110, meanQ=4.269379, numObservations: 1
action -1, numVisits=80, meanQ=2.894559, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.677559 0.892366 0.610095 0.877743 0.293685 0.977148 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 31
Initial state: 0 0.689717 0.833432 0.523342 0.862739 0.955934 0.442024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54249 episodes
GETTING ACTION FROM:
action 2, numVisits=54237, meanQ=4.998746, numObservations: 4
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=4, meanQ=-2.749975, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.689717 0.833432 0.523342 0.862739 0.955934 0.442024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 32
Initial state: 0 0.577208 0.875877 0.962457 0.580427 0.522295 0.870845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54524 episodes
GETTING ACTION FROM:
action 2, numVisits=54448, meanQ=4.995452, numObservations: 5
action 1, numVisits=50, meanQ=4.036206, numObservations: 5
action -1, numVisits=23, meanQ=3.573086, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.577208 0.875877 0.962457 0.580427 0.522295 0.870845 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 33
Initial state: 0 0.644516 0.89959 0.654688 0.8946 0.973128 0.638412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51904 episodes
GETTING ACTION FROM:
action 3, numVisits=51844, meanQ=4.838631, numObservations: 4
action 0, numVisits=48, meanQ=3.861333, numObservations: 1
action 1, numVisits=9, meanQ=2.210000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.644516 0.89959 0.654688 0.8946 0.973128 0.638412 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 34
Initial state: 0 0.608065 0.841045 0.584968 0.0760394 0.677451 0.894327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51500 episodes
GETTING ACTION FROM:
action 2, numVisits=51472, meanQ=4.784369, numObservations: 4
action 1, numVisits=22, meanQ=2.453636, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.608065 0.841045 0.584968 0.0760394 0.677451 0.894327 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.138315 0.358888 0.619201 0.830048 0.528434 0.832128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54148 episodes
GETTING ACTION FROM:
action 3, numVisits=53941, meanQ=5.010141, numObservations: 5
action -1, numVisits=202, meanQ=1.943292, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.499950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.138315 0.358888 0.619201 0.830048 0.528434 0.832128 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3909, meanQ=4.833455, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
Sampled 67192 episodes
GETTING ACTION FROM:
action 2, numVisits=71075, meanQ=5.794173, numObservations: 5
action 1, numVisits=25, meanQ=3.556000, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=4, meanQ=-4.002500, numObservations: 2
action: 2
Next state: 1 0.138315 0.358888 0.619201 0.830048 0.528434 0.832128 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 36
Initial state: 0 0.412605 0.53808 0.583264 0.823608 0.666671 0.822915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 23563 episodes
GETTING ACTION FROM:
action -1, numVisits=23484, meanQ=3.811246, numObservations: 1
action 0, numVisits=49, meanQ=2.945923, numObservations: 1
action 3, numVisits=26, meanQ=2.461942, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 1
action: -1
Next state: 0 0.412605 0.53808 0.583264 0.823608 0.666671 0.822915 w: 1
Observation: 0 0.400113 0 0.678552 0 0.574679 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=23462, meanQ=5.919119, numObservations: 3
action 2, numVisits=6, meanQ=1.001683, numObservations: 3
action 1, numVisits=12, meanQ=0.656667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 33673 episodes
GETTING ACTION FROM:
action 0, numVisits=57135, meanQ=5.946884, numObservations: 3
action 2, numVisits=6, meanQ=1.001683, numObservations: 3
action 1, numVisits=12, meanQ=0.656667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.412605 0.53808 0.583264 0.823608 0.666671 0.822915 w: 1
Observation: 0 0 0.609839 0 0.778144 0 0.752523 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=16906, meanQ=8.212222, numObservations: 4
action 3, numVisits=18, meanQ=6.443894, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54519 episodes
GETTING ACTION FROM:
action 2, numVisits=71398, meanQ=5.628944, numObservations: 4
action 3, numVisits=32, meanQ=4.121569, numObservations: 3
action -1, numVisits=12, meanQ=3.693347, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 2
Next state: 1 0.412605 0.53808 0.583264 0.823608 0.666671 0.822915 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 37
Initial state: 0 0.731965 0.295982 0.688222 0.861099 0.576409 0.874089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53877 episodes
GETTING ACTION FROM:
action 2, numVisits=52931, meanQ=5.003096, numObservations: 4
action -1, numVisits=940, meanQ=3.197610, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.731965 0.295982 0.688222 0.861099 0.576409 0.874089 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 38
Initial state: 0 0.549403 0.800843 0.606177 0.00893709 0.525992 0.878202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54436 episodes
GETTING ACTION FROM:
action 3, numVisits=54418, meanQ=5.038452, numObservations: 5
action 2, numVisits=12, meanQ=2.833350, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.549403 0.800843 0.606177 0.00893709 0.525992 0.878202 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 39
Initial state: 0 0.577212 0.865346 0.610121 0.883246 0.200342 0.462285 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54100 episodes
GETTING ACTION FROM:
action 1, numVisits=54054, meanQ=4.990480, numObservations: 5
action 0, numVisits=38, meanQ=3.921653, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-4.499950, numObservations: 1
action: 1
Next state: 1 0.577212 0.865346 0.610121 0.883246 0.200342 0.462285 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 40
Initial state: 0 0.562359 0.848154 0.21314 0.0467021 0.618088 0.888304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53818 episodes
GETTING ACTION FROM:
action 2, numVisits=53752, meanQ=4.950480, numObservations: 5
action -1, numVisits=57, meanQ=4.063304, numObservations: 1
action 3, numVisits=4, meanQ=0.750000, numObservations: 3
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.562359 0.848154 0.21314 0.0467021 0.618088 0.888304 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7450, meanQ=8.363116, numObservations: 5
action 3, numVisits=65, meanQ=7.583235, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3110 episodes
GETTING ACTION FROM:
action 1, numVisits=7450, meanQ=8.363116, numObservations: 5
action 3, numVisits=74, meanQ=6.889464, numObservations: 3
action 0, numVisits=3082, meanQ=0.131295, numObservations: 2
action -1, numVisits=20, meanQ=-1.554995, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 1
Next state: 1 0.562359 0.848154 0.21314 0.0467021 0.618088 0.888304 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 41
Initial state: 0 0.0983706 0.978257 0.673664 0.863793 0.619382 0.802236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53754 episodes
GETTING ACTION FROM:
action 1, numVisits=53449, meanQ=5.005985, numObservations: 4
action 2, numVisits=296, meanQ=4.499626, numObservations: 5
action 3, numVisits=5, meanQ=-0.002000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0983706 0.978257 0.673664 0.863793 0.619382 0.802236 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1303, meanQ=7.694099, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2869 episodes
GETTING ACTION FROM:
action 3, numVisits=1303, meanQ=7.694099, numObservations: 3
action 1, numVisits=10, meanQ=3.390000, numObservations: 3
action 2, numVisits=9, meanQ=1.453502, numObservations: 3
action 0, numVisits=2839, meanQ=0.196897, numObservations: 1
action -1, numVisits=15, meanQ=-2.067320, numObservations: 1
action: 3
Next state: 1 0.0983706 0.978257 0.673664 0.863793 0.619382 0.802236 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 42
Initial state: 0 0.635553 0.862783 0.592662 0.817453 0.725583 0.750167 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53313 episodes
GETTING ACTION FROM:
action 1, numVisits=53297, meanQ=5.027052, numObservations: 4
action 3, numVisits=11, meanQ=3.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.635553 0.862783 0.592662 0.817453 0.725583 0.750167 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 43
Initial state: 0 0.532181 0.837127 0.636591 0.881776 0.916173 0.11123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54180 episodes
GETTING ACTION FROM:
action 3, numVisits=54174, meanQ=4.951906, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.532181 0.837127 0.636591 0.881776 0.916173 0.11123 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 44
Initial state: 0 0.63977 0.895192 0.330631 0.297141 0.540384 0.889359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54224 episodes
GETTING ACTION FROM:
action 3, numVisits=53896, meanQ=5.040703, numObservations: 5
action 0, numVisits=65, meanQ=4.244731, numObservations: 1
action -1, numVisits=257, meanQ=3.921223, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action: 3
Next state: 1 0.63977 0.895192 0.330631 0.297141 0.540384 0.889359 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 45
Initial state: 0 0.610316 0.859087 0.630071 0.835244 0.896829 0.128212 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54332 episodes
GETTING ACTION FROM:
action 3, numVisits=54323, meanQ=5.041051, numObservations: 4
action 1, numVisits=3, meanQ=-2.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 3
Next state: 2 0.610316 0.859087 0.630071 0.835244 0.896829 0.128212 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 46
Initial state: 0 0.512124 0.810739 0.664658 0.890503 0.778943 0.71808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32031 episodes
GETTING ACTION FROM:
action -1, numVisits=32018, meanQ=3.019386, numObservations: 1
action 2, numVisits=7, meanQ=-1.428571, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=3, meanQ=-3.363333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.512124 0.810739 0.664658 0.890503 0.778943 0.71808 w: 1
Observation: 0 0.564252 0 0.682854 0 0.725483 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31978, meanQ=5.030960, numObservations: 4
action 0, numVisits=21, meanQ=3.654623, numObservations: 1
action 3, numVisits=15, meanQ=2.465340, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54119 episodes
GETTING ACTION FROM:
action 1, numVisits=86094, meanQ=4.983627, numObservations: 4
action 0, numVisits=23, meanQ=3.443045, numObservations: 1
action 3, numVisits=15, meanQ=2.465340, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-4.994950, numObservations: 1
action: 1
Next state: 1 0.512124 0.810739 0.664658 0.890503 0.778943 0.71808 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 47
Initial state: 0 0.725608 0.661885 0.640407 0.866509 0.5359 0.892428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54123 episodes
GETTING ACTION FROM:
action 2, numVisits=54054, meanQ=5.117068, numObservations: 5
action 3, numVisits=29, meanQ=3.865179, numObservations: 3
action 0, numVisits=27, meanQ=3.854326, numObservations: 1
action -1, numVisits=12, meanQ=3.148426, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.725608 0.661885 0.640407 0.866509 0.5359 0.892428 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 48
Initial state: 0 0.595693 0.812635 0.658067 0.882667 0.256255 0.00453047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54343 episodes
GETTING ACTION FROM:
action 2, numVisits=54299, meanQ=5.031909, numObservations: 5
action 0, numVisits=30, meanQ=3.788817, numObservations: 1
action 1, numVisits=7, meanQ=0.844286, numObservations: 3
action 3, numVisits=5, meanQ=0.800040, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.595693 0.812635 0.658067 0.882667 0.256255 0.00453047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 49
Initial state: 0 0.683226 0.879682 0.668001 0.826519 0.157202 0.550707 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54116 episodes
GETTING ACTION FROM:
action 1, numVisits=54026, meanQ=4.967809, numObservations: 4
action 2, numVisits=52, meanQ=3.945773, numObservations: 3
action 0, numVisits=33, meanQ=3.782496, numObservations: 1
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.683226 0.879682 0.668001 0.826519 0.157202 0.550707 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 50
Initial state: 0 0.693558 0.854687 0.646815 0.855394 0.0625217 0.362689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53787 episodes
GETTING ACTION FROM:
action 1, numVisits=53777, meanQ=5.007830, numObservations: 5
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.693558 0.854687 0.646815 0.855394 0.0625217 0.362689 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 51
Initial state: 0 0.0325789 0.39175 0.678487 0.841084 0.53944 0.871625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54207 episodes
GETTING ACTION FROM:
action 1, numVisits=54124, meanQ=5.169919, numObservations: 5
action 3, numVisits=72, meanQ=4.024703, numObservations: 4
action 2, numVisits=7, meanQ=2.428571, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.0325789 0.39175 0.678487 0.841084 0.53944 0.871625 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6003, meanQ=8.527191, numObservations: 3
action 2, numVisits=18, meanQ=7.211111, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2926 episodes
GETTING ACTION FROM:
action 3, numVisits=6003, meanQ=8.527191, numObservations: 3
action 2, numVisits=104, meanQ=6.378365, numObservations: 4
action 0, numVisits=2817, meanQ=0.390824, numObservations: 1
action 1, numVisits=5, meanQ=-1.402000, numObservations: 3
action -1, numVisits=21, meanQ=-2.000471, numObservations: 1
action: 3
Next state: 1 0.0325789 0.39175 0.678487 0.841084 0.53944 0.871625 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 52
Initial state: 0 0.51777 0.899961 0.679017 0.864776 0.984308 0.307674 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51850 episodes
GETTING ACTION FROM:
action 1, numVisits=51843, meanQ=4.787783, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.51777 0.899961 0.679017 0.864776 0.984308 0.307674 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 53
Initial state: 0 0.0518735 0.342653 0.662419 0.851857 0.554596 0.87997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54036 episodes
GETTING ACTION FROM:
action 3, numVisits=53889, meanQ=4.968855, numObservations: 5
action 0, numVisits=69, meanQ=4.193569, numObservations: 1
action 2, numVisits=74, meanQ=3.825206, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.0518735 0.342653 0.662419 0.851857 0.554596 0.87997 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 54
Initial state: 0 0.508623 0.871762 0.588439 0.896841 0.738168 0.968561 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54184 episodes
GETTING ACTION FROM:
action 1, numVisits=53783, meanQ=4.994186, numObservations: 4
action 3, numVisits=357, meanQ=4.650381, numObservations: 4
action 0, numVisits=27, meanQ=3.724107, numObservations: 1
action -1, numVisits=11, meanQ=2.803780, numObservations: 1
action 2, numVisits=6, meanQ=1.333333, numObservations: 3
action: 1
Next state: 1 0.508623 0.871762 0.588439 0.896841 0.738168 0.968561 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 55
Initial state: 0 0.916741 0.956766 0.532756 0.878894 0.584776 0.814144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52069 episodes
GETTING ACTION FROM:
action 3, numVisits=48786, meanQ=4.972211, numObservations: 4
action -1, numVisits=3262, meanQ=2.924315, numObservations: 1
action 2, numVisits=14, meanQ=1.485714, numObservations: 3
action 1, numVisits=5, meanQ=-0.597980, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.916741 0.956766 0.532756 0.878894 0.584776 0.814144 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 56
Initial state: 0 0.652931 0.805175 0.543043 0.845385 0.0781466 0.315039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51808 episodes
GETTING ACTION FROM:
action 2, numVisits=51768, meanQ=4.921005, numObservations: 5
action 3, numVisits=28, meanQ=2.314646, numObservations: 3
action 1, numVisits=8, meanQ=0.263750, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.652931 0.805175 0.543043 0.845385 0.0781466 0.315039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 57
Initial state: 0 0.516673 0.818471 0.674946 0.846584 0.404804 0.914039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51631 episodes
GETTING ACTION FROM:
action 3, numVisits=51496, meanQ=4.879401, numObservations: 5
action -1, numVisits=131, meanQ=4.321293, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.516673 0.818471 0.674946 0.846584 0.404804 0.914039 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=3794, meanQ=3.472130, numObservations: 1
action -1, numVisits=44, meanQ=2.430080, numObservations: 1
action 1, numVisits=17, meanQ=1.471182, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67186 episodes
GETTING ACTION FROM:
action 2, numVisits=67185, meanQ=5.848436, numObservations: 5
action 0, numVisits=3796, meanQ=3.470693, numObservations: 1
action -1, numVisits=44, meanQ=2.430080, numObservations: 1
action 1, numVisits=17, meanQ=1.471182, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.516673 0.818471 0.674946 0.846584 0.404804 0.914039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 58
Initial state: 0 0.0760883 0.888026 0.531505 0.841439 0.647002 0.867802 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54294 episodes
GETTING ACTION FROM:
action 2, numVisits=54266, meanQ=5.003843, numObservations: 3
action -1, numVisits=17, meanQ=3.236654, numObservations: 1
action 1, numVisits=6, meanQ=2.003350, numObservations: 3
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.0760883 0.888026 0.531505 0.841439 0.647002 0.867802 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 59
Initial state: 0 0.453972 0.867819 0.582477 0.830737 0.590102 0.819482 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54431 episodes
GETTING ACTION FROM:
action 3, numVisits=54418, meanQ=5.047508, numObservations: 4
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.453972 0.867819 0.582477 0.830737 0.590102 0.819482 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 60
Initial state: 0 0.394373 0.500716 0.501771 0.872216 0.654921 0.802628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54339 episodes
GETTING ACTION FROM:
action 2, numVisits=54291, meanQ=4.974082, numObservations: 3
action -1, numVisits=31, meanQ=3.751295, numObservations: 1
action 3, numVisits=9, meanQ=1.555567, numObservations: 2
action 1, numVisits=6, meanQ=1.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.394373 0.500716 0.501771 0.872216 0.654921 0.802628 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 61
Initial state: 0 0.530464 0.892765 0.418221 0.845882 0.633319 0.899768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54155 episodes
GETTING ACTION FROM:
action 2, numVisits=52591, meanQ=5.004602, numObservations: 5
action 1, numVisits=1435, meanQ=4.685750, numObservations: 4
action -1, numVisits=78, meanQ=4.201793, numObservations: 1
action 3, numVisits=49, meanQ=4.033678, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.530464 0.892765 0.418221 0.845882 0.633319 0.899768 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2585, meanQ=7.806334, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3651 episodes
GETTING ACTION FROM:
action 1, numVisits=2585, meanQ=7.806334, numObservations: 5
action 3, numVisits=45, meanQ=6.210059, numObservations: 3
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=3590, meanQ=0.253279, numObservations: 1
action 0, numVisits=16, meanQ=-2.527563, numObservations: 1
action: 1
Next state: 1 0.530464 0.892765 0.418221 0.845882 0.633319 0.899768 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 62
Initial state: 0 0.66525 0.854555 0.935787 0.341177 0.601281 0.83774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51436 episodes
GETTING ACTION FROM:
action 1, numVisits=51349, meanQ=4.797746, numObservations: 3
action -1, numVisits=80, meanQ=4.034850, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=3, meanQ=-3.296667, numObservations: 2
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 1
Next state: 1 0.66525 0.854555 0.935787 0.341177 0.601281 0.83774 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 63
Initial state: 0 0.885156 0.507029 0.508246 0.807967 0.595559 0.856753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54135 episodes
GETTING ACTION FROM:
action 3, numVisits=54110, meanQ=4.978326, numObservations: 3
action -1, numVisits=20, meanQ=3.503761, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.885156 0.507029 0.508246 0.807967 0.595559 0.856753 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 64
Initial state: 0 0.147934 0.0355309 0.549894 0.809892 0.631595 0.807378 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51352 episodes
GETTING ACTION FROM:
action 2, numVisits=51338, meanQ=4.885216, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.147934 0.0355309 0.549894 0.809892 0.631595 0.807378 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=3739, meanQ=3.059804, numObservations: 1
action 1, numVisits=7, meanQ=0.127157, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 60865 episodes
GETTING ACTION FROM:
action 2, numVisits=60852, meanQ=4.927739, numObservations: 4
action 0, numVisits=3739, meanQ=3.059804, numObservations: 1
action 3, numVisits=16, meanQ=2.931875, numObservations: 2
action 1, numVisits=7, meanQ=0.127157, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.147934 0.0355309 0.549894 0.809892 0.631595 0.807378 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 65
Initial state: 0 0.670715 0.835487 0.24117 0.470714 0.563131 0.872266 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51418 episodes
GETTING ACTION FROM:
action 3, numVisits=51410, meanQ=4.841379, numObservations: 5
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.670715 0.835487 0.24117 0.470714 0.563131 0.872266 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 66
Initial state: 0 0.639304 0.817564 0.674631 0.801665 0.428274 0.703571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54407 episodes
GETTING ACTION FROM:
action 2, numVisits=54399, meanQ=5.132483, numObservations: 5
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.639304 0.817564 0.674631 0.801665 0.428274 0.703571 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 67
Initial state: 0 0.681827 0.829762 0.653698 0.866829 0.0691949 0.0187039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54072 episodes
GETTING ACTION FROM:
action 1, numVisits=54034, meanQ=5.049220, numObservations: 5
action 2, numVisits=33, meanQ=3.385461, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.681827 0.829762 0.653698 0.866829 0.0691949 0.0187039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 68
Initial state: 0 0.587337 0.816528 0.170848 0.850545 0.517567 0.832016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31954 episodes
GETTING ACTION FROM:
action 0, numVisits=31946, meanQ=3.198168, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=2, meanQ=-4.499950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.587337 0.816528 0.170848 0.850545 0.517567 0.832016 w: 1
Observation: 0 0 0.741984 0 0.786126 0 0.794099 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=26298, meanQ=4.235652, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 53384 episodes
GETTING ACTION FROM:
action 2, numVisits=53367, meanQ=4.986834, numObservations: 4
action 3, numVisits=26298, meanQ=4.235652, numObservations: 4
action 1, numVisits=22, meanQ=3.272727, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.587337 0.816528 0.170848 0.850545 0.517567 0.832016 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1429, meanQ=7.842325, numObservations: 3
action 3, numVisits=4, meanQ=4.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3252 episodes
GETTING ACTION FROM:
action 1, numVisits=1429, meanQ=7.842325, numObservations: 3
action 3, numVisits=55, meanQ=5.809951, numObservations: 3
action 2, numVisits=5, meanQ=5.780000, numObservations: 3
action 0, numVisits=3192, meanQ=0.339151, numObservations: 1
action -1, numVisits=7, meanQ=-1.858571, numObservations: 1
action: 1
Next state: 1 0.587337 0.816528 0.170848 0.850545 0.517567 0.832016 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 69
Initial state: 0 0.580205 0.880402 0.614835 0.82893 0.717584 0.129454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53800 episodes
GETTING ACTION FROM:
action 3, numVisits=53573, meanQ=5.001548, numObservations: 5
action -1, numVisits=130, meanQ=2.670877, numObservations: 1
action 0, numVisits=95, meanQ=2.601461, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.580205 0.880402 0.614835 0.82893 0.717584 0.129454 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 70
Initial state: 0 0.550032 0.864415 0.537231 0.867357 0.845433 0.0321607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31855 episodes
GETTING ACTION FROM:
action -1, numVisits=31837, meanQ=2.997135, numObservations: 1
action 3, numVisits=7, meanQ=0.285743, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=5, meanQ=-1.402000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: -1
Next state: 0 0.550032 0.864415 0.537231 0.867357 0.845433 0.0321607 w: 1
Observation: 0 0.525999 0 0.558007 0 0.772259 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31604, meanQ=4.983864, numObservations: 4
action -1, numVisits=173, meanQ=4.524215, numObservations: 1
action 1, numVisits=29, meanQ=3.758279, numObservations: 4
action 0, numVisits=25, meanQ=3.678353, numObservations: 1
action 2, numVisits=5, meanQ=1.396020, numObservations: 3
Sampled 54841 episodes
GETTING ACTION FROM:
action 3, numVisits=86411, meanQ=4.964554, numObservations: 4
action -1, numVisits=201, meanQ=4.510131, numObservations: 1
action 1, numVisits=34, meanQ=3.700297, numObservations: 4
action 0, numVisits=26, meanQ=3.605567, numObservations: 1
action 2, numVisits=5, meanQ=1.396020, numObservations: 3
action: 3
Next state: 0 0.550032 0.864415 0.537231 0.867357 0.845433 0.0321607 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=6073, meanQ=4.795922, numObservations: 5
action 0, numVisits=142, meanQ=4.312700, numObservations: 1
action -1, numVisits=74, meanQ=4.125662, numObservations: 1
action 2, numVisits=45, meanQ=3.561558, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
Sampled 2992 episodes
GETTING ACTION FROM:
action 1, numVisits=6073, meanQ=4.795922, numObservations: 5
action 2, numVisits=45, meanQ=3.561558, numObservations: 4
action 0, numVisits=1998, meanQ=0.153847, numObservations: 1
action -1, numVisits=1210, meanQ=0.147482, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.550032 0.864415 0.537231 0.867357 0.845433 0.0321607 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 71
Initial state: 0 0.698483 0.845914 0.532881 0.894995 0.0993324 0.586689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53796 episodes
GETTING ACTION FROM:
action 2, numVisits=53788, meanQ=4.974553, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 2
Next state: 0 0.698483 0.845914 0.532881 0.894995 0.0993324 0.586689 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3807, meanQ=5.417755, numObservations: 3
action 1, numVisits=232, meanQ=4.719048, numObservations: 4
action 3, numVisits=6, meanQ=2.333350, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 66408 episodes
GETTING ACTION FROM:
action 3, numVisits=66410, meanQ=6.027252, numObservations: 4
action 2, numVisits=3807, meanQ=5.417755, numObservations: 3
action 1, numVisits=232, meanQ=4.719048, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 3
Next state: 0 0.698483 0.845914 0.532881 0.894995 0.0993324 0.586689 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=820, meanQ=8.484866, numObservations: 3
action 2, numVisits=20, meanQ=6.994000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9803 episodes
GETTING ACTION FROM:
action 1, numVisits=987, meanQ=8.020770, numObservations: 3
action 2, numVisits=45, meanQ=5.441778, numObservations: 3
action -1, numVisits=9525, meanQ=-1.656592, numObservations: 1
action 0, numVisits=87, meanQ=-2.396407, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 1
Next state: 1 0.698483 0.845914 0.532881 0.894995 0.0993324 0.586689 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 72
Initial state: 0 0.792915 0.5974 0.689412 0.806076 0.53201 0.894397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53375 episodes
GETTING ACTION FROM:
action 1, numVisits=53284, meanQ=4.899553, numObservations: 3
action 0, numVisits=86, meanQ=4.179031, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.792915 0.5974 0.689412 0.806076 0.53201 0.894397 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3957, meanQ=5.184904, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2253 episodes
GETTING ACTION FROM:
action 1, numVisits=3957, meanQ=5.184904, numObservations: 3
action 2, numVisits=15, meanQ=4.599340, numObservations: 4
action 3, numVisits=10, meanQ=2.499000, numObservations: 3
action 0, numVisits=2226, meanQ=0.398059, numObservations: 1
action -1, numVisits=6, meanQ=-66.066808, numObservations: 1
action: 1
Next state: 2 0.792915 0.5974 0.689412 0.806076 0.53201 0.894397 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 73
Initial state: 0 0.00543124 0.784042 0.662054 0.857098 0.676056 0.826437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54361 episodes
GETTING ACTION FROM:
action 2, numVisits=54351, meanQ=5.027511, numObservations: 5
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 2
Next state: 1 0.00543124 0.784042 0.662054 0.857098 0.676056 0.826437 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 74
Initial state: 0 0.634538 0.826529 0.561869 0.889887 0.0427762 0.635075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53172 episodes
GETTING ACTION FROM:
action 2, numVisits=53155, meanQ=4.940444, numObservations: 4
action 3, numVisits=12, meanQ=1.998333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.634538 0.826529 0.561869 0.889887 0.0427762 0.635075 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 75
Initial state: 0 0.309473 0.0735663 0.659118 0.811499 0.622381 0.862105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47477 episodes
GETTING ACTION FROM:
action 3, numVisits=37961, meanQ=4.885974, numObservations: 5
action 0, numVisits=9510, meanQ=3.080247, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.309473 0.0735663 0.659118 0.811499 0.622381 0.862105 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2917, meanQ=4.576237, numObservations: 4
action 1, numVisits=4, meanQ=-0.504975, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67394 episodes
GETTING ACTION FROM:
action 2, numVisits=70307, meanQ=5.825047, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=4, meanQ=-0.504975, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.309473 0.0735663 0.659118 0.811499 0.622381 0.862105 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 76
Initial state: 0 0.789021 0.00584723 0.564413 0.845688 0.67235 0.801439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53752 episodes
GETTING ACTION FROM:
action 3, numVisits=53744, meanQ=4.999563, numObservations: 5
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.789021 0.00584723 0.564413 0.845688 0.67235 0.801439 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 77
Initial state: 0 0.608638 0.803758 0.0789159 0.430701 0.536066 0.807997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51892 episodes
GETTING ACTION FROM:
action 2, numVisits=51830, meanQ=4.808045, numObservations: 3
action -1, numVisits=37, meanQ=3.658043, numObservations: 1
action 3, numVisits=22, meanQ=3.226832, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.608638 0.803758 0.0789159 0.430701 0.536066 0.807997 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8281, meanQ=8.321195, numObservations: 3
action 1, numVisits=91, meanQ=7.675165, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6881 episodes
GETTING ACTION FROM:
action 3, numVisits=8281, meanQ=8.321195, numObservations: 3
action 1, numVisits=91, meanQ=7.675165, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action 0, numVisits=6878, meanQ=0.313790, numObservations: 1
action -1, numVisits=4, meanQ=-97.803487, numObservations: 1
action: 3
Next state: 1 0.608638 0.803758 0.0789159 0.430701 0.536066 0.807997 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 78
Initial state: 0 0.628386 0.863561 0.62465 0.808566 0.417235 0.133326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52908 episodes
GETTING ACTION FROM:
action 3, numVisits=20620, meanQ=5.073942, numObservations: 4
action 2, numVisits=32282, meanQ=4.834573, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.628386 0.863561 0.62465 0.808566 0.417235 0.133326 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2346, meanQ=8.533879, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1876 episodes
GETTING ACTION FROM:
action 1, numVisits=2346, meanQ=8.533879, numObservations: 3
action 3, numVisits=2, meanQ=0.950000, numObservations: 1
action 0, numVisits=1480, meanQ=0.353919, numObservations: 1
action -1, numVisits=395, meanQ=0.007545, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 1
Next state: 1 0.628386 0.863561 0.62465 0.808566 0.417235 0.133326 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 79
Initial state: 0 0.599493 0.800765 0.687886 0.821316 0.750054 0.541748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53082 episodes
GETTING ACTION FROM:
action 2, numVisits=53029, meanQ=4.906724, numObservations: 3
action 0, numVisits=40, meanQ=3.792187, numObservations: 1
action 3, numVisits=5, meanQ=1.198020, numObservations: 2
action 1, numVisits=6, meanQ=0.166667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.599493 0.800765 0.687886 0.821316 0.750054 0.541748 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 80
Initial state: 0 0.651686 0.849742 0.325595 0.755895 0.50275 0.884098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54344 episodes
GETTING ACTION FROM:
action 1, numVisits=54234, meanQ=4.980534, numObservations: 4
action 0, numVisits=105, meanQ=2.299718, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.651686 0.849742 0.325595 0.755895 0.50275 0.884098 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 81
Initial state: 0 0.500084 0.806908 0.380928 0.955827 0.553439 0.81127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54654 episodes
GETTING ACTION FROM:
action 1, numVisits=54640, meanQ=5.003548, numObservations: 5
action 3, numVisits=8, meanQ=2.127512, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 1
Next state: 1 0.500084 0.806908 0.380928 0.955827 0.553439 0.81127 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 82
Initial state: 0 0.608142 0.872062 0.180323 0.53332 0.500388 0.806379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31852 episodes
GETTING ACTION FROM:
action 0, numVisits=31835, meanQ=2.953216, numObservations: 1
action 2, numVisits=8, meanQ=-0.125000, numObservations: 3
action 1, numVisits=5, meanQ=-0.200000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 0
Next state: 0 0.608142 0.872062 0.180323 0.53332 0.500388 0.806379 w: 1
Observation: 0 0 0.896002 0 0.631843 0 0.786089 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31769, meanQ=4.981257, numObservations: 5
action 0, numVisits=44, meanQ=4.027111, numObservations: 1
action 2, numVisits=17, meanQ=2.644706, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 54008 episodes
GETTING ACTION FROM:
action 1, numVisits=85774, meanQ=4.994715, numObservations: 5
action 0, numVisits=47, meanQ=4.013900, numObservations: 1
action 2, numVisits=17, meanQ=2.644706, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.608142 0.872062 0.180323 0.53332 0.500388 0.806379 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 83
Initial state: 0 0.540435 0.256849 0.502337 0.84838 0.639671 0.885222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49587 episodes
GETTING ACTION FROM:
action 1, numVisits=48525, meanQ=4.858879, numObservations: 4
action 0, numVisits=1006, meanQ=2.702294, numObservations: 1
action -1, numVisits=54, meanQ=2.147386, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.540435 0.256849 0.502337 0.84838 0.639671 0.885222 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6736, meanQ=8.417007, numObservations: 5
action 3, numVisits=18, meanQ=6.887783, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 4153 episodes
GETTING ACTION FROM:
action 2, numVisits=6736, meanQ=8.417007, numObservations: 5
action 3, numVisits=18, meanQ=6.887783, numObservations: 3
action 0, numVisits=2497, meanQ=0.298370, numObservations: 1
action -1, numVisits=1658, meanQ=0.236158, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.540435 0.256849 0.502337 0.84838 0.639671 0.885222 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 84
Initial state: 0 0.6551 0.827055 0.286473 0.581714 0.500908 0.80603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54329 episodes
GETTING ACTION FROM:
action 2, numVisits=54318, meanQ=5.053883, numObservations: 4
action 3, numVisits=6, meanQ=2.333333, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.6551 0.827055 0.286473 0.581714 0.500908 0.80603 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8801, meanQ=8.299854, numObservations: 3
action 3, numVisits=314, meanQ=8.014808, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6781 episodes
GETTING ACTION FROM:
action 1, numVisits=8801, meanQ=8.299854, numObservations: 3
action 3, numVisits=314, meanQ=8.014808, numObservations: 4
action -1, numVisits=5302, meanQ=0.196598, numObservations: 1
action 0, numVisits=1480, meanQ=0.118453, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 1
Next state: 1 0.6551 0.827055 0.286473 0.581714 0.500908 0.80603 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 85
Initial state: 0 0.67251 0.884615 0.616487 0.815039 0.504047 0.314868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53831 episodes
GETTING ACTION FROM:
action 1, numVisits=53823, meanQ=4.926360, numObservations: 5
action 3, numVisits=3, meanQ=0.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.67251 0.884615 0.616487 0.815039 0.504047 0.314868 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 86
Initial state: 0 0.641019 0.862801 0.191887 0.293172 0.53056 0.819751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54016 episodes
GETTING ACTION FROM:
action 2, numVisits=53952, meanQ=5.034128, numObservations: 4
action 1, numVisits=38, meanQ=3.971321, numObservations: 4
action 0, numVisits=23, meanQ=3.622042, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 2 0.641019 0.862801 0.191887 0.293172 0.53056 0.819751 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 87
Initial state: 0 0.642286 0.867601 0.692603 0.825925 0.114513 0.125632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54240 episodes
GETTING ACTION FROM:
action 2, numVisits=53844, meanQ=4.987874, numObservations: 4
action 3, numVisits=307, meanQ=4.565658, numObservations: 4
action 0, numVisits=61, meanQ=4.120349, numObservations: 1
action -1, numVisits=26, meanQ=3.648663, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.642286 0.867601 0.692603 0.825925 0.114513 0.125632 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 88
Initial state: 0 0.58739 0.809201 0.638086 0.808566 0.288455 0.0651225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54129 episodes
GETTING ACTION FROM:
action 2, numVisits=54115, meanQ=4.950583, numObservations: 4
action 3, numVisits=7, meanQ=1.428571, numObservations: 2
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.58739 0.809201 0.638086 0.808566 0.288455 0.0651225 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 89
Initial state: 0 0.572839 0.838302 0.257105 0.875305 0.565239 0.817468 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54472 episodes
GETTING ACTION FROM:
action 1, numVisits=54427, meanQ=4.865864, numObservations: 4
action -1, numVisits=30, meanQ=3.090889, numObservations: 1
action 2, numVisits=11, meanQ=2.362745, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.572839 0.838302 0.257105 0.875305 0.565239 0.817468 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3368, meanQ=4.057789, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 61070 episodes
GETTING ACTION FROM:
action 1, numVisits=61069, meanQ=4.897167, numObservations: 5
action 2, numVisits=3368, meanQ=4.057789, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.572839 0.838302 0.257105 0.875305 0.565239 0.817468 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 90
Initial state: 0 0.58714 0.87093 0.19486 0.622858 0.618004 0.829788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54275 episodes
GETTING ACTION FROM:
action 1, numVisits=54251, meanQ=4.985714, numObservations: 5
action -1, numVisits=14, meanQ=3.195449, numObservations: 1
action 3, numVisits=7, meanQ=2.285729, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.58714 0.87093 0.19486 0.622858 0.618004 0.829788 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 91
Initial state: 0 0.498585 0.424852 0.584171 0.807666 0.649338 0.856904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53856 episodes
GETTING ACTION FROM:
action 3, numVisits=53488, meanQ=4.994712, numObservations: 5
action -1, numVisits=351, meanQ=0.548619, numObservations: 1
action 1, numVisits=11, meanQ=-0.817255, numObservations: 3
action 2, numVisits=4, meanQ=-2.500000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.498585 0.424852 0.584171 0.807666 0.649338 0.856904 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 92
Initial state: 0 0.854063 0.0262166 0.635075 0.835298 0.596905 0.882442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31867 episodes
GETTING ACTION FROM:
action -1, numVisits=31294, meanQ=2.912661, numObservations: 1
action 0, numVisits=567, meanQ=2.664764, numObservations: 1
action 3, numVisits=4, meanQ=-2.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.854063 0.0262166 0.635075 0.835298 0.596905 0.882442 w: 1
Observation: 0 0.903545 0 0.559797 0 0.562 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31286, meanQ=4.956426, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55863 episodes
GETTING ACTION FROM:
action 3, numVisits=41317, meanQ=5.169846, numObservations: 5
action 1, numVisits=45830, meanQ=4.836891, numObservations: 3
action 2, numVisits=5, meanQ=-1.600000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.854063 0.0262166 0.635075 0.835298 0.596905 0.882442 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 93
Initial state: 0 0.585658 0.861499 0.590096 0.860368 0.658547 0.662888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51893 episodes
GETTING ACTION FROM:
action 1, numVisits=51887, meanQ=4.871550, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.585658 0.861499 0.590096 0.860368 0.658547 0.662888 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 94
Initial state: 0 0.225157 0.755164 0.576803 0.809556 0.518793 0.85495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52345 episodes
GETTING ACTION FROM:
action 1, numVisits=49542, meanQ=5.003636, numObservations: 4
action -1, numVisits=2796, meanQ=2.878187, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.225157 0.755164 0.576803 0.809556 0.518793 0.85495 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 95
Initial state: 0 0.989837 0.633106 0.610648 0.817506 0.562703 0.80091 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54509 episodes
GETTING ACTION FROM:
action 2, numVisits=54430, meanQ=5.039881, numObservations: 3
action -1, numVisits=52, meanQ=4.100494, numObservations: 1
action 3, numVisits=21, meanQ=2.951919, numObservations: 4
action 1, numVisits=4, meanQ=1.755025, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.989837 0.633106 0.610648 0.817506 0.562703 0.80091 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 96
Initial state: 0 0.660368 0.875123 0.195609 0.712977 0.516103 0.816855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30936 episodes
GETTING ACTION FROM:
action -1, numVisits=30900, meanQ=2.790105, numObservations: 1
action 1, numVisits=22, meanQ=1.135918, numObservations: 3
action 2, numVisits=9, meanQ=0.667800, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action: -1
Next state: 0 0.660368 0.875123 0.195609 0.712977 0.516103 0.816855 w: 1
Observation: 0 0.757691 0 0.264062 0 0.5905 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=30893, meanQ=4.827677, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 52484 episodes
GETTING ACTION FROM:
action 1, numVisits=82303, meanQ=4.986408, numObservations: 3
action 3, numVisits=728, meanQ=4.602930, numObservations: 4
action 2, numVisits=348, meanQ=4.479177, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.660368 0.875123 0.195609 0.712977 0.516103 0.816855 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 97
Initial state: 0 0.597546 0.861568 0.635458 0.0121121 0.629459 0.897745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54237 episodes
GETTING ACTION FROM:
action 3, numVisits=54126, meanQ=4.997851, numObservations: 4
action -1, numVisits=58, meanQ=4.083322, numObservations: 1
action 1, numVisits=35, meanQ=3.667429, numObservations: 4
action 2, numVisits=16, meanQ=3.295006, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.597546 0.861568 0.635458 0.0121121 0.629459 0.897745 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 98
Initial state: 0 0.653993 0.87078 0.604174 0.81096 0.457761 0.193725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54306 episodes
GETTING ACTION FROM:
action 1, numVisits=54296, meanQ=4.959234, numObservations: 5
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.653993 0.87078 0.604174 0.81096 0.457761 0.193725 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 99
Initial state: 0 0.630324 0.850211 0.229835 0.612347 0.5308 0.80911 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54030 episodes
GETTING ACTION FROM:
action 2, numVisits=54014, meanQ=4.967027, numObservations: 5
action 3, numVisits=10, meanQ=0.504020, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.630324 0.850211 0.229835 0.612347 0.5308 0.80911 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6118, meanQ=8.497592, numObservations: 3
action 3, numVisits=12, meanQ=6.832508, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2479 episodes
GETTING ACTION FROM:
action 1, numVisits=6160, meanQ=8.490484, numObservations: 4
action 3, numVisits=62, meanQ=5.677260, numObservations: 4
action 0, numVisits=2383, meanQ=-0.006290, numObservations: 2
action -1, numVisits=6, meanQ=-3.151765, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.630324 0.850211 0.229835 0.612347 0.5308 0.80911 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 100
Initial state: 0 0.494278 0.501145 0.609153 0.883068 0.690991 0.813398 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54174 episodes
GETTING ACTION FROM:
action 3, numVisits=54167, meanQ=4.979284, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.494278 0.501145 0.609153 0.883068 0.690991 0.813398 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 101
Initial state: 0 0.742887 0.486635 0.632768 0.833908 0.696287 0.83146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54342 episodes
GETTING ACTION FROM:
action 1, numVisits=54254, meanQ=5.080927, numObservations: 5
action 0, numVisits=84, meanQ=4.356778, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.742887 0.486635 0.632768 0.833908 0.696287 0.83146 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3448, meanQ=6.186183, numObservations: 4
action 2, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1860 episodes
GETTING ACTION FROM:
action 1, numVisits=3448, meanQ=6.186183, numObservations: 4
action 2, numVisits=30, meanQ=4.966673, numObservations: 3
action 0, numVisits=1830, meanQ=0.191525, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action -1, numVisits=4, meanQ=-97.803236, numObservations: 1
action: 1
Next state: 2 0.742887 0.486635 0.632768 0.833908 0.696287 0.83146 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 102
Initial state: 0 0.674622 0.804371 0.680877 0.896613 0.547389 0.455143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54418 episodes
GETTING ACTION FROM:
action 2, numVisits=54334, meanQ=5.004741, numObservations: 4
action -1, numVisits=56, meanQ=4.144415, numObservations: 1
action 3, numVisits=25, meanQ=3.360012, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.674622 0.804371 0.680877 0.896613 0.547389 0.455143 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 103
Initial state: 0 0.568507 0.891857 0.663878 0.895401 0.938276 0.67906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54700 episodes
GETTING ACTION FROM:
action 2, numVisits=54620, meanQ=5.089002, numObservations: 5
action 0, numVisits=33, meanQ=3.922158, numObservations: 1
action -1, numVisits=22, meanQ=3.539928, numObservations: 1
action 1, numVisits=16, meanQ=3.311256, numObservations: 4
action 3, numVisits=9, meanQ=2.113344, numObservations: 3
action: 2
Next state: 1 0.568507 0.891857 0.663878 0.895401 0.938276 0.67906 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 104
Initial state: 0 0.555884 0.810232 0.51254 0.802911 0.848601 0.690844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30523 episodes
GETTING ACTION FROM:
action -1, numVisits=30512, meanQ=2.750513, numObservations: 1
action 3, numVisits=4, meanQ=-0.999975, numObservations: 2
action 1, numVisits=4, meanQ=-2.749975, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: -1
Next state: 0 0.555884 0.810232 0.51254 0.802911 0.848601 0.690844 w: 1
Observation: 0 0.636351 0 0.590951 0 0.789126 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=30505, meanQ=4.774057, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 51723 episodes
GETTING ACTION FROM:
action 1, numVisits=82185, meanQ=4.805895, numObservations: 5
action -1, numVisits=37, meanQ=3.692540, numObservations: 1
action 2, numVisits=8, meanQ=0.873750, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.555884 0.810232 0.51254 0.802911 0.848601 0.690844 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 105
Initial state: 0 0.0203123 0.615098 0.630819 0.839067 0.677416 0.803363 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54243 episodes
GETTING ACTION FROM:
action 3, numVisits=54177, meanQ=5.018304, numObservations: 4
action 0, numVisits=61, meanQ=4.175251, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.0203123 0.615098 0.630819 0.839067 0.677416 0.803363 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 106
Initial state: 0 0.631551 0.856657 0.47806 0.46631 0.650042 0.849847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54099 episodes
GETTING ACTION FROM:
action 1, numVisits=53984, meanQ=4.895556, numObservations: 5
action 2, numVisits=101, meanQ=3.962581, numObservations: 3
action 3, numVisits=10, meanQ=2.499000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.631551 0.856657 0.47806 0.46631 0.650042 0.849847 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 107
Initial state: 0 0.526966 0.806373 0.258934 0.285989 0.678295 0.806301 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54447 episodes
GETTING ACTION FROM:
action 3, numVisits=54399, meanQ=5.084924, numObservations: 3
action -1, numVisits=44, meanQ=4.081234, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.526966 0.806373 0.258934 0.285989 0.678295 0.806301 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 108
Initial state: 0 0.825096 0.526184 0.509853 0.880865 0.686259 0.898758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53229 episodes
GETTING ACTION FROM:
action 1, numVisits=53105, meanQ=4.895308, numObservations: 5
action -1, numVisits=100, meanQ=4.202986, numObservations: 1
action 2, numVisits=21, meanQ=3.034295, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.825096 0.526184 0.509853 0.880865 0.686259 0.898758 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 109
Initial state: 0 0.668686 0.837394 0.632664 0.81616 0.867613 0.962077 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54340 episodes
GETTING ACTION FROM:
action 3, numVisits=54270, meanQ=5.005330, numObservations: 3
action 0, numVisits=66, meanQ=4.188436, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.668686 0.837394 0.632664 0.81616 0.867613 0.962077 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 110
Initial state: 0 0.411094 0.572786 0.577352 0.815978 0.608685 0.812941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54166 episodes
GETTING ACTION FROM:
action 1, numVisits=53902, meanQ=5.002901, numObservations: 4
action -1, numVisits=143, meanQ=4.459459, numObservations: 1
action 0, numVisits=96, meanQ=4.339857, numObservations: 1
action 2, numVisits=24, meanQ=2.113754, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.411094 0.572786 0.577352 0.815978 0.608685 0.812941 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 111
Initial state: 0 0.654904 0.841225 0.740515 0.673858 0.534143 0.835082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31643 episodes
GETTING ACTION FROM:
action 0, numVisits=31636, meanQ=3.196928, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.654904 0.841225 0.740515 0.673858 0.534143 0.835082 w: 1
Observation: 0 0 0.851595 0 0.671784 0 0.77839 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=26499, meanQ=4.285034, numObservations: 4
action -1, numVisits=49, meanQ=3.410258, numObservations: 1
action 3, numVisits=8, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55808 episodes
GETTING ACTION FROM:
action 1, numVisits=82306, meanQ=4.796714, numObservations: 4
action -1, numVisits=49, meanQ=3.410258, numObservations: 1
action 3, numVisits=8, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 1
Next state: 1 0.654904 0.841225 0.740515 0.673858 0.534143 0.835082 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 112
Initial state: 0 0.567551 0.886246 0.340453 0.349996 0.655871 0.845245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54926 episodes
GETTING ACTION FROM:
action 3, numVisits=54916, meanQ=5.003374, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.567551 0.886246 0.340453 0.349996 0.655871 0.845245 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4237, meanQ=5.586184, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 60662 episodes
GETTING ACTION FROM:
action 3, numVisits=64892, meanQ=5.499524, numObservations: 5
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-2.663300, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action: 3
Next state: 1 0.567551 0.886246 0.340453 0.349996 0.655871 0.845245 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 113
Initial state: 0 0.921186 0.154438 0.503086 0.860071 0.521509 0.809675 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54640 episodes
GETTING ACTION FROM:
action 3, numVisits=54633, meanQ=4.999674, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.921186 0.154438 0.503086 0.860071 0.521509 0.809675 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 114
Initial state: 0 0.118571 0.568415 0.511543 0.867374 0.595359 0.853968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51818 episodes
GETTING ACTION FROM:
action 2, numVisits=51811, meanQ=5.038070, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.118571 0.568415 0.511543 0.867374 0.595359 0.853968 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 115
Initial state: 0 0.475716 0.157394 0.635441 0.81985 0.635679 0.869813 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54032 episodes
GETTING ACTION FROM:
action 1, numVisits=53780, meanQ=5.036926, numObservations: 3
action 3, numVisits=148, meanQ=4.446268, numObservations: 4
action 0, numVisits=69, meanQ=4.250684, numObservations: 1
action -1, numVisits=32, meanQ=3.860460, numObservations: 1
action 2, numVisits=3, meanQ=0.000033, numObservations: 2
action: 1
Next state: 0 0.475716 0.157394 0.635441 0.81985 0.635679 0.869813 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8842, meanQ=8.319288, numObservations: 3
action 3, numVisits=40, meanQ=7.300008, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3451 episodes
GETTING ACTION FROM:
action 2, numVisits=8842, meanQ=8.319288, numObservations: 3
action 3, numVisits=40, meanQ=7.300008, numObservations: 3
action 1, numVisits=13, meanQ=6.223077, numObservations: 4
action -1, numVisits=3429, meanQ=-0.071680, numObservations: 1
action 0, numVisits=12, meanQ=-2.000825, numObservations: 1
action: 2
Next state: 1 0.475716 0.157394 0.635441 0.81985 0.635679 0.869813 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 116
Initial state: 0 0.070232 0.897861 0.587709 0.855922 0.528787 0.847143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51519 episodes
GETTING ACTION FROM:
action 1, numVisits=51508, meanQ=4.947456, numObservations: 3
action 3, numVisits=6, meanQ=1.498333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.070232 0.897861 0.587709 0.855922 0.528787 0.847143 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8464, meanQ=8.294979, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 4175 episodes
GETTING ACTION FROM:
action 2, numVisits=8464, meanQ=8.294979, numObservations: 4
action 3, numVisits=5, meanQ=0.998040, numObservations: 3
action 0, numVisits=4166, meanQ=0.286313, numObservations: 1
action -1, numVisits=7, meanQ=-2.001414, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 2
Next state: 1 0.070232 0.897861 0.587709 0.855922 0.528787 0.847143 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 117
Initial state: 0 0.603632 0.814907 0.626244 0.818043 0.949892 0.0399566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54175 episodes
GETTING ACTION FROM:
action 3, numVisits=54086, meanQ=4.955450, numObservations: 5
action 1, numVisits=82, meanQ=3.621375, numObservations: 4
action 2, numVisits=3, meanQ=0.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.603632 0.814907 0.626244 0.818043 0.949892 0.0399566 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 118
Initial state: 0 0.509151 0.84381 0.633348 0.882437 0.995094 0.113814 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31799 episodes
GETTING ACTION FROM:
action 0, numVisits=31790, meanQ=2.829377, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 0
Next state: 0 0.509151 0.84381 0.633348 0.882437 0.995094 0.113814 w: 1
Observation: 0 0 0.782248 0 0.971094 0 0.164291 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31764, meanQ=4.933450, numObservations: 5
action 3, numVisits=13, meanQ=2.816923, numObservations: 4
action 1, numVisits=8, meanQ=2.012500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 54326 episodes
GETTING ACTION FROM:
action 2, numVisits=86088, meanQ=4.899080, numObservations: 5
action 3, numVisits=13, meanQ=2.816923, numObservations: 4
action -1, numVisits=3, meanQ=0.966700, numObservations: 1
action 1, numVisits=9, meanQ=0.566667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.509151 0.84381 0.633348 0.882437 0.995094 0.113814 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 119
Initial state: 0 0.582184 0.866114 0.699035 0.849435 0.641074 0.371769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 44794 episodes
GETTING ACTION FROM:
action 1, numVisits=30915, meanQ=5.063297, numObservations: 5
action -1, numVisits=13847, meanQ=2.974486, numObservations: 1
action 3, numVisits=29, meanQ=1.688972, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.582184 0.866114 0.699035 0.849435 0.641074 0.371769 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 120
Initial state: 0 0.699015 0.815002 0.544018 0.805785 0.413567 0.00811241 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54037 episodes
GETTING ACTION FROM:
action 2, numVisits=53960, meanQ=4.900962, numObservations: 5
action 3, numVisits=70, meanQ=3.159716, numObservations: 3
action 1, numVisits=3, meanQ=0.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.699015 0.815002 0.544018 0.805785 0.413567 0.00811241 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 121
Initial state: 0 0.64474 0.816423 0.572621 0.820676 0.575263 0.774059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54599 episodes
GETTING ACTION FROM:
action 1, numVisits=54591, meanQ=4.977263, numObservations: 5
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.64474 0.816423 0.572621 0.820676 0.575263 0.774059 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 122
Initial state: 0 0.608956 0.847985 0.518709 0.485362 0.624054 0.875831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54088 episodes
GETTING ACTION FROM:
action 3, numVisits=52325, meanQ=5.022346, numObservations: 5
action 2, numVisits=1757, meanQ=4.814803, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.608956 0.847985 0.518709 0.485362 0.624054 0.875831 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 123
Initial state: 0 0.694834 0.894697 0.481505 0.566195 0.563108 0.888258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54507 episodes
GETTING ACTION FROM:
action 1, numVisits=54488, meanQ=5.047105, numObservations: 4
action 3, numVisits=13, meanQ=2.455392, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.694834 0.894697 0.481505 0.566195 0.563108 0.888258 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 124
Initial state: 0 0.502569 0.90173 0.664268 0.802363 0.649381 0.872602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50017 episodes
GETTING ACTION FROM:
action 2, numVisits=46702, meanQ=4.856877, numObservations: 5
action -1, numVisits=3103, meanQ=2.924332, numObservations: 1
action 0, numVisits=200, meanQ=2.620392, numObservations: 1
action 1, numVisits=10, meanQ=0.399010, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.502569 0.90173 0.664268 0.802363 0.649381 0.872602 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 125
Initial state: 0 0.862145 0.0121754 0.682761 0.895755 0.664342 0.866164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54588 episodes
GETTING ACTION FROM:
action 2, numVisits=54570, meanQ=5.028066, numObservations: 5
action 3, numVisits=7, meanQ=1.428571, numObservations: 4
action 1, numVisits=7, meanQ=1.401429, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.862145 0.0121754 0.682761 0.895755 0.664342 0.866164 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 126
Initial state: 0 0.591747 0.814329 0.735457 0.522567 0.699178 0.858035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54209 episodes
GETTING ACTION FROM:
action 2, numVisits=54030, meanQ=4.961304, numObservations: 5
action -1, numVisits=98, meanQ=4.297541, numObservations: 1
action 0, numVisits=69, meanQ=4.159490, numObservations: 1
action 3, numVisits=11, meanQ=2.272745, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.591747 0.814329 0.735457 0.522567 0.699178 0.858035 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 127
Initial state: 0 0.643216 0.878342 0.560435 0.808412 0.0302777 0.470452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54095 episodes
GETTING ACTION FROM:
action 1, numVisits=54033, meanQ=5.019365, numObservations: 5
action 3, numVisits=51, meanQ=4.066671, numObservations: 5
action 2, numVisits=7, meanQ=2.428571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.643216 0.878342 0.560435 0.808412 0.0302777 0.470452 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 128
Initial state: 0 0.420258 0.975172 0.619433 0.892799 0.571037 0.862902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54286 episodes
GETTING ACTION FROM:
action 3, numVisits=54199, meanQ=4.944654, numObservations: 5
action 0, numVisits=80, meanQ=4.191321, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.420258 0.975172 0.619433 0.892799 0.571037 0.862902 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 129
Initial state: 0 0.39814 0.244348 0.618539 0.805374 0.563214 0.811762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31114 episodes
GETTING ACTION FROM:
action 0, numVisits=31094, meanQ=2.778317, numObservations: 1
action 3, numVisits=11, meanQ=0.180000, numObservations: 4
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 1, numVisits=4, meanQ=-2.500000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 0
Next state: 0 0.39814 0.244348 0.618539 0.805374 0.563214 0.811762 w: 1
Observation: 0 0 0.22796 0 0.709869 0 0.736921 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31085, meanQ=4.882871, numObservations: 5
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 53029 episodes
GETTING ACTION FROM:
action 1, numVisits=84099, meanQ=4.849214, numObservations: 5
action 3, numVisits=13, meanQ=2.470777, numObservations: 4
action 2, numVisits=6, meanQ=0.331667, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.39814 0.244348 0.618539 0.805374 0.563214 0.811762 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 130
Initial state: 0 0.412143 0.628498 0.666687 0.810471 0.583761 0.863853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54087 episodes
GETTING ACTION FROM:
action 3, numVisits=54080, meanQ=5.004243, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-4.499950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.412143 0.628498 0.666687 0.810471 0.583761 0.863853 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 131
Initial state: 0 0.502821 0.882649 0.562258 0.827019 0.431068 0.616646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54225 episodes
GETTING ACTION FROM:
action 3, numVisits=54137, meanQ=4.970424, numObservations: 5
action 0, numVisits=68, meanQ=4.188730, numObservations: 1
action 2, numVisits=17, meanQ=1.999418, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.502821 0.882649 0.562258 0.827019 0.431068 0.616646 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 132
Initial state: 0 0.817673 0.43893 0.553182 0.854687 0.605399 0.876352 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53860 episodes
GETTING ACTION FROM:
action 1, numVisits=53841, meanQ=4.927136, numObservations: 4
action -1, numVisits=9, meanQ=2.730000, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.817673 0.43893 0.553182 0.854687 0.605399 0.876352 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 133
Initial state: 0 0.522576 0.865596 0.678747 0.857337 0.924783 0.0473463 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54042 episodes
GETTING ACTION FROM:
action 3, numVisits=54020, meanQ=4.986954, numObservations: 5
action 2, numVisits=12, meanQ=1.585008, numObservations: 3
action 1, numVisits=6, meanQ=1.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.522576 0.865596 0.678747 0.857337 0.924783 0.0473463 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 134
Initial state: 0 0.0273985 0.0328001 0.625637 0.809556 0.613722 0.811838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54253 episodes
GETTING ACTION FROM:
action 1, numVisits=54210, meanQ=4.939149, numObservations: 3
action 0, numVisits=20, meanQ=3.476994, numObservations: 1
action -1, numVisits=14, meanQ=2.939657, numObservations: 1
action 3, numVisits=8, meanQ=0.873750, numObservations: 4
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0273985 0.0328001 0.625637 0.809556 0.613722 0.811838 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4984, meanQ=8.297152, numObservations: 4
action 3, numVisits=3951, meanQ=8.228378, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1873 episodes
GETTING ACTION FROM:
action 2, numVisits=4984, meanQ=8.297152, numObservations: 4
action 3, numVisits=3951, meanQ=8.228378, numObservations: 5
action 1, numVisits=2, meanQ=0.950000, numObservations: 1
action 0, numVisits=1664, meanQ=0.233450, numObservations: 1
action -1, numVisits=210, meanQ=-0.043571, numObservations: 1
action: 2
Next state: 1 0.0273985 0.0328001 0.625637 0.809556 0.613722 0.811838 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 135
Initial state: 0 0.152635 0.482276 0.646351 0.817022 0.547365 0.86803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32056 episodes
GETTING ACTION FROM:
action 0, numVisits=32040, meanQ=2.948914, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=9, meanQ=-1.787778, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.152635 0.482276 0.646351 0.817022 0.547365 0.86803 w: 1
Observation: 0 0 0.454921 0 0.75756 0 0.84318 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32026, meanQ=5.031081, numObservations: 5
action 2, numVisits=6, meanQ=2.333333, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 54866 episodes
GETTING ACTION FROM:
action 1, numVisits=86886, meanQ=5.100805, numObservations: 5
action 2, numVisits=10, meanQ=1.000000, numObservations: 3
action 0, numVisits=3, meanQ=0.966700, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=4, meanQ=-4.002500, numObservations: 2
action: 1
Next state: 0 0.152635 0.482276 0.646351 0.817022 0.547365 0.86803 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=11857, meanQ=8.345576, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2234 episodes
GETTING ACTION FROM:
action 3, numVisits=11857, meanQ=8.345576, numObservations: 5
action 2, numVisits=27, meanQ=5.592222, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=2181, meanQ=0.039010, numObservations: 1
action 0, numVisits=28, meanQ=-1.081421, numObservations: 1
action: 3
Next state: 1 0.152635 0.482276 0.646351 0.817022 0.547365 0.86803 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 136
Initial state: 0 0.643119 0.823218 0.0648814 0.564397 0.556591 0.855794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54132 episodes
GETTING ACTION FROM:
action 2, numVisits=54106, meanQ=4.990723, numObservations: 4
action 1, numVisits=20, meanQ=3.498505, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.643119 0.823218 0.0648814 0.564397 0.556591 0.855794 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8754, meanQ=8.260532, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 18024 episodes
GETTING ACTION FROM:
action 3, numVisits=17094, meanQ=7.131583, numObservations: 4
action 1, numVisits=9672, meanQ=6.013720, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action 0, numVisits=13, meanQ=-31.796330, numObservations: 1
action -1, numVisits=2, meanQ=-197.619169, numObservations: 1
action: 3
Next state: 1 0.643119 0.823218 0.0648814 0.564397 0.556591 0.855794 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 137
Initial state: 0 0.258296 0.638734 0.621344 0.806839 0.516955 0.873631 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31926 episodes
GETTING ACTION FROM:
action 0, numVisits=31918, meanQ=2.856452, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-7.500000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.258296 0.638734 0.621344 0.806839 0.516955 0.873631 w: 1
Observation: 0 0 0.594817 0 0.856014 0 0.960312 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31891, meanQ=4.910889, numObservations: 3
action 2, numVisits=19, meanQ=3.420532, numObservations: 5
action 3, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 54683 episodes
GETTING ACTION FROM:
action 1, numVisits=86545, meanQ=4.987980, numObservations: 3
action 3, numVisits=32, meanQ=3.579691, numObservations: 4
action 2, numVisits=19, meanQ=3.420532, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.258296 0.638734 0.621344 0.806839 0.516955 0.873631 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=14206, meanQ=8.295583, numObservations: 4
action 2, numVisits=6, meanQ=3.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 17634 episodes
GETTING ACTION FROM:
action 3, numVisits=22793, meanQ=7.288220, numObservations: 4
action 2, numVisits=9049, meanQ=5.686319, numObservations: 4
action 1, numVisits=2, meanQ=-6.173169, numObservations: 1
action -1, numVisits=3, meanQ=-132.522855, numObservations: 1
action 0, numVisits=2, meanQ=-197.863802, numObservations: 1
action: 3
Next state: 1 0.258296 0.638734 0.621344 0.806839 0.516955 0.873631 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 138
Initial state: 0 0.386819 0.869761 0.613596 0.888601 0.511806 0.831103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53696 episodes
GETTING ACTION FROM:
action 2, numVisits=49484, meanQ=4.982079, numObservations: 4
action 3, numVisits=4207, meanQ=4.851823, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.386819 0.869761 0.613596 0.888601 0.511806 0.831103 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 139
Initial state: 0 0.209404 0.336997 0.627938 0.884702 0.610396 0.835732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32710 episodes
GETTING ACTION FROM:
action 0, numVisits=32668, meanQ=5.626521, numObservations: 2
action -1, numVisits=26, meanQ=1.811499, numObservations: 1
action 2, numVisits=11, meanQ=1.090918, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 0
Next state: 0 0.209404 0.336997 0.627938 0.884702 0.610396 0.835732 w: 1
Observation: 0 0 0.288889 0 0.916234 0 0.917013 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=21529, meanQ=7.595709, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 52314 episodes
GETTING ACTION FROM:
action 3, numVisits=73840, meanQ=5.356449, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.209404 0.336997 0.627938 0.884702 0.610396 0.835732 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 140
Initial state: 0 0.636616 0.850695 0.537212 0.819189 0.369296 0.995265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54226 episodes
GETTING ACTION FROM:
action 2, numVisits=54170, meanQ=4.954482, numObservations: 3
action 0, numVisits=50, meanQ=4.000030, numObservations: 1
action 3, numVisits=3, meanQ=-0.659967, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.636616 0.850695 0.537212 0.819189 0.369296 0.995265 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 141
Initial state: 0 0.383732 0.792993 0.521729 0.888875 0.679986 0.87096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51620 episodes
GETTING ACTION FROM:
action 1, numVisits=51537, meanQ=4.880725, numObservations: 5
action 0, numVisits=59, meanQ=4.020204, numObservations: 1
action -1, numVisits=10, meanQ=2.058510, numObservations: 1
action 3, numVisits=12, meanQ=1.249183, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 0 0.383732 0.792993 0.521729 0.888875 0.679986 0.87096 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5855, meanQ=8.519782, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3055 episodes
GETTING ACTION FROM:
action 2, numVisits=5855, meanQ=8.519782, numObservations: 3
action 3, numVisits=18, meanQ=4.221672, numObservations: 5
action 0, numVisits=3037, meanQ=0.264903, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action -1, numVisits=2, meanQ=-197.205238, numObservations: 1
action: 2
Next state: 1 0.383732 0.792993 0.521729 0.888875 0.679986 0.87096 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 142
Initial state: 0 0.830334 0.20545 0.678515 0.815594 0.542612 0.833155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54163 episodes
GETTING ACTION FROM:
action 1, numVisits=53864, meanQ=4.989623, numObservations: 4
action 2, numVisits=188, meanQ=4.518041, numObservations: 4
action -1, numVisits=57, meanQ=4.130268, numObservations: 1
action 0, numVisits=53, meanQ=4.064623, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.830334 0.20545 0.678515 0.815594 0.542612 0.833155 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 143
Initial state: 0 0.628209 0.819718 0.690795 0.860186 0.172471 0.74361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53658 episodes
GETTING ACTION FROM:
action 3, numVisits=53626, meanQ=4.985752, numObservations: 5
action -1, numVisits=18, meanQ=3.384427, numObservations: 1
action 1, numVisits=11, meanQ=1.727273, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.628209 0.819718 0.690795 0.860186 0.172471 0.74361 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5283, meanQ=8.413144, numObservations: 4
action 1, numVisits=2344, meanQ=8.370009, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2431 episodes
GETTING ACTION FROM:
action 2, numVisits=5283, meanQ=8.413144, numObservations: 4
action 1, numVisits=2344, meanQ=8.370009, numObservations: 4
action 0, numVisits=2425, meanQ=0.190656, numObservations: 2
action -1, numVisits=7, meanQ=-2.144257, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.628209 0.819718 0.690795 0.860186 0.172471 0.74361 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 144
Initial state: 0 0.625008 0.888001 0.838678 0.743398 0.572761 0.828615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31861 episodes
GETTING ACTION FROM:
action -1, numVisits=31846, meanQ=2.881968, numObservations: 1
action 3, numVisits=9, meanQ=-0.555556, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.625008 0.888001 0.838678 0.743398 0.572761 0.828615 w: 1
Observation: 0 0.59127 0 0.836825 0 0.494117 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31799, meanQ=4.955671, numObservations: 5
action -1, numVisits=41, meanQ=3.926419, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 53755 episodes
GETTING ACTION FROM:
action 1, numVisits=85552, meanQ=4.925833, numObservations: 5
action -1, numVisits=42, meanQ=3.866243, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 1
Next state: 1 0.625008 0.888001 0.838678 0.743398 0.572761 0.828615 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 145
Initial state: 0 0.526887 0.879942 0.645563 0.806827 0.334573 0.275188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54329 episodes
GETTING ACTION FROM:
action 2, numVisits=54293, meanQ=4.985124, numObservations: 4
action 1, numVisits=30, meanQ=3.621000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.489950, numObservations: 1
action: 2
Next state: 1 0.526887 0.879942 0.645563 0.806827 0.334573 0.275188 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 146
Initial state: 0 0.583605 0.843173 0.96704 0.419634 0.597287 0.804162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54148 episodes
GETTING ACTION FROM:
action 3, numVisits=54141, meanQ=4.992410, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.583605 0.843173 0.96704 0.419634 0.597287 0.804162 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 147
Initial state: 0 0.507169 0.804547 0.600831 0.893675 0.921401 0.812063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54002 episodes
GETTING ACTION FROM:
action 1, numVisits=53996, meanQ=4.928578, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.507169 0.804547 0.600831 0.893675 0.921401 0.812063 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 148
Initial state: 0 0.608106 0.851787 0.648495 0.801743 0.744668 0.481801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51833 episodes
GETTING ACTION FROM:
action 3, numVisits=51808, meanQ=4.892834, numObservations: 4
action 2, numVisits=13, meanQ=2.146154, numObservations: 3
action 1, numVisits=8, meanQ=0.873750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.608106 0.851787 0.648495 0.801743 0.744668 0.481801 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 149
Initial state: 0 0.605062 0.816298 0.953572 0.319323 0.659925 0.81806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48092 episodes
GETTING ACTION FROM:
action 3, numVisits=42157, meanQ=4.865216, numObservations: 4
action 0, numVisits=5929, meanQ=3.092064, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.605062 0.816298 0.953572 0.319323 0.659925 0.81806 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 150
Initial state: 0 0.61869 0.870613 0.883835 0.800282 0.529277 0.884123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49857 episodes
GETTING ACTION FROM:
action 3, numVisits=49766, meanQ=4.858747, numObservations: 4
action 0, numVisits=84, meanQ=4.130746, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.61869 0.870613 0.883835 0.800282 0.529277 0.884123 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 151
Initial state: 0 0.584718 0.899325 0.0814722 0.385936 0.52337 0.884096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53859 episodes
GETTING ACTION FROM:
action 3, numVisits=53803, meanQ=4.941305, numObservations: 5
action 0, numVisits=52, meanQ=4.041310, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.584718 0.899325 0.0814722 0.385936 0.52337 0.884096 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 152
Initial state: 0 0.64952 0.86957 0.539552 0.856712 0.402305 0.999149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53995 episodes
GETTING ACTION FROM:
action 2, numVisits=53393, meanQ=4.932713, numObservations: 4
action -1, numVisits=579, meanQ=3.045260, numObservations: 1
action 1, numVisits=19, meanQ=1.367895, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.489950, numObservations: 1
action: 2
Next state: 1 0.64952 0.86957 0.539552 0.856712 0.402305 0.999149 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 153
Initial state: 0 0.149524 0.947069 0.549961 0.864141 0.632579 0.803734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53688 episodes
GETTING ACTION FROM:
action 3, numVisits=53660, meanQ=4.924288, numObservations: 4
action 1, numVisits=22, meanQ=2.999550, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.149524 0.947069 0.549961 0.864141 0.632579 0.803734 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 154
Initial state: 0 0.591482 0.823997 0.156919 0.203683 0.507668 0.818488 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31939 episodes
GETTING ACTION FROM:
action -1, numVisits=28363, meanQ=3.020402, numObservations: 1
action 0, numVisits=3572, meanQ=2.950852, numObservations: 1
action 3, numVisits=2, meanQ=-7.500000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.591482 0.823997 0.156919 0.203683 0.507668 0.818488 w: 1
Observation: 0 0.499235 0 0.0917837 0 0.535708 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=28356, meanQ=5.040108, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54703 episodes
GETTING ACTION FROM:
action 3, numVisits=83055, meanQ=5.156982, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=4, meanQ=-4.497475, numObservations: 3
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.591482 0.823997 0.156919 0.203683 0.507668 0.818488 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 155
Initial state: 0 0.417525 0.0794029 0.554098 0.861349 0.536439 0.898283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52911 episodes
GETTING ACTION FROM:
action 2, numVisits=52865, meanQ=4.872695, numObservations: 4
action 0, numVisits=19, meanQ=3.354342, numObservations: 1
action 1, numVisits=21, meanQ=3.276671, numObservations: 4
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.417525 0.0794029 0.554098 0.861349 0.536439 0.898283 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2374, meanQ=4.662557, numObservations: 4
action -1, numVisits=1524, meanQ=2.594278, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 66858 episodes
GETTING ACTION FROM:
action 1, numVisits=69184, meanQ=5.904630, numObservations: 4
action 3, numVisits=48, meanQ=3.749383, numObservations: 3
action -1, numVisits=1524, meanQ=2.594278, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-3.505000, numObservations: 2
action: 1
Next state: 0 0.417525 0.0794029 0.554098 0.861349 0.536439 0.898283 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1301, meanQ=8.159293, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11628 episodes
GETTING ACTION FROM:
action 2, numVisits=1307, meanQ=8.159541, numObservations: 3
action 3, numVisits=86, meanQ=6.302209, numObservations: 4
action 1, numVisits=7, meanQ=0.428571, numObservations: 2
action -1, numVisits=5874, meanQ=-1.569385, numObservations: 1
action 0, numVisits=5659, meanQ=-1.575068, numObservations: 1
action: 2
Next state: 1 0.417525 0.0794029 0.554098 0.861349 0.536439 0.898283 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 156
Initial state: 0 0.677606 0.846757 0.616944 0.817775 0.571282 0.993166 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54015 episodes
GETTING ACTION FROM:
action 1, numVisits=53884, meanQ=4.915710, numObservations: 4
action -1, numVisits=63, meanQ=4.072847, numObservations: 1
action 0, numVisits=42, meanQ=3.841193, numObservations: 1
action 2, numVisits=25, meanQ=2.000408, numObservations: 3
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.677606 0.846757 0.616944 0.817775 0.571282 0.993166 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 157
Initial state: 0 0.523258 0.818488 0.509742 0.851828 0.428915 0.578932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54352 episodes
GETTING ACTION FROM:
action 2, numVisits=54325, meanQ=5.101731, numObservations: 5
action 1, numVisits=20, meanQ=3.145505, numObservations: 3
action 3, numVisits=3, meanQ=0.000033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.523258 0.818488 0.509742 0.851828 0.428915 0.578932 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 158
Initial state: 0 0.580342 0.815448 0.00867659 0.628284 0.665162 0.802819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54026 episodes
GETTING ACTION FROM:
action 3, numVisits=53905, meanQ=4.934472, numObservations: 4
action -1, numVisits=23, meanQ=3.569511, numObservations: 1
action 1, numVisits=94, meanQ=3.182632, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.580342 0.815448 0.00867659 0.628284 0.665162 0.802819 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 159
Initial state: 0 0.770621 0.243407 0.58836 0.850114 0.660395 0.831083 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54437 episodes
GETTING ACTION FROM:
action 1, numVisits=54430, meanQ=4.963138, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 2 0.770621 0.243407 0.58836 0.850114 0.660395 0.831083 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 160
Initial state: 0 0.628246 0.867643 0.112646 0.768996 0.504975 0.810935 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51517 episodes
GETTING ACTION FROM:
action 1, numVisits=51441, meanQ=4.980653, numObservations: 4
action -1, numVisits=67, meanQ=4.165027, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 3
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.628246 0.867643 0.112646 0.768996 0.504975 0.810935 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=3765, meanQ=4.897818, numObservations: 2
action -1, numVisits=70, meanQ=2.704007, numObservations: 1
action 2, numVisits=12, meanQ=1.331683, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 59241 episodes
GETTING ACTION FROM:
action 1, numVisits=46262, meanQ=4.938118, numObservations: 4
action 0, numVisits=16649, meanQ=1.066086, numObservations: 2
action -1, numVisits=165, meanQ=0.620397, numObservations: 1
action 2, numVisits=15, meanQ=-0.866647, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.628246 0.867643 0.112646 0.768996 0.504975 0.810935 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 161
Initial state: 0 0.58885 0.856079 0.882 0.496729 0.5462 0.848792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54340 episodes
GETTING ACTION FROM:
action 2, numVisits=54324, meanQ=5.020160, numObservations: 5
action -1, numVisits=12, meanQ=3.071770, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.58885 0.856079 0.882 0.496729 0.5462 0.848792 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 162
Initial state: 0 0.598712 0.844818 0.593326 0.811732 0.78059 0.257909 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54249 episodes
GETTING ACTION FROM:
action 1, numVisits=54228, meanQ=5.031759, numObservations: 4
action 2, numVisits=15, meanQ=2.408013, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.598712 0.844818 0.593326 0.811732 0.78059 0.257909 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 163
Initial state: 0 0.699379 0.824328 0.0892413 0.610658 0.619196 0.840729 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54602 episodes
GETTING ACTION FROM:
action 3, numVisits=54534, meanQ=5.029246, numObservations: 5
action -1, numVisits=53, meanQ=3.543298, numObservations: 1
action 2, numVisits=10, meanQ=2.499000, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.699379 0.824328 0.0892413 0.610658 0.619196 0.840729 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 164
Initial state: 0 0.617878 0.87374 0.238839 0.917338 0.598853 0.89576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54229 episodes
GETTING ACTION FROM:
action 1, numVisits=54155, meanQ=4.990416, numObservations: 4
action -1, numVisits=69, meanQ=2.297070, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.617878 0.87374 0.238839 0.917338 0.598853 0.89576 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 165
Initial state: 0 0.27689 0.991088 0.624391 0.822087 0.562012 0.830166 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53772 episodes
GETTING ACTION FROM:
action 2, numVisits=53763, meanQ=4.907938, numObservations: 5
action 3, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.27689 0.991088 0.624391 0.822087 0.562012 0.830166 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1220, meanQ=5.757059, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2522 episodes
GETTING ACTION FROM:
action 1, numVisits=85, meanQ=6.964787, numObservations: 3
action 2, numVisits=1220, meanQ=5.757059, numObservations: 3
action 3, numVisits=14, meanQ=2.427857, numObservations: 3
action -1, numVisits=2405, meanQ=0.156595, numObservations: 1
action 0, numVisits=22, meanQ=-1.145000, numObservations: 1
action: 1
Next state: 0 0.27689 0.991088 0.624391 0.822087 0.562012 0.830166 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=9.000000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 8371 episodes
GETTING ACTION FROM:
action 3, numVisits=585, meanQ=6.341265, numObservations: 4
action 2, numVisits=37, meanQ=3.594595, numObservations: 4
action 1, numVisits=8, meanQ=-1.000000, numObservations: 3
action -1, numVisits=7691, meanQ=-1.647060, numObservations: 1
action 0, numVisits=51, meanQ=-9.484154, numObservations: 1
action: 3
Next state: 1 0.27689 0.991088 0.624391 0.822087 0.562012 0.830166 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 166
Initial state: 0 0.639894 0.810867 0.638572 0.845119 0.0616176 0.0617459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54422 episodes
GETTING ACTION FROM:
action 1, numVisits=54414, meanQ=4.940244, numObservations: 3
action 3, numVisits=3, meanQ=0.000033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.639894 0.810867 0.638572 0.845119 0.0616176 0.0617459 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 167
Initial state: 0 0.564324 0.819033 0.0936288 0.0549336 0.695868 0.859932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52845 episodes
GETTING ACTION FROM:
action 3, numVisits=52779, meanQ=5.005849, numObservations: 5
action -1, numVisits=35, meanQ=3.848450, numObservations: 1
action 0, numVisits=26, meanQ=3.708635, numObservations: 1
action 2, numVisits=4, meanQ=0.750000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.564324 0.819033 0.0936288 0.0549336 0.695868 0.859932 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 168
Initial state: 0 0.571048 0.888979 0.520697 0.875202 0.329135 0.294432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52364 episodes
GETTING ACTION FROM:
action 1, numVisits=52277, meanQ=5.061910, numObservations: 4
action 0, numVisits=82, meanQ=1.812465, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.571048 0.888979 0.520697 0.875202 0.329135 0.294432 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 169
Initial state: 0 0.0807276 0.129693 0.696829 0.811112 0.579461 0.886962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54663 episodes
GETTING ACTION FROM:
action 3, numVisits=54645, meanQ=4.943451, numObservations: 4
action 1, numVisits=13, meanQ=2.922315, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0807276 0.129693 0.696829 0.811112 0.579461 0.886962 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 170
Initial state: 0 0.511346 0.803619 0.503184 0.899901 0.345892 0.602678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53354 episodes
GETTING ACTION FROM:
action 1, numVisits=53311, meanQ=4.880146, numObservations: 4
action 2, numVisits=31, meanQ=2.805813, numObservations: 3
action 3, numVisits=8, meanQ=1.375025, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.511346 0.803619 0.503184 0.899901 0.345892 0.602678 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 171
Initial state: 0 0.693509 0.81094 0.277331 0.373953 0.690672 0.803272 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32023 episodes
GETTING ACTION FROM:
action 0, numVisits=32010, meanQ=3.032370, numObservations: 1
action 3, numVisits=7, meanQ=0.570014, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.693509 0.81094 0.277331 0.373953 0.690672 0.803272 w: 1
Observation: 0 0 0.893731 0 0.344091 0 0.789682 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27052, meanQ=5.039811, numObservations: 5
action 2, numVisits=4833, meanQ=4.904234, numObservations: 3
action 0, numVisits=87, meanQ=4.365732, numObservations: 1
action -1, numVisits=32, meanQ=3.836124, numObservations: 1
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
Sampled 54429 episodes
GETTING ACTION FROM:
action 1, numVisits=80218, meanQ=4.855666, numObservations: 5
action 2, numVisits=6081, meanQ=4.790346, numObservations: 3
action 0, numVisits=100, meanQ=4.195725, numObservations: 1
action -1, numVisits=34, meanQ=3.675415, numObservations: 1
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action: 1
Next state: 1 0.693509 0.81094 0.277331 0.373953 0.690672 0.803272 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 172
Initial state: 0 0.54845 0.851602 0.68234 0.895808 0.444861 0.765881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54077 episodes
GETTING ACTION FROM:
action 2, numVisits=53842, meanQ=4.892320, numObservations: 4
action 3, numVisits=126, meanQ=4.292384, numObservations: 5
action 0, numVisits=61, meanQ=4.044686, numObservations: 1
action -1, numVisits=46, meanQ=3.928342, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.54845 0.851602 0.68234 0.895808 0.444861 0.765881 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 173
Initial state: 0 0.0326523 0.167547 0.528941 0.865473 0.586902 0.842116 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52932 episodes
GETTING ACTION FROM:
action 2, numVisits=50984, meanQ=5.042004, numObservations: 5
action -1, numVisits=1944, meanQ=3.053329, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0326523 0.167547 0.528941 0.865473 0.586902 0.842116 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 174
Initial state: 0 0.657032 0.836222 0.252227 0.870588 0.503495 0.859839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54218 episodes
GETTING ACTION FROM:
action 2, numVisits=54171, meanQ=4.965796, numObservations: 3
action 0, numVisits=39, meanQ=3.930482, numObservations: 1
action 3, numVisits=5, meanQ=1.198020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.657032 0.836222 0.252227 0.870588 0.503495 0.859839 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8802, meanQ=8.336356, numObservations: 5
action 3, numVisits=152, meanQ=7.885592, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 7539 episodes
GETTING ACTION FROM:
action 1, numVisits=8802, meanQ=8.336356, numObservations: 5
action 3, numVisits=152, meanQ=7.885592, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=7503, meanQ=0.231491, numObservations: 1
action 0, numVisits=38, meanQ=-1.062366, numObservations: 1
action: 1
Next state: 1 0.657032 0.836222 0.252227 0.870588 0.503495 0.859839 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 175
Initial state: 0 0.0683375 0.113127 0.695751 0.879791 0.630023 0.848554 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53989 episodes
GETTING ACTION FROM:
action 1, numVisits=53621, meanQ=4.935892, numObservations: 4
action -1, numVisits=240, meanQ=3.067196, numObservations: 1
action 0, numVisits=114, meanQ=2.920624, numObservations: 1
action 2, numVisits=11, meanQ=1.271818, numObservations: 3
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action: 1
Next state: 2 0.0683375 0.113127 0.695751 0.879791 0.630023 0.848554 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 176
Initial state: 0 0.376861 0.802423 0.673862 0.847096 0.697516 0.847904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54085 episodes
GETTING ACTION FROM:
action 3, numVisits=53963, meanQ=4.919374, numObservations: 5
action -1, numVisits=113, meanQ=4.288497, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 2, numVisits=3, meanQ=0.000033, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.376861 0.802423 0.673862 0.847096 0.697516 0.847904 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 177
Initial state: 0 0.571186 0.851698 0.101309 0.363725 0.65953 0.818926 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51663 episodes
GETTING ACTION FROM:
action 3, numVisits=51511, meanQ=4.815834, numObservations: 5
action 0, numVisits=89, meanQ=4.111458, numObservations: 1
action -1, numVisits=61, meanQ=3.969602, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.571186 0.851698 0.101309 0.363725 0.65953 0.818926 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 178
Initial state: 0 0.846682 0.129172 0.568648 0.834441 0.695834 0.812418 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54064 episodes
GETTING ACTION FROM:
action 2, numVisits=54048, meanQ=4.939968, numObservations: 5
action 3, numVisits=9, meanQ=2.333333, numObservations: 2
action 1, numVisits=3, meanQ=0.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.846682 0.129172 0.568648 0.834441 0.695834 0.812418 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=287, meanQ=5.158417, numObservations: 4
action 2, numVisits=25, meanQ=3.400004, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2003 episodes
GETTING ACTION FROM:
action 1, numVisits=287, meanQ=5.158417, numObservations: 4
action 2, numVisits=38, meanQ=4.605268, numObservations: 4
action 0, numVisits=1983, meanQ=0.211150, numObservations: 1
action -1, numVisits=8, meanQ=-2.126225, numObservations: 1
action 3, numVisits=2, meanQ=-11.000000, numObservations: 2
action: 1
Next state: 0 0.846682 0.129172 0.568648 0.834441 0.695834 0.812418 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=12, meanQ=5.331667, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6906 episodes
GETTING ACTION FROM:
action 3, numVisits=793, meanQ=6.525244, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2264, meanQ=-1.536056, numObservations: 1
action 0, numVisits=3862, meanQ=-1.584726, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 0 0.846682 0.129172 0.568648 0.834441 0.695834 0.812418 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33141 episodes
GETTING ACTION FROM:
action 1, numVisits=3533, meanQ=6.417750, numObservations: 4
action 3, numVisits=468, meanQ=5.724359, numObservations: 5
action 2, numVisits=413, meanQ=5.658596, numObservations: 4
action 0, numVisits=20637, meanQ=-1.936102, numObservations: 1
action -1, numVisits=8090, meanQ=-1.962926, numObservations: 1
action: 1
Next state: 2 0.846682 0.129172 0.568648 0.834441 0.695834 0.812418 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -22.5537
Run # 179
Initial state: 0 0.391628 0.31008 0.592349 0.801161 0.625352 0.857993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54487 episodes
GETTING ACTION FROM:
action 2, numVisits=54375, meanQ=4.996613, numObservations: 3
action -1, numVisits=101, meanQ=3.826794, numObservations: 1
action 3, numVisits=8, meanQ=2.375000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.391628 0.31008 0.592349 0.801161 0.625352 0.857993 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=523, meanQ=4.953592, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1853 episodes
GETTING ACTION FROM:
action 3, numVisits=523, meanQ=4.953592, numObservations: 4
action 1, numVisits=14, meanQ=3.856429, numObservations: 2
action 0, numVisits=1832, meanQ=0.304765, numObservations: 1
action -1, numVisits=9, meanQ=-2.001100, numObservations: 1
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 3
Next state: 1 0.391628 0.31008 0.592349 0.801161 0.625352 0.857993 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 180
Initial state: 0 0.556564 0.810833 0.0810346 0.819358 0.53781 0.88481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54811 episodes
GETTING ACTION FROM:
action 2, numVisits=54779, meanQ=5.035135, numObservations: 5
action 3, numVisits=21, meanQ=2.808100, numObservations: 4
action 1, numVisits=7, meanQ=0.428586, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.556564 0.810833 0.0810346 0.819358 0.53781 0.88481 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 181
Initial state: 0 0.61781 0.875138 0.0978 0.285083 0.516313 0.832892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54125 episodes
GETTING ACTION FROM:
action 2, numVisits=54115, meanQ=4.983930, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.61781 0.875138 0.0978 0.285083 0.516313 0.832892 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6941, meanQ=8.424533, numObservations: 5
action 1, numVisits=473, meanQ=8.220559, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 4616 episodes
GETTING ACTION FROM:
action 3, numVisits=6941, meanQ=8.424533, numObservations: 5
action 1, numVisits=501, meanQ=8.096276, numObservations: 3
action -1, numVisits=4576, meanQ=0.286130, numObservations: 1
action 2, numVisits=7, meanQ=-0.287143, numObservations: 2
action 0, numVisits=8, meanQ=-1.876250, numObservations: 1
action: 3
Next state: 1 0.61781 0.875138 0.0978 0.285083 0.516313 0.832892 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 182
Initial state: 0 0.529144 0.890826 0.343401 0.752547 0.693411 0.848524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31829 episodes
GETTING ACTION FROM:
action -1, numVisits=31816, meanQ=2.860501, numObservations: 1
action 2, numVisits=6, meanQ=-1.000000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.529144 0.890826 0.343401 0.752547 0.693411 0.848524 w: 1
Observation: 0 0.494284 0 0.392782 0 0.738063 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31760, meanQ=4.975908, numObservations: 4
action 2, numVisits=27, meanQ=3.292985, numObservations: 3
action 0, numVisits=17, meanQ=3.260742, numObservations: 1
action 3, numVisits=9, meanQ=2.332244, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 54379 episodes
GETTING ACTION FROM:
action 1, numVisits=86138, meanQ=4.896467, numObservations: 4
action 2, numVisits=27, meanQ=3.292985, numObservations: 3
action 0, numVisits=18, meanQ=2.913478, numObservations: 1
action 3, numVisits=9, meanQ=2.332244, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.529144 0.890826 0.343401 0.752547 0.693411 0.848524 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 183
Initial state: 0 0.529603 0.88497 0.0519797 0.275371 0.641789 0.848439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53822 episodes
GETTING ACTION FROM:
action 2, numVisits=53733, meanQ=4.986703, numObservations: 3
action 0, numVisits=25, meanQ=3.617189, numObservations: 1
action -1, numVisits=47, meanQ=3.331801, numObservations: 1
action 3, numVisits=15, meanQ=2.466000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 0 0.529603 0.88497 0.0519797 0.275371 0.641789 0.848439 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8891, meanQ=8.304821, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2051 episodes
GETTING ACTION FROM:
action 1, numVisits=8891, meanQ=8.304821, numObservations: 4
action 3, numVisits=31, meanQ=5.612581, numObservations: 4
action 2, numVisits=7, meanQ=1.570000, numObservations: 4
action 0, numVisits=2011, meanQ=0.105042, numObservations: 1
action -1, numVisits=6, meanQ=-64.490011, numObservations: 1
action: 1
Next state: 1 0.529603 0.88497 0.0519797 0.275371 0.641789 0.848439 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 184
Initial state: 0 0.597931 0.868003 0.605782 0.88495 0.064238 0.618625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53997 episodes
GETTING ACTION FROM:
action 2, numVisits=53917, meanQ=5.047984, numObservations: 5
action -1, numVisits=72, meanQ=4.265975, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=4, meanQ=-2.252500, numObservations: 2
action: 2
Next state: 0 0.597931 0.868003 0.605782 0.88495 0.064238 0.618625 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3989, meanQ=5.406170, numObservations: 4
action 1, numVisits=5, meanQ=-0.201980, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 60329 episodes
GETTING ACTION FROM:
action 2, numVisits=64245, meanQ=4.961022, numObservations: 4
action 3, numVisits=72, meanQ=4.164031, numObservations: 4
action 1, numVisits=5, meanQ=-0.201980, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.597931 0.868003 0.605782 0.88495 0.064238 0.618625 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 185
Initial state: 0 0.609749 0.155102 0.559097 0.877609 0.580247 0.888667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32110 episodes
GETTING ACTION FROM:
action -1, numVisits=32102, meanQ=2.960617, numObservations: 1
action 3, numVisits=2, meanQ=-3.505000, numObservations: 2
action 0, numVisits=3, meanQ=-3.656600, numObservations: 1
action 1, numVisits=2, meanQ=-4.499950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.609749 0.155102 0.559097 0.877609 0.580247 0.888667 w: 1
Observation: 0 0.671697 0 0.462414 0 0.508041 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31236, meanQ=4.989115, numObservations: 5
action 3, numVisits=849, meanQ=4.788016, numObservations: 5
action -1, numVisits=13, meanQ=3.006825, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 56008 episodes
GETTING ACTION FROM:
action 2, numVisits=87243, meanQ=5.209151, numObservations: 5
action 3, numVisits=849, meanQ=4.788016, numObservations: 5
action -1, numVisits=13, meanQ=3.006825, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 2
Next state: 1 0.609749 0.155102 0.559097 0.877609 0.580247 0.888667 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 186
Initial state: 0 0.566288 0.877512 0.848743 0.905413 0.628456 0.814057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53933 episodes
GETTING ACTION FROM:
action 1, numVisits=53852, meanQ=4.959011, numObservations: 5
action -1, numVisits=77, meanQ=1.883917, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.566288 0.877512 0.848743 0.905413 0.628456 0.814057 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 187
Initial state: 0 0.51781 0.869506 0.825966 0.211433 0.678856 0.807066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54342 episodes
GETTING ACTION FROM:
action 3, numVisits=54251, meanQ=4.979858, numObservations: 3
action 0, numVisits=81, meanQ=4.265914, numObservations: 1
action 2, numVisits=6, meanQ=1.498333, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.51781 0.869506 0.825966 0.211433 0.678856 0.807066 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 188
Initial state: 0 0.56738 0.83345 0.587845 0.822081 0.633525 0.783301 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54382 episodes
GETTING ACTION FROM:
action 3, numVisits=54339, meanQ=4.974045, numObservations: 4
action 0, numVisits=19, meanQ=3.411197, numObservations: 1
action 1, numVisits=21, meanQ=3.229057, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.56738 0.83345 0.587845 0.822081 0.633525 0.783301 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4031, meanQ=4.914948, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67281 episodes
GETTING ACTION FROM:
action 1, numVisits=67276, meanQ=6.003748, numObservations: 4
action 2, numVisits=4031, meanQ=4.914948, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=3, meanQ=-6.003333, numObservations: 2
action: 1
Next state: 1 0.56738 0.83345 0.587845 0.822081 0.633525 0.783301 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 189
Initial state: 0 0.590139 0.121757 0.52696 0.872922 0.638856 0.894061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53964 episodes
GETTING ACTION FROM:
action 3, numVisits=53879, meanQ=5.002619, numObservations: 4
action 0, numVisits=39, meanQ=3.953867, numObservations: 1
action -1, numVisits=27, meanQ=3.711445, numObservations: 1
action 2, numVisits=18, meanQ=2.498889, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.590139 0.121757 0.52696 0.872922 0.638856 0.894061 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 190
Initial state: 0 0.519095 0.825242 0.625032 0.876871 0.0949439 0.903354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52790 episodes
GETTING ACTION FROM:
action 2, numVisits=52749, meanQ=4.946805, numObservations: 5
action -1, numVisits=35, meanQ=3.852466, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.519095 0.825242 0.625032 0.876871 0.0949439 0.903354 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 191
Initial state: 0 0.597851 0.881173 0.959498 0.225471 0.526632 0.867225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53669 episodes
GETTING ACTION FROM:
action 1, numVisits=53549, meanQ=4.961700, numObservations: 5
action 0, numVisits=85, meanQ=4.240113, numObservations: 1
action -1, numVisits=32, meanQ=3.741462, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.597851 0.881173 0.959498 0.225471 0.526632 0.867225 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 192
Initial state: 0 0.685507 0.882098 0.584897 0.895677 0.0720846 0.765212 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54336 episodes
GETTING ACTION FROM:
action 1, numVisits=54326, meanQ=5.040406, numObservations: 5
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=3, meanQ=-3.363333, numObservations: 2
action: 1
Next state: 1 0.685507 0.882098 0.584897 0.895677 0.0720846 0.765212 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 193
Initial state: 0 0.253089 0.475279 0.62888 0.806308 0.627327 0.814677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53870 episodes
GETTING ACTION FROM:
action 2, numVisits=53774, meanQ=4.988785, numObservations: 4
action -1, numVisits=69, meanQ=4.200531, numObservations: 1
action 1, numVisits=22, meanQ=2.855914, numObservations: 3
action 3, numVisits=3, meanQ=0.000033, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.253089 0.475279 0.62888 0.806308 0.627327 0.814677 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 194
Initial state: 0 0.506194 0.81492 0.0257173 0.804814 0.634553 0.840279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51515 episodes
GETTING ACTION FROM:
action 1, numVisits=51498, meanQ=4.825132, numObservations: 5
action 2, numVisits=10, meanQ=2.400000, numObservations: 3
action 3, numVisits=3, meanQ=-2.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.506194 0.81492 0.0257173 0.804814 0.634553 0.840279 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 195
Initial state: 0 0.0416597 0.134587 0.591062 0.833637 0.650192 0.879142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54481 episodes
GETTING ACTION FROM:
action 1, numVisits=54449, meanQ=5.004095, numObservations: 4
action 2, numVisits=20, meanQ=3.099500, numObservations: 4
action 3, numVisits=8, meanQ=2.375000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.0416597 0.134587 0.591062 0.833637 0.650192 0.879142 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7528, meanQ=8.360969, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 4763 episodes
GETTING ACTION FROM:
action 2, numVisits=7528, meanQ=8.360969, numObservations: 5
action 1, numVisits=3, meanQ=4.996667, numObservations: 2
action 3, numVisits=9, meanQ=1.368551, numObservations: 3
action 0, numVisits=3457, meanQ=0.175594, numObservations: 1
action -1, numVisits=1299, meanQ=0.153757, numObservations: 1
action: 2
Next state: 1 0.0416597 0.134587 0.591062 0.833637 0.650192 0.879142 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 196
Initial state: 0 0.172981 0.590231 0.580679 0.816615 0.691938 0.821579 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54071 episodes
GETTING ACTION FROM:
action 3, numVisits=54064, meanQ=4.979106, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.172981 0.590231 0.580679 0.816615 0.691938 0.821579 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 197
Initial state: 0 0.202714 0.914165 0.614563 0.805133 0.689892 0.806119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31886 episodes
GETTING ACTION FROM:
action 0, numVisits=31875, meanQ=2.840900, numObservations: 1
action 2, numVisits=7, meanQ=0.428586, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.202714 0.914165 0.614563 0.805133 0.689892 0.806119 w: 1
Observation: 0 0 0.860185 0 0.790079 0 0.759454 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31752, meanQ=4.924693, numObservations: 5
action 0, numVisits=79, meanQ=4.204099, numObservations: 1
action -1, numVisits=40, meanQ=3.880667, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54397 episodes
GETTING ACTION FROM:
action 3, numVisits=86119, meanQ=4.742356, numObservations: 5
action 0, numVisits=104, meanQ=4.096708, numObservations: 1
action -1, numVisits=44, meanQ=3.718571, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.202714 0.914165 0.614563 0.805133 0.689892 0.806119 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 198
Initial state: 0 0.691871 0.895894 0.574989 0.824298 0.108322 0.365978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54108 episodes
GETTING ACTION FROM:
action 1, numVisits=54094, meanQ=5.018785, numObservations: 4
action 2, numVisits=9, meanQ=0.222222, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.691871 0.895894 0.574989 0.824298 0.108322 0.365978 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=417, meanQ=3.874653, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1661 episodes
GETTING ACTION FROM:
action -1, numVisits=2075, meanQ=0.441105, numObservations: 1
action 0, numVisits=5, meanQ=-2.001980, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.691871 0.895894 0.574989 0.824298 0.108322 0.365978 w: 1
Observation: 0 0.642044 0 0.543622 0 0.13881 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=389, meanQ=6.889640, numObservations: 1
action 1, numVisits=409, meanQ=5.567946, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 4
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1129 episodes
GETTING ACTION FROM:
action 1, numVisits=409, meanQ=5.567946, numObservations: 3
action -1, numVisits=1513, meanQ=1.875592, numObservations: 1
action 3, numVisits=5, meanQ=1.780000, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.691871 0.895894 0.574989 0.824298 0.108322 0.365978 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8409
Run # 199
Initial state: 0 0.696949 0.892871 0.189922 0.452637 0.607451 0.88975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54644 episodes
GETTING ACTION FROM:
action 2, numVisits=54582, meanQ=5.015842, numObservations: 4
action -1, numVisits=25, meanQ=3.278608, numObservations: 1
action 1, numVisits=29, meanQ=3.266562, numObservations: 4
action 3, numVisits=6, meanQ=1.166683, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.696949 0.892871 0.189922 0.452637 0.607451 0.88975 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2694, meanQ=7.763666, numObservations: 4
action 3, numVisits=4, meanQ=4.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3588 episodes
GETTING ACTION FROM:
action 1, numVisits=2694, meanQ=7.763666, numObservations: 4
action 3, numVisits=10, meanQ=3.391736, numObservations: 2
action 0, numVisits=3577, meanQ=0.501155, numObservations: 1
action -1, numVisits=6, meanQ=-1.835000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 1
Next state: 1 0.696949 0.892871 0.189922 0.452637 0.607451 0.88975 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 200
Initial state: 0 0.651728 0.859142 0.66553 0.766225 0.6564 0.850077 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50283 episodes
GETTING ACTION FROM:
action 2, numVisits=44464, meanQ=4.995173, numObservations: 5
action -1, numVisits=5810, meanQ=3.016145, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 1
action: 2
Next state: 0 0.651728 0.859142 0.66553 0.766225 0.6564 0.850077 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6196, meanQ=8.323375, numObservations: 3
action 1, numVisits=34, meanQ=7.293532, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2299 episodes
GETTING ACTION FROM:
action 3, numVisits=6196, meanQ=8.323375, numObservations: 3
action 1, numVisits=37, meanQ=6.350814, numObservations: 3
action 0, numVisits=2290, meanQ=0.194860, numObservations: 1
action -1, numVisits=7, meanQ=-2.144257, numObservations: 1
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 3
Next state: 0 0.651728 0.859142 0.66553 0.766225 0.6564 0.850077 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=108, meanQ=7.886576, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8299 episodes
GETTING ACTION FROM:
action 1, numVisits=133, meanQ=7.613986, numObservations: 3
action 3, numVisits=8, meanQ=4.998750, numObservations: 4
action 0, numVisits=8166, meanQ=-1.698047, numObservations: 3
action -1, numVisits=104, meanQ=-3.855559, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.651728 0.859142 0.66553 0.766225 0.6564 0.850077 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 201
Initial state: 0 0.669732 0.889533 0.620977 0.888355 0.426502 0.679264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53707 episodes
GETTING ACTION FROM:
action 2, numVisits=53655, meanQ=4.901256, numObservations: 4
action -1, numVisits=18, meanQ=3.345262, numObservations: 1
action 3, numVisits=30, meanQ=2.417667, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.669732 0.889533 0.620977 0.888355 0.426502 0.679264 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 202
Initial state: 0 0.188809 0.710012 0.660231 0.858286 0.643456 0.824316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51633 episodes
GETTING ACTION FROM:
action 3, numVisits=51500, meanQ=4.834989, numObservations: 5
action 0, numVisits=115, meanQ=4.227922, numObservations: 1
action -1, numVisits=14, meanQ=3.052901, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.188809 0.710012 0.660231 0.858286 0.643456 0.824316 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 203
Initial state: 0 0.674913 0.833473 0.510844 0.800935 0.23288 0.466997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53804 episodes
GETTING ACTION FROM:
action 1, numVisits=53792, meanQ=4.972540, numObservations: 4
action 3, numVisits=6, meanQ=0.816667, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.674913 0.833473 0.510844 0.800935 0.23288 0.466997 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3803, meanQ=5.370247, numObservations: 4
action 2, numVisits=9, meanQ=3.221111, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
Sampled 66692 episodes
GETTING ACTION FROM:
action 2, numVisits=62046, meanQ=5.815889, numObservations: 4
action 1, numVisits=8456, meanQ=5.159382, numObservations: 5
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 2
Next state: 0 0.674913 0.833473 0.510844 0.800935 0.23288 0.466997 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1193, meanQ=6.953194, numObservations: 3
action 3, numVisits=47, meanQ=6.140855, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 69161 episodes
GETTING ACTION FROM:
action 3, numVisits=54758, meanQ=6.122129, numObservations: 4
action 1, numVisits=6328, meanQ=6.099415, numObservations: 5
action 2, numVisits=9314, meanQ=6.080996, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 0 0.674913 0.833473 0.510844 0.800935 0.23288 0.466997 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=39, meanQ=5.918208, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 52034 episodes
GETTING ACTION FROM:
action 2, numVisits=8150, meanQ=5.913908, numObservations: 4
action 1, numVisits=49, meanQ=5.647349, numObservations: 4
action 3, numVisits=22, meanQ=4.817727, numObservations: 4
action 0, numVisits=23757, meanQ=-1.957287, numObservations: 1
action -1, numVisits=20101, meanQ=-1.961387, numObservations: 1
action: 2
Next state: 0 0.674913 0.833473 0.510844 0.800935 0.23288 0.466997 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=9.000000, numObservations: 1
action 3, numVisits=1, meanQ=9.000000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 119237 episodes
GETTING ACTION FROM:
action 1, numVisits=117838, meanQ=6.648636, numObservations: 5
action 2, numVisits=793, meanQ=5.746532, numObservations: 5
action 3, numVisits=600, meanQ=5.600000, numObservations: 5
action -1, numVisits=4, meanQ=-2.000000, numObservations: 1
action 0, numVisits=4, meanQ=-2.000000, numObservations: 1
action: 1
Next state: 1 0.674913 0.833473 0.510844 0.800935 0.23288 0.466997 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -7.11623
Run # 204
Initial state: 0 0.168552 0.151533 0.653115 0.854929 0.538187 0.89031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53881 episodes
GETTING ACTION FROM:
action 3, numVisits=45512, meanQ=4.978430, numObservations: 5
action 1, numVisits=8285, meanQ=4.885931, numObservations: 3
action 0, numVisits=70, meanQ=4.178845, numObservations: 1
action 2, numVisits=12, meanQ=2.415842, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.168552 0.151533 0.653115 0.854929 0.538187 0.89031 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 205
Initial state: 0 0.504411 0.896565 0.82745 0.697256 0.65869 0.893968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53670 episodes
GETTING ACTION FROM:
action 3, numVisits=53649, meanQ=4.911546, numObservations: 4
action -1, numVisits=17, meanQ=3.313739, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.504411 0.896565 0.82745 0.697256 0.65869 0.893968 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 206
Initial state: 0 0.514658 0.827534 0.078828 0.949718 0.561872 0.865163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54952 episodes
GETTING ACTION FROM:
action 2, numVisits=54912, meanQ=5.195744, numObservations: 4
action 3, numVisits=31, meanQ=3.386787, numObservations: 4
action 1, numVisits=5, meanQ=-0.200000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.514658 0.827534 0.078828 0.949718 0.561872 0.865163 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 207
Initial state: 0 0.616236 0.844454 0.637385 0.863582 0.099645 0.676952 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52298 episodes
GETTING ACTION FROM:
action 3, numVisits=52290, meanQ=4.834663, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.616236 0.844454 0.637385 0.863582 0.099645 0.676952 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 208
Initial state: 0 0.843216 0.397982 0.615717 0.851019 0.578794 0.870235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54392 episodes
GETTING ACTION FROM:
action 2, numVisits=54386, meanQ=4.964976, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.843216 0.397982 0.615717 0.851019 0.578794 0.870235 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 209
Initial state: 0 0.697069 0.877132 0.087345 0.726037 0.635691 0.891327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51756 episodes
GETTING ACTION FROM:
action 1, numVisits=51745, meanQ=4.809951, numObservations: 4
action 2, numVisits=3, meanQ=0.663333, numObservations: 2
action 3, numVisits=4, meanQ=-0.272500, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.697069 0.877132 0.087345 0.726037 0.635691 0.891327 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 210
Initial state: 0 0.0165826 0.48629 0.624801 0.880893 0.605209 0.898173 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54312 episodes
GETTING ACTION FROM:
action 1, numVisits=54296, meanQ=5.038024, numObservations: 5
action 2, numVisits=5, meanQ=1.000000, numObservations: 1
action 3, numVisits=7, meanQ=0.844286, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0165826 0.48629 0.624801 0.880893 0.605209 0.898173 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6029, meanQ=8.494332, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1774 episodes
GETTING ACTION FROM:
action 2, numVisits=6029, meanQ=8.494332, numObservations: 3
action 3, numVisits=82, meanQ=5.498938, numObservations: 4
action 0, numVisits=1672, meanQ=0.152889, numObservations: 1
action 1, numVisits=4, meanQ=-2.252500, numObservations: 3
action -1, numVisits=20, meanQ=-2.271930, numObservations: 1
action: 2
Next state: 1 0.0165826 0.48629 0.624801 0.880893 0.605209 0.898173 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 211
Initial state: 0 0.636602 0.82735 0.831628 0.292259 0.604091 0.889381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54298 episodes
GETTING ACTION FROM:
action 3, numVisits=54065, meanQ=4.943075, numObservations: 4
action 1, numVisits=209, meanQ=3.930128, numObservations: 5
action -1, numVisits=20, meanQ=3.452239, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.489950, numObservations: 1
action: 3
Next state: 1 0.636602 0.82735 0.831628 0.292259 0.604091 0.889381 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 212
Initial state: 0 0.497868 0.787541 0.60594 0.878979 0.531246 0.887545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51564 episodes
GETTING ACTION FROM:
action 2, numVisits=47697, meanQ=4.937032, numObservations: 4
action -1, numVisits=3846, meanQ=2.971899, numObservations: 1
action 1, numVisits=13, meanQ=1.216169, numObservations: 2
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.497868 0.787541 0.60594 0.878979 0.531246 0.887545 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 213
Initial state: 0 0.515252 0.801741 0.680785 0.896159 0.0426666 0.909039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52434 episodes
GETTING ACTION FROM:
action 1, numVisits=52426, meanQ=4.908948, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 1
Next state: 1 0.515252 0.801741 0.680785 0.896159 0.0426666 0.909039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 214
Initial state: 0 0.00741159 0.491805 0.565134 0.800126 0.654885 0.886804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50068 episodes
GETTING ACTION FROM:
action 1, numVisits=50057, meanQ=4.790656, numObservations: 5
action 2, numVisits=6, meanQ=1.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.00741159 0.491805 0.565134 0.800126 0.654885 0.886804 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5613, meanQ=8.534053, numObservations: 3
action 3, numVisits=9, meanQ=4.555567, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3118 episodes
GETTING ACTION FROM:
action 2, numVisits=5613, meanQ=8.534053, numObservations: 3
action 3, numVisits=102, meanQ=6.450981, numObservations: 4
action 0, numVisits=3023, meanQ=0.074969, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action -1, numVisits=3, meanQ=-130.429728, numObservations: 1
action: 2
Next state: 1 0.00741159 0.491805 0.565134 0.800126 0.654885 0.886804 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 215
Initial state: 0 0.79908 0.0255785 0.563479 0.860687 0.562174 0.819154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54054 episodes
GETTING ACTION FROM:
action 1, numVisits=54048, meanQ=4.913849, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.79908 0.0255785 0.563479 0.860687 0.562174 0.819154 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 216
Initial state: 0 0.524629 0.866574 0.580212 0.816175 0.99212 0.259265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54324 episodes
GETTING ACTION FROM:
action 2, numVisits=54315, meanQ=5.044685, numObservations: 3
action 3, numVisits=3, meanQ=0.000033, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.524629 0.866574 0.580212 0.816175 0.99212 0.259265 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 217
Initial state: 0 0.657776 0.899113 0.64593 0.826387 0.191397 0.921668 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53917 episodes
GETTING ACTION FROM:
action 1, numVisits=53875, meanQ=5.008485, numObservations: 5
action 0, numVisits=35, meanQ=3.899526, numObservations: 1
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.657776 0.899113 0.64593 0.826387 0.191397 0.921668 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 218
Initial state: 0 0.537186 0.802806 0.108268 0.176633 0.529227 0.854005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54115 episodes
GETTING ACTION FROM:
action 1, numVisits=54034, meanQ=4.899243, numObservations: 4
action -1, numVisits=68, meanQ=4.088748, numObservations: 1
action 3, numVisits=10, meanQ=1.681000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.537186 0.802806 0.108268 0.176633 0.529227 0.854005 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 219
Initial state: 0 0.973689 0.253059 0.502591 0.836293 0.530408 0.866924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51342 episodes
GETTING ACTION FROM:
action 3, numVisits=51313, meanQ=4.804690, numObservations: 4
action 0, numVisits=24, meanQ=3.428101, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.973689 0.253059 0.502591 0.836293 0.530408 0.866924 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 220
Initial state: 0 0.611805 0.869959 0.425308 0.208362 0.552177 0.872816 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54506 episodes
GETTING ACTION FROM:
action 1, numVisits=54487, meanQ=5.172665, numObservations: 5
action 3, numVisits=14, meanQ=2.850743, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.611805 0.869959 0.425308 0.208362 0.552177 0.872816 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 221
Initial state: 0 0.120873 0.659228 0.693032 0.833874 0.62018 0.815519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54382 episodes
GETTING ACTION FROM:
action 2, numVisits=54369, meanQ=5.159627, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.120873 0.659228 0.693032 0.833874 0.62018 0.815519 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 222
Initial state: 0 0.240026 0.0724577 0.557992 0.821078 0.655358 0.837986 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53971 episodes
GETTING ACTION FROM:
action 1, numVisits=53914, meanQ=4.925752, numObservations: 3
action -1, numVisits=53, meanQ=4.028834, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.240026 0.0724577 0.557992 0.821078 0.655358 0.837986 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8811, meanQ=8.259307, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 4439 episodes
GETTING ACTION FROM:
action 3, numVisits=8811, meanQ=8.259307, numObservations: 4
action 2, numVisits=23, meanQ=5.260439, numObservations: 4
action 1, numVisits=4, meanQ=2.747500, numObservations: 2
action -1, numVisits=4370, meanQ=0.069259, numObservations: 1
action 0, numVisits=47, meanQ=-2.000211, numObservations: 1
action: 3
Next state: 1 0.240026 0.0724577 0.557992 0.821078 0.655358 0.837986 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 223
Initial state: 0 0.587544 0.827127 0.564097 0.834556 0.263548 0.779975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52861 episodes
GETTING ACTION FROM:
action 3, numVisits=50934, meanQ=4.986424, numObservations: 4
action 0, numVisits=1917, meanQ=2.931938, numObservations: 1
action 1, numVisits=7, meanQ=0.570014, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.587544 0.827127 0.564097 0.834556 0.263548 0.779975 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1172, meanQ=7.912390, numObservations: 4
action 2, numVisits=29, meanQ=6.792417, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2254 episodes
GETTING ACTION FROM:
action 1, numVisits=1172, meanQ=7.912390, numObservations: 4
action 2, numVisits=108, meanQ=6.887871, numObservations: 5
action 3, numVisits=14, meanQ=2.927857, numObservations: 3
action 0, numVisits=2154, meanQ=0.250710, numObservations: 1
action -1, numVisits=10, meanQ=-2.100980, numObservations: 1
action: 1
Next state: 1 0.587544 0.827127 0.564097 0.834556 0.263548 0.779975 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 224
Initial state: 0 0.606787 0.840442 0.699828 0.836853 0.13383 0.787672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54076 episodes
GETTING ACTION FROM:
action 2, numVisits=54007, meanQ=4.945684, numObservations: 5
action 0, numVisits=34, meanQ=3.840779, numObservations: 1
action 3, numVisits=27, meanQ=3.470378, numObservations: 4
action 1, numVisits=6, meanQ=1.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.606787 0.840442 0.699828 0.836853 0.13383 0.787672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 225
Initial state: 0 0.645074 0.856672 0.522805 0.851711 0.772004 0.721432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53906 episodes
GETTING ACTION FROM:
action 3, numVisits=53850, meanQ=4.903562, numObservations: 4
action -1, numVisits=42, meanQ=3.880406, numObservations: 1
action 1, numVisits=11, meanQ=2.909100, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.645074 0.856672 0.522805 0.851711 0.772004 0.721432 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 226
Initial state: 0 0.59296 0.895119 0.69143 0.826137 0.398992 0.776393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54228 episodes
GETTING ACTION FROM:
action 2, numVisits=54213, meanQ=5.080224, numObservations: 5
action 3, numVisits=9, meanQ=1.666667, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.59296 0.895119 0.69143 0.826137 0.398992 0.776393 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 227
Initial state: 0 0.502809 0.896686 0.611999 0.853576 0.0936024 0.594454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54162 episodes
GETTING ACTION FROM:
action 1, numVisits=54153, meanQ=5.017359, numObservations: 5
action 2, numVisits=3, meanQ=0.000033, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.502809 0.896686 0.611999 0.853576 0.0936024 0.594454 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3929, meanQ=5.688807, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 66977 episodes
GETTING ACTION FROM:
action 3, numVisits=66835, meanQ=5.868781, numObservations: 4
action 1, numVisits=4070, meanQ=5.675071, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 3
Next state: 0 0.502809 0.896686 0.611999 0.853576 0.0936024 0.594454 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=890, meanQ=8.435714, numObservations: 5
action 1, numVisits=42, meanQ=7.761669, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11752 episodes
GETTING ACTION FROM:
action 2, numVisits=944, meanQ=8.319688, numObservations: 5
action 1, numVisits=117, meanQ=6.937261, numObservations: 4
action 3, numVisits=17, meanQ=3.587647, numObservations: 4
action -1, numVisits=6050, meanQ=-1.608421, numObservations: 1
action 0, numVisits=5559, meanQ=-1.608919, numObservations: 2
action: 2
Next state: 1 0.502809 0.896686 0.611999 0.853576 0.0936024 0.594454 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 228
Initial state: 0 0.61479 0.80186 0.324464 0.775956 0.666944 0.810284 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31774 episodes
GETTING ACTION FROM:
action 0, numVisits=31676, meanQ=3.008850, numObservations: 1
action -1, numVisits=94, meanQ=2.374195, numObservations: 1
action 2, numVisits=2, meanQ=-4.499950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.61479 0.80186 0.324464 0.775956 0.666944 0.810284 w: 1
Observation: 0 0 0.891514 0 0.850411 0 0.887142 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31613, meanQ=5.069976, numObservations: 4
action 0, numVisits=51, meanQ=4.169896, numObservations: 1
action 2, numVisits=8, meanQ=2.498750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 53874 episodes
GETTING ACTION FROM:
action 1, numVisits=85461, meanQ=4.834490, numObservations: 4
action 0, numVisits=59, meanQ=3.962480, numObservations: 1
action 3, numVisits=15, meanQ=2.998007, numObservations: 4
action 2, numVisits=12, meanQ=2.658333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.61479 0.80186 0.324464 0.775956 0.666944 0.810284 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 229
Initial state: 0 0.662032 0.830616 0.698151 0.863187 0.0519804 0.137441 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51242 episodes
GETTING ACTION FROM:
action 2, numVisits=51236, meanQ=4.901851, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.662032 0.830616 0.698151 0.863187 0.0519804 0.137441 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 230
Initial state: 0 0.516714 0.863532 0.0983848 0.0449627 0.538306 0.879826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53179 episodes
GETTING ACTION FROM:
action 2, numVisits=53165, meanQ=4.984540, numObservations: 5
action 1, numVisits=8, meanQ=2.375000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 2
Next state: 0 0.516714 0.863532 0.0983848 0.0449627 0.538306 0.879826 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7384, meanQ=8.330651, numObservations: 4
action 3, numVisits=6, meanQ=4.335017, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1663 episodes
GETTING ACTION FROM:
action 1, numVisits=7384, meanQ=8.330651, numObservations: 4
action 3, numVisits=75, meanQ=5.002174, numObservations: 4
action 0, numVisits=1572, meanQ=0.232526, numObservations: 1
action -1, numVisits=23, meanQ=-1.613039, numObservations: 1
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 1
Next state: 1 0.516714 0.863532 0.0983848 0.0449627 0.538306 0.879826 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 231
Initial state: 0 0.880576 0.388164 0.589901 0.832691 0.680521 0.866529 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51811 episodes
GETTING ACTION FROM:
action 2, numVisits=51654, meanQ=4.814281, numObservations: 4
action -1, numVisits=151, meanQ=2.913928, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.880576 0.388164 0.589901 0.832691 0.680521 0.866529 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 232
Initial state: 0 0.509439 0.806739 0.674344 0.85892 0.801277 0.253736 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52310 episodes
GETTING ACTION FROM:
action 1, numVisits=52293, meanQ=4.862227, numObservations: 4
action 2, numVisits=9, meanQ=2.333344, numObservations: 2
action 3, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.509439 0.806739 0.674344 0.85892 0.801277 0.253736 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 233
Initial state: 0 0.221836 0.569825 0.637444 0.860739 0.580835 0.885703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54137 episodes
GETTING ACTION FROM:
action 1, numVisits=54095, meanQ=4.987223, numObservations: 4
action 2, numVisits=19, meanQ=3.263700, numObservations: 2
action 3, numVisits=19, meanQ=3.160011, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.221836 0.569825 0.637444 0.860739 0.580835 0.885703 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7670, meanQ=8.338546, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1999 episodes
GETTING ACTION FROM:
action 2, numVisits=7689, meanQ=8.331733, numObservations: 4
action 3, numVisits=49, meanQ=6.751363, numObservations: 5
action 1, numVisits=3, meanQ=4.996667, numObservations: 2
action 0, numVisits=1927, meanQ=0.209771, numObservations: 1
action -1, numVisits=6, meanQ=-66.372629, numObservations: 1
action: 2
Next state: 1 0.221836 0.569825 0.637444 0.860739 0.580835 0.885703 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 234
Initial state: 0 0.602861 0.89718 0.558376 0.441393 0.630869 0.872297 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31627 episodes
GETTING ACTION FROM:
action -1, numVisits=31621, meanQ=2.940698, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.602861 0.89718 0.558376 0.441393 0.630869 0.872297 w: 1
Observation: 0 0.640902 0 0.466246 0 0.679667 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31541, meanQ=4.980606, numObservations: 5
action 0, numVisits=58, meanQ=4.154688, numObservations: 1
action 2, numVisits=18, meanQ=3.433344, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54000 episodes
GETTING ACTION FROM:
action 1, numVisits=85529, meanQ=4.838832, numObservations: 5
action 0, numVisits=67, meanQ=4.017421, numObservations: 1
action 2, numVisits=20, meanQ=2.990010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-3.505000, numObservations: 2
action: 1
Next state: 1 0.602861 0.89718 0.558376 0.441393 0.630869 0.872297 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 235
Initial state: 0 0.529979 0.803682 0.683593 0.846001 0.67691 0.130496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53936 episodes
GETTING ACTION FROM:
action 1, numVisits=53930, meanQ=4.944670, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.529979 0.803682 0.683593 0.846001 0.67691 0.130496 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 236
Initial state: 0 0.623248 0.0274829 0.532365 0.866951 0.694037 0.885556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53775 episodes
GETTING ACTION FROM:
action 3, numVisits=53759, meanQ=4.991767, numObservations: 3
action 2, numVisits=11, meanQ=0.365464, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.623248 0.0274829 0.532365 0.866951 0.694037 0.885556 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 237
Initial state: 0 0.0292675 0.749798 0.566215 0.835702 0.666988 0.846468 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54019 episodes
GETTING ACTION FROM:
action 1, numVisits=53905, meanQ=5.009676, numObservations: 4
action 0, numVisits=87, meanQ=4.328558, numObservations: 1
action 2, numVisits=24, meanQ=3.329171, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0292675 0.749798 0.566215 0.835702 0.666988 0.846468 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7646, meanQ=8.407996, numObservations: 5
action 3, numVisits=29, meanQ=7.206214, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10641 episodes
GETTING ACTION FROM:
action 2, numVisits=7646, meanQ=8.407996, numObservations: 5
action 3, numVisits=29, meanQ=7.206214, numObservations: 3
action 0, numVisits=10629, meanQ=0.092328, numObservations: 1
action -1, numVisits=13, meanQ=-2.000762, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.0292675 0.749798 0.566215 0.835702 0.666988 0.846468 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 238
Initial state: 0 0.673669 0.876017 0.316577 0.529636 0.661204 0.818035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54424 episodes
GETTING ACTION FROM:
action 1, numVisits=54414, meanQ=4.984250, numObservations: 4
action 3, numVisits=3, meanQ=0.000033, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.673669 0.876017 0.316577 0.529636 0.661204 0.818035 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 239
Initial state: 0 0.60883 0.874217 0.907863 0.246076 0.502738 0.844022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54057 episodes
GETTING ACTION FROM:
action 2, numVisits=53913, meanQ=5.012133, numObservations: 5
action 0, numVisits=138, meanQ=4.466494, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.60883 0.874217 0.907863 0.246076 0.502738 0.844022 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 240
Initial state: 0 0.658547 0.818939 0.54085 0.818372 0.32148 0.533614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54599 episodes
GETTING ACTION FROM:
action 1, numVisits=54494, meanQ=5.087206, numObservations: 5
action 0, numVisits=89, meanQ=4.414429, numObservations: 1
action 3, numVisits=12, meanQ=2.833350, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.658547 0.818939 0.54085 0.818372 0.32148 0.533614 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 241
Initial state: 0 0.534405 0.826298 0.318963 0.33897 0.572635 0.843085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54233 episodes
GETTING ACTION FROM:
action 2, numVisits=54122, meanQ=4.963705, numObservations: 5
action 0, numVisits=71, meanQ=2.586981, numObservations: 1
action 1, numVisits=36, meanQ=2.302778, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.534405 0.826298 0.318963 0.33897 0.572635 0.843085 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2712, meanQ=7.901408, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3670 episodes
GETTING ACTION FROM:
action 1, numVisits=2712, meanQ=7.901408, numObservations: 4
action 3, numVisits=19, meanQ=4.525789, numObservations: 4
action -1, numVisits=3646, meanQ=0.233881, numObservations: 1
action 0, numVisits=7, meanQ=-2.001414, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 1
Next state: 1 0.534405 0.826298 0.318963 0.33897 0.572635 0.843085 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 242
Initial state: 0 0.622741 0.883163 0.683973 0.861878 0.0709913 0.676354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51684 episodes
GETTING ACTION FROM:
action 1, numVisits=51582, meanQ=4.870678, numObservations: 4
action 0, numVisits=82, meanQ=4.126187, numObservations: 1
action -1, numVisits=17, meanQ=3.271240, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.622741 0.883163 0.683973 0.861878 0.0709913 0.676354 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 243
Initial state: 0 0.566654 0.872337 0.379336 0.768153 0.686286 0.800873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54340 episodes
GETTING ACTION FROM:
action 1, numVisits=54331, meanQ=4.984222, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.566654 0.872337 0.379336 0.768153 0.686286 0.800873 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8970, meanQ=8.317770, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3583 episodes
GETTING ACTION FROM:
action 2, numVisits=9445, meanQ=8.190431, numObservations: 4
action 1, numVisits=8, meanQ=4.123762, numObservations: 4
action 3, numVisits=19, meanQ=3.121423, numObservations: 4
action 0, numVisits=3082, meanQ=0.314661, numObservations: 2
action -1, numVisits=4, meanQ=-98.409894, numObservations: 1
action: 2
Next state: 0 0.566654 0.872337 0.379336 0.768153 0.686286 0.800873 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=112, meanQ=7.942146, numObservations: 4
action 0, numVisits=3, meanQ=4.270000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-197.101651, numObservations: 1
Sampled 4802 episodes
GETTING ACTION FROM:
action 3, numVisits=112, meanQ=7.942146, numObservations: 4
action 0, numVisits=4805, meanQ=-1.608533, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-197.101651, numObservations: 1
action: 3
Next state: 1 0.566654 0.872337 0.379336 0.768153 0.686286 0.800873 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 244
Initial state: 0 0.0981412 0.802238 0.539899 0.883021 0.502046 0.864789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 38114 episodes
GETTING ACTION FROM:
action 0, numVisits=27135, meanQ=5.888972, numObservations: 3
action 2, numVisits=10972, meanQ=5.031788, numObservations: 4
action 1, numVisits=4, meanQ=1.755025, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0981412 0.802238 0.539899 0.883021 0.502046 0.864789 w: 1
Observation: 0 0 0.897295 0 0.92059 0 0.932234 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11668, meanQ=7.558816, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55534 episodes
GETTING ACTION FROM:
action 2, numVisits=67195, meanQ=5.217916, numObservations: 4
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.0981412 0.802238 0.539899 0.883021 0.502046 0.864789 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 245
Initial state: 0 0.529222 0.888907 0.513792 0.888121 0.943934 0.623473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54625 episodes
GETTING ACTION FROM:
action 3, numVisits=54564, meanQ=4.974223, numObservations: 4
action -1, numVisits=51, meanQ=4.043104, numObservations: 1
action 2, numVisits=5, meanQ=-0.200000, numObservations: 3
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.529222 0.888907 0.513792 0.888121 0.943934 0.623473 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 246
Initial state: 0 0.600312 0.492692 0.556818 0.834068 0.64087 0.879063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54182 episodes
GETTING ACTION FROM:
action 2, numVisits=54148, meanQ=5.157681, numObservations: 4
action 3, numVisits=21, meanQ=3.571438, numObservations: 2
action 1, numVisits=9, meanQ=1.886667, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.600312 0.492692 0.556818 0.834068 0.64087 0.879063 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 247
Initial state: 0 0.688995 0.857597 0.539389 0.841478 0.339938 0.0364371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53809 episodes
GETTING ACTION FROM:
action 3, numVisits=53779, meanQ=4.946835, numObservations: 4
action 1, numVisits=15, meanQ=1.726667, numObservations: 3
action 2, numVisits=11, meanQ=1.637282, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.688995 0.857597 0.539389 0.841478 0.339938 0.0364371 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 248
Initial state: 0 0.0775994 0.219372 0.69405 0.812475 0.550181 0.837623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54123 episodes
GETTING ACTION FROM:
action 1, numVisits=54092, meanQ=4.990685, numObservations: 5
action 0, numVisits=22, meanQ=3.587810, numObservations: 1
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0775994 0.219372 0.69405 0.812475 0.550181 0.837623 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7613, meanQ=8.390838, numObservations: 5
action 2, numVisits=34, meanQ=7.408238, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12147 episodes
GETTING ACTION FROM:
action 3, numVisits=7613, meanQ=8.390838, numObservations: 5
action 2, numVisits=47, meanQ=6.910428, numObservations: 4
action -1, numVisits=12123, meanQ=0.143979, numObservations: 1
action 0, numVisits=10, meanQ=-1.901000, numObservations: 1
action 1, numVisits=4, meanQ=-2.252500, numObservations: 2
action: 3
Next state: 1 0.0775994 0.219372 0.69405 0.812475 0.550181 0.837623 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 249
Initial state: 0 0.00819162 0.887945 0.686691 0.800918 0.540818 0.814099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54712 episodes
GETTING ACTION FROM:
action 2, numVisits=54693, meanQ=5.030729, numObservations: 3
action 3, numVisits=9, meanQ=2.766667, numObservations: 3
action 1, numVisits=6, meanQ=1.836700, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.00819162 0.887945 0.686691 0.800918 0.540818 0.814099 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 250
Initial state: 0 0.155559 0.486794 0.572932 0.870378 0.634304 0.863495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51014 episodes
GETTING ACTION FROM:
action 3, numVisits=50980, meanQ=4.707670, numObservations: 4
action -1, numVisits=21, meanQ=1.823758, numObservations: 1
action 1, numVisits=10, meanQ=1.099010, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.155559 0.486794 0.572932 0.870378 0.634304 0.863495 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 251
Initial state: 0 0.477613 0.527499 0.560661 0.869077 0.648441 0.869459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51387 episodes
GETTING ACTION FROM:
action 2, numVisits=51329, meanQ=4.863211, numObservations: 4
action 0, numVisits=32, meanQ=3.687460, numObservations: 1
action 3, numVisits=14, meanQ=2.356443, numObservations: 3
action 1, numVisits=10, meanQ=2.209000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.477613 0.527499 0.560661 0.869077 0.648441 0.869459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 252
Initial state: 0 0.547375 0.826636 0.949611 0.610163 0.693934 0.807232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53679 episodes
GETTING ACTION FROM:
action 3, numVisits=53644, meanQ=4.969453, numObservations: 5
action 0, numVisits=30, meanQ=3.784155, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.547375 0.826636 0.949611 0.610163 0.693934 0.807232 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3969, meanQ=5.228049, numObservations: 3
action 2, numVisits=14, meanQ=2.427857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 59591 episodes
GETTING ACTION FROM:
action 3, numVisits=63556, meanQ=4.958298, numObservations: 3
action 2, numVisits=14, meanQ=2.427857, numObservations: 3
action -1, numVisits=4, meanQ=0.475000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.547375 0.826636 0.949611 0.610163 0.693934 0.807232 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 253
Initial state: 0 0.661085 0.817655 0.559433 0.831344 0.308205 0.769429 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53956 episodes
GETTING ACTION FROM:
action 1, numVisits=53888, meanQ=4.958897, numObservations: 4
action -1, numVisits=59, meanQ=3.440266, numObservations: 1
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.661085 0.817655 0.559433 0.831344 0.308205 0.769429 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 254
Initial state: 0 0.519514 0.89001 0.730466 0.0917548 0.685196 0.882158 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54133 episodes
GETTING ACTION FROM:
action 2, numVisits=54124, meanQ=5.025519, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 2
Next state: 2 0.519514 0.89001 0.730466 0.0917548 0.685196 0.882158 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 255
Initial state: 0 0.511679 0.866475 0.397447 0.140793 0.606319 0.835299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54180 episodes
GETTING ACTION FROM:
action 1, numVisits=54131, meanQ=4.974280, numObservations: 4
action -1, numVisits=44, meanQ=3.976326, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.511679 0.866475 0.397447 0.140793 0.606319 0.835299 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 256
Initial state: 0 0.628434 0.894839 0.385611 0.637168 0.602814 0.807569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53731 episodes
GETTING ACTION FROM:
action 1, numVisits=53682, meanQ=4.987213, numObservations: 3
action -1, numVisits=39, meanQ=3.920435, numObservations: 1
action 3, numVisits=7, meanQ=1.428571, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.628434 0.894839 0.385611 0.637168 0.602814 0.807569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 257
Initial state: 0 0.536464 0.831088 0.172753 0.184802 0.60203 0.814227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54366 episodes
GETTING ACTION FROM:
action 2, numVisits=54343, meanQ=5.077716, numObservations: 4
action 3, numVisits=18, meanQ=3.378344, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.536464 0.831088 0.172753 0.184802 0.60203 0.814227 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7071, meanQ=8.402079, numObservations: 4
action 1, numVisits=550, meanQ=8.215052, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1929 episodes
GETTING ACTION FROM:
action 3, numVisits=7071, meanQ=8.402079, numObservations: 4
action 1, numVisits=562, meanQ=8.178932, numObservations: 4
action 2, numVisits=3, meanQ=4.996667, numObservations: 2
action -1, numVisits=1915, meanQ=-0.018459, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.536464 0.831088 0.172753 0.184802 0.60203 0.814227 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 258
Initial state: 0 0.53469 0.878124 0.102638 0.349946 0.569456 0.815017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54002 episodes
GETTING ACTION FROM:
action 1, numVisits=53690, meanQ=4.967249, numObservations: 5
action 0, numVisits=305, meanQ=4.544623, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 1
Next state: 1 0.53469 0.878124 0.102638 0.349946 0.569456 0.815017 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 259
Initial state: 0 0.666652 0.848039 0.609713 0.801925 0.887288 0.8962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51522 episodes
GETTING ACTION FROM:
action 1, numVisits=51381, meanQ=5.002121, numObservations: 5
action 3, numVisits=70, meanQ=4.170864, numObservations: 4
action -1, numVisits=61, meanQ=4.169217, numObservations: 1
action 2, numVisits=8, meanQ=2.375000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.666652 0.848039 0.609713 0.801925 0.887288 0.8962 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 260
Initial state: 0 0.582164 0.895226 0.667074 0.846342 0.308463 0.447228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54376 episodes
GETTING ACTION FROM:
action 2, numVisits=54339, meanQ=5.018042, numObservations: 4
action -1, numVisits=28, meanQ=3.771483, numObservations: 1
action 1, numVisits=3, meanQ=0.000033, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.582164 0.895226 0.667074 0.846342 0.308463 0.447228 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 261
Initial state: 0 0.616369 0.879243 0.924666 0.584572 0.557456 0.817486 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54054 episodes
GETTING ACTION FROM:
action 2, numVisits=53883, meanQ=4.918561, numObservations: 5
action 0, numVisits=43, meanQ=3.882064, numObservations: 1
action 3, numVisits=124, meanQ=3.434287, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.616369 0.879243 0.924666 0.584572 0.557456 0.817486 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 262
Initial state: 0 0.662622 0.871986 0.500572 0.878984 0.832037 0.98432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54565 episodes
GETTING ACTION FROM:
action 3, numVisits=54557, meanQ=5.021688, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=3, meanQ=-3.363333, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.662622 0.871986 0.500572 0.878984 0.832037 0.98432 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 263
Initial state: 0 0.980824 0.763676 0.647777 0.839754 0.697352 0.846171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54709 episodes
GETTING ACTION FROM:
action 2, numVisits=54692, meanQ=5.052992, numObservations: 5
action 1, numVisits=11, meanQ=1.271818, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.980824 0.763676 0.647777 0.839754 0.697352 0.846171 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.551703 0.895317 0.244091 0.728881 0.621187 0.884866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53857 episodes
GETTING ACTION FROM:
action 3, numVisits=53839, meanQ=4.983277, numObservations: 4
action -1, numVisits=13, meanQ=3.127692, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.551703 0.895317 0.244091 0.728881 0.621187 0.884866 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 265
Initial state: 0 0.582457 0.85663 0.444906 0.295736 0.591792 0.88604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54299 episodes
GETTING ACTION FROM:
action 2, numVisits=54290, meanQ=5.015306, numObservations: 5
action 3, numVisits=3, meanQ=0.333333, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.582457 0.85663 0.444906 0.295736 0.591792 0.88604 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7540, meanQ=8.447169, numObservations: 4
action 3, numVisits=69, meanQ=7.747972, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2629 episodes
GETTING ACTION FROM:
action 1, numVisits=7540, meanQ=8.447169, numObservations: 4
action 3, numVisits=79, meanQ=7.601520, numObservations: 4
action 2, numVisits=3, meanQ=4.996667, numObservations: 2
action 0, numVisits=2474, meanQ=0.067635, numObservations: 1
action -1, numVisits=145, meanQ=-0.340965, numObservations: 1
action: 1
Next state: 1 0.582457 0.85663 0.444906 0.295736 0.591792 0.88604 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 266
Initial state: 0 0.531793 0.833265 0.929826 0.291102 0.507098 0.868631 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54468 episodes
GETTING ACTION FROM:
action 1, numVisits=54462, meanQ=5.007827, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.531793 0.833265 0.929826 0.291102 0.507098 0.868631 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 267
Initial state: 0 0.162122 0.067904 0.544039 0.831523 0.685746 0.809066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54214 episodes
GETTING ACTION FROM:
action 2, numVisits=54126, meanQ=4.981548, numObservations: 4
action 0, numVisits=62, meanQ=4.157812, numObservations: 1
action -1, numVisits=16, meanQ=3.253806, numObservations: 1
action 1, numVisits=7, meanQ=2.428571, numObservations: 3
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action: 2
Next state: 1 0.162122 0.067904 0.544039 0.831523 0.685746 0.809066 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 268
Initial state: 0 0.603641 0.89658 0.736144 0.580168 0.62926 0.877755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53759 episodes
GETTING ACTION FROM:
action 3, numVisits=53751, meanQ=5.003316, numObservations: 4
action 1, numVisits=3, meanQ=0.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.603641 0.89658 0.736144 0.580168 0.62926 0.877755 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 269
Initial state: 0 0.630226 0.84378 0.849729 0.37676 0.516281 0.865562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54335 episodes
GETTING ACTION FROM:
action 2, numVisits=54250, meanQ=5.124305, numObservations: 5
action 0, numVisits=66, meanQ=4.324196, numObservations: 1
action -1, numVisits=14, meanQ=3.290489, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action: 2
Next state: 2 0.630226 0.84378 0.849729 0.37676 0.516281 0.865562 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 270
Initial state: 0 0.362005 0.64515 0.551635 0.841209 0.583101 0.808011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54209 episodes
GETTING ACTION FROM:
action 2, numVisits=54057, meanQ=4.981555, numObservations: 5
action 0, numVisits=89, meanQ=4.297235, numObservations: 1
action 1, numVisits=35, meanQ=2.441714, numObservations: 4
action 3, numVisits=26, meanQ=2.418865, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.362005 0.64515 0.551635 0.841209 0.583101 0.808011 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 271
Initial state: 0 0.510407 0.74697 0.568587 0.848916 0.594487 0.896065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51320 episodes
GETTING ACTION FROM:
action 2, numVisits=46978, meanQ=5.149489, numObservations: 5
action 0, numVisits=4335, meanQ=3.005073, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 2
Next state: 1 0.510407 0.74697 0.568587 0.848916 0.594487 0.896065 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 272
Initial state: 0 0.567111 0.830485 0.559081 0.816964 0.157809 0.485906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54315 episodes
GETTING ACTION FROM:
action 3, numVisits=54309, meanQ=5.167446, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.567111 0.830485 0.559081 0.816964 0.157809 0.485906 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6166, meanQ=8.507894, numObservations: 3
action 1, numVisits=57, meanQ=7.631058, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6997 episodes
GETTING ACTION FROM:
action 2, numVisits=6174, meanQ=8.494866, numObservations: 3
action 1, numVisits=122, meanQ=6.557134, numObservations: 4
action 0, numVisits=6917, meanQ=0.206566, numObservations: 1
action -1, numVisits=9, meanQ=-1.890000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.567111 0.830485 0.559081 0.816964 0.157809 0.485906 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 273
Initial state: 0 0.0796376 0.561678 0.63693 0.816715 0.610817 0.83231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54143 episodes
GETTING ACTION FROM:
action 3, numVisits=54113, meanQ=5.004276, numObservations: 5
action -1, numVisits=26, meanQ=3.615354, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0796376 0.561678 0.63693 0.816715 0.610817 0.83231 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 274
Initial state: 0 0.51364 0.82139 0.596022 0.896275 0.152117 0.674518 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54184 episodes
GETTING ACTION FROM:
action 1, numVisits=54176, meanQ=5.008232, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=3, meanQ=-3.296667, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.51364 0.82139 0.596022 0.896275 0.152117 0.674518 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 275
Initial state: 0 0.686617 0.863531 0.644599 0.857351 0.131256 0.0672491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52615 episodes
GETTING ACTION FROM:
action 3, numVisits=52498, meanQ=4.942152, numObservations: 5
action -1, numVisits=79, meanQ=4.201944, numObservations: 1
action 1, numVisits=23, meanQ=3.461743, numObservations: 3
action 2, numVisits=13, meanQ=2.846154, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.686617 0.863531 0.644599 0.857351 0.131256 0.0672491 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3618, meanQ=8.311344, numObservations: 3
action 2, numVisits=3806, meanQ=8.219358, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1710 episodes
GETTING ACTION FROM:
action 1, numVisits=3618, meanQ=8.311344, numObservations: 3
action 2, numVisits=3806, meanQ=8.219358, numObservations: 3
action 3, numVisits=3, meanQ=0.330033, numObservations: 1
action 0, numVisits=1708, meanQ=0.212430, numObservations: 1
action -1, numVisits=2, meanQ=-195.399779, numObservations: 1
action: 1
Next state: 1 0.686617 0.863531 0.644599 0.857351 0.131256 0.0672491 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 276
Initial state: 0 0.851182 0.932661 0.647404 0.836386 0.611832 0.852105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51696 episodes
GETTING ACTION FROM:
action 2, numVisits=51678, meanQ=4.831900, numObservations: 3
action 0, numVisits=11, meanQ=2.496925, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.489950, numObservations: 1
action: 2
Next state: 1 0.851182 0.932661 0.647404 0.836386 0.611832 0.852105 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 277
Initial state: 0 0.598353 0.850843 0.645979 0.870449 0.98937 0.888664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51495 episodes
GETTING ACTION FROM:
action 3, numVisits=51442, meanQ=4.761148, numObservations: 4
action 0, numVisits=43, meanQ=3.724853, numObservations: 1
action 1, numVisits=7, meanQ=2.285729, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.598353 0.850843 0.645979 0.870449 0.98937 0.888664 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.633957 0.830323 0.721021 0.66955 0.587706 0.82499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54112 episodes
GETTING ACTION FROM:
action 2, numVisits=54065, meanQ=5.029207, numObservations: 5
action 0, numVisits=28, meanQ=3.760415, numObservations: 1
action 1, numVisits=13, meanQ=2.846154, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.633957 0.830323 0.721021 0.66955 0.587706 0.82499 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 279
Initial state: 0 0.491924 0.244868 0.500872 0.830967 0.515631 0.879307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54200 episodes
GETTING ACTION FROM:
action 1, numVisits=54194, meanQ=5.179452, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.491924 0.244868 0.500872 0.830967 0.515631 0.879307 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6243, meanQ=8.539262, numObservations: 3
action 2, numVisits=14, meanQ=6.992143, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 4129 episodes
GETTING ACTION FROM:
action 3, numVisits=6243, meanQ=8.539262, numObservations: 3
action 2, numVisits=242, meanQ=5.897769, numObservations: 4
action 0, numVisits=3897, meanQ=0.179816, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action -1, numVisits=5, meanQ=-79.736590, numObservations: 1
action: 3
Next state: 1 0.491924 0.244868 0.500872 0.830967 0.515631 0.879307 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 280
Initial state: 0 0.921857 0.119836 0.57911 0.894868 0.628712 0.833271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53944 episodes
GETTING ACTION FROM:
action 2, numVisits=53921, meanQ=5.009315, numObservations: 4
action -1, numVisits=19, meanQ=3.417974, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.921857 0.119836 0.57911 0.894868 0.628712 0.833271 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 281
Initial state: 0 0.698668 0.869765 0.0127788 0.0936782 0.536201 0.80005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53834 episodes
GETTING ACTION FROM:
action 1, numVisits=53805, meanQ=4.896186, numObservations: 3
action -1, numVisits=23, meanQ=3.540024, numObservations: 1
action 3, numVisits=3, meanQ=0.000033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.698668 0.869765 0.0127788 0.0936782 0.536201 0.80005 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 282
Initial state: 0 0.54654 0.884294 0.997707 0.993559 0.59477 0.834574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54305 episodes
GETTING ACTION FROM:
action 2, numVisits=54254, meanQ=5.044011, numObservations: 4
action -1, numVisits=43, meanQ=4.029679, numObservations: 1
action 1, numVisits=5, meanQ=1.582000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.54654 0.884294 0.997707 0.993559 0.59477 0.834574 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 283
Initial state: 0 0.558555 0.864733 0.092636 0.152029 0.566691 0.824576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49405 episodes
GETTING ACTION FROM:
action 2, numVisits=49399, meanQ=4.648060, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.558555 0.864733 0.092636 0.152029 0.566691 0.824576 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=6999, meanQ=6.294480, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2413 episodes
GETTING ACTION FROM:
action -1, numVisits=9409, meanQ=4.695377, numObservations: 1
action 0, numVisits=4, meanQ=0.475000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.558555 0.864733 0.092636 0.152029 0.566691 0.824576 w: 1
Observation: 0 0.533475 0 0.142461 0 0.647537 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=6859, meanQ=8.378638, numObservations: 5
action 3, numVisits=136, meanQ=7.925007, numObservations: 3
action -1, numVisits=597, meanQ=6.896734, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2566 episodes
GETTING ACTION FROM:
action 1, numVisits=6859, meanQ=8.378638, numObservations: 5
action 3, numVisits=136, meanQ=7.925007, numObservations: 3
action -1, numVisits=3160, meanQ=1.333104, numObservations: 1
action 0, numVisits=4, meanQ=-1.752500, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.558555 0.864733 0.092636 0.152029 0.566691 0.824576 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8409
Run # 284
Initial state: 0 0.982293 0.343147 0.512497 0.873431 0.639289 0.847617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 36489 episodes
GETTING ACTION FROM:
action 0, numVisits=29144, meanQ=5.888228, numObservations: 3
action 3, numVisits=7341, meanQ=4.887236, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.982293 0.343147 0.512497 0.873431 0.639289 0.847617 w: 1
Observation: 0 0 0.384343 0 0.855362 0 0.780777 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9244, meanQ=8.100419, numObservations: 4
action 2, numVisits=24, meanQ=5.333346, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55814 episodes
GETTING ACTION FROM:
action 3, numVisits=65034, meanQ=5.554031, numObservations: 4
action 2, numVisits=30, meanQ=4.066350, numObservations: 5
action -1, numVisits=12, meanQ=3.556458, numObservations: 1
action 1, numVisits=7, meanQ=2.711429, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.982293 0.343147 0.512497 0.873431 0.639289 0.847617 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 285
Initial state: 0 0.751188 0.901782 0.623658 0.890241 0.656076 0.88491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53943 episodes
GETTING ACTION FROM:
action 1, numVisits=53851, meanQ=4.941591, numObservations: 4
action -1, numVisits=64, meanQ=4.033636, numObservations: 1
action 0, numVisits=19, meanQ=3.342347, numObservations: 1
action 3, numVisits=8, meanQ=2.351250, numObservations: 3
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.751188 0.901782 0.623658 0.890241 0.656076 0.88491 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 286
Initial state: 0 0.550926 0.823236 0.512519 0.833747 0.0979644 0.0589767 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54358 episodes
GETTING ACTION FROM:
action 1, numVisits=54304, meanQ=5.122327, numObservations: 4
action 0, numVisits=45, meanQ=4.101326, numObservations: 1
action 3, numVisits=6, meanQ=0.166667, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.550926 0.823236 0.512519 0.833747 0.0979644 0.0589767 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 287
Initial state: 0 0.545259 0.829335 0.495021 0.485094 0.529054 0.8774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51950 episodes
GETTING ACTION FROM:
action 1, numVisits=51838, meanQ=4.950095, numObservations: 3
action -1, numVisits=79, meanQ=4.213463, numObservations: 1
action 3, numVisits=28, meanQ=3.639293, numObservations: 4
action 2, numVisits=3, meanQ=-2.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.545259 0.829335 0.495021 0.485094 0.529054 0.8774 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 288
Initial state: 0 0.949255 0.883492 0.648137 0.857128 0.626976 0.886024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54172 episodes
GETTING ACTION FROM:
action 2, numVisits=53225, meanQ=4.994392, numObservations: 5
action 1, numVisits=924, meanQ=4.783953, numObservations: 4
action 0, numVisits=18, meanQ=3.157937, numObservations: 1
action 3, numVisits=3, meanQ=0.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.949255 0.883492 0.648137 0.857128 0.626976 0.886024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 289
Initial state: 0 0.44594 0.0251521 0.662839 0.819695 0.647136 0.840141 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54462 episodes
GETTING ACTION FROM:
action 2, numVisits=54408, meanQ=5.005380, numObservations: 4
action -1, numVisits=45, meanQ=4.018962, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.44594 0.0251521 0.662839 0.819695 0.647136 0.840141 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6912, meanQ=8.329945, numObservations: 3
action 3, numVisits=2085, meanQ=8.281593, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2403 episodes
GETTING ACTION FROM:
action 1, numVisits=6912, meanQ=8.329945, numObservations: 3
action 3, numVisits=2126, meanQ=8.246074, numObservations: 5
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=2355, meanQ=0.296968, numObservations: 1
action 0, numVisits=8, meanQ=-1.876250, numObservations: 1
action: 1
Next state: 0 0.44594 0.0251521 0.662839 0.819695 0.647136 0.840141 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=120, meanQ=7.991500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6410 episodes
GETTING ACTION FROM:
action 3, numVisits=152, meanQ=7.387434, numObservations: 3
action 2, numVisits=54, meanQ=6.185000, numObservations: 5
action -1, numVisits=6313, meanQ=-1.639943, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 0, numVisits=13, meanQ=-17.033168, numObservations: 1
action: 3
Next state: 0 0.44594 0.0251521 0.662839 0.819695 0.647136 0.840141 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=9.000000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26960 episodes
GETTING ACTION FROM:
action 2, numVisits=820, meanQ=6.198671, numObservations: 4
action 1, numVisits=413, meanQ=5.820823, numObservations: 5
action 3, numVisits=265, meanQ=5.554717, numObservations: 3
action -1, numVisits=13002, meanQ=-1.929417, numObservations: 1
action 0, numVisits=12461, meanQ=-1.931358, numObservations: 1
action: 2
Next state: 1 0.44594 0.0251521 0.662839 0.819695 0.647136 0.840141 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 290
Initial state: 0 0.59445 0.858547 0.520238 0.443378 0.507479 0.888846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54483 episodes
GETTING ACTION FROM:
action 3, numVisits=54477, meanQ=5.050617, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.59445 0.858547 0.520238 0.443378 0.507479 0.888846 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 291
Initial state: 0 0.624002 0.829769 0.820812 0.153931 0.501393 0.835147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53673 episodes
GETTING ACTION FROM:
action 3, numVisits=53665, meanQ=5.000430, numObservations: 5
action 2, numVisits=3, meanQ=0.000033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.624002 0.829769 0.820812 0.153931 0.501393 0.835147 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3989, meanQ=5.587553, numObservations: 3
action 2, numVisits=4, meanQ=2.002525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 65348 episodes
GETTING ACTION FROM:
action 2, numVisits=55515, meanQ=6.080976, numObservations: 4
action 3, numVisits=13779, meanQ=5.335882, numObservations: 3
action 1, numVisits=45, meanQ=4.444222, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=3, meanQ=-2.003300, numObservations: 1
action: 2
Next state: 2 0.624002 0.829769 0.820812 0.153931 0.501393 0.835147 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 292
Initial state: 0 0.635113 0.801654 0.113424 0.544826 0.635445 0.848706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52267 episodes
GETTING ACTION FROM:
action 3, numVisits=50036, meanQ=4.957182, numObservations: 4
action -1, numVisits=2224, meanQ=3.029802, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 3
Next state: 1 0.635113 0.801654 0.113424 0.544826 0.635445 0.848706 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 293
Initial state: 0 0.409915 0.299698 0.623808 0.837343 0.549684 0.884033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54692 episodes
GETTING ACTION FROM:
action 2, numVisits=54656, meanQ=4.972863, numObservations: 3
action 3, numVisits=30, meanQ=3.249007, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.409915 0.299698 0.623808 0.837343 0.549684 0.884033 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 294
Initial state: 0 0.526979 0.605379 0.563836 0.886387 0.6077 0.875706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54528 episodes
GETTING ACTION FROM:
action 2, numVisits=54522, meanQ=4.997399, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.526979 0.605379 0.563836 0.886387 0.6077 0.875706 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 295
Initial state: 0 0.77308 0.777594 0.589083 0.828637 0.523193 0.850326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32080 episodes
GETTING ACTION FROM:
action 0, numVisits=31975, meanQ=2.962756, numObservations: 1
action -1, numVisits=69, meanQ=2.202705, numObservations: 1
action 1, numVisits=29, meanQ=1.639317, numObservations: 3
action 2, numVisits=6, meanQ=-0.834983, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.77308 0.777594 0.589083 0.828637 0.523193 0.850326 w: 1
Observation: 0 0 0.857769 0 0.883891 0 0.776944 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31894, meanQ=5.018019, numObservations: 5
action 0, numVisits=73, meanQ=4.294573, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55446 episodes
GETTING ACTION FROM:
action 2, numVisits=87339, meanQ=5.114878, numObservations: 5
action 0, numVisits=74, meanQ=4.283284, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.77308 0.777594 0.589083 0.828637 0.523193 0.850326 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 296
Initial state: 0 0.481588 0.983894 0.63179 0.850452 0.652751 0.808835 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54368 episodes
GETTING ACTION FROM:
action 1, numVisits=54358, meanQ=4.959763, numObservations: 4
action 3, numVisits=3, meanQ=0.663333, numObservations: 2
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.481588 0.983894 0.63179 0.850452 0.652751 0.808835 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4017, meanQ=4.716784, numObservations: 4
action 3, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
Sampled 67815 episodes
GETTING ACTION FROM:
action 2, numVisits=71830, meanQ=6.051046, numObservations: 4
action 3, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.481588 0.983894 0.63179 0.850452 0.652751 0.808835 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 297
Initial state: 0 0.501716 0.807183 0.531141 0.811974 0.968162 0.10176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54632 episodes
GETTING ACTION FROM:
action 2, numVisits=54621, meanQ=4.945399, numObservations: 4
action 1, numVisits=5, meanQ=-0.200000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.501716 0.807183 0.531141 0.811974 0.968162 0.10176 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 298
Initial state: 0 0.695631 0.898286 0.536192 0.899909 0.189888 0.405495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54279 episodes
GETTING ACTION FROM:
action 3, numVisits=54233, meanQ=5.208870, numObservations: 4
action -1, numVisits=36, meanQ=4.092145, numObservations: 1
action 2, numVisits=7, meanQ=2.570000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.695631 0.898286 0.536192 0.899909 0.189888 0.405495 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6144, meanQ=8.527078, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 4111 episodes
GETTING ACTION FROM:
action 2, numVisits=6207, meanQ=8.511796, numObservations: 4
action 1, numVisits=49, meanQ=5.224286, numObservations: 4
action 0, numVisits=3986, meanQ=0.202042, numObservations: 1
action 3, numVisits=8, meanQ=-0.001250, numObservations: 3
action -1, numVisits=10, meanQ=-2.100980, numObservations: 1
action: 2
Next state: 1 0.695631 0.898286 0.536192 0.899909 0.189888 0.405495 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 299
Initial state: 0 0.697926 0.857551 0.789131 0.813729 0.601478 0.897653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53976 episodes
GETTING ACTION FROM:
action 2, numVisits=53948, meanQ=4.941825, numObservations: 4
action -1, numVisits=21, meanQ=3.367738, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-9.445000, numObservations: 1
action: 2
Next state: 1 0.697926 0.857551 0.789131 0.813729 0.601478 0.897653 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 300
Initial state: 0 0.571628 0.81233 0.612632 0.831636 0.644096 0.345932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54068 episodes
GETTING ACTION FROM:
action 1, numVisits=54062, meanQ=4.971698, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.571628 0.81233 0.612632 0.831636 0.644096 0.345932 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 301
Initial state: 0 0.00620084 0.420392 0.576143 0.829562 0.557759 0.89846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31750 episodes
GETTING ACTION FROM:
action -1, numVisits=31744, meanQ=3.001459, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.00620084 0.420392 0.576143 0.829562 0.557759 0.89846 w: 1
Observation: 0 0.0138945 0 0.625154 0 0.640392 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31708, meanQ=5.013861, numObservations: 4
action 0, numVisits=20, meanQ=3.524519, numObservations: 1
action -1, numVisits=12, meanQ=2.619044, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 53520 episodes
GETTING ACTION FROM:
action 3, numVisits=85225, meanQ=4.751014, numObservations: 4
action 0, numVisits=23, meanQ=3.316144, numObservations: 1
action -1, numVisits=12, meanQ=2.619044, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.00620084 0.420392 0.576143 0.829562 0.557759 0.89846 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 302
Initial state: 0 0.671586 0.813341 0.539232 0.80699 0.430884 0.6865 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53840 episodes
GETTING ACTION FROM:
action 1, numVisits=53765, meanQ=4.988008, numObservations: 4
action -1, numVisits=46, meanQ=4.016710, numObservations: 1
action 0, numVisits=22, meanQ=3.561839, numObservations: 1
action 2, numVisits=3, meanQ=0.663333, numObservations: 2
action 3, numVisits=4, meanQ=-0.222500, numObservations: 1
action: 1
Next state: 1 0.671586 0.813341 0.539232 0.80699 0.430884 0.6865 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 303
Initial state: 0 0.52387 0.81315 0.698808 0.403962 0.670447 0.828538 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54367 episodes
GETTING ACTION FROM:
action 3, numVisits=54358, meanQ=4.982963, numObservations: 5
action 2, numVisits=4, meanQ=-0.502500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.52387 0.81315 0.698808 0.403962 0.670447 0.828538 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 304
Initial state: 0 0.619228 0.802969 0.626397 0.865464 0.10331 0.132088 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54175 episodes
GETTING ACTION FROM:
action 1, numVisits=54144, meanQ=4.980353, numObservations: 4
action 2, numVisits=25, meanQ=2.720816, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.619228 0.802969 0.626397 0.865464 0.10331 0.132088 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 305
Initial state: 0 0.473339 0.622763 0.609605 0.879421 0.552667 0.885296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54238 episodes
GETTING ACTION FROM:
action 3, numVisits=54192, meanQ=4.918242, numObservations: 5
action -1, numVisits=32, meanQ=3.713391, numObservations: 1
action 2, numVisits=11, meanQ=2.357282, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.473339 0.622763 0.609605 0.879421 0.552667 0.885296 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 306
Initial state: 0 0.672403 0.817917 0.515291 0.857671 0.0995638 0.7334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53838 episodes
GETTING ACTION FROM:
action 3, numVisits=53767, meanQ=4.880192, numObservations: 4
action -1, numVisits=66, meanQ=4.075918, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.672403 0.817917 0.515291 0.857671 0.0995638 0.7334 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7543, meanQ=8.418256, numObservations: 4
action 2, numVisits=14, meanQ=4.436436, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 5448 episodes
GETTING ACTION FROM:
action 1, numVisits=7543, meanQ=8.418256, numObservations: 4
action 3, numVisits=3, meanQ=4.996667, numObservations: 3
action 2, numVisits=14, meanQ=4.436436, numObservations: 2
action 0, numVisits=5439, meanQ=0.051169, numObservations: 1
action -1, numVisits=9, meanQ=-2.112200, numObservations: 1
action: 1
Next state: 1 0.672403 0.817917 0.515291 0.857671 0.0995638 0.7334 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 307
Initial state: 0 0.618579 0.866738 0.684854 0.817647 0.959893 0.725565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53082 episodes
GETTING ACTION FROM:
action 2, numVisits=53076, meanQ=5.003669, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.618579 0.866738 0.684854 0.817647 0.959893 0.725565 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3695, meanQ=7.034236, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 64904 episodes
GETTING ACTION FROM:
action 3, numVisits=50897, meanQ=5.945920, numObservations: 5
action 2, numVisits=17426, meanQ=5.490753, numObservations: 5
action 1, numVisits=275, meanQ=5.129601, numObservations: 5
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 2 0.618579 0.866738 0.684854 0.817647 0.959893 0.725565 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 308
Initial state: 0 0.513406 0.884789 0.538304 0.885137 0.478112 0.673545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52209 episodes
GETTING ACTION FROM:
action 1, numVisits=51940, meanQ=4.856663, numObservations: 5
action -1, numVisits=117, meanQ=4.260948, numObservations: 1
action 0, numVisits=108, meanQ=4.230348, numObservations: 1
action 2, numVisits=43, meanQ=3.530472, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.513406 0.884789 0.538304 0.885137 0.478112 0.673545 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 309
Initial state: 0 0.976072 0.868784 0.542531 0.834957 0.573345 0.823414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53900 episodes
GETTING ACTION FROM:
action 3, numVisits=53893, meanQ=4.940023, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.976072 0.868784 0.542531 0.834957 0.573345 0.823414 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 310
Initial state: 0 0.577778 0.869312 0.557942 0.540224 0.549388 0.85288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53266 episodes
GETTING ACTION FROM:
action 2, numVisits=51965, meanQ=5.011399, numObservations: 4
action -1, numVisits=1231, meanQ=3.241559, numObservations: 1
action 0, numVisits=66, meanQ=2.697922, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 2
Next state: 2 0.577778 0.869312 0.557942 0.540224 0.549388 0.85288 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 311
Initial state: 0 0.540421 0.842623 0.0845753 0.0390149 0.676106 0.81501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31843 episodes
GETTING ACTION FROM:
action 0, numVisits=31639, meanQ=2.894942, numObservations: 1
action -1, numVisits=195, meanQ=2.465304, numObservations: 1
action 3, numVisits=6, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=2, meanQ=-4.499950, numObservations: 1
action: 0
Next state: 0 0.540421 0.842623 0.0845753 0.0390149 0.676106 0.81501 w: 1
Observation: 0 0 0.852416 0 0.0448335 0 0.736502 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31630, meanQ=4.947339, numObservations: 5
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54947 episodes
GETTING ACTION FROM:
action 1, numVisits=86553, meanQ=5.033509, numObservations: 5
action 2, numVisits=20, meanQ=2.944500, numObservations: 3
action 3, numVisits=8, meanQ=-1.626250, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.540421 0.842623 0.0845753 0.0390149 0.676106 0.81501 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 312
Initial state: 0 0.323495 0.27804 0.590345 0.859737 0.555037 0.814473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54303 episodes
GETTING ACTION FROM:
action 1, numVisits=54219, meanQ=5.006664, numObservations: 5
action 0, numVisits=79, meanQ=4.247442, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.323495 0.27804 0.590345 0.859737 0.555037 0.814473 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6179, meanQ=8.560618, numObservations: 3
action 3, numVisits=6, meanQ=4.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2787 episodes
GETTING ACTION FROM:
action 2, numVisits=6179, meanQ=8.560618, numObservations: 3
action 1, numVisits=3, meanQ=4.996667, numObservations: 2
action 3, numVisits=15, meanQ=3.410687, numObservations: 3
action -1, numVisits=2772, meanQ=0.404643, numObservations: 1
action 0, numVisits=6, meanQ=-2.001650, numObservations: 1
action: 2
Next state: 1 0.323495 0.27804 0.590345 0.859737 0.555037 0.814473 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 313
Initial state: 0 0.663913 0.892517 0.57322 0.807347 0.178378 0.751153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54143 episodes
GETTING ACTION FROM:
action 1, numVisits=54135, meanQ=4.977270, numObservations: 5
action 3, numVisits=3, meanQ=0.000033, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.663913 0.892517 0.57322 0.807347 0.178378 0.751153 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 314
Initial state: 0 0.697842 0.858564 0.586467 0.823688 0.50814 0.571985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53838 episodes
GETTING ACTION FROM:
action 2, numVisits=53767, meanQ=4.913355, numObservations: 5
action 0, numVisits=52, meanQ=2.139657, numObservations: 1
action 1, numVisits=12, meanQ=1.234167, numObservations: 3
action 3, numVisits=5, meanQ=-1.600000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.697842 0.858564 0.586467 0.823688 0.50814 0.571985 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 315
Initial state: 0 0.231405 0.971062 0.673358 0.841904 0.639624 0.866088 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54102 episodes
GETTING ACTION FROM:
action 2, numVisits=54043, meanQ=5.037814, numObservations: 3
action -1, numVisits=37, meanQ=3.938709, numObservations: 1
action 3, numVisits=13, meanQ=1.922308, numObservations: 3
action 1, numVisits=7, meanQ=0.844286, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.231405 0.971062 0.673358 0.841904 0.639624 0.866088 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 316
Initial state: 0 0.627818 0.873892 0.202672 0.108051 0.548078 0.894062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53834 episodes
GETTING ACTION FROM:
action 3, numVisits=53796, meanQ=4.930223, numObservations: 5
action 1, numVisits=26, meanQ=2.576550, numObservations: 4
action 2, numVisits=8, meanQ=1.888750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.627818 0.873892 0.202672 0.108051 0.548078 0.894062 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 317
Initial state: 0 0.0445156 0.0674912 0.629987 0.873509 0.508371 0.819914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53550 episodes
GETTING ACTION FROM:
action 2, numVisits=53504, meanQ=5.152860, numObservations: 4
action -1, numVisits=23, meanQ=2.808958, numObservations: 1
action 1, numVisits=18, meanQ=2.656667, numObservations: 3
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.0445156 0.0674912 0.629987 0.873509 0.508371 0.819914 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1733, meanQ=7.988093, numObservations: 5
action 3, numVisits=5, meanQ=4.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2461 episodes
GETTING ACTION FROM:
action 1, numVisits=1733, meanQ=7.988093, numObservations: 5
action 3, numVisits=16, meanQ=3.720469, numObservations: 4
action -1, numVisits=2443, meanQ=0.173700, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=9, meanQ=-44.717984, numObservations: 1
action: 1
Next state: 0 0.0445156 0.0674912 0.629987 0.873509 0.508371 0.819914 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=13, meanQ=7.761538, numObservations: 1
action 3, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 14642 episodes
GETTING ACTION FROM:
action 2, numVisits=311, meanQ=6.314339, numObservations: 4
action 3, numVisits=99, meanQ=6.050404, numObservations: 5
action 1, numVisits=8, meanQ=-0.001250, numObservations: 3
action -1, numVisits=9542, meanQ=-1.767388, numObservations: 1
action 0, numVisits=4701, meanQ=-1.796567, numObservations: 3
action: 2
Next state: 1 0.0445156 0.0674912 0.629987 0.873509 0.508371 0.819914 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 318
Initial state: 0 0.247628 0.708327 0.552512 0.89841 0.64494 0.801744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52586 episodes
GETTING ACTION FROM:
action 2, numVisits=52561, meanQ=4.907288, numObservations: 4
action 1, numVisits=13, meanQ=3.069246, numObservations: 3
action 3, numVisits=8, meanQ=1.500000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.247628 0.708327 0.552512 0.89841 0.64494 0.801744 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2836, meanQ=4.597552, numObservations: 5
action 0, numVisits=829, meanQ=2.079802, numObservations: 1
action -1, numVisits=214, meanQ=1.899723, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 66660 episodes
GETTING ACTION FROM:
action 1, numVisits=69447, meanQ=5.859398, numObservations: 5
action 2, numVisits=50, meanQ=3.874004, numObservations: 4
action 0, numVisits=829, meanQ=2.079802, numObservations: 1
action -1, numVisits=214, meanQ=1.899723, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.247628 0.708327 0.552512 0.89841 0.64494 0.801744 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1277, meanQ=8.385140, numObservations: 4
action 2, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 12475 episodes
GETTING ACTION FROM:
action 3, numVisits=1377, meanQ=8.208957, numObservations: 4
action 1, numVisits=12, meanQ=2.333333, numObservations: 4
action 2, numVisits=13, meanQ=1.922308, numObservations: 3
action 0, numVisits=5930, meanQ=-1.664273, numObservations: 2
action -1, numVisits=6426, meanQ=-1.668459, numObservations: 1
action: 3
Next state: 0 0.247628 0.708327 0.552512 0.89841 0.64494 0.801744 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=70, meanQ=8.081574, numObservations: 3
action 2, numVisits=16, meanQ=6.756250, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 66921 episodes
GETTING ACTION FROM:
action 1, numVisits=4454, meanQ=6.237313, numObservations: 4
action 3, numVisits=1886, meanQ=6.051230, numObservations: 3
action 2, numVisits=539, meanQ=5.556772, numObservations: 4
action 0, numVisits=33162, meanQ=-1.977700, numObservations: 1
action -1, numVisits=26969, meanQ=-1.981830, numObservations: 1
action: 1
Next state: 0 0.247628 0.708327 0.552512 0.89841 0.64494 0.801744 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80632 episodes
GETTING ACTION FROM:
action 3, numVisits=48323, meanQ=6.723071, numObservations: 4
action 2, numVisits=631, meanQ=5.957211, numObservations: 5
action 1, numVisits=300, meanQ=5.533333, numObservations: 3
action 0, numVisits=15958, meanQ=-1.993238, numObservations: 1
action -1, numVisits=15420, meanQ=-1.994158, numObservations: 1
action: 3
Next state: 1 0.247628 0.708327 0.552512 0.89841 0.64494 0.801744 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -7.11623
Run # 319
Initial state: 0 0.699203 0.874026 0.552426 0.820427 0.428811 0.987761 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54407 episodes
GETTING ACTION FROM:
action 2, numVisits=54391, meanQ=4.971143, numObservations: 5
action 1, numVisits=9, meanQ=1.555567, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.699203 0.874026 0.552426 0.820427 0.428811 0.987761 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 320
Initial state: 0 0.547065 0.862163 0.621208 0.868436 0.71414 0.673559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54335 episodes
GETTING ACTION FROM:
action 1, numVisits=54316, meanQ=5.145811, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action 2, numVisits=8, meanQ=1.500012, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.547065 0.862163 0.621208 0.868436 0.71414 0.673559 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 321
Initial state: 0 0.530149 0.887518 0.447625 0.382692 0.679273 0.861176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54559 episodes
GETTING ACTION FROM:
action 2, numVisits=54548, meanQ=5.016439, numObservations: 5
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.530149 0.887518 0.447625 0.382692 0.679273 0.861176 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7661, meanQ=8.392142, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2962 episodes
GETTING ACTION FROM:
action 1, numVisits=7661, meanQ=8.392142, numObservations: 4
action 3, numVisits=59, meanQ=6.047629, numObservations: 5
action 0, numVisits=2355, meanQ=0.342785, numObservations: 2
action -1, numVisits=546, meanQ=0.088773, numObservations: 1
action 2, numVisits=7, meanQ=-0.287143, numObservations: 3
action: 1
Next state: 1 0.530149 0.887518 0.447625 0.382692 0.679273 0.861176 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 322
Initial state: 0 0.396626 0.749834 0.68568 0.861293 0.605653 0.832902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54366 episodes
GETTING ACTION FROM:
action 1, numVisits=54359, meanQ=5.050553, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.396626 0.749834 0.68568 0.861293 0.605653 0.832902 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8870, meanQ=8.307647, numObservations: 4
action 3, numVisits=9, meanQ=6.110011, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2197 episodes
GETTING ACTION FROM:
action 2, numVisits=8870, meanQ=8.307647, numObservations: 4
action 3, numVisits=39, meanQ=5.768977, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action 0, numVisits=2162, meanQ=0.196587, numObservations: 1
action -1, numVisits=6, meanQ=-2.501600, numObservations: 1
action: 2
Next state: 1 0.396626 0.749834 0.68568 0.861293 0.605653 0.832902 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 323
Initial state: 0 0.0424609 0.945823 0.673287 0.821908 0.672093 0.854241 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54115 episodes
GETTING ACTION FROM:
action 1, numVisits=54108, meanQ=4.947728, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.0424609 0.945823 0.673287 0.821908 0.672093 0.854241 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 324
Initial state: 0 0.387247 0.0859718 0.56365 0.807731 0.680931 0.899809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54522 episodes
GETTING ACTION FROM:
action 2, numVisits=54429, meanQ=4.998593, numObservations: 4
action -1, numVisits=86, meanQ=2.888606, numObservations: 1
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.387247 0.0859718 0.56365 0.807731 0.680931 0.899809 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 325
Initial state: 0 0.390256 0.565545 0.599858 0.83735 0.538397 0.897244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54209 episodes
GETTING ACTION FROM:
action 2, numVisits=54190, meanQ=4.923357, numObservations: 4
action 3, numVisits=14, meanQ=0.786443, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.390256 0.565545 0.599858 0.83735 0.538397 0.897244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3938, meanQ=4.641553, numObservations: 5
action 0, numVisits=83, meanQ=4.086586, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 67206 episodes
GETTING ACTION FROM:
action 1, numVisits=67200, meanQ=5.983412, numObservations: 5
action 3, numVisits=3938, meanQ=4.641553, numObservations: 5
action 0, numVisits=90, meanQ=3.663520, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.390256 0.565545 0.599858 0.83735 0.538397 0.897244 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=792, meanQ=8.179199, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10808 episodes
GETTING ACTION FROM:
action 3, numVisits=792, meanQ=8.179199, numObservations: 4
action 2, numVisits=242, meanQ=5.055503, numObservations: 4
action -1, numVisits=10562, meanQ=-1.666877, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 0, numVisits=5, meanQ=-78.677457, numObservations: 1
action: 3
Next state: 1 0.390256 0.565545 0.599858 0.83735 0.538397 0.897244 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 326
Initial state: 0 0.220329 0.209654 0.678277 0.817987 0.549363 0.887158 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54216 episodes
GETTING ACTION FROM:
action 3, numVisits=54185, meanQ=4.975764, numObservations: 5
action 0, numVisits=21, meanQ=3.445481, numObservations: 1
action 1, numVisits=6, meanQ=1.333333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.220329 0.209654 0.678277 0.817987 0.549363 0.887158 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 327
Initial state: 0 0.518486 0.815272 0.131286 0.784238 0.580877 0.873992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52313 episodes
GETTING ACTION FROM:
action 1, numVisits=50146, meanQ=4.941615, numObservations: 4
action 0, numVisits=1918, meanQ=2.793010, numObservations: 1
action -1, numVisits=205, meanQ=2.531600, numObservations: 1
action 3, numVisits=25, meanQ=1.735200, numObservations: 3
action 2, numVisits=19, meanQ=1.631579, numObservations: 4
action: 1
Next state: 1 0.518486 0.815272 0.131286 0.784238 0.580877 0.873992 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 328
Initial state: 0 0.0809108 0.0539902 0.654632 0.896524 0.504648 0.831206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54239 episodes
GETTING ACTION FROM:
action 3, numVisits=54191, meanQ=4.985499, numObservations: 4
action 0, numVisits=36, meanQ=3.839454, numObservations: 1
action 2, numVisits=8, meanQ=2.366262, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.0809108 0.0539902 0.654632 0.896524 0.504648 0.831206 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 329
Initial state: 0 0.662536 0.886824 0.616432 0.866319 0.523127 0.438853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53844 episodes
GETTING ACTION FROM:
action 2, numVisits=51920, meanQ=4.992915, numObservations: 3
action 1, numVisits=1887, meanQ=4.764705, numObservations: 4
action 3, numVisits=33, meanQ=3.751821, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.662536 0.886824 0.616432 0.866319 0.523127 0.438853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3822, meanQ=4.900197, numObservations: 5
action 2, numVisits=13, meanQ=2.222308, numObservations: 3
action 1, numVisits=6, meanQ=1.663333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 65752 episodes
GETTING ACTION FROM:
action 3, numVisits=69566, meanQ=5.678941, numObservations: 5
action 1, numVisits=11, meanQ=3.180000, numObservations: 4
action 2, numVisits=13, meanQ=2.222308, numObservations: 3
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 2 0.662536 0.886824 0.616432 0.866319 0.523127 0.438853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 330
Initial state: 0 0.585458 0.854128 0.531164 0.820763 0.302549 0.678252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50746 episodes
GETTING ACTION FROM:
action 2, numVisits=44644, meanQ=4.990527, numObservations: 4
action -1, numVisits=6098, meanQ=3.315212, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.585458 0.854128 0.531164 0.820763 0.302549 0.678252 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 331
Initial state: 0 0.680765 0.805426 0.595314 0.849418 0.939147 0.105956 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54675 episodes
GETTING ACTION FROM:
action 3, numVisits=54669, meanQ=5.244161, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.680765 0.805426 0.595314 0.849418 0.939147 0.105956 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 332
Initial state: 0 0.0234235 0.413048 0.595072 0.821423 0.648742 0.839875 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54393 episodes
GETTING ACTION FROM:
action 1, numVisits=54380, meanQ=4.921946, numObservations: 4
action 2, numVisits=7, meanQ=2.428571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 1
Next state: 2 0.0234235 0.413048 0.595072 0.821423 0.648742 0.839875 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 333
Initial state: 0 0.621189 0.809617 0.752374 0.294081 0.556257 0.881874 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54215 episodes
GETTING ACTION FROM:
action 1, numVisits=54192, meanQ=4.971168, numObservations: 5
action 3, numVisits=13, meanQ=2.693854, numObservations: 4
action 2, numVisits=6, meanQ=1.498333, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.621189 0.809617 0.752374 0.294081 0.556257 0.881874 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4004, meanQ=4.892352, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 66919 episodes
GETTING ACTION FROM:
action 3, numVisits=66915, meanQ=5.912498, numObservations: 5
action 2, numVisits=4004, meanQ=4.892352, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-2.003300, numObservations: 1
action 1, numVisits=2, meanQ=-11.000000, numObservations: 2
action: 3
Next state: 1 0.621189 0.809617 0.752374 0.294081 0.556257 0.881874 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 334
Initial state: 0 0.650025 0.835191 0.889938 0.846332 0.607623 0.875499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54444 episodes
GETTING ACTION FROM:
action 3, numVisits=54427, meanQ=5.009070, numObservations: 4
action 1, numVisits=12, meanQ=1.585008, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.650025 0.835191 0.889938 0.846332 0.607623 0.875499 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 335
Initial state: 0 0.681225 0.882328 0.642309 0.858495 0.464552 0.372532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54106 episodes
GETTING ACTION FROM:
action 1, numVisits=54058, meanQ=4.961213, numObservations: 4
action 0, numVisits=41, meanQ=3.919502, numObservations: 1
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.681225 0.882328 0.642309 0.858495 0.464552 0.372532 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 336
Initial state: 0 0.542314 0.18975 0.642671 0.835563 0.571216 0.886894 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53624 episodes
GETTING ACTION FROM:
action 3, numVisits=53610, meanQ=5.026765, numObservations: 5
action 1, numVisits=9, meanQ=2.678889, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.542314 0.18975 0.642671 0.835563 0.571216 0.886894 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 337
Initial state: 0 0.537013 0.869501 0.498826 0.437604 0.664709 0.804039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32017 episodes
GETTING ACTION FROM:
action 0, numVisits=31755, meanQ=2.999774, numObservations: 1
action -1, numVisits=255, meanQ=2.632186, numObservations: 1
action 2, numVisits=4, meanQ=-0.999975, numObservations: 2
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.537013 0.869501 0.498826 0.437604 0.664709 0.804039 w: 1
Observation: 0 0 0.870107 0 0.463401 0 0.898054 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31707, meanQ=5.063365, numObservations: 5
action -1, numVisits=19, meanQ=3.586255, numObservations: 1
action 2, numVisits=25, meanQ=3.389212, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55749 episodes
GETTING ACTION FROM:
action 1, numVisits=87454, meanQ=4.929089, numObservations: 5
action -1, numVisits=21, meanQ=3.446538, numObservations: 1
action 2, numVisits=25, meanQ=3.389212, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.537013 0.869501 0.498826 0.437604 0.664709 0.804039 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 338
Initial state: 0 0.223367 0.935212 0.632163 0.8594 0.518611 0.846181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54467 episodes
GETTING ACTION FROM:
action 1, numVisits=54461, meanQ=5.021712, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.223367 0.935212 0.632163 0.8594 0.518611 0.846181 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 339
Initial state: 0 0.54561 0.888569 0.599362 0.877748 0.809934 0.148922 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51284 episodes
GETTING ACTION FROM:
action 1, numVisits=51272, meanQ=4.847127, numObservations: 4
action 2, numVisits=7, meanQ=0.145729, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.54561 0.888569 0.599362 0.877748 0.809934 0.148922 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 340
Initial state: 0 0.559509 0.878539 0.401202 0.694769 0.605519 0.857454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53818 episodes
GETTING ACTION FROM:
action 2, numVisits=53808, meanQ=4.979338, numObservations: 5
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.559509 0.878539 0.401202 0.694769 0.605519 0.857454 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6169, meanQ=8.508996, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3698 episodes
GETTING ACTION FROM:
action 3, numVisits=6169, meanQ=8.508996, numObservations: 3
action 1, numVisits=12, meanQ=4.665833, numObservations: 4
action 0, numVisits=3345, meanQ=0.357650, numObservations: 1
action -1, numVisits=343, meanQ=0.106997, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.559509 0.878539 0.401202 0.694769 0.605519 0.857454 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 341
Initial state: 0 0.514213 0.84506 0.352311 0.489245 0.559156 0.814956 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32045 episodes
GETTING ACTION FROM:
action 0, numVisits=32011, meanQ=3.086553, numObservations: 1
action 1, numVisits=21, meanQ=1.658571, numObservations: 3
action 2, numVisits=10, meanQ=0.790000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.514213 0.84506 0.352311 0.489245 0.559156 0.814956 w: 1
Observation: 0 0 0.878092 0 0.502138 0 0.7753 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31999, meanQ=5.160589, numObservations: 5
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 54578 episodes
GETTING ACTION FROM:
action 2, numVisits=86574, meanQ=5.216641, numObservations: 5
action 3, numVisits=8, meanQ=0.748762, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 2
Next state: 0 0.514213 0.84506 0.352311 0.489245 0.559156 0.814956 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=10755, meanQ=8.528183, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1674 episodes
GETTING ACTION FROM:
action 3, numVisits=10755, meanQ=8.528183, numObservations: 3
action 2, numVisits=17, meanQ=6.293535, numObservations: 4
action 1, numVisits=16, meanQ=5.293568, numObservations: 4
action 0, numVisits=1639, meanQ=0.294698, numObservations: 1
action -1, numVisits=7, meanQ=-2.287100, numObservations: 1
action: 3
Next state: 1 0.514213 0.84506 0.352311 0.489245 0.559156 0.814956 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 342
Initial state: 0 0.962685 0.0793542 0.522585 0.821512 0.550102 0.866879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54252 episodes
GETTING ACTION FROM:
action 3, numVisits=54164, meanQ=5.008795, numObservations: 4
action 0, numVisits=75, meanQ=4.243804, numObservations: 1
action 2, numVisits=10, meanQ=2.400000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.962685 0.0793542 0.522585 0.821512 0.550102 0.866879 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 343
Initial state: 0 0.502327 0.836223 0.938517 0.567457 0.624842 0.841382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53928 episodes
GETTING ACTION FROM:
action 1, numVisits=53920, meanQ=4.972268, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.502327 0.836223 0.938517 0.567457 0.624842 0.841382 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 344
Initial state: 0 0.733228 0.880676 0.58829 0.842105 0.681236 0.894861 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54213 episodes
GETTING ACTION FROM:
action 2, numVisits=54199, meanQ=4.914525, numObservations: 3
action 3, numVisits=9, meanQ=1.776667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.733228 0.880676 0.58829 0.842105 0.681236 0.894861 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 345
Initial state: 0 0.0277623 0.18812 0.552913 0.891706 0.62027 0.857358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51456 episodes
GETTING ACTION FROM:
action 1, numVisits=51201, meanQ=4.834479, numObservations: 4
action 2, numVisits=166, meanQ=4.322607, numObservations: 3
action 0, numVisits=50, meanQ=3.909926, numObservations: 1
action 3, numVisits=37, meanQ=3.719732, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0277623 0.18812 0.552913 0.891706 0.62027 0.857358 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7153, meanQ=8.221048, numObservations: 3
action 3, numVisits=5, meanQ=3.402020, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2285 episodes
GETTING ACTION FROM:
action 2, numVisits=7192, meanQ=8.202081, numObservations: 3
action 3, numVisits=100, meanQ=7.025775, numObservations: 5
action 1, numVisits=3, meanQ=4.996667, numObservations: 2
action -1, numVisits=2138, meanQ=0.383307, numObservations: 1
action 0, numVisits=13, meanQ=-2.077677, numObservations: 1
action: 2
Next state: 1 0.0277623 0.18812 0.552913 0.891706 0.62027 0.857358 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 346
Initial state: 0 0.620928 0.800874 0.610496 0.882416 0.698147 0.230206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54317 episodes
GETTING ACTION FROM:
action 3, numVisits=54308, meanQ=4.964623, numObservations: 4
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 3
Next state: 0 0.620928 0.800874 0.610496 0.882416 0.698147 0.230206 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7582, meanQ=8.384886, numObservations: 4
action 1, numVisits=21, meanQ=7.095243, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3354 episodes
GETTING ACTION FROM:
action 2, numVisits=7582, meanQ=8.384886, numObservations: 4
action 1, numVisits=89, meanQ=6.560788, numObservations: 3
action -1, numVisits=3273, meanQ=0.254345, numObservations: 1
action 3, numVisits=9, meanQ=-0.445556, numObservations: 4
action 0, numVisits=7, meanQ=-2.287100, numObservations: 1
action: 2
Next state: 1 0.620928 0.800874 0.610496 0.882416 0.698147 0.230206 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 347
Initial state: 0 0.605829 0.819568 0.11417 0.969595 0.538551 0.802032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54403 episodes
GETTING ACTION FROM:
action 1, numVisits=54341, meanQ=4.976050, numObservations: 4
action 3, numVisits=37, meanQ=3.445138, numObservations: 3
action -1, numVisits=22, meanQ=3.228706, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.605829 0.819568 0.11417 0.969595 0.538551 0.802032 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 348
Initial state: 0 0.639669 0.890808 0.627437 0.842747 0.0571869 0.759509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54522 episodes
GETTING ACTION FROM:
action 3, numVisits=54370, meanQ=5.035407, numObservations: 5
action 0, numVisits=101, meanQ=4.382962, numObservations: 1
action 1, numVisits=34, meanQ=3.842062, numObservations: 4
action 2, numVisits=15, meanQ=2.532000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.639669 0.890808 0.627437 0.842747 0.0571869 0.759509 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7583, meanQ=8.331244, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 4852 episodes
GETTING ACTION FROM:
action 1, numVisits=7583, meanQ=8.331244, numObservations: 5
action 2, numVisits=31, meanQ=5.386774, numObservations: 4
action 0, numVisits=4655, meanQ=0.327508, numObservations: 1
action -1, numVisits=168, meanQ=-0.090773, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 1
Next state: 1 0.639669 0.890808 0.627437 0.842747 0.0571869 0.759509 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 349
Initial state: 0 0.677048 0.834685 0.672808 0.817311 0.543984 0.59592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50651 episodes
GETTING ACTION FROM:
action 2, numVisits=50636, meanQ=4.711987, numObservations: 5
action 1, numVisits=10, meanQ=1.899000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.677048 0.834685 0.672808 0.817311 0.543984 0.59592 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 350
Initial state: 0 0.601024 0.849686 0.662723 0.813935 0.907204 0.949201 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51615 episodes
GETTING ACTION FROM:
action 2, numVisits=51465, meanQ=4.863567, numObservations: 4
action -1, numVisits=95, meanQ=4.207421, numObservations: 1
action 3, numVisits=52, meanQ=3.699427, numObservations: 4
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.601024 0.849686 0.662723 0.813935 0.907204 0.949201 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 351
Initial state: 0 0.643325 0.871492 0.56935 0.82559 0.684105 0.236038 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53849 episodes
GETTING ACTION FROM:
action 2, numVisits=53611, meanQ=4.967145, numObservations: 4
action 0, numVisits=232, meanQ=2.395612, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.643325 0.871492 0.56935 0.82559 0.684105 0.236038 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 352
Initial state: 0 0.555331 0.832678 0.461208 0.885733 0.658799 0.88156 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54473 episodes
GETTING ACTION FROM:
action 1, numVisits=54382, meanQ=4.944435, numObservations: 4
action 3, numVisits=61, meanQ=3.813451, numObservations: 4
action -1, numVisits=27, meanQ=3.614831, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.555331 0.832678 0.461208 0.885733 0.658799 0.88156 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 353
Initial state: 0 0.678001 0.865614 0.699239 0.556234 0.564059 0.860621 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54106 episodes
GETTING ACTION FROM:
action 1, numVisits=53825, meanQ=4.965118, numObservations: 5
action 3, numVisits=224, meanQ=4.214856, numObservations: 4
action -1, numVisits=30, meanQ=3.714127, numObservations: 1
action 2, numVisits=25, meanQ=3.506004, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.678001 0.865614 0.699239 0.556234 0.564059 0.860621 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 354
Initial state: 0 0.535146 0.861928 0.582694 0.81216 0.948943 0.456111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54573 episodes
GETTING ACTION FROM:
action 2, numVisits=54468, meanQ=5.024339, numObservations: 4
action -1, numVisits=79, meanQ=4.292908, numObservations: 1
action 3, numVisits=13, meanQ=2.770008, numObservations: 3
action 1, numVisits=11, meanQ=2.729100, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.535146 0.861928 0.582694 0.81216 0.948943 0.456111 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 355
Initial state: 0 0.626277 0.804032 0.992543 0.545126 0.567626 0.846998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53336 episodes
GETTING ACTION FROM:
action 1, numVisits=53330, meanQ=4.936315, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.626277 0.804032 0.992543 0.545126 0.567626 0.846998 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 356
Initial state: 0 0.668204 0.864488 0.881153 0.264659 0.635792 0.888916 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52887 episodes
GETTING ACTION FROM:
action 2, numVisits=52881, meanQ=5.217992, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.668204 0.864488 0.881153 0.264659 0.635792 0.888916 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 357
Initial state: 0 0.693661 0.835951 0.614777 0.859519 0.396012 0.126153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31949 episodes
GETTING ACTION FROM:
action -1, numVisits=31935, meanQ=2.868670, numObservations: 1
action 3, numVisits=7, meanQ=-1.287143, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action: -1
Next state: 0 0.693661 0.835951 0.614777 0.859519 0.396012 0.126153 w: 1
Observation: 0 0.670659 0 0.627718 0 0.304158 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31920, meanQ=4.976498, numObservations: 4
action 3, numVisits=9, meanQ=0.997800, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54575 episodes
GETTING ACTION FROM:
action 1, numVisits=86484, meanQ=5.052805, numObservations: 4
action 2, numVisits=11, meanQ=1.271818, numObservations: 4
action 3, numVisits=9, meanQ=0.997800, numObservations: 3
action -1, numVisits=3, meanQ=0.966700, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.693661 0.835951 0.614777 0.859519 0.396012 0.126153 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 358
Initial state: 0 0.306158 0.948 0.515017 0.817042 0.64087 0.881009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52142 episodes
GETTING ACTION FROM:
action 1, numVisits=49790, meanQ=5.012443, numObservations: 4
action -1, numVisits=2346, meanQ=2.757483, numObservations: 1
action 3, numVisits=3, meanQ=-0.659967, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.306158 0.948 0.515017 0.817042 0.64087 0.881009 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 359
Initial state: 0 0.585731 0.889911 0.700877 0.878749 0.659041 0.803214 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53736 episodes
GETTING ACTION FROM:
action 3, numVisits=53730, meanQ=4.946524, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.585731 0.889911 0.700877 0.878749 0.659041 0.803214 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 360
Initial state: 0 0.38588 0.158877 0.546324 0.830561 0.597873 0.880393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54614 episodes
GETTING ACTION FROM:
action 2, numVisits=54545, meanQ=5.058294, numObservations: 4
action -1, numVisits=51, meanQ=4.152019, numObservations: 1
action 3, numVisits=15, meanQ=2.593333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.38588 0.158877 0.546324 0.830561 0.597873 0.880393 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 361
Initial state: 0 0.612 0.898556 0.689772 0.827569 0.317652 0.575613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51704 episodes
GETTING ACTION FROM:
action 2, numVisits=50953, meanQ=4.893525, numObservations: 3
action 3, numVisits=662, meanQ=4.525023, numObservations: 4
action 0, numVisits=47, meanQ=3.900818, numObservations: 1
action -1, numVisits=41, meanQ=3.830682, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.612 0.898556 0.689772 0.827569 0.317652 0.575613 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 362
Initial state: 0 0.869596 0.718693 0.677862 0.826475 0.59806 0.881131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54297 episodes
GETTING ACTION FROM:
action 1, numVisits=54285, meanQ=4.971164, numObservations: 5
action 2, numVisits=5, meanQ=-1.600000, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.869596 0.718693 0.677862 0.826475 0.59806 0.881131 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 363
Initial state: 0 0.666946 0.890168 0.557578 0.801338 0.951489 0.0582333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54064 episodes
GETTING ACTION FROM:
action 3, numVisits=53993, meanQ=4.948661, numObservations: 4
action -1, numVisits=55, meanQ=4.068904, numObservations: 1
action 2, numVisits=11, meanQ=2.909100, numObservations: 4
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.666946 0.890168 0.557578 0.801338 0.951489 0.0582333 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 364
Initial state: 0 0.445143 0.953458 0.511961 0.834425 0.63825 0.847149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53985 episodes
GETTING ACTION FROM:
action 2, numVisits=53978, meanQ=4.858162, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.445143 0.953458 0.511961 0.834425 0.63825 0.847149 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 365
Initial state: 0 0.639466 0.856572 0.709038 0.729222 0.610203 0.800438 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54188 episodes
GETTING ACTION FROM:
action 1, numVisits=54174, meanQ=5.031124, numObservations: 4
action 2, numVisits=9, meanQ=0.888889, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.639466 0.856572 0.709038 0.729222 0.610203 0.800438 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 366
Initial state: 0 0.629733 0.850549 0.566213 0.81834 0.339082 0.405742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54401 episodes
GETTING ACTION FROM:
action 2, numVisits=54360, meanQ=5.016420, numObservations: 5
action 0, numVisits=35, meanQ=3.900708, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.629733 0.850549 0.566213 0.81834 0.339082 0.405742 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 367
Initial state: 0 0.583885 0.854332 0.177612 0.410505 0.672943 0.81339 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54226 episodes
GETTING ACTION FROM:
action 1, numVisits=54217, meanQ=4.964637, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.583885 0.854332 0.177612 0.410505 0.672943 0.81339 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 368
Initial state: 0 0.555648 0.804446 0.965247 0.23987 0.648458 0.824261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53887 episodes
GETTING ACTION FROM:
action 2, numVisits=53881, meanQ=4.926262, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.555648 0.804446 0.965247 0.23987 0.648458 0.824261 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 369
Initial state: 0 0.51711 0.87831 0.423152 0.738471 0.517263 0.89765 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53489 episodes
GETTING ACTION FROM:
action 1, numVisits=53467, meanQ=4.887461, numObservations: 4
action 3, numVisits=13, meanQ=3.070008, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.51711 0.87831 0.423152 0.738471 0.517263 0.89765 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 370
Initial state: 0 0.414579 0.647932 0.551438 0.88357 0.641001 0.817862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54145 episodes
GETTING ACTION FROM:
action 3, numVisits=53973, meanQ=4.981542, numObservations: 5
action -1, numVisits=167, meanQ=3.455639, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.414579 0.647932 0.551438 0.88357 0.641001 0.817862 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 371
Initial state: 0 0.585257 0.834582 0.973714 0.772878 0.623867 0.859265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54515 episodes
GETTING ACTION FROM:
action 2, numVisits=54445, meanQ=5.016227, numObservations: 4
action -1, numVisits=62, meanQ=4.074419, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 3
action 3, numVisits=3, meanQ=0.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.585257 0.834582 0.973714 0.772878 0.623867 0.859265 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3934, meanQ=5.508857, numObservations: 4
action 1, numVisits=20, meanQ=4.185500, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3574 episodes
GETTING ACTION FROM:
action 3, numVisits=15, meanQ=6.866000, numObservations: 3
action 2, numVisits=3934, meanQ=5.508857, numObservations: 4
action 1, numVisits=20, meanQ=4.185500, numObservations: 5
action -1, numVisits=3555, meanQ=0.190810, numObservations: 1
action 0, numVisits=7, meanQ=-2.144257, numObservations: 1
action: 3
Next state: 1 0.585257 0.834582 0.973714 0.772878 0.623867 0.859265 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 372
Initial state: 0 0.516129 0.843385 0.524139 0.121023 0.550455 0.813381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31871 episodes
GETTING ACTION FROM:
action -1, numVisits=31862, meanQ=2.945857, numObservations: 1
action 1, numVisits=4, meanQ=-1.494975, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=2, meanQ=-5.489950, numObservations: 1
action: -1
Next state: 0 0.516129 0.843385 0.524139 0.121023 0.550455 0.813381 w: 1
Observation: 0 0.494834 0 0.540936 0 0.575252 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31760, meanQ=4.958960, numObservations: 5
action -1, numVisits=90, meanQ=4.293113, numObservations: 1
action 2, numVisits=8, meanQ=1.996250, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54014 episodes
GETTING ACTION FROM:
action 3, numVisits=85764, meanQ=4.965704, numObservations: 5
action -1, numVisits=93, meanQ=4.279832, numObservations: 1
action 1, numVisits=8, meanQ=2.498750, numObservations: 3
action 2, numVisits=8, meanQ=1.996250, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.516129 0.843385 0.524139 0.121023 0.550455 0.813381 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 373
Initial state: 0 0.651118 0.853832 0.623402 0.810402 0.301496 0.993146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54581 episodes
GETTING ACTION FROM:
action 3, numVisits=54452, meanQ=5.015357, numObservations: 5
action -1, numVisits=78, meanQ=4.176497, numObservations: 1
action 0, numVisits=39, meanQ=3.887356, numObservations: 1
action 1, numVisits=9, meanQ=2.554444, numObservations: 3
action 2, numVisits=3, meanQ=0.333333, numObservations: 2
action: 3
Next state: 1 0.651118 0.853832 0.623402 0.810402 0.301496 0.993146 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 374
Initial state: 0 0.24537 0.504614 0.612683 0.827814 0.514813 0.857633 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54426 episodes
GETTING ACTION FROM:
action 2, numVisits=52678, meanQ=5.020142, numObservations: 5
action 1, numVisits=1667, meanQ=4.881065, numObservations: 5
action 0, numVisits=49, meanQ=4.086833, numObservations: 1
action -1, numVisits=13, meanQ=3.143786, numObservations: 1
action 3, numVisits=19, meanQ=3.094737, numObservations: 4
action: 2
Next state: 1 0.24537 0.504614 0.612683 0.827814 0.514813 0.857633 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 375
Initial state: 0 0.991002 0.466579 0.524725 0.871925 0.586791 0.836919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54096 episodes
GETTING ACTION FROM:
action 2, numVisits=53896, meanQ=4.942801, numObservations: 4
action 0, numVisits=125, meanQ=4.347569, numObservations: 1
action -1, numVisits=73, meanQ=4.170710, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 1 0.991002 0.466579 0.524725 0.871925 0.586791 0.836919 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 376
Initial state: 0 0.735505 0.123383 0.626863 0.857243 0.525153 0.836071 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53801 episodes
GETTING ACTION FROM:
action 1, numVisits=53068, meanQ=5.013637, numObservations: 5
action 3, numVisits=727, meanQ=4.782580, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.735505 0.123383 0.626863 0.857243 0.525153 0.836071 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3806, meanQ=4.686393, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2013 episodes
GETTING ACTION FROM:
action 3, numVisits=33, meanQ=4.757576, numObservations: 4
action 2, numVisits=3806, meanQ=4.686393, numObservations: 4
action 1, numVisits=23, meanQ=4.347830, numObservations: 4
action 0, numVisits=1943, meanQ=0.223026, numObservations: 1
action -1, numVisits=19, meanQ=-2.105774, numObservations: 1
action: 3
Next state: 1 0.735505 0.123383 0.626863 0.857243 0.525153 0.836071 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 377
Initial state: 0 0.650253 0.861801 0.114585 0.114221 0.570905 0.804715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52417 episodes
GETTING ACTION FROM:
action 3, numVisits=52360, meanQ=4.916879, numObservations: 5
action 0, numVisits=51, meanQ=3.989208, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-4.499950, numObservations: 1
action: 3
Next state: 0 0.650253 0.861801 0.114585 0.114221 0.570905 0.804715 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1201, meanQ=6.409668, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 10539 episodes
GETTING ACTION FROM:
action 1, numVisits=1201, meanQ=6.409668, numObservations: 4
action 3, numVisits=4, meanQ=5.997500, numObservations: 1
action -1, numVisits=10533, meanQ=0.291672, numObservations: 1
action 2, numVisits=2, meanQ=-3.505000, numObservations: 2
action 0, numVisits=4, meanQ=-5.116521, numObservations: 1
action: 1
Next state: 1 0.650253 0.861801 0.114585 0.114221 0.570905 0.804715 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 378
Initial state: 0 0.550788 0.86074 0.438102 0.0418375 0.593517 0.870898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31878 episodes
GETTING ACTION FROM:
action 0, numVisits=31867, meanQ=2.764990, numObservations: 1
action 1, numVisits=5, meanQ=-2.418000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 0
Next state: 0 0.550788 0.86074 0.438102 0.0418375 0.593517 0.870898 w: 1
Observation: 0 0 0.848189 0 0.0646882 0 0.805814 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31814, meanQ=4.915188, numObservations: 4
action 0, numVisits=44, meanQ=3.856037, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 54645 episodes
GETTING ACTION FROM:
action 3, numVisits=86458, meanQ=5.001453, numObservations: 4
action 0, numVisits=45, meanQ=3.827821, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.550788 0.86074 0.438102 0.0418375 0.593517 0.870898 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 379
Initial state: 0 0.551175 0.833504 0.763663 0.320026 0.541518 0.824445 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51805 episodes
GETTING ACTION FROM:
action 1, numVisits=51764, meanQ=4.865671, numObservations: 3
action -1, numVisits=37, meanQ=3.765735, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.551175 0.833504 0.763663 0.320026 0.541518 0.824445 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 380
Initial state: 0 0.528219 0.834048 0.289637 0.512132 0.68181 0.837794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53806 episodes
GETTING ACTION FROM:
action 1, numVisits=53788, meanQ=4.940166, numObservations: 4
action 3, numVisits=8, meanQ=2.498750, numObservations: 2
action 2, numVisits=6, meanQ=2.166700, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.528219 0.834048 0.289637 0.512132 0.68181 0.837794 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 381
Initial state: 0 0.56584 0.820478 0.306666 0.278346 0.620884 0.809869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53903 episodes
GETTING ACTION FROM:
action 3, numVisits=53888, meanQ=4.977901, numObservations: 5
action 2, numVisits=10, meanQ=2.900020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.56584 0.820478 0.306666 0.278346 0.620884 0.809869 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 382
Initial state: 0 0.54802 0.826873 0.297691 0.359845 0.628779 0.885677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54258 episodes
GETTING ACTION FROM:
action 1, numVisits=54188, meanQ=5.015472, numObservations: 4
action 2, numVisits=63, meanQ=4.140003, numObservations: 4
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.54802 0.826873 0.297691 0.359845 0.628779 0.885677 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 383
Initial state: 0 0.535081 0.896929 0.439213 0.389494 0.692836 0.856907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31819 episodes
GETTING ACTION FROM:
action -1, numVisits=31578, meanQ=3.002781, numObservations: 1
action 0, numVisits=231, meanQ=2.613913, numObservations: 1
action 1, numVisits=7, meanQ=0.428571, numObservations: 4
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.535081 0.896929 0.439213 0.389494 0.692836 0.856907 w: 1
Observation: 0 0.626585 0 0.421443 0 0.762166 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31563, meanQ=5.050984, numObservations: 3
action 3, numVisits=9, meanQ=0.331122, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54273 episodes
GETTING ACTION FROM:
action 1, numVisits=45663, meanQ=5.131986, numObservations: 4
action 2, numVisits=40174, meanQ=5.011179, numObservations: 3
action 3, numVisits=9, meanQ=0.331122, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.535081 0.896929 0.439213 0.389494 0.692836 0.856907 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 384
Initial state: 0 0.40328 0.963075 0.528973 0.863227 0.6265 0.818228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53934 episodes
GETTING ACTION FROM:
action 2, numVisits=53858, meanQ=5.007026, numObservations: 4
action 0, numVisits=70, meanQ=4.227130, numObservations: 1
action 3, numVisits=3, meanQ=-0.659967, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.40328 0.963075 0.528973 0.863227 0.6265 0.818228 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 385
Initial state: 0 0.89003 0.707194 0.697123 0.880399 0.646089 0.889016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31946 episodes
GETTING ACTION FROM:
action -1, numVisits=26557, meanQ=3.054760, numObservations: 1
action 0, numVisits=5374, meanQ=3.006419, numObservations: 1
action 3, numVisits=13, meanQ=1.079246, numObservations: 3
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.89003 0.707194 0.697123 0.880399 0.646089 0.889016 w: 1
Observation: 0 0.807947 0 0.737812 0 0.707618 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=26528, meanQ=5.078690, numObservations: 5
action 0, numVisits=16, meanQ=3.428397, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 54003 episodes
GETTING ACTION FROM:
action 1, numVisits=80530, meanQ=4.968179, numObservations: 5
action 0, numVisits=17, meanQ=3.330258, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.89003 0.707194 0.697123 0.880399 0.646089 0.889016 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 386
Initial state: 0 0.609881 0.845667 0.666513 0.819241 0.220046 0.05035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54441 episodes
GETTING ACTION FROM:
action 2, numVisits=54435, meanQ=5.010349, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.609881 0.845667 0.666513 0.819241 0.220046 0.05035 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 387
Initial state: 0 0.675036 0.810891 0.162648 0.726043 0.699904 0.856354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54152 episodes
GETTING ACTION FROM:
action 3, numVisits=53628, meanQ=4.990802, numObservations: 4
action -1, numVisits=516, meanQ=2.990027, numObservations: 1
action 2, numVisits=4, meanQ=-2.500000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 3
Next state: 1 0.675036 0.810891 0.162648 0.726043 0.699904 0.856354 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 388
Initial state: 0 0.302306 0.469943 0.619082 0.889327 0.518545 0.8774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53927 episodes
GETTING ACTION FROM:
action 1, numVisits=53920, meanQ=5.016260, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.302306 0.469943 0.619082 0.889327 0.518545 0.8774 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8948, meanQ=8.310192, numObservations: 3
action 2, numVisits=12, meanQ=6.332500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2916 episodes
GETTING ACTION FROM:
action 3, numVisits=8948, meanQ=8.310192, numObservations: 3
action 2, numVisits=16, meanQ=4.499375, numObservations: 3
action 1, numVisits=3, meanQ=3.633333, numObservations: 2
action 0, numVisits=2903, meanQ=0.179501, numObservations: 1
action -1, numVisits=9, meanQ=-1.890000, numObservations: 1
action: 3
Next state: 1 0.302306 0.469943 0.619082 0.889327 0.518545 0.8774 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 389
Initial state: 0 0.654766 0.890929 0.942503 0.448909 0.542466 0.829765 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54172 episodes
GETTING ACTION FROM:
action 3, numVisits=54139, meanQ=4.927795, numObservations: 3
action -1, numVisits=27, meanQ=3.661564, numObservations: 1
action 2, numVisits=3, meanQ=-0.659967, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.654766 0.890929 0.942503 0.448909 0.542466 0.829765 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 390
Initial state: 0 0.627147 0.112353 0.510834 0.85922 0.626208 0.856833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54411 episodes
GETTING ACTION FROM:
action 3, numVisits=53938, meanQ=4.998120, numObservations: 4
action 2, numVisits=444, meanQ=4.620633, numObservations: 4
action 0, numVisits=20, meanQ=3.512285, numObservations: 1
action 1, numVisits=7, meanQ=2.002871, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.627147 0.112353 0.510834 0.85922 0.626208 0.856833 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 391
Initial state: 0 0.523473 0.83924 0.631823 0.860712 0.981377 0.719154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53550 episodes
GETTING ACTION FROM:
action 3, numVisits=53520, meanQ=4.915408, numObservations: 5
action -1, numVisits=20, meanQ=3.390365, numObservations: 1
action 1, numVisits=7, meanQ=2.002871, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.523473 0.83924 0.631823 0.860712 0.981377 0.719154 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 392
Initial state: 0 0.73996 0.534497 0.580595 0.853683 0.583077 0.839381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51624 episodes
GETTING ACTION FROM:
action 1, numVisits=51613, meanQ=4.858155, numObservations: 4
action 3, numVisits=5, meanQ=-0.795980, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.73996 0.534497 0.580595 0.853683 0.583077 0.839381 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 393
Initial state: 0 0.241942 0.768687 0.684315 0.847049 0.587179 0.808391 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53777 episodes
GETTING ACTION FROM:
action 2, numVisits=52730, meanQ=4.992292, numObservations: 4
action -1, numVisits=1023, meanQ=3.213908, numObservations: 1
action 3, numVisits=20, meanQ=1.750000, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.241942 0.768687 0.684315 0.847049 0.587179 0.808391 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 394
Initial state: 0 0.0350263 0.631543 0.589971 0.889646 0.647475 0.879457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30924 episodes
GETTING ACTION FROM:
action -1, numVisits=30881, meanQ=2.828007, numObservations: 1
action 0, numVisits=35, meanQ=1.775029, numObservations: 1
action 3, numVisits=6, meanQ=-0.515000, numObservations: 2
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: -1
Next state: 0 0.0350263 0.631543 0.589971 0.889646 0.647475 0.879457 w: 1
Observation: 0 0.000157689 0 0.665748 0 0.589329 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=30859, meanQ=4.884069, numObservations: 5
action 3, numVisits=16, meanQ=3.237500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 52413 episodes
GETTING ACTION FROM:
action 1, numVisits=83266, meanQ=4.925094, numObservations: 5
action 3, numVisits=16, meanQ=3.237500, numObservations: 2
action 0, numVisits=3, meanQ=0.966700, numObservations: 1
action 2, numVisits=6, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.0350263 0.631543 0.589971 0.889646 0.647475 0.879457 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=4806, meanQ=8.398003, numObservations: 5
action 2, numVisits=6070, meanQ=8.373826, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2611 episodes
GETTING ACTION FROM:
action 3, numVisits=4847, meanQ=8.393454, numObservations: 5
action 2, numVisits=6070, meanQ=8.373826, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=2569, meanQ=-0.089373, numObservations: 1
action 0, numVisits=2, meanQ=-198.583869, numObservations: 1
action: 3
Next state: 1 0.0350263 0.631543 0.589971 0.889646 0.647475 0.879457 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 395
Initial state: 0 0.637474 0.834912 0.450404 0.416561 0.50138 0.803942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54501 episodes
GETTING ACTION FROM:
action 1, numVisits=54471, meanQ=5.195414, numObservations: 5
action 0, numVisits=23, meanQ=3.785883, numObservations: 1
action 3, numVisits=3, meanQ=0.333333, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.637474 0.834912 0.450404 0.416561 0.50138 0.803942 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 396
Initial state: 0 0.800263 0.236088 0.542198 0.848203 0.5461 0.849248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53592 episodes
GETTING ACTION FROM:
action 1, numVisits=53547, meanQ=4.910530, numObservations: 4
action -1, numVisits=35, meanQ=3.599214, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 2, numVisits=3, meanQ=0.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.800263 0.236088 0.542198 0.848203 0.5461 0.849248 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3971, meanQ=4.700001, numObservations: 3
action 3, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 7758 episodes
GETTING ACTION FROM:
action 2, numVisits=3971, meanQ=4.700001, numObservations: 3
action -1, numVisits=7677, meanQ=0.227209, numObservations: 1
action 0, numVisits=23, meanQ=-1.311735, numObservations: 2
action 3, numVisits=60, meanQ=-1.355124, numObservations: 4
action 1, numVisits=6, meanQ=-1.835000, numObservations: 4
action: 2
Next state: 1 0.800263 0.236088 0.542198 0.848203 0.5461 0.849248 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 397
Initial state: 0 0.6909 0.807848 0.721416 0.327929 0.505892 0.86046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53940 episodes
GETTING ACTION FROM:
action 3, numVisits=53866, meanQ=4.908567, numObservations: 3
action -1, numVisits=61, meanQ=4.065808, numObservations: 1
action 2, numVisits=10, meanQ=1.402020, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.6909 0.807848 0.721416 0.327929 0.505892 0.86046 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 398
Initial state: 0 0.595071 0.838683 0.682221 0.660964 0.623443 0.887069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31813 episodes
GETTING ACTION FROM:
action -1, numVisits=31796, meanQ=2.957439, numObservations: 1
action 3, numVisits=11, meanQ=0.910918, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.595071 0.838683 0.682221 0.660964 0.623443 0.887069 w: 1
Observation: 0 0.601345 0 0.730212 0 0.538412 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31724, meanQ=5.046932, numObservations: 5
action -1, numVisits=53, meanQ=4.195864, numObservations: 1
action 2, numVisits=13, meanQ=2.237692, numObservations: 2
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 55666 episodes
GETTING ACTION FROM:
action 1, numVisits=87387, meanQ=5.062751, numObservations: 5
action -1, numVisits=56, meanQ=4.162893, numObservations: 1
action 2, numVisits=13, meanQ=2.237692, numObservations: 2
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.595071 0.838683 0.682221 0.660964 0.623443 0.887069 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 399
Initial state: 0 0.602581 0.890316 0.589755 0.843405 0.29879 0.440417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54036 episodes
GETTING ACTION FROM:
action 1, numVisits=54012, meanQ=5.005904, numObservations: 5
action 2, numVisits=19, meanQ=3.473684, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.602581 0.890316 0.589755 0.843405 0.29879 0.440417 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 400
Initial state: 0 0.483336 0.625155 0.594489 0.840729 0.508851 0.82015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53026 episodes
GETTING ACTION FROM:
action 3, numVisits=51384, meanQ=4.943569, numObservations: 3
action -1, numVisits=1636, meanQ=2.713645, numObservations: 1
action 1, numVisits=3, meanQ=-0.700000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.483336 0.625155 0.594489 0.840729 0.508851 0.82015 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 401
Initial state: 0 0.64107 0.892622 0.533372 0.818574 0.317831 0.427163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53093 episodes
GETTING ACTION FROM:
action 1, numVisits=53082, meanQ=4.984716, numObservations: 5
action 2, numVisits=6, meanQ=1.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.64107 0.892622 0.533372 0.818574 0.317831 0.427163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 402
Initial state: 0 0.455716 0.954193 0.612866 0.812494 0.52151 0.804426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53798 episodes
GETTING ACTION FROM:
action 2, numVisits=53732, meanQ=4.914648, numObservations: 5
action 0, numVisits=62, meanQ=4.080181, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.455716 0.954193 0.612866 0.812494 0.52151 0.804426 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 403
Initial state: 0 0.18166 0.108652 0.673152 0.833245 0.560685 0.848441 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53997 episodes
GETTING ACTION FROM:
action 3, numVisits=53966, meanQ=4.999646, numObservations: 4
action 0, numVisits=20, meanQ=3.394821, numObservations: 1
action 2, numVisits=8, meanQ=2.375000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.18166 0.108652 0.673152 0.833245 0.560685 0.848441 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 404
Initial state: 0 0.984158 0.476504 0.543995 0.805542 0.500543 0.841276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53992 episodes
GETTING ACTION FROM:
action 2, numVisits=53931, meanQ=4.962813, numObservations: 3
action 0, numVisits=30, meanQ=3.757495, numObservations: 1
action 3, numVisits=24, meanQ=3.408758, numObservations: 4
action 1, numVisits=5, meanQ=1.000020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.984158 0.476504 0.543995 0.805542 0.500543 0.841276 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 405
Initial state: 0 0.536322 0.850785 0.611984 0.892875 0.961251 0.321987 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54136 episodes
GETTING ACTION FROM:
action 2, numVisits=54047, meanQ=5.033955, numObservations: 4
action 0, numVisits=51, meanQ=4.117360, numObservations: 1
action 3, numVisits=34, meanQ=3.195594, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.536322 0.850785 0.611984 0.892875 0.961251 0.321987 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 406
Initial state: 0 0.616944 0.819514 0.666398 0.880925 0.453872 0.0974766 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54408 episodes
GETTING ACTION FROM:
action 3, numVisits=54297, meanQ=5.033047, numObservations: 5
action -1, numVisits=59, meanQ=4.139419, numObservations: 1
action 0, numVisits=48, meanQ=4.076602, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.616944 0.819514 0.666398 0.880925 0.453872 0.0974766 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7402, meanQ=8.416230, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2081 episodes
GETTING ACTION FROM:
action 2, numVisits=7402, meanQ=8.416230, numObservations: 3
action 1, numVisits=17, meanQ=4.764118, numObservations: 3
action -1, numVisits=2061, meanQ=0.537681, numObservations: 1
action 0, numVisits=6, meanQ=-2.001650, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.616944 0.819514 0.666398 0.880925 0.453872 0.0974766 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 407
Initial state: 0 0.503135 0.858973 0.749361 0.599074 0.671556 0.899479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54261 episodes
GETTING ACTION FROM:
action 2, numVisits=54154, meanQ=4.993551, numObservations: 3
action -1, numVisits=87, meanQ=4.310042, numObservations: 1
action 1, numVisits=17, meanQ=3.288247, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.503135 0.858973 0.749361 0.599074 0.671556 0.899479 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3887, meanQ=5.413510, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
Sampled 3355 episodes
GETTING ACTION FROM:
action 2, numVisits=3887, meanQ=5.413510, numObservations: 4
action 1, numVisits=9, meanQ=2.333333, numObservations: 3
action 0, numVisits=3342, meanQ=0.367463, numObservations: 2
action -1, numVisits=7, meanQ=-2.905298, numObservations: 1
action 3, numVisits=4, meanQ=-4.002500, numObservations: 2
action: 2
Next state: 2 0.503135 0.858973 0.749361 0.599074 0.671556 0.899479 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 408
Initial state: 0 0.645058 0.813107 0.658843 0.811813 0.822459 0.13278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54190 episodes
GETTING ACTION FROM:
action 2, numVisits=53987, meanQ=4.969677, numObservations: 4
action 0, numVisits=195, meanQ=4.427011, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.645058 0.813107 0.658843 0.811813 0.822459 0.13278 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 409
Initial state: 0 0.626516 0.872964 0.00800378 0.826736 0.672247 0.83519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 55062 episodes
GETTING ACTION FROM:
action 2, numVisits=54262, meanQ=5.280925, numObservations: 5
action 1, numVisits=779, meanQ=5.055100, numObservations: 4
action 0, numVisits=17, meanQ=3.695201, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.626516 0.872964 0.00800378 0.826736 0.672247 0.83519 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3127, meanQ=7.954904, numObservations: 5
action 1, numVisits=13, meanQ=6.228462, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2481 episodes
GETTING ACTION FROM:
action 3, numVisits=3127, meanQ=7.954904, numObservations: 5
action 1, numVisits=38, meanQ=5.312632, numObservations: 4
action -1, numVisits=2456, meanQ=0.158974, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.626516 0.872964 0.00800378 0.826736 0.672247 0.83519 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 410
Initial state: 0 0.547003 0.885281 0.536263 0.807353 0.737441 0.0729505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54277 episodes
GETTING ACTION FROM:
action 3, numVisits=54227, meanQ=5.026965, numObservations: 4
action -1, numVisits=46, meanQ=4.050803, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.547003 0.885281 0.536263 0.807353 0.737441 0.0729505 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 411
Initial state: 0 0.401036 0.912541 0.599423 0.882436 0.650573 0.805651 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54140 episodes
GETTING ACTION FROM:
action 2, numVisits=54060, meanQ=4.993973, numObservations: 4
action 0, numVisits=67, meanQ=4.150689, numObservations: 1
action 1, numVisits=8, meanQ=0.873750, numObservations: 2
action 3, numVisits=3, meanQ=-0.659967, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.401036 0.912541 0.599423 0.882436 0.650573 0.805651 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 412
Initial state: 0 0.546772 0.853386 0.177839 0.660702 0.532304 0.839079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54395 episodes
GETTING ACTION FROM:
action 2, numVisits=54160, meanQ=4.960234, numObservations: 3
action 0, numVisits=101, meanQ=4.286185, numObservations: 1
action 1, numVisits=92, meanQ=4.201495, numObservations: 5
action -1, numVisits=38, meanQ=3.891389, numObservations: 1
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action: 2
Next state: 0 0.546772 0.853386 0.177839 0.660702 0.532304 0.839079 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8803, meanQ=8.279720, numObservations: 4
action 1, numVisits=34, meanQ=6.646482, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2780 episodes
GETTING ACTION FROM:
action 3, numVisits=8803, meanQ=8.279720, numObservations: 4
action 1, numVisits=43, meanQ=6.578847, numObservations: 3
action -1, numVisits=2765, meanQ=0.246387, numObservations: 1
action 0, numVisits=7, meanQ=-3.249735, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 3
Next state: 1 0.546772 0.853386 0.177839 0.660702 0.532304 0.839079 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 413
Initial state: 0 0.558974 0.822741 0.0748603 0.303208 0.554318 0.866801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54188 episodes
GETTING ACTION FROM:
action 1, numVisits=54181, meanQ=4.970216, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.558974 0.822741 0.0748603 0.303208 0.554318 0.866801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 414
Initial state: 0 0.648014 0.828505 0.173013 0.195297 0.664501 0.810356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54488 episodes
GETTING ACTION FROM:
action 1, numVisits=25928, meanQ=4.968435, numObservations: 3
action 3, numVisits=28554, meanQ=4.964013, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.648014 0.828505 0.173013 0.195297 0.664501 0.810356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 415
Initial state: 0 0.320862 0.846694 0.521905 0.894952 0.674518 0.815589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54546 episodes
GETTING ACTION FROM:
action 2, numVisits=54455, meanQ=4.988849, numObservations: 3
action 0, numVisits=43, meanQ=4.002686, numObservations: 1
action -1, numVisits=33, meanQ=3.796796, numObservations: 1
action 1, numVisits=14, meanQ=3.078579, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.320862 0.846694 0.521905 0.894952 0.674518 0.815589 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 416
Initial state: 0 0.588733 0.801286 0.548816 0.837459 0.422057 0.184533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54443 episodes
GETTING ACTION FROM:
action 3, numVisits=54260, meanQ=4.996290, numObservations: 5
action 0, numVisits=102, meanQ=4.354690, numObservations: 1
action -1, numVisits=77, meanQ=4.253784, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.588733 0.801286 0.548816 0.837459 0.422057 0.184533 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7586, meanQ=8.381433, numObservations: 3
action 1, numVisits=7, meanQ=4.427143, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 4459 episodes
GETTING ACTION FROM:
action 2, numVisits=7586, meanQ=8.381433, numObservations: 3
action 3, numVisits=3, meanQ=4.996667, numObservations: 3
action 1, numVisits=9, meanQ=3.221111, numObservations: 4
action -1, numVisits=4454, meanQ=0.214719, numObservations: 1
action 0, numVisits=3, meanQ=-4.453284, numObservations: 1
action: 2
Next state: 1 0.588733 0.801286 0.548816 0.837459 0.422057 0.184533 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 417
Initial state: 0 0.546985 0.837817 0.566018 0.858134 0.379683 0.93403 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54374 episodes
GETTING ACTION FROM:
action 2, numVisits=54307, meanQ=5.041706, numObservations: 5
action 3, numVisits=62, meanQ=4.162585, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.546985 0.837817 0.566018 0.858134 0.379683 0.93403 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 418
Initial state: 0 0.698504 0.846754 0.513013 0.865335 0.750582 0.93613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51485 episodes
GETTING ACTION FROM:
action 1, numVisits=51352, meanQ=4.799196, numObservations: 4
action -1, numVisits=128, meanQ=4.241449, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.698504 0.846754 0.513013 0.865335 0.750582 0.93613 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 419
Initial state: 0 0.561717 0.816471 0.590729 0.878824 0.269741 0.992996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54245 episodes
GETTING ACTION FROM:
action 1, numVisits=54222, meanQ=4.998368, numObservations: 5
action 2, numVisits=18, meanQ=2.721678, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.561717 0.816471 0.590729 0.878824 0.269741 0.992996 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4052, meanQ=5.522699, numObservations: 4
action 2, numVisits=8, meanQ=0.748763, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67880 episodes
GETTING ACTION FROM:
action 3, numVisits=67843, meanQ=5.906052, numObservations: 5
action 1, numVisits=4052, meanQ=5.522699, numObservations: 4
action 2, numVisits=42, meanQ=4.571193, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 3
Next state: 0 0.561717 0.816471 0.590729 0.878824 0.269741 0.992996 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1143, meanQ=7.456011, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 70299 episodes
GETTING ACTION FROM:
action 2, numVisits=66742, meanQ=6.358019, numObservations: 5
action 3, numVisits=4636, meanQ=6.115233, numObservations: 5
action 1, numVisits=62, meanQ=5.129032, numObservations: 4
action -1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 2
Next state: 1 0.561717 0.816471 0.590729 0.878824 0.269741 0.992996 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 420
Initial state: 0 0.217135 0.0919609 0.597563 0.886012 0.548006 0.867314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31807 episodes
GETTING ACTION FROM:
action -1, numVisits=31800, meanQ=2.895423, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.217135 0.0919609 0.597563 0.886012 0.548006 0.867314 w: 1
Observation: 0 0.207239 0 0.622828 0 0.503777 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31707, meanQ=4.935837, numObservations: 3
action -1, numVisits=77, meanQ=4.209436, numObservations: 1
action 2, numVisits=12, meanQ=1.497508, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54480 episodes
GETTING ACTION FROM:
action 3, numVisits=86185, meanQ=5.210699, numObservations: 3
action -1, numVisits=78, meanQ=4.186445, numObservations: 1
action 2, numVisits=12, meanQ=1.497508, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 0 0.217135 0.0919609 0.597563 0.886012 0.548006 0.867314 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=6405, meanQ=4.634799, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 65515 episodes
GETTING ACTION FROM:
action 1, numVisits=71869, meanQ=5.743923, numObservations: 4
action 2, numVisits=47, meanQ=3.765957, numObservations: 4
action -1, numVisits=3, meanQ=-2.003300, numObservations: 1
action 0, numVisits=3, meanQ=-2.003300, numObservations: 1
action 3, numVisits=4, meanQ=-5.752475, numObservations: 2
action: 1
Next state: 0 0.217135 0.0919609 0.597563 0.886012 0.548006 0.867314 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=796, meanQ=7.366078, numObservations: 3
action 2, numVisits=7, meanQ=5.001443, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 9729 episodes
GETTING ACTION FROM:
action 3, numVisits=813, meanQ=7.369248, numObservations: 3
action 1, numVisits=74, meanQ=5.418784, numObservations: 4
action 2, numVisits=28, meanQ=3.964646, numObservations: 3
action 0, numVisits=4346, meanQ=-1.624823, numObservations: 1
action -1, numVisits=5274, meanQ=-1.626451, numObservations: 1
action: 3
Next state: 1 0.217135 0.0919609 0.597563 0.886012 0.548006 0.867314 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -1.14771
Run # 421
Initial state: 0 0.503614 0.88967 0.124233 0.325717 0.670324 0.827346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53816 episodes
GETTING ACTION FROM:
action 1, numVisits=53695, meanQ=4.996154, numObservations: 4
action 0, numVisits=61, meanQ=4.147448, numObservations: 3
action -1, numVisits=57, meanQ=3.553188, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.503614 0.88967 0.124233 0.325717 0.670324 0.827346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 422
Initial state: 0 0.692492 0.826151 0.339121 0.391796 0.532183 0.899896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 41505 episodes
GETTING ACTION FROM:
action 2, numVisits=23149, meanQ=5.004176, numObservations: 3
action 0, numVisits=18334, meanQ=2.956579, numObservations: 1
action 1, numVisits=15, meanQ=0.680000, numObservations: 3
action 3, numVisits=5, meanQ=-0.200000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.692492 0.826151 0.339121 0.391796 0.532183 0.899896 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=3760, meanQ=8.290585, numObservations: 4
action 1, numVisits=21, meanQ=6.994767, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 4677 episodes
GETTING ACTION FROM:
action 3, numVisits=3760, meanQ=8.290585, numObservations: 4
action 1, numVisits=51, meanQ=6.213531, numObservations: 4
action 0, numVisits=1298, meanQ=0.396441, numObservations: 1
action -1, numVisits=3345, meanQ=0.389614, numObservations: 1
action 2, numVisits=7, meanQ=-1.883808, numObservations: 3
action: 3
Next state: 1 0.692492 0.826151 0.339121 0.391796 0.532183 0.899896 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 423
Initial state: 0 0.511459 0.852058 0.647182 0.853306 0.273073 0.877712 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 35625 episodes
GETTING ACTION FROM:
action 0, numVisits=30277, meanQ=5.883039, numObservations: 3
action 3, numVisits=5312, meanQ=4.767715, numObservations: 5
action -1, numVisits=26, meanQ=3.632153, numObservations: 1
action 1, numVisits=9, meanQ=2.333344, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.511459 0.852058 0.647182 0.853306 0.273073 0.877712 w: 1
Observation: 0 0 0.822186 0 0.952447 0 0.934751 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=13976, meanQ=7.638859, numObservations: 5
action 1, numVisits=14, meanQ=4.408571, numObservations: 3
action 3, numVisits=5, meanQ=3.402020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 55511 episodes
GETTING ACTION FROM:
action 2, numVisits=69482, meanQ=5.386820, numObservations: 5
action 1, numVisits=16, meanQ=3.732500, numObservations: 3
action 3, numVisits=6, meanQ=2.001700, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.511459 0.852058 0.647182 0.853306 0.273073 0.877712 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 424
Initial state: 0 0.59389 0.89894 0.0981452 0.526694 0.667131 0.844142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53545 episodes
GETTING ACTION FROM:
action 2, numVisits=53432, meanQ=5.091746, numObservations: 5
action 0, numVisits=72, meanQ=4.304486, numObservations: 1
action -1, numVisits=36, meanQ=3.954716, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action: 2
Next state: 0 0.59389 0.89894 0.0981452 0.526694 0.667131 0.844142 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6157, meanQ=8.526579, numObservations: 3
action 1, numVisits=21, meanQ=7.189529, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2499 episodes
GETTING ACTION FROM:
action 3, numVisits=6157, meanQ=8.526579, numObservations: 3
action 1, numVisits=51, meanQ=5.234906, numObservations: 4
action 2, numVisits=3, meanQ=4.996667, numObservations: 2
action -1, numVisits=2453, meanQ=0.027220, numObservations: 1
action 0, numVisits=16, meanQ=-1.443744, numObservations: 1
action: 3
Next state: 1 0.59389 0.89894 0.0981452 0.526694 0.667131 0.844142 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 425
Initial state: 0 0.520477 0.811761 0.59748 0.979867 0.578622 0.801964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54299 episodes
GETTING ACTION FROM:
action 3, numVisits=54291, meanQ=4.987672, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 3
Next state: 1 0.520477 0.811761 0.59748 0.979867 0.578622 0.801964 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 426
Initial state: 0 0.863553 0.00597089 0.516861 0.846202 0.529178 0.823794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54354 episodes
GETTING ACTION FROM:
action 3, numVisits=54327, meanQ=4.947188, numObservations: 5
action 0, numVisits=23, meanQ=3.551768, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.863553 0.00597089 0.516861 0.846202 0.529178 0.823794 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 427
Initial state: 0 0.548263 0.795524 0.642542 0.844469 0.614044 0.878374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54522 episodes
GETTING ACTION FROM:
action 3, numVisits=54337, meanQ=4.943338, numObservations: 4
action 1, numVisits=116, meanQ=4.256121, numObservations: 5
action -1, numVisits=54, meanQ=4.046920, numObservations: 1
action 2, numVisits=13, meanQ=2.693854, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.548263 0.795524 0.642542 0.844469 0.614044 0.878374 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 428
Initial state: 0 0.408143 0.825883 0.674433 0.805684 0.692376 0.894304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54156 episodes
GETTING ACTION FROM:
action 2, numVisits=54143, meanQ=4.991401, numObservations: 3
action 3, numVisits=8, meanQ=1.863750, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.408143 0.825883 0.674433 0.805684 0.692376 0.894304 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 429
Initial state: 0 0.28869 0.135291 0.511336 0.826313 0.51139 0.819277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54280 episodes
GETTING ACTION FROM:
action 3, numVisits=54258, meanQ=4.996581, numObservations: 4
action 2, numVisits=17, meanQ=2.818829, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.28869 0.135291 0.511336 0.826313 0.51139 0.819277 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 430
Initial state: 0 0.681916 0.86377 0.553504 0.881512 0.761204 0.149889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54048 episodes
GETTING ACTION FROM:
action 2, numVisits=54029, meanQ=5.009856, numObservations: 5
action 3, numVisits=9, meanQ=2.656678, numObservations: 3
action 1, numVisits=6, meanQ=2.333333, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.681916 0.86377 0.553504 0.881512 0.761204 0.149889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 431
Initial state: 0 0.739335 0.217505 0.640122 0.863263 0.595434 0.844853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54840 episodes
GETTING ACTION FROM:
action 3, numVisits=54832, meanQ=5.016133, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 3
Next state: 1 0.739335 0.217505 0.640122 0.863263 0.595434 0.844853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 432
Initial state: 0 0.519572 0.82304 0.598185 0.526225 0.69091 0.873196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32081 episodes
GETTING ACTION FROM:
action 0, numVisits=32033, meanQ=2.961655, numObservations: 1
action 3, numVisits=12, meanQ=0.919183, numObservations: 2
action 2, numVisits=16, meanQ=0.881263, numObservations: 3
action 1, numVisits=18, meanQ=0.775556, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.519572 0.82304 0.598185 0.526225 0.69091 0.873196 w: 1
Observation: 0 0 0.799511 0 0.538107 0 0.948277 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32026, meanQ=5.004584, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55160 episodes
GETTING ACTION FROM:
action 1, numVisits=87173, meanQ=5.077273, numObservations: 3
action 3, numVisits=12, meanQ=2.499167, numObservations: 4
action -1, numVisits=3, meanQ=0.966700, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=2, meanQ=-11.000000, numObservations: 2
action: 1
Next state: 1 0.519572 0.82304 0.598185 0.526225 0.69091 0.873196 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 433
Initial state: 0 0.641301 0.870873 0.661154 0.870296 0.514431 0.465746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54408 episodes
GETTING ACTION FROM:
action 3, numVisits=54236, meanQ=4.967542, numObservations: 5
action 2, numVisits=97, meanQ=4.248045, numObservations: 5
action -1, numVisits=71, meanQ=4.185192, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.641301 0.870873 0.661154 0.870296 0.514431 0.465746 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 434
Initial state: 0 0.685654 0.833421 0.870737 0.0254621 0.595531 0.864844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54196 episodes
GETTING ACTION FROM:
action 1, numVisits=54140, meanQ=4.951556, numObservations: 4
action 0, numVisits=34, meanQ=3.836900, numObservations: 1
action 3, numVisits=19, meanQ=3.052116, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.685654 0.833421 0.870737 0.0254621 0.595531 0.864844 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 435
Initial state: 0 0.402724 0.0978658 0.578102 0.827284 0.596734 0.882001 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54253 episodes
GETTING ACTION FROM:
action 3, numVisits=54161, meanQ=5.038168, numObservations: 4
action 0, numVisits=72, meanQ=4.278146, numObservations: 1
action -1, numVisits=15, meanQ=3.348158, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 1 0.402724 0.0978658 0.578102 0.827284 0.596734 0.882001 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 436
Initial state: 0 0.575056 0.843743 0.280043 0.393089 0.658001 0.862975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49349 episodes
GETTING ACTION FROM:
action 1, numVisits=49317, meanQ=4.646034, numObservations: 4
action -1, numVisits=23, meanQ=3.162778, numObservations: 1
action 3, numVisits=6, meanQ=-0.668333, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.575056 0.843743 0.280043 0.393089 0.658001 0.862975 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 437
Initial state: 0 0.656403 0.812146 0.662964 0.825407 0.434498 0.439026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54338 episodes
GETTING ACTION FROM:
action 3, numVisits=54198, meanQ=4.992261, numObservations: 4
action -1, numVisits=88, meanQ=4.286073, numObservations: 1
action 0, numVisits=48, meanQ=4.029772, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.656403 0.812146 0.662964 0.825407 0.434498 0.439026 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8756, meanQ=8.280809, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11443 episodes
GETTING ACTION FROM:
action 1, numVisits=8756, meanQ=8.280809, numObservations: 4
action 2, numVisits=28, meanQ=5.421786, numObservations: 4
action -1, numVisits=11400, meanQ=-0.209522, numObservations: 1
action 0, numVisits=18, meanQ=-1.945000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 1
Next state: 1 0.656403 0.812146 0.662964 0.825407 0.434498 0.439026 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 438
Initial state: 0 0.558098 0.880934 0.582993 0.803647 0.033877 0.355922 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 52964 episodes
GETTING ACTION FROM:
action 3, numVisits=29530, meanQ=4.921351, numObservations: 3
action 1, numVisits=23426, meanQ=4.906741, numObservations: 5
action 2, numVisits=4, meanQ=0.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.558098 0.880934 0.582993 0.803647 0.033877 0.355922 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4473, meanQ=8.301912, numObservations: 4
action 1, numVisits=393, meanQ=8.078252, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2140 episodes
GETTING ACTION FROM:
action 2, numVisits=4473, meanQ=8.301912, numObservations: 4
action 1, numVisits=393, meanQ=8.078252, numObservations: 3
action 3, numVisits=3, meanQ=4.996667, numObservations: 2
action -1, numVisits=2049, meanQ=0.109000, numObservations: 1
action 0, numVisits=91, meanQ=-0.618352, numObservations: 1
action: 2
Next state: 1 0.558098 0.880934 0.582993 0.803647 0.033877 0.355922 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 439
Initial state: 0 0.508541 0.840221 0.552808 0.844738 0.495193 0.365627 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54255 episodes
GETTING ACTION FROM:
action 2, numVisits=54211, meanQ=4.984836, numObservations: 5
action 0, numVisits=23, meanQ=3.536899, numObservations: 1
action -1, numVisits=19, meanQ=3.329352, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.508541 0.840221 0.552808 0.844738 0.495193 0.365627 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4152, meanQ=5.686107, numObservations: 3
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67167 episodes
GETTING ACTION FROM:
action 1, numVisits=67167, meanQ=5.955006, numObservations: 3
action 2, numVisits=4152, meanQ=5.686107, numObservations: 3
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 1
Next state: 1 0.508541 0.840221 0.552808 0.844738 0.495193 0.365627 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 440
Initial state: 0 0.616263 0.810211 0.513728 0.856308 0.953284 0.0986647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51957 episodes
GETTING ACTION FROM:
action 3, numVisits=51949, meanQ=4.963235, numObservations: 5
action 1, numVisits=3, meanQ=-0.659967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.616263 0.810211 0.513728 0.856308 0.953284 0.0986647 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 441
Initial state: 0 0.664267 0.868416 0.683004 0.83078 0.449704 0.295197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51427 episodes
GETTING ACTION FROM:
action 2, numVisits=51380, meanQ=4.871712, numObservations: 3
action 0, numVisits=37, meanQ=3.756077, numObservations: 1
action 1, numVisits=7, meanQ=1.844286, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.664267 0.868416 0.683004 0.83078 0.449704 0.295197 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 442
Initial state: 0 0.541205 0.860903 0.530646 0.827031 0.402926 0.775303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31156 episodes
GETTING ACTION FROM:
action -1, numVisits=31149, meanQ=2.778274, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.541205 0.860903 0.530646 0.827031 0.402926 0.775303 w: 1
Observation: 0 0.442406 0 0.554254 0 0.46942 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31089, meanQ=4.939965, numObservations: 4
action 0, numVisits=52, meanQ=3.956105, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 54527 episodes
GETTING ACTION FROM:
action 2, numVisits=85601, meanQ=4.598231, numObservations: 4
action 0, numVisits=66, meanQ=3.780310, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action: 2
Next state: 1 0.541205 0.860903 0.530646 0.827031 0.402926 0.775303 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 443
Initial state: 0 0.508091 0.84132 0.642032 0.331252 0.606549 0.81328 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54120 episodes
GETTING ACTION FROM:
action 3, numVisits=54092, meanQ=4.968844, numObservations: 4
action 0, numVisits=15, meanQ=3.165710, numObservations: 1
action 1, numVisits=10, meanQ=2.090000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.508091 0.84132 0.642032 0.331252 0.606549 0.81328 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3974, meanQ=4.645594, numObservations: 5
action 0, numVisits=115, meanQ=1.933422, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 66770 episodes
GETTING ACTION FROM:
action 1, numVisits=66727, meanQ=5.679661, numObservations: 5
action 2, numVisits=3974, meanQ=4.645594, numObservations: 5
action 3, numVisits=45, meanQ=4.016002, numObservations: 4
action 0, numVisits=115, meanQ=1.933422, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.508091 0.84132 0.642032 0.331252 0.606549 0.81328 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 444
Initial state: 0 0.663793 0.829418 0.512403 0.855821 0.916525 0.987549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51783 episodes
GETTING ACTION FROM:
action 1, numVisits=51754, meanQ=4.847039, numObservations: 4
action 3, numVisits=23, meanQ=3.114352, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.663793 0.829418 0.512403 0.855821 0.916525 0.987549 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 445
Initial state: 0 0.673223 0.898435 0.967159 0.513528 0.561575 0.838201 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53948 episodes
GETTING ACTION FROM:
action 2, numVisits=53927, meanQ=5.013317, numObservations: 5
action 3, numVisits=11, meanQ=2.363636, numObservations: 2
action 1, numVisits=6, meanQ=0.166667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.673223 0.898435 0.967159 0.513528 0.561575 0.838201 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 446
Initial state: 0 0.548842 0.832692 0.390405 0.707859 0.558195 0.888347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31921 episodes
GETTING ACTION FROM:
action -1, numVisits=31287, meanQ=2.952292, numObservations: 1
action 0, numVisits=623, meanQ=2.729427, numObservations: 1
action 3, numVisits=6, meanQ=-0.515000, numObservations: 3
action 1, numVisits=4, meanQ=-0.999975, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.548842 0.832692 0.390405 0.707859 0.558195 0.888347 w: 1
Observation: 0 0.505938 0 0.352041 0 0.512597 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31256, meanQ=5.024445, numObservations: 4
action 0, numVisits=23, meanQ=3.709749, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 55064 episodes
GETTING ACTION FROM:
action 1, numVisits=86245, meanQ=4.813774, numObservations: 4
action 3, numVisits=73, meanQ=3.994200, numObservations: 4
action 0, numVisits=26, meanQ=3.431178, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.548842 0.832692 0.390405 0.707859 0.558195 0.888347 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 447
Initial state: 0 0.620581 0.403749 0.523796 0.825262 0.620419 0.816004 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54061 episodes
GETTING ACTION FROM:
action 1, numVisits=53643, meanQ=4.958109, numObservations: 4
action 3, numVisits=413, meanQ=4.633327, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.620581 0.403749 0.523796 0.825262 0.620419 0.816004 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 448
Initial state: 0 0.53468 0.89347 0.164 0.71805 0.571758 0.86008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54215 episodes
GETTING ACTION FROM:
action 1, numVisits=54084, meanQ=4.984841, numObservations: 3
action -1, numVisits=126, meanQ=4.365026, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.53468 0.89347 0.164 0.71805 0.571758 0.86008 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 449
Initial state: 0 0.570511 0.831404 0.581805 0.878901 0.1207 0.306943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51352 episodes
GETTING ACTION FROM:
action 3, numVisits=51088, meanQ=4.856310, numObservations: 4
action -1, numVisits=258, meanQ=3.970076, numObservations: 1
action 1, numVisits=3, meanQ=-2.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.570511 0.831404 0.581805 0.878901 0.1207 0.306943 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5801, meanQ=8.542007, numObservations: 3
action 2, numVisits=8, meanQ=5.748762, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3412 episodes
GETTING ACTION FROM:
action 1, numVisits=5801, meanQ=8.542007, numObservations: 3
action 2, numVisits=34, meanQ=5.470300, numObservations: 3
action 3, numVisits=13, meanQ=2.460769, numObservations: 5
action 0, numVisits=3364, meanQ=0.134795, numObservations: 1
action -1, numVisits=12, meanQ=-2.000825, numObservations: 1
action: 1
Next state: 1 0.570511 0.831404 0.581805 0.878901 0.1207 0.306943 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 450
Initial state: 0 0.661186 0.835402 0.673689 0.816846 0.076709 0.380527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53323 episodes
GETTING ACTION FROM:
action 2, numVisits=53223, meanQ=4.942944, numObservations: 5
action -1, numVisits=90, meanQ=4.272336, numObservations: 1
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.661186 0.835402 0.673689 0.816846 0.076709 0.380527 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 451
Initial state: 0 0.19061 0.525616 0.620831 0.844984 0.55285 0.892501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33276 episodes
GETTING ACTION FROM:
action 0, numVisits=32579, meanQ=5.511755, numObservations: 2
action -1, numVisits=692, meanQ=1.419424, numObservations: 1
action 1, numVisits=3, meanQ=-3.363333, numObservations: 2
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.19061 0.525616 0.620831 0.844984 0.55285 0.892501 w: 1
Observation: 0 0 0.595871 0 0.803765 0 0.870707 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=24650, meanQ=7.394934, numObservations: 4
action 1, numVisits=7, meanQ=1.570000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 55211 episodes
GETTING ACTION FROM:
action 3, numVisits=79684, meanQ=5.838221, numObservations: 4
action 2, numVisits=177, meanQ=5.323074, numObservations: 4
action 1, numVisits=7, meanQ=1.570000, numObservations: 4
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.19061 0.525616 0.620831 0.844984 0.55285 0.892501 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 452
Initial state: 0 0.0684868 0.956412 0.684141 0.820112 0.619055 0.892567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51559 episodes
GETTING ACTION FROM:
action 1, numVisits=51540, meanQ=4.783487, numObservations: 4
action 2, numVisits=14, meanQ=2.427857, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0684868 0.956412 0.684141 0.820112 0.619055 0.892567 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=3837, meanQ=2.754883, numObservations: 1
action 2, numVisits=6, meanQ=0.331667, numObservations: 3
action 3, numVisits=5, meanQ=-0.622000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67409 episodes
GETTING ACTION FROM:
action 2, numVisits=67228, meanQ=5.772060, numObservations: 4
action -1, numVisits=4023, meanQ=2.592802, numObservations: 1
action 3, numVisits=5, meanQ=-0.622000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.0684868 0.956412 0.684141 0.820112 0.619055 0.892567 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 453
Initial state: 0 0.587699 0.869373 0.831311 0.151445 0.576425 0.872938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54416 episodes
GETTING ACTION FROM:
action 3, numVisits=54390, meanQ=5.002908, numObservations: 3
action 2, numVisits=20, meanQ=2.999510, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 3
Next state: 0 0.587699 0.869373 0.831311 0.151445 0.576425 0.872938 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4045, meanQ=5.562604, numObservations: 3
action 2, numVisits=7, meanQ=2.711429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67101 episodes
GETTING ACTION FROM:
action 1, numVisits=66500, meanQ=5.689919, numObservations: 5
action 3, numVisits=4645, meanQ=5.512233, numObservations: 4
action 2, numVisits=7, meanQ=2.711429, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.587699 0.869373 0.831311 0.151445 0.576425 0.872938 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 454
Initial state: 0 0.281698 0.572783 0.58278 0.828994 0.569474 0.869863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54142 episodes
GETTING ACTION FROM:
action 3, numVisits=54103, meanQ=4.959988, numObservations: 5
action -1, numVisits=19, meanQ=3.457280, numObservations: 1
action 1, numVisits=14, meanQ=2.643593, numObservations: 3
action 2, numVisits=4, meanQ=0.750000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.281698 0.572783 0.58278 0.828994 0.569474 0.869863 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 455
Initial state: 0 0.972797 0.140232 0.5371 0.894015 0.641825 0.800824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54056 episodes
GETTING ACTION FROM:
action 1, numVisits=54047, meanQ=4.958200, numObservations: 5
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.972797 0.140232 0.5371 0.894015 0.641825 0.800824 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 456
Initial state: 0 0.636013 0.873913 0.624849 0.885951 0.00113064 0.632366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54223 episodes
GETTING ACTION FROM:
action 2, numVisits=54120, meanQ=4.989220, numObservations: 5
action 0, numVisits=44, meanQ=3.961310, numObservations: 1
action 1, numVisits=39, meanQ=3.785646, numObservations: 4
action 3, numVisits=18, meanQ=3.055561, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.636013 0.873913 0.624849 0.885951 0.00113064 0.632366 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 457
Initial state: 0 0.826899 0.509865 0.6245 0.842208 0.644954 0.843022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51677 episodes
GETTING ACTION FROM:
action 3, numVisits=51653, meanQ=4.801378, numObservations: 4
action 2, numVisits=15, meanQ=2.201340, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.826899 0.509865 0.6245 0.842208 0.644954 0.843022 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 458
Initial state: 0 0.636637 0.86879 0.474753 0.517179 0.606623 0.875098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53904 episodes
GETTING ACTION FROM:
action 2, numVisits=53860, meanQ=4.950922, numObservations: 5
action 0, numVisits=40, meanQ=3.922848, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 2
Next state: 0 0.636637 0.86879 0.474753 0.517179 0.606623 0.875098 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7422, meanQ=8.430135, numObservations: 4
action 1, numVisits=42, meanQ=7.276429, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1623 episodes
GETTING ACTION FROM:
action 3, numVisits=7422, meanQ=8.430135, numObservations: 4
action 1, numVisits=49, meanQ=7.114490, numObservations: 4
action 2, numVisits=8, meanQ=2.375000, numObservations: 2
action -1, numVisits=1599, meanQ=0.384909, numObservations: 1
action 0, numVisits=12, meanQ=-2.000825, numObservations: 1
action: 3
Next state: 1 0.636637 0.86879 0.474753 0.517179 0.606623 0.875098 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 459
Initial state: 0 0.635063 0.884086 0.686755 0.892021 0.301549 0.449766 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54417 episodes
GETTING ACTION FROM:
action 3, numVisits=54411, meanQ=4.975876, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.635063 0.884086 0.686755 0.892021 0.301549 0.449766 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7641, meanQ=8.356512, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2168 episodes
GETTING ACTION FROM:
action 1, numVisits=7641, meanQ=8.356512, numObservations: 4
action 2, numVisits=31, meanQ=4.741613, numObservations: 4
action 0, numVisits=2116, meanQ=0.168898, numObservations: 1
action -1, numVisits=24, meanQ=-1.216250, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.635063 0.884086 0.686755 0.892021 0.301549 0.449766 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 460
Initial state: 0 0.00368059 0.267619 0.623611 0.813365 0.654916 0.820553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54162 episodes
GETTING ACTION FROM:
action 2, numVisits=54102, meanQ=5.062683, numObservations: 4
action 0, numVisits=30, meanQ=3.878005, numObservations: 1
action -1, numVisits=25, meanQ=3.269008, numObservations: 1
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action 1, numVisits=2, meanQ=-7.500000, numObservations: 1
action: 2
Next state: 1 0.00368059 0.267619 0.623611 0.813365 0.654916 0.820553 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 461
Initial state: 0 0.621104 0.805405 0.723868 0.360705 0.537829 0.810888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54138 episodes
GETTING ACTION FROM:
action 1, numVisits=54128, meanQ=4.979448, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.621104 0.805405 0.723868 0.360705 0.537829 0.810888 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 462
Initial state: 0 0.637351 0.849815 0.56222 0.875375 0.910323 0.739021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54319 episodes
GETTING ACTION FROM:
action 2, numVisits=54290, meanQ=4.982273, numObservations: 3
action -1, numVisits=24, meanQ=3.043231, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.637351 0.849815 0.56222 0.875375 0.910323 0.739021 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 463
Initial state: 0 0.98467 0.510182 0.528269 0.823869 0.500246 0.861734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54301 episodes
GETTING ACTION FROM:
action 2, numVisits=54291, meanQ=4.961513, numObservations: 5
action 1, numVisits=5, meanQ=-0.200000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.98467 0.510182 0.528269 0.823869 0.500246 0.861734 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 464
Initial state: 0 0.690238 0.843312 0.660039 0.829584 0.126706 0.613052 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53641 episodes
GETTING ACTION FROM:
action 2, numVisits=53633, meanQ=4.953909, numObservations: 5
action 3, numVisits=3, meanQ=-2.000000, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.690238 0.843312 0.660039 0.829584 0.126706 0.613052 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 465
Initial state: 0 0.609735 0.818803 0.569428 0.881325 0.628492 0.715869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54587 episodes
GETTING ACTION FROM:
action 3, numVisits=54577, meanQ=5.034283, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.609735 0.818803 0.569428 0.881325 0.628492 0.715869 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 466
Initial state: 0 0.80968 0.551423 0.676682 0.838349 0.619989 0.8784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54120 episodes
GETTING ACTION FROM:
action 2, numVisits=54111, meanQ=5.006738, numObservations: 4
action 3, numVisits=4, meanQ=0.750000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.80968 0.551423 0.676682 0.838349 0.619989 0.8784 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 467
Initial state: 0 0.96008 0.510842 0.662593 0.834906 0.686336 0.842021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54254 episodes
GETTING ACTION FROM:
action 2, numVisits=51096, meanQ=4.933459, numObservations: 4
action 1, numVisits=3026, meanQ=4.833213, numObservations: 4
action 0, numVisits=88, meanQ=4.237353, numObservations: 1
action -1, numVisits=41, meanQ=3.895519, numObservations: 1
action 3, numVisits=3, meanQ=-0.700000, numObservations: 2
action: 2
Next state: 1 0.96008 0.510842 0.662593 0.834906 0.686336 0.842021 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 468
Initial state: 0 0.520923 0.824967 0.676894 0.829337 0.706205 0.412173 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53773 episodes
GETTING ACTION FROM:
action 3, numVisits=48320, meanQ=5.004893, numObservations: 5
action 2, numVisits=5390, meanQ=4.911418, numObservations: 4
action -1, numVisits=58, meanQ=4.137025, numObservations: 1
action 1, numVisits=3, meanQ=-0.659967, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.520923 0.824967 0.676894 0.829337 0.706205 0.412173 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 469
Initial state: 0 0.526674 0.822791 0.539017 0.836851 0.272717 0.0276019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54338 episodes
GETTING ACTION FROM:
action 1, numVisits=54325, meanQ=4.980342, numObservations: 5
action 3, numVisits=8, meanQ=1.748750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.526674 0.822791 0.539017 0.836851 0.272717 0.0276019 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 470
Initial state: 0 0.665646 0.866799 0.935807 0.238719 0.564145 0.840947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54109 episodes
GETTING ACTION FROM:
action 2, numVisits=54079, meanQ=4.916492, numObservations: 3
action -1, numVisits=24, meanQ=3.521173, numObservations: 1
action 1, numVisits=3, meanQ=0.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.665646 0.866799 0.935807 0.238719 0.564145 0.840947 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 471
Initial state: 0 0.639178 0.859621 0.611435 0.820372 0.311854 0.0343582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53810 episodes
GETTING ACTION FROM:
action 1, numVisits=53713, meanQ=4.985224, numObservations: 4
action 3, numVisits=61, meanQ=4.014184, numObservations: 5
action -1, numVisits=31, meanQ=3.804898, numObservations: 1
action 2, numVisits=3, meanQ=0.000033, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.639178 0.859621 0.611435 0.820372 0.311854 0.0343582 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 472
Initial state: 0 0.531968 0.885675 0.194447 0.327856 0.646498 0.838024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53953 episodes
GETTING ACTION FROM:
action 3, numVisits=53876, meanQ=4.942558, numObservations: 4
action 0, numVisits=40, meanQ=3.912583, numObservations: 1
action -1, numVisits=34, meanQ=3.820522, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=2, meanQ=-4.499950, numObservations: 1
action: 3
Next state: 1 0.531968 0.885675 0.194447 0.327856 0.646498 0.838024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 473
Initial state: 0 0.536369 0.874041 0.59929 0.838485 0.258912 0.864391 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54483 episodes
GETTING ACTION FROM:
action 2, numVisits=54366, meanQ=5.126273, numObservations: 4
action 0, numVisits=86, meanQ=4.419064, numObservations: 1
action -1, numVisits=19, meanQ=3.498985, numObservations: 1
action 1, numVisits=8, meanQ=2.375000, numObservations: 3
action 3, numVisits=4, meanQ=0.750000, numObservations: 2
action: 2
Next state: 1 0.536369 0.874041 0.59929 0.838485 0.258912 0.864391 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 474
Initial state: 0 0.684823 0.874079 0.527804 0.805298 0.114324 0.944138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54035 episodes
GETTING ACTION FROM:
action 3, numVisits=54025, meanQ=4.902571, numObservations: 4
action 2, numVisits=5, meanQ=1.198020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 0 0.684823 0.874079 0.527804 0.805298 0.114324 0.944138 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2287, meanQ=7.744225, numObservations: 4
action 2, numVisits=332, meanQ=7.304490, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 5428 episodes
GETTING ACTION FROM:
action 1, numVisits=2287, meanQ=7.744225, numObservations: 4
action 2, numVisits=332, meanQ=7.304490, numObservations: 4
action 0, numVisits=5425, meanQ=0.109214, numObservations: 2
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action -1, numVisits=4, meanQ=-99.096294, numObservations: 1
action: 1
Next state: 1 0.684823 0.874079 0.527804 0.805298 0.114324 0.944138 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 475
Initial state: 0 0.389744 0.595118 0.639602 0.856145 0.533087 0.822316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 36072 episodes
GETTING ACTION FROM:
action 0, numVisits=29283, meanQ=5.875272, numObservations: 3
action 3, numVisits=6768, meanQ=4.857666, numObservations: 5
action -1, numVisits=19, meanQ=3.546245, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 0
Next state: 0 0.389744 0.595118 0.639602 0.856145 0.533087 0.822316 w: 1
Observation: 0 0 0.55437 0 0.925751 0 0.806316 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7226, meanQ=8.250202, numObservations: 4
action 2, numVisits=1334, meanQ=8.127375, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 55699 episodes
GETTING ACTION FROM:
action 3, numVisits=52296, meanQ=5.548115, numObservations: 4
action 2, numVisits=11961, meanQ=5.520548, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.389744 0.595118 0.639602 0.856145 0.533087 0.822316 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 476
Initial state: 0 0.690874 0.897184 0.946349 0.651358 0.669831 0.847585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54231 episodes
GETTING ACTION FROM:
action 1, numVisits=54211, meanQ=4.932018, numObservations: 4
action 3, numVisits=13, meanQ=3.075385, numObservations: 3
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.690874 0.897184 0.946349 0.651358 0.669831 0.847585 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 477
Initial state: 0 0.612745 0.868829 0.5861 0.829811 0.413828 0.140817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54360 episodes
GETTING ACTION FROM:
action 2, numVisits=54252, meanQ=5.018111, numObservations: 5
action 0, numVisits=74, meanQ=4.256607, numObservations: 1
action -1, numVisits=30, meanQ=3.819360, numObservations: 1
action 3, numVisits=3, meanQ=-0.659967, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.612745 0.868829 0.5861 0.829811 0.413828 0.140817 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.530698 0.879622 0.109809 0.140258 0.528804 0.805176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53984 episodes
GETTING ACTION FROM:
action 3, numVisits=53958, meanQ=4.916846, numObservations: 4
action 0, numVisits=22, meanQ=3.366239, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.530698 0.879622 0.109809 0.140258 0.528804 0.805176 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 479
Initial state: 0 0.0923726 0.948242 0.507809 0.845935 0.601338 0.850218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53994 episodes
GETTING ACTION FROM:
action 1, numVisits=53982, meanQ=4.899233, numObservations: 3
action 3, numVisits=7, meanQ=0.428571, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 0 0.0923726 0.948242 0.507809 0.845935 0.601338 0.850218 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=8958, meanQ=8.302821, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 4664 episodes
GETTING ACTION FROM:
action 2, numVisits=8958, meanQ=8.302821, numObservations: 3
action 3, numVisits=40, meanQ=7.199750, numObservations: 4
action 0, numVisits=4622, meanQ=0.068460, numObservations: 1
action 1, numVisits=4, meanQ=-4.002500, numObservations: 2
action -1, numVisits=3, meanQ=-130.770051, numObservations: 1
action: 2
Next state: 1 0.0923726 0.948242 0.507809 0.845935 0.601338 0.850218 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 480
Initial state: 0 0.635053 0.856771 0.930463 0.0764951 0.575014 0.872853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54288 episodes
GETTING ACTION FROM:
action 1, numVisits=54194, meanQ=5.088732, numObservations: 4
action 0, numVisits=41, meanQ=4.065310, numObservations: 1
action -1, numVisits=37, meanQ=4.013471, numObservations: 1
action 2, numVisits=10, meanQ=2.901010, numObservations: 4
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action: 1
Next state: 1 0.635053 0.856771 0.930463 0.0764951 0.575014 0.872853 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 481
Initial state: 0 0.544848 0.837362 0.57933 0.889168 0.716464 0.0672842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53947 episodes
GETTING ACTION FROM:
action 3, numVisits=53902, meanQ=4.943299, numObservations: 5
action 0, numVisits=40, meanQ=3.886200, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 2 0.544848 0.837362 0.57933 0.889168 0.716464 0.0672842 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 482
Initial state: 0 0.989065 0.375701 0.66977 0.819008 0.64151 0.844817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25877 episodes
GETTING ACTION FROM:
action 0, numVisits=25865, meanQ=4.004229, numObservations: 2
action 3, numVisits=5, meanQ=-0.795980, numObservations: 2
action 1, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action: 0
Next state: 0 0.989065 0.375701 0.66977 0.819008 0.64151 0.844817 w: 1
Observation: 0 0 0.422188 0 0.897806 0 0.821673 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=16287, meanQ=5.300704, numObservations: 1
action 2, numVisits=2271, meanQ=4.446651, numObservations: 3
action 1, numVisits=85, meanQ=3.840055, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 30362 episodes
GETTING ACTION FROM:
action 0, numVisits=46649, meanQ=4.573373, numObservations: 1
action 2, numVisits=2271, meanQ=4.446651, numObservations: 3
action 1, numVisits=85, meanQ=3.840055, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.989065 0.375701 0.66977 0.819008 0.64151 0.844817 w: 1
Observation: 0 0 0.354209 0 0.844325 0 0.798732 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=46641, meanQ=5.689980, numObservations: 4
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 49869 episodes
GETTING ACTION FROM:
action 3, numVisits=96494, meanQ=5.244060, numObservations: 4
action -1, numVisits=16, meanQ=3.411856, numObservations: 1
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.989065 0.375701 0.66977 0.819008 0.64151 0.844817 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 483
Initial state: 0 0.569627 0.880132 0.544486 0.831587 0.367082 0.286962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54350 episodes
GETTING ACTION FROM:
action 2, numVisits=54296, meanQ=5.011833, numObservations: 4
action -1, numVisits=47, meanQ=4.060586, numObservations: 1
action 1, numVisits=4, meanQ=0.750000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.569627 0.880132 0.544486 0.831587 0.367082 0.286962 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 484
Initial state: 0 0.63466 0.834449 0.529131 0.0799864 0.635036 0.848227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53419 episodes
GETTING ACTION FROM:
action 2, numVisits=52465, meanQ=4.984972, numObservations: 4
action 0, numVisits=945, meanQ=4.782347, numObservations: 3
action 1, numVisits=6, meanQ=1.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.63466 0.834449 0.529131 0.0799864 0.635036 0.848227 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8736, meanQ=8.284805, numObservations: 5
action 3, numVisits=7, meanQ=4.427143, numObservations: 1
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 6280 episodes
GETTING ACTION FROM:
action 1, numVisits=8736, meanQ=8.284805, numObservations: 5
action 2, numVisits=23, meanQ=3.952174, numObservations: 4
action 3, numVisits=19, meanQ=3.104737, numObservations: 2
action 0, numVisits=6245, meanQ=0.311480, numObservations: 1
action -1, numVisits=4, meanQ=-3.800149, numObservations: 1
action: 1
Next state: 1 0.63466 0.834449 0.529131 0.0799864 0.635036 0.848227 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 485
Initial state: 0 0.409073 0.239777 0.595775 0.847754 0.648473 0.835938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50507 episodes
GETTING ACTION FROM:
action 3, numVisits=50497, meanQ=4.861515, numObservations: 4
action 1, numVisits=4, meanQ=0.750000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.409073 0.239777 0.595775 0.847754 0.648473 0.835938 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 486
Initial state: 0 0.699204 0.873899 0.968706 0.44778 0.524271 0.880517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51756 episodes
GETTING ACTION FROM:
action 1, numVisits=48489, meanQ=4.993984, numObservations: 3
action 0, numVisits=3259, meanQ=2.923236, numObservations: 1
action 2, numVisits=3, meanQ=-2.000000, numObservations: 2
action 3, numVisits=3, meanQ=-2.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.699204 0.873899 0.968706 0.44778 0.524271 0.880517 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3274, meanQ=4.764072, numObservations: 4
action 3, numVisits=202, meanQ=4.155782, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 67161 episodes
GETTING ACTION FROM:
action 2, numVisits=70420, meanQ=5.899334, numObservations: 4
action 3, numVisits=202, meanQ=4.155782, numObservations: 5
action 1, numVisits=14, meanQ=3.064293, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 2 0.699204 0.873899 0.968706 0.44778 0.524271 0.880517 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 487
Initial state: 0 0.54368 0.831013 0.103891 0.678125 0.53887 0.832647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53983 episodes
GETTING ACTION FROM:
action 3, numVisits=53952, meanQ=5.019837, numObservations: 4
action 2, numVisits=17, meanQ=1.175894, numObservations: 3
action 1, numVisits=10, meanQ=0.702020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.54368 0.831013 0.103891 0.678125 0.53887 0.832647 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 488
Initial state: 0 0.542896 0.879497 0.615132 0.864772 0.0417029 0.865014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54283 episodes
GETTING ACTION FROM:
action 2, numVisits=54231, meanQ=4.984735, numObservations: 4
action 0, numVisits=34, meanQ=3.817476, numObservations: 1
action 3, numVisits=9, meanQ=1.782244, numObservations: 3
action 1, numVisits=7, meanQ=1.428571, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.542896 0.879497 0.615132 0.864772 0.0417029 0.865014 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 489
Initial state: 0 0.565385 0.863917 0.699736 0.891622 0.465512 0.237123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 53819 episodes
GETTING ACTION FROM:
action 1, numVisits=53779, meanQ=4.944393, numObservations: 5
action 3, numVisits=34, meanQ=2.441776, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-4.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.565385 0.863917 0.699736 0.891622 0.465512 0.237123 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 490
Initial state: 0 0.608 0.827185 0.810822 0.559815 0.605032 0.88065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51647 episodes
GETTING ACTION FROM:
action 2, numVisits=51599, meanQ=4.824817, numObservations: 4
action -1, numVisits=35, meanQ=3.665257, numObservations: 1
action 1, numVisits=10, meanQ=2.011000, numObservations: 2
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.608 0.827185 0.810822 0.559815 0.605032 0.88065 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 491
Initial state: 0 0.261313 0.786132 0.679249 0.833573 0.547103 0.833946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54016 episodes
GETTING ACTION FROM:
action 3, numVisits=54004, meanQ=4.997669, numObservations: 5
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.261313 0.786132 0.679249 0.833573 0.547103 0.833946 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 492
Initial state: 0 0.661616 0.887305 0.0112169 0.538539 0.50397 0.826912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54172 episodes
GETTING ACTION FROM:
action 3, numVisits=54032, meanQ=4.907315, numObservations: 4
action -1, numVisits=88, meanQ=4.214993, numObservations: 1
action 0, numVisits=50, meanQ=3.987329, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.661616 0.887305 0.0112169 0.538539 0.50397 0.826912 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 493
Initial state: 0 0.404905 0.724602 0.505881 0.85256 0.566532 0.822228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54534 episodes
GETTING ACTION FROM:
action 3, numVisits=54502, meanQ=4.921860, numObservations: 4
action 1, numVisits=25, meanQ=2.680820, numObservations: 4
action 2, numVisits=3, meanQ=-2.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.404905 0.724602 0.505881 0.85256 0.566532 0.822228 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3872, meanQ=4.948417, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 67125 episodes
GETTING ACTION FROM:
action 2, numVisits=70974, meanQ=5.716112, numObservations: 3
action 1, numVisits=22, meanQ=3.362727, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.404905 0.724602 0.505881 0.85256 0.566532 0.822228 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 494
Initial state: 0 0.648953 0.812212 0.400856 0.924037 0.698357 0.807294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 41601 episodes
GETTING ACTION FROM:
action 3, numVisits=22938, meanQ=4.990317, numObservations: 4
action 0, numVisits=18565, meanQ=2.982433, numObservations: 1
action -1, numVisits=90, meanQ=2.359643, numObservations: 1
action 2, numVisits=6, meanQ=0.166667, numObservations: 2
action 1, numVisits=2, meanQ=-4.000000, numObservations: 2
action: 3
Next state: 1 0.648953 0.812212 0.400856 0.924037 0.698357 0.807294 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 495
Initial state: 0 0.629815 0.814188 0.0874945 0.283794 0.607541 0.870422 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54644 episodes
GETTING ACTION FROM:
action 1, numVisits=54637, meanQ=5.034263, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-4.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.629815 0.814188 0.0874945 0.283794 0.607541 0.870422 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 496
Initial state: 0 0.646763 0.80803 0.592674 0.811326 0.0554423 0.957037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51669 episodes
GETTING ACTION FROM:
action 3, numVisits=51642, meanQ=4.806133, numObservations: 5
action 0, numVisits=22, meanQ=3.395750, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.646763 0.80803 0.592674 0.811326 0.0554423 0.957037 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=3692, meanQ=2.747361, numObservations: 1
action 3, numVisits=9, meanQ=0.331122, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 68430 episodes
GETTING ACTION FROM:
action 2, numVisits=68422, meanQ=5.877441, numObservations: 4
action 0, numVisits=3696, meanQ=2.743473, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action 3, numVisits=9, meanQ=0.331122, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.646763 0.80803 0.592674 0.811326 0.0554423 0.957037 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 497
Initial state: 0 0.567339 0.872999 0.592797 0.898038 0.697738 0.133293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54543 episodes
GETTING ACTION FROM:
action 2, numVisits=54527, meanQ=5.027237, numObservations: 5
action 3, numVisits=11, meanQ=1.193645, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.567339 0.872999 0.592797 0.898038 0.697738 0.133293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 498
Initial state: 0 0.558601 0.819149 0.548609 0.845241 0.220673 0.953684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54307 episodes
GETTING ACTION FROM:
action 2, numVisits=54275, meanQ=5.007596, numObservations: 4
action -1, numVisits=27, meanQ=3.697792, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.558601 0.819149 0.548609 0.845241 0.220673 0.953684 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 499
Initial state: 0 0.546708 0.880927 0.613462 0.863146 0.899162 0.0237719 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54470 episodes
GETTING ACTION FROM:
action 3, numVisits=54423, meanQ=4.946645, numObservations: 5
action 0, numVisits=31, meanQ=3.724165, numObservations: 1
action 2, numVisits=10, meanQ=0.790000, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.546708 0.880927 0.613462 0.863146 0.899162 0.0237719 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2657, meanQ=7.805391, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2763 episodes
GETTING ACTION FROM:
action 2, numVisits=2657, meanQ=7.805391, numObservations: 4
action 1, numVisits=141, meanQ=6.349029, numObservations: 3
action 3, numVisits=3, meanQ=4.996667, numObservations: 3
action -1, numVisits=2602, meanQ=0.023751, numObservations: 1
action 0, numVisits=21, meanQ=-1.671414, numObservations: 1
action: 2
Next state: 1 0.546708 0.880927 0.613462 0.863146 0.899162 0.0237719 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 500
Initial state: 0 0.592449 0.89408 0.398043 0.214522 0.590017 0.884343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 54014 episodes
GETTING ACTION FROM:
action 3, numVisits=53975, meanQ=4.952916, numObservations: 5
action 0, numVisits=26, meanQ=3.641440, numObservations: 1
action 2, numVisits=10, meanQ=2.499000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.592449 0.89408 0.398043 0.214522 0.590017 0.884343 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
