Run # 1
Initial state: 0 0.723208 0.58059 0.580951 0.347386 0.523719 0.612342 0.649898 0.657595 0.616039 0.831397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27991 episodes
GETTING ACTION FROM:
action 4, numVisits=27980, meanQ=3.130446, numObservations: 5
action -1, numVisits=3, meanQ=-2.996600, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.500000, numObservations: 2
action 2, numVisits=2, meanQ=-7.500000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.723208 0.58059 0.580951 0.347386 0.523719 0.612342 0.649898 0.657595 0.616039 0.831397 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=1757, meanQ=5.158114, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1572 episodes
GETTING ACTION FROM:
action -1, numVisits=3328, meanQ=3.364493, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.723208 0.58059 0.580951 0.347386 0.523719 0.612342 0.649898 0.657595 0.616039 0.831397 w: 1
Observation: 0 0.641058 0 0.604509 0 0.490781 0 0.6921 0 0.686776 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=1547, meanQ=6.165501, numObservations: 3
action 4, numVisits=23, meanQ=1.651757, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1376 episodes
GETTING ACTION FROM:
action 0, numVisits=2923, meanQ=4.234518, numObservations: 3
action 4, numVisits=23, meanQ=1.651757, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.723208 0.58059 0.580951 0.347386 0.523719 0.612342 0.649898 0.657595 0.616039 0.831397 w: 1
Observation: 0 0 0.519872 0 0.363482 0 0.644337 0 0.579119 0 0.926196 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=612, meanQ=7.600292, numObservations: 2
action 5, numVisits=469, meanQ=6.583208, numObservations: 5
action 2, numVisits=4, meanQ=-0.252500, numObservations: 2
action 3, numVisits=5, meanQ=-0.804000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=3, meanQ=-4.970000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1368 episodes
GETTING ACTION FROM:
action 5, numVisits=469, meanQ=6.583208, numObservations: 5
action -1, numVisits=1980, meanQ=3.692745, numObservations: 2
action 2, numVisits=4, meanQ=-0.252500, numObservations: 2
action 3, numVisits=5, meanQ=-0.804000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=3, meanQ=-4.970000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.723208 0.58059 0.580951 0.347386 0.523719 0.612342 0.649898 0.657595 0.616039 0.831397 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 7903 episodes
GETTING ACTION FROM:
action 4, numVisits=8, meanQ=7.763750, numObservations: 4
action 5, numVisits=13, meanQ=6.230769, numObservations: 3
action 2, numVisits=4203, meanQ=5.767746, numObservations: 5
action 3, numVisits=3652, meanQ=3.849548, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=19, meanQ=-29.666260, numObservations: 1
action -1, numVisits=7, meanQ=-77.474760, numObservations: 2
action: 4
Next state: 2 0.723208 0.58059 0.580951 0.347386 0.523719 0.612342 0.649898 0.657595 0.616039 0.831397 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -22.388
Run # 2
Initial state: 0 0.265291 0.602699 0.113807 0.152251 0.521675 0.873564 0.722645 0.247365 0.297727 0.520663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16976 episodes
GETTING ACTION FROM:
action -1, numVisits=16717, meanQ=2.144547, numObservations: 5
action 3, numVisits=247, meanQ=1.781641, numObservations: 5
action 0, numVisits=3, meanQ=-2.333300, numObservations: 2
action 5, numVisits=5, meanQ=-2.600000, numObservations: 3
action 2, numVisits=2, meanQ=-5.489950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.265291 0.602699 0.113807 0.152251 0.521675 0.873564 0.722645 0.247365 0.297727 0.520663 w: 1
Observation: 0 0.257525 0 0.112676 0 0.48441 0 0.662276 0 0.226083 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5278, meanQ=2.807224, numObservations: 5
action 3, numVisits=9, meanQ=-1.446667, numObservations: 4
action 2, numVisits=10, meanQ=-1.994970, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 25533 episodes
GETTING ACTION FROM:
action 1, numVisits=30811, meanQ=2.529918, numObservations: 5
action 3, numVisits=9, meanQ=-1.446667, numObservations: 4
action 2, numVisits=10, meanQ=-1.994970, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.265291 0.602699 0.113807 0.152251 0.521675 0.873564 0.722645 0.247365 0.297727 0.520663 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=10188, meanQ=2.430325, numObservations: 2
action 2, numVisits=11, meanQ=-0.021809, numObservations: 4
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 5, numVisits=2, meanQ=-7.005000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1993 episodes
GETTING ACTION FROM:
action -1, numVisits=12180, meanQ=2.172939, numObservations: 2
action 2, numVisits=11, meanQ=-0.021809, numObservations: 4
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=3, meanQ=-6.970000, numObservations: 2
action 5, numVisits=2, meanQ=-7.005000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.265291 0.602699 0.113807 0.152251 0.521675 0.873564 0.722645 0.247365 0.297727 0.520663 w: 1
Observation: 0 0.350149 0 0.0587833 0 0.530906 0 0.766254 0 0.236692 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=8299, meanQ=4.187581, numObservations: 4
action -1, numVisits=662, meanQ=1.563876, numObservations: 2
action 4, numVisits=9, meanQ=-0.999989, numObservations: 2
action 0, numVisits=4, meanQ=-2.997425, numObservations: 1
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 5, numVisits=2, meanQ=-8.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2027 episodes
GETTING ACTION FROM:
action 2, numVisits=8302, meanQ=4.188362, numObservations: 4
action -1, numVisits=2686, meanQ=1.450435, numObservations: 3
action 4, numVisits=9, meanQ=-0.999989, numObservations: 2
action 0, numVisits=4, meanQ=-2.997425, numObservations: 1
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 5, numVisits=2, meanQ=-8.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.265291 0.602699 0.113807 0.152251 0.521675 0.873564 0.722645 0.247365 0.297727 0.520663 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 0, numVisits=2858, meanQ=10.152424, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2899 episodes
GETTING ACTION FROM:
action 0, numVisits=5757, meanQ=5.472854, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.265291 0.602699 0.113807 0.152251 0.521675 0.873564 0.722645 0.247365 0.297727 0.520663 w: 1
Observation: 0 0 0.641231 0 0.0583628 0 0.821572 0 0.183628 0 0.439341 
Immediate reward: -2
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action -1, numVisits=217, meanQ=11.283063, numObservations: 1
action 5, numVisits=928, meanQ=10.292246, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2268 episodes
GETTING ACTION FROM:
action 5, numVisits=928, meanQ=10.292246, numObservations: 4
action -1, numVisits=2485, meanQ=1.664645, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.265291 0.602699 0.113807 0.152251 0.521675 0.873564 0.722645 0.247365 0.297727 0.520663 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 6
Improving policy...
PLANNING FROM:
action 3, numVisits=205, meanQ=21.302380, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 3131 episodes
GETTING ACTION FROM:
action 3, numVisits=487, meanQ=12.162409, numObservations: 4
action 0, numVisits=2840, meanQ=-1.588879, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=11, meanQ=-33.876548, numObservations: 1
action: 3
Next state: 1 0.265291 0.602699 0.113807 0.152251 0.521675 0.873564 0.722645 0.247365 0.297727 0.520663 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 5.06898
Run # 3
Initial state: 0 0.987417 0.115123 0.902799 0.10885 0.620997 0.81961 0.225612 0.248477 0.412803 0.904997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30215 episodes
GETTING ACTION FROM:
action 2, numVisits=30207, meanQ=3.117094, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.987417 0.115123 0.902799 0.10885 0.620997 0.81961 0.225612 0.248477 0.412803 0.904997 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.827267 0.612872 0.00369067 0.780587 0.033703 0.218244 0.695852 0.80874 0.798565 0.10645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30146 episodes
GETTING ACTION FROM:
action 1, numVisits=30135, meanQ=2.944150, numObservations: 4
action 5, numVisits=4, meanQ=-1.225000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.827267 0.612872 0.00369067 0.780587 0.033703 0.218244 0.695852 0.80874 0.798565 0.10645 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 5
Initial state: 0 0.951056 0.54268 0.85664 0.159849 0.128585 0.626706 0.711786 0.326414 0.641718 0.885509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19689 episodes
GETTING ACTION FROM:
action -1, numVisits=19678, meanQ=1.548227, numObservations: 2
action 0, numVisits=4, meanQ=-2.499950, numObservations: 2
action 4, numVisits=2, meanQ=-7.500000, numObservations: 1
action 5, numVisits=2, meanQ=-7.500000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.951056 0.54268 0.85664 0.159849 0.128585 0.626706 0.711786 0.326414 0.641718 0.885509 w: 1
Observation: 0 0.988132 0 0.80168 0 0.0403294 0 0.629689 0 0.717906 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3394, meanQ=2.951368, numObservations: 4
action 4, numVisits=6, meanQ=-2.503333, numObservations: 2
action 3, numVisits=2, meanQ=-4.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 29017 episodes
GETTING ACTION FROM:
action 2, numVisits=32411, meanQ=2.728229, numObservations: 4
action 4, numVisits=6, meanQ=-2.503333, numObservations: 2
action 3, numVisits=2, meanQ=-4.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.951056 0.54268 0.85664 0.159849 0.128585 0.626706 0.711786 0.326414 0.641718 0.885509 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
