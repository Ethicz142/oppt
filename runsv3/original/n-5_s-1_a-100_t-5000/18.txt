Run # 1
Initial state: 0 0.821663 0.0797081 0.910618 0.411078 0.61909 0.908782 0.486191 0.938833 0.493788 0.316959 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 188808 episodes
GETTING ACTION FROM:
action 0, numVisits=188772, meanQ=62.485089, numObservations: 243
action -1, numVisits=26, meanQ=-1.199808, numObservations: 24
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=4, meanQ=-7.012500, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.821663 0.0797081 0.910618 0.411078 0.61909 0.908782 0.486191 0.938833 0.493788 0.316959 w: 1
Observation: 0 0 1 0 2 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=919, meanQ=61.568848, numObservations: 9
action 4, numVisits=10, meanQ=44.185500, numObservations: 4
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 868477 episodes
GETTING ACTION FROM:
action 5, numVisits=869396, meanQ=67.378784, numObservations: 9
action 4, numVisits=10, meanQ=44.185500, numObservations: 4
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.821663 0.0797081 0.910618 0.411078 0.61909 0.908782 0.486191 0.938833 0.493788 0.316959 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 2
Initial state: 0 0.0994133 0.481744 0.43185 0.310298 0.550018 0.082482 0.230834 0.494578 0.0567197 0.664971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 586990 episodes
GETTING ACTION FROM:
action 5, numVisits=586977, meanQ=40.149955, numObservations: 9
action 2, numVisits=7, meanQ=13.285714, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 0 0.0994133 0.481744 0.43185 0.310298 0.550018 0.082482 0.230834 0.494578 0.0567197 0.664971 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=66640, meanQ=52.243601, numObservations: 9
action 1, numVisits=8, meanQ=29.288125, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 542067 episodes
GETTING ACTION FROM:
action 5, numVisits=608707, meanQ=64.738711, numObservations: 9
action 1, numVisits=8, meanQ=29.288125, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.0994133 0.481744 0.43185 0.310298 0.550018 0.082482 0.230834 0.494578 0.0567197 0.664971 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=220523, meanQ=50.532393, numObservations: 9
action 3, numVisits=7, meanQ=22.193214, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 684053 episodes
GETTING ACTION FROM:
action 5, numVisits=904576, meanQ=69.489358, numObservations: 9
action 3, numVisits=7, meanQ=22.193214, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.0994133 0.481744 0.43185 0.310298 0.550018 0.082482 0.230834 0.494578 0.0567197 0.664971 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=309022, meanQ=43.140659, numObservations: 9
action 3, numVisits=20, meanQ=32.642500, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 876391 episodes
GETTING ACTION FROM:
action 2, numVisits=1185413, meanQ=54.433192, numObservations: 9
action 3, numVisits=20, meanQ=32.642500, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.0994133 0.481744 0.43185 0.310298 0.550018 0.082482 0.230834 0.494578 0.0567197 0.664971 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 53.5026
Run # 3
Initial state: 0 0.519034 0.390766 0.658824 0.2522 0.293291 0.552221 0.411178 0.490632 0.483263 0.190414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 496922 episodes
GETTING ACTION FROM:
action 3, numVisits=496901, meanQ=41.270392, numObservations: 9
action 4, numVisits=7, meanQ=26.278571, numObservations: 3
action 1, numVisits=7, meanQ=23.692857, numObservations: 5
action 5, numVisits=4, meanQ=16.725625, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.519034 0.390766 0.658824 0.2522 0.293291 0.552221 0.411178 0.490632 0.483263 0.190414 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 4
Initial state: 0 0.779641 0.137447 0.123289 0.423013 0.651878 0.0737573 0.785268 0.577709 0.512454 0.32925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 636017 episodes
GETTING ACTION FROM:
action 3, numVisits=635995, meanQ=38.984931, numObservations: 9
action 4, numVisits=13, meanQ=19.457692, numObservations: 6
action 2, numVisits=5, meanQ=14.990500, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 2 0.779641 0.137447 0.123289 0.423013 0.651878 0.0737573 0.785268 0.577709 0.512454 0.32925 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 5
Initial state: 0 0.675218 0.697675 0.484647 0.774272 0.47491 0.0789343 0.118017 0.29912 0.420286 0.371099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 533768 episodes
GETTING ACTION FROM:
action 4, numVisits=533716, meanQ=40.561975, numObservations: 9
action 1, numVisits=44, meanQ=33.066080, numObservations: 9
action 2, numVisits=4, meanQ=21.737500, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.675218 0.697675 0.484647 0.774272 0.47491 0.0789343 0.118017 0.29912 0.420286 0.371099 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=61309, meanQ=59.530032, numObservations: 243
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=5, meanQ=-20.430000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 213089 episodes
GETTING ACTION FROM:
action -1, numVisits=274398, meanQ=43.835916, numObservations: 243
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=5, meanQ=-20.430000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.675218 0.697675 0.484647 0.774272 0.47491 0.0789343 0.118017 0.29912 0.420286 0.371099 w: 1
Observation: 0 3 0 2 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=111, meanQ=60.164550, numObservations: 9
action 3, numVisits=815, meanQ=21.738349, numObservations: 9
action 1, numVisits=302, meanQ=21.589437, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 866861 episodes
GETTING ACTION FROM:
action 2, numVisits=866972, meanQ=59.497523, numObservations: 9
action 3, numVisits=815, meanQ=21.738349, numObservations: 9
action 1, numVisits=302, meanQ=21.589437, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.675218 0.697675 0.484647 0.774272 0.47491 0.0789343 0.118017 0.29912 0.420286 0.371099 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 6
Initial state: 0 0.585703 0.00317145 0.86375 0.641232 0.482738 0.312196 0.151346 0.323179 0.0259822 0.676235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 194042 episodes
GETTING ACTION FROM:
action -1, numVisits=194019, meanQ=56.355843, numObservations: 243
action 0, numVisits=18, meanQ=-6.433333, numObservations: 17
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.585703 0.00317145 0.86375 0.641232 0.482738 0.312196 0.151346 0.323179 0.0259822 0.676235 w: 1
Observation: 0 3 0 3 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1249, meanQ=84.783780, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 895177 episodes
GETTING ACTION FROM:
action 3, numVisits=896426, meanQ=86.098461, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.585703 0.00317145 0.86375 0.641232 0.482738 0.312196 0.151346 0.323179 0.0259822 0.676235 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=55072, meanQ=94.764170, numObservations: 9
action 5, numVisits=5, meanQ=59.000000, numObservations: 4
action 1, numVisits=2, meanQ=44.475000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 1011327 episodes
GETTING ACTION FROM:
action 3, numVisits=1066399, meanQ=97.644182, numObservations: 9
action 5, numVisits=5, meanQ=59.000000, numObservations: 4
action 1, numVisits=2, meanQ=44.475000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.585703 0.00317145 0.86375 0.641232 0.482738 0.312196 0.151346 0.323179 0.0259822 0.676235 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=11151, meanQ=93.877800, numObservations: 9
action 2, numVisits=6, meanQ=65.666667, numObservations: 4
action 1, numVisits=4, meanQ=49.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 1009610 episodes
GETTING ACTION FROM:
action 3, numVisits=1020761, meanQ=98.770772, numObservations: 9
action 2, numVisits=6, meanQ=65.666667, numObservations: 4
action 1, numVisits=4, meanQ=49.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.585703 0.00317145 0.86375 0.641232 0.482738 0.312196 0.151346 0.323179 0.0259822 0.676235 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 62.5026
Run # 7
Initial state: 0 0.794111 0.45952 0.429346 0.408159 0.940058 0.914402 0.854594 0.274572 0.275455 0.613872 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675899 episodes
GETTING ACTION FROM:
action 2, numVisits=675884, meanQ=39.097877, numObservations: 9
action 3, numVisits=8, meanQ=35.368750, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.794111 0.45952 0.429346 0.408159 0.940058 0.914402 0.854594 0.274572 0.275455 0.613872 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 8
Initial state: 0 0.763945 0.66629 0.0852564 0.0033471 0.15358 0.268046 0.225367 0.112871 0.440794 0.381793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 542288 episodes
GETTING ACTION FROM:
action 5, numVisits=542275, meanQ=40.661860, numObservations: 9
action 1, numVisits=7, meanQ=13.285714, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.763945 0.66629 0.0852564 0.0033471 0.15358 0.268046 0.225367 0.112871 0.440794 0.381793 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 9
Initial state: 0 0.314463 0.56938 0.485783 0.327853 0.456917 0.993037 0.384044 0.21567 0.896856 0.859566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 618598 episodes
GETTING ACTION FROM:
action 3, numVisits=618586, meanQ=39.652479, numObservations: 9
action 5, numVisits=3, meanQ=26.300000, numObservations: 3
action 1, numVisits=5, meanQ=15.380000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.314463 0.56938 0.485783 0.327853 0.456917 0.993037 0.384044 0.21567 0.896856 0.859566 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 10
Initial state: 0 0.459563 0.900055 0.560549 0.0398748 0.749869 0.678227 0.508603 0.341976 0.956427 0.0609345 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 607744 episodes
GETTING ACTION FROM:
action 2, numVisits=607725, meanQ=39.342969, numObservations: 9
action 4, numVisits=8, meanQ=35.368750, numObservations: 4
action 3, numVisits=5, meanQ=33.570000, numObservations: 4
action 1, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.459563 0.900055 0.560549 0.0398748 0.749869 0.678227 0.508603 0.341976 0.956427 0.0609345 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 11
Initial state: 0 0.639796 0.0797701 0.690132 0.368154 0.551485 0.0550104 0.503646 0.376553 0.250792 0.508651 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665730 episodes
GETTING ACTION FROM:
action 2, numVisits=665720, meanQ=38.284129, numObservations: 9
action 5, numVisits=4, meanQ=21.737500, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.639796 0.0797701 0.690132 0.368154 0.551485 0.0550104 0.503646 0.376553 0.250792 0.508651 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 12
Initial state: 0 0.444711 0.369133 0.129737 0.824425 0.71057 0.270826 0.422496 0.473681 0.364627 0.561993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 190646 episodes
GETTING ACTION FROM:
action -1, numVisits=190627, meanQ=55.336110, numObservations: 243
action 0, numVisits=12, meanQ=-1.050000, numObservations: 12
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.444711 0.369133 0.129737 0.824425 0.71057 0.270826 0.422496 0.473681 0.364627 0.561993 w: 1
Observation: 0 2 0 1 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1225, meanQ=85.897225, numObservations: 9
action 4, numVisits=23, meanQ=46.826087, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 940026 episodes
GETTING ACTION FROM:
action 1, numVisits=941251, meanQ=89.862132, numObservations: 9
action 4, numVisits=23, meanQ=46.826087, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.444711 0.369133 0.129737 0.824425 0.71057 0.270826 0.422496 0.473681 0.364627 0.561993 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 13
Initial state: 0 0.422375 0.433246 0.970513 0.624206 0.411967 0.969086 0.299199 0.451969 0.187584 0.696212 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674274 episodes
GETTING ACTION FROM:
action 4, numVisits=674256, meanQ=38.901064, numObservations: 9
action -1, numVisits=3, meanQ=-1.050000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 1, numVisits=9, meanQ=-2.005556, numObservations: 6
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.422375 0.433246 0.970513 0.624206 0.411967 0.969086 0.299199 0.451969 0.187584 0.696212 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=8480, meanQ=61.271088, numObservations: 241
action -1, numVisits=12, meanQ=-9.287292, numObservations: 10
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 257016 episodes
GETTING ACTION FROM:
action 0, numVisits=265496, meanQ=8.989213, numObservations: 243
action -1, numVisits=12, meanQ=-9.287292, numObservations: 10
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 0
Next state: 0 0.422375 0.433246 0.970513 0.624206 0.411967 0.969086 0.299199 0.451969 0.187584 0.696212 w: 1
Observation: 0 0 2 0 3 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=416, meanQ=62.830132, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 955891 episodes
GETTING ACTION FROM:
action 2, numVisits=956307, meanQ=76.764818, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.422375 0.433246 0.970513 0.624206 0.411967 0.969086 0.299199 0.451969 0.187584 0.696212 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 14
Initial state: 0 0.965672 0.635495 0.463793 0.406549 0.874513 0.216951 0.725443 0.566774 0.751113 0.953451 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 633776 episodes
GETTING ACTION FROM:
action 4, numVisits=633762, meanQ=39.813288, numObservations: 9
action 3, numVisits=9, meanQ=28.094722, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.965672 0.635495 0.463793 0.406549 0.874513 0.216951 0.725443 0.566774 0.751113 0.953451 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 15
Initial state: 0 0.980406 0.775712 0.640611 0.301113 0.189041 0.0111682 0.0427137 0.724634 0.453382 0.394919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 619264 episodes
GETTING ACTION FROM:
action 4, numVisits=619258, meanQ=39.427947, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.980406 0.775712 0.640611 0.301113 0.189041 0.0111682 0.0427137 0.724634 0.453382 0.394919 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 16
Initial state: 0 0.86372 0.0577198 0.450311 0.376258 0.137373 0.345642 0.849557 0.98513 0.413483 0.818748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663696 episodes
GETTING ACTION FROM:
action 3, numVisits=663601, meanQ=38.535491, numObservations: 9
action 5, numVisits=43, meanQ=34.386163, numObservations: 9
action 1, numVisits=48, meanQ=34.150208, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.86372 0.0577198 0.450311 0.376258 0.137373 0.345642 0.849557 0.98513 0.413483 0.818748 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=6091, meanQ=39.553785, numObservations: 9
action 3, numVisits=9, meanQ=27.217222, numObservations: 4
action 2, numVisits=12, meanQ=26.933542, numObservations: 7
action 1, numVisits=7, meanQ=26.278571, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 925465 episodes
GETTING ACTION FROM:
action 5, numVisits=931556, meanQ=49.906062, numObservations: 9
action 3, numVisits=9, meanQ=27.217222, numObservations: 4
action 2, numVisits=12, meanQ=26.933542, numObservations: 7
action 1, numVisits=7, meanQ=26.278571, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.86372 0.0577198 0.450311 0.376258 0.137373 0.345642 0.849557 0.98513 0.413483 0.818748 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 17
Initial state: 0 0.781778 0.587808 0.963174 0.284114 0.744949 0.638248 0.462111 0.356644 0.722497 0.0943058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 636536 episodes
GETTING ACTION FROM:
action 5, numVisits=636524, meanQ=39.342640, numObservations: 9
action 2, numVisits=7, meanQ=13.285714, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.781778 0.587808 0.963174 0.284114 0.744949 0.638248 0.462111 0.356644 0.722497 0.0943058 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 18
Initial state: 0 0.41976 0.00622119 0.414737 0.402008 0.271343 0.0886185 0.489866 0.828023 0.00858005 0.672339 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689264 episodes
GETTING ACTION FROM:
action 1, numVisits=689223, meanQ=39.092872, numObservations: 9
action 5, numVisits=32, meanQ=32.961250, numObservations: 9
action 2, numVisits=4, meanQ=21.737500, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 2 0.41976 0.00622119 0.414737 0.402008 0.271343 0.0886185 0.489866 0.828023 0.00858005 0.672339 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 19
Initial state: 0 0.485751 0.371434 0.423831 0.547554 0.335075 0.918444 0.452023 0.0241809 0.441846 0.464487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673877 episodes
GETTING ACTION FROM:
action 5, numVisits=673865, meanQ=38.893055, numObservations: 9
action 4, numVisits=5, meanQ=15.380000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.485751 0.371434 0.423831 0.547554 0.335075 0.918444 0.452023 0.0241809 0.441846 0.464487 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 20
Initial state: 0 0.90356 0.963843 0.768734 0.826727 0.119859 0.312037 0.985416 0.592817 0.532377 0.314436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 577652 episodes
GETTING ACTION FROM:
action 3, numVisits=577616, meanQ=40.017156, numObservations: 9
action 2, numVisits=26, meanQ=34.527115, numObservations: 9
action 4, numVisits=5, meanQ=31.470500, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 0 0.90356 0.963843 0.768734 0.826727 0.119859 0.312037 0.985416 0.592817 0.532377 0.314436 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=20724, meanQ=40.020663, numObservations: 9
action 4, numVisits=8, meanQ=21.737500, numObservations: 5
action 1, numVisits=15, meanQ=16.586667, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 777642 episodes
GETTING ACTION FROM:
action 5, numVisits=798366, meanQ=44.682409, numObservations: 9
action 4, numVisits=8, meanQ=21.737500, numObservations: 5
action 1, numVisits=15, meanQ=16.586667, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.90356 0.963843 0.768734 0.826727 0.119859 0.312037 0.985416 0.592817 0.532377 0.314436 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 21
Initial state: 0 0.974578 0.625556 0.68724 0.887281 0.951858 0.315299 0.487966 0.434825 0.720708 0.0910633 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701872 episodes
GETTING ACTION FROM:
action 3, numVisits=701860, meanQ=38.975468, numObservations: 9
action 5, numVisits=6, meanQ=11.141667, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.974578 0.625556 0.68724 0.887281 0.951858 0.315299 0.487966 0.434825 0.720708 0.0910633 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 22
Initial state: 0 0.490692 0.364249 0.115709 0.031155 0.56194 0.211325 0.465362 0.995603 0.733631 0.431569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 679307 episodes
GETTING ACTION FROM:
action 2, numVisits=679298, meanQ=38.826737, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 0 0.490692 0.364249 0.115709 0.031155 0.56194 0.211325 0.465362 0.995603 0.733631 0.431569 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=53434, meanQ=44.658917, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 828150 episodes
GETTING ACTION FROM:
action 4, numVisits=881584, meanQ=47.111984, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.490692 0.364249 0.115709 0.031155 0.56194 0.211325 0.465362 0.995603 0.733631 0.431569 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 23
Initial state: 0 0.498331 0.409918 0.229866 0.731202 0.734707 0.231127 0.952728 0.586264 0.355515 0.246981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697767 episodes
GETTING ACTION FROM:
action 1, numVisits=697754, meanQ=38.734389, numObservations: 9
action 2, numVisits=6, meanQ=14.158333, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.498331 0.409918 0.229866 0.731202 0.734707 0.231127 0.952728 0.586264 0.355515 0.246981 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 24
Initial state: 0 0.275688 0.549298 0.474562 0.426995 0.521903 0.709268 0.467999 0.482038 0.574239 0.905991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 184289 episodes
GETTING ACTION FROM:
action -1, numVisits=184258, meanQ=52.393128, numObservations: 243
action 0, numVisits=20, meanQ=-1.147375, numObservations: 19
action 2, numVisits=7, meanQ=-2.292857, numObservations: 5
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.275688 0.549298 0.474562 0.426995 0.521903 0.709268 0.467999 0.482038 0.574239 0.905991 w: 1
Observation: 0 1 0 1 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1083, meanQ=86.385872, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 939978 episodes
GETTING ACTION FROM:
action 4, numVisits=941061, meanQ=85.738898, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.275688 0.549298 0.474562 0.426995 0.521903 0.709268 0.467999 0.482038 0.574239 0.905991 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 25
Initial state: 0 0.986328 0.914053 0.66761 0.948876 0.536447 0.319707 0.714291 0.202251 0.343854 0.221284 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672348 episodes
GETTING ACTION FROM:
action 5, numVisits=672297, meanQ=38.997891, numObservations: 9
action -1, numVisits=27, meanQ=-4.638889, numObservations: 26
action 0, numVisits=16, meanQ=-7.227969, numObservations: 14
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.986328 0.914053 0.66761 0.948876 0.536447 0.319707 0.714291 0.202251 0.343854 0.221284 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=51252, meanQ=44.379573, numObservations: 9
action 4, numVisits=673, meanQ=34.994102, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 753192 episodes
GETTING ACTION FROM:
action 2, numVisits=804444, meanQ=38.690973, numObservations: 9
action 4, numVisits=673, meanQ=34.994102, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.986328 0.914053 0.66761 0.948876 0.536447 0.319707 0.714291 0.202251 0.343854 0.221284 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 26
Initial state: 0 0.64246 0.517082 0.532456 0.344611 0.757817 0.748607 0.298259 0.933985 0.875358 0.299834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 512284 episodes
GETTING ACTION FROM:
action 3, numVisits=512270, meanQ=41.293085, numObservations: 9
action 1, numVisits=7, meanQ=21.414286, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.64246 0.517082 0.532456 0.344611 0.757817 0.748607 0.298259 0.933985 0.875358 0.299834 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 27
Initial state: 0 0.234208 0.24074 0.693548 0.898226 0.48526 0.365197 0.448178 0.112869 0.926604 0.806099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 461144 episodes
GETTING ACTION FROM:
action 1, numVisits=461114, meanQ=41.598200, numObservations: 9
action 5, numVisits=24, meanQ=22.808438, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 0 0.234208 0.24074 0.693548 0.898226 0.48526 0.365197 0.448178 0.112869 0.926604 0.806099 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=52863, meanQ=60.649491, numObservations: 243
action 0, numVisits=9, meanQ=-1.050000, numObservations: 9
action 3, numVisits=6, meanQ=-5.008333, numObservations: 5
action 4, numVisits=8, meanQ=-5.768438, numObservations: 5
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 213208 episodes
GETTING ACTION FROM:
action -1, numVisits=266071, meanQ=44.248102, numObservations: 243
action 0, numVisits=9, meanQ=-1.050000, numObservations: 9
action 3, numVisits=6, meanQ=-5.008333, numObservations: 5
action 4, numVisits=8, meanQ=-5.768438, numObservations: 5
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.234208 0.24074 0.693548 0.898226 0.48526 0.365197 0.448178 0.112869 0.926604 0.806099 w: 1
Observation: 0 1 0 3 0 2 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=2219, meanQ=56.343059, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 949472 episodes
GETTING ACTION FROM:
action 4, numVisits=951691, meanQ=64.864940, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.234208 0.24074 0.693548 0.898226 0.48526 0.365197 0.448178 0.112869 0.926604 0.806099 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=2712, meanQ=50.169026, numObservations: 9
action 5, numVisits=25, meanQ=29.914000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 1018642 episodes
GETTING ACTION FROM:
action 3, numVisits=1021354, meanQ=65.361457, numObservations: 9
action 5, numVisits=25, meanQ=29.914000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.234208 0.24074 0.693548 0.898226 0.48526 0.365197 0.448178 0.112869 0.926604 0.806099 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 62.0526
Run # 28
Initial state: 0 0.868199 0.937795 0.844388 0.696776 0.0993257 0.464629 0.494622 0.318285 0.246897 0.683545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 542683 episodes
GETTING ACTION FROM:
action 3, numVisits=542647, meanQ=39.775733, numObservations: 9
action 2, numVisits=11, meanQ=24.627273, numObservations: 6
action 4, numVisits=19, meanQ=18.623684, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 3
Next state: 0 0.868199 0.937795 0.844388 0.696776 0.0993257 0.464629 0.494622 0.318285 0.246897 0.683545 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=62291, meanQ=44.584122, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 844002 episodes
GETTING ACTION FROM:
action 5, numVisits=906293, meanQ=51.135489, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 0 0.868199 0.937795 0.844388 0.696776 0.0993257 0.464629 0.494622 0.318285 0.246897 0.683545 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=4445, meanQ=43.171554, numObservations: 9
action 1, numVisits=7, meanQ=39.271429, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 1012656 episodes
GETTING ACTION FROM:
action 5, numVisits=1017101, meanQ=73.173464, numObservations: 9
action 1, numVisits=7, meanQ=39.271429, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 0 0.868199 0.937795 0.844388 0.696776 0.0993257 0.464629 0.494622 0.318285 0.246897 0.683545 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=12345, meanQ=54.264420, numObservations: 9
action 4, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 951211 episodes
GETTING ACTION FROM:
action 2, numVisits=963556, meanQ=67.239901, numObservations: 9
action 4, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.868199 0.937795 0.844388 0.696776 0.0993257 0.464629 0.494622 0.318285 0.246897 0.683545 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 53.5026
Run # 29
Initial state: 0 0.416117 0.304416 0.25491 0.13132 0.694564 0.16777 0.312377 0.999252 0.786966 0.808359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 533813 episodes
GETTING ACTION FROM:
action 3, numVisits=533788, meanQ=40.750729, numObservations: 9
action 2, numVisits=20, meanQ=30.940000, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 2 0.416117 0.304416 0.25491 0.13132 0.694564 0.16777 0.312377 0.999252 0.786966 0.808359 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 30
Initial state: 0 0.115993 0.847344 0.916656 0.27223 0.605092 0.254018 0.152692 0.517525 0.473736 0.409664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 197135 episodes
GETTING ACTION FROM:
action 0, numVisits=197101, meanQ=62.169738, numObservations: 243
action -1, numVisits=15, meanQ=-1.050000, numObservations: 15
action 4, numVisits=11, meanQ=-1.822727, numObservations: 6
action 3, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.115993 0.847344 0.916656 0.27223 0.605092 0.254018 0.152692 0.517525 0.473736 0.409664 w: 1
Observation: 0 0 3 0 2 0 3 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1802, meanQ=86.731139, numObservations: 9
action 4, numVisits=4, meanQ=71.737500, numObservations: 2
action 3, numVisits=3, meanQ=62.650000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 935886 episodes
GETTING ACTION FROM:
action 2, numVisits=937688, meanQ=90.715094, numObservations: 9
action 4, numVisits=4, meanQ=71.737500, numObservations: 2
action 3, numVisits=3, meanQ=62.650000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.115993 0.847344 0.916656 0.27223 0.605092 0.254018 0.152692 0.517525 0.473736 0.409664 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 31
Initial state: 0 0.325265 0.522256 0.985 0.012295 0.604009 0.81006 0.296642 0.734083 0.50844 0.395381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 523461 episodes
GETTING ACTION FROM:
action 1, numVisits=523454, meanQ=40.868867, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.325265 0.522256 0.985 0.012295 0.604009 0.81006 0.296642 0.734083 0.50844 0.395381 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=60371, meanQ=44.031145, numObservations: 9
action 1, numVisits=7, meanQ=34.907857, numObservations: 3
action 5, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 779880 episodes
GETTING ACTION FROM:
action 3, numVisits=840251, meanQ=48.899227, numObservations: 9
action 1, numVisits=7, meanQ=34.907857, numObservations: 3
action 5, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.325265 0.522256 0.985 0.012295 0.604009 0.81006 0.296642 0.734083 0.50844 0.395381 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 32
Initial state: 0 0.204604 0.502369 0.422463 0.76648 0.350188 0.426725 0.513083 0.388384 0.00559176 0.435261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 633635 episodes
GETTING ACTION FROM:
action 3, numVisits=633622, meanQ=39.245879, numObservations: 9
action 5, numVisits=8, meanQ=33.106250, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.204604 0.502369 0.422463 0.76648 0.350188 0.426725 0.513083 0.388384 0.00559176 0.435261 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 33
Initial state: 0 0.152756 0.803891 0.171594 0.399067 0.778968 0.784237 0.503567 0.324146 0.242905 0.513549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697663 episodes
GETTING ACTION FROM:
action 3, numVisits=697652, meanQ=38.968768, numObservations: 9
action 1, numVisits=3, meanQ=26.300000, numObservations: 3
action 2, numVisits=4, meanQ=21.737500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 2 0.152756 0.803891 0.171594 0.399067 0.778968 0.784237 0.503567 0.324146 0.242905 0.513549 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 34
Initial state: 0 0.890424 0.66284 0.0613834 0.792373 0.630178 0.251421 0.43176 0.389611 0.501129 0.974476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 677434 episodes
GETTING ACTION FROM:
action 3, numVisits=677420, meanQ=39.201968, numObservations: 9
action 5, numVisits=9, meanQ=4.922500, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 2 0.890424 0.66284 0.0613834 0.792373 0.630178 0.251421 0.43176 0.389611 0.501129 0.974476 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 35
Initial state: 0 0.982556 0.649381 0.613769 0.928088 0.431734 0.408678 0.950149 0.168349 0.753322 0.258628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 631373 episodes
GETTING ACTION FROM:
action 5, numVisits=631365, meanQ=39.161890, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-6.000000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 2 0.982556 0.649381 0.613769 0.928088 0.431734 0.408678 0.950149 0.168349 0.753322 0.258628 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 36
Initial state: 0 0.36471 0.637883 0.184041 0.349288 0.0605165 0.65448 0.536369 0.410116 0.135398 0.0521556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670499 episodes
GETTING ACTION FROM:
action 2, numVisits=670489, meanQ=38.653503, numObservations: 9
action 3, numVisits=4, meanQ=21.737500, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 0 0.36471 0.637883 0.184041 0.349288 0.0605165 0.65448 0.536369 0.410116 0.135398 0.0521556 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=23888, meanQ=42.271887, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 757091 episodes
GETTING ACTION FROM:
action 5, numVisits=780979, meanQ=44.411728, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.36471 0.637883 0.184041 0.349288 0.0605165 0.65448 0.536369 0.410116 0.135398 0.0521556 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=31616, meanQ=66.382006, numObservations: 239
action 1, numVisits=4, meanQ=-5.525000, numObservations: 3
action 3, numVisits=5, meanQ=-6.430000, numObservations: 5
action 0, numVisits=16, meanQ=-7.106250, numObservations: 15
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 229353 episodes
GETTING ACTION FROM:
action -1, numVisits=260969, meanQ=33.988985, numObservations: 243
action 1, numVisits=4, meanQ=-5.525000, numObservations: 3
action 3, numVisits=5, meanQ=-6.430000, numObservations: 5
action 0, numVisits=16, meanQ=-7.106250, numObservations: 15
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.36471 0.637883 0.184041 0.349288 0.0605165 0.65448 0.536369 0.410116 0.135398 0.0521556 w: 1
Observation: 0 1 0 3 0 1 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=184, meanQ=76.803057, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 1018507 episodes
GETTING ACTION FROM:
action 4, numVisits=1018691, meanQ=85.191247, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.36471 0.637883 0.184041 0.349288 0.0605165 0.65448 0.536369 0.410116 0.135398 0.0521556 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 61.6251
Run # 37
Initial state: 0 0.210674 0.745271 0.592166 0.653594 0.436079 0.398006 0.211936 0.493794 0.564661 0.116993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 635098 episodes
GETTING ACTION FROM:
action 1, numVisits=635082, meanQ=38.863532, numObservations: 9
action 4, numVisits=10, meanQ=23.425250, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.210674 0.745271 0.592166 0.653594 0.436079 0.398006 0.211936 0.493794 0.564661 0.116993 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 38
Initial state: 0 0.875804 0.566034 0.393066 0.572499 0.455074 0.357527 0.477573 0.688981 0.814254 0.722483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657274 episodes
GETTING ACTION FROM:
action 4, numVisits=657258, meanQ=39.331781, numObservations: 9
action 2, numVisits=10, meanQ=6.285000, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.875804 0.566034 0.393066 0.572499 0.455074 0.357527 0.477573 0.688981 0.814254 0.722483 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 39
Initial state: 0 0.441566 0.310125 0.675274 0.391068 0.487609 0.974449 0.100464 0.931964 0.562567 0.283375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664225 episodes
GETTING ACTION FROM:
action 2, numVisits=664194, meanQ=38.686757, numObservations: 9
action 1, numVisits=22, meanQ=33.447727, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.441566 0.310125 0.675274 0.391068 0.487609 0.974449 0.100464 0.931964 0.562567 0.283375 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 40
Initial state: 0 0.712783 0.939119 0.463345 0.395334 0.27573 0.814345 0.609409 0.608319 0.421771 0.481417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 524202 episodes
GETTING ACTION FROM:
action 5, numVisits=524165, meanQ=41.216581, numObservations: 9
action 2, numVisits=20, meanQ=31.640125, numObservations: 8
action 1, numVisits=11, meanQ=24.450227, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.712783 0.939119 0.463345 0.395334 0.27573 0.814345 0.609409 0.608319 0.421771 0.481417 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.0595604 0.689411 0.356562 0.903498 0.514443 0.394669 0.0208676 0.930121 0.624724 0.0916348 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 563281 episodes
GETTING ACTION FROM:
action 2, numVisits=563213, meanQ=39.726534, numObservations: 9
action 5, numVisits=30, meanQ=22.498500, numObservations: 8
action 3, numVisits=21, meanQ=18.964405, numObservations: 9
action 4, numVisits=5, meanQ=15.380000, numObservations: 4
action 1, numVisits=10, meanQ=15.185250, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 2
Next state: 1 0.0595604 0.689411 0.356562 0.903498 0.514443 0.394669 0.0208676 0.930121 0.624724 0.0916348 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 42
Initial state: 0 0.5465 0.936153 0.47655 0.586849 0.534938 0.397661 0.988032 0.9436 0.00938477 0.886323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 572881 episodes
GETTING ACTION FROM:
action 5, numVisits=572874, meanQ=39.591269, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.5465 0.936153 0.47655 0.586849 0.534938 0.397661 0.988032 0.9436 0.00938477 0.886323 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=66312, meanQ=45.170404, numObservations: 9
action 1, numVisits=12, meanQ=38.241875, numObservations: 7
action 4, numVisits=5, meanQ=33.180500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 660761 episodes
GETTING ACTION FROM:
action 3, numVisits=727073, meanQ=48.334844, numObservations: 9
action 1, numVisits=12, meanQ=38.241875, numObservations: 7
action 4, numVisits=5, meanQ=33.180500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.5465 0.936153 0.47655 0.586849 0.534938 0.397661 0.988032 0.9436 0.00938477 0.886323 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 43
Initial state: 0 0.76705 0.145011 0.143983 0.579009 0.363428 0.456912 0.525847 0.849039 0.41313 0.430952 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 517148 episodes
GETTING ACTION FROM:
action 3, numVisits=517142, meanQ=41.333240, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.76705 0.145011 0.143983 0.579009 0.363428 0.456912 0.525847 0.849039 0.41313 0.430952 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=6591, meanQ=48.573089, numObservations: 9
action 1, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
Sampled 902941 episodes
GETTING ACTION FROM:
action 3, numVisits=909532, meanQ=52.259595, numObservations: 9
action 1, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action: 3
Next state: 1 0.76705 0.145011 0.143983 0.579009 0.363428 0.456912 0.525847 0.849039 0.41313 0.430952 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 44
Initial state: 0 0.709104 0.265266 0.097056 0.889041 0.938562 0.393803 0.377146 0.22298 0.525661 0.3281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 679572 episodes
GETTING ACTION FROM:
action 3, numVisits=679562, meanQ=38.158269, numObservations: 9
action 4, numVisits=4, meanQ=21.737500, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.709104 0.265266 0.097056 0.889041 0.938562 0.393803 0.377146 0.22298 0.525661 0.3281 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 45
Initial state: 0 0.45592 0.315668 0.219951 0.125036 0.882492 0.0751738 0.0330648 0.601748 0.0496699 0.318249 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 569090 episodes
GETTING ACTION FROM:
action 5, numVisits=569045, meanQ=39.907486, numObservations: 9
action 4, numVisits=37, meanQ=27.606959, numObservations: 9
action 3, numVisits=4, meanQ=21.737500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.45592 0.315668 0.219951 0.125036 0.882492 0.0751738 0.0330648 0.601748 0.0496699 0.318249 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 46
Initial state: 0 0.440651 0.410855 0.401155 0.942817 0.692127 0.44666 0.0270944 0.610236 0.872276 0.349785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 536217 episodes
GETTING ACTION FROM:
action 1, numVisits=536206, meanQ=40.706629, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.440651 0.410855 0.401155 0.942817 0.692127 0.44666 0.0270944 0.610236 0.872276 0.349785 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 47
Initial state: 0 0.528729 0.891278 0.427595 0.362593 0.592654 0.505787 0.102467 0.913066 0.804181 0.873549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658801 episodes
GETTING ACTION FROM:
action 4, numVisits=658790, meanQ=39.251867, numObservations: 9
action 5, numVisits=6, meanQ=14.158333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.528729 0.891278 0.427595 0.362593 0.592654 0.505787 0.102467 0.913066 0.804181 0.873549 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=75860, meanQ=49.828222, numObservations: 9
action 5, numVisits=25, meanQ=44.692200, numObservations: 6
action 1, numVisits=34, meanQ=42.613676, numObservations: 8
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 600476 episodes
GETTING ACTION FROM:
action 4, numVisits=676336, meanQ=61.122288, numObservations: 9
action 5, numVisits=25, meanQ=44.692200, numObservations: 6
action 1, numVisits=34, meanQ=42.613676, numObservations: 8
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 0 0.528729 0.891278 0.427595 0.362593 0.592654 0.505787 0.102467 0.913066 0.804181 0.873549 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=259291, meanQ=46.781151, numObservations: 9
action 3, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 790341 episodes
GETTING ACTION FROM:
action 5, numVisits=1049632, meanQ=52.160148, numObservations: 9
action 3, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.528729 0.891278 0.427595 0.362593 0.592654 0.505787 0.102467 0.913066 0.804181 0.873549 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 48
Initial state: 0 0.454314 0.760789 0.697415 0.886444 0.89948 0.325814 0.444464 0.307342 0.309999 0.947011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 676691 episodes
GETTING ACTION FROM:
action 2, numVisits=676682, meanQ=39.085929, numObservations: 9
action 4, numVisits=3, meanQ=26.300000, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.454314 0.760789 0.697415 0.886444 0.89948 0.325814 0.444464 0.307342 0.309999 0.947011 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 49
Initial state: 0 0.392839 0.401217 0.674721 0.693887 0.666033 0.351827 0.712229 0.346729 0.47773 0.369136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 588653 episodes
GETTING ACTION FROM:
action 5, numVisits=588640, meanQ=39.573448, numObservations: 9
action 4, numVisits=8, meanQ=10.368750, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.392839 0.401217 0.674721 0.693887 0.666033 0.351827 0.712229 0.346729 0.47773 0.369136 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 50
Initial state: 0 0.243093 0.810365 0.0210357 0.919426 0.443209 0.314738 0.259789 0.836558 0.245449 0.603954 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 630398 episodes
GETTING ACTION FROM:
action 2, numVisits=630383, meanQ=39.065048, numObservations: 9
action 1, numVisits=6, meanQ=29.316667, numObservations: 5
action 5, numVisits=3, meanQ=25.650833, numObservations: 1
action 4, numVisits=3, meanQ=22.800833, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.243093 0.810365 0.0210357 0.919426 0.443209 0.314738 0.259789 0.836558 0.245449 0.603954 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=4625, meanQ=61.662633, numObservations: 235
action -1, numVisits=17, meanQ=-1.164559, numObservations: 16
action 4, numVisits=7, meanQ=-2.292857, numObservations: 6
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 269349 episodes
GETTING ACTION FROM:
action 0, numVisits=273974, meanQ=1.833489, numObservations: 243
action -1, numVisits=17, meanQ=-1.164559, numObservations: 16
action 4, numVisits=7, meanQ=-2.292857, numObservations: 6
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 0
Next state: 0 0.243093 0.810365 0.0210357 0.919426 0.443209 0.314738 0.259789 0.836558 0.245449 0.603954 w: 1
Observation: 0 0 3 0 3 0 2 0 1 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=249, meanQ=57.052331, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 1039613 episodes
GETTING ACTION FROM:
action 1, numVisits=1039862, meanQ=77.881866, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.243093 0.810365 0.0210357 0.919426 0.443209 0.314738 0.259789 0.836558 0.245449 0.603954 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=318, meanQ=94.892162, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 1039196 episodes
GETTING ACTION FROM:
action 3, numVisits=1039514, meanQ=95.037380, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.243093 0.810365 0.0210357 0.919426 0.443209 0.314738 0.259789 0.836558 0.245449 0.603954 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 62.0526
[32m ProblemEnvironment.hpp 351: Done.[39m
