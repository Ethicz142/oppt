Run # 1
Initial state: 0 0.0091255 0.27664 0.717536 0.614981 0.209732 0.498211 0.522205 0.982772 0.304033 0.350953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 684856 episodes
GETTING ACTION FROM:
action 2, numVisits=684847, meanQ=33.226010, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.0091255 0.27664 0.717536 0.614981 0.209732 0.498211 0.522205 0.982772 0.304033 0.350953 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 2
Initial state: 0 0.374642 0.345796 0.448296 0.464842 0.0188239 0.313321 0.707116 0.105371 0.977125 0.217403 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 196911 episodes
GETTING ACTION FROM:
action -1, numVisits=196801, meanQ=55.764410, numObservations: 243
action 0, numVisits=89, meanQ=-1.608792, numObservations: 72
action 5, numVisits=13, meanQ=-1.696154, numObservations: 7
action 3, numVisits=5, meanQ=-6.819500, numObservations: 4
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.374642 0.345796 0.448296 0.464842 0.0188239 0.313321 0.707116 0.105371 0.977125 0.217403 w: 1
Observation: 0 2 0 3 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=883, meanQ=52.389310, numObservations: 9
action 2, numVisits=6, meanQ=14.158333, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 927427 episodes
GETTING ACTION FROM:
action 1, numVisits=928310, meanQ=63.782292, numObservations: 9
action 2, numVisits=6, meanQ=14.158333, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.374642 0.345796 0.448296 0.464842 0.0188239 0.313321 0.707116 0.105371 0.977125 0.217403 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 3
Initial state: 0 0.988542 0.0518474 0.313228 0.339336 0.894733 0.186117 0.967302 0.927529 0.641702 0.714921 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694202 episodes
GETTING ACTION FROM:
action 2, numVisits=694146, meanQ=33.936461, numObservations: 9
action 1, numVisits=40, meanQ=24.621438, numObservations: 9
action 3, numVisits=11, meanQ=16.359091, numObservations: 6
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.988542 0.0518474 0.313228 0.339336 0.894733 0.186117 0.967302 0.927529 0.641702 0.714921 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 4
Initial state: 0 0.202605 0.635728 0.356634 0.167004 0.383459 0.309285 0.612132 0.745595 0.38466 0.439561 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 196373 episodes
GETTING ACTION FROM:
action 0, numVisits=196340, meanQ=61.240034, numObservations: 243
action 5, numVisits=17, meanQ=-2.597059, numObservations: 7
action -1, numVisits=12, meanQ=-9.125000, numObservations: 11
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.202605 0.635728 0.356634 0.167004 0.383459 0.309285 0.612132 0.745595 0.38466 0.439561 w: 1
Observation: 0 0 3 0 1 0 1 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1045, meanQ=67.421495, numObservations: 9
action 1, numVisits=11, meanQ=52.722727, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 871121 episodes
GETTING ACTION FROM:
action 4, numVisits=872166, meanQ=63.044687, numObservations: 9
action 1, numVisits=11, meanQ=52.722727, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.202605 0.635728 0.356634 0.167004 0.383459 0.309285 0.612132 0.745595 0.38466 0.439561 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 5
Initial state: 0 0.726632 0.378305 0.347937 0.41613 0.110703 0.861794 0.0677922 0.0630295 0.665814 0.741018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 526596 episodes
GETTING ACTION FROM:
action 1, numVisits=526590, meanQ=36.621637, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.726632 0.378305 0.347937 0.41613 0.110703 0.861794 0.0677922 0.0630295 0.665814 0.741018 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 6
Initial state: 0 0.974147 0.827305 0.291076 0.390797 0.916301 0.787131 0.914121 0.988671 0.578159 0.742285 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 196429 episodes
GETTING ACTION FROM:
action 0, numVisits=196411, meanQ=62.830970, numObservations: 243
action -1, numVisits=13, meanQ=-1.050000, numObservations: 13
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.974147 0.827305 0.291076 0.390797 0.916301 0.787131 0.914121 0.988671 0.578159 0.742285 w: 1
Observation: 0 0 2 0 2 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1489, meanQ=55.645585, numObservations: 9
action 2, numVisits=6, meanQ=47.491667, numObservations: 2
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 886542 episodes
GETTING ACTION FROM:
action 1, numVisits=888031, meanQ=67.646409, numObservations: 9
action 2, numVisits=6, meanQ=47.491667, numObservations: 2
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.974147 0.827305 0.291076 0.390797 0.916301 0.787131 0.914121 0.988671 0.578159 0.742285 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 7
Initial state: 0 0.973161 0.460999 0.625919 0.0698998 0.222139 0.0502543 0.557747 0.832218 0.359439 0.433979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 761801 episodes
GETTING ACTION FROM:
action 1, numVisits=761787, meanQ=33.220014, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=6, meanQ=-4.016667, numObservations: 5
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.973161 0.460999 0.625919 0.0698998 0.222139 0.0502543 0.557747 0.832218 0.359439 0.433979 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 8
Initial state: 0 0.698451 0.481578 0.910788 0.663961 0.38347 0.412808 0.302056 0.221668 0.343845 0.478378 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699658 episodes
GETTING ACTION FROM:
action 4, numVisits=699626, meanQ=33.815758, numObservations: 9
action 3, numVisits=5, meanQ=19.000000, numObservations: 5
action 1, numVisits=22, meanQ=18.856932, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 2 0.698451 0.481578 0.910788 0.663961 0.38347 0.412808 0.302056 0.221668 0.343845 0.478378 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 9
Initial state: 0 0.823541 0.982762 0.324238 0.423272 0.792138 0.112669 0.990828 0.448111 0.289276 0.502016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 770673 episodes
GETTING ACTION FROM:
action 2, numVisits=770666, meanQ=32.590635, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.823541 0.982762 0.324238 0.423272 0.792138 0.112669 0.990828 0.448111 0.289276 0.502016 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 10
Initial state: 0 0.219813 0.974499 0.420166 0.269387 0.909605 0.892506 0.323182 0.886251 0.378992 0.3751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 728991 episodes
GETTING ACTION FROM:
action 3, numVisits=728973, meanQ=32.985501, numObservations: 9
action 1, numVisits=11, meanQ=16.359091, numObservations: 7
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.219813 0.974499 0.420166 0.269387 0.909605 0.892506 0.323182 0.886251 0.378992 0.3751 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 11
Initial state: 0 0.156171 0.366807 0.877909 0.803189 0.872385 0.230092 0.365417 0.44977 0.847208 0.333781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675099 episodes
GETTING ACTION FROM:
action 4, numVisits=675091, meanQ=33.564072, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.156171 0.366807 0.877909 0.803189 0.872385 0.230092 0.365417 0.44977 0.847208 0.333781 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 12
Initial state: 0 0.372774 0.41749 0.380853 0.585325 0.127883 0.380536 0.576793 0.186031 0.140096 0.823321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 651973 episodes
GETTING ACTION FROM:
action 2, numVisits=651967, meanQ=34.185498, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 2 0.372774 0.41749 0.380853 0.585325 0.127883 0.380536 0.576793 0.186031 0.140096 0.823321 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 13
Initial state: 0 0.639439 0.0942626 0.590238 0.316161 0.372572 0.672536 0.295986 0.381333 0.853678 0.18882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 771382 episodes
GETTING ACTION FROM:
action 1, numVisits=771366, meanQ=32.718576, numObservations: 9
action 5, numVisits=10, meanQ=7.500000, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.639439 0.0942626 0.590238 0.316161 0.372572 0.672536 0.295986 0.381333 0.853678 0.18882 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 14
Initial state: 0 0.336864 0.365049 0.23147 0.0370741 0.490068 0.805311 0.506575 0.0704111 0.607352 0.985409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 733378 episodes
GETTING ACTION FROM:
action 2, numVisits=733334, meanQ=33.746617, numObservations: 9
action 3, numVisits=16, meanQ=28.687500, numObservations: 8
action 4, numVisits=18, meanQ=27.544444, numObservations: 8
action 1, numVisits=7, meanQ=26.278571, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.336864 0.365049 0.23147 0.0370741 0.490068 0.805311 0.506575 0.0704111 0.607352 0.985409 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=10484, meanQ=55.267533, numObservations: 242
action 0, numVisits=10, meanQ=-1.050000, numObservations: 10
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 244563 episodes
GETTING ACTION FROM:
action -1, numVisits=255047, meanQ=14.878005, numObservations: 243
action 0, numVisits=10, meanQ=-1.050000, numObservations: 10
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.336864 0.365049 0.23147 0.0370741 0.490068 0.805311 0.506575 0.0704111 0.607352 0.985409 w: 1
Observation: 0 2 0 1 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=644, meanQ=80.117349, numObservations: 9
action 3, numVisits=3, meanQ=62.650000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 995984 episodes
GETTING ACTION FROM:
action 1, numVisits=996628, meanQ=72.216950, numObservations: 9
action 3, numVisits=3, meanQ=62.650000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.336864 0.365049 0.23147 0.0370741 0.490068 0.805311 0.506575 0.0704111 0.607352 0.985409 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 15
Initial state: 0 0.210242 0.217757 0.368806 0.354404 0.54834 0.12268 0.504193 0.0748496 0.505759 0.740647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 738528 episodes
GETTING ACTION FROM:
action 4, numVisits=738506, meanQ=32.852010, numObservations: 9
action 3, numVisits=16, meanQ=16.053125, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.210242 0.217757 0.368806 0.354404 0.54834 0.12268 0.504193 0.0748496 0.505759 0.740647 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 16
Initial state: 0 0.425748 0.229166 0.878377 0.264288 0.133785 0.253596 0.33208 0.412525 0.927627 0.627262 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 202816 episodes
GETTING ACTION FROM:
action 0, numVisits=202784, meanQ=63.728827, numObservations: 243
action -1, numVisits=13, meanQ=-1.050000, numObservations: 13
action 3, numVisits=5, meanQ=-2.810000, numObservations: 4
action 2, numVisits=6, meanQ=-4.016667, numObservations: 3
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=4, meanQ=-5.525000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.425748 0.229166 0.878377 0.264288 0.133785 0.253596 0.33208 0.412525 0.927627 0.627262 w: 1
Observation: 0 0 1 0 3 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=423, meanQ=69.548230, numObservations: 9
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 827397 episodes
GETTING ACTION FROM:
action 5, numVisits=827820, meanQ=67.466394, numObservations: 9
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.425748 0.229166 0.878377 0.264288 0.133785 0.253596 0.33208 0.412525 0.927627 0.627262 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 17
Initial state: 0 0.566122 0.798883 0.65038 0.300529 0.511481 0.545126 0.553223 0.355418 0.324163 0.463936 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 715360 episodes
GETTING ACTION FROM:
action 4, numVisits=714515, meanQ=33.452481, numObservations: 9
action 5, numVisits=824, meanQ=32.590391, numObservations: 9
action 3, numVisits=7, meanQ=26.278571, numObservations: 5
action 1, numVisits=11, meanQ=26.272727, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.566122 0.798883 0.65038 0.300529 0.511481 0.545126 0.553223 0.355418 0.324163 0.463936 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 18
Initial state: 0 0.285816 0.300834 0.752986 0.545533 0.327748 0.430004 0.219725 0.548881 0.262045 0.0611269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 754748 episodes
GETTING ACTION FROM:
action 5, numVisits=754728, meanQ=33.584127, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=13, meanQ=-2.153846, numObservations: 6
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.285816 0.300834 0.752986 0.545533 0.327748 0.430004 0.219725 0.548881 0.262045 0.0611269 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=39785, meanQ=37.451965, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 2
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 758840 episodes
GETTING ACTION FROM:
action 1, numVisits=798625, meanQ=32.939485, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 2
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.285816 0.300834 0.752986 0.545533 0.327748 0.430004 0.219725 0.548881 0.262045 0.0611269 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=31527, meanQ=21.201897, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 830568 episodes
GETTING ACTION FROM:
action 3, numVisits=862095, meanQ=22.866008, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 0 0.285816 0.300834 0.752986 0.545533 0.327748 0.430004 0.219725 0.548881 0.262045 0.0611269 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 0, numVisits=7663, meanQ=70.525976, numObservations: 189
action -1, numVisits=13, meanQ=-1.499423, numObservations: 10
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 262612 episodes
GETTING ACTION FROM:
action 0, numVisits=270275, meanQ=10.496856, numObservations: 243
action -1, numVisits=13, meanQ=-1.499423, numObservations: 10
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.285816 0.300834 0.752986 0.545533 0.327748 0.430004 0.219725 0.548881 0.262045 0.0611269 w: 1
Observation: 0 0 1 0 3 0 2 0 3 0 1 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 4, numVisits=22, meanQ=89.909091, numObservations: 5
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 1035437 episodes
GETTING ACTION FROM:
action 4, numVisits=1035459, meanQ=74.982679, numObservations: 9
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.285816 0.300834 0.752986 0.545533 0.327748 0.430004 0.219725 0.548881 0.262045 0.0611269 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 47.5439
Run # 19
Initial state: 0 0.487231 0.723661 0.505072 0.528505 0.415351 0.389681 0.231326 0.532303 0.333052 0.474213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 743378 episodes
GETTING ACTION FROM:
action 2, numVisits=743323, meanQ=33.750589, numObservations: 9
action 1, numVisits=50, meanQ=13.410300, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.487231 0.723661 0.505072 0.528505 0.415351 0.389681 0.231326 0.532303 0.333052 0.474213 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 20
Initial state: 0 0.229419 0.427307 0.0795796 0.533393 0.319883 0.475611 0.677844 0.724455 0.175473 0.800019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 615808 episodes
GETTING ACTION FROM:
action 4, numVisits=615765, meanQ=34.793543, numObservations: 9
action 5, numVisits=23, meanQ=20.963370, numObservations: 7
action 2, numVisits=13, meanQ=20.534808, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action: 4
Next state: 1 0.229419 0.427307 0.0795796 0.533393 0.319883 0.475611 0.677844 0.724455 0.175473 0.800019 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 21
Initial state: 0 0.466081 0.580986 0.383413 0.460197 0.50696 0.839974 0.121992 0.387114 0.119976 0.0313459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 759616 episodes
GETTING ACTION FROM:
action 5, numVisits=759608, meanQ=33.269349, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.466081 0.580986 0.383413 0.460197 0.50696 0.839974 0.121992 0.387114 0.119976 0.0313459 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=41738, meanQ=37.843807, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 846473 episodes
GETTING ACTION FROM:
action 4, numVisits=888211, meanQ=36.588291, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.466081 0.580986 0.383413 0.460197 0.50696 0.839974 0.121992 0.387114 0.119976 0.0313459 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 22
Initial state: 0 0.476749 0.721948 0.340477 0.355251 0.4842 0.360549 0.4209 0.64939 0.225668 0.840078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687351 episodes
GETTING ACTION FROM:
action 5, numVisits=687345, meanQ=33.395819, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.476749 0.721948 0.340477 0.355251 0.4842 0.360549 0.4209 0.64939 0.225668 0.840078 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 23
Initial state: 0 0.643399 0.528904 0.357093 0.439733 0.145826 0.752994 0.352221 0.618623 0.444899 0.490434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 708473 episodes
GETTING ACTION FROM:
action 4, numVisits=708463, meanQ=32.734894, numObservations: 9
action 5, numVisits=4, meanQ=21.737500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.643399 0.528904 0.357093 0.439733 0.145826 0.752994 0.352221 0.618623 0.444899 0.490434 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 24
Initial state: 0 0.375527 0.596682 0.818577 0.217462 0.603804 0.869463 0.223389 0.182058 0.341603 0.376659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 749357 episodes
GETTING ACTION FROM:
action 1, numVisits=749339, meanQ=32.787981, numObservations: 9
action 2, numVisits=12, meanQ=20.408333, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.375527 0.596682 0.818577 0.217462 0.603804 0.869463 0.223389 0.182058 0.341603 0.376659 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 25
Initial state: 0 0.494094 0.94818 0.318333 0.456897 0.776077 0.783626 0.819605 0.1529 0.809444 0.9131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 763715 episodes
GETTING ACTION FROM:
action 1, numVisits=763707, meanQ=33.322312, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.494094 0.94818 0.318333 0.456897 0.776077 0.783626 0.819605 0.1529 0.809444 0.9131 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 26
Initial state: 0 0.335451 0.730324 0.797101 0.443408 0.885849 0.80171 0.296596 0.463066 0.438005 0.339058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 680596 episodes
GETTING ACTION FROM:
action 3, numVisits=680569, meanQ=33.283579, numObservations: 9
action 1, numVisits=4, meanQ=21.737500, numObservations: 4
action 4, numVisits=4, meanQ=21.737500, numObservations: 3
action 5, numVisits=4, meanQ=21.737500, numObservations: 4
action 2, numVisits=13, meanQ=20.684615, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 3
Next state: 1 0.335451 0.730324 0.797101 0.443408 0.885849 0.80171 0.296596 0.463066 0.438005 0.339058 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 27
Initial state: 0 0.345871 0.455462 0.24755 0.470517 0.720258 0.374691 0.913361 0.717726 0.652696 0.0457274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 751865 episodes
GETTING ACTION FROM:
action 2, numVisits=751796, meanQ=32.513301, numObservations: 9
action 3, numVisits=27, meanQ=24.183426, numObservations: 9
action 4, numVisits=38, meanQ=23.679013, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.345871 0.455462 0.24755 0.470517 0.720258 0.374691 0.913361 0.717726 0.652696 0.0457274 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=18110, meanQ=35.505528, numObservations: 9
action 2, numVisits=5, meanQ=9.660500, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 859698 episodes
GETTING ACTION FROM:
action 3, numVisits=877808, meanQ=37.748018, numObservations: 9
action 2, numVisits=5, meanQ=9.660500, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.345871 0.455462 0.24755 0.470517 0.720258 0.374691 0.913361 0.717726 0.652696 0.0457274 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 28
Initial state: 0 0.957022 0.601617 0.80836 0.783832 0.330648 0.935117 0.56466 0.356106 0.273554 0.468388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 712288 episodes
GETTING ACTION FROM:
action 3, numVisits=712245, meanQ=33.786109, numObservations: 9
action 5, numVisits=34, meanQ=31.523750, numObservations: 9
action 2, numVisits=5, meanQ=19.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.957022 0.601617 0.80836 0.783832 0.330648 0.935117 0.56466 0.356106 0.273554 0.468388 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 29
Initial state: 0 0.454851 0.43556 0.515339 0.00815605 0.26908 0.400688 0.0831079 0.0118426 0.986703 0.484941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 753700 episodes
GETTING ACTION FROM:
action 2, numVisits=753693, meanQ=33.359175, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.454851 0.43556 0.515339 0.00815605 0.26908 0.400688 0.0831079 0.0118426 0.986703 0.484941 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 30
Initial state: 0 0.200363 0.166362 0.299416 0.20373 0.606776 0.652856 0.352853 0.417833 0.317713 0.0480866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 201078 episodes
GETTING ACTION FROM:
action 0, numVisits=201059, meanQ=63.611573, numObservations: 243
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=4, meanQ=-5.525000, numObservations: 4
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action: 0
Next state: 0 0.200363 0.166362 0.299416 0.20373 0.606776 0.652856 0.352853 0.417833 0.317713 0.0480866 w: 1
Observation: 0 0 1 0 1 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=751, meanQ=84.228525, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 943770 episodes
GETTING ACTION FROM:
action 4, numVisits=944521, meanQ=87.521318, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.200363 0.166362 0.299416 0.20373 0.606776 0.652856 0.352853 0.417833 0.317713 0.0480866 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 31
Initial state: 0 0.343325 0.89152 0.167305 0.447252 0.46564 0.139397 0.374454 0.390213 0.0546047 0.817323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 764675 episodes
GETTING ACTION FROM:
action 1, numVisits=764656, meanQ=33.301670, numObservations: 9
action 4, numVisits=11, meanQ=12.537045, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 1
Next state: 2 0.343325 0.89152 0.167305 0.447252 0.46564 0.139397 0.374454 0.390213 0.0546047 0.817323 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 32
Initial state: 0 0.955843 0.995017 0.178599 0.873131 0.302921 0.0530647 0.292335 0.333243 0.564305 0.966759 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 737135 episodes
GETTING ACTION FROM:
action 3, numVisits=737121, meanQ=33.407474, numObservations: 9
action 1, numVisits=8, meanQ=7.862812, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.955843 0.995017 0.178599 0.873131 0.302921 0.0530647 0.292335 0.333243 0.564305 0.966759 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 33
Initial state: 0 0.764874 0.139909 0.45872 0.605336 0.339205 0.464813 0.431528 0.319538 0.800543 0.520015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 754966 episodes
GETTING ACTION FROM:
action 3, numVisits=754960, meanQ=32.649347, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.764874 0.139909 0.45872 0.605336 0.339205 0.464813 0.431528 0.319538 0.800543 0.520015 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 34
Initial state: 0 0.279031 0.459171 0.575934 0.710431 0.42281 0.568077 0.257832 0.0410516 0.555103 0.862452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 733541 episodes
GETTING ACTION FROM:
action 5, numVisits=733498, meanQ=33.436009, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 1, numVisits=32, meanQ=-2.131250, numObservations: 9
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.279031 0.459171 0.575934 0.710431 0.42281 0.568077 0.257832 0.0410516 0.555103 0.862452 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 35
Initial state: 0 0.773046 0.469 0.445577 0.339863 0.917124 0.295267 0.902516 0.756465 0.330917 0.437813 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 756259 episodes
GETTING ACTION FROM:
action 3, numVisits=756226, meanQ=33.412794, numObservations: 9
action 5, numVisits=19, meanQ=16.513421, numObservations: 7
action 2, numVisits=10, meanQ=7.500000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.773046 0.469 0.445577 0.339863 0.917124 0.295267 0.902516 0.756465 0.330917 0.437813 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 36
Initial state: 0 0.375165 0.342991 0.201539 0.82304 0.679107 0.749943 0.268561 0.790731 0.218201 0.737001 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 741675 episodes
GETTING ACTION FROM:
action 1, numVisits=741653, meanQ=33.543994, numObservations: 9
action 2, numVisits=17, meanQ=21.997059, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.375165 0.342991 0.201539 0.82304 0.679107 0.749943 0.268561 0.790731 0.218201 0.737001 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 37
Initial state: 0 0.765329 0.903833 0.140353 0.804874 0.15392 0.361304 0.147327 0.229928 0.278302 0.38736 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 682315 episodes
GETTING ACTION FROM:
action 5, numVisits=682282, meanQ=34.048345, numObservations: 9
action 2, numVisits=27, meanQ=30.772222, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.765329 0.903833 0.140353 0.804874 0.15392 0.361304 0.147327 0.229928 0.278302 0.38736 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 38
Initial state: 0 0.0726178 0.643226 0.00481074 0.310854 0.00909957 0.726445 0.308641 0.458928 0.306838 0.0589939 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 773973 episodes
GETTING ACTION FROM:
action 4, numVisits=773932, meanQ=33.294606, numObservations: 9
action 2, numVisits=15, meanQ=16.586667, numObservations: 7
action 3, numVisits=22, meanQ=15.088864, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0726178 0.643226 0.00481074 0.310854 0.00909957 0.726445 0.308641 0.458928 0.306838 0.0589939 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 39
Initial state: 0 0.477662 0.321024 0.914822 0.741583 0.424061 0.374932 0.28036 0.374243 0.321191 0.710745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 771339 episodes
GETTING ACTION FROM:
action 1, numVisits=771314, meanQ=33.353233, numObservations: 9
action 3, numVisits=19, meanQ=18.071184, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.477662 0.321024 0.914822 0.741583 0.424061 0.374932 0.28036 0.374243 0.321191 0.710745 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 40
Initial state: 0 0.791939 0.484607 0.832738 0.110057 0.707241 0.252582 0.231083 0.950254 0.357949 0.403247 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 617026 episodes
GETTING ACTION FROM:
action 1, numVisits=617011, meanQ=35.013967, numObservations: 9
action 2, numVisits=9, meanQ=8.100000, numObservations: 5
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.791939 0.484607 0.832738 0.110057 0.707241 0.252582 0.231083 0.950254 0.357949 0.403247 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.409655 0.729491 0.179785 0.27669 0.135586 0.00562706 0.341913 0.156615 0.278511 0.360102 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 639536 episodes
GETTING ACTION FROM:
action 4, numVisits=639520, meanQ=34.976982, numObservations: 9
action 5, numVisits=6, meanQ=14.158333, numObservations: 3
action 3, numVisits=6, meanQ=14.158333, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.409655 0.729491 0.179785 0.27669 0.135586 0.00562706 0.341913 0.156615 0.278511 0.360102 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 42
Initial state: 0 0.870498 0.419405 0.0418925 0.572167 0.0601279 0.0755737 0.0247051 0.899203 0.386905 0.443945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 762569 episodes
GETTING ACTION FROM:
action 3, numVisits=762535, meanQ=33.628821, numObservations: 9
action 1, numVisits=29, meanQ=13.825948, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.870498 0.419405 0.0418925 0.572167 0.0601279 0.0755737 0.0247051 0.899203 0.386905 0.443945 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 43
Initial state: 0 0.272823 0.467523 0.840598 0.426741 0.856207 0.281309 0.568258 0.45082 0.248957 0.797134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657845 episodes
GETTING ACTION FROM:
action 5, numVisits=657832, meanQ=34.750455, numObservations: 9
action 1, numVisits=7, meanQ=13.285714, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 0 0.272823 0.467523 0.840598 0.426741 0.856207 0.281309 0.568258 0.45082 0.248957 0.797134 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=44105, meanQ=39.354645, numObservations: 9
action 1, numVisits=14, meanQ=18.489286, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 837601 episodes
GETTING ACTION FROM:
action 3, numVisits=881706, meanQ=45.696074, numObservations: 9
action 1, numVisits=14, meanQ=18.489286, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.272823 0.467523 0.840598 0.426741 0.856207 0.281309 0.568258 0.45082 0.248957 0.797134 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 44
Initial state: 0 0.307411 0.282624 0.595789 0.438578 0.392029 0.340102 0.66451 0.694946 0.33892 0.773106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 634951 episodes
GETTING ACTION FROM:
action 1, numVisits=634935, meanQ=34.662209, numObservations: 9
action 2, numVisits=8, meanQ=10.368750, numObservations: 5
action 5, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.307411 0.282624 0.595789 0.438578 0.392029 0.340102 0.66451 0.694946 0.33892 0.773106 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 45
Initial state: 0 0.465508 0.619213 0.139419 0.365378 0.877694 0.325954 0.339937 0.473415 0.162368 0.0406433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 623013 episodes
GETTING ACTION FROM:
action 1, numVisits=623004, meanQ=34.358613, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.465508 0.619213 0.139419 0.365378 0.877694 0.325954 0.339937 0.473415 0.162368 0.0406433 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 46
Initial state: 0 0.649818 0.0223852 0.377097 0.40183 0.125225 0.225698 0.191796 0.979018 0.516301 0.0558745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700231 episodes
GETTING ACTION FROM:
action 3, numVisits=700205, meanQ=33.587797, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=19, meanQ=-3.484079, numObservations: 8
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.649818 0.0223852 0.377097 0.40183 0.125225 0.225698 0.191796 0.979018 0.516301 0.0558745 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=38128, meanQ=38.646537, numObservations: 9
action 2, numVisits=7, meanQ=26.278571, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 806805 episodes
GETTING ACTION FROM:
action 2, numVisits=742054, meanQ=40.612172, numObservations: 9
action 1, numVisits=102886, meanQ=28.825290, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.649818 0.0223852 0.377097 0.40183 0.125225 0.225698 0.191796 0.979018 0.516301 0.0558745 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 47
Initial state: 0 0.667626 0.47138 0.417707 0.340521 0.273792 0.380415 0.59276 0.947027 0.632465 0.714222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 575379 episodes
GETTING ACTION FROM:
action 3, numVisits=575372, meanQ=35.664958, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.667626 0.47138 0.417707 0.340521 0.273792 0.380415 0.59276 0.947027 0.632465 0.714222 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 48
Initial state: 0 0.29236 0.427031 0.637686 0.857783 0.51415 0.0960245 0.0115024 0.339328 0.383433 0.833634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 762960 episodes
GETTING ACTION FROM:
action 2, numVisits=762933, meanQ=32.999387, numObservations: 9
action 3, numVisits=11, meanQ=14.713636, numObservations: 7
action 1, numVisits=12, meanQ=13.662500, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.29236 0.427031 0.637686 0.857783 0.51415 0.0960245 0.0115024 0.339328 0.383433 0.833634 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 49
Initial state: 0 0.0266202 0.260587 0.518035 0.517408 0.301114 0.337989 0.0679435 0.16581 0.83037 0.38437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 637071 episodes
GETTING ACTION FROM:
action 1, numVisits=637050, meanQ=34.503534, numObservations: 9
action 4, numVisits=8, meanQ=21.737500, numObservations: 4
action 5, numVisits=6, meanQ=14.158333, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=4, meanQ=-5.525000, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0266202 0.260587 0.518035 0.517408 0.301114 0.337989 0.0679435 0.16581 0.83037 0.38437 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=34394, meanQ=60.865006, numObservations: 243
action 2, numVisits=17, meanQ=-2.597059, numObservations: 7
action 5, numVisits=13, meanQ=-3.088462, numObservations: 7
action 0, numVisits=16, meanQ=-7.106250, numObservations: 15
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 213107 episodes
GETTING ACTION FROM:
action -1, numVisits=247501, meanQ=49.012603, numObservations: 243
action 2, numVisits=17, meanQ=-2.597059, numObservations: 7
action 5, numVisits=13, meanQ=-3.088462, numObservations: 7
action 0, numVisits=16, meanQ=-7.106250, numObservations: 15
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0266202 0.260587 0.518035 0.517408 0.301114 0.337989 0.0679435 0.16581 0.83037 0.38437 w: 1
Observation: 0 1 0 3 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2071, meanQ=87.636094, numObservations: 9
action 5, numVisits=4, meanQ=49.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 964227 episodes
GETTING ACTION FROM:
action 3, numVisits=966298, meanQ=89.939598, numObservations: 9
action 5, numVisits=4, meanQ=49.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.0266202 0.260587 0.518035 0.517408 0.301114 0.337989 0.0679435 0.16581 0.83037 0.38437 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 50
Initial state: 0 0.287329 0.332265 0.783829 0.984894 0.146035 0.0269901 0.114066 0.408592 0.737782 0.0896733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 637155 episodes
GETTING ACTION FROM:
action 3, numVisits=637127, meanQ=34.994692, numObservations: 9
action 5, numVisits=23, meanQ=0.215543, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.287329 0.332265 0.783829 0.984894 0.146035 0.0269901 0.114066 0.408592 0.737782 0.0896733 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=34300, meanQ=37.894848, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 635211 episodes
GETTING ACTION FROM:
action 2, numVisits=669511, meanQ=29.236777, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.287329 0.332265 0.783829 0.984894 0.146035 0.0269901 0.114066 0.408592 0.737782 0.0896733 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
[32m ProblemEnvironment.hpp 351: Done.[39m
