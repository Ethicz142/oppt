Run # 1
Initial state: 0 0.548258 0.262758 0.40417 0.251362 0.591919 0.880789 0.908177 0.355693 0.462095 0.430959 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 393472 episodes
GETTING ACTION FROM:
action 5, numVisits=393458, meanQ=35.712977, numObservations: 9
action 2, numVisits=5, meanQ=15.380000, numObservations: 4
action 4, numVisits=5, meanQ=15.380000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.548258 0.262758 0.40417 0.251362 0.591919 0.880789 0.908177 0.355693 0.462095 0.430959 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 2
Initial state: 0 0.309829 0.00603376 0.0783973 0.926134 0.418831 0.360325 0.0563992 0.102351 0.492088 0.63662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 417367 episodes
GETTING ACTION FROM:
action 3, numVisits=417340, meanQ=36.194599, numObservations: 9
action 5, numVisits=16, meanQ=29.684375, numObservations: 8
action 1, numVisits=6, meanQ=14.158333, numObservations: 6
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 0 0.309829 0.00603376 0.0783973 0.926134 0.418831 0.360325 0.0563992 0.102351 0.492088 0.63662 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=7021, meanQ=76.792532, numObservations: 9
action 2, numVisits=5, meanQ=55.380000, numObservations: 4
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 600625 episodes
GETTING ACTION FROM:
action 3, numVisits=607646, meanQ=88.307728, numObservations: 9
action 2, numVisits=5, meanQ=55.380000, numObservations: 4
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.309829 0.00603376 0.0783973 0.926134 0.418831 0.360325 0.0563992 0.102351 0.492088 0.63662 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 3
Initial state: 0 0.0931456 0.972362 0.32028 0.40096 0.375518 0.447456 0.284793 0.431372 0.0129874 0.426516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 415317 episodes
GETTING ACTION FROM:
action 5, numVisits=415293, meanQ=35.541921, numObservations: 9
action 3, numVisits=19, meanQ=32.052895, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.0931456 0.972362 0.32028 0.40096 0.375518 0.447456 0.284793 0.431372 0.0129874 0.426516 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=15535, meanQ=40.214868, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 484666 episodes
GETTING ACTION FROM:
action 1, numVisits=500201, meanQ=37.090475, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 0 0.0931456 0.972362 0.32028 0.40096 0.375518 0.447456 0.284793 0.431372 0.0129874 0.426516 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=20253, meanQ=49.537939, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 320104 episodes
GETTING ACTION FROM:
action 1, numVisits=340357, meanQ=70.425004, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0931456 0.972362 0.32028 0.40096 0.375518 0.447456 0.284793 0.431372 0.0129874 0.426516 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 0, numVisits=59951, meanQ=67.999030, numObservations: 243
action -1, numVisits=15, meanQ=-1.179833, numObservations: 14
action 4, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 147850 episodes
GETTING ACTION FROM:
action 0, numVisits=207801, meanQ=29.516512, numObservations: 243
action -1, numVisits=15, meanQ=-1.179833, numObservations: 14
action 4, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0931456 0.972362 0.32028 0.40096 0.375518 0.447456 0.284793 0.431372 0.0129874 0.426516 w: 1
Observation: 0 0 3 0 3 0 2 0 2 0 2 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 4, numVisits=3518, meanQ=40.111082, numObservations: 9
action 2, numVisits=20, meanQ=13.547500, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 618706 episodes
GETTING ACTION FROM:
action 4, numVisits=622224, meanQ=39.697227, numObservations: 9
action 2, numVisits=20, meanQ=13.547500, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.0931456 0.972362 0.32028 0.40096 0.375518 0.447456 0.284793 0.431372 0.0129874 0.426516 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 3, numVisits=225, meanQ=93.561800, numObservations: 9
action 1, numVisits=4, meanQ=71.737500, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 615429 episodes
GETTING ACTION FROM:
action 3, numVisits=615654, meanQ=91.139983, numObservations: 9
action 1, numVisits=4, meanQ=71.737500, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.0931456 0.972362 0.32028 0.40096 0.375518 0.447456 0.284793 0.431372 0.0129874 0.426516 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 34.5525
Run # 4
Initial state: 0 0.313573 0.240592 0.146075 0.607789 0.324863 0.883718 0.412702 0.473918 0.798388 0.411639 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 411117 episodes
GETTING ACTION FROM:
action 3, numVisits=411109, meanQ=35.804477, numObservations: 9
action 1, numVisits=3, meanQ=26.300000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.313573 0.240592 0.146075 0.607789 0.324863 0.883718 0.412702 0.473918 0.798388 0.411639 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=39880, meanQ=41.488184, numObservations: 9
action 2, numVisits=10, meanQ=28.095000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 486061 episodes
GETTING ACTION FROM:
action 4, numVisits=525941, meanQ=44.162579, numObservations: 9
action 2, numVisits=10, meanQ=28.095000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.313573 0.240592 0.146075 0.607789 0.324863 0.883718 0.412702 0.473918 0.798388 0.411639 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 5
Initial state: 0 0.893797 0.555836 0.461578 0.87685 0.0924205 0.331794 0.438726 0.334914 0.783883 0.970233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 410959 episodes
GETTING ACTION FROM:
action 2, numVisits=410943, meanQ=36.392352, numObservations: 9
action 1, numVisits=7, meanQ=10.421786, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.893797 0.555836 0.461578 0.87685 0.0924205 0.331794 0.438726 0.334914 0.783883 0.970233 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 6
Initial state: 0 0.312273 0.122545 0.088987 0.655437 0.692621 0.922762 0.432689 0.439259 0.849912 0.703932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 358786 episodes
GETTING ACTION FROM:
action 1, numVisits=358778, meanQ=37.236374, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.312273 0.122545 0.088987 0.655437 0.692621 0.922762 0.432689 0.439259 0.849912 0.703932 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=26485, meanQ=57.159057, numObservations: 243
action 0, numVisits=17, meanQ=-2.285000, numObservations: 15
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 128329 episodes
GETTING ACTION FROM:
action -1, numVisits=154814, meanQ=46.300846, numObservations: 243
action 0, numVisits=17, meanQ=-2.285000, numObservations: 15
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: -1
Next state: 0 0.312273 0.122545 0.088987 0.655437 0.692621 0.922762 0.432689 0.439259 0.849912 0.703932 w: 1
Observation: 0 1 0 1 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=2511, meanQ=87.406720, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 580090 episodes
GETTING ACTION FROM:
action 4, numVisits=582601, meanQ=84.191747, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.312273 0.122545 0.088987 0.655437 0.692621 0.922762 0.432689 0.439259 0.849912 0.703932 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 7
Initial state: 0 0.558309 0.0173947 0.380122 0.339761 0.453224 0.827243 0.430125 0.826413 0.617461 0.717693 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 435515 episodes
GETTING ACTION FROM:
action 3, numVisits=435505, meanQ=35.883820, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.558309 0.0173947 0.380122 0.339761 0.453224 0.827243 0.430125 0.826413 0.617461 0.717693 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 8
Initial state: 0 0.0720858 0.21167 0.37957 0.408797 0.952803 0.443648 0.596524 0.680943 0.543293 0.490169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 404879 episodes
GETTING ACTION FROM:
action 2, numVisits=404835, meanQ=35.390051, numObservations: 9
action 1, numVisits=32, meanQ=29.553438, numObservations: 9
action 3, numVisits=6, meanQ=29.316667, numObservations: 4
action 4, numVisits=3, meanQ=25.650833, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0720858 0.21167 0.37957 0.408797 0.952803 0.443648 0.596524 0.680943 0.543293 0.490169 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 9
Initial state: 0 0.318282 0.594442 0.974556 0.334404 0.764685 0.199826 0.399155 0.370155 0.290831 0.00877125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 427609 episodes
GETTING ACTION FROM:
action 2, numVisits=427595, meanQ=35.869640, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=9, meanQ=-2.005556, numObservations: 6
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.318282 0.594442 0.974556 0.334404 0.764685 0.199826 0.399155 0.370155 0.290831 0.00877125 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 10
Initial state: 0 0.427305 0.342734 0.778815 0.928389 0.66047 0.612691 0.956357 0.835812 0.301717 0.146303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 438983 episodes
GETTING ACTION FROM:
action 3, numVisits=438972, meanQ=36.244283, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.427305 0.342734 0.778815 0.928389 0.66047 0.612691 0.956357 0.835812 0.301717 0.146303 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 11
Initial state: 0 0.399677 0.459518 0.413334 0.849916 0.438732 0.271701 0.57663 0.916574 0.536025 0.107245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 426437 episodes
GETTING ACTION FROM:
action 3, numVisits=426398, meanQ=35.693863, numObservations: 9
action 5, numVisits=16, meanQ=33.581406, numObservations: 7
action 4, numVisits=17, meanQ=26.997059, numObservations: 7
action 2, numVisits=3, meanQ=26.300000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 2 0.399677 0.459518 0.413334 0.849916 0.438732 0.271701 0.57663 0.916574 0.536025 0.107245 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 12
Initial state: 0 0.592665 0.20124 0.469465 0.335242 0.903302 0.528774 0.718234 0.760972 0.32878 0.998068 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 428888 episodes
GETTING ACTION FROM:
action 3, numVisits=428867, meanQ=35.359501, numObservations: 9
action 1, numVisits=14, meanQ=29.593036, numObservations: 6
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.592665 0.20124 0.469465 0.335242 0.903302 0.528774 0.718234 0.760972 0.32878 0.998068 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 13
Initial state: 0 0.765968 0.58375 0.440808 0.829248 0.41426 0.449347 0.12946 0.274538 0.948633 0.363858 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 391015 episodes
GETTING ACTION FROM:
action 4, numVisits=391008, meanQ=36.030058, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.765968 0.58375 0.440808 0.829248 0.41426 0.449347 0.12946 0.274538 0.948633 0.363858 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=14372, meanQ=39.196809, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 520022 episodes
GETTING ACTION FROM:
action 3, numVisits=534394, meanQ=44.600271, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.765968 0.58375 0.440808 0.829248 0.41426 0.449347 0.12946 0.274538 0.948633 0.363858 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 14
Initial state: 0 0.822886 0.866709 0.499659 0.831869 0.416514 0.366818 0.931301 0.237048 0.65998 0.219424 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 398906 episodes
GETTING ACTION FROM:
action 1, numVisits=398897, meanQ=36.924665, numObservations: 9
action 2, numVisits=4, meanQ=21.737500, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.822886 0.866709 0.499659 0.831869 0.416514 0.366818 0.931301 0.237048 0.65998 0.219424 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 15
Initial state: 0 0.117935 0.0633524 0.751083 0.209214 0.5433 0.631534 0.408636 0.388677 0.728976 0.055425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 118420 episodes
GETTING ACTION FROM:
action 0, numVisits=118375, meanQ=61.417508, numObservations: 243
action 4, numVisits=25, meanQ=-0.787600, numObservations: 7
action -1, numVisits=10, meanQ=-1.244750, numObservations: 9
action 5, numVisits=5, meanQ=-2.810000, numObservations: 5
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.117935 0.0633524 0.751083 0.209214 0.5433 0.631534 0.408636 0.388677 0.728976 0.055425 w: 1
Observation: 0 0 1 0 1 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=376, meanQ=61.925819, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 506318 episodes
GETTING ACTION FROM:
action 3, numVisits=506694, meanQ=63.922716, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.117935 0.0633524 0.751083 0.209214 0.5433 0.631534 0.408636 0.388677 0.728976 0.055425 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 16
Initial state: 0 0.378409 0.472473 0.982338 0.0199608 0.16382 0.139662 0.184445 0.585895 0.767708 0.0697187 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 437381 episodes
GETTING ACTION FROM:
action 2, numVisits=437368, meanQ=36.174557, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action -1, numVisits=2, meanQ=-2.023750, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.378409 0.472473 0.982338 0.0199608 0.16382 0.139662 0.184445 0.585895 0.767708 0.0697187 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 17
Initial state: 0 0.20266 0.809068 0.340304 0.0728666 0.491076 0.875807 0.413816 0.348466 0.569249 0.770332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 400998 episodes
GETTING ACTION FROM:
action 4, numVisits=400988, meanQ=36.835858, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.20266 0.809068 0.340304 0.0728666 0.491076 0.875807 0.413816 0.348466 0.569249 0.770332 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 18
Initial state: 0 0.548328 0.0625173 0.470015 0.338907 0.883404 0.206844 0.449086 0.664394 0.266148 0.314884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 350338 episodes
GETTING ACTION FROM:
action 2, numVisits=350328, meanQ=36.857065, numObservations: 9
action 5, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.548328 0.0625173 0.470015 0.338907 0.883404 0.206844 0.449086 0.664394 0.266148 0.314884 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 19
Initial state: 0 0.587538 0.414076 0.403784 0.391927 0.685666 0.441729 0.727974 0.335691 0.757597 0.425897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 419191 episodes
GETTING ACTION FROM:
action 3, numVisits=419174, meanQ=36.542300, numObservations: 9
action 4, numVisits=10, meanQ=5.690000, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.587538 0.414076 0.403784 0.391927 0.685666 0.441729 0.727974 0.335691 0.757597 0.425897 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 20
Initial state: 0 0.380018 0.720761 0.42614 0.386685 0.202984 0.39146 0.604963 0.25908 0.129435 0.780807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 358217 episodes
GETTING ACTION FROM:
action 4, numVisits=358202, meanQ=37.390947, numObservations: 9
action 2, numVisits=10, meanQ=17.190000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.380018 0.720761 0.42614 0.386685 0.202984 0.39146 0.604963 0.25908 0.129435 0.780807 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 21
Initial state: 0 0.896183 0.391147 0.396553 0.335116 0.261688 0.84955 0.837508 0.30076 0.284117 0.865165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 345710 episodes
GETTING ACTION FROM:
action 5, numVisits=345703, meanQ=36.833750, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 0 0.896183 0.391147 0.396553 0.335116 0.261688 0.84955 0.837508 0.30076 0.284117 0.865165 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32913, meanQ=42.962128, numObservations: 9
action 4, numVisits=20, meanQ=32.117625, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 422466 episodes
GETTING ACTION FROM:
action 1, numVisits=455379, meanQ=45.417802, numObservations: 9
action 4, numVisits=20, meanQ=32.117625, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.896183 0.391147 0.396553 0.335116 0.261688 0.84955 0.837508 0.30076 0.284117 0.865165 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 22
Initial state: 0 0.402348 0.332793 0.740406 0.81518 0.888919 0.843811 0.278918 0.53265 0.247625 0.19533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 428351 episodes
GETTING ACTION FROM:
action 4, numVisits=428278, meanQ=36.039914, numObservations: 9
action 1, numVisits=64, meanQ=19.509414, numObservations: 9
action 3, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.402348 0.332793 0.740406 0.81518 0.888919 0.843811 0.278918 0.53265 0.247625 0.19533 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=41148, meanQ=40.426700, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 496935 episodes
GETTING ACTION FROM:
action 3, numVisits=538083, meanQ=44.510491, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.402348 0.332793 0.740406 0.81518 0.888919 0.843811 0.278918 0.53265 0.247625 0.19533 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 23
Initial state: 0 0.99575 0.222733 0.705987 0.0900581 0.27503 0.815906 0.438776 0.342813 0.215507 0.733725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 346019 episodes
GETTING ACTION FROM:
action 4, numVisits=346010, meanQ=38.512891, numObservations: 9
action 1, numVisits=3, meanQ=26.300000, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.99575 0.222733 0.705987 0.0900581 0.27503 0.815906 0.438776 0.342813 0.215507 0.733725 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 24
Initial state: 0 0.325403 0.858197 0.146473 0.468265 0.0403922 0.413208 0.455671 0.362636 0.448376 0.212714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 428831 episodes
GETTING ACTION FROM:
action 1, numVisits=428817, meanQ=35.742485, numObservations: 9
action 5, numVisits=9, meanQ=8.100000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.325403 0.858197 0.146473 0.468265 0.0403922 0.413208 0.455671 0.362636 0.448376 0.212714 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=41755, meanQ=42.595010, numObservations: 9
action 1, numVisits=7, meanQ=33.686429, numObservations: 2
action 5, numVisits=6, meanQ=29.316667, numObservations: 5
action 4, numVisits=6, meanQ=27.567083, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 478389 episodes
GETTING ACTION FROM:
action 2, numVisits=520144, meanQ=51.518478, numObservations: 9
action 1, numVisits=7, meanQ=33.686429, numObservations: 2
action 5, numVisits=6, meanQ=29.316667, numObservations: 5
action 4, numVisits=6, meanQ=27.567083, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 2 0.325403 0.858197 0.146473 0.468265 0.0403922 0.413208 0.455671 0.362636 0.448376 0.212714 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 25
Initial state: 0 0.884044 0.668325 0.114837 0.74145 0.390766 0.333202 0.225542 0.348146 0.771325 0.378473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 405347 episodes
GETTING ACTION FROM:
action 5, numVisits=405335, meanQ=36.062548, numObservations: 9
action 2, numVisits=7, meanQ=23.692857, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.884044 0.668325 0.114837 0.74145 0.390766 0.333202 0.225542 0.348146 0.771325 0.378473 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 26
Initial state: 0 0.236516 0.468039 0.649454 0.553545 0.436245 0.386986 0.0949941 0.902326 0.718564 0.662844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 393819 episodes
GETTING ACTION FROM:
action 5, numVisits=393813, meanQ=37.479456, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.236516 0.468039 0.649454 0.553545 0.436245 0.386986 0.0949941 0.902326 0.718564 0.662844 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 27
Initial state: 0 0.344998 0.984826 0.436778 0.463561 0.529352 0.956068 0.158853 0.260746 0.455312 0.595948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 402333 episodes
GETTING ACTION FROM:
action 2, numVisits=402321, meanQ=37.392073, numObservations: 9
action 3, numVisits=5, meanQ=15.380000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.016667, numObservations: 2
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.344998 0.984826 0.436778 0.463561 0.529352 0.956068 0.158853 0.260746 0.455312 0.595948 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 28
Initial state: 0 0.468534 0.251183 0.0164576 0.990569 0.392546 0.248372 0.446607 0.421467 0.40658 0.638274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 410171 episodes
GETTING ACTION FROM:
action 2, numVisits=410129, meanQ=36.426516, numObservations: 9
action 3, numVisits=20, meanQ=20.042750, numObservations: 9
action 5, numVisits=18, meanQ=17.989167, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.468534 0.251183 0.0164576 0.990569 0.392546 0.248372 0.446607 0.421467 0.40658 0.638274 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=39636, meanQ=42.895054, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 452845 episodes
GETTING ACTION FROM:
action 5, numVisits=492481, meanQ=49.892022, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.468534 0.251183 0.0164576 0.990569 0.392546 0.248372 0.446607 0.421467 0.40658 0.638274 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 29
Initial state: 0 0.358046 0.00407424 0.908984 0.163397 0.155043 0.266691 0.403293 0.401454 0.221258 0.510261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 360400 episodes
GETTING ACTION FROM:
action 2, numVisits=360392, meanQ=36.968159, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.358046 0.00407424 0.908984 0.163397 0.155043 0.266691 0.403293 0.401454 0.221258 0.510261 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=5372, meanQ=44.137615, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 601759 episodes
GETTING ACTION FROM:
action 4, numVisits=607131, meanQ=20.003706, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.358046 0.00407424 0.908984 0.163397 0.155043 0.266691 0.403293 0.401454 0.221258 0.510261 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 30
Initial state: 0 0.482144 0.77377 0.170222 0.160689 0.445887 0.331157 0.103397 0.02595 0.0235893 0.57897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 398901 episodes
GETTING ACTION FROM:
action 2, numVisits=398855, meanQ=36.227125, numObservations: 9
action 3, numVisits=40, meanQ=15.166625, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.482144 0.77377 0.170222 0.160689 0.445887 0.331157 0.103397 0.02595 0.0235893 0.57897 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=29435, meanQ=40.106873, numObservations: 9
action 3, numVisits=16, meanQ=32.450156, numObservations: 9
action 1, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=5, meanQ=15.380000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 488460 episodes
GETTING ACTION FROM:
action 1, numVisits=470112, meanQ=42.468155, numObservations: 9
action 4, numVisits=47786, meanQ=36.091431, numObservations: 9
action 3, numVisits=16, meanQ=32.450156, numObservations: 9
action 5, numVisits=5, meanQ=15.380000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.482144 0.77377 0.170222 0.160689 0.445887 0.331157 0.103397 0.02595 0.0235893 0.57897 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 31
Initial state: 0 0.453317 0.335938 0.482604 0.936783 0.534838 0.139309 0.0569236 0.437899 0.149945 0.635079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 413354 episodes
GETTING ACTION FROM:
action 2, numVisits=413347, meanQ=36.026973, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.453317 0.335938 0.482604 0.936783 0.534838 0.139309 0.0569236 0.437899 0.149945 0.635079 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 32
Initial state: 0 0.0108317 0.412327 0.500517 0.845443 0.134268 0.477 0.128765 0.791244 0.395911 0.439018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 376200 episodes
GETTING ACTION FROM:
action 1, numVisits=376190, meanQ=36.117699, numObservations: 9
action 5, numVisits=4, meanQ=21.737500, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.0108317 0.412327 0.500517 0.845443 0.134268 0.477 0.128765 0.791244 0.395911 0.439018 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 33
Initial state: 0 0.473476 0.449602 0.899533 0.953732 0.731519 0.862609 0.469503 0.138966 0.757112 0.572111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 412881 episodes
GETTING ACTION FROM:
action 1, numVisits=412864, meanQ=36.131588, numObservations: 9
action 3, numVisits=7, meanQ=26.278571, numObservations: 4
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.473476 0.449602 0.899533 0.953732 0.731519 0.862609 0.469503 0.138966 0.757112 0.572111 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 34
Initial state: 0 0.662264 0.594509 0.445633 0.35845 0.408354 0.756369 0.906536 0.332763 0.283202 0.73196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 351772 episodes
GETTING ACTION FROM:
action 2, numVisits=351761, meanQ=37.397911, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.662264 0.594509 0.445633 0.35845 0.408354 0.756369 0.906536 0.332763 0.283202 0.73196 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 35
Initial state: 0 0.276859 0.64269 0.457542 0.424503 0.223597 0.0242769 0.47656 0.17457 0.885635 0.548794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 397196 episodes
GETTING ACTION FROM:
action 5, numVisits=397177, meanQ=36.021955, numObservations: 9
action 3, numVisits=10, meanQ=28.095000, numObservations: 4
action 2, numVisits=5, meanQ=15.380000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.276859 0.64269 0.457542 0.424503 0.223597 0.0242769 0.47656 0.17457 0.885635 0.548794 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 36
Initial state: 0 0.697344 0.357767 0.376388 0.447832 0.0517271 0.0125746 0.12346 0.432434 0.0757665 0.0413687 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 421121 episodes
GETTING ACTION FROM:
action 3, numVisits=421106, meanQ=35.095363, numObservations: 9
action 4, numVisits=10, meanQ=16.995250, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.697344 0.357767 0.376388 0.447832 0.0517271 0.0125746 0.12346 0.432434 0.0757665 0.0413687 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=40975, meanQ=40.482760, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 497085 episodes
GETTING ACTION FROM:
action 1, numVisits=538060, meanQ=48.304076, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.697344 0.357767 0.376388 0.447832 0.0517271 0.0125746 0.12346 0.432434 0.0757665 0.0413687 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 37
Initial state: 0 0.384474 0.43684 0.182688 0.66379 0.521912 0.439317 0.513452 0.466456 0.891052 0.474756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 119279 episodes
GETTING ACTION FROM:
action 0, numVisits=119254, meanQ=60.424785, numObservations: 243
action -1, numVisits=16, meanQ=-1.050000, numObservations: 16
action 1, numVisits=3, meanQ=-4.016667, numObservations: 2
action 4, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.384474 0.43684 0.182688 0.66379 0.521912 0.439317 0.513452 0.466456 0.891052 0.474756 w: 1
Observation: 0 0 2 0 3 0 2 0 2 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=177, meanQ=39.089477, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 337342 episodes
GETTING ACTION FROM:
action 5, numVisits=337519, meanQ=40.258437, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.384474 0.43684 0.182688 0.66379 0.521912 0.439317 0.513452 0.466456 0.891052 0.474756 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 38
Initial state: 0 0.715483 0.860318 0.483895 0.107751 0.0131948 0.702794 0.459556 0.335133 0.603782 0.740599 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 424225 episodes
GETTING ACTION FROM:
action 2, numVisits=424211, meanQ=36.008900, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 5, numVisits=5, meanQ=-2.810000, numObservations: 5
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 2 0.715483 0.860318 0.483895 0.107751 0.0131948 0.702794 0.459556 0.335133 0.603782 0.740599 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 39
Initial state: 0 0.397966 0.673867 0.419835 0.383481 0.317468 0.654225 0.96353 0.067544 0.208048 0.754809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 365765 episodes
GETTING ACTION FROM:
action 2, numVisits=365756, meanQ=37.472982, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.397966 0.673867 0.419835 0.383481 0.317468 0.654225 0.96353 0.067544 0.208048 0.754809 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 40
Initial state: 0 0.144299 0.063484 0.449322 0.387261 0.879233 0.0440018 0.498765 0.668211 0.829027 0.0532337 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 416423 episodes
GETTING ACTION FROM:
action 4, numVisits=416413, meanQ=36.607581, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.144299 0.063484 0.449322 0.387261 0.879233 0.0440018 0.498765 0.668211 0.829027 0.0532337 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.435801 0.449314 0.509923 0.80035 0.461309 0.968924 0.505313 0.0544643 0.411905 0.208685 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 434410 episodes
GETTING ACTION FROM:
action 4, numVisits=434396, meanQ=36.132001, numObservations: 9
action 5, numVisits=5, meanQ=13.280500, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 0 0.435801 0.449314 0.509923 0.80035 0.461309 0.968924 0.505313 0.0544643 0.411905 0.208685 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=6521, meanQ=40.428160, numObservations: 9
action 2, numVisits=9, meanQ=18.205556, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 577372 episodes
GETTING ACTION FROM:
action 5, numVisits=583892, meanQ=17.422676, numObservations: 9
action 2, numVisits=10, meanQ=6.285000, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.435801 0.449314 0.509923 0.80035 0.461309 0.968924 0.505313 0.0544643 0.411905 0.208685 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 42
Initial state: 0 0.738805 0.504586 0.395978 0.3324 0.982094 0.76111 0.183308 0.855111 0.0399191 0.0996905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 419058 episodes
GETTING ACTION FROM:
action 4, numVisits=419048, meanQ=35.456946, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.738805 0.504586 0.395978 0.3324 0.982094 0.76111 0.183308 0.855111 0.0399191 0.0996905 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=40416, meanQ=41.133988, numObservations: 9
action 5, numVisits=7, meanQ=26.278571, numObservations: 6
action 4, numVisits=6, meanQ=24.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 495794 episodes
GETTING ACTION FROM:
action 1, numVisits=536210, meanQ=45.979577, numObservations: 9
action 5, numVisits=7, meanQ=26.278571, numObservations: 6
action 4, numVisits=6, meanQ=24.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.738805 0.504586 0.395978 0.3324 0.982094 0.76111 0.183308 0.855111 0.0399191 0.0996905 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 43
Initial state: 0 0.501687 0.726341 0.0242283 0.278688 0.413394 0.464845 0.120834 0.253441 0.0912222 0.799254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 428663 episodes
GETTING ACTION FROM:
action 1, numVisits=428613, meanQ=35.680198, numObservations: 9
action 5, numVisits=44, meanQ=19.710455, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.501687 0.726341 0.0242283 0.278688 0.413394 0.464845 0.120834 0.253441 0.0912222 0.799254 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 44
Initial state: 0 0.32959 0.646052 0.990138 0.112625 0.168191 0.970169 0.453335 0.208834 0.402608 0.429671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 343718 episodes
GETTING ACTION FROM:
action 5, numVisits=343699, meanQ=38.585516, numObservations: 9
action 1, numVisits=10, meanQ=26.285000, numObservations: 6
action 2, numVisits=4, meanQ=21.737500, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.32959 0.646052 0.990138 0.112625 0.168191 0.970169 0.453335 0.208834 0.402608 0.429671 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 45
Initial state: 0 0.438639 0.45264 0.665855 0.182272 0.605258 0.408079 0.889168 0.110079 0.503523 0.766436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 384453 episodes
GETTING ACTION FROM:
action 1, numVisits=384447, meanQ=36.628786, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.438639 0.45264 0.665855 0.182272 0.605258 0.408079 0.889168 0.110079 0.503523 0.766436 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6435, meanQ=72.240172, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action 3, numVisits=11, meanQ=41.359091, numObservations: 5
action 5, numVisits=5, meanQ=37.190000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 584794 episodes
GETTING ACTION FROM:
action 1, numVisits=591229, meanQ=89.414769, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action 3, numVisits=11, meanQ=41.359091, numObservations: 5
action 5, numVisits=5, meanQ=37.190000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.438639 0.45264 0.665855 0.182272 0.605258 0.408079 0.889168 0.110079 0.503523 0.766436 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 46
Initial state: 0 0.266074 0.557226 0.386469 0.14282 0.435391 0.38522 0.711123 0.497975 0.0377284 0.657735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 339385 episodes
GETTING ACTION FROM:
action 5, numVisits=339377, meanQ=37.323759, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.266074 0.557226 0.386469 0.14282 0.435391 0.38522 0.711123 0.497975 0.0377284 0.657735 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 47
Initial state: 0 0.387931 0.187167 0.788517 0.619071 0.374674 0.426772 0.466006 0.314726 0.943048 0.779609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 116593 episodes
GETTING ACTION FROM:
action 0, numVisits=116533, meanQ=60.227664, numObservations: 243
action -1, numVisits=49, meanQ=-1.322398, numObservations: 42
action 5, numVisits=5, meanQ=-2.810000, numObservations: 4
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.387931 0.187167 0.788517 0.619071 0.374674 0.426772 0.466006 0.314726 0.943048 0.779609 w: 1
Observation: 0 0 1 0 3 0 2 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=584, meanQ=67.524522, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=4, meanQ=-5.525000, numObservations: 4
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 496025 episodes
GETTING ACTION FROM:
action 2, numVisits=496609, meanQ=78.256689, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=4, meanQ=-5.525000, numObservations: 4
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.387931 0.187167 0.788517 0.619071 0.374674 0.426772 0.466006 0.314726 0.943048 0.779609 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 48
Initial state: 0 0.0233895 0.50174 0.113769 0.33695 0.394007 0.334513 0.996828 0.703066 0.0470377 0.446183 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 119828 episodes
GETTING ACTION FROM:
action 0, numVisits=119812, meanQ=60.245554, numObservations: 243
action -1, numVisits=11, meanQ=-1.050000, numObservations: 11
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0233895 0.50174 0.113769 0.33695 0.394007 0.334513 0.996828 0.703066 0.0470377 0.446183 w: 1
Observation: 0 0 3 0 2 0 2 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=442, meanQ=64.278510, numObservations: 9
action 2, numVisits=4, meanQ=49.000000, numObservations: 4
action 3, numVisits=4, meanQ=21.737500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 442159 episodes
GETTING ACTION FROM:
action 4, numVisits=442601, meanQ=62.486302, numObservations: 9
action 2, numVisits=4, meanQ=49.000000, numObservations: 4
action 3, numVisits=4, meanQ=21.737500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.0233895 0.50174 0.113769 0.33695 0.394007 0.334513 0.996828 0.703066 0.0470377 0.446183 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 49
Initial state: 0 0.0931424 0.17622 0.935224 0.93239 0.0352392 0.509564 0.374901 0.886401 0.44967 0.318638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 359895 episodes
GETTING ACTION FROM:
action 3, numVisits=359799, meanQ=37.448514, numObservations: 9
action 2, numVisits=90, meanQ=34.394507, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.0931424 0.17622 0.935224 0.93239 0.0352392 0.509564 0.374901 0.886401 0.44967 0.318638 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=34778, meanQ=40.674828, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 457187 episodes
GETTING ACTION FROM:
action 4, numVisits=491965, meanQ=45.205837, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0931424 0.17622 0.935224 0.93239 0.0352392 0.509564 0.374901 0.886401 0.44967 0.318638 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 50
Initial state: 0 0.510726 0.387768 0.0487168 0.296501 0.932143 0.962008 0.451056 0.353815 0.0803373 0.765265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 425069 episodes
GETTING ACTION FROM:
action 1, numVisits=425063, meanQ=36.064915, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.510726 0.387768 0.0487168 0.296501 0.932143 0.962008 0.451056 0.353815 0.0803373 0.765265 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
[32m ProblemEnvironment.hpp 351: Done.[39m
