Run # 1
Initial state: 0 0.509837 0.884338 0.20152 0.598051 0.160556 0.0136722 0.0847272 0.169328 0.566912 0.368077 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 380824 episodes
GETTING ACTION FROM:
action 3, numVisits=380804, meanQ=41.106154, numObservations: 9
action 1, numVisits=15, meanQ=34.583667, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 0 0.509837 0.884338 0.20152 0.598051 0.160556 0.0136722 0.0847272 0.169328 0.566912 0.368077 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26393, meanQ=44.974603, numObservations: 9
action 4, numVisits=4, meanQ=21.737500, numObservations: 4
action 1, numVisits=5, meanQ=15.380000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 485886 episodes
GETTING ACTION FROM:
action 2, numVisits=512279, meanQ=43.579428, numObservations: 9
action 4, numVisits=4, meanQ=21.737500, numObservations: 4
action 1, numVisits=5, meanQ=15.380000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.509837 0.884338 0.20152 0.598051 0.160556 0.0136722 0.0847272 0.169328 0.566912 0.368077 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=44754, meanQ=40.270229, numObservations: 9
action 1, numVisits=9, meanQ=17.989167, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 473972 episodes
GETTING ACTION FROM:
action 5, numVisits=518726, meanQ=43.131916, numObservations: 9
action 1, numVisits=9, meanQ=17.989167, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.509837 0.884338 0.20152 0.598051 0.160556 0.0136722 0.0847272 0.169328 0.566912 0.368077 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 2
Initial state: 0 0.856315 0.86119 0.128423 0.652313 0.347206 0.173417 0.537354 0.355438 0.974096 0.496497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 431733 episodes
GETTING ACTION FROM:
action 5, numVisits=431702, meanQ=39.841559, numObservations: 9
action 3, numVisits=26, meanQ=34.609808, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.856315 0.86119 0.128423 0.652313 0.347206 0.173417 0.537354 0.355438 0.974096 0.496497 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 3
Initial state: 0 0.404718 0.316685 0.609677 0.413391 0.180133 0.961515 0.542701 0.843446 0.0733407 0.162359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 428902 episodes
GETTING ACTION FROM:
action 3, numVisits=428890, meanQ=40.505498, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action 2, numVisits=5, meanQ=15.380000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.404718 0.316685 0.609677 0.413391 0.180133 0.961515 0.542701 0.843446 0.0733407 0.162359 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=49604, meanQ=45.588885, numObservations: 9
action 5, numVisits=6, meanQ=29.316667, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 507812 episodes
GETTING ACTION FROM:
action 1, numVisits=557416, meanQ=50.942557, numObservations: 9
action 5, numVisits=6, meanQ=29.316667, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.404718 0.316685 0.609677 0.413391 0.180133 0.961515 0.542701 0.843446 0.0733407 0.162359 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 4
Initial state: 0 0.461975 0.116141 0.00107889 0.585971 0.904152 0.349212 0.873865 0.623676 0.400892 0.375766 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 119461 episodes
GETTING ACTION FROM:
action 0, numVisits=119426, meanQ=64.025152, numObservations: 243
action -1, numVisits=28, meanQ=-1.424911, numObservations: 27
action 1, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.461975 0.116141 0.00107889 0.585971 0.904152 0.349212 0.873865 0.623676 0.400892 0.375766 w: 1
Observation: 0 0 1 0 3 0 2 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=469, meanQ=64.470306, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 510941 episodes
GETTING ACTION FROM:
action 3, numVisits=511410, meanQ=56.487393, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.461975 0.116141 0.00107889 0.585971 0.904152 0.349212 0.873865 0.623676 0.400892 0.375766 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 5
Initial state: 0 0.879702 0.625504 0.281388 0.127253 0.486775 0.382522 0.247785 0.542674 0.506995 0.520213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 433048 episodes
GETTING ACTION FROM:
action 4, numVisits=433038, meanQ=40.425705, numObservations: 9
action 5, numVisits=3, meanQ=26.300000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.879702 0.625504 0.281388 0.127253 0.486775 0.382522 0.247785 0.542674 0.506995 0.520213 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 6
Initial state: 0 0.853161 0.236692 0.0857598 0.433129 0.306934 0.295304 0.438677 0.389668 0.925943 0.904537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 407662 episodes
GETTING ACTION FROM:
action 3, numVisits=407626, meanQ=40.059033, numObservations: 9
action 5, numVisits=18, meanQ=30.744583, numObservations: 7
action 1, numVisits=12, meanQ=29.316667, numObservations: 8
action 4, numVisits=3, meanQ=25.650833, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.853161 0.236692 0.0857598 0.433129 0.306934 0.295304 0.438677 0.389668 0.925943 0.904537 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=11276, meanQ=43.691938, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 502636 episodes
GETTING ACTION FROM:
action 5, numVisits=513912, meanQ=43.449998, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.853161 0.236692 0.0857598 0.433129 0.306934 0.295304 0.438677 0.389668 0.925943 0.904537 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 7
Initial state: 0 0.29079 0.25092 0.539749 0.798682 0.948493 0.351833 0.961169 0.185393 0.449943 0.356593 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 347372 episodes
GETTING ACTION FROM:
action 5, numVisits=347343, meanQ=41.539934, numObservations: 9
action 1, numVisits=19, meanQ=33.936842, numObservations: 8
action 3, numVisits=4, meanQ=20.250000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.29079 0.25092 0.539749 0.798682 0.948493 0.351833 0.961169 0.185393 0.449943 0.356593 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 8
Initial state: 0 0.500414 0.300325 0.4205 0.646457 0.520915 0.224655 0.585801 0.374118 0.0909456 0.532245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 426289 episodes
GETTING ACTION FROM:
action 2, numVisits=426278, meanQ=40.319984, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=5, meanQ=-2.810000, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 2 0.500414 0.300325 0.4205 0.646457 0.520915 0.224655 0.585801 0.374118 0.0909456 0.532245 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 9
Initial state: 0 0.469289 0.39014 0.580303 0.666593 0.741894 0.744901 0.697677 0.501133 0.77356 0.733594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 412015 episodes
GETTING ACTION FROM:
action 4, numVisits=411989, meanQ=40.812621, numObservations: 9
action 1, numVisits=19, meanQ=34.889474, numObservations: 8
action 5, numVisits=3, meanQ=32.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.469289 0.39014 0.580303 0.666593 0.741894 0.744901 0.697677 0.501133 0.77356 0.733594 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 10
Initial state: 0 0.413458 0.498253 0.498902 0.356349 0.0631506 0.11523 0.663141 0.697374 0.167349 0.0667487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 332289 episodes
GETTING ACTION FROM:
action 2, numVisits=332282, meanQ=41.955062, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.413458 0.498253 0.498902 0.356349 0.0631506 0.11523 0.663141 0.697374 0.167349 0.0667487 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 11
Initial state: 0 0.216805 0.547716 0.45367 0.360974 0.0499883 0.437799 0.365459 0.706522 0.938439 0.506697 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 289793 episodes
GETTING ACTION FROM:
action 4, numVisits=289787, meanQ=43.545938, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 0 0.216805 0.547716 0.45367 0.360974 0.0499883 0.437799 0.365459 0.706522 0.938439 0.506697 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=33435, meanQ=67.861537, numObservations: 243
action 3, numVisits=11, meanQ=-3.468182, numObservations: 7
action -1, numVisits=4, meanQ=-3.674375, numObservations: 3
action 2, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 134492 episodes
GETTING ACTION FROM:
action 0, numVisits=167927, meanQ=48.318696, numObservations: 243
action 3, numVisits=11, meanQ=-3.468182, numObservations: 7
action -1, numVisits=4, meanQ=-3.674375, numObservations: 3
action 2, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 0
Next state: 0 0.216805 0.547716 0.45367 0.360974 0.0499883 0.437799 0.365459 0.706522 0.938439 0.506697 w: 1
Observation: 0 0 3 0 2 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=4994, meanQ=70.361531, numObservations: 9
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 526506 episodes
GETTING ACTION FROM:
action 3, numVisits=531500, meanQ=66.903417, numObservations: 9
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.216805 0.547716 0.45367 0.360974 0.0499883 0.437799 0.365459 0.706522 0.938439 0.506697 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 12
Initial state: 0 0.70321 0.805844 0.436084 0.351837 0.588288 0.438046 0.874844 0.298316 0.829111 0.106882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 332951 episodes
GETTING ACTION FROM:
action 3, numVisits=332879, meanQ=41.789003, numObservations: 9
action 2, numVisits=57, meanQ=30.877368, numObservations: 9
action 5, numVisits=6, meanQ=29.316667, numObservations: 5
action 1, numVisits=6, meanQ=28.992083, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.70321 0.805844 0.436084 0.351837 0.588288 0.438046 0.874844 0.298316 0.829111 0.106882 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 13
Initial state: 0 0.24398 0.671058 0.471465 0.992097 0.710028 0.650668 0.598516 0.889452 0.554442 0.334298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 122501 episodes
GETTING ACTION FROM:
action 0, numVisits=122447, meanQ=64.688150, numObservations: 243
action -1, numVisits=49, meanQ=-3.829235, numObservations: 41
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.24398 0.671058 0.471465 0.992097 0.710028 0.650668 0.598516 0.889452 0.554442 0.334298 w: 1
Observation: 0 0 3 0 3 0 1 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1271, meanQ=87.919945, numObservations: 9
action 1, numVisits=4, meanQ=49.000000, numObservations: 3
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 561303 episodes
GETTING ACTION FROM:
action 5, numVisits=562574, meanQ=91.312860, numObservations: 9
action 1, numVisits=4, meanQ=49.000000, numObservations: 3
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.24398 0.671058 0.471465 0.992097 0.710028 0.650668 0.598516 0.889452 0.554442 0.334298 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 14
Initial state: 0 0.444056 0.30643 0.36509 0.113148 0.292463 0.501821 0.46562 0.641445 0.0322305 0.183569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 431335 episodes
GETTING ACTION FROM:
action 5, numVisits=431322, meanQ=40.396545, numObservations: 9
action 2, numVisits=4, meanQ=21.737500, numObservations: 4
action 3, numVisits=5, meanQ=15.380000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 0 0.444056 0.30643 0.36509 0.113148 0.292463 0.501821 0.46562 0.641445 0.0322305 0.183569 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11641, meanQ=43.606974, numObservations: 9
action 3, numVisits=4, meanQ=21.737500, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 527602 episodes
GETTING ACTION FROM:
action 2, numVisits=539243, meanQ=48.446969, numObservations: 9
action 3, numVisits=4, meanQ=21.737500, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.444056 0.30643 0.36509 0.113148 0.292463 0.501821 0.46562 0.641445 0.0322305 0.183569 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=23464, meanQ=55.576811, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 537547 episodes
GETTING ACTION FROM:
action 1, numVisits=561011, meanQ=48.022284, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.444056 0.30643 0.36509 0.113148 0.292463 0.501821 0.46562 0.641445 0.0322305 0.183569 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 15
Initial state: 0 0.48906 0.44706 0.832111 0.0454832 0.401109 0.415599 0.250574 0.0192775 0.465428 0.305606 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 120877 episodes
GETTING ACTION FROM:
action 0, numVisits=120843, meanQ=65.414586, numObservations: 243
action -1, numVisits=25, meanQ=-1.547800, numObservations: 23
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=5, meanQ=-21.000000, numObservations: 4
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.48906 0.44706 0.832111 0.0454832 0.401109 0.415599 0.250574 0.0192775 0.465428 0.305606 w: 1
Observation: 0 0 3 0 1 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=668, meanQ=83.445992, numObservations: 9
action 1, numVisits=2, meanQ=44.475000, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 553454 episodes
GETTING ACTION FROM:
action 5, numVisits=554122, meanQ=91.234705, numObservations: 9
action 1, numVisits=2, meanQ=44.475000, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.48906 0.44706 0.832111 0.0454832 0.401109 0.415599 0.250574 0.0192775 0.465428 0.305606 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 16
Initial state: 0 0.577714 0.855746 0.20901 0.338752 0.886153 0.539147 0.502896 0.220882 0.476864 0.349502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 434392 episodes
GETTING ACTION FROM:
action 1, numVisits=434376, meanQ=40.351538, numObservations: 9
action 5, numVisits=11, meanQ=22.981818, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.577714 0.855746 0.20901 0.338752 0.886153 0.539147 0.502896 0.220882 0.476864 0.349502 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 17
Initial state: 0 0.465949 0.388465 0.358462 0.985811 0.559491 0.27887 0.989477 0.15338 0.699075 0.368253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 429655 episodes
GETTING ACTION FROM:
action 3, numVisits=429610, meanQ=39.859080, numObservations: 9
action 1, numVisits=12, meanQ=35.525208, numObservations: 6
action 4, numVisits=29, meanQ=34.927586, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.465949 0.388465 0.358462 0.985811 0.559491 0.27887 0.989477 0.15338 0.699075 0.368253 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 18
Initial state: 0 0.440116 0.402043 0.490709 0.318465 0.380479 0.390095 0.345663 0.334651 0.748263 0.365252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 435583 episodes
GETTING ACTION FROM:
action 3, numVisits=435574, meanQ=40.424383, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=4, meanQ=-5.525000, numObservations: 4
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.440116 0.402043 0.490709 0.318465 0.380479 0.390095 0.345663 0.334651 0.748263 0.365252 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=11745, meanQ=44.332464, numObservations: 9
action 2, numVisits=17, meanQ=24.250147, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 446448 episodes
GETTING ACTION FROM:
action 5, numVisits=458193, meanQ=45.580597, numObservations: 9
action 2, numVisits=17, meanQ=24.250147, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.440116 0.402043 0.490709 0.318465 0.380479 0.390095 0.345663 0.334651 0.748263 0.365252 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 19
Initial state: 0 0.429106 0.358821 0.848711 0.282282 0.576228 0.305844 0.349589 0.00597269 0.739011 0.382434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 286758 episodes
GETTING ACTION FROM:
action 2, numVisits=286729, meanQ=43.958719, numObservations: 9
action 1, numVisits=6, meanQ=32.333333, numObservations: 5
action 4, numVisits=16, meanQ=32.085000, numObservations: 6
action 5, numVisits=4, meanQ=21.737500, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 2 0.429106 0.358821 0.848711 0.282282 0.576228 0.305844 0.349589 0.00597269 0.739011 0.382434 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 20
Initial state: 0 0.167573 0.528256 0.119896 0.657067 0.275884 0.398766 0.327349 0.883707 0.464294 0.388534 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 387657 episodes
GETTING ACTION FROM:
action 1, numVisits=387651, meanQ=40.419962, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.167573 0.528256 0.119896 0.657067 0.275884 0.398766 0.327349 0.883707 0.464294 0.388534 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=44906, meanQ=45.159048, numObservations: 9
action 4, numVisits=13, meanQ=34.676923, numObservations: 8
action 1, numVisits=5, meanQ=33.570000, numObservations: 3
action 5, numVisits=3, meanQ=25.650833, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 513188 episodes
GETTING ACTION FROM:
action 2, numVisits=558094, meanQ=51.757801, numObservations: 9
action 4, numVisits=13, meanQ=34.676923, numObservations: 8
action 1, numVisits=5, meanQ=33.570000, numObservations: 3
action 5, numVisits=3, meanQ=25.650833, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.167573 0.528256 0.119896 0.657067 0.275884 0.398766 0.327349 0.883707 0.464294 0.388534 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=37053, meanQ=54.096076, numObservations: 9
action 4, numVisits=5, meanQ=37.190000, numObservations: 5
action 1, numVisits=3, meanQ=22.800833, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 547164 episodes
GETTING ACTION FROM:
action 3, numVisits=584217, meanQ=65.108733, numObservations: 9
action 4, numVisits=5, meanQ=37.190000, numObservations: 5
action 1, numVisits=3, meanQ=22.800833, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.167573 0.528256 0.119896 0.657067 0.275884 0.398766 0.327349 0.883707 0.464294 0.388534 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 21
Initial state: 0 0.684589 0.419417 0.901011 0.281656 0.341014 0.258688 0.476606 0.296701 0.831593 0.809603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 432268 episodes
GETTING ACTION FROM:
action 1, numVisits=432256, meanQ=40.534134, numObservations: 9
action 5, numVisits=5, meanQ=19.000000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.684589 0.419417 0.901011 0.281656 0.341014 0.258688 0.476606 0.296701 0.831593 0.809603 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 22
Initial state: 0 0.497844 0.296848 0.856414 0.741771 0.722441 0.270595 0.0792265 0.506315 0.466985 0.672079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 415888 episodes
GETTING ACTION FROM:
action 3, numVisits=415873, meanQ=40.442463, numObservations: 9
action 4, numVisits=8, meanQ=33.106250, numObservations: 5
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.497844 0.296848 0.856414 0.741771 0.722441 0.270595 0.0792265 0.506315 0.466985 0.672079 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5496, meanQ=43.519795, numObservations: 9
action 4, numVisits=5, meanQ=15.380000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 584544 episodes
GETTING ACTION FROM:
action 1, numVisits=590040, meanQ=20.068017, numObservations: 9
action 4, numVisits=5, meanQ=15.380000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.497844 0.296848 0.856414 0.741771 0.722441 0.270595 0.0792265 0.506315 0.466985 0.672079 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 23
Initial state: 0 0.431071 0.810368 0.301631 0.0607135 0.214972 0.963891 0.421061 0.304216 0.640948 0.914108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 431427 episodes
GETTING ACTION FROM:
action 1, numVisits=431379, meanQ=41.058251, numObservations: 9
action 2, numVisits=36, meanQ=25.626458, numObservations: 9
action 4, numVisits=7, meanQ=25.428571, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.431071 0.810368 0.301631 0.0607135 0.214972 0.963891 0.421061 0.304216 0.640948 0.914108 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 24
Initial state: 0 0.406947 0.296065 0.243056 0.779837 0.56224 0.950012 0.199213 0.0927238 0.390865 0.451418 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 331975 episodes
GETTING ACTION FROM:
action 3, numVisits=331947, meanQ=41.854579, numObservations: 9
action 2, numVisits=23, meanQ=31.358804, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.406947 0.296065 0.243056 0.779837 0.56224 0.950012 0.199213 0.0927238 0.390865 0.451418 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 25
Initial state: 0 0.936622 0.491422 0.386311 0.376253 0.308678 0.0413482 0.8139 0.552575 0.280818 0.313317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 342807 episodes
GETTING ACTION FROM:
action 2, numVisits=342800, meanQ=41.621754, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.936622 0.491422 0.386311 0.376253 0.308678 0.0413482 0.8139 0.552575 0.280818 0.313317 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5535, meanQ=78.286645, numObservations: 9
action 4, numVisits=15, meanQ=44.460000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 599862 episodes
GETTING ACTION FROM:
action 2, numVisits=605397, meanQ=85.676575, numObservations: 9
action 4, numVisits=15, meanQ=44.460000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.936622 0.491422 0.386311 0.376253 0.308678 0.0413482 0.8139 0.552575 0.280818 0.313317 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 26
Initial state: 0 0.145142 0.0244001 0.334875 0.0669399 0.00560347 0.426793 0.692832 0.495434 0.510305 0.351971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 122931 episodes
GETTING ACTION FROM:
action 0, numVisits=122892, meanQ=64.320079, numObservations: 243
action -1, numVisits=34, meanQ=-1.667500, numObservations: 32
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.145142 0.0244001 0.334875 0.0669399 0.00560347 0.426793 0.692832 0.495434 0.510305 0.351971 w: 1
Observation: 0 0 1 0 1 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=458, meanQ=57.847885, numObservations: 9
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action 5, numVisits=5, meanQ=36.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 323859 episodes
GETTING ACTION FROM:
action 3, numVisits=324317, meanQ=69.616477, numObservations: 9
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action 5, numVisits=5, meanQ=36.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.145142 0.0244001 0.334875 0.0669399 0.00560347 0.426793 0.692832 0.495434 0.510305 0.351971 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 27
Initial state: 0 0.00739613 0.0805632 0.485184 0.314038 0.928332 0.106967 0.271449 0.562704 0.0170577 0.899748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 122086 episodes
GETTING ACTION FROM:
action 0, numVisits=122075, meanQ=65.023861, numObservations: 243
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=6, meanQ=-17.200000, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.00739613 0.0805632 0.485184 0.314038 0.928332 0.106967 0.271449 0.562704 0.0170577 0.899748 w: 1
Observation: 0 0 1 0 2 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=643, meanQ=86.993676, numObservations: 9
action 5, numVisits=4, meanQ=49.000000, numObservations: 2
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 562563 episodes
GETTING ACTION FROM:
action 2, numVisits=563206, meanQ=91.881972, numObservations: 9
action 5, numVisits=4, meanQ=49.000000, numObservations: 2
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.00739613 0.0805632 0.485184 0.314038 0.928332 0.106967 0.271449 0.562704 0.0170577 0.899748 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 28
Initial state: 0 0.547952 0.320816 0.127767 0.480672 0.121714 0.42594 0.0444404 0.182251 0.738407 0.247588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 434308 episodes
GETTING ACTION FROM:
action 5, numVisits=434299, meanQ=39.893860, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=4, meanQ=-5.525000, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.547952 0.320816 0.127767 0.480672 0.121714 0.42594 0.0444404 0.182251 0.738407 0.247588 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 29
Initial state: 0 0.1689 0.471554 0.791995 0.817265 0.681644 0.413666 0.415204 0.309364 0.878311 0.687254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 420072 episodes
GETTING ACTION FROM:
action 3, numVisits=420066, meanQ=40.598892, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.1689 0.471554 0.791995 0.817265 0.681644 0.413666 0.415204 0.309364 0.878311 0.687254 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 30
Initial state: 0 0.790483 0.0626069 0.197617 0.821861 0.614988 0.484199 0.5554 0.320279 0.474055 0.00120491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 385352 episodes
GETTING ACTION FROM:
action 3, numVisits=385338, meanQ=41.002727, numObservations: 9
action 5, numVisits=9, meanQ=20.216667, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.790483 0.0626069 0.197617 0.821861 0.614988 0.484199 0.5554 0.320279 0.474055 0.00120491 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 31
Initial state: 0 0.514243 0.315234 0.288275 0.375659 0.812623 0.804041 0.180905 0.162648 0.702394 0.727174 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 429175 episodes
GETTING ACTION FROM:
action 5, numVisits=429167, meanQ=39.763551, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.514243 0.315234 0.288275 0.375659 0.812623 0.804041 0.180905 0.162648 0.702394 0.727174 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 32
Initial state: 0 0.501626 0.933783 0.150197 0.720075 0.201879 0.66242 0.173175 0.479822 0.457265 0.303716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 382871 episodes
GETTING ACTION FROM:
action 1, numVisits=382830, meanQ=40.176960, numObservations: 9
action 3, numVisits=18, meanQ=35.494444, numObservations: 7
action 5, numVisits=3, meanQ=26.300000, numObservations: 3
action 4, numVisits=12, meanQ=25.896458, numObservations: 6
action 2, numVisits=6, meanQ=14.158333, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 1
Next state: 2 0.501626 0.933783 0.150197 0.720075 0.201879 0.66242 0.173175 0.479822 0.457265 0.303716 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 33
Initial state: 0 0.406529 0.292899 0.662033 0.0432503 0.68785 0.769253 0.634274 0.900568 0.371627 0.308389 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 383952 episodes
GETTING ACTION FROM:
action 4, numVisits=383928, meanQ=42.057365, numObservations: 9
action 3, numVisits=12, meanQ=23.245833, numObservations: 6
action 2, numVisits=8, meanQ=10.368750, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.406529 0.292899 0.662033 0.0432503 0.68785 0.769253 0.634274 0.900568 0.371627 0.308389 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 34
Initial state: 0 0.512847 0.38353 0.998698 0.464941 0.690727 0.577129 0.508516 0.225953 0.507869 0.609719 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 356818 episodes
GETTING ACTION FROM:
action 2, numVisits=356744, meanQ=40.366946, numObservations: 9
action 0, numVisits=53, meanQ=-3.221557, numObservations: 47
action -1, numVisits=13, meanQ=-8.503846, numObservations: 12
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=5, meanQ=-21.000000, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.512847 0.38353 0.998698 0.464941 0.690727 0.577129 0.508516 0.225953 0.507869 0.609719 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 35
Initial state: 0 0.154177 0.0443396 0.748772 0.127903 0.537823 0.334166 0.577449 0.304336 0.736048 0.526319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 409558 episodes
GETTING ACTION FROM:
action 5, numVisits=409540, meanQ=40.401810, numObservations: 9
action 4, numVisits=3, meanQ=26.300000, numObservations: 3
action 2, numVisits=6, meanQ=14.158333, numObservations: 3
action 3, numVisits=6, meanQ=14.158333, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.154177 0.0443396 0.748772 0.127903 0.537823 0.334166 0.577449 0.304336 0.736048 0.526319 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 36
Initial state: 0 0.477289 0.468794 0.655817 0.927395 0.928481 0.463124 0.49192 0.334516 0.560053 0.39507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 420713 episodes
GETTING ACTION FROM:
action 1, numVisits=420705, meanQ=40.282545, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 2 0.477289 0.468794 0.655817 0.927395 0.928481 0.463124 0.49192 0.334516 0.560053 0.39507 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 37
Initial state: 0 0.556522 0.045404 0.425604 0.509618 0.277001 0.688062 0.405244 0.384097 0.239435 0.828031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 120745 episodes
GETTING ACTION FROM:
action -1, numVisits=120726, meanQ=52.156407, numObservations: 243
action 0, numVisits=14, meanQ=-1.189107, numObservations: 13
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.556522 0.045404 0.425604 0.509618 0.277001 0.688062 0.405244 0.384097 0.239435 0.828031 w: 1
Observation: 0 2 0 2 0 2 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=205, meanQ=42.473524, numObservations: 9
action 4, numVisits=6, meanQ=32.333333, numObservations: 2
action 3, numVisits=5, meanQ=19.000000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 517007 episodes
GETTING ACTION FROM:
action 1, numVisits=517211, meanQ=24.903916, numObservations: 9
action 3, numVisits=5, meanQ=19.000000, numObservations: 3
action 4, numVisits=7, meanQ=13.285714, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 0 0.556522 0.045404 0.425604 0.509618 0.277001 0.688062 0.405244 0.384097 0.239435 0.828031 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=32652, meanQ=76.231446, numObservations: 9
action 3, numVisits=4, meanQ=49.000000, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 583639 episodes
GETTING ACTION FROM:
action 2, numVisits=616291, meanQ=60.556959, numObservations: 9
action 3, numVisits=4, meanQ=49.000000, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.556522 0.045404 0.425604 0.509618 0.277001 0.688062 0.405244 0.384097 0.239435 0.828031 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 38
Initial state: 0 0.947588 0.834688 0.721624 0.736845 0.666536 0.89613 0.978349 0.14445 0.406812 0.320487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 412583 episodes
GETTING ACTION FROM:
action 2, numVisits=412551, meanQ=40.316615, numObservations: 9
action 5, numVisits=18, meanQ=14.158333, numObservations: 9
action 3, numVisits=8, meanQ=4.288125, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 2
Next state: 1 0.947588 0.834688 0.721624 0.736845 0.666536 0.89613 0.978349 0.14445 0.406812 0.320487 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 39
Initial state: 0 0.554509 0.131486 0.685275 0.6731 0.905143 0.0668099 0.474249 0.375063 0.0824382 0.234961 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 325289 episodes
GETTING ACTION FROM:
action 2, numVisits=325280, meanQ=41.633991, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.554509 0.131486 0.685275 0.6731 0.905143 0.0668099 0.474249 0.375063 0.0824382 0.234961 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 40
Initial state: 0 0.203516 0.0118926 0.512342 0.364782 0.268572 0.712067 0.371256 0.0366781 0.805769 0.83103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 430947 episodes
GETTING ACTION FROM:
action 3, numVisits=430928, meanQ=40.629941, numObservations: 9
action 2, numVisits=11, meanQ=32.718409, numObservations: 6
action 4, numVisits=3, meanQ=26.300000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.203516 0.0118926 0.512342 0.364782 0.268572 0.712067 0.371256 0.0366781 0.805769 0.83103 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.497314 0.36404 0.473218 0.0193665 0.109312 0.864111 0.235914 0.312487 0.991797 0.293664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 430581 episodes
GETTING ACTION FROM:
action 2, numVisits=430574, meanQ=40.208233, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.497314 0.36404 0.473218 0.0193665 0.109312 0.864111 0.235914 0.312487 0.991797 0.293664 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 42
Initial state: 0 0.819073 0.770174 0.542781 0.314586 0.0213676 0.295649 0.353602 0.0105051 0.180095 0.267573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 412442 episodes
GETTING ACTION FROM:
action 1, numVisits=412434, meanQ=41.020203, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.819073 0.770174 0.542781 0.314586 0.0213676 0.295649 0.353602 0.0105051 0.180095 0.267573 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 43
Initial state: 0 0.947132 0.257732 0.310432 0.867042 0.454493 0.130514 0.406329 0.373194 0.053048 0.573142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 416854 episodes
GETTING ACTION FROM:
action 2, numVisits=416846, meanQ=40.873035, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.947132 0.257732 0.310432 0.867042 0.454493 0.130514 0.406329 0.373194 0.053048 0.573142 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=48395, meanQ=49.375383, numObservations: 9
action 4, numVisits=16, meanQ=44.487656, numObservations: 7
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 393817 episodes
GETTING ACTION FROM:
action 2, numVisits=442212, meanQ=64.400127, numObservations: 9
action 4, numVisits=16, meanQ=44.487656, numObservations: 7
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 0 0.947132 0.257732 0.310432 0.867042 0.454493 0.130514 0.406329 0.373194 0.053048 0.573142 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=157542, meanQ=44.378447, numObservations: 9
action 3, numVisits=57, meanQ=33.943947, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 505963 episodes
GETTING ACTION FROM:
action 5, numVisits=663505, meanQ=52.831502, numObservations: 9
action 3, numVisits=57, meanQ=33.943947, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.947132 0.257732 0.310432 0.867042 0.454493 0.130514 0.406329 0.373194 0.053048 0.573142 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 44
Initial state: 0 0.00229212 0.876124 0.0405652 0.175353 0.649464 0.625375 0.522828 0.29724 0.905251 0.689609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 118582 episodes
GETTING ACTION FROM:
action -1, numVisits=118569, meanQ=50.013390, numObservations: 243
action 0, numVisits=6, meanQ=-1.050000, numObservations: 6
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.00229212 0.876124 0.0405652 0.175353 0.649464 0.625375 0.522828 0.29724 0.905251 0.689609 w: 1
Observation: 0 1 0 1 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=579, meanQ=34.619128, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 568008 episodes
GETTING ACTION FROM:
action 5, numVisits=568587, meanQ=38.943244, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.00229212 0.876124 0.0405652 0.175353 0.649464 0.625375 0.522828 0.29724 0.905251 0.689609 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 45
Initial state: 0 0.533176 0.801579 0.477148 0.341884 0.631975 0.359525 0.464913 0.610063 0.431422 0.123824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 420456 episodes
GETTING ACTION FROM:
action 2, numVisits=420448, meanQ=40.453684, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.533176 0.801579 0.477148 0.341884 0.631975 0.359525 0.464913 0.610063 0.431422 0.123824 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 46
Initial state: 0 0.421681 0.828008 0.635163 0.350634 0.856432 0.875544 0.227779 0.292984 0.514035 0.308037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 408010 episodes
GETTING ACTION FROM:
action 2, numVisits=407982, meanQ=41.112129, numObservations: 9
action 1, numVisits=18, meanQ=28.769722, numObservations: 9
action 3, numVisits=6, meanQ=14.158333, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.421681 0.828008 0.635163 0.350634 0.856432 0.875544 0.227779 0.292984 0.514035 0.308037 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 47
Initial state: 0 0.128626 0.737678 0.734426 0.597184 0.686077 0.926558 0.988872 0.0767486 0.475738 0.292486 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 417567 episodes
GETTING ACTION FROM:
action 5, numVisits=417555, meanQ=41.094492, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=5, meanQ=-4.000000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.128626 0.737678 0.734426 0.597184 0.686077 0.926558 0.988872 0.0767486 0.475738 0.292486 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 48
Initial state: 0 0.0451388 0.970635 0.845989 0.209979 0.0204531 0.0925925 0.473097 0.768211 0.560153 0.383946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 390613 episodes
GETTING ACTION FROM:
action 1, numVisits=390592, meanQ=41.268707, numObservations: 9
action 5, numVisits=16, meanQ=34.237500, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0451388 0.970635 0.845989 0.209979 0.0204531 0.0925925 0.473097 0.768211 0.560153 0.383946 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=45489, meanQ=45.240591, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 526260 episodes
GETTING ACTION FROM:
action 4, numVisits=571749, meanQ=49.120824, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 2 0.0451388 0.970635 0.845989 0.209979 0.0204531 0.0925925 0.473097 0.768211 0.560153 0.383946 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 49
Initial state: 0 0.120926 0.112213 0.442011 0.385186 0.674924 0.0524 0.21479 0.617312 0.241822 0.640914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 426754 episodes
GETTING ACTION FROM:
action 3, numVisits=426712, meanQ=39.577072, numObservations: 9
action 1, numVisits=21, meanQ=29.654881, numObservations: 9
action 5, numVisits=16, meanQ=28.687500, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.120926 0.112213 0.442011 0.385186 0.674924 0.0524 0.21479 0.617312 0.241822 0.640914 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 50
Initial state: 0 0.115573 0.681295 0.728684 0.776079 0.815753 0.531842 0.496291 0.326091 0.603351 0.660159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 400457 episodes
GETTING ACTION FROM:
action 4, numVisits=400427, meanQ=40.053538, numObservations: 9
action 2, numVisits=22, meanQ=4.668409, numObservations: 8
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.115573 0.681295 0.728684 0.776079 0.815753 0.531842 0.496291 0.326091 0.603351 0.660159 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
[32m ProblemEnvironment.hpp 351: Done.[39m
