Run # 1
Initial state: 0 0.945424 0.250829 0.720235 0.549568 0.299731 0.75668 0.360664 0.623815 0.513655 0.334152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 380914 episodes
GETTING ACTION FROM:
action 2, numVisits=380905, meanQ=35.387542, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 2 0.945424 0.250829 0.720235 0.549568 0.299731 0.75668 0.360664 0.623815 0.513655 0.334152 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 2
Initial state: 0 0.301848 0.315165 0.428493 0.368729 0.103636 0.461912 0.169991 0.200396 0.158004 0.88269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 396120 episodes
GETTING ACTION FROM:
action 1, numVisits=396104, meanQ=34.724826, numObservations: 9
action 5, numVisits=11, meanQ=4.622955, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.301848 0.315165 0.428493 0.368729 0.103636 0.461912 0.169991 0.200396 0.158004 0.88269 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=6463, meanQ=40.758591, numObservations: 9
action 2, numVisits=4, meanQ=21.737500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 582351 episodes
GETTING ACTION FROM:
action 4, numVisits=588807, meanQ=5.171793, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.525000, numObservations: 2
action 2, numVisits=9, meanQ=-2.005556, numObservations: 6
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.301848 0.315165 0.428493 0.368729 0.103636 0.461912 0.169991 0.200396 0.158004 0.88269 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=8674, meanQ=57.619368, numObservations: 9
action 5, numVisits=4, meanQ=17.212500, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 581771 episodes
GETTING ACTION FROM:
action 2, numVisits=590443, meanQ=17.151695, numObservations: 9
action 5, numVisits=6, meanQ=11.141667, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.301848 0.315165 0.428493 0.368729 0.103636 0.461912 0.169991 0.200396 0.158004 0.88269 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 3
Initial state: 0 0.442199 0.189575 0.461885 0.457254 0.0499835 0.310137 0.802847 0.952923 0.660237 0.802547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 364445 episodes
GETTING ACTION FROM:
action 2, numVisits=364427, meanQ=35.605674, numObservations: 9
action 4, numVisits=4, meanQ=21.737500, numObservations: 3
action 1, numVisits=10, meanQ=17.190000, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.442199 0.189575 0.461885 0.457254 0.0499835 0.310137 0.802847 0.952923 0.660237 0.802547 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 4
Initial state: 0 0.442069 0.354927 0.835378 0.190901 0.704342 0.423387 0.329747 0.746679 0.299823 0.10685 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 365431 episodes
GETTING ACTION FROM:
action 5, numVisits=365420, meanQ=35.551898, numObservations: 9
action 2, numVisits=6, meanQ=11.141667, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.442069 0.354927 0.835378 0.190901 0.704342 0.423387 0.329747 0.746679 0.299823 0.10685 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31532, meanQ=38.581374, numObservations: 9
action 1, numVisits=11, meanQ=32.895455, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 462023 episodes
GETTING ACTION FROM:
action 3, numVisits=493555, meanQ=38.200096, numObservations: 9
action 1, numVisits=11, meanQ=32.895455, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.442069 0.354927 0.835378 0.190901 0.704342 0.423387 0.329747 0.746679 0.299823 0.10685 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 5
Initial state: 0 0.751554 0.588265 0.812403 0.102014 0.103411 0.678269 0.445054 0.423612 0.709669 0.998116 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 418904 episodes
GETTING ACTION FROM:
action 4, numVisits=418894, meanQ=33.924047, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 0 0.751554 0.588265 0.812403 0.102014 0.103411 0.678269 0.445054 0.423612 0.709669 0.998116 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=18350, meanQ=38.346229, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 521625 episodes
GETTING ACTION FROM:
action 3, numVisits=539975, meanQ=37.894155, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.751554 0.588265 0.812403 0.102014 0.103411 0.678269 0.445054 0.423612 0.709669 0.998116 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=18305, meanQ=56.036177, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 524363 episodes
GETTING ACTION FROM:
action 1, numVisits=542668, meanQ=44.379457, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.751554 0.588265 0.812403 0.102014 0.103411 0.678269 0.445054 0.423612 0.709669 0.998116 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 6
Initial state: 0 0.565873 0.457727 0.941978 0.474864 0.499178 0.399271 0.342253 0.296263 0.368272 0.377651 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 395716 episodes
GETTING ACTION FROM:
action 1, numVisits=395708, meanQ=34.557988, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.565873 0.457727 0.941978 0.474864 0.499178 0.399271 0.342253 0.296263 0.368272 0.377651 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 7
Initial state: 0 0.910741 0.75952 0.223505 0.113891 0.600431 0.132843 0.519903 0.425698 0.621265 0.699481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 320943 episodes
GETTING ACTION FROM:
action 4, numVisits=320892, meanQ=36.942843, numObservations: 9
action 2, numVisits=28, meanQ=6.584018, numObservations: 9
action 3, numVisits=10, meanQ=5.235250, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=9, meanQ=-4.233056, numObservations: 6
action: 4
Next state: 1 0.910741 0.75952 0.223505 0.113891 0.600431 0.132843 0.519903 0.425698 0.621265 0.699481 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 8
Initial state: 0 0.104414 0.045777 0.0147592 0.851323 0.653269 0.825914 0.463155 0.386679 0.247598 0.529769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 333686 episodes
GETTING ACTION FROM:
action 4, numVisits=333671, meanQ=35.698791, numObservations: 9
action 2, numVisits=7, meanQ=8.421429, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=4, meanQ=-5.525000, numObservations: 4
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.104414 0.045777 0.0147592 0.851323 0.653269 0.825914 0.463155 0.386679 0.247598 0.529769 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 9
Initial state: 0 0.535863 0.772787 0.477552 0.405453 0.789121 0.556531 0.416813 0.234891 0.46683 0.229456 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 413794 episodes
GETTING ACTION FROM:
action 2, numVisits=413782, meanQ=34.410789, numObservations: 9
action 1, numVisits=6, meanQ=11.141667, numObservations: 5
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.535863 0.772787 0.477552 0.405453 0.789121 0.556531 0.416813 0.234891 0.46683 0.229456 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 10
Initial state: 0 0.797809 0.613274 0.0469544 0.125111 0.526272 0.463499 0.746451 0.0041346 0.62631 0.145398 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 370510 episodes
GETTING ACTION FROM:
action 2, numVisits=370488, meanQ=35.789416, numObservations: 9
action 4, numVisits=17, meanQ=7.988382, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.797809 0.613274 0.0469544 0.125111 0.526272 0.463499 0.746451 0.0041346 0.62631 0.145398 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32049, meanQ=39.856319, numObservations: 9
action 5, numVisits=11, meanQ=31.941136, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 376254 episodes
GETTING ACTION FROM:
action 1, numVisits=408303, meanQ=39.225567, numObservations: 9
action 5, numVisits=11, meanQ=31.941136, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.797809 0.613274 0.0469544 0.125111 0.526272 0.463499 0.746451 0.0041346 0.62631 0.145398 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 11
Initial state: 0 0.442132 0.412615 0.705531 0.996335 0.457007 0.147572 0.830028 0.561693 0.194213 0.486274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 381536 episodes
GETTING ACTION FROM:
action 4, numVisits=381527, meanQ=34.863596, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=4, meanQ=-5.525000, numObservations: 4
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 2 0.442132 0.412615 0.705531 0.996335 0.457007 0.147572 0.830028 0.561693 0.194213 0.486274 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 12
Initial state: 0 0.104916 0.0773159 0.431876 0.441114 0.441739 0.752193 0.785981 0.744388 0.414659 0.046748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 328573 episodes
GETTING ACTION FROM:
action 4, numVisits=328556, meanQ=36.279487, numObservations: 9
action 5, numVisits=4, meanQ=21.737500, numObservations: 4
action 3, numVisits=9, meanQ=20.216667, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.104916 0.0773159 0.431876 0.441114 0.441739 0.752193 0.785981 0.744388 0.414659 0.046748 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 13
Initial state: 0 0.396106 0.809365 0.487021 0.976347 0.493376 0.459939 0.950158 0.637231 0.861003 0.647925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 346474 episodes
GETTING ACTION FROM:
action 4, numVisits=346468, meanQ=35.544862, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.396106 0.809365 0.487021 0.976347 0.493376 0.459939 0.950158 0.637231 0.861003 0.647925 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 14
Initial state: 0 0.172731 0.771025 0.332229 0.700494 0.213587 0.757629 0.747181 0.541791 0.475385 0.458773 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 402082 episodes
GETTING ACTION FROM:
action 1, numVisits=402069, meanQ=34.942091, numObservations: 9
action 5, numVisits=8, meanQ=10.368750, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 0 0.172731 0.771025 0.332229 0.700494 0.213587 0.757629 0.747181 0.541791 0.475385 0.458773 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=41923, meanQ=46.003306, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 355789 episodes
GETTING ACTION FROM:
action 1, numVisits=397712, meanQ=58.221056, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.172731 0.771025 0.332229 0.700494 0.213587 0.757629 0.747181 0.541791 0.475385 0.458773 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=145245, meanQ=37.860571, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 511394 episodes
GETTING ACTION FROM:
action 5, numVisits=656639, meanQ=47.771789, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 0 0.172731 0.771025 0.332229 0.700494 0.213587 0.757629 0.747181 0.541791 0.475385 0.458773 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=17654, meanQ=47.676101, numObservations: 9
action 1, numVisits=11, meanQ=37.255455, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 560784 episodes
GETTING ACTION FROM:
action 4, numVisits=578438, meanQ=48.381140, numObservations: 9
action 1, numVisits=11, meanQ=37.255455, numObservations: 2
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.172731 0.771025 0.332229 0.700494 0.213587 0.757629 0.747181 0.541791 0.475385 0.458773 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 53.5026
Run # 15
Initial state: 0 0.810283 0.163366 0.207165 0.211186 0.158105 0.464036 0.47892 0.425569 0.772558 0.527843 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 364606 episodes
GETTING ACTION FROM:
action 3, numVisits=364600, meanQ=35.041332, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.810283 0.163366 0.207165 0.211186 0.158105 0.464036 0.47892 0.425569 0.772558 0.527843 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=15800, meanQ=39.162208, numObservations: 9
action 1, numVisits=16, meanQ=28.181250, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 418148 episodes
GETTING ACTION FROM:
action 4, numVisits=433948, meanQ=43.904187, numObservations: 9
action 1, numVisits=16, meanQ=28.181250, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.810283 0.163366 0.207165 0.211186 0.158105 0.464036 0.47892 0.425569 0.772558 0.527843 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 16
Initial state: 0 0.35583 0.429811 0.828456 0.797949 0.18098 0.231337 0.501358 0.356046 0.622916 0.446362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 367522 episodes
GETTING ACTION FROM:
action 5, numVisits=367516, meanQ=34.941073, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 2 0.35583 0.429811 0.828456 0.797949 0.18098 0.231337 0.501358 0.356046 0.622916 0.446362 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 17
Initial state: 0 0.811164 0.201544 0.967376 0.179369 0.788791 0.669079 0.440531 0.476778 0.00164579 0.45155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 420933 episodes
GETTING ACTION FROM:
action 4, numVisits=420896, meanQ=34.453828, numObservations: 9
action 3, numVisits=27, meanQ=21.365185, numObservations: 9
action 2, numVisits=6, meanQ=14.158333, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.811164 0.201544 0.967376 0.179369 0.788791 0.669079 0.440531 0.476778 0.00164579 0.45155 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 18
Initial state: 0 0.99278 0.917694 0.73927 0.240083 0.00567133 0.612499 0.904409 0.38829 0.519397 0.348259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 288619 episodes
GETTING ACTION FROM:
action 5, numVisits=288601, meanQ=36.681805, numObservations: 9
action 4, numVisits=12, meanQ=23.245833, numObservations: 7
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.99278 0.917694 0.73927 0.240083 0.00567133 0.612499 0.904409 0.38829 0.519397 0.348259 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 19
Initial state: 0 0.515769 0.379592 0.356321 0.400124 0.77039 0.403097 0.217541 0.950806 0.990203 0.823823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 341438 episodes
GETTING ACTION FROM:
action 2, numVisits=341358, meanQ=35.973025, numObservations: 9
action 5, numVisits=54, meanQ=22.592963, numObservations: 8
action 3, numVisits=16, meanQ=19.294062, numObservations: 8
action 1, numVisits=5, meanQ=15.380000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action: 2
Next state: 0 0.515769 0.379592 0.356321 0.400124 0.77039 0.403097 0.217541 0.950806 0.990203 0.823823 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=15093, meanQ=38.363368, numObservations: 9
action 4, numVisits=4, meanQ=21.737500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 499537 episodes
GETTING ACTION FROM:
action 3, numVisits=514630, meanQ=30.064327, numObservations: 9
action 4, numVisits=4, meanQ=21.737500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.515769 0.379592 0.356321 0.400124 0.77039 0.403097 0.217541 0.950806 0.990203 0.823823 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 20
Initial state: 0 0.755111 0.409924 0.87165 0.584417 0.433528 0.175043 0.486558 0.343079 0.375879 0.33863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 359520 episodes
GETTING ACTION FROM:
action 5, numVisits=359511, meanQ=34.815989, numObservations: 9
action 3, numVisits=3, meanQ=25.650833, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.755111 0.409924 0.87165 0.584417 0.433528 0.175043 0.486558 0.343079 0.375879 0.33863 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 21
Initial state: 0 0.96295 0.285694 0.343346 0.0353358 0.448389 0.983557 0.525568 0.485212 0.320566 0.959611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 409337 episodes
GETTING ACTION FROM:
action 4, numVisits=409318, meanQ=34.323883, numObservations: 9
action 3, numVisits=14, meanQ=18.489286, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.96295 0.285694 0.343346 0.0353358 0.448389 0.983557 0.525568 0.485212 0.320566 0.959611 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 22
Initial state: 0 0.189286 0.727696 0.861912 0.64252 0.627113 0.105877 0.507683 0.447479 0.40207 0.168803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 410342 episodes
GETTING ACTION FROM:
action 1, numVisits=410336, meanQ=34.215556, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.189286 0.727696 0.861912 0.64252 0.627113 0.105877 0.507683 0.447479 0.40207 0.168803 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=42518, meanQ=40.087771, numObservations: 9
action 4, numVisits=67, meanQ=36.222687, numObservations: 9
action 1, numVisits=6, meanQ=28.992083, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 422580 episodes
GETTING ACTION FROM:
action 3, numVisits=465098, meanQ=46.740499, numObservations: 9
action 4, numVisits=67, meanQ=36.222687, numObservations: 9
action 1, numVisits=6, meanQ=28.992083, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.189286 0.727696 0.861912 0.64252 0.627113 0.105877 0.507683 0.447479 0.40207 0.168803 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 23
Initial state: 0 0.496903 0.321194 0.58265 0.743679 0.702844 0.868221 0.5055 0.332518 0.380129 0.932057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 371947 episodes
GETTING ACTION FROM:
action 2, numVisits=371940, meanQ=34.889548, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.496903 0.321194 0.58265 0.743679 0.702844 0.868221 0.5055 0.332518 0.380129 0.932057 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 24
Initial state: 0 0.846785 0.0979105 0.703351 0.810393 0.785103 0.31557 0.472454 0.399857 0.211806 0.666899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 389780 episodes
GETTING ACTION FROM:
action 4, numVisits=389773, meanQ=35.100369, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.846785 0.0979105 0.703351 0.810393 0.785103 0.31557 0.472454 0.399857 0.211806 0.666899 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 25
Initial state: 0 0.191946 0.531341 0.990494 0.166951 0.443938 0.336433 0.570441 0.784786 0.378798 0.10678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 369797 episodes
GETTING ACTION FROM:
action 5, numVisits=369788, meanQ=35.103210, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.191946 0.531341 0.990494 0.166951 0.443938 0.336433 0.570441 0.784786 0.378798 0.10678 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31658, meanQ=39.779131, numObservations: 9
action 1, numVisits=4, meanQ=21.737500, numObservations: 4
action 3, numVisits=7, meanQ=10.700000, numObservations: 6
action 4, numVisits=6, meanQ=9.392083, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 437876 episodes
GETTING ACTION FROM:
action 2, numVisits=469534, meanQ=36.519169, numObservations: 9
action 1, numVisits=4, meanQ=21.737500, numObservations: 4
action 3, numVisits=7, meanQ=10.700000, numObservations: 6
action 4, numVisits=6, meanQ=9.392083, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 2 0.191946 0.531341 0.990494 0.166951 0.443938 0.336433 0.570441 0.784786 0.378798 0.10678 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 26
Initial state: 0 0.0353451 0.576524 0.955782 0.864841 0.311703 0.447967 0.423081 0.0756353 0.502518 0.449453 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 404477 episodes
GETTING ACTION FROM:
action 3, numVisits=404471, meanQ=34.557101, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 0 0.0353451 0.576524 0.955782 0.864841 0.311703 0.447967 0.423081 0.0756353 0.502518 0.449453 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=17733, meanQ=38.194203, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 425096 episodes
GETTING ACTION FROM:
action 1, numVisits=442829, meanQ=30.198073, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0353451 0.576524 0.955782 0.864841 0.311703 0.447967 0.423081 0.0756353 0.502518 0.449453 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1911, meanQ=27.930492, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 581806 episodes
GETTING ACTION FROM:
action 4, numVisits=583717, meanQ=45.510235, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.0353451 0.576524 0.955782 0.864841 0.311703 0.447967 0.423081 0.0756353 0.502518 0.449453 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -112.603
Run # 27
Initial state: 0 0.566013 0.280875 0.125548 0.954579 0.811589 0.853207 0.488771 0.330296 0.493416 0.238641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 278919 episodes
GETTING ACTION FROM:
action 5, numVisits=278913, meanQ=37.791478, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.566013 0.280875 0.125548 0.954579 0.811589 0.853207 0.488771 0.330296 0.493416 0.238641 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 28
Initial state: 0 0.726109 0.179488 0.514924 0.46625 0.0395668 0.661484 0.194858 0.328765 0.53012 0.520062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 402594 episodes
GETTING ACTION FROM:
action 5, numVisits=402588, meanQ=33.812622, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.726109 0.179488 0.514924 0.46625 0.0395668 0.661484 0.194858 0.328765 0.53012 0.520062 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 29
Initial state: 0 0.422022 0.432554 0.743234 0.704914 0.903334 0.523731 0.38246 0.0437271 0.116705 0.444452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 119075 episodes
GETTING ACTION FROM:
action 0, numVisits=119057, meanQ=60.383460, numObservations: 243
action -1, numVisits=10, meanQ=-1.244750, numObservations: 9
action 4, numVisits=4, meanQ=-5.525000, numObservations: 4
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.422022 0.432554 0.743234 0.704914 0.903334 0.523731 0.38246 0.0437271 0.116705 0.444452 w: 1
Observation: 0 0 1 0 3 0 3 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=285, meanQ=52.987754, numObservations: 9
action 2, numVisits=10, meanQ=45.690000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-6.000000, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 309549 episodes
GETTING ACTION FROM:
action 3, numVisits=309834, meanQ=71.230697, numObservations: 9
action 2, numVisits=10, meanQ=45.690000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-6.000000, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.422022 0.432554 0.743234 0.704914 0.903334 0.523731 0.38246 0.0437271 0.116705 0.444452 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 30
Initial state: 0 0.0439476 0.363995 0.62032 0.722127 0.911903 0.105659 0.526171 0.436983 0.750764 0.580718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 394039 episodes
GETTING ACTION FROM:
action 3, numVisits=394032, meanQ=34.281585, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.0439476 0.363995 0.62032 0.722127 0.911903 0.105659 0.526171 0.436983 0.750764 0.580718 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 31
Initial state: 0 0.969579 0.242737 0.743527 0.213802 0.485753 0.379882 0.71222 0.627628 0.127886 0.318476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 377211 episodes
GETTING ACTION FROM:
action 2, numVisits=377201, meanQ=34.890749, numObservations: 9
action 1, numVisits=4, meanQ=21.737500, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.969579 0.242737 0.743527 0.213802 0.485753 0.379882 0.71222 0.627628 0.127886 0.318476 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1840, meanQ=28.221664, numObservations: 9
action 5, numVisits=5, meanQ=13.280500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 592753 episodes
GETTING ACTION FROM:
action 4, numVisits=594593, meanQ=38.724746, numObservations: 9
action 5, numVisits=5, meanQ=13.280500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.969579 0.242737 0.743527 0.213802 0.485753 0.379882 0.71222 0.627628 0.127886 0.318476 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 32
Initial state: 0 0.511346 0.0692667 0.26154 0.20304 0.677383 0.253382 0.418881 0.408272 0.185181 0.548325 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 325226 episodes
GETTING ACTION FROM:
action 2, numVisits=325190, meanQ=36.216051, numObservations: 9
action 1, numVisits=6, meanQ=-4.016667, numObservations: 5
action -1, numVisits=15, meanQ=-7.510000, numObservations: 14
action 0, numVisits=12, meanQ=-9.125000, numObservations: 11
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.511346 0.0692667 0.26154 0.20304 0.677383 0.253382 0.418881 0.408272 0.185181 0.548325 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=27853, meanQ=59.523259, numObservations: 243
action 0, numVisits=32, meanQ=-4.406172, numObservations: 30
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
Sampled 126744 episodes
GETTING ACTION FROM:
action -1, numVisits=154597, meanQ=50.553687, numObservations: 243
action 0, numVisits=32, meanQ=-4.406172, numObservations: 30
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action: -1
Next state: 0 0.511346 0.0692667 0.26154 0.20304 0.677383 0.253382 0.418881 0.408272 0.185181 0.548325 w: 1
Observation: 0 2 0 1 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2387, meanQ=91.515647, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 558452 episodes
GETTING ACTION FROM:
action 1, numVisits=560839, meanQ=92.418702, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.511346 0.0692667 0.26154 0.20304 0.677383 0.253382 0.418881 0.408272 0.185181 0.548325 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -104.053
Run # 33
Initial state: 0 0.794497 0.214131 0.871939 0.694904 0.194463 0.48512 0.222112 0.412502 0.523141 0.385028 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 406459 episodes
GETTING ACTION FROM:
action 4, numVisits=406452, meanQ=33.576714, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 2 0.794497 0.214131 0.871939 0.694904 0.194463 0.48512 0.222112 0.412502 0.523141 0.385028 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 34
Initial state: 0 0.612013 0.676342 0.122426 0.457796 0.0548627 0.652042 0.442406 0.466014 0.606459 0.733633 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 367220 episodes
GETTING ACTION FROM:
action 4, numVisits=367214, meanQ=35.131758, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.612013 0.676342 0.122426 0.457796 0.0548627 0.652042 0.442406 0.466014 0.606459 0.733633 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 35
Initial state: 0 0.996377 0.826314 0.825313 0.402532 0.465789 0.391919 0.964473 0.170209 0.840765 0.607018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 394705 episodes
GETTING ACTION FROM:
action 1, numVisits=394692, meanQ=34.526265, numObservations: 9
action 3, numVisits=5, meanQ=19.000000, numObservations: 4
action 2, numVisits=4, meanQ=17.212500, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.996377 0.826314 0.825313 0.402532 0.465789 0.391919 0.964473 0.170209 0.840765 0.607018 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 36
Initial state: 0 0.521589 0.485041 0.309987 0.380498 0.366085 0.0885691 0.748962 0.402635 0.452299 0.573221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 378359 episodes
GETTING ACTION FROM:
action 2, numVisits=378333, meanQ=35.012055, numObservations: 9
action 5, numVisits=9, meanQ=17.989167, numObservations: 6
action 3, numVisits=9, meanQ=15.978056, numObservations: 6
action 1, numVisits=5, meanQ=15.380000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.521589 0.485041 0.309987 0.380498 0.366085 0.0885691 0.748962 0.402635 0.452299 0.573221 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=16567, meanQ=38.379021, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 458631 episodes
GETTING ACTION FROM:
action 5, numVisits=475198, meanQ=34.449832, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.521589 0.485041 0.309987 0.380498 0.366085 0.0885691 0.748962 0.402635 0.452299 0.573221 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 37
Initial state: 0 0.00111606 0.168363 0.154734 0.393771 0.484876 0.449248 0.243177 0.910748 0.755272 0.450743 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 341082 episodes
GETTING ACTION FROM:
action 5, numVisits=341070, meanQ=35.713527, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.00111606 0.168363 0.154734 0.393771 0.484876 0.449248 0.243177 0.910748 0.755272 0.450743 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 38
Initial state: 0 0.428941 0.465226 0.127744 0.0673667 0.168279 0.596831 0.0235515 0.862787 0.607777 0.820037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 358862 episodes
GETTING ACTION FROM:
action 2, numVisits=358831, meanQ=34.583037, numObservations: 9
action 3, numVisits=21, meanQ=28.395476, numObservations: 9
action 4, numVisits=6, meanQ=14.158333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 0 0.428941 0.465226 0.127744 0.0673667 0.168279 0.596831 0.0235515 0.862787 0.607777 0.820037 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=5623, meanQ=39.548375, numObservations: 9
action 1, numVisits=4, meanQ=21.737500, numObservations: 4
action 3, numVisits=8, meanQ=20.425312, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 587243 episodes
GETTING ACTION FROM:
action 5, numVisits=592860, meanQ=15.236517, numObservations: 9
action 3, numVisits=11, meanQ=5.491136, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=7, meanQ=-2.292857, numObservations: 7
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.428941 0.465226 0.127744 0.0673667 0.168279 0.596831 0.0235515 0.862787 0.607777 0.820037 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 39
Initial state: 0 0.806201 0.602693 0.0329358 0.185953 0.346681 0.535535 0.132928 0.412382 0.451853 0.327973 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 421817 episodes
GETTING ACTION FROM:
action 1, numVisits=421793, meanQ=34.146700, numObservations: 9
action 5, numVisits=19, meanQ=17.016053, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.806201 0.602693 0.0329358 0.185953 0.346681 0.535535 0.132928 0.412382 0.451853 0.327973 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 40
Initial state: 0 0.953904 0.434947 0.470035 0.396039 0.807302 0.550542 0.976151 0.965658 0.286385 0.900367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 373537 episodes
GETTING ACTION FROM:
action 4, numVisits=373526, meanQ=35.636402, numObservations: 9
action 3, numVisits=5, meanQ=15.380000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.953904 0.434947 0.470035 0.396039 0.807302 0.550542 0.976151 0.965658 0.286385 0.900367 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 41
Initial state: 0 0.151921 0.946272 0.840534 0.0776561 0.462916 0.329343 0.515821 0.724364 0.49757 0.253792 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 361255 episodes
GETTING ACTION FROM:
action 1, numVisits=361243, meanQ=34.853860, numObservations: 9
action 2, numVisits=7, meanQ=13.285714, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.151921 0.946272 0.840534 0.0776561 0.462916 0.329343 0.515821 0.724364 0.49757 0.253792 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=37650, meanQ=39.982493, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=4, meanQ=-7.012500, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 484389 episodes
GETTING ACTION FROM:
action 2, numVisits=522039, meanQ=44.276895, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=4, meanQ=-7.012500, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.151921 0.946272 0.840534 0.0776561 0.462916 0.329343 0.515821 0.724364 0.49757 0.253792 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 42
Initial state: 0 0.761493 0.0907824 0.272861 0.26198 0.509219 0.421237 0.590527 0.905189 0.0127908 0.145428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 414285 episodes
GETTING ACTION FROM:
action 4, numVisits=414266, meanQ=34.322818, numObservations: 9
action 1, numVisits=14, meanQ=10.700000, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.761493 0.0907824 0.272861 0.26198 0.509219 0.421237 0.590527 0.905189 0.0127908 0.145428 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 43
Initial state: 0 0.0401663 0.352945 0.99161 0.594917 0.42468 0.370127 0.554518 0.600024 0.384722 0.899151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 343889 episodes
GETTING ACTION FROM:
action 2, numVisits=343882, meanQ=35.057851, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0401663 0.352945 0.99161 0.594917 0.42468 0.370127 0.554518 0.600024 0.384722 0.899151 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 44
Initial state: 0 0.00536452 0.520798 0.340087 0.435439 0.464332 0.346129 0.916657 0.388285 0.820664 0.81415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 396727 episodes
GETTING ACTION FROM:
action 5, numVisits=396720, meanQ=34.091423, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.00536452 0.520798 0.340087 0.435439 0.464332 0.346129 0.916657 0.388285 0.820664 0.81415 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 45
Initial state: 0 0.167491 0.999696 0.727558 0.981927 0.473838 0.370395 0.992214 0.109267 0.289971 0.655512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 313681 episodes
GETTING ACTION FROM:
action 4, numVisits=313620, meanQ=35.610679, numObservations: 9
action 3, numVisits=6, meanQ=-4.016667, numObservations: 6
action 0, numVisits=26, meanQ=-4.776923, numObservations: 25
action -1, numVisits=19, meanQ=-6.150000, numObservations: 18
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=8, meanQ=-14.631250, numObservations: 6
action: 4
Next state: 2 0.167491 0.999696 0.727558 0.981927 0.473838 0.370395 0.992214 0.109267 0.289971 0.655512 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 46
Initial state: 0 0.691326 0.906134 0.110046 0.779304 0.406115 0.0499556 0.516591 0.327617 0.356397 0.444132 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 334502 episodes
GETTING ACTION FROM:
action 1, numVisits=334459, meanQ=35.622456, numObservations: 9
action 5, numVisits=38, meanQ=19.921053, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.691326 0.906134 0.110046 0.779304 0.406115 0.0499556 0.516591 0.327617 0.356397 0.444132 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 47
Initial state: 0 0.167747 0.168404 0.248297 0.113979 0.957763 0.50058 0.982033 0.756215 0.436354 0.481111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 112403 episodes
GETTING ACTION FROM:
action 0, numVisits=112372, meanQ=58.259637, numObservations: 243
action 1, numVisits=7, meanQ=-2.292857, numObservations: 5
action -1, numVisits=18, meanQ=-6.433333, numObservations: 17
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.167747 0.168404 0.248297 0.113979 0.957763 0.50058 0.982033 0.756215 0.436354 0.481111 w: 1
Observation: 0 0 1 0 1 0 2 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=384, meanQ=45.159460, numObservations: 79
action -1, numVisits=5, meanQ=-1.050000, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 128103 episodes
GETTING ACTION FROM:
action 0, numVisits=128487, meanQ=63.912908, numObservations: 240
action -1, numVisits=5, meanQ=-1.050000, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.167747 0.168404 0.248297 0.113979 0.957763 0.50058 0.982033 0.756215 0.436354 0.481111 w: 1
Observation: 0 0 1 0 1 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=8850, meanQ=67.194369, numObservations: 147
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 140225 episodes
GETTING ACTION FROM:
action 0, numVisits=149075, meanQ=72.514670, numObservations: 215
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.167747 0.168404 0.248297 0.113979 0.957763 0.50058 0.982033 0.756215 0.436354 0.481111 w: 1
Observation: 0 0 3 0 1 0 2 0 3 0 2 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=1704, meanQ=72.329501, numObservations: 9
action 3, numVisits=14, meanQ=59.164643, numObservations: 5
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 505142 episodes
GETTING ACTION FROM:
action 4, numVisits=506846, meanQ=74.542359, numObservations: 9
action 3, numVisits=14, meanQ=59.164643, numObservations: 5
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.167747 0.168404 0.248297 0.113979 0.957763 0.50058 0.982033 0.756215 0.436354 0.481111 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 79.1751
Run # 48
Initial state: 0 0.199164 0.158065 0.0632603 0.657387 0.476357 0.377793 0.641625 0.566151 0.46529 0.809769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 387024 episodes
GETTING ACTION FROM:
action 1, numVisits=387018, meanQ=34.580178, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.199164 0.158065 0.0632603 0.657387 0.476357 0.377793 0.641625 0.566151 0.46529 0.809769 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=33442, meanQ=40.466134, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 377377 episodes
GETTING ACTION FROM:
action 2, numVisits=410819, meanQ=36.853930, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.199164 0.158065 0.0632603 0.657387 0.476357 0.377793 0.641625 0.566151 0.46529 0.809769 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=13067, meanQ=51.053634, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 537743 episodes
GETTING ACTION FROM:
action 3, numVisits=550810, meanQ=44.550490, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.199164 0.158065 0.0632603 0.657387 0.476357 0.377793 0.641625 0.566151 0.46529 0.809769 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 49
Initial state: 0 0.115297 0.99934 0.457066 0.335864 0.99687 0.853091 0.803737 0.608195 0.924429 0.664236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 400449 episodes
GETTING ACTION FROM:
action 5, numVisits=400437, meanQ=35.004054, numObservations: 9
action 4, numVisits=4, meanQ=21.737500, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.115297 0.99934 0.457066 0.335864 0.99687 0.853091 0.803737 0.608195 0.924429 0.664236 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 50
Initial state: 0 0.174927 0.0443784 0.185708 0.248051 0.910745 0.994571 0.858876 0.566692 0.478734 0.367108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 398480 episodes
GETTING ACTION FROM:
action 5, numVisits=398470, meanQ=35.005865, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.174927 0.0443784 0.185708 0.248051 0.910745 0.994571 0.858876 0.566692 0.478734 0.367108 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
[32m ProblemEnvironment.hpp 351: Done.[39m
