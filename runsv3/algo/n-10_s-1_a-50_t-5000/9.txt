Run # 1
Initial state: 0 0.953851 0.0513356 0.7741 0.032649 0.75155 0.857813 0.421736 0.174584 0.426005 0.461219 0.0154835 0.273829 0.738132 0.817574 0.292866 0.650684 0.710421 0.865151 0.773307 0.187261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84876 episodes
GETTING ACTION FROM:
action 1, numVisits=84830, meanQ=22.965129, numObservations: 9
action 3, numVisits=24, meanQ=5.627083, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 7, numVisits=5, meanQ=-3.000000, numObservations: 5
action 10, numVisits=5, meanQ=-3.000000, numObservations: 5
action 9, numVisits=4, meanQ=-6.000000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.953851 0.0513356 0.7741 0.032649 0.75155 0.857813 0.421736 0.174584 0.426005 0.461219 0.0154835 0.273829 0.738132 0.817574 0.292866 0.650684 0.710421 0.865151 0.773307 0.187261 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 2
Initial state: 0 0.477986 0.393922 0.328289 0.181878 0.267244 0.569475 0.796718 0.136903 0.00741451 0.903994 0.319656 0.0889214 0.535736 0.415176 0.844409 0.605325 0.338186 0.631685 0.799525 0.862832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89893 episodes
GETTING ACTION FROM:
action 5, numVisits=89846, meanQ=22.673788, numObservations: 9
action 3, numVisits=20, meanQ=20.222750, numObservations: 8
action 4, numVisits=9, meanQ=20.111111, numObservations: 6
action 2, numVisits=9, meanQ=18.205556, numObservations: 6
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.477986 0.393922 0.328289 0.181878 0.267244 0.569475 0.796718 0.136903 0.00741451 0.903994 0.319656 0.0889214 0.535736 0.415176 0.844409 0.605325 0.338186 0.631685 0.799525 0.862832 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8606, meanQ=27.841236, numObservations: 9
action 3, numVisits=29, meanQ=20.914397, numObservations: 8
action 4, numVisits=7, meanQ=10.700000, numObservations: 6
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 6, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 10, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25357 episodes
GETTING ACTION FROM:
action 1, numVisits=33963, meanQ=34.325390, numObservations: 9
action 3, numVisits=29, meanQ=20.914397, numObservations: 8
action 4, numVisits=7, meanQ=10.700000, numObservations: 6
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 6, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 10, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.477986 0.393922 0.328289 0.181878 0.267244 0.569475 0.796718 0.136903 0.00741451 0.903994 0.319656 0.0889214 0.535736 0.415176 0.844409 0.605325 0.338186 0.631685 0.799525 0.862832 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 3
Initial state: 0 0.457625 0.865073 0.651126 0.987785 0.745245 0.698441 0.309837 0.880664 0.499455 0.755731 0.37848 0.339541 0.309358 0.700307 0.721796 0.367983 0.24389 0.328866 0.938574 0.989846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 66026 episodes
GETTING ACTION FROM:
action 5, numVisits=66006, meanQ=20.513720, numObservations: 9
action 7, numVisits=5, meanQ=15.000000, numObservations: 5
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.457625 0.865073 0.651126 0.987785 0.745245 0.698441 0.309837 0.880664 0.499455 0.755731 0.37848 0.339541 0.309358 0.700307 0.721796 0.367983 0.24389 0.328866 0.938574 0.989846 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 4
Initial state: 0 0.285228 0.205258 0.27855 0.985667 0.965919 0.544529 0.456171 0.715159 0.484351 0.161684 0.732376 0.0558617 0.498724 0.450102 0.567168 0.201551 0.986932 0.384265 0.626812 0.181973 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88189 episodes
GETTING ACTION FROM:
action 6, numVisits=88161, meanQ=21.360589, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=12, meanQ=-3.083333, numObservations: 6
action 8, numVisits=4, meanQ=-7.487500, numObservations: 3
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 2 0.285228 0.205258 0.27855 0.985667 0.965919 0.544529 0.456171 0.715159 0.484351 0.161684 0.732376 0.0558617 0.498724 0.450102 0.567168 0.201551 0.986932 0.384265 0.626812 0.181973 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 5
Initial state: 0 0.0269778 0.441916 0.969545 0.78663 0.422623 0.269856 0.496236 0.44703 0.0344414 0.191074 0.644759 0.771934 0.555676 0.944815 0.0698087 0.980735 0.896709 0.373248 0.0198054 0.900876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89175 episodes
GETTING ACTION FROM:
action 6, numVisits=48147, meanQ=23.708320, numObservations: 9
action 1, numVisits=28945, meanQ=23.654174, numObservations: 9
action 8, numVisits=12069, meanQ=23.628880, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 1 0.0269778 0.441916 0.969545 0.78663 0.422623 0.269856 0.496236 0.44703 0.0344414 0.191074 0.644759 0.771934 0.555676 0.944815 0.0698087 0.980735 0.896709 0.373248 0.0198054 0.900876 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 6
Initial state: 0 0.293692 0.43247 0.738456 0.774591 0.42192 0.388353 0.10818 0.103737 0.654901 0.677791 0.78585 0.887431 0.073594 0.273757 0.299639 0.339786 0.282338 0.0562497 0.264712 0.694231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83470 episodes
GETTING ACTION FROM:
action 1, numVisits=83456, meanQ=22.997142, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 6, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.293692 0.43247 0.738456 0.774591 0.42192 0.388353 0.10818 0.103737 0.654901 0.677791 0.78585 0.887431 0.073594 0.273757 0.299639 0.339786 0.282338 0.0562497 0.264712 0.694231 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 8, numVisits=301, meanQ=29.373782, numObservations: 9
action 10, numVisits=14, meanQ=11.992857, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 6, numVisits=1, meanQ=-10.050000, numObservations: 1
action 7, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 85095 episodes
GETTING ACTION FROM:
action 8, numVisits=85396, meanQ=23.193596, numObservations: 9
action 10, numVisits=14, meanQ=11.992857, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 6, numVisits=1, meanQ=-10.050000, numObservations: 1
action 7, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 2 0.293692 0.43247 0.738456 0.774591 0.42192 0.388353 0.10818 0.103737 0.654901 0.677791 0.78585 0.887431 0.073594 0.273757 0.299639 0.339786 0.282338 0.0562497 0.264712 0.694231 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 7
Initial state: 0 0.510946 0.877457 0.306817 0.415084 0.590678 0.819782 0.482653 0.329799 0.0875585 0.940352 0.600687 0.386354 0.263103 0.153839 0.366529 0.507702 0.801814 0.087208 0.814897 0.902091 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81736 episodes
GETTING ACTION FROM:
action 4, numVisits=81711, meanQ=22.253890, numObservations: 9
action 5, numVisits=5, meanQ=19.000000, numObservations: 4
action 8, numVisits=7, meanQ=10.564286, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-6.316667, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.510946 0.877457 0.306817 0.415084 0.590678 0.819782 0.482653 0.329799 0.0875585 0.940352 0.600687 0.386354 0.263103 0.153839 0.366529 0.507702 0.801814 0.087208 0.814897 0.902091 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 8
Initial state: 0 0.103138 0.308004 0.97555 0.430946 0.0273646 0.752553 0.746779 0.643305 0.867202 0.205491 0.755079 0.452848 0.362859 0.379392 0.884618 0.0799557 0.864824 0.130133 0.0489509 0.661107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88781 episodes
GETTING ACTION FROM:
action 3, numVisits=88764, meanQ=22.771432, numObservations: 9
action 8, numVisits=6, meanQ=14.158333, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.103138 0.308004 0.97555 0.430946 0.0273646 0.752553 0.746779 0.643305 0.867202 0.205491 0.755079 0.452848 0.362859 0.379392 0.884618 0.0799557 0.864824 0.130133 0.0489509 0.661107 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 9
Initial state: 0 0.729149 0.723568 0.281403 0.00579943 0.895723 0.924048 0.76669 0.434432 0.361805 0.410278 0.573653 0.0571322 0.918508 0.7926 0.262452 0.500126 0.773948 0.295296 0.454934 0.149682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82790 episodes
GETTING ACTION FROM:
action 2, numVisits=82776, meanQ=21.427109, numObservations: 9
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 8, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.729149 0.723568 0.281403 0.00579943 0.895723 0.924048 0.76669 0.434432 0.361805 0.410278 0.573653 0.0571322 0.918508 0.7926 0.262452 0.500126 0.773948 0.295296 0.454934 0.149682 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 6, numVisits=8044, meanQ=28.601338, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 10, numVisits=5, meanQ=-2.810000, numObservations: 4
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 7, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 26216 episodes
GETTING ACTION FROM:
action 6, numVisits=34260, meanQ=29.171002, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 10, numVisits=5, meanQ=-2.810000, numObservations: 4
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 7, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 2 0.729149 0.723568 0.281403 0.00579943 0.895723 0.924048 0.76669 0.434432 0.361805 0.410278 0.573653 0.0571322 0.918508 0.7926 0.262452 0.500126 0.773948 0.295296 0.454934 0.149682 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 10
Initial state: 0 0.262132 0.69076 0.733154 0.547634 0.61257 0.0857377 0.825724 0.0430489 0.0651985 0.610005 0.551248 0.788782 0.992021 0.125448 0.38964 0.460492 0.942763 0.236067 0.935321 0.175645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88713 episodes
GETTING ACTION FROM:
action 2, numVisits=88694, meanQ=22.284056, numObservations: 9
action 1, numVisits=5, meanQ=19.000000, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 9, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.262132 0.69076 0.733154 0.547634 0.61257 0.0857377 0.825724 0.0430489 0.0651985 0.610005 0.551248 0.788782 0.992021 0.125448 0.38964 0.460492 0.942763 0.236067 0.935321 0.175645 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 11
Initial state: 0 0.112821 0.158236 0.913867 0.0941442 0.443657 0.941689 0.186448 0.111386 0.976677 0.780593 0.109864 0.524817 0.0396007 0.00550984 0.729117 0.534856 0.365889 0.359814 0.66694 0.0673904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81528 episodes
GETTING ACTION FROM:
action 1, numVisits=81503, meanQ=24.672668, numObservations: 9
action 5, numVisits=8, meanQ=21.618750, numObservations: 7
action 9, numVisits=7, meanQ=10.428571, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.112821 0.158236 0.913867 0.0941442 0.443657 0.941689 0.186448 0.111386 0.976677 0.780593 0.109864 0.524817 0.0396007 0.00550984 0.729117 0.534856 0.365889 0.359814 0.66694 0.0673904 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 6, numVisits=6556, meanQ=25.510384, numObservations: 9
action 2, numVisits=142, meanQ=24.299701, numObservations: 9
action 8, numVisits=4, meanQ=21.737500, numObservations: 4
action 3, numVisits=11, meanQ=14.359545, numObservations: 6
action 10, numVisits=8, meanQ=10.368750, numObservations: 6
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 19458 episodes
GETTING ACTION FROM:
action 6, numVisits=25861, meanQ=20.142510, numObservations: 9
action 2, numVisits=294, meanQ=19.062152, numObservations: 9
action 3, numVisits=11, meanQ=14.359545, numObservations: 6
action 10, numVisits=8, meanQ=10.368750, numObservations: 6
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 8, numVisits=5, meanQ=-2.810000, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 1 0.112821 0.158236 0.913867 0.0941442 0.443657 0.941689 0.186448 0.111386 0.976677 0.780593 0.109864 0.524817 0.0396007 0.00550984 0.729117 0.534856 0.365889 0.359814 0.66694 0.0673904 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 12
Initial state: 0 0.832403 0.607893 0.860822 0.446243 0.850756 0.771174 0.0558791 0.732178 0.858889 0.771594 0.750174 0.672642 0.419275 0.390283 0.80081 0.96507 0.468994 0.709586 0.948973 0.487866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87019 episodes
GETTING ACTION FROM:
action 8, numVisits=86979, meanQ=22.392187, numObservations: 9
action -1, numVisits=13, meanQ=-1.050000, numObservations: 13
action 0, numVisits=12, meanQ=-1.050000, numObservations: 12
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=5, meanQ=-21.000000, numObservations: 3
action 10, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 1 0.832403 0.607893 0.860822 0.446243 0.850756 0.771174 0.0558791 0.732178 0.858889 0.771594 0.750174 0.672642 0.419275 0.390283 0.80081 0.96507 0.468994 0.709586 0.948973 0.487866 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 13
Initial state: 0 0.953004 0.691674 0.398423 0.778007 0.895678 0.536188 0.335879 0.532265 0.813084 0.877559 0.573474 0.24362 0.251708 0.711865 0.468425 0.345847 0.790333 0.749211 0.254833 0.628946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82632 episodes
GETTING ACTION FROM:
action 8, numVisits=82577, meanQ=21.280544, numObservations: 9
action 3, numVisits=17, meanQ=6.561912, numObservations: 7
action 7, numVisits=10, meanQ=6.190000, numObservations: 6
action 10, numVisits=14, meanQ=1.957321, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 9, numVisits=6, meanQ=-4.175000, numObservations: 4
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 1 0.953004 0.691674 0.398423 0.778007 0.895678 0.536188 0.335879 0.532265 0.813084 0.877559 0.573474 0.24362 0.251708 0.711865 0.468425 0.345847 0.790333 0.749211 0.254833 0.628946 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 14
Initial state: 0 0.59376 0.410315 0.459036 0.0753911 0.901067 0.174873 0.468507 0.405359 0.435255 0.141263 0.324399 0.782607 0.0626958 0.609159 0.838327 0.707291 0.0753182 0.241915 0.143112 0.519003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84147 episodes
GETTING ACTION FROM:
action 4, numVisits=84122, meanQ=21.490442, numObservations: 9
action 1, numVisits=5, meanQ=15.380000, numObservations: 4
action 2, numVisits=5, meanQ=14.800500, numObservations: 4
action 9, numVisits=6, meanQ=14.000000, numObservations: 4
action 6, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.59376 0.410315 0.459036 0.0753911 0.901067 0.174873 0.468507 0.405359 0.435255 0.141263 0.324399 0.782607 0.0626958 0.609159 0.838327 0.707291 0.0753182 0.241915 0.143112 0.519003 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 15
Initial state: 0 0.750611 0.599589 0.945857 0.830458 0.205477 0.57104 0.259218 0.642272 0.968484 0.893084 0.497063 0.487907 0.998946 0.606803 0.49669 0.663218 0.504177 0.780324 0.56527 0.88776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 60463 episodes
GETTING ACTION FROM:
action 7, numVisits=60444, meanQ=19.596155, numObservations: 9
action 3, numVisits=9, meanQ=16.828056, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 1 0.750611 0.599589 0.945857 0.830458 0.205477 0.57104 0.259218 0.642272 0.968484 0.893084 0.497063 0.487907 0.998946 0.606803 0.49669 0.663218 0.504177 0.780324 0.56527 0.88776 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 16
Initial state: 0 0.430917 0.69892 0.994262 0.556432 0.222762 0.0339005 0.501754 0.275566 0.124217 0.263968 0.379831 0.371467 0.91343 0.56303 0.137051 0.876177 0.65788 0.999946 0.63134 0.542818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84637 episodes
GETTING ACTION FROM:
action 6, numVisits=84614, meanQ=21.459110, numObservations: 9
action 3, numVisits=9, meanQ=14.495000, numObservations: 6
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 1 0.430917 0.69892 0.994262 0.556432 0.222762 0.0339005 0.501754 0.275566 0.124217 0.263968 0.379831 0.371467 0.91343 0.56303 0.137051 0.876177 0.65788 0.999946 0.63134 0.542818 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 17
Initial state: 0 0.158502 0.0181738 0.847954 0.0179094 0.875686 0.600854 0.820322 0.324399 0.606243 0.383086 0.873034 0.380612 0.912187 0.959729 0.547063 0.491951 0.437459 0.426663 0.420699 0.00327772 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83894 episodes
GETTING ACTION FROM:
action 10, numVisits=83873, meanQ=24.025354, numObservations: 9
action 2, numVisits=5, meanQ=15.000000, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 9, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 10
Next state: 2 0.158502 0.0181738 0.847954 0.0179094 0.875686 0.600854 0.820322 0.324399 0.606243 0.383086 0.873034 0.380612 0.912187 0.959729 0.547063 0.491951 0.437459 0.426663 0.420699 0.00327772 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 18
Initial state: 0 0.991349 0.32548 0.963174 0.0617038 0.681318 0.868654 0.629615 0.776581 0.500289 0.867916 0.974586 0.787943 0.758085 0.864364 0.473493 0.415643 0.210018 0.351564 0.711277 0.299769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 58180 episodes
GETTING ACTION FROM:
action 7, numVisits=58143, meanQ=18.914438, numObservations: 9
action -1, numVisits=13, meanQ=-1.050000, numObservations: 13
action 0, numVisits=13, meanQ=-1.050000, numObservations: 13
action 10, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 1 0.991349 0.32548 0.963174 0.0617038 0.681318 0.868654 0.629615 0.776581 0.500289 0.867916 0.974586 0.787943 0.758085 0.864364 0.473493 0.415643 0.210018 0.351564 0.711277 0.299769 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 19
Initial state: 0 0.607423 0.976986 0.994073 0.828341 0.521415 0.361932 0.133088 0.14652 0.33326 0.94468 0.843824 0.219525 0.419349 0.0018411 0.556804 0.0793404 0.598557 0.191347 0.0169326 0.689818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83772 episodes
GETTING ACTION FROM:
action 8, numVisits=83700, meanQ=21.240265, numObservations: 9
action 10, numVisits=51, meanQ=11.427794, numObservations: 9
action 1, numVisits=8, meanQ=10.250000, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 7, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 2 0.607423 0.976986 0.994073 0.828341 0.521415 0.361932 0.133088 0.14652 0.33326 0.94468 0.843824 0.219525 0.419349 0.0018411 0.556804 0.0793404 0.598557 0.191347 0.0169326 0.689818 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 20
Initial state: 0 0.252975 0.162501 0.189144 0.0668649 0.684788 0.672853 0.701752 0.633747 0.163649 0.174535 0.634921 0.945638 0.196188 0.571772 0.60728 0.184459 0.518794 0.411872 0.346925 0.790382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87632 episodes
GETTING ACTION FROM:
action 9, numVisits=87610, meanQ=22.682320, numObservations: 9
action 8, numVisits=5, meanQ=15.190000, numObservations: 5
action 5, numVisits=6, meanQ=14.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 6, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 9
Next state: 1 0.252975 0.162501 0.189144 0.0668649 0.684788 0.672853 0.701752 0.633747 0.163649 0.174535 0.634921 0.945638 0.196188 0.571772 0.60728 0.184459 0.518794 0.411872 0.346925 0.790382 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 21
Initial state: 0 0.935699 0.963002 0.313794 0.603436 0.65941 0.546066 0.913957 0.251808 0.0322309 0.646814 0.890087 0.701435 0.537816 0.167639 0.905809 0.254161 0.944875 0.214937 0.4483 0.368512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 59213 episodes
GETTING ACTION FROM:
action 7, numVisits=59171, meanQ=19.873368, numObservations: 9
action 10, numVisits=10, meanQ=15.595000, numObservations: 7
action 2, numVisits=17, meanQ=13.226618, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 9, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 2 0.935699 0.963002 0.313794 0.603436 0.65941 0.546066 0.913957 0.251808 0.0322309 0.646814 0.890087 0.701435 0.537816 0.167639 0.905809 0.254161 0.944875 0.214937 0.4483 0.368512 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 22
Initial state: 0 0.793429 0.24785 0.267762 0.408489 0.941689 0.814076 0.390912 0.442796 0.671542 0.707195 0.644564 0.428786 0.376035 0.778627 0.422365 0.659298 0.856759 0.300124 0.261515 0.981237 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90122 episodes
GETTING ACTION FROM:
action 7, numVisits=90110, meanQ=21.546475, numObservations: 9
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 1 0.793429 0.24785 0.267762 0.408489 0.941689 0.814076 0.390912 0.442796 0.671542 0.707195 0.644564 0.428786 0.376035 0.778627 0.422365 0.659298 0.856759 0.300124 0.261515 0.981237 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 23
Initial state: 0 0.461547 0.466597 0.922411 0.141331 0.434874 0.102153 0.200426 0.308333 0.451714 0.848926 0.250915 0.0588268 0.530255 0.532834 0.0459694 0.558794 0.973188 0.128468 0.202648 0.94995 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85767 episodes
GETTING ACTION FROM:
action 5, numVisits=85728, meanQ=23.955251, numObservations: 9
action 7, numVisits=12, meanQ=11.616875, numObservations: 6
action 6, numVisits=6, meanQ=10.983333, numObservations: 5
action 9, numVisits=13, meanQ=9.615769, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.461547 0.466597 0.922411 0.141331 0.434874 0.102153 0.200426 0.308333 0.451714 0.848926 0.250915 0.0588268 0.530255 0.532834 0.0459694 0.558794 0.973188 0.128468 0.202648 0.94995 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 24
Initial state: 0 0.814629 0.420561 0.840917 0.280776 0.648089 0.409454 0.574432 0.900758 0.599624 0.495778 0.96057 0.0325957 0.491452 0.400733 0.291943 0.543122 0.0843828 0.74511 0.25039 0.893229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88199 episodes
GETTING ACTION FROM:
action 6, numVisits=88181, meanQ=22.105280, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 2 0.814629 0.420561 0.840917 0.280776 0.648089 0.409454 0.574432 0.900758 0.599624 0.495778 0.96057 0.0325957 0.491452 0.400733 0.291943 0.543122 0.0843828 0.74511 0.25039 0.893229 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 25
Initial state: 0 0.259588 0.314163 0.118952 0.14887 0.736642 0.0227056 0.0237096 0.597987 0.0495209 0.87904 0.452464 0.392097 0.971031 0.308222 0.528863 0.234036 0.707607 0.761183 0.0873865 0.986016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82473 episodes
GETTING ACTION FROM:
action 6, numVisits=82455, meanQ=20.558126, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=4, meanQ=-6.000000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 1 0.259588 0.314163 0.118952 0.14887 0.736642 0.0227056 0.0237096 0.597987 0.0495209 0.87904 0.452464 0.392097 0.971031 0.308222 0.528863 0.234036 0.707607 0.761183 0.0873865 0.986016 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 26
Initial state: 0 0.376323 0.47703 0.420724 0.919245 0.247116 0.185588 0.986449 0.545402 0.738056 0.126137 0.0789965 0.385801 0.971483 0.707279 0.157641 0.578046 0.392348 0.0924086 0.985094 0.86913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 59673 episodes
GETTING ACTION FROM:
action 1, numVisits=59615, meanQ=20.323826, numObservations: 9
action 6, numVisits=41, meanQ=14.734451, numObservations: 9
action 5, numVisits=5, meanQ=12.000000, numObservations: 4
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.376323 0.47703 0.420724 0.919245 0.247116 0.185588 0.986449 0.545402 0.738056 0.126137 0.0789965 0.385801 0.971483 0.707279 0.157641 0.578046 0.392348 0.0924086 0.985094 0.86913 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 27
Initial state: 0 0.407408 0.397381 0.860411 0.510336 0.177417 0.772724 0.95765 0.237168 0.170051 0.013818 0.805465 0.465276 0.737467 0.705455 0.182056 0.39579 0.414543 0.903797 0.776713 0.128737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84728 episodes
GETTING ACTION FROM:
action 6, numVisits=84704, meanQ=24.212993, numObservations: 9
action 1, numVisits=9, meanQ=18.100000, numObservations: 7
action 2, numVisits=4, meanQ=16.975000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 2 0.407408 0.397381 0.860411 0.510336 0.177417 0.772724 0.95765 0.237168 0.170051 0.013818 0.805465 0.465276 0.737467 0.705455 0.182056 0.39579 0.414543 0.903797 0.776713 0.128737 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 28
Initial state: 0 0.511583 0.219942 0.518947 0.369379 0.698833 0.484874 0.364848 0.645245 0.372186 0.852766 0.179594 0.495982 0.870072 0.618311 0.312247 0.601192 0.714817 0.690515 0.173533 0.736039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77443 episodes
GETTING ACTION FROM:
action 6, numVisits=77403, meanQ=23.091933, numObservations: 9
action 8, numVisits=22, meanQ=17.859318, numObservations: 9
action 1, numVisits=7, meanQ=10.428571, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-6.316667, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 2 0.511583 0.219942 0.518947 0.369379 0.698833 0.484874 0.364848 0.645245 0.372186 0.852766 0.179594 0.495982 0.870072 0.618311 0.312247 0.601192 0.714817 0.690515 0.173533 0.736039 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 29
Initial state: 0 0.412211 0.347959 0.150482 0.761271 0.41622 0.66221 0.683025 0.939526 0.173036 0.818961 0.368781 0.515802 0.328391 0.82976 0.146542 0.0979162 0.624401 0.492196 0.701298 0.164151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90205 episodes
GETTING ACTION FROM:
action 8, numVisits=90177, meanQ=22.550012, numObservations: 9
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 5, numVisits=11, meanQ=-3.727273, numObservations: 7
action 9, numVisits=4, meanQ=-7.250000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 0 0.412211 0.347959 0.150482 0.761271 0.41622 0.66221 0.683025 0.939526 0.173036 0.818961 0.368781 0.515802 0.328391 0.82976 0.146542 0.0979162 0.624401 0.492196 0.701298 0.164151 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7158, meanQ=27.978652, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 7, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18184 episodes
GETTING ACTION FROM:
action 1, numVisits=25342, meanQ=25.141253, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 7, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.412211 0.347959 0.150482 0.761271 0.41622 0.66221 0.683025 0.939526 0.173036 0.818961 0.368781 0.515802 0.328391 0.82976 0.146542 0.0979162 0.624401 0.492196 0.701298 0.164151 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 30
Initial state: 0 0.333859 0.295738 0.913355 0.423271 0.776606 0.659874 0.86333 0.553199 0.536393 0.255799 0.770449 0.3677 0.527648 0.331554 0.219273 0.903422 0.653616 0.564448 0.570065 0.661001 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 62403 episodes
GETTING ACTION FROM:
action 7, numVisits=62305, meanQ=22.406940, numObservations: 9
action 8, numVisits=35, meanQ=20.963143, numObservations: 9
action 6, numVisits=9, meanQ=20.111111, numObservations: 5
action 2, numVisits=38, meanQ=18.088487, numObservations: 8
action 4, numVisits=5, meanQ=15.190000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 9, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 1 0.333859 0.295738 0.913355 0.423271 0.776606 0.659874 0.86333 0.553199 0.536393 0.255799 0.770449 0.3677 0.527648 0.331554 0.219273 0.903422 0.653616 0.564448 0.570065 0.661001 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 31
Initial state: 0 0.884875 0.830934 0.520086 0.42425 0.740909 0.430022 0.333185 0.358005 0.438227 0.594671 0.157288 0.273472 0.748276 0.412028 0.365467 0.225985 0.674154 0.831436 0.506367 0.19935 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 73753 episodes
GETTING ACTION FROM:
action 1, numVisits=73735, meanQ=22.767568, numObservations: 9
action 8, numVisits=5, meanQ=15.190000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 7, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.884875 0.830934 0.520086 0.42425 0.740909 0.430022 0.333185 0.358005 0.438227 0.594671 0.157288 0.273472 0.748276 0.412028 0.365467 0.225985 0.674154 0.831436 0.506367 0.19935 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 32
Initial state: 0 0.0478236 0.115107 0.301842 0.114365 0.362587 0.963746 0.428223 0.385235 0.384099 0.84165 0.864262 0.702371 0.835328 0.864255 0.265272 0.0316518 0.365904 0.780904 0.958419 0.253458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87963 episodes
GETTING ACTION FROM:
action 8, numVisits=87897, meanQ=21.955363, numObservations: 9
action 7, numVisits=25, meanQ=18.758200, numObservations: 9
action 6, numVisits=26, meanQ=16.271154, numObservations: 9
action 4, numVisits=6, meanQ=14.000000, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 0 0.0478236 0.115107 0.301842 0.114365 0.362587 0.963746 0.428223 0.385235 0.384099 0.84165 0.864262 0.702371 0.835328 0.864255 0.265272 0.0316518 0.365904 0.780904 0.958419 0.253458 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 9, numVisits=7096, meanQ=25.164148, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 7, numVisits=3, meanQ=-4.016667, numObservations: 3
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25359 episodes
GETTING ACTION FROM:
action 9, numVisits=32455, meanQ=18.171018, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 7, numVisits=3, meanQ=-4.016667, numObservations: 3
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 9
Next state: 2 0.0478236 0.115107 0.301842 0.114365 0.362587 0.963746 0.428223 0.385235 0.384099 0.84165 0.864262 0.702371 0.835328 0.864255 0.265272 0.0316518 0.365904 0.780904 0.958419 0.253458 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 33
Initial state: 0 0.725855 0.611633 0.0685061 0.330654 0.492613 0.424454 0.356732 0.90807 0.19248 0.174172 0.034543 0.261034 0.36685 0.862676 0.349215 0.191811 0.537682 0.0672803 0.726303 0.440803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88729 episodes
GETTING ACTION FROM:
action 6, numVisits=88694, meanQ=22.238482, numObservations: 9
action 8, numVisits=4, meanQ=16.737500, numObservations: 4
action 7, numVisits=10, meanQ=8.000000, numObservations: 7
action 2, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 10, numVisits=5, meanQ=-3.000000, numObservations: 5
action 4, numVisits=4, meanQ=-6.000000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 0 0.725855 0.611633 0.0685061 0.330654 0.492613 0.424454 0.356732 0.90807 0.19248 0.174172 0.034543 0.261034 0.36685 0.862676 0.349215 0.191811 0.537682 0.0672803 0.726303 0.440803 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=7177, meanQ=24.746308, numObservations: 9
action 7, numVisits=17, meanQ=19.867647, numObservations: 9
action 9, numVisits=5, meanQ=19.000000, numObservations: 5
action 8, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 6, numVisits=1, meanQ=-10.050000, numObservations: 1
action 10, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 24963 episodes
GETTING ACTION FROM:
action 7, numVisits=15801, meanQ=24.136480, numObservations: 9
action 4, numVisits=16317, meanQ=22.194261, numObservations: 9
action 9, numVisits=44, meanQ=19.012795, numObservations: 9
action 8, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 6, numVisits=1, meanQ=-10.050000, numObservations: 1
action 10, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 7
Next state: 1 0.725855 0.611633 0.0685061 0.330654 0.492613 0.424454 0.356732 0.90807 0.19248 0.174172 0.034543 0.261034 0.36685 0.862676 0.349215 0.191811 0.537682 0.0672803 0.726303 0.440803 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 34
Initial state: 0 0.992285 0.168787 0.104758 0.804673 0.0878253 0.707729 0.178099 0.420548 0.928119 0.269154 0.962542 0.340877 0.651851 0.369626 0.976438 0.0217766 0.368052 0.363516 0.145653 0.248358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84406 episodes
GETTING ACTION FROM:
action 2, numVisits=84339, meanQ=23.805645, numObservations: 9
action 1, numVisits=35, meanQ=16.223000, numObservations: 8
action 8, numVisits=5, meanQ=15.000000, numObservations: 5
action 3, numVisits=19, meanQ=10.502763, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.992285 0.168787 0.104758 0.804673 0.0878253 0.707729 0.178099 0.420548 0.928119 0.269154 0.962542 0.340877 0.651851 0.369626 0.976438 0.0217766 0.368052 0.363516 0.145653 0.248358 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 35
Initial state: 0 0.396503 0.944741 0.873744 0.0536701 0.216573 0.265632 0.23294 0.367525 0.831159 0.903647 0.421618 0.107583 0.979063 0.0779283 0.0659164 0.253258 0.457241 0.398839 0.41756 0.322141 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89709 episodes
GETTING ACTION FROM:
action 2, numVisits=89688, meanQ=22.417455, numObservations: 9
action 6, numVisits=7, meanQ=10.428571, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.396503 0.944741 0.873744 0.0536701 0.216573 0.265632 0.23294 0.367525 0.831159 0.903647 0.421618 0.107583 0.979063 0.0779283 0.0659164 0.253258 0.457241 0.398839 0.41756 0.322141 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 36
Initial state: 0 0.6422 0.0745667 0.697204 0.304044 0.408032 0.500261 0.907953 0.692453 0.155523 0.159794 0.923627 0.0828868 0.110867 0.415003 0.424231 0.214432 0.618259 0.346868 0.662773 0.409462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87728 episodes
GETTING ACTION FROM:
action 6, numVisits=87670, meanQ=22.079701, numObservations: 9
action 10, numVisits=30, meanQ=6.863417, numObservations: 8
action 9, numVisits=13, meanQ=5.226923, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 8, numVisits=5, meanQ=-3.000000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 2 0.6422 0.0745667 0.697204 0.304044 0.408032 0.500261 0.907953 0.692453 0.155523 0.159794 0.923627 0.0828868 0.110867 0.415003 0.424231 0.214432 0.618259 0.346868 0.662773 0.409462 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 37
Initial state: 0 0.869394 0.822935 0.293454 0.501608 0.714863 0.978463 0.675443 0.0820128 0.650897 0.28325 0.277229 0.714419 0.627962 0.821208 0.271115 0.477897 0.484244 0.433518 0.381596 0.670696 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86948 episodes
GETTING ACTION FROM:
action 6, numVisits=86915, meanQ=22.073969, numObservations: 9
action 1, numVisits=22, meanQ=19.822727, numObservations: 6
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 1 0.869394 0.822935 0.293454 0.501608 0.714863 0.978463 0.675443 0.0820128 0.650897 0.28325 0.277229 0.714419 0.627962 0.821208 0.271115 0.477897 0.484244 0.433518 0.381596 0.670696 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 38
Initial state: 0 0.0267064 0.902044 0.514864 0.503696 0.0738445 0.421502 0.514058 0.0909491 0.593371 0.9037 0.860315 0.864806 0.218771 0.607243 0.469629 0.482835 0.220725 0.383666 0.303375 0.0491567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89567 episodes
GETTING ACTION FROM:
action 2, numVisits=89531, meanQ=21.942954, numObservations: 9
action 10, numVisits=9, meanQ=17.883611, numObservations: 4
action 9, numVisits=6, meanQ=14.000000, numObservations: 5
action 3, numVisits=7, meanQ=10.564286, numObservations: 5
action 5, numVisits=7, meanQ=10.564286, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0267064 0.902044 0.514864 0.503696 0.0738445 0.421502 0.514058 0.0909491 0.593371 0.9037 0.860315 0.864806 0.218771 0.607243 0.469629 0.482835 0.220725 0.383666 0.303375 0.0491567 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 39
Initial state: 0 0.385499 0.335547 0.157803 0.101912 0.770907 0.385473 0.575056 0.956852 0.701305 0.498396 0.331656 0.815172 0.768073 0.381465 0.323217 0.312798 0.420556 0.0357639 0.344674 0.155343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79312 episodes
GETTING ACTION FROM:
action 8, numVisits=79276, meanQ=20.647571, numObservations: 9
action 5, numVisits=17, meanQ=15.411912, numObservations: 6
action 10, numVisits=5, meanQ=15.190000, numObservations: 5
action 4, numVisits=6, meanQ=14.158333, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 0 0.385499 0.335547 0.157803 0.101912 0.770907 0.385473 0.575056 0.956852 0.701305 0.498396 0.331656 0.815172 0.768073 0.381465 0.323217 0.312798 0.420556 0.0357639 0.344674 0.155343 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 10, numVisits=6436, meanQ=23.717026, numObservations: 9
action 2, numVisits=19, meanQ=6.592237, numObservations: 7
action 1, numVisits=9, meanQ=6.088889, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 7, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 26244 episodes
GETTING ACTION FROM:
action 10, numVisits=32680, meanQ=20.363276, numObservations: 9
action 2, numVisits=19, meanQ=6.592237, numObservations: 7
action 1, numVisits=9, meanQ=6.088889, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 7, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 10
Next state: 2 0.385499 0.335547 0.157803 0.101912 0.770907 0.385473 0.575056 0.956852 0.701305 0.498396 0.331656 0.815172 0.768073 0.381465 0.323217 0.312798 0.420556 0.0357639 0.344674 0.155343 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 40
Initial state: 0 0.518711 0.493935 0.523966 0.630293 0.693608 0.671858 0.809225 0.455883 0.279035 0.954317 0.231653 0.955851 0.843246 0.826003 0.176927 0.331159 0.646311 0.677148 0.142998 0.888443 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 66997 episodes
GETTING ACTION FROM:
action 2, numVisits=66953, meanQ=20.256740, numObservations: 9
action -1, numVisits=12, meanQ=-1.050000, numObservations: 12
action 0, numVisits=12, meanQ=-1.050000, numObservations: 12
action 9, numVisits=3, meanQ=-4.333333, numObservations: 3
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=10, meanQ=-12.000000, numObservations: 6
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.518711 0.493935 0.523966 0.630293 0.693608 0.671858 0.809225 0.455883 0.279035 0.954317 0.231653 0.955851 0.843246 0.826003 0.176927 0.331159 0.646311 0.677148 0.142998 0.888443 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.995394 0.322186 0.334127 0.0337428 0.0443951 0.709244 0.358879 0.426353 0.229695 0.162439 0.0707907 0.953863 0.369538 0.690866 0.995247 0.663665 0.481745 0.849886 0.316556 0.985986 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86527 episodes
GETTING ACTION FROM:
action 7, numVisits=86463, meanQ=22.925945, numObservations: 9
action 8, numVisits=18, meanQ=20.163889, numObservations: 7
action 5, numVisits=26, meanQ=19.575192, numObservations: 9
action 4, numVisits=4, meanQ=16.737500, numObservations: 4
action 3, numVisits=5, meanQ=15.190000, numObservations: 4
action 1, numVisits=5, meanQ=15.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 1 0.995394 0.322186 0.334127 0.0337428 0.0443951 0.709244 0.358879 0.426353 0.229695 0.162439 0.0707907 0.953863 0.369538 0.690866 0.995247 0.663665 0.481745 0.849886 0.316556 0.985986 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 42
Initial state: 0 0.323787 0.8117 0.223319 0.205934 0.244938 0.622208 0.3597 0.384953 0.679853 0.460316 0.663517 0.974063 0.65829 0.69608 0.486933 0.159932 0.349407 0.62464 0.627732 0.157682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88884 episodes
GETTING ACTION FROM:
action 2, numVisits=88859, meanQ=21.969504, numObservations: 9
action 8, numVisits=12, meanQ=6.500000, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.323787 0.8117 0.223319 0.205934 0.244938 0.622208 0.3597 0.384953 0.679853 0.460316 0.663517 0.974063 0.65829 0.69608 0.486933 0.159932 0.349407 0.62464 0.627732 0.157682 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 43
Initial state: 0 0.857958 0.449687 0.792324 0.987091 0.53266 0.361684 0.0259007 0.325604 0.395012 0.822858 0.202554 0.728032 0.39884 0.50093 0.794066 0.625088 0.490437 0.706243 0.882577 0.867124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77212 episodes
GETTING ACTION FROM:
action 9, numVisits=77193, meanQ=21.987542, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=6, meanQ=-4.333333, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 9
Next state: 1 0.857958 0.449687 0.792324 0.987091 0.53266 0.361684 0.0259007 0.325604 0.395012 0.822858 0.202554 0.728032 0.39884 0.50093 0.794066 0.625088 0.490437 0.706243 0.882577 0.867124 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 44
Initial state: 0 0.109928 0.422983 0.00824308 0.667327 0.431894 0.117114 0.469696 0.219569 0.534854 0.888571 0.45629 0.339969 0.616015 0.564749 0.28354 0.315769 0.195784 0.678696 0.769899 0.190729 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88908 episodes
GETTING ACTION FROM:
action 4, numVisits=88859, meanQ=22.759446, numObservations: 9
action 8, numVisits=38, meanQ=17.054145, numObservations: 8
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.109928 0.422983 0.00824308 0.667327 0.431894 0.117114 0.469696 0.219569 0.534854 0.888571 0.45629 0.339969 0.616015 0.564749 0.28354 0.315769 0.195784 0.678696 0.769899 0.190729 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1838, meanQ=33.432982, numObservations: 9
action 10, numVisits=16, meanQ=21.615781, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 39640 episodes
GETTING ACTION FROM:
action 1, numVisits=41469, meanQ=7.057074, numObservations: 9
action 10, numVisits=21, meanQ=1.945357, numObservations: 8
action 0, numVisits=3, meanQ=-1.366667, numObservations: 3
action -1, numVisits=3, meanQ=-1.683333, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.109928 0.422983 0.00824308 0.667327 0.431894 0.117114 0.469696 0.219569 0.534854 0.888571 0.45629 0.339969 0.616015 0.564749 0.28354 0.315769 0.195784 0.678696 0.769899 0.190729 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 7, numVisits=560, meanQ=61.865040, numObservations: 9
action 6, numVisits=6, meanQ=13.166667, numObservations: 3
action 5, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=5, meanQ=-2.810000, numObservations: 4
action 9, numVisits=4, meanQ=-6.011875, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 10, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31023 episodes
GETTING ACTION FROM:
action 7, numVisits=31583, meanQ=22.465805, numObservations: 9
action 6, numVisits=6, meanQ=13.166667, numObservations: 3
action 5, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=5, meanQ=-2.810000, numObservations: 4
action 9, numVisits=4, meanQ=-6.011875, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 10, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 1 0.109928 0.422983 0.00824308 0.667327 0.431894 0.117114 0.469696 0.219569 0.534854 0.888571 0.45629 0.339969 0.616015 0.564749 0.28354 0.315769 0.195784 0.678696 0.769899 0.190729 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 45
Initial state: 0 0.792883 0.784127 0.0417711 0.669235 0.399441 0.736147 0.789877 0.979562 0.634615 0.901016 0.240587 0.14213 0.647352 0.392469 0.268677 0.74568 0.480457 0.404481 0.613916 0.193028 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85585 episodes
GETTING ACTION FROM:
action 3, numVisits=85493, meanQ=22.028170, numObservations: 9
action 9, numVisits=17, meanQ=18.438382, numObservations: 7
action 4, numVisits=64, meanQ=17.869805, numObservations: 9
action 6, numVisits=2, meanQ=-1.000000, numObservations: 2
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.792883 0.784127 0.0417711 0.669235 0.399441 0.736147 0.789877 0.979562 0.634615 0.901016 0.240587 0.14213 0.647352 0.392469 0.268677 0.74568 0.480457 0.404481 0.613916 0.193028 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 46
Initial state: 0 0.403877 0.353611 0.879331 0.9802 0.842935 0.423833 0.146842 0.143816 0.680045 0.217907 0.767839 0.331362 0.00448048 0.817671 0.245237 0.0543993 0.451363 0.326605 0.788607 0.757621 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88713 episodes
GETTING ACTION FROM:
action 3, numVisits=88675, meanQ=22.466625, numObservations: 9
action 5, numVisits=22, meanQ=19.193295, numObservations: 8
action 2, numVisits=5, meanQ=14.800500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.403877 0.353611 0.879331 0.9802 0.842935 0.423833 0.146842 0.143816 0.680045 0.217907 0.767839 0.331362 0.00448048 0.817671 0.245237 0.0543993 0.451363 0.326605 0.788607 0.757621 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 47
Initial state: 0 0.92216 0.728257 0.915393 0.907027 0.60125 0.527393 0.0516391 0.292944 0.0303728 0.358484 0.599472 0.108556 0.227179 0.627424 0.601015 0.884946 0.0258082 0.0809135 0.414387 0.348102 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87274 episodes
GETTING ACTION FROM:
action 3, numVisits=87256, meanQ=23.010403, numObservations: 9
action 7, numVisits=5, meanQ=19.000000, numObservations: 4
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 9, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.92216 0.728257 0.915393 0.907027 0.60125 0.527393 0.0516391 0.292944 0.0303728 0.358484 0.599472 0.108556 0.227179 0.627424 0.601015 0.884946 0.0258082 0.0809135 0.414387 0.348102 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 48
Initial state: 0 0.949829 0.46828 0.764816 0.0529657 0.772998 0.127904 0.988128 0.77904 0.4427 0.714075 0.661077 0.2344 0.92432 0.0689009 0.0167034 0.0805028 0.495449 0.414143 0.549376 0.499566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87341 episodes
GETTING ACTION FROM:
action 3, numVisits=87298, meanQ=22.217305, numObservations: 9
action 6, numVisits=14, meanQ=17.671607, numObservations: 6
action 2, numVisits=13, meanQ=16.765385, numObservations: 7
action 5, numVisits=5, meanQ=15.190000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 8, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.949829 0.46828 0.764816 0.0529657 0.772998 0.127904 0.988128 0.77904 0.4427 0.714075 0.661077 0.2344 0.92432 0.0689009 0.0167034 0.0805028 0.495449 0.414143 0.549376 0.499566 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 49
Initial state: 0 0.00575316 0.169556 0.98829 0.458593 0.6658 0.745856 0.704287 0.0642984 0.42382 0.674172 0.54557 0.495035 0.692047 0.0921821 0.458113 0.775294 0.478275 0.452185 0.0544997 0.996923 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88068 episodes
GETTING ACTION FROM:
action 8, numVisits=88052, meanQ=22.088805, numObservations: 9
action 1, numVisits=6, meanQ=14.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 2 0.00575316 0.169556 0.98829 0.458593 0.6658 0.745856 0.704287 0.0642984 0.42382 0.674172 0.54557 0.495035 0.692047 0.0921821 0.458113 0.775294 0.478275 0.452185 0.0544997 0.996923 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 50
Initial state: 0 0.762469 0.35989 0.521985 0.329038 0.664989 0.248709 0.310866 0.630512 0.0675861 0.122619 0.530923 0.215557 0.335615 0.15356 0.266185 0.0554027 0.362571 0.954537 0.158184 0.0148656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86598 episodes
GETTING ACTION FROM:
action 6, numVisits=86504, meanQ=22.090100, numObservations: 9
action 3, numVisits=69, meanQ=20.776196, numObservations: 8
action 4, numVisits=13, meanQ=11.307692, numObservations: 7
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 10, numVisits=3, meanQ=-4.333333, numObservations: 3
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 2 0.762469 0.35989 0.521985 0.329038 0.664989 0.248709 0.310866 0.630512 0.0675861 0.122619 0.530923 0.215557 0.335615 0.15356 0.266185 0.0554027 0.362571 0.954537 0.158184 0.0148656 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
[32m ProblemEnvironment.hpp 351: Done.[39m
