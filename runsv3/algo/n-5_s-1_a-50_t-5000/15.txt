Run # 1
Initial state: 0 0.155587 0.84581 0.011237 0.405473 0.288541 0.896132 0.53228 0.385637 0.457789 0.468167 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 145598 episodes
GETTING ACTION FROM:
action 5, numVisits=145588, meanQ=28.156785, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=4, meanQ=-6.000000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.155587 0.84581 0.011237 0.405473 0.288541 0.896132 0.53228 0.385637 0.457789 0.468167 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 2
Initial state: 0 0.859355 0.0139418 0.299795 0.432027 0.190361 0.645935 0.697068 0.38302 0.294092 0.426018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80228 episodes
GETTING ACTION FROM:
action -1, numVisits=80179, meanQ=46.898100, numObservations: 243
action 0, numVisits=25, meanQ=-1.050000, numObservations: 25
action 2, numVisits=16, meanQ=-3.502969, numObservations: 7
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.859355 0.0139418 0.299795 0.432027 0.190361 0.645935 0.697068 0.38302 0.294092 0.426018 w: 1
Observation: 0 3 0 2 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=350, meanQ=84.229464, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 189084 episodes
GETTING ACTION FROM:
action 2, numVisits=189434, meanQ=87.129199, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.859355 0.0139418 0.299795 0.432027 0.190361 0.645935 0.697068 0.38302 0.294092 0.426018 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 3
Initial state: 0 0.623659 0.600551 0.505995 0.289595 0.442078 0.455864 0.651377 0.162808 0.488145 0.328462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 145202 episodes
GETTING ACTION FROM:
action 4, numVisits=145196, meanQ=29.317197, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.623659 0.600551 0.505995 0.289595 0.442078 0.455864 0.651377 0.162808 0.488145 0.328462 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 4
Initial state: 0 0.577754 0.830283 0.0409285 0.117697 0.349501 0.495086 0.926369 0.678166 0.549087 0.0524927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153581 episodes
GETTING ACTION FROM:
action 5, numVisits=153574, meanQ=27.162440, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.577754 0.830283 0.0409285 0.117697 0.349501 0.495086 0.926369 0.678166 0.549087 0.0524927 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 5
Initial state: 0 0.743335 0.23865 0.546588 0.334838 0.514422 0.0794971 0.381292 0.505973 0.0448464 0.683468 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 151498 episodes
GETTING ACTION FROM:
action 1, numVisits=151461, meanQ=28.428937, numObservations: 9
action 4, numVisits=30, meanQ=9.376917, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.743335 0.23865 0.546588 0.334838 0.514422 0.0794971 0.381292 0.505973 0.0448464 0.683468 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 6
Initial state: 0 0.462613 0.609089 0.0310921 0.28061 0.743902 0.203453 0.450877 0.43333 0.202037 0.767208 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156730 episodes
GETTING ACTION FROM:
action 4, numVisits=156659, meanQ=26.864595, numObservations: 9
action 1, numVisits=66, meanQ=18.455492, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.462613 0.609089 0.0310921 0.28061 0.743902 0.203453 0.450877 0.43333 0.202037 0.767208 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 7
Initial state: 0 0.799173 0.651383 0.383938 0.50186 0.618439 0.912758 0.186861 0.821223 0.473391 0.180472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 151850 episodes
GETTING ACTION FROM:
action 5, numVisits=151844, meanQ=28.754172, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.799173 0.651383 0.383938 0.50186 0.618439 0.912758 0.186861 0.821223 0.473391 0.180472 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 8
Initial state: 0 0.417536 0.470295 0.628971 0.833303 0.811283 0.0221428 0.164515 0.582291 0.502945 0.0106154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153030 episodes
GETTING ACTION FROM:
action 5, numVisits=152981, meanQ=27.594674, numObservations: 9
action 3, numVisits=43, meanQ=20.089593, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.417536 0.470295 0.628971 0.833303 0.811283 0.0221428 0.164515 0.582291 0.502945 0.0106154 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 9
Initial state: 0 0.427927 0.422273 0.710925 0.277197 0.29582 0.549647 0.296601 0.314195 0.65814 0.686769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156540 episodes
GETTING ACTION FROM:
action 4, numVisits=156533, meanQ=27.149511, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.427927 0.422273 0.710925 0.277197 0.29582 0.549647 0.296601 0.314195 0.65814 0.686769 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=11145, meanQ=31.261927, numObservations: 9
action 5, numVisits=12, meanQ=12.487708, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-6.000000, numObservations: 2
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 52021 episodes
GETTING ACTION FROM:
action 1, numVisits=63166, meanQ=31.878688, numObservations: 9
action 5, numVisits=12, meanQ=12.487708, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-6.000000, numObservations: 2
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.427927 0.422273 0.710925 0.277197 0.29582 0.549647 0.296601 0.314195 0.65814 0.686769 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1098, meanQ=87.300018, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 68527 episodes
GETTING ACTION FROM:
action 1, numVisits=1180, meanQ=87.585733, numObservations: 9
action 0, numVisits=68349, meanQ=3.279313, numObservations: 243
action -1, numVisits=94, meanQ=-2.950000, numObservations: 51
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=6, meanQ=-19.551099, numObservations: 4
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.427927 0.422273 0.710925 0.277197 0.29582 0.549647 0.296601 0.314195 0.65814 0.686769 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 10
Initial state: 0 0.0436883 0.365955 0.309097 0.687689 0.390814 0.917658 0.915857 0.540201 0.328872 0.503555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 146705 episodes
GETTING ACTION FROM:
action 2, numVisits=146693, meanQ=28.085141, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=6, meanQ=-1.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0436883 0.365955 0.309097 0.687689 0.390814 0.917658 0.915857 0.540201 0.328872 0.503555 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 11
Initial state: 0 0.339331 0.948469 0.543756 0.161913 0.562725 0.0439437 0.440995 0.410615 0.742655 0.907581 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156928 episodes
GETTING ACTION FROM:
action 5, numVisits=156919, meanQ=26.656568, numObservations: 9
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.339331 0.948469 0.543756 0.161913 0.562725 0.0439437 0.440995 0.410615 0.742655 0.907581 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 12
Initial state: 0 0.399893 0.429037 0.25387 0.311207 0.292121 0.780621 0.573505 0.230943 0.99782 0.62343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80924 episodes
GETTING ACTION FROM:
action -1, numVisits=80910, meanQ=47.565137, numObservations: 243
action 0, numVisits=9, meanQ=-11.816667, numObservations: 8
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.399893 0.429037 0.25387 0.311207 0.292121 0.780621 0.573505 0.230943 0.99782 0.62343 w: 1
Observation: 0 2 0 1 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=393, meanQ=81.237449, numObservations: 9
action 3, numVisits=4, meanQ=44.475000, numObservations: 3
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 187495 episodes
GETTING ACTION FROM:
action 1, numVisits=187888, meanQ=80.031282, numObservations: 9
action 3, numVisits=4, meanQ=44.475000, numObservations: 3
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.399893 0.429037 0.25387 0.311207 0.292121 0.780621 0.573505 0.230943 0.99782 0.62343 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 13
Initial state: 0 0.0241107 0.594133 0.122499 0.586449 0.946371 0.974807 0.161204 0.923889 0.332618 0.410819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159941 episodes
GETTING ACTION FROM:
action 5, numVisits=159920, meanQ=27.202392, numObservations: 9
action 0, numVisits=10, meanQ=-1.050000, numObservations: 10
action -1, numVisits=7, meanQ=-1.328214, numObservations: 6
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0241107 0.594133 0.122499 0.586449 0.946371 0.974807 0.161204 0.923889 0.332618 0.410819 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 14
Initial state: 0 0.04467 0.327791 0.308083 0.430202 0.580634 0.517541 0.987095 0.0910957 0.378393 0.0926129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162883 episodes
GETTING ACTION FROM:
action 2, numVisits=162841, meanQ=26.340826, numObservations: 9
action 3, numVisits=37, meanQ=16.106959, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.04467 0.327791 0.308083 0.430202 0.580634 0.517541 0.987095 0.0910957 0.378393 0.0926129 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 15
Initial state: 0 0.30172 0.396245 0.380036 0.0891119 0.426272 0.079572 0.963536 0.218481 0.401723 0.675107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160849 episodes
GETTING ACTION FROM:
action 4, numVisits=160807, meanQ=26.093502, numObservations: 9
action 2, numVisits=19, meanQ=18.260526, numObservations: 8
action 5, numVisits=4, meanQ=16.975000, numObservations: 4
action 3, numVisits=16, meanQ=15.934375, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.30172 0.396245 0.380036 0.0891119 0.426272 0.079572 0.963536 0.218481 0.401723 0.675107 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 16
Initial state: 0 0.658861 0.384204 0.947898 0.665881 0.696149 0.531186 0.347836 0.414583 0.679671 0.902963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158600 episodes
GETTING ACTION FROM:
action 2, numVisits=158587, meanQ=26.362302, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=6, meanQ=-4.333333, numObservations: 5
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.658861 0.384204 0.947898 0.665881 0.696149 0.531186 0.347836 0.414583 0.679671 0.902963 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 17
Initial state: 0 0.970895 0.0671274 0.340643 0.462941 0.417024 0.5895 0.651058 0.139698 0.526533 0.672136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159851 episodes
GETTING ACTION FROM:
action 4, numVisits=159833, meanQ=26.237420, numObservations: 9
action 3, numVisits=11, meanQ=22.545682, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.970895 0.0671274 0.340643 0.462941 0.417024 0.5895 0.651058 0.139698 0.526533 0.672136 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 18
Initial state: 0 0.311614 0.502378 0.661266 0.766482 0.290912 0.187386 0.0140974 0.735171 0.17655 0.968978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 149866 episodes
GETTING ACTION FROM:
action 5, numVisits=149851, meanQ=28.142240, numObservations: 9
action 2, numVisits=7, meanQ=13.285714, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.311614 0.502378 0.661266 0.766482 0.290912 0.187386 0.0140974 0.735171 0.17655 0.968978 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2819, meanQ=29.110651, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 120607 episodes
GETTING ACTION FROM:
action 4, numVisits=123426, meanQ=26.224865, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.311614 0.502378 0.661266 0.766482 0.290912 0.187386 0.0140974 0.735171 0.17655 0.968978 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1577, meanQ=40.158974, numObservations: 9
action 2, numVisits=35, meanQ=34.085445, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 100720 episodes
GETTING ACTION FROM:
action 2, numVisits=99927, meanQ=43.766682, numObservations: 9
action 1, numVisits=2405, meanQ=35.462714, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.311614 0.502378 0.661266 0.766482 0.290912 0.187386 0.0140974 0.735171 0.17655 0.968978 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 19
Initial state: 0 0.0409332 0.147011 0.141974 0.165126 0.323658 0.405723 0.261179 0.201419 0.454925 0.995833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81310 episodes
GETTING ACTION FROM:
action 0, numVisits=81285, meanQ=60.962888, numObservations: 243
action -1, numVisits=11, meanQ=-1.050000, numObservations: 11
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=8, meanQ=-14.750000, numObservations: 6
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0409332 0.147011 0.141974 0.165126 0.323658 0.405723 0.261179 0.201419 0.454925 0.995833 w: 1
Observation: 0 0 1 0 1 0 2 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=367, meanQ=82.704629, numObservations: 9
action -1, numVisits=32, meanQ=-7.349688, numObservations: 26
action 0, numVisits=14, meanQ=-8.110536, numObservations: 12
action 5, numVisits=4, meanQ=-8.149375, numObservations: 2
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 191570 episodes
GETTING ACTION FROM:
action 3, numVisits=191937, meanQ=90.449587, numObservations: 9
action -1, numVisits=32, meanQ=-7.349688, numObservations: 26
action 0, numVisits=14, meanQ=-8.110536, numObservations: 12
action 5, numVisits=4, meanQ=-8.149375, numObservations: 2
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.0409332 0.147011 0.141974 0.165126 0.323658 0.405723 0.261179 0.201419 0.454925 0.995833 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 20
Initial state: 0 0.827524 0.593347 0.0702541 0.512106 0.206076 0.932359 0.312508 0.465455 0.0204536 0.340372 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158526 episodes
GETTING ACTION FROM:
action 1, numVisits=158513, meanQ=26.827702, numObservations: 9
action 5, numVisits=4, meanQ=16.975000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=4, meanQ=-7.250000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.827524 0.593347 0.0702541 0.512106 0.206076 0.932359 0.312508 0.465455 0.0204536 0.340372 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 21
Initial state: 0 0.56786 0.728324 0.21562 0.231371 0.26457 0.785276 0.302108 0.441471 0.447156 0.187446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161452 episodes
GETTING ACTION FROM:
action 5, numVisits=161438, meanQ=26.698937, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=9, meanQ=-4.338611, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.56786 0.728324 0.21562 0.231371 0.26457 0.785276 0.302108 0.441471 0.447156 0.187446 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2934, meanQ=27.739468, numObservations: 9
action 1, numVisits=5, meanQ=12.190000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 83099 episodes
GETTING ACTION FROM:
action 3, numVisits=86032, meanQ=16.275821, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=6, meanQ=-6.675000, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 0 0.56786 0.728324 0.21562 0.231371 0.26457 0.785276 0.302108 0.441471 0.447156 0.187446 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=892, meanQ=68.646740, numObservations: 9
action 0, numVisits=46, meanQ=-3.905163, numObservations: 36
action -1, numVisits=26, meanQ=-6.361902, numObservations: 19
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 116383 episodes
GETTING ACTION FROM:
action 4, numVisits=117275, meanQ=17.728038, numObservations: 9
action 0, numVisits=46, meanQ=-3.905163, numObservations: 36
action -1, numVisits=26, meanQ=-6.361902, numObservations: 19
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.56786 0.728324 0.21562 0.231371 0.26457 0.785276 0.302108 0.441471 0.447156 0.187446 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=388, meanQ=83.420481, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-12.483487, numObservations: 1
action 3, numVisits=1, meanQ=-12.558696, numObservations: 1
action 5, numVisits=1, meanQ=-214.164134, numObservations: 1
Sampled 179873 episodes
GETTING ACTION FROM:
action 4, numVisits=180261, meanQ=90.709919, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-12.483487, numObservations: 1
action 3, numVisits=1, meanQ=-12.558696, numObservations: 1
action 5, numVisits=1, meanQ=-214.164134, numObservations: 1
action: 4
Next state: 1 0.56786 0.728324 0.21562 0.231371 0.26457 0.785276 0.302108 0.441471 0.447156 0.187446 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 53.5026
Run # 22
Initial state: 0 0.309379 0.458725 0.592004 0.821137 0.49222 0.272888 0.758122 0.093841 0.88224 0.110767 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147646 episodes
GETTING ACTION FROM:
action 4, numVisits=147638, meanQ=28.281470, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.309379 0.458725 0.592004 0.821137 0.49222 0.272888 0.758122 0.093841 0.88224 0.110767 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 23
Initial state: 0 0.417238 0.484832 0.0195429 0.102002 0.413368 0.138511 0.161201 0.367017 0.924272 0.440924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161409 episodes
GETTING ACTION FROM:
action 2, numVisits=161369, meanQ=27.217047, numObservations: 9
action -1, numVisits=19, meanQ=-6.150000, numObservations: 18
action 0, numVisits=17, meanQ=-6.750000, numObservations: 16
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.417238 0.484832 0.0195429 0.102002 0.413368 0.138511 0.161201 0.367017 0.924272 0.440924 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=11546, meanQ=31.069471, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 49216 episodes
GETTING ACTION FROM:
action 1, numVisits=60762, meanQ=31.059639, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 0 0.417238 0.484832 0.0195429 0.102002 0.413368 0.138511 0.161201 0.367017 0.924272 0.440924 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=956, meanQ=50.658297, numObservations: 153
action -1, numVisits=6, meanQ=-1.050000, numObservations: 6
action 4, numVisits=30, meanQ=-1.591417, numObservations: 9
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 68586 episodes
GETTING ACTION FROM:
action 0, numVisits=69542, meanQ=4.135760, numObservations: 243
action -1, numVisits=6, meanQ=-1.050000, numObservations: 6
action 4, numVisits=30, meanQ=-1.591417, numObservations: 9
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 0
Next state: 0 0.417238 0.484832 0.0195429 0.102002 0.413368 0.138511 0.161201 0.367017 0.924272 0.440924 w: 1
Observation: 0 0 2 0 1 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=242, meanQ=53.078705, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 190887 episodes
GETTING ACTION FROM:
action 5, numVisits=191129, meanQ=68.198747, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.417238 0.484832 0.0195429 0.102002 0.413368 0.138511 0.161201 0.367017 0.924272 0.440924 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 61.6251
Run # 24
Initial state: 0 0.157682 0.0295595 0.532256 0.354619 0.422348 0.751221 0.342718 0.408522 0.935915 0.34605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158582 episodes
GETTING ACTION FROM:
action 3, numVisits=158576, meanQ=25.758472, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.157682 0.0295595 0.532256 0.354619 0.422348 0.751221 0.342718 0.408522 0.935915 0.34605 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 25
Initial state: 0 0.399695 0.320863 0.806591 0.982276 0.948529 0.189667 0.473585 0.502126 0.329489 0.662961 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80216 episodes
GETTING ACTION FROM:
action -1, numVisits=80158, meanQ=45.406513, numObservations: 243
action 0, numVisits=53, meanQ=-3.113113, numObservations: 50
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.399695 0.320863 0.806591 0.982276 0.948529 0.189667 0.473585 0.502126 0.329489 0.662961 w: 1
Observation: 0 2 0 3 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=415, meanQ=51.002984, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 183616 episodes
GETTING ACTION FROM:
action 1, numVisits=184031, meanQ=40.880382, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.399695 0.320863 0.806591 0.982276 0.948529 0.189667 0.473585 0.502126 0.329489 0.662961 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 26
Initial state: 0 0.573805 0.624535 0.290565 0.619492 0.577382 0.810541 0.183489 0.454879 0.425911 0.492136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 148324 episodes
GETTING ACTION FROM:
action 2, numVisits=148313, meanQ=28.646928, numObservations: 9
action 1, numVisits=6, meanQ=9.233750, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.573805 0.624535 0.290565 0.619492 0.577382 0.810541 0.183489 0.454879 0.425911 0.492136 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3575, meanQ=33.680307, numObservations: 9
action 3, numVisits=25, meanQ=28.232300, numObservations: 8
action 5, numVisits=6, meanQ=26.300000, numObservations: 5
action 2, numVisits=5, meanQ=13.280500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
Sampled 77390 episodes
GETTING ACTION FROM:
action 4, numVisits=80798, meanQ=29.475345, numObservations: 9
action 3, numVisits=191, meanQ=27.437930, numObservations: 9
action 2, numVisits=5, meanQ=13.280500, numObservations: 3
action 5, numVisits=7, meanQ=8.114286, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 4
Next state: 0 0.573805 0.624535 0.290565 0.619492 0.577382 0.810541 0.183489 0.454879 0.425911 0.492136 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=232, meanQ=50.036549, numObservations: 9
action 5, numVisits=16, meanQ=36.500000, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 165689 episodes
GETTING ACTION FROM:
action 1, numVisits=165921, meanQ=42.545274, numObservations: 9
action 5, numVisits=16, meanQ=36.500000, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.573805 0.624535 0.290565 0.619492 0.577382 0.810541 0.183489 0.454879 0.425911 0.492136 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 27
Initial state: 0 0.904695 0.497242 0.573612 0.899975 0.458325 0.482098 0.245742 0.12082 0.186175 0.39812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154097 episodes
GETTING ACTION FROM:
action 3, numVisits=154090, meanQ=28.457307, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.904695 0.497242 0.573612 0.899975 0.458325 0.482098 0.245742 0.12082 0.186175 0.39812 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 28
Initial state: 0 0.849994 0.240656 0.232429 0.00993409 0.832719 0.942062 0.571775 0.306637 0.321683 0.40161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80658 episodes
GETTING ACTION FROM:
action 0, numVisits=80624, meanQ=59.561361, numObservations: 243
action -1, numVisits=19, meanQ=-1.050000, numObservations: 19
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=7, meanQ=-15.285714, numObservations: 5
action 2, numVisits=5, meanQ=-21.000000, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.849994 0.240656 0.232429 0.00993409 0.832719 0.942062 0.571775 0.306637 0.321683 0.40161 w: 1
Observation: 0 0 1 0 3 0 3 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=248, meanQ=61.134693, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action 3, numVisits=4, meanQ=21.737500, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 162690 episodes
GETTING ACTION FROM:
action 5, numVisits=162938, meanQ=66.062966, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action 3, numVisits=4, meanQ=21.737500, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.849994 0.240656 0.232429 0.00993409 0.832719 0.942062 0.571775 0.306637 0.321683 0.40161 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 29
Initial state: 0 0.913706 0.383999 0.611124 0.645383 0.807695 0.230522 0.474172 0.484541 0.501601 0.931793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80636 episodes
GETTING ACTION FROM:
action -1, numVisits=80610, meanQ=47.193940, numObservations: 243
action 2, numVisits=13, meanQ=-3.311346, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=9, meanQ=-11.816667, numObservations: 8
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.913706 0.383999 0.611124 0.645383 0.807695 0.230522 0.474172 0.484541 0.501601 0.931793 w: 1
Observation: 0 3 0 2 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=669, meanQ=41.911540, numObservations: 9
action 1, numVisits=13, meanQ=13.688462, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 186714 episodes
GETTING ACTION FROM:
action 2, numVisits=187383, meanQ=56.235703, numObservations: 9
action 1, numVisits=13, meanQ=13.688462, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.913706 0.383999 0.611124 0.645383 0.807695 0.230522 0.474172 0.484541 0.501601 0.931793 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 30
Initial state: 0 0.451261 0.484195 0.492563 0.930307 0.635376 0.806002 0.951515 0.713655 0.817881 0.0811703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144172 episodes
GETTING ACTION FROM:
action 3, numVisits=144154, meanQ=28.696144, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 4, numVisits=7, meanQ=-2.428571, numObservations: 6
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.451261 0.484195 0.492563 0.930307 0.635376 0.806002 0.951515 0.713655 0.817881 0.0811703 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 31
Initial state: 0 0.305652 0.401891 0.20131 0.112592 0.334144 0.210964 0.13776 0.595812 0.692881 0.52913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161239 episodes
GETTING ACTION FROM:
action 3, numVisits=161202, meanQ=26.338425, numObservations: 9
action 2, numVisits=26, meanQ=0.059808, numObservations: 7
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.305652 0.401891 0.20131 0.112592 0.334144 0.210964 0.13776 0.595812 0.692881 0.52913 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 32
Initial state: 0 0.930248 0.645748 0.948802 0.769486 0.234333 0.0315634 0.465322 0.461298 0.847976 0.693602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82371 episodes
GETTING ACTION FROM:
action 0, numVisits=82337, meanQ=61.389546, numObservations: 243
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action -1, numVisits=27, meanQ=-5.099815, numObservations: 24
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.930248 0.645748 0.948802 0.769486 0.234333 0.0315634 0.465322 0.461298 0.847976 0.693602 w: 1
Observation: 0 0 3 0 3 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=294, meanQ=66.947338, numObservations: 9
action 2, numVisits=6, meanQ=32.333333, numObservations: 4
action 5, numVisits=4, meanQ=21.737500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
Sampled 179220 episodes
GETTING ACTION FROM:
action 1, numVisits=179514, meanQ=69.798337, numObservations: 9
action 2, numVisits=6, meanQ=32.333333, numObservations: 4
action 5, numVisits=4, meanQ=21.737500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 1
Next state: 1 0.930248 0.645748 0.948802 0.769486 0.234333 0.0315634 0.465322 0.461298 0.847976 0.693602 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 33
Initial state: 0 0.204194 0.239419 0.8786 0.605206 0.449199 0.422698 0.719863 0.264656 0.607101 0.786582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154658 episodes
GETTING ACTION FROM:
action 1, numVisits=154649, meanQ=28.387859, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.204194 0.239419 0.8786 0.605206 0.449199 0.422698 0.719863 0.264656 0.607101 0.786582 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=11175, meanQ=32.534130, numObservations: 9
action 0, numVisits=12, meanQ=-9.125000, numObservations: 11
action 1, numVisits=2, meanQ=-10.050000, numObservations: 2
action -1, numVisits=5, meanQ=-20.430000, numObservations: 4
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 54409 episodes
GETTING ACTION FROM:
action 5, numVisits=65584, meanQ=22.201994, numObservations: 9
action 0, numVisits=12, meanQ=-9.125000, numObservations: 11
action 1, numVisits=2, meanQ=-10.050000, numObservations: 2
action -1, numVisits=5, meanQ=-20.430000, numObservations: 4
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.204194 0.239419 0.8786 0.605206 0.449199 0.422698 0.719863 0.264656 0.607101 0.786582 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 34
Initial state: 0 0.447297 0.426765 0.982674 0.455746 0.199382 0.0783695 0.305586 0.952402 0.0747858 0.145725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155028 episodes
GETTING ACTION FROM:
action 1, numVisits=155011, meanQ=27.733843, numObservations: 9
action 2, numVisits=12, meanQ=19.987708, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.447297 0.426765 0.982674 0.455746 0.199382 0.0783695 0.305586 0.952402 0.0747858 0.145725 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 35
Initial state: 0 0.41871 0.0171506 0.26068 0.458984 0.512445 0.195074 0.92415 0.288303 0.418554 0.408978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 150235 episodes
GETTING ACTION FROM:
action 3, numVisits=150208, meanQ=27.961217, numObservations: 9
action 2, numVisits=19, meanQ=8.047368, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.41871 0.0171506 0.26068 0.458984 0.512445 0.195074 0.92415 0.288303 0.418554 0.408978 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 36
Initial state: 0 0.779228 0.607289 0.400701 0.416128 0.760824 0.0713158 0.745179 0.153721 0.98537 0.907473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 150889 episodes
GETTING ACTION FROM:
action 1, numVisits=148984, meanQ=27.727384, numObservations: 9
action 3, numVisits=1893, meanQ=25.816968, numObservations: 9
action 4, numVisits=7, meanQ=13.285714, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.779228 0.607289 0.400701 0.416128 0.760824 0.0713158 0.745179 0.153721 0.98537 0.907473 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 37
Initial state: 0 0.781286 0.231232 0.84836 0.609655 0.799729 0.631068 0.0132062 0.904754 0.38837 0.450281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 148921 episodes
GETTING ACTION FROM:
action 5, numVisits=148888, meanQ=28.411481, numObservations: 9
action 3, numVisits=20, meanQ=22.595000, numObservations: 8
action 1, numVisits=8, meanQ=10.250000, numObservations: 6
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.781286 0.231232 0.84836 0.609655 0.799729 0.631068 0.0132062 0.904754 0.38837 0.450281 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=851, meanQ=28.360800, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 163095 episodes
GETTING ACTION FROM:
action 4, numVisits=163946, meanQ=26.206411, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.781286 0.231232 0.84836 0.609655 0.799729 0.631068 0.0132062 0.904754 0.38837 0.450281 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=129, meanQ=46.868392, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 180165 episodes
GETTING ACTION FROM:
action 3, numVisits=180294, meanQ=35.459632, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.781286 0.231232 0.84836 0.609655 0.799729 0.631068 0.0132062 0.904754 0.38837 0.450281 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 38
Initial state: 0 0.904813 0.244173 0.450015 0.227322 0.673297 0.787958 0.468301 0.467342 0.150302 0.527274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156223 episodes
GETTING ACTION FROM:
action 4, numVisits=156192, meanQ=27.596687, numObservations: 9
action 5, numVisits=17, meanQ=20.761912, numObservations: 7
action 3, numVisits=10, meanQ=16.900250, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.904813 0.244173 0.450015 0.227322 0.673297 0.787958 0.468301 0.467342 0.150302 0.527274 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 39
Initial state: 0 0.0934858 0.166566 0.0914572 0.47245 0.431878 0.392542 0.95424 0.155862 0.548629 0.351849 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82165 episodes
GETTING ACTION FROM:
action 0, numVisits=82140, meanQ=60.354296, numObservations: 243
action -1, numVisits=20, meanQ=-5.895000, numObservations: 19
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0934858 0.166566 0.0914572 0.47245 0.431878 0.392542 0.95424 0.155862 0.548629 0.351849 w: 1
Observation: 0 0 1 0 2 0 2 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=89, meanQ=7.343090, numObservations: 64
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 0, numVisits=19, meanQ=-6.150000, numObservations: 18
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 81839 episodes
GETTING ACTION FROM:
action -1, numVisits=81928, meanQ=64.906285, numObservations: 243
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 0, numVisits=19, meanQ=-6.150000, numObservations: 18
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0934858 0.166566 0.0914572 0.47245 0.431878 0.392542 0.95424 0.155862 0.548629 0.351849 w: 1
Observation: 0 1 0 1 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=297, meanQ=46.947092, numObservations: 73
action -1, numVisits=11, meanQ=-1.395455, numObservations: 9
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 83337 episodes
GETTING ACTION FROM:
action 0, numVisits=83634, meanQ=78.150584, numObservations: 237
action -1, numVisits=11, meanQ=-1.395455, numObservations: 9
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0934858 0.166566 0.0914572 0.47245 0.431878 0.392542 0.95424 0.155862 0.548629 0.351849 w: 1
Observation: 0 0 1 0 2 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=16745, meanQ=96.282678, numObservations: 9
action 2, numVisits=6, meanQ=65.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 193097 episodes
GETTING ACTION FROM:
action 3, numVisits=209842, meanQ=96.606951, numObservations: 9
action 2, numVisits=6, meanQ=65.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.0934858 0.166566 0.0914572 0.47245 0.431878 0.392542 0.95424 0.155862 0.548629 0.351849 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 79.1751
Run # 40
Initial state: 0 0.366707 0.481841 0.613899 0.911546 0.712337 0.210363 0.486806 0.182858 0.958371 0.799592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 149632 episodes
GETTING ACTION FROM:
action 4, numVisits=149625, meanQ=28.241539, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.366707 0.481841 0.613899 0.911546 0.712337 0.210363 0.486806 0.182858 0.958371 0.799592 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 41
Initial state: 0 0.733445 0.63951 0.987836 0.377885 0.419292 0.509929 0.599434 0.568925 0.748156 0.120551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82825 episodes
GETTING ACTION FROM:
action 0, numVisits=82752, meanQ=62.142354, numObservations: 243
action -1, numVisits=23, meanQ=-1.050000, numObservations: 23
action 3, numVisits=44, meanQ=-2.182784, numObservations: 9
action 5, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.733445 0.63951 0.987836 0.377885 0.419292 0.509929 0.599434 0.568925 0.748156 0.120551 w: 1
Observation: 0 0 3 0 1 0 1 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=217, meanQ=72.508892, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 167291 episodes
GETTING ACTION FROM:
action 4, numVisits=167508, meanQ=69.125467, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.733445 0.63951 0.987836 0.377885 0.419292 0.509929 0.599434 0.568925 0.748156 0.120551 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 42
Initial state: 0 0.680179 0.121569 0.840901 0.574433 0.389382 0.44149 0.320435 0.55861 0.67597 0.458885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160121 episodes
GETTING ACTION FROM:
action 2, numVisits=160115, meanQ=26.585700, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.680179 0.121569 0.840901 0.574433 0.389382 0.44149 0.320435 0.55861 0.67597 0.458885 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 43
Initial state: 0 0.272089 0.417234 0.487465 0.954131 0.930535 0.0287242 0.523298 0.484669 0.415315 0.473844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 152127 episodes
GETTING ACTION FROM:
action 3, numVisits=152107, meanQ=28.231531, numObservations: 9
action 5, numVisits=15, meanQ=17.600167, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.272089 0.417234 0.487465 0.954131 0.930535 0.0287242 0.523298 0.484669 0.415315 0.473844 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 44
Initial state: 0 0.518881 0.988806 0.327223 0.50317 0.0740818 0.268436 0.0343169 0.381138 0.975433 0.742387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156114 episodes
GETTING ACTION FROM:
action 5, numVisits=156106, meanQ=26.846717, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.518881 0.988806 0.327223 0.50317 0.0740818 0.268436 0.0343169 0.381138 0.975433 0.742387 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 45
Initial state: 0 0.576396 0.705747 0.413789 0.454319 0.650108 0.942245 0.796889 0.22678 0.383814 0.855196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 151896 episodes
GETTING ACTION FROM:
action 5, numVisits=151884, meanQ=28.122346, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=5, meanQ=-3.000000, numObservations: 5
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.576396 0.705747 0.413789 0.454319 0.650108 0.942245 0.796889 0.22678 0.383814 0.855196 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 46
Initial state: 0 0.692178 0.593627 0.300286 0.504192 0.408651 0.887101 0.688833 0.807353 0.816535 0.542949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82687 episodes
GETTING ACTION FROM:
action 0, numVisits=82663, meanQ=62.132746, numObservations: 243
action -1, numVisits=14, meanQ=-1.050000, numObservations: 14
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=4, meanQ=-28.500000, numObservations: 4
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.692178 0.593627 0.300286 0.504192 0.408651 0.887101 0.688833 0.807353 0.816535 0.542949 w: 1
Observation: 0 0 2 0 2 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=418, meanQ=64.001233, numObservations: 9
action 4, numVisits=8, meanQ=35.368750, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 191050 episodes
GETTING ACTION FROM:
action 3, numVisits=191468, meanQ=60.330278, numObservations: 9
action 4, numVisits=8, meanQ=35.368750, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.692178 0.593627 0.300286 0.504192 0.408651 0.887101 0.688833 0.807353 0.816535 0.542949 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 47
Initial state: 0 0.333063 0.469569 0.0957916 0.23142 0.0395379 0.370921 0.55588 0.610886 0.348592 0.0380566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153300 episodes
GETTING ACTION FROM:
action 4, numVisits=153283, meanQ=27.472069, numObservations: 9
action 3, numVisits=7, meanQ=10.564286, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=5, meanQ=-3.000000, numObservations: 5
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.333063 0.469569 0.0957916 0.23142 0.0395379 0.370921 0.55588 0.610886 0.348592 0.0380566 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 48
Initial state: 0 0.770893 0.57606 0.738774 0.258348 0.655059 0.840449 0.600739 0.873881 0.397789 0.465355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80481 episodes
GETTING ACTION FROM:
action -1, numVisits=80457, meanQ=46.767900, numObservations: 243
action 0, numVisits=19, meanQ=-1.152500, numObservations: 18
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.770893 0.57606 0.738774 0.258348 0.655059 0.840449 0.600739 0.873881 0.397789 0.465355 w: 1
Observation: 0 3 0 3 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=626, meanQ=79.545866, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
Sampled 187142 episodes
GETTING ACTION FROM:
action 5, numVisits=187768, meanQ=81.476790, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 5
Next state: 0 0.770893 0.57606 0.738774 0.258348 0.655059 0.840449 0.600739 0.873881 0.397789 0.465355 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1292, meanQ=91.212821, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 132345 episodes
GETTING ACTION FROM:
action 5, numVisits=1324, meanQ=91.086869, numObservations: 9
action 4, numVisits=132191, meanQ=67.956638, numObservations: 9
action 2, numVisits=98, meanQ=-1.000000, numObservations: 8
action 0, numVisits=15, meanQ=-1.873333, numObservations: 13
action -1, numVisits=14, meanQ=-1.932143, numObservations: 11
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.770893 0.57606 0.738774 0.258348 0.655059 0.840449 0.600739 0.873881 0.397789 0.465355 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 49
Initial state: 0 0.780009 0.184869 0.854424 0.907701 0.309972 0.245476 0.468653 0.460156 0.954213 0.149898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160912 episodes
GETTING ACTION FROM:
action 4, numVisits=160867, meanQ=26.522804, numObservations: 9
action 2, numVisits=5, meanQ=15.000000, numObservations: 5
action 1, numVisits=31, meanQ=13.769355, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=6, meanQ=-4.175000, numObservations: 5
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.780009 0.184869 0.854424 0.907701 0.309972 0.245476 0.468653 0.460156 0.954213 0.149898 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 50
Initial state: 0 0.478211 0.757599 0.613712 0.848778 0.267131 0.31407 0.779572 0.818826 0.379083 0.490078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82400 episodes
GETTING ACTION FROM:
action 0, numVisits=82377, meanQ=61.790159, numObservations: 243
action 1, numVisits=5, meanQ=-7.000000, numObservations: 4
action -1, numVisits=14, meanQ=-7.971429, numObservations: 13
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.478211 0.757599 0.613712 0.848778 0.267131 0.31407 0.779572 0.818826 0.379083 0.490078 w: 1
Observation: 0 0 3 0 3 0 1 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=638, meanQ=65.415975, numObservations: 9
action 2, numVisits=13, meanQ=44.457692, numObservations: 3
action 1, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 182270 episodes
GETTING ACTION FROM:
action 4, numVisits=182908, meanQ=64.678523, numObservations: 9
action 2, numVisits=13, meanQ=44.457692, numObservations: 3
action 1, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.478211 0.757599 0.613712 0.848778 0.267131 0.31407 0.779572 0.818826 0.379083 0.490078 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
[32m ProblemEnvironment.hpp 351: Done.[39m
