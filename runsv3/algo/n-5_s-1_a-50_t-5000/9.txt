Run # 1
Initial state: 0 0.176706 0.365713 0.243284 0.591604 0.170527 0.804972 0.206016 0.451175 0.542553 0.494171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 130828 episodes
GETTING ACTION FROM:
action 2, numVisits=130815, meanQ=31.503535, numObservations: 9
action 5, numVisits=7, meanQ=23.864286, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.176706 0.365713 0.243284 0.591604 0.170527 0.804972 0.206016 0.451175 0.542553 0.494171 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=16570, meanQ=39.571345, numObservations: 9
action 0, numVisits=20, meanQ=-6.517250, numObservations: 17
action -1, numVisits=20, meanQ=-7.567000, numObservations: 15
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 42830 episodes
GETTING ACTION FROM:
action 4, numVisits=59400, meanQ=43.517061, numObservations: 9
action 0, numVisits=20, meanQ=-6.517250, numObservations: 17
action -1, numVisits=20, meanQ=-7.567000, numObservations: 15
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.176706 0.365713 0.243284 0.591604 0.170527 0.804972 0.206016 0.451175 0.542553 0.494171 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2238, meanQ=49.977273, numObservations: 9
action 4, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 29687 episodes
GETTING ACTION FROM:
action 3, numVisits=31925, meanQ=46.394290, numObservations: 9
action 4, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.176706 0.365713 0.243284 0.591604 0.170527 0.804972 0.206016 0.451175 0.542553 0.494171 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=2361, meanQ=80.489003, numObservations: 9
action 5, numVisits=5, meanQ=37.190000, numObservations: 3
action 2, numVisits=3, meanQ=26.300000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 73326 episodes
GETTING ACTION FROM:
action 1, numVisits=75687, meanQ=69.773178, numObservations: 9
action 5, numVisits=5, meanQ=37.190000, numObservations: 3
action 2, numVisits=3, meanQ=26.300000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 0 0.176706 0.365713 0.243284 0.591604 0.170527 0.804972 0.206016 0.451175 0.542553 0.494171 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=220, meanQ=68.183613, numObservations: 9
action 3, numVisits=2, meanQ=43.420260, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-12.104766, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-215.089314, numObservations: 1
Sampled 154376 episodes
GETTING ACTION FROM:
action 3, numVisits=2, meanQ=43.420260, numObservations: 1
action 5, numVisits=154596, meanQ=25.596331, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-12.104766, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-215.089314, numObservations: 1
action: 3
Next state: 1 0.176706 0.365713 0.243284 0.591604 0.170527 0.804972 0.206016 0.451175 0.542553 0.494171 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 39.8275
Run # 2
Initial state: 0 0.81433 0.790985 0.220992 0.699091 0.713517 0.4729 0.580365 0.427299 0.428685 0.556639 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132136 episodes
GETTING ACTION FROM:
action 2, numVisits=132118, meanQ=32.272122, numObservations: 9
action 4, numVisits=11, meanQ=16.272727, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.81433 0.790985 0.220992 0.699091 0.713517 0.4729 0.580365 0.427299 0.428685 0.556639 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 3
Initial state: 0 0.707303 0.240086 0.586166 0.46358 0.908284 0.615346 0.680293 0.765331 0.948817 0.831184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136938 episodes
GETTING ACTION FROM:
action 4, numVisits=136932, meanQ=32.149909, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.707303 0.240086 0.586166 0.46358 0.908284 0.615346 0.680293 0.765331 0.948817 0.831184 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 4
Initial state: 0 0.129388 0.250303 0.457165 0.517876 0.615416 0.419672 0.779853 0.263891 0.83681 0.145385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 134237 episodes
GETTING ACTION FROM:
action 5, numVisits=134188, meanQ=31.581214, numObservations: 9
action 1, numVisits=37, meanQ=20.309662, numObservations: 8
action 2, numVisits=8, meanQ=16.731875, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.129388 0.250303 0.457165 0.517876 0.615416 0.419672 0.779853 0.263891 0.83681 0.145385 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 5
Initial state: 0 0.548627 0.423729 0.938628 0.566151 0.732025 0.216254 0.507506 0.168156 0.991914 0.195249 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 129910 episodes
GETTING ACTION FROM:
action 2, numVisits=129901, meanQ=31.198606, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.548627 0.423729 0.938628 0.566151 0.732025 0.216254 0.507506 0.168156 0.991914 0.195249 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 6
Initial state: 0 0.624175 0.432287 0.762985 0.677976 0.968018 0.0976515 0.805568 0.531921 0.378606 0.410531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 117639 episodes
GETTING ACTION FROM:
action 4, numVisits=117623, meanQ=33.798298, numObservations: 9
action 1, numVisits=11, meanQ=20.491136, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.624175 0.432287 0.762985 0.677976 0.968018 0.0976515 0.805568 0.531921 0.378606 0.410531 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 7
Initial state: 0 0.127333 0.777326 0.0342973 0.583263 0.421793 0.770316 0.92206 0.375047 0.58254 0.476408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 134050 episodes
GETTING ACTION FROM:
action 2, numVisits=134022, meanQ=31.588153, numObservations: 9
action 1, numVisits=19, meanQ=29.758421, numObservations: 7
action 4, numVisits=4, meanQ=21.500000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.127333 0.777326 0.0342973 0.583263 0.421793 0.770316 0.92206 0.375047 0.58254 0.476408 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=16439, meanQ=38.389337, numObservations: 9
action 5, numVisits=395, meanQ=37.700831, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 42412 episodes
GETTING ACTION FROM:
action 4, numVisits=58851, meanQ=40.541931, numObservations: 9
action 5, numVisits=395, meanQ=37.700831, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.127333 0.777326 0.0342973 0.583263 0.421793 0.770316 0.92206 0.375047 0.58254 0.476408 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 8
Initial state: 0 0.262961 0.834099 0.733093 0.926935 0.642625 0.251161 0.539026 0.61404 0.582048 0.524657 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132700 episodes
GETTING ACTION FROM:
action 4, numVisits=132693, meanQ=32.625741, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.262961 0.834099 0.733093 0.926935 0.642625 0.251161 0.539026 0.61404 0.582048 0.524657 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 9
Initial state: 0 0.912939 0.80227 0.280154 0.44097 0.638577 0.480111 0.55229 0.677497 0.12459 0.496391 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137092 episodes
GETTING ACTION FROM:
action 1, numVisits=137086, meanQ=31.780964, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.912939 0.80227 0.280154 0.44097 0.638577 0.480111 0.55229 0.677497 0.12459 0.496391 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 10
Initial state: 0 0.602716 0.515787 0.968889 0.0818936 0.260885 0.601846 0.160855 0.709096 0.168913 0.428834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 137685 episodes
GETTING ACTION FROM:
action 1, numVisits=137679, meanQ=31.986699, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.602716 0.515787 0.968889 0.0818936 0.260885 0.601846 0.160855 0.709096 0.168913 0.428834 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 11
Initial state: 0 0.836132 0.336277 0.985084 0.235707 0.581318 0.417495 0.799301 0.239038 0.67789 0.759744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78378 episodes
GETTING ACTION FROM:
action -1, numVisits=78304, meanQ=53.846731, numObservations: 243
action 0, numVisits=30, meanQ=-1.526583, numObservations: 27
action 1, numVisits=14, meanQ=-2.360714, numObservations: 8
action 5, numVisits=27, meanQ=-2.638333, numObservations: 8
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.836132 0.336277 0.985084 0.235707 0.581318 0.417495 0.799301 0.239038 0.67789 0.759744 w: 1
Observation: 0 3 0 3 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=180, meanQ=79.823639, numObservations: 9
action 5, numVisits=11, meanQ=60.990909, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 185880 episodes
GETTING ACTION FROM:
action 3, numVisits=186060, meanQ=76.862267, numObservations: 9
action 5, numVisits=11, meanQ=60.990909, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.836132 0.336277 0.985084 0.235707 0.581318 0.417495 0.799301 0.239038 0.67789 0.759744 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 12
Initial state: 0 0.747519 0.392837 0.481514 0.157361 0.540795 0.138444 0.0250129 0.0902853 0.617984 0.520617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 135326 episodes
GETTING ACTION FROM:
action 3, numVisits=135309, meanQ=31.306999, numObservations: 9
action 2, numVisits=12, meanQ=21.496042, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.747519 0.392837 0.481514 0.157361 0.540795 0.138444 0.0250129 0.0902853 0.617984 0.520617 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 13
Initial state: 0 0.632435 0.798815 0.133655 0.789502 0.633523 0.6601 0.181633 0.316826 0.578381 0.390341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 124288 episodes
GETTING ACTION FROM:
action 5, numVisits=124273, meanQ=33.362443, numObservations: 9
action 3, numVisits=10, meanQ=10.345750, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.632435 0.798815 0.133655 0.789502 0.633523 0.6601 0.181633 0.316826 0.578381 0.390341 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 14
Initial state: 0 0.918708 0.694843 0.806778 0.169637 0.587321 0.414724 0.0572024 0.0862915 0.434974 0.463872 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 134572 episodes
GETTING ACTION FROM:
action 1, numVisits=134566, meanQ=31.989446, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.918708 0.694843 0.806778 0.169637 0.587321 0.414724 0.0572024 0.0862915 0.434974 0.463872 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 15
Initial state: 0 0.604775 0.41175 0.905383 0.132653 0.50661 0.85247 0.637097 0.822675 0.973623 0.848833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 125634 episodes
GETTING ACTION FROM:
action 3, numVisits=125625, meanQ=32.924228, numObservations: 9
action 5, numVisits=4, meanQ=21.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.604775 0.41175 0.905383 0.132653 0.50661 0.85247 0.637097 0.822675 0.973623 0.848833 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=15949, meanQ=49.754541, numObservations: 9
action 5, numVisits=16, meanQ=14.921875, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=5, meanQ=-2.810000, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 45524 episodes
GETTING ACTION FROM:
action 5, numVisits=45536, meanQ=53.016512, numObservations: 9
action 3, numVisits=15950, meanQ=49.754132, numObservations: 9
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action -1, numVisits=2, meanQ=-1.525000, numObservations: 2
action 4, numVisits=5, meanQ=-2.810000, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.604775 0.41175 0.905383 0.132653 0.50661 0.85247 0.637097 0.822675 0.973623 0.848833 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 16
Initial state: 0 0.233738 0.95691 0.62112 0.390592 0.682334 0.972782 0.000843432 0.608001 0.803347 0.139992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 132701 episodes
GETTING ACTION FROM:
action 2, numVisits=132695, meanQ=32.267311, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.233738 0.95691 0.62112 0.390592 0.682334 0.972782 0.000843432 0.608001 0.803347 0.139992 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 17
Initial state: 0 0.404523 0.623879 0.618142 0.108352 0.592501 0.392011 0.150691 0.0881008 0.193862 0.393664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79196 episodes
GETTING ACTION FROM:
action -1, numVisits=79162, meanQ=54.991532, numObservations: 243
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 0, numVisits=27, meanQ=-4.638889, numObservations: 26
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.404523 0.623879 0.618142 0.108352 0.592501 0.392011 0.150691 0.0881008 0.193862 0.393664 w: 1
Observation: 0 1 0 3 0 2 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=745, meanQ=80.676521, numObservations: 9
action 1, numVisits=2, meanQ=44.475000, numObservations: 2
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 182842 episodes
GETTING ACTION FROM:
action 3, numVisits=183587, meanQ=89.080396, numObservations: 9
action 1, numVisits=2, meanQ=44.475000, numObservations: 2
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.404523 0.623879 0.618142 0.108352 0.592501 0.392011 0.150691 0.0881008 0.193862 0.393664 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 18
Initial state: 0 0.393621 0.228828 0.766163 0.548426 0.580555 0.501629 0.130668 0.190813 0.481146 0.310295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 126916 episodes
GETTING ACTION FROM:
action 3, numVisits=126908, meanQ=33.179731, numObservations: 9
action 1, numVisits=3, meanQ=25.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.393621 0.228828 0.766163 0.548426 0.580555 0.501629 0.130668 0.190813 0.481146 0.310295 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 19
Initial state: 0 0.507127 0.942924 0.883837 0.854416 0.626563 0.38993 0.68796 0.494719 0.326253 0.547097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 124400 episodes
GETTING ACTION FROM:
action 3, numVisits=124344, meanQ=33.616795, numObservations: 9
action 2, numVisits=50, meanQ=23.461050, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.507127 0.942924 0.883837 0.854416 0.626563 0.38993 0.68796 0.494719 0.326253 0.547097 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 20
Initial state: 0 0.426365 0.554148 0.241415 0.902866 0.629878 0.515244 0.908587 0.694751 0.0811071 0.198222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 120847 episodes
GETTING ACTION FROM:
action 1, numVisits=120835, meanQ=34.665656, numObservations: 9
action 2, numVisits=7, meanQ=6.343214, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.426365 0.554148 0.241415 0.902866 0.629878 0.515244 0.908587 0.694751 0.0811071 0.198222 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=6743, meanQ=56.682292, numObservations: 243
action -1, numVisits=16, meanQ=-7.106250, numObservations: 15
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 16262 episodes
GETTING ACTION FROM:
action 0, numVisits=23005, meanQ=43.803719, numObservations: 243
action -1, numVisits=16, meanQ=-7.106250, numObservations: 15
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 0
Next state: 0 0.426365 0.554148 0.241415 0.902866 0.629878 0.515244 0.908587 0.694751 0.0811071 0.198222 w: 1
Observation: 0 0 3 0 1 0 1 0 3 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=3, meanQ=24.491361, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 30252 episodes
GETTING ACTION FROM:
action 4, numVisits=30255, meanQ=66.641021, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.426365 0.554148 0.241415 0.902866 0.629878 0.515244 0.908587 0.694751 0.0811071 0.198222 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 21
Initial state: 0 0.70863 0.289898 0.691931 0.87938 0.63238 0.37374 0.330581 0.726294 0.191892 0.433233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131489 episodes
GETTING ACTION FROM:
action 2, numVisits=131478, meanQ=32.960465, numObservations: 9
action 5, numVisits=3, meanQ=25.666667, numObservations: 3
action 3, numVisits=4, meanQ=21.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.70863 0.289898 0.691931 0.87938 0.63238 0.37374 0.330581 0.726294 0.191892 0.433233 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 22
Initial state: 0 0.607036 0.510795 0.868111 0.10574 0.556423 0.721724 0.745492 0.16838 0.211022 0.619317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76779 episodes
GETTING ACTION FROM:
action 0, numVisits=76766, meanQ=56.185982, numObservations: 243
action -1, numVisits=4, meanQ=-3.674375, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=5, meanQ=-21.000000, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.607036 0.510795 0.868111 0.10574 0.556423 0.721724 0.745492 0.16838 0.211022 0.619317 w: 1
Observation: 0 0 2 0 1 0 3 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=366, meanQ=79.327036, numObservations: 9
action 3, numVisits=33, meanQ=62.109167, numObservations: 5
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 165464 episodes
GETTING ACTION FROM:
action 1, numVisits=165830, meanQ=85.495970, numObservations: 9
action 3, numVisits=33, meanQ=62.109167, numObservations: 5
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.607036 0.510795 0.868111 0.10574 0.556423 0.721724 0.745492 0.16838 0.211022 0.619317 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 23
Initial state: 0 0.0795005 0.763969 0.272102 0.309355 0.664019 0.642269 0.582979 0.449056 0.301623 0.915531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 134998 episodes
GETTING ACTION FROM:
action 4, numVisits=134992, meanQ=31.610612, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0795005 0.763969 0.272102 0.309355 0.664019 0.642269 0.582979 0.449056 0.301623 0.915531 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 24
Initial state: 0 0.536764 0.449494 0.449866 0.623917 0.642793 0.455129 0.286899 0.789116 0.951891 0.546212 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 130609 episodes
GETTING ACTION FROM:
action 3, numVisits=130603, meanQ=32.390661, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.536764 0.449494 0.449866 0.623917 0.642793 0.455129 0.286899 0.789116 0.951891 0.546212 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 25
Initial state: 0 0.456038 0.734859 0.417835 0.620618 0.735555 0.847076 0.61393 0.37081 0.614166 0.4599 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 123818 episodes
GETTING ACTION FROM:
action 4, numVisits=123808, meanQ=33.822098, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=5, meanQ=-3.000000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.456038 0.734859 0.417835 0.620618 0.735555 0.847076 0.61393 0.37081 0.614166 0.4599 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 26
Initial state: 0 0.124485 0.555401 0.366933 0.494434 0.549412 0.42979 0.541566 0.920126 0.672616 0.665066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 135599 episodes
GETTING ACTION FROM:
action 1, numVisits=135550, meanQ=32.233021, numObservations: 9
action 2, numVisits=44, meanQ=23.105000, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.124485 0.555401 0.366933 0.494434 0.549412 0.42979 0.541566 0.920126 0.672616 0.665066 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13228, meanQ=38.732175, numObservations: 9
action 5, numVisits=3807, meanQ=38.557995, numObservations: 9
action 4, numVisits=39, meanQ=35.685064, numObservations: 8
action 1, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 46584 episodes
GETTING ACTION FROM:
action 5, numVisits=50329, meanQ=45.289664, numObservations: 9
action 3, numVisits=13290, meanQ=38.733007, numObservations: 9
action 4, numVisits=39, meanQ=35.685064, numObservations: 8
action 1, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.124485 0.555401 0.366933 0.494434 0.549412 0.42979 0.541566 0.920126 0.672616 0.665066 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 27
Initial state: 0 0.556519 0.287143 0.159861 0.513517 0.0365455 0.764471 0.484009 0.643092 0.543135 0.393627 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131487 episodes
GETTING ACTION FROM:
action 2, numVisits=131479, meanQ=32.175971, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.556519 0.287143 0.159861 0.513517 0.0365455 0.764471 0.484009 0.643092 0.543135 0.393627 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=7314, meanQ=59.437501, numObservations: 243
action -1, numVisits=30, meanQ=-4.694833, numObservations: 27
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 19125 episodes
GETTING ACTION FROM:
action 0, numVisits=26439, meanQ=44.046257, numObservations: 243
action -1, numVisits=30, meanQ=-4.694833, numObservations: 27
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.556519 0.287143 0.159861 0.513517 0.0365455 0.764471 0.484009 0.643092 0.543135 0.393627 w: 1
Observation: 0 0 1 0 2 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=138, meanQ=77.514664, numObservations: 9
action 4, numVisits=4, meanQ=41.850625, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 97590 episodes
GETTING ACTION FROM:
action 5, numVisits=97728, meanQ=60.475432, numObservations: 9
action 4, numVisits=4, meanQ=41.850625, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.556519 0.287143 0.159861 0.513517 0.0365455 0.764471 0.484009 0.643092 0.543135 0.393627 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=2592, meanQ=91.533747, numObservations: 9
action 4, numVisits=3, meanQ=61.896134, numObservations: 2
action 1, numVisits=2, meanQ=43.180086, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-12.387480, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 95635 episodes
GETTING ACTION FROM:
action 5, numVisits=2626, meanQ=91.600215, numObservations: 9
action 4, numVisits=95604, meanQ=86.544833, numObservations: 9
action 1, numVisits=2, meanQ=43.180086, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-12.387480, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.556519 0.287143 0.159861 0.513517 0.0365455 0.764471 0.484009 0.643092 0.543135 0.393627 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 62.0526
Run # 28
Initial state: 0 0.636321 0.725673 0.742719 0.0584058 0.0290267 0.678121 0.715876 0.452209 0.629754 0.454667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136537 episodes
GETTING ACTION FROM:
action 3, numVisits=134341, meanQ=31.569470, numObservations: 9
action 5, numVisits=2188, meanQ=31.353322, numObservations: 9
action 2, numVisits=4, meanQ=21.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.636321 0.725673 0.742719 0.0584058 0.0290267 0.678121 0.715876 0.452209 0.629754 0.454667 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=17407, meanQ=38.488621, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 35322 episodes
GETTING ACTION FROM:
action 1, numVisits=52729, meanQ=34.166370, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 2 0.636321 0.725673 0.742719 0.0584058 0.0290267 0.678121 0.715876 0.452209 0.629754 0.454667 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 29
Initial state: 0 0.839929 0.369924 0.633582 0.498341 0.628093 0.298317 0.194352 0.0364613 0.180854 0.156603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 123726 episodes
GETTING ACTION FROM:
action 5, numVisits=123720, meanQ=32.463818, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.839929 0.369924 0.633582 0.498341 0.628093 0.298317 0.194352 0.0364613 0.180854 0.156603 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=16116, meanQ=57.607320, numObservations: 243
action -1, numVisits=7, meanQ=-4.049286, numObservations: 5
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 15072 episodes
GETTING ACTION FROM:
action 0, numVisits=31188, meanQ=53.983157, numObservations: 243
action -1, numVisits=7, meanQ=-4.049286, numObservations: 5
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.839929 0.369924 0.633582 0.498341 0.628093 0.298317 0.194352 0.0364613 0.180854 0.156603 w: 1
Observation: 0 0 1 0 2 0 1 0 1 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=303, meanQ=78.224035, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 116075 episodes
GETTING ACTION FROM:
action 2, numVisits=116378, meanQ=85.304162, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.839929 0.369924 0.633582 0.498341 0.628093 0.298317 0.194352 0.0364613 0.180854 0.156603 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 30
Initial state: 0 0.254316 0.300442 0.645705 0.505138 0.954544 0.25976 0.598381 0.46457 0.80942 0.625263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78364 episodes
GETTING ACTION FROM:
action 0, numVisits=78348, meanQ=56.413688, numObservations: 243
action -1, numVisits=7, meanQ=-1.050000, numObservations: 7
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.254316 0.300442 0.645705 0.505138 0.954544 0.25976 0.598381 0.46457 0.80942 0.625263 w: 1
Observation: 0 0 1 0 2 0 1 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=307, meanQ=17.688595, numObservations: 136
action 0, numVisits=14, meanQ=-1.606429, numObservations: 10
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 80118 episodes
GETTING ACTION FROM:
action -1, numVisits=80425, meanQ=70.631082, numObservations: 243
action 0, numVisits=14, meanQ=-1.606429, numObservations: 10
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.254316 0.300442 0.645705 0.505138 0.954544 0.25976 0.598381 0.46457 0.80942 0.625263 w: 1
Observation: 0 1 0 3 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=2997, meanQ=94.510769, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 196386 episodes
GETTING ACTION FROM:
action 4, numVisits=199383, meanQ=96.062879, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.254316 0.300442 0.645705 0.505138 0.954544 0.25976 0.598381 0.46457 0.80942 0.625263 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 31
Initial state: 0 0.186043 0.892702 0.214879 0.776727 0.340052 0.052154 0.638987 0.371305 0.0382561 0.906886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77606 episodes
GETTING ACTION FROM:
action 0, numVisits=77564, meanQ=55.697522, numObservations: 243
action -1, numVisits=32, meanQ=-1.232578, numObservations: 29
action 3, numVisits=6, meanQ=-9.257917, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.186043 0.892702 0.214879 0.776727 0.340052 0.052154 0.638987 0.371305 0.0382561 0.906886 w: 1
Observation: 0 0 3 0 1 0 3 0 2 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=381, meanQ=61.754569, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 143518 episodes
GETTING ACTION FROM:
action 1, numVisits=143899, meanQ=63.751653, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 0 0.186043 0.892702 0.214879 0.776727 0.340052 0.052154 0.638987 0.371305 0.0382561 0.906886 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=44268, meanQ=69.721112, numObservations: 9
action 4, numVisits=16, meanQ=34.237500, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 71474 episodes
GETTING ACTION FROM:
action 3, numVisits=115742, meanQ=71.469884, numObservations: 9
action 4, numVisits=16, meanQ=34.237500, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 0 0.186043 0.892702 0.214879 0.776727 0.340052 0.052154 0.638987 0.371305 0.0382561 0.906886 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=187, meanQ=76.821549, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 147365 episodes
GETTING ACTION FROM:
action 5, numVisits=147552, meanQ=70.684630, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.186043 0.892702 0.214879 0.776727 0.340052 0.052154 0.638987 0.371305 0.0382561 0.906886 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=99.000000, numObservations: 1
action 4, numVisits=179, meanQ=82.423902, numObservations: 9
action 5, numVisits=2, meanQ=43.262293, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.847628, numObservations: 1
Sampled 198443 episodes
GETTING ACTION FROM:
action 4, numVisits=198619, meanQ=84.126142, numObservations: 9
action 1, numVisits=4, meanQ=49.000000, numObservations: 1
action 5, numVisits=2, meanQ=43.262293, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.847628, numObservations: 1
action: 4
Next state: 1 0.186043 0.892702 0.214879 0.776727 0.340052 0.052154 0.638987 0.371305 0.0382561 0.906886 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 48.8275
Run # 32
Initial state: 0 0.550016 0.529813 0.638033 0.0774551 0.367169 0.560493 0.949961 0.391429 0.978375 0.667024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 129464 episodes
GETTING ACTION FROM:
action 5, numVisits=129456, meanQ=32.590790, numObservations: 9
action 1, numVisits=3, meanQ=25.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.550016 0.529813 0.638033 0.0774551 0.367169 0.560493 0.949961 0.391429 0.978375 0.667024 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 33
Initial state: 0 0.214605 0.188398 0.643717 0.593023 0.447197 0.393777 0.609874 0.51186 0.0829284 0.47983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78955 episodes
GETTING ACTION FROM:
action -1, numVisits=78929, meanQ=53.495385, numObservations: 243
action 0, numVisits=9, meanQ=-2.216389, numObservations: 8
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=8, meanQ=-4.574688, numObservations: 4
action 2, numVisits=4, meanQ=-6.249375, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.214605 0.188398 0.643717 0.593023 0.447197 0.393777 0.609874 0.51186 0.0829284 0.47983 w: 1
Observation: 0 1 0 3 0 1 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=755, meanQ=79.776497, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 174523 episodes
GETTING ACTION FROM:
action 4, numVisits=175278, meanQ=88.042020, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.214605 0.188398 0.643717 0.593023 0.447197 0.393777 0.609874 0.51186 0.0829284 0.47983 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 34
Initial state: 0 0.615905 0.538511 0.205184 0.241831 0.392329 0.00139648 0.251316 0.384427 0.33139 0.545793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 122961 episodes
GETTING ACTION FROM:
action 3, numVisits=122942, meanQ=34.195531, numObservations: 9
action 1, numVisits=5, meanQ=15.000000, numObservations: 5
action 5, numVisits=10, meanQ=12.450250, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.615905 0.538511 0.205184 0.241831 0.392329 0.00139648 0.251316 0.384427 0.33139 0.545793 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 35
Initial state: 0 0.896503 0.363676 0.339702 0.311928 0.209369 0.272803 0.639398 0.470948 0.593205 0.182664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 127839 episodes
GETTING ACTION FROM:
action 3, numVisits=127821, meanQ=34.672602, numObservations: 9
action 2, numVisits=6, meanQ=29.000000, numObservations: 4
action 4, numVisits=8, meanQ=21.500000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.896503 0.363676 0.339702 0.311928 0.209369 0.272803 0.639398 0.470948 0.593205 0.182664 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=16411, meanQ=38.492748, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 4, numVisits=4, meanQ=-5.525000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 39816 episodes
GETTING ACTION FROM:
action 5, numVisits=56227, meanQ=37.511733, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 4, numVisits=4, meanQ=-5.525000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 2 0.896503 0.363676 0.339702 0.311928 0.209369 0.272803 0.639398 0.470948 0.593205 0.182664 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 36
Initial state: 0 0.631423 0.437087 0.365165 0.140482 0.458031 0.817023 0.38263 0.724757 0.505627 0.486136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131750 episodes
GETTING ACTION FROM:
action 4, numVisits=131737, meanQ=32.675674, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=6, meanQ=-7.999167, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.631423 0.437087 0.365165 0.140482 0.458031 0.817023 0.38263 0.724757 0.505627 0.486136 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 37
Initial state: 0 0.0613963 0.886758 0.381889 0.901556 0.941369 0.592548 0.032576 0.330104 0.558964 0.461263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 135283 episodes
GETTING ACTION FROM:
action 2, numVisits=135276, meanQ=30.700262, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.0613963 0.886758 0.381889 0.901556 0.941369 0.592548 0.032576 0.330104 0.558964 0.461263 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=17122, meanQ=38.046387, numObservations: 9
action 5, numVisits=6, meanQ=14.158333, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 42989 episodes
GETTING ACTION FROM:
action 3, numVisits=60111, meanQ=39.602633, numObservations: 9
action 5, numVisits=6, meanQ=14.158333, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.0613963 0.886758 0.381889 0.901556 0.941369 0.592548 0.032576 0.330104 0.558964 0.461263 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 38
Initial state: 0 0.565914 0.4603 0.683314 0.938808 0.902155 0.74424 0.623912 0.91925 0.401181 0.521853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131167 episodes
GETTING ACTION FROM:
action 5, numVisits=131143, meanQ=31.905359, numObservations: 9
action 2, numVisits=19, meanQ=20.502763, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.565914 0.4603 0.683314 0.938808 0.902155 0.74424 0.623912 0.91925 0.401181 0.521853 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7440, meanQ=36.283656, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.016667, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32721 episodes
GETTING ACTION FROM:
action 2, numVisits=40161, meanQ=29.880896, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.016667, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.565914 0.4603 0.683314 0.938808 0.902155 0.74424 0.623912 0.91925 0.401181 0.521853 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 39
Initial state: 0 0.629818 0.379835 0.293057 0.726968 0.482196 0.797708 0.063022 0.935922 0.165437 0.800211 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80791 episodes
GETTING ACTION FROM:
action -1, numVisits=80737, meanQ=55.247570, numObservations: 243
action 0, numVisits=41, meanQ=-1.448537, numObservations: 37
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=7, meanQ=-15.285714, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.629818 0.379835 0.293057 0.726968 0.482196 0.797708 0.063022 0.935922 0.165437 0.800211 w: 1
Observation: 0 2 0 1 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1107, meanQ=86.730605, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 190011 episodes
GETTING ACTION FROM:
action 1, numVisits=191118, meanQ=92.766310, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.629818 0.379835 0.293057 0.726968 0.482196 0.797708 0.063022 0.935922 0.165437 0.800211 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 40
Initial state: 0 0.211807 0.750984 0.459639 0.0613371 0.0423999 0.716761 0.891198 0.234752 0.616341 0.420295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131339 episodes
GETTING ACTION FROM:
action 2, numVisits=131331, meanQ=32.433123, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.211807 0.750984 0.459639 0.0613371 0.0423999 0.716761 0.891198 0.234752 0.616341 0.420295 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16896, meanQ=37.903196, numObservations: 9
action 1, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 29393 episodes
GETTING ACTION FROM:
action 3, numVisits=46288, meanQ=33.724399, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=4, meanQ=-5.525000, numObservations: 4
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.211807 0.750984 0.459639 0.0613371 0.0423999 0.716761 0.891198 0.234752 0.616341 0.420295 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=5698, meanQ=42.758888, numObservations: 9
action 4, numVisits=12, meanQ=38.230499, numObservations: 6
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action 3, numVisits=3, meanQ=26.300000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 31874 episodes
GETTING ACTION FROM:
action 1, numVisits=37569, meanQ=40.764420, numObservations: 9
action 4, numVisits=15, meanQ=34.924399, numObservations: 6
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action 3, numVisits=3, meanQ=26.300000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.211807 0.750984 0.459639 0.0613371 0.0423999 0.716761 0.891198 0.234752 0.616341 0.420295 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 41
Initial state: 0 0.601919 0.378992 0.399709 0.819748 0.240127 0.666522 0.430591 0.420112 0.0307017 0.339778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 120441 episodes
GETTING ACTION FROM:
action 1, numVisits=120336, meanQ=34.474212, numObservations: 9
action 3, numVisits=69, meanQ=29.917464, numObservations: 9
action 5, numVisits=21, meanQ=28.907262, numObservations: 8
action 2, numVisits=9, meanQ=26.011111, numObservations: 5
action 4, numVisits=4, meanQ=21.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 1
Next state: 1 0.601919 0.378992 0.399709 0.819748 0.240127 0.666522 0.430591 0.420112 0.0307017 0.339778 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 42
Initial state: 0 0.0333273 0.318258 0.527795 0.0335215 0.285905 0.595259 0.86069 0.698081 0.613349 0.464051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 135793 episodes
GETTING ACTION FROM:
action 4, numVisits=135779, meanQ=31.911551, numObservations: 9
action 3, numVisits=9, meanQ=7.994444, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0333273 0.318258 0.527795 0.0335215 0.285905 0.595259 0.86069 0.698081 0.613349 0.464051 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 43
Initial state: 0 0.619454 0.426128 0.565872 0.864695 0.418417 0.431467 0.169904 0.261641 0.821495 0.793794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136293 episodes
GETTING ACTION FROM:
action 3, numVisits=136281, meanQ=31.752044, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=4, meanQ=-6.000000, numObservations: 4
action 5, numVisits=4, meanQ=-8.386875, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.619454 0.426128 0.565872 0.864695 0.418417 0.431467 0.169904 0.261641 0.821495 0.793794 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7717, meanQ=36.441589, numObservations: 9
action 2, numVisits=12, meanQ=30.825000, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 37391 episodes
GETTING ACTION FROM:
action 1, numVisits=45106, meanQ=28.933866, numObservations: 9
action 2, numVisits=14, meanQ=24.585944, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.619454 0.426128 0.565872 0.864695 0.418417 0.431467 0.169904 0.261641 0.821495 0.793794 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 44
Initial state: 0 0.798994 0.468282 0.168784 0.388195 0.562365 0.518363 0.839842 0.151578 0.626472 0.956144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79305 episodes
GETTING ACTION FROM:
action -1, numVisits=79275, meanQ=54.830116, numObservations: 243
action 0, numVisits=25, meanQ=-1.205800, numObservations: 23
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.798994 0.468282 0.168784 0.388195 0.562365 0.518363 0.839842 0.151578 0.626472 0.956144 w: 1
Observation: 0 3 0 1 0 2 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=219, meanQ=50.189578, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 173956 episodes
GETTING ACTION FROM:
action 5, numVisits=174175, meanQ=43.654061, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 2 0.798994 0.468282 0.168784 0.388195 0.562365 0.518363 0.839842 0.151578 0.626472 0.956144 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 45
Initial state: 0 0.0768904 0.566032 0.621073 0.573333 0.787807 0.915607 0.617438 0.438169 0.193183 0.704989 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78547 episodes
GETTING ACTION FROM:
action -1, numVisits=78506, meanQ=50.501621, numObservations: 243
action 0, numVisits=31, meanQ=-4.175806, numObservations: 30
action 4, numVisits=6, meanQ=-4.333333, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0768904 0.566032 0.621073 0.573333 0.787807 0.915607 0.617438 0.438169 0.193183 0.704989 w: 1
Observation: 0 1 0 2 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=322, meanQ=51.087515, numObservations: 9
action 2, numVisits=5, meanQ=37.190000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 174479 episodes
GETTING ACTION FROM:
action 4, numVisits=174801, meanQ=53.234170, numObservations: 9
action 2, numVisits=5, meanQ=37.190000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.0768904 0.566032 0.621073 0.573333 0.787807 0.915607 0.617438 0.438169 0.193183 0.704989 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 46
Initial state: 0 0.256372 0.188179 0.932995 0.904226 0.212006 0.113717 0.312667 0.955429 0.571436 0.459597 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 125885 episodes
GETTING ACTION FROM:
action 4, numVisits=125862, meanQ=34.135646, numObservations: 9
action 0, numVisits=9, meanQ=-1.050000, numObservations: 9
action -1, numVisits=10, meanQ=-1.050000, numObservations: 10
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.256372 0.188179 0.932995 0.904226 0.212006 0.113717 0.312667 0.955429 0.571436 0.459597 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=15685, meanQ=38.215343, numObservations: 9
action 5, numVisits=7, meanQ=26.278571, numObservations: 6
action 4, numVisits=3, meanQ=22.800833, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37426 episodes
GETTING ACTION FROM:
action 1, numVisits=53111, meanQ=46.371072, numObservations: 9
action 5, numVisits=7, meanQ=26.278571, numObservations: 6
action 4, numVisits=3, meanQ=22.800833, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.256372 0.188179 0.932995 0.904226 0.212006 0.113717 0.312667 0.955429 0.571436 0.459597 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 47
Initial state: 0 0.787379 0.0716243 0.507583 0.459757 0.769353 0.574791 0.564864 0.511865 0.738436 0.013564 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 125612 episodes
GETTING ACTION FROM:
action 4, numVisits=125603, meanQ=33.109418, numObservations: 9
action 1, numVisits=4, meanQ=21.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.787379 0.0716243 0.507583 0.459757 0.769353 0.574791 0.564864 0.511865 0.738436 0.013564 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 48
Initial state: 0 0.0110895 0.204128 0.574764 0.454841 0.722926 0.243751 0.692499 0.0870836 0.8133 0.248439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 136484 episodes
GETTING ACTION FROM:
action 5, numVisits=136469, meanQ=31.324224, numObservations: 9
action 4, numVisits=10, meanQ=19.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.0110895 0.204128 0.574764 0.454841 0.722926 0.243751 0.692499 0.0870836 0.8133 0.248439 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 49
Initial state: 0 0.854219 0.709941 0.196366 0.81049 0.259463 0.186597 0.554473 0.524381 0.684265 0.457364 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 135415 episodes
GETTING ACTION FROM:
action 2, numVisits=135392, meanQ=31.301946, numObservations: 9
action 4, numVisits=15, meanQ=21.793333, numObservations: 7
action 5, numVisits=4, meanQ=16.975000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.854219 0.709941 0.196366 0.81049 0.259463 0.186597 0.554473 0.524381 0.684265 0.457364 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=17114, meanQ=36.962574, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 40412 episodes
GETTING ACTION FROM:
action 3, numVisits=57526, meanQ=40.989856, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.854219 0.709941 0.196366 0.81049 0.259463 0.186597 0.554473 0.524381 0.684265 0.457364 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=606, meanQ=32.852356, numObservations: 9
action 2, numVisits=11, meanQ=5.005682, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 44159 episodes
GETTING ACTION FROM:
action 5, numVisits=44765, meanQ=27.575786, numObservations: 9
action 2, numVisits=11, meanQ=5.005682, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 2 0.854219 0.709941 0.196366 0.81049 0.259463 0.186597 0.554473 0.524381 0.684265 0.457364 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -112.603
Run # 50
Initial state: 0 0.637853 0.504888 0.997153 0.945399 0.992709 0.733237 0.159246 0.753414 0.913759 0.937374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131426 episodes
GETTING ACTION FROM:
action 1, numVisits=131403, meanQ=31.718939, numObservations: 9
action 2, numVisits=10, meanQ=5.500000, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=8, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.637853 0.504888 0.997153 0.945399 0.992709 0.733237 0.159246 0.753414 0.913759 0.937374 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
[32m ProblemEnvironment.hpp 351: Done.[39m
