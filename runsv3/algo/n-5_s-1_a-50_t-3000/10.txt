Run # 1
Initial state: 0 0.945616 0.882264 0.896258 0.0530534 0.303752 0.971022 0.889547 0.172493 0.496718 0.492311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82403 episodes
GETTING ACTION FROM:
action 3, numVisits=82388, meanQ=22.660529, numObservations: 9
action 2, numVisits=7, meanQ=7.978571, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=4, meanQ=-5.762500, numObservations: 4
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.945616 0.882264 0.896258 0.0530534 0.303752 0.971022 0.889547 0.172493 0.496718 0.492311 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 2
Initial state: 0 0.884225 0.458347 0.743722 0.739038 0.32862 0.717103 0.536845 0.536635 0.349193 0.308129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80551 episodes
GETTING ACTION FROM:
action 3, numVisits=80528, meanQ=25.328923, numObservations: 9
action 2, numVisits=15, meanQ=2.360333, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.884225 0.458347 0.743722 0.739038 0.32862 0.717103 0.536845 0.536635 0.349193 0.308129 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 3
Initial state: 0 0.938575 0.121197 0.689622 0.258343 0.165628 0.899081 0.528333 0.45237 0.745543 0.596316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89933 episodes
GETTING ACTION FROM:
action 2, numVisits=89923, meanQ=22.721492, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.938575 0.121197 0.689622 0.258343 0.165628 0.899081 0.528333 0.45237 0.745543 0.596316 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 4
Initial state: 0 0.841126 0.409689 0.156225 0.0543172 0.407571 0.529027 0.182567 0.790043 0.369234 0.821547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82666 episodes
GETTING ACTION FROM:
action 4, numVisits=82626, meanQ=24.437327, numObservations: 9
action 1, numVisits=25, meanQ=14.798100, numObservations: 8
action 5, numVisits=9, meanQ=7.778056, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 4
Next state: 0 0.841126 0.409689 0.156225 0.0543172 0.407571 0.529027 0.182567 0.790043 0.369234 0.821547 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6732, meanQ=26.092187, numObservations: 9
action 2, numVisits=18, meanQ=13.044583, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 30874 episodes
GETTING ACTION FROM:
action 1, numVisits=37606, meanQ=33.772447, numObservations: 9
action 2, numVisits=18, meanQ=13.044583, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 0 0.841126 0.409689 0.156225 0.0543172 0.407571 0.529027 0.182567 0.790043 0.369234 0.821547 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=561, meanQ=42.187807, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 67667 episodes
GETTING ACTION FROM:
action 5, numVisits=68228, meanQ=15.177588, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.841126 0.409689 0.156225 0.0543172 0.407571 0.529027 0.182567 0.790043 0.369234 0.821547 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 0, numVisits=599, meanQ=57.072852, numObservations: 90
action -1, numVisits=14, meanQ=-1.934646, numObservations: 13
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-12.029591, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37067 episodes
GETTING ACTION FROM:
action 0, numVisits=37666, meanQ=4.766181, numObservations: 230
action -1, numVisits=14, meanQ=-1.934646, numObservations: 13
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-12.029591, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.841126 0.409689 0.156225 0.0543172 0.407571 0.529027 0.182567 0.790043 0.369234 0.821547 w: 1
Observation: 0 0 1 0 1 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 4, numVisits=1, meanQ=99.000000, numObservations: 1
action 2, numVisits=82, meanQ=70.779365, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-12.199010, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-113.719593, numObservations: 1
Sampled 113301 episodes
GETTING ACTION FROM:
action 2, numVisits=113379, meanQ=51.956813, numObservations: 9
action 4, numVisits=5, meanQ=37.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-12.199010, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-113.719593, numObservations: 1
action: 2
Next state: 0 0.841126 0.409689 0.156225 0.0543172 0.407571 0.529027 0.182567 0.790043 0.369234 0.821547 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 2, numVisits=13, meanQ=22.076923, numObservations: 4
action 5, numVisits=2, meanQ=9.381463, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-12.391393, numObservations: 1
action 4, numVisits=1, meanQ=-80.075573, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 138511 episodes
GETTING ACTION FROM:
action 3, numVisits=135092, meanQ=87.017765, numObservations: 9
action 5, numVisits=3234, meanQ=45.892664, numObservations: 9
action 2, numVisits=143, meanQ=5.293706, numObservations: 9
action -1, numVisits=30, meanQ=-1.968333, numObservations: 13
action 0, numVisits=30, meanQ=-1.968333, numObservations: 12
action 4, numVisits=1, meanQ=-80.075573, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.841126 0.409689 0.156225 0.0543172 0.407571 0.529027 0.182567 0.790043 0.369234 0.821547 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 34.5525
Run # 5
Initial state: 0 0.0508688 0.824545 0.117599 0.298113 0.987364 0.964956 0.513915 0.484722 0.0213065 0.799356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49693 episodes
GETTING ACTION FROM:
action 0, numVisits=49633, meanQ=56.798483, numObservations: 243
action 4, numVisits=35, meanQ=-3.315571, numObservations: 9
action 3, numVisits=6, meanQ=-9.257917, numObservations: 5
action -1, numVisits=11, meanQ=-9.859091, numObservations: 10
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=6, meanQ=-19.175000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0508688 0.824545 0.117599 0.298113 0.987364 0.964956 0.513915 0.484722 0.0213065 0.799356 w: 1
Observation: 0 0 3 0 1 0 3 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=247, meanQ=83.253134, numObservations: 9
action 3, numVisits=13, meanQ=49.612115, numObservations: 4
action 1, numVisits=8, meanQ=46.737500, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 110010 episodes
GETTING ACTION FROM:
action 4, numVisits=110257, meanQ=79.840292, numObservations: 9
action 3, numVisits=13, meanQ=49.612115, numObservations: 4
action 1, numVisits=8, meanQ=46.737500, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0508688 0.824545 0.117599 0.298113 0.987364 0.964956 0.513915 0.484722 0.0213065 0.799356 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 6
Initial state: 0 0.462828 0.436261 0.062829 0.938027 0.896773 0.871765 0.490379 0.703916 0.516655 0.222123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80070 episodes
GETTING ACTION FROM:
action 4, numVisits=80062, meanQ=25.380802, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.462828 0.436261 0.062829 0.938027 0.896773 0.871765 0.490379 0.703916 0.516655 0.222123 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 7
Initial state: 0 0.0252422 0.164065 0.404034 0.593297 0.866336 0.250907 0.217385 0.514626 0.137053 0.942527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84226 episodes
GETTING ACTION FROM:
action 5, numVisits=84218, meanQ=23.152155, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.0252422 0.164065 0.404034 0.593297 0.866336 0.250907 0.217385 0.514626 0.137053 0.942527 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3516, meanQ=29.616315, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36463 episodes
GETTING ACTION FROM:
action 4, numVisits=39979, meanQ=23.222365, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.0252422 0.164065 0.404034 0.593297 0.866336 0.250907 0.217385 0.514626 0.137053 0.942527 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=434, meanQ=79.276170, numObservations: 9
action 1, numVisits=3, meanQ=22.800833, numObservations: 2
action 2, numVisits=7, meanQ=13.285714, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 69842 episodes
GETTING ACTION FROM:
action 4, numVisits=451, meanQ=79.063739, numObservations: 9
action 3, numVisits=69789, meanQ=42.833234, numObservations: 9
action 0, numVisits=18, meanQ=-1.894444, numObservations: 15
action -1, numVisits=16, meanQ=-1.940625, numObservations: 15
action 1, numVisits=4, meanQ=-8.149375, numObservations: 2
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=11, meanQ=-10.090909, numObservations: 5
action: 4
Next state: 2 0.0252422 0.164065 0.404034 0.593297 0.866336 0.250907 0.217385 0.514626 0.137053 0.942527 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -112.603
Run # 8
Initial state: 0 0.654176 0.971719 0.886982 0.487009 0.524949 0.532157 0.893195 0.625134 0.193675 0.419172 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84316 episodes
GETTING ACTION FROM:
action 5, numVisits=84308, meanQ=24.619352, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.654176 0.971719 0.886982 0.487009 0.524949 0.532157 0.893195 0.625134 0.193675 0.419172 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9187, meanQ=30.167178, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31448 episodes
GETTING ACTION FROM:
action 1, numVisits=40635, meanQ=21.799651, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.654176 0.971719 0.886982 0.487009 0.524949 0.532157 0.893195 0.625134 0.193675 0.419172 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 9
Initial state: 0 0.321294 0.654892 0.322022 0.689514 0.53458 0.489993 0.247362 0.820442 0.690075 0.963393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84923 episodes
GETTING ACTION FROM:
action 4, numVisits=84899, meanQ=24.237973, numObservations: 9
action -1, numVisits=3, meanQ=-1.050000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 2, numVisits=15, meanQ=-6.003000, numObservations: 8
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.321294 0.654892 0.322022 0.689514 0.53458 0.489993 0.247362 0.820442 0.690075 0.963393 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 10
Initial state: 0 0.47539 0.572061 0.43008 0.772699 0.933075 0.251227 0.332745 0.714151 0.997001 0.354694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87602 episodes
GETTING ACTION FROM:
action 4, numVisits=87587, meanQ=23.576953, numObservations: 9
action 1, numVisits=9, meanQ=15.656111, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.47539 0.572061 0.43008 0.772699 0.933075 0.251227 0.332745 0.714151 0.997001 0.354694 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 11
Initial state: 0 0.778509 0.388022 0.541341 0.545173 0.867917 0.0392136 0.481065 0.52237 0.171812 0.943341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88852 episodes
GETTING ACTION FROM:
action 2, numVisits=88845, meanQ=23.000664, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.778509 0.388022 0.541341 0.545173 0.867917 0.0392136 0.481065 0.52237 0.171812 0.943341 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 12
Initial state: 0 0.539617 0.47146 0.0894562 0.416087 0.88921 0.313784 0.562356 0.333108 0.247461 0.0542827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89443 episodes
GETTING ACTION FROM:
action 4, numVisits=89433, meanQ=22.487194, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=5, meanQ=-6.810000, numObservations: 5
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.539617 0.47146 0.0894562 0.416087 0.88921 0.313784 0.562356 0.333108 0.247461 0.0542827 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 13
Initial state: 0 0.535435 0.266767 0.368253 0.245629 0.725182 0.099076 0.51103 0.585098 0.215828 0.506243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83974 episodes
GETTING ACTION FROM:
action 4, numVisits=83966, meanQ=23.018779, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.535435 0.266767 0.368253 0.245629 0.725182 0.099076 0.51103 0.585098 0.215828 0.506243 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=731, meanQ=32.567652, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 62132 episodes
GETTING ACTION FROM:
action 3, numVisits=62115, meanQ=35.596665, numObservations: 9
action 4, numVisits=739, meanQ=32.353628, numObservations: 9
action 5, numVisits=8, meanQ=-1.000000, numObservations: 5
action -1, numVisits=4, meanQ=-1.287500, numObservations: 4
action 0, numVisits=3, meanQ=-1.683333, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.535435 0.266767 0.368253 0.245629 0.725182 0.099076 0.51103 0.585098 0.215828 0.506243 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 14
Initial state: 0 0.372014 0.997123 0.796979 0.403212 0.495612 0.525675 0.786574 0.856952 0.766487 0.165227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88674 episodes
GETTING ACTION FROM:
action 4, numVisits=88666, meanQ=23.079638, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.372014 0.997123 0.796979 0.403212 0.495612 0.525675 0.786574 0.856952 0.766487 0.165227 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 15
Initial state: 0 0.209155 0.0659329 0.412293 0.448519 0.0466749 0.485414 0.765724 0.548184 0.545923 0.172856 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81159 episodes
GETTING ACTION FROM:
action 5, numVisits=81113, meanQ=21.139502, numObservations: 9
action -1, numVisits=21, meanQ=-1.050000, numObservations: 21
action 0, numVisits=21, meanQ=-1.050000, numObservations: 21
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.209155 0.0659329 0.412293 0.448519 0.0466749 0.485414 0.765724 0.548184 0.545923 0.172856 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 16
Initial state: 0 0.124178 0.656925 0.358233 0.589521 0.443467 0.464899 0.807818 0.614938 0.857471 0.634845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48977 episodes
GETTING ACTION FROM:
action 0, numVisits=48930, meanQ=55.851857, numObservations: 243
action -1, numVisits=42, meanQ=-1.686726, numObservations: 37
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.124178 0.656925 0.358233 0.589521 0.443467 0.464899 0.807818 0.614938 0.857471 0.634845 w: 1
Observation: 0 0 2 0 3 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=152, meanQ=54.223832, numObservations: 9
action 2, numVisits=9, meanQ=40.427778, numObservations: 6
action 4, numVisits=11, meanQ=39.909091, numObservations: 7
action 5, numVisits=5, meanQ=37.190000, numObservations: 3
action 1, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
Sampled 97985 episodes
GETTING ACTION FROM:
action 3, numVisits=98137, meanQ=54.196911, numObservations: 9
action 2, numVisits=9, meanQ=40.427778, numObservations: 6
action 4, numVisits=11, meanQ=39.909091, numObservations: 7
action 5, numVisits=5, meanQ=37.190000, numObservations: 3
action 1, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 3
Next state: 1 0.124178 0.656925 0.358233 0.589521 0.443467 0.464899 0.807818 0.614938 0.857471 0.634845 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 17
Initial state: 0 0.387605 0.467699 0.530954 0.549632 0.716666 0.417527 0.180193 0.709433 0.134135 0.911458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49531 episodes
GETTING ACTION FROM:
action 0, numVisits=49481, meanQ=57.009445, numObservations: 243
action -1, numVisits=41, meanQ=-1.142683, numObservations: 39
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 0
Next state: 0 0.387605 0.467699 0.530954 0.549632 0.716666 0.417527 0.180193 0.709433 0.134135 0.911458 w: 1
Observation: 0 0 2 0 2 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=214, meanQ=61.797674, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 88698 episodes
GETTING ACTION FROM:
action 5, numVisits=88912, meanQ=61.649701, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.387605 0.467699 0.530954 0.549632 0.716666 0.417527 0.180193 0.709433 0.134135 0.911458 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 18
Initial state: 0 0.244757 0.650943 0.793608 0.842769 0.498925 0.553305 0.213972 0.579494 0.931022 0.695169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81190 episodes
GETTING ACTION FROM:
action 2, numVisits=81170, meanQ=24.880033, numObservations: 9
action 3, numVisits=15, meanQ=1.330167, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.244757 0.650943 0.793608 0.842769 0.498925 0.553305 0.213972 0.579494 0.931022 0.695169 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 19
Initial state: 0 0.275894 0.171202 0.267637 0.352682 0.639308 0.821671 0.629921 0.725638 0.53112 0.551126 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78627 episodes
GETTING ACTION FROM:
action 4, numVisits=78620, meanQ=25.269568, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.275894 0.171202 0.267637 0.352682 0.639308 0.821671 0.629921 0.725638 0.53112 0.551126 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 20
Initial state: 0 0.877908 0.578182 0.0127597 0.291207 0.0927669 0.528536 0.445624 0.579425 0.787462 0.905302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89628 episodes
GETTING ACTION FROM:
action 5, numVisits=89616, meanQ=21.886180, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.877908 0.578182 0.0127597 0.291207 0.0927669 0.528536 0.445624 0.579425 0.787462 0.905302 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 21
Initial state: 0 0.0390664 0.493528 0.453713 0.44166 0.704768 0.897279 0.904121 0.0649346 0.988558 0.513884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84698 episodes
GETTING ACTION FROM:
action 5, numVisits=84657, meanQ=22.884196, numObservations: 9
action 3, numVisits=36, meanQ=12.190556, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.0390664 0.493528 0.453713 0.44166 0.704768 0.897279 0.904121 0.0649346 0.988558 0.513884 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 22
Initial state: 0 0.887334 0.147281 0.235461 0.921251 0.219493 0.347409 0.470415 0.444948 0.973882 0.759128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86417 episodes
GETTING ACTION FROM:
action 5, numVisits=86406, meanQ=22.253510, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=4, meanQ=-8.386875, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.887334 0.147281 0.235461 0.921251 0.219493 0.347409 0.470415 0.444948 0.973882 0.759128 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 23
Initial state: 0 0.0982249 0.629548 0.288698 0.0890376 0.532361 0.44023 0.668847 0.942157 0.133909 0.108545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80449 episodes
GETTING ACTION FROM:
action 4, numVisits=80401, meanQ=25.665642, numObservations: 9
action -1, numVisits=27, meanQ=-8.227778, numObservations: 25
action 0, numVisits=13, meanQ=-9.311346, numObservations: 11
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0982249 0.629548 0.288698 0.0890376 0.532361 0.44023 0.668847 0.942157 0.133909 0.108545 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 24
Initial state: 0 0.646787 0.240511 0.949567 0.739601 0.124564 0.0645328 0.555756 0.578353 0.539066 0.574913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86577 episodes
GETTING ACTION FROM:
action 3, numVisits=86542, meanQ=22.923538, numObservations: 9
action 2, numVisits=28, meanQ=20.539286, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.646787 0.240511 0.949567 0.739601 0.124564 0.0645328 0.555756 0.578353 0.539066 0.574913 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 25
Initial state: 0 0.380246 0.891512 0.41048 0.751423 0.902292 0.620596 0.489184 0.546982 0.129885 0.515603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48524 episodes
GETTING ACTION FROM:
action 0, numVisits=48442, meanQ=56.446102, numObservations: 243
action -1, numVisits=67, meanQ=-1.507276, numObservations: 60
action 1, numVisits=6, meanQ=-4.333333, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=6, meanQ=-19.333333, numObservations: 4
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.380246 0.891512 0.41048 0.751423 0.902292 0.620596 0.489184 0.546982 0.129885 0.515603 w: 1
Observation: 0 0 3 0 3 0 2 0 2 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=98, meanQ=60.013373, numObservations: 9
action 5, numVisits=9, meanQ=20.216667, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 97267 episodes
GETTING ACTION FROM:
action 1, numVisits=97365, meanQ=58.899265, numObservations: 9
action 5, numVisits=9, meanQ=20.216667, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.380246 0.891512 0.41048 0.751423 0.902292 0.620596 0.489184 0.546982 0.129885 0.515603 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=125, meanQ=56.831125, numObservations: 8
action 1, numVisits=4, meanQ=44.475000, numObservations: 4
action 5, numVisits=11, meanQ=34.540909, numObservations: 6
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 99433 episodes
GETTING ACTION FROM:
action 2, numVisits=99558, meanQ=58.704541, numObservations: 9
action 1, numVisits=4, meanQ=44.475000, numObservations: 4
action 5, numVisits=11, meanQ=34.540909, numObservations: 6
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.380246 0.891512 0.41048 0.751423 0.902292 0.620596 0.489184 0.546982 0.129885 0.515603 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 26
Initial state: 0 0.61386 0.817797 0.0537662 0.622301 0.501689 0.549619 0.857649 0.371561 0.491554 0.85027 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86887 episodes
GETTING ACTION FROM:
action 4, numVisits=86866, meanQ=23.715200, numObservations: 9
action 2, numVisits=14, meanQ=17.282143, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.61386 0.817797 0.0537662 0.622301 0.501689 0.549619 0.857649 0.371561 0.491554 0.85027 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 27
Initial state: 0 0.507704 0.448767 0.30128 0.84473 0.319628 0.938219 0.0899875 0.61394 0.336126 0.731997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49467 episodes
GETTING ACTION FROM:
action -1, numVisits=49408, meanQ=47.989389, numObservations: 243
action 0, numVisits=21, meanQ=-1.050000, numObservations: 21
action 2, numVisits=21, meanQ=-2.711905, numObservations: 8
action 4, numVisits=5, meanQ=-2.810000, numObservations: 4
action 1, numVisits=10, meanQ=-3.000000, numObservations: 5
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.507704 0.448767 0.30128 0.84473 0.319628 0.938219 0.0899875 0.61394 0.336126 0.731997 w: 1
Observation: 0 2 0 1 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=126, meanQ=40.008180, numObservations: 9
action -1, numVisits=3, meanQ=-4.549167, numObservations: 2
action 0, numVisits=28, meanQ=-4.580268, numObservations: 26
action 2, numVisits=4, meanQ=-5.525000, numObservations: 2
action 4, numVisits=26, meanQ=-5.890385, numObservations: 6
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 107522 episodes
GETTING ACTION FROM:
action 3, numVisits=107648, meanQ=54.268802, numObservations: 9
action -1, numVisits=3, meanQ=-4.549167, numObservations: 2
action 0, numVisits=28, meanQ=-4.580268, numObservations: 26
action 2, numVisits=4, meanQ=-5.525000, numObservations: 2
action 4, numVisits=26, meanQ=-5.890385, numObservations: 6
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.507704 0.448767 0.30128 0.84473 0.319628 0.938219 0.0899875 0.61394 0.336126 0.731997 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=1842, meanQ=60.385165, numObservations: 175
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=6, meanQ=-17.200000, numObservations: 5
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18593 episodes
GETTING ACTION FROM:
action 0, numVisits=20435, meanQ=37.636015, numObservations: 242
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=6, meanQ=-17.200000, numObservations: 5
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.507704 0.448767 0.30128 0.84473 0.319628 0.938219 0.0899875 0.61394 0.336126 0.731997 w: 1
Observation: 0 0 1 0 2 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 75122 episodes
GETTING ACTION FROM:
action 3, numVisits=50, meanQ=78.580050, numObservations: 7
action 2, numVisits=75062, meanQ=57.102427, numObservations: 9
action 1, numVisits=3, meanQ=32.333333, numObservations: 1
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action: 3
Next state: 1 0.507704 0.448767 0.30128 0.84473 0.319628 0.938219 0.0899875 0.61394 0.336126 0.731997 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 70.6251
Run # 28
Initial state: 0 0.550323 0.192794 0.180824 0.465358 0.548559 0.6871 0.470502 0.440823 0.551415 0.927361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87297 episodes
GETTING ACTION FROM:
action 1, numVisits=87287, meanQ=21.705894, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.550323 0.192794 0.180824 0.465358 0.548559 0.6871 0.470502 0.440823 0.551415 0.927361 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=1769, meanQ=51.655088, numObservations: 206
action -1, numVisits=42, meanQ=-3.993869, numObservations: 36
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 40942 episodes
GETTING ACTION FROM:
action 0, numVisits=42711, meanQ=7.609726, numObservations: 243
action -1, numVisits=42, meanQ=-3.993869, numObservations: 36
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.550323 0.192794 0.180824 0.465358 0.548559 0.6871 0.470502 0.440823 0.551415 0.927361 w: 1
Observation: 0 0 1 0 1 0 3 0 1 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=9, meanQ=64.411956, numObservations: 3
action 3, numVisits=12, meanQ=29.964302, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 90136 episodes
GETTING ACTION FROM:
action 3, numVisits=90036, meanQ=41.446751, numObservations: 9
action 5, numVisits=121, meanQ=31.357624, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.550323 0.192794 0.180824 0.465358 0.548559 0.6871 0.470502 0.440823 0.551415 0.927361 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 29
Initial state: 0 0.193314 0.780883 0.457296 0.446189 0.104584 0.340889 0.639035 0.986941 0.953935 0.113837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83114 episodes
GETTING ACTION FROM:
action 5, numVisits=83106, meanQ=24.489235, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.193314 0.780883 0.457296 0.446189 0.104584 0.340889 0.639035 0.986941 0.953935 0.113837 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 30
Initial state: 0 0.725229 0.721328 0.524094 0.360433 0.758398 0.154425 0.704188 0.124627 0.466724 0.538883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87209 episodes
GETTING ACTION FROM:
action 4, numVisits=87203, meanQ=23.365303, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.725229 0.721328 0.524094 0.360433 0.758398 0.154425 0.704188 0.124627 0.466724 0.538883 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 31
Initial state: 0 0.649249 0.108005 0.455485 0.564569 0.672231 0.114096 0.698624 0.0301653 0.617741 0.243745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49613 episodes
GETTING ACTION FROM:
action 0, numVisits=49567, meanQ=57.112666, numObservations: 243
action 5, numVisits=28, meanQ=-5.340804, numObservations: 8
action -1, numVisits=14, meanQ=-7.971429, numObservations: 13
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.649249 0.108005 0.455485 0.564569 0.672231 0.114096 0.698624 0.0301653 0.617741 0.243745 w: 1
Observation: 0 0 2 0 2 0 3 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=206, meanQ=54.853940, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 107585 episodes
GETTING ACTION FROM:
action 1, numVisits=107791, meanQ=51.633188, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.649249 0.108005 0.455485 0.564569 0.672231 0.114096 0.698624 0.0301653 0.617741 0.243745 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 32
Initial state: 0 0.423195 0.568316 0.0568839 0.204448 0.768016 0.267057 0.170652 0.929942 0.0536097 0.507067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88835 episodes
GETTING ACTION FROM:
action 3, numVisits=88800, meanQ=21.724263, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=24, meanQ=-2.476562, numObservations: 8
action 2, numVisits=4, meanQ=-6.000000, numObservations: 4
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.423195 0.568316 0.0568839 0.204448 0.768016 0.267057 0.170652 0.929942 0.0536097 0.507067 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 33
Initial state: 0 0.501581 0.568815 0.431651 0.267455 0.152061 0.51329 0.20845 0.16415 0.815465 0.913097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86865 episodes
GETTING ACTION FROM:
action 4, numVisits=86834, meanQ=22.729023, numObservations: 9
action 1, numVisits=18, meanQ=8.669444, numObservations: 6
action 3, numVisits=8, meanQ=7.862812, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.501581 0.568815 0.431651 0.267455 0.152061 0.51329 0.20845 0.16415 0.815465 0.913097 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9559, meanQ=25.619028, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 30672 episodes
GETTING ACTION FROM:
action 1, numVisits=40231, meanQ=24.084921, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.501581 0.568815 0.431651 0.267455 0.152061 0.51329 0.20845 0.16415 0.815465 0.913097 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 34
Initial state: 0 0.500633 0.857043 0.463191 0.5546 0.374687 0.213315 0.998131 0.963226 0.685117 0.321221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82089 episodes
GETTING ACTION FROM:
action 2, numVisits=82058, meanQ=24.794274, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=5, meanQ=-3.000000, numObservations: 4
action 3, numVisits=5, meanQ=-3.000000, numObservations: 3
action 4, numVisits=16, meanQ=-4.812344, numObservations: 7
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.500633 0.857043 0.463191 0.5546 0.374687 0.213315 0.998131 0.963226 0.685117 0.321221 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1345, meanQ=26.197097, numObservations: 9
action 1, numVisits=5, meanQ=19.000000, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 85820 episodes
GETTING ACTION FROM:
action 5, numVisits=87165, meanQ=31.644932, numObservations: 9
action 1, numVisits=5, meanQ=19.000000, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 2 0.500633 0.857043 0.463191 0.5546 0.374687 0.213315 0.998131 0.963226 0.685117 0.321221 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 35
Initial state: 0 0.555573 0.0769617 0.453004 0.715307 0.671964 0.0528938 0.473101 0.50045 0.644412 0.733663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83282 episodes
GETTING ACTION FROM:
action 3, numVisits=83269, meanQ=24.477476, numObservations: 9
action 4, numVisits=6, meanQ=14.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.555573 0.0769617 0.453004 0.715307 0.671964 0.0528938 0.473101 0.50045 0.644412 0.733663 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 36
Initial state: 0 0.742971 0.837064 0.886319 0.945149 0.219244 0.467934 0.230799 0.838144 0.535897 0.471691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88543 episodes
GETTING ACTION FROM:
action 5, numVisits=88528, meanQ=22.884089, numObservations: 9
action 1, numVisits=10, meanQ=6.095000, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.742971 0.837064 0.886319 0.945149 0.219244 0.467934 0.230799 0.838144 0.535897 0.471691 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 37
Initial state: 0 0.438829 0.460061 0.0579888 0.546695 0.680328 0.787192 0.2648 0.939669 0.930121 0.131417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49364 episodes
GETTING ACTION FROM:
action 0, numVisits=49322, meanQ=55.854111, numObservations: 243
action -1, numVisits=34, meanQ=-3.900000, numObservations: 33
action 5, numVisits=4, meanQ=-6.000000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.438829 0.460061 0.0579888 0.546695 0.680328 0.787192 0.2648 0.939669 0.930121 0.131417 w: 1
Observation: 0 0 2 0 2 0 3 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=185, meanQ=63.917248, numObservations: 9
action 1, numVisits=7, meanQ=26.278571, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 96018 episodes
GETTING ACTION FROM:
action 3, numVisits=96203, meanQ=62.554996, numObservations: 9
action 1, numVisits=7, meanQ=26.278571, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.438829 0.460061 0.0579888 0.546695 0.680328 0.787192 0.2648 0.939669 0.930121 0.131417 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 38
Initial state: 0 0.459565 0.921578 0.681955 0.500458 0.0966493 0.788005 0.0559298 0.799566 0.49647 0.590624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87581 episodes
GETTING ACTION FROM:
action 2, numVisits=87563, meanQ=23.848729, numObservations: 9
action 5, numVisits=6, meanQ=14.000000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 2
Next state: 1 0.459565 0.921578 0.681955 0.500458 0.0966493 0.788005 0.0559298 0.799566 0.49647 0.590624 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 39
Initial state: 0 0.605418 0.012587 0.158599 0.413299 0.929531 0.318561 0.307462 0.560784 0.452332 0.434962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84568 episodes
GETTING ACTION FROM:
action 3, numVisits=84537, meanQ=23.861297, numObservations: 9
action 4, numVisits=26, meanQ=18.456058, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.605418 0.012587 0.158599 0.413299 0.929531 0.318561 0.307462 0.560784 0.452332 0.434962 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 40
Initial state: 0 0.164864 0.918706 0.450071 0.560331 0.594176 0.838623 0.746462 0.436168 0.839377 0.551967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80151 episodes
GETTING ACTION FROM:
action 2, numVisits=80145, meanQ=25.343444, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.164864 0.918706 0.450071 0.560331 0.594176 0.838623 0.746462 0.436168 0.839377 0.551967 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.866306 0.000665449 0.0238437 0.301824 0.873549 0.192723 0.408304 0.491555 0.997972 0.823684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49592 episodes
GETTING ACTION FROM:
action -1, numVisits=49583, meanQ=47.192207, numObservations: 243
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 4, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.866306 0.000665449 0.0238437 0.301824 0.873549 0.192723 0.408304 0.491555 0.997972 0.823684 w: 1
Observation: 0 3 0 3 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=174, meanQ=10.469009, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 115530 episodes
GETTING ACTION FROM:
action 1, numVisits=115704, meanQ=21.582326, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.866306 0.000665449 0.0238437 0.301824 0.873549 0.192723 0.408304 0.491555 0.997972 0.823684 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 42
Initial state: 0 0.138319 0.0140321 0.00886328 0.111994 0.0311977 0.974854 0.540383 0.486842 0.333016 0.839608 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85978 episodes
GETTING ACTION FROM:
action 2, numVisits=85960, meanQ=23.302168, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=3, meanQ=-1.699167, numObservations: 2
action 5, numVisits=5, meanQ=-3.000000, numObservations: 4
action 3, numVisits=4, meanQ=-6.000000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.138319 0.0140321 0.00886328 0.111994 0.0311977 0.974854 0.540383 0.486842 0.333016 0.839608 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 43
Initial state: 0 0.544613 0.300611 0.572103 0.649012 0.459022 0.563789 0.833367 0.859755 0.304975 0.199902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84210 episodes
GETTING ACTION FROM:
action 5, numVisits=84198, meanQ=23.624852, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=7, meanQ=-5.285714, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.544613 0.300611 0.572103 0.649012 0.459022 0.563789 0.833367 0.859755 0.304975 0.199902 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=453, meanQ=26.942757, numObservations: 165
action -1, numVisits=8, meanQ=-1.050000, numObservations: 8
action 4, numVisits=8, meanQ=-3.262500, numObservations: 5
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 101855 episodes
GETTING ACTION FROM:
action 2, numVisits=89207, meanQ=40.043849, numObservations: 9
action 0, numVisits=13101, meanQ=0.840920, numObservations: 243
action -1, numVisits=10, meanQ=-1.240000, numObservations: 9
action 4, numVisits=8, meanQ=-3.262500, numObservations: 5
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=4, meanQ=-28.262500, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.544613 0.300611 0.572103 0.649012 0.459022 0.563789 0.833367 0.859755 0.304975 0.199902 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 44
Initial state: 0 0.0951848 0.78817 0.669075 0.743319 0.418901 0.455554 0.849908 0.187381 0.575405 0.891709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88167 episodes
GETTING ACTION FROM:
action 2, numVisits=88080, meanQ=22.564481, numObservations: 9
action -1, numVisits=33, meanQ=-3.986364, numObservations: 32
action 0, numVisits=44, meanQ=-5.543068, numObservations: 40
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=7, meanQ=-18.142857, numObservations: 6
action: 2
Next state: 1 0.0951848 0.78817 0.669075 0.743319 0.418901 0.455554 0.849908 0.187381 0.575405 0.891709 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 45
Initial state: 0 0.452633 0.488392 0.903484 0.426529 0.828111 0.621009 0.63103 0.414672 0.0631178 0.255815 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81219 episodes
GETTING ACTION FROM:
action 5, numVisits=81213, meanQ=25.777560, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.452633 0.488392 0.903484 0.426529 0.828111 0.621009 0.63103 0.414672 0.0631178 0.255815 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=3377, meanQ=48.787233, numObservations: 230
action 0, numVisits=7, meanQ=-1.050000, numObservations: 7
action 1, numVisits=13, meanQ=-3.088462, numObservations: 7
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 14976 episodes
GETTING ACTION FROM:
action -1, numVisits=18353, meanQ=32.945597, numObservations: 243
action 0, numVisits=7, meanQ=-1.050000, numObservations: 7
action 1, numVisits=13, meanQ=-3.088462, numObservations: 7
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.452633 0.488392 0.903484 0.426529 0.828111 0.621009 0.63103 0.414672 0.0631178 0.255815 w: 1
Observation: 0 1 0 2 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=199, meanQ=31.196112, numObservations: 80
action 3, numVisits=5, meanQ=-2.810000, numObservations: 4
action -1, numVisits=5, meanQ=-3.149500, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=5, meanQ=-21.000000, numObservations: 3
Sampled 22944 episodes
GETTING ACTION FROM:
action 0, numVisits=23143, meanQ=62.521547, numObservations: 242
action 3, numVisits=5, meanQ=-2.810000, numObservations: 4
action -1, numVisits=5, meanQ=-3.149500, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=5, meanQ=-21.000000, numObservations: 3
action: 0
Next state: 0 0.452633 0.488392 0.903484 0.426529 0.828111 0.621009 0.63103 0.414672 0.0631178 0.255815 w: 1
Observation: 0 0 3 0 1 0 3 0 1 0 3 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=52, meanQ=74.822534, numObservations: 8
action 3, numVisits=11, meanQ=62.636364, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-12.557994, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-213.616336, numObservations: 1
Sampled 101612 episodes
GETTING ACTION FROM:
action 2, numVisits=101664, meanQ=83.372236, numObservations: 9
action 3, numVisits=11, meanQ=62.636364, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-12.557994, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-213.616336, numObservations: 1
action: 2
Next state: 2 0.452633 0.488392 0.903484 0.426529 0.828111 0.621009 0.63103 0.414672 0.0631178 0.255815 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101.3
Run # 46
Initial state: 0 0.67787 0.131475 0.375237 0.0210419 0.517669 0.839388 0.186767 0.00261345 0.471759 0.596899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48845 episodes
GETTING ACTION FROM:
action -1, numVisits=48796, meanQ=46.729136, numObservations: 243
action 0, numVisits=11, meanQ=-1.050000, numObservations: 11
action 5, numVisits=9, meanQ=-2.111111, numObservations: 5
action 4, numVisits=5, meanQ=-2.810000, numObservations: 4
action 1, numVisits=22, meanQ=-4.822500, numObservations: 9
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.67787 0.131475 0.375237 0.0210419 0.517669 0.839388 0.186767 0.00261345 0.471759 0.596899 w: 1
Observation: 0 3 0 1 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=156, meanQ=47.906170, numObservations: 9
action 3, numVisits=13, meanQ=36.069231, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 102065 episodes
GETTING ACTION FROM:
action 5, numVisits=102221, meanQ=44.441386, numObservations: 9
action 3, numVisits=13, meanQ=36.069231, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.67787 0.131475 0.375237 0.0210419 0.517669 0.839388 0.186767 0.00261345 0.471759 0.596899 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 47
Initial state: 0 0.512525 0.185344 0.788252 0.704329 0.404663 0.43975 0.342123 0.131218 0.950586 0.623012 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80528 episodes
GETTING ACTION FROM:
action 2, numVisits=80486, meanQ=25.969102, numObservations: 9
action 4, numVisits=29, meanQ=19.770776, numObservations: 8
action 5, numVisits=4, meanQ=16.975000, numObservations: 4
action 1, numVisits=6, meanQ=10.500417, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.512525 0.185344 0.788252 0.704329 0.404663 0.43975 0.342123 0.131218 0.950586 0.623012 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 48
Initial state: 0 0.462109 0.0135469 0.788961 0.110838 0.134513 0.0294896 0.535897 0.575275 0.337317 0.0795646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88566 episodes
GETTING ACTION FROM:
action 5, numVisits=88548, meanQ=23.104346, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=11, meanQ=-3.727273, numObservations: 7
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.462109 0.0135469 0.788961 0.110838 0.134513 0.0294896 0.535897 0.575275 0.337317 0.0795646 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9656, meanQ=28.315685, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 30308 episodes
GETTING ACTION FROM:
action 3, numVisits=39964, meanQ=20.911527, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.462109 0.0135469 0.788961 0.110838 0.134513 0.0294896 0.535897 0.575275 0.337317 0.0795646 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=606, meanQ=35.819887, numObservations: 9
action 1, numVisits=23, meanQ=14.754457, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 35762 episodes
GETTING ACTION FROM:
action 4, numVisits=36368, meanQ=18.839757, numObservations: 9
action 1, numVisits=23, meanQ=14.754457, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.462109 0.0135469 0.788961 0.110838 0.134513 0.0294896 0.535897 0.575275 0.337317 0.0795646 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 49
Initial state: 0 0.877542 0.244381 0.26477 0.312018 0.473636 0.581084 0.188678 0.91955 0.970104 0.269508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49479 episodes
GETTING ACTION FROM:
action -1, numVisits=49428, meanQ=49.747312, numObservations: 243
action 0, numVisits=39, meanQ=-1.249744, numObservations: 35
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=6, meanQ=-4.499583, numObservations: 5
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.877542 0.244381 0.26477 0.312018 0.473636 0.581084 0.188678 0.91955 0.970104 0.269508 w: 1
Observation: 0 3 0 1 0 3 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=133, meanQ=14.841353, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=7, meanQ=-2.292857, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 115146 episodes
GETTING ACTION FROM:
action 1, numVisits=115279, meanQ=23.248292, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=7, meanQ=-2.292857, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.877542 0.244381 0.26477 0.312018 0.473636 0.581084 0.188678 0.91955 0.970104 0.269508 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 50
Initial state: 0 0.724625 0.0910807 0.166882 0.387056 0.247623 0.552779 0.480387 0.562744 0.688893 0.976287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49086 episodes
GETTING ACTION FROM:
action -1, numVisits=49050, meanQ=47.679672, numObservations: 243
action 0, numVisits=28, meanQ=-4.955179, numObservations: 25
action 3, numVisits=4, meanQ=-6.249375, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.724625 0.0910807 0.166882 0.387056 0.247623 0.552779 0.480387 0.562744 0.688893 0.976287 w: 1
Observation: 0 1 0 1 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=214, meanQ=46.338669, numObservations: 51
action 0, numVisits=45, meanQ=-2.110833, numObservations: 38
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 50797 episodes
GETTING ACTION FROM:
action -1, numVisits=51011, meanQ=77.247756, numObservations: 232
action 0, numVisits=45, meanQ=-2.110833, numObservations: 38
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.724625 0.0910807 0.166882 0.387056 0.247623 0.552779 0.480387 0.562744 0.688893 0.976287 w: 1
Observation: 0 3 0 1 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=2156, meanQ=92.492834, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 114728 episodes
GETTING ACTION FROM:
action 4, numVisits=116884, meanQ=94.524820, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.724625 0.0910807 0.166882 0.387056 0.247623 0.552779 0.480387 0.562744 0.688893 0.976287 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
[32m ProblemEnvironment.hpp 351: Done.[39m
