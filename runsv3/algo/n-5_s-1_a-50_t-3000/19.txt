Run # 1
Initial state: 0 0.410719 0.151598 0.847271 0.638916 0.229593 0.425062 0.219446 0.527772 0.527493 0.462981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84349 episodes
GETTING ACTION FROM:
action 3, numVisits=84342, meanQ=27.972361, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.410719 0.151598 0.847271 0.638916 0.229593 0.425062 0.219446 0.527772 0.527493 0.462981 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=321, meanQ=18.676114, numObservations: 145
action -1, numVisits=9, meanQ=-2.216389, numObservations: 8
action 1, numVisits=13, meanQ=-5.396154, numObservations: 6
action 2, numVisits=4, meanQ=-5.525000, numObservations: 4
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 43167 episodes
GETTING ACTION FROM:
action 0, numVisits=43488, meanQ=3.710209, numObservations: 243
action -1, numVisits=9, meanQ=-2.216389, numObservations: 8
action 1, numVisits=13, meanQ=-5.396154, numObservations: 6
action 2, numVisits=4, meanQ=-5.525000, numObservations: 4
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.410719 0.151598 0.847271 0.638916 0.229593 0.425062 0.219446 0.527772 0.527493 0.462981 w: 1
Observation: 0 0 1 0 3 0 2 0 2 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=99.000000, numObservations: 1
action 5, numVisits=54, meanQ=59.536930, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-12.900087, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 93457 episodes
GETTING ACTION FROM:
action 5, numVisits=93510, meanQ=77.956168, numObservations: 9
action 3, numVisits=2, meanQ=44.000000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-12.900087, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.410719 0.151598 0.847271 0.638916 0.229593 0.425062 0.219446 0.527772 0.527493 0.462981 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 2
Initial state: 0 0.610665 0.48775 0.442173 0.462523 0.957993 0.596414 0.745048 0.0114473 0.320642 0.019604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85809 episodes
GETTING ACTION FROM:
action 3, numVisits=85802, meanQ=26.583691, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.610665 0.48775 0.442173 0.462523 0.957993 0.596414 0.745048 0.0114473 0.320642 0.019604 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 3
Initial state: 0 0.911488 0.228872 0.169162 0.509699 0.484089 0.486744 0.238607 0.174684 0.861104 0.772627 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79204 episodes
GETTING ACTION FROM:
action 2, numVisits=79150, meanQ=28.896867, numObservations: 9
action 1, numVisits=42, meanQ=0.820536, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 4, numVisits=6, meanQ=-4.333333, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.911488 0.228872 0.169162 0.509699 0.484089 0.486744 0.238607 0.174684 0.861104 0.772627 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=3032, meanQ=50.414380, numObservations: 228
action 0, numVisits=8, meanQ=-1.050000, numObservations: 8
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 14839 episodes
GETTING ACTION FROM:
action -1, numVisits=17871, meanQ=33.869403, numObservations: 243
action 0, numVisits=8, meanQ=-1.050000, numObservations: 8
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.911488 0.228872 0.169162 0.509699 0.484089 0.486744 0.238607 0.174684 0.861104 0.772627 w: 1
Observation: 0 3 0 1 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=167, meanQ=80.118488, numObservations: 7
action 1, numVisits=45, meanQ=20.532333, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 68044 episodes
GETTING ACTION FROM:
action 3, numVisits=68211, meanQ=85.764975, numObservations: 9
action 1, numVisits=45, meanQ=20.532333, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.911488 0.228872 0.169162 0.509699 0.484089 0.486744 0.238607 0.174684 0.861104 0.772627 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 4
Initial state: 0 0.6354 0.733979 0.393891 0.471933 0.020012 0.659698 0.218333 0.241043 0.556093 0.457061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87095 episodes
GETTING ACTION FROM:
action 2, numVisits=87077, meanQ=26.179098, numObservations: 9
action 1, numVisits=10, meanQ=8.000000, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.6354 0.733979 0.393891 0.471933 0.020012 0.659698 0.218333 0.241043 0.556093 0.457061 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 5
Initial state: 0 0.588842 0.480221 0.359999 0.213867 0.054139 0.959329 0.36151 0.822409 0.0597567 0.916288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80842 episodes
GETTING ACTION FROM:
action 1, numVisits=80833, meanQ=28.902377, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=4, meanQ=-6.000000, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.588842 0.480221 0.359999 0.213867 0.054139 0.959329 0.36151 0.822409 0.0597567 0.916288 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 6
Initial state: 0 0.106631 0.365818 0.259161 0.666346 0.376215 0.773884 0.299126 0.841303 0.536492 0.525356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77740 episodes
GETTING ACTION FROM:
action 5, numVisits=77717, meanQ=29.751540, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 1, numVisits=7, meanQ=-2.428571, numObservations: 5
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=4, meanQ=-6.000000, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.106631 0.365818 0.259161 0.666346 0.376215 0.773884 0.299126 0.841303 0.536492 0.525356 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 7
Initial state: 0 0.113564 0.742481 0.849015 0.313545 0.67513 0.835903 0.342077 0.887752 0.550053 0.406665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83991 episodes
GETTING ACTION FROM:
action 1, numVisits=83985, meanQ=27.822062, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.113564 0.742481 0.849015 0.313545 0.67513 0.835903 0.342077 0.887752 0.550053 0.406665 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 8
Initial state: 0 0.155247 0.699217 0.195376 0.047003 0.277144 0.708567 0.987891 0.389439 0.4182 0.529623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49076 episodes
GETTING ACTION FROM:
action -1, numVisits=49028, meanQ=46.357068, numObservations: 243
action 0, numVisits=40, meanQ=-1.456125, numObservations: 36
action 1, numVisits=4, meanQ=-6.000000, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.155247 0.699217 0.195376 0.047003 0.277144 0.708567 0.987891 0.389439 0.4182 0.529623 w: 1
Observation: 0 1 0 3 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=221, meanQ=79.491697, numObservations: 9
action 2, numVisits=13, meanQ=20.226923, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 109720 episodes
GETTING ACTION FROM:
action 5, numVisits=109941, meanQ=84.036641, numObservations: 9
action 2, numVisits=13, meanQ=20.226923, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.155247 0.699217 0.195376 0.047003 0.277144 0.708567 0.987891 0.389439 0.4182 0.529623 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 9
Initial state: 0 0.170846 0.200454 0.137215 0.0874197 0.715803 0.409392 0.529931 0.456642 0.540475 0.0694746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81713 episodes
GETTING ACTION FROM:
action 5, numVisits=81707, meanQ=27.658904, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.170846 0.200454 0.137215 0.0874197 0.715803 0.409392 0.529931 0.456642 0.540475 0.0694746 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 10
Initial state: 0 0.0106865 0.540063 0.602937 0.493716 0.688376 0.872977 0.332239 0.162244 0.281259 0.0756653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86951 episodes
GETTING ACTION FROM:
action 4, numVisits=86945, meanQ=27.307111, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.0106865 0.540063 0.602937 0.493716 0.688376 0.872977 0.332239 0.162244 0.281259 0.0756653 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9076, meanQ=31.281508, numObservations: 9
action 5, numVisits=28, meanQ=26.852143, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 26217 episodes
GETTING ACTION FROM:
action 2, numVisits=35277, meanQ=25.801862, numObservations: 9
action 5, numVisits=44, meanQ=23.156765, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.0106865 0.540063 0.602937 0.493716 0.688376 0.872977 0.332239 0.162244 0.281259 0.0756653 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 11
Initial state: 0 0.534851 0.468085 0.696293 0.705814 0.049729 0.301966 0.310406 0.734922 0.925922 0.457324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87325 episodes
GETTING ACTION FROM:
action 1, numVisits=87313, meanQ=26.732820, numObservations: 9
action 4, numVisits=6, meanQ=9.233750, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.534851 0.468085 0.696293 0.705814 0.049729 0.301966 0.310406 0.734922 0.925922 0.457324 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 12
Initial state: 0 0.559396 0.825344 0.464721 0.410661 0.222547 0.902449 0.134605 0.241177 0.199293 0.655879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87346 episodes
GETTING ACTION FROM:
action 5, numVisits=87338, meanQ=26.718393, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.559396 0.825344 0.464721 0.410661 0.222547 0.902449 0.134605 0.241177 0.199293 0.655879 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 13
Initial state: 0 0.946923 0.660882 0.513843 0.652973 0.474459 0.40927 0.253357 0.69179 0.00793298 0.787304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84325 episodes
GETTING ACTION FROM:
action 2, numVisits=84307, meanQ=26.544050, numObservations: 9
action 3, numVisits=12, meanQ=13.996042, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.946923 0.660882 0.513843 0.652973 0.474459 0.40927 0.253357 0.69179 0.00793298 0.787304 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 14
Initial state: 0 0.519019 0.988348 0.706792 0.664777 0.353715 0.680511 0.452821 0.417897 0.353143 0.771197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49431 episodes
GETTING ACTION FROM:
action 0, numVisits=49335, meanQ=59.570201, numObservations: 243
action -1, numVisits=79, meanQ=-1.244810, numObservations: 71
action 4, numVisits=9, meanQ=-3.883333, numObservations: 5
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.519019 0.988348 0.706792 0.664777 0.353715 0.680511 0.452821 0.417897 0.353143 0.771197 w: 1
Observation: 0 0 3 0 3 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=383, meanQ=65.213991, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 98860 episodes
GETTING ACTION FROM:
action 3, numVisits=99243, meanQ=68.869481, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.519019 0.988348 0.706792 0.664777 0.353715 0.680511 0.452821 0.417897 0.353143 0.771197 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=18973, meanQ=89.591458, numObservations: 9
action 2, numVisits=4, meanQ=49.000000, numObservations: 2
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 77081 episodes
GETTING ACTION FROM:
action 4, numVisits=96054, meanQ=88.631997, numObservations: 9
action 2, numVisits=4, meanQ=49.000000, numObservations: 2
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.519019 0.988348 0.706792 0.664777 0.353715 0.680511 0.452821 0.417897 0.353143 0.771197 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 15
Initial state: 0 0.278047 0.117133 0.556072 0.471926 0.154768 0.632503 0.775656 0.0766608 0.838911 0.33846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86331 episodes
GETTING ACTION FROM:
action 2, numVisits=86315, meanQ=26.709917, numObservations: 9
action -1, numVisits=6, meanQ=-1.050000, numObservations: 6
action 0, numVisits=6, meanQ=-1.050000, numObservations: 6
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.278047 0.117133 0.556072 0.471926 0.154768 0.632503 0.775656 0.0766608 0.838911 0.33846 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 16
Initial state: 0 0.765737 0.955508 0.57202 0.493079 0.418119 0.342275 0.996105 0.808433 0.837942 0.146593 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86114 episodes
GETTING ACTION FROM:
action 1, numVisits=86101, meanQ=26.618118, numObservations: 9
action 4, numVisits=8, meanQ=21.500000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.765737 0.955508 0.57202 0.493079 0.418119 0.342275 0.996105 0.808433 0.837942 0.146593 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 17
Initial state: 0 0.553022 0.429225 0.0512042 0.85946 0.492031 0.861739 0.259349 0.600705 0.505361 0.81032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84733 episodes
GETTING ACTION FROM:
action 2, numVisits=84496, meanQ=27.790358, numObservations: 9
action 4, numVisits=229, meanQ=23.724992, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.553022 0.429225 0.0512042 0.85946 0.492031 0.861739 0.259349 0.600705 0.505361 0.81032 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8581, meanQ=31.828700, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 26434 episodes
GETTING ACTION FROM:
action 3, numVisits=35015, meanQ=33.274732, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.553022 0.429225 0.0512042 0.85946 0.492031 0.861739 0.259349 0.600705 0.505361 0.81032 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 18
Initial state: 0 0.63029 0.874693 0.656575 0.361532 0.615218 0.0227877 0.796576 0.0520856 0.578471 0.460213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80042 episodes
GETTING ACTION FROM:
action 3, numVisits=80005, meanQ=28.339439, numObservations: 9
action 1, numVisits=10, meanQ=15.595000, numObservations: 5
action 5, numVisits=22, meanQ=13.856932, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.63029 0.874693 0.656575 0.361532 0.615218 0.0227877 0.796576 0.0520856 0.578471 0.460213 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 19
Initial state: 0 0.547928 0.51418 0.81261 0.671085 0.493414 0.713552 0.709274 0.723885 0.422348 0.161131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48431 episodes
GETTING ACTION FROM:
action -1, numVisits=48413, meanQ=46.052559, numObservations: 243
action 0, numVisits=11, meanQ=-1.050000, numObservations: 11
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.547928 0.51418 0.81261 0.671085 0.493414 0.713552 0.709274 0.723885 0.422348 0.161131 w: 1
Observation: 0 2 0 3 0 2 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=161, meanQ=36.315357, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 101133 episodes
GETTING ACTION FROM:
action 1, numVisits=101294, meanQ=39.353131, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.547928 0.51418 0.81261 0.671085 0.493414 0.713552 0.709274 0.723885 0.422348 0.161131 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 20
Initial state: 0 0.572842 0.376834 0.213702 0.714674 0.523708 0.118772 0.53398 0.43526 0.812844 0.856887 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48140 episodes
GETTING ACTION FROM:
action 0, numVisits=48069, meanQ=56.637737, numObservations: 243
action 1, numVisits=26, meanQ=-3.115385, numObservations: 9
action -1, numVisits=39, meanQ=-3.853718, numObservations: 36
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.572842 0.376834 0.213702 0.714674 0.523708 0.118772 0.53398 0.43526 0.812844 0.856887 w: 1
Observation: 0 0 1 0 3 0 1 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=268, meanQ=85.284179, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 110298 episodes
GETTING ACTION FROM:
action 4, numVisits=110566, meanQ=87.811451, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.572842 0.376834 0.213702 0.714674 0.523708 0.118772 0.53398 0.43526 0.812844 0.856887 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 21
Initial state: 0 0.133596 0.867472 0.750241 0.862007 0.801 0.0335338 0.384294 0.244389 0.569615 0.532826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88658 episodes
GETTING ACTION FROM:
action 2, numVisits=88614, meanQ=26.191151, numObservations: 9
action 5, numVisits=37, meanQ=0.981486, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.133596 0.867472 0.750241 0.862007 0.801 0.0335338 0.384294 0.244389 0.569615 0.532826 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 22
Initial state: 0 0.471928 0.151077 0.519192 0.530149 0.0747848 0.415588 0.379445 0.617534 0.961555 0.880757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83804 episodes
GETTING ACTION FROM:
action 1, numVisits=83791, meanQ=27.848168, numObservations: 9
action 2, numVisits=4, meanQ=21.500000, numObservations: 4
action 4, numVisits=5, meanQ=15.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.471928 0.151077 0.519192 0.530149 0.0747848 0.415588 0.379445 0.617534 0.961555 0.880757 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7872, meanQ=46.453229, numObservations: 9
action 4, numVisits=6, meanQ=14.158333, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 30614 episodes
GETTING ACTION FROM:
action 4, numVisits=30616, meanQ=47.883634, numObservations: 9
action 1, numVisits=7876, meanQ=46.471730, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.471928 0.151077 0.519192 0.530149 0.0747848 0.415588 0.379445 0.617534 0.961555 0.880757 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 23
Initial state: 0 0.477546 0.15965 0.113738 0.223125 0.173817 0.346147 0.504338 0.5137 0.0133988 0.799265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84461 episodes
GETTING ACTION FROM:
action 5, numVisits=84447, meanQ=27.719637, numObservations: 9
action 2, numVisits=9, meanQ=19.555556, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.477546 0.15965 0.113738 0.223125 0.173817 0.346147 0.504338 0.5137 0.0133988 0.799265 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 24
Initial state: 0 0.544567 0.295383 0.597862 0.248625 0.229251 0.751816 0.601816 0.484461 0.749916 0.352781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49086 episodes
GETTING ACTION FROM:
action 0, numVisits=49064, meanQ=58.328547, numObservations: 243
action -1, numVisits=17, meanQ=-1.667500, numObservations: 16
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.544567 0.295383 0.597862 0.248625 0.229251 0.751816 0.601816 0.484461 0.749916 0.352781 w: 1
Observation: 0 0 1 0 1 0 3 0 2 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=79, meanQ=53.557722, numObservations: 9
action 3, numVisits=80, meanQ=46.778899, numObservations: 8
action 4, numVisits=14, meanQ=40.564286, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 97609 episodes
GETTING ACTION FROM:
action 5, numVisits=97688, meanQ=60.590011, numObservations: 9
action 3, numVisits=80, meanQ=46.778899, numObservations: 8
action 4, numVisits=14, meanQ=40.564286, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.544567 0.295383 0.597862 0.248625 0.229251 0.751816 0.601816 0.484461 0.749916 0.352781 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 25
Initial state: 0 0.891035 0.0975222 0.821923 0.915962 0.559839 0.431423 0.489408 0.902343 0.135587 0.0424464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84300 episodes
GETTING ACTION FROM:
action 2, numVisits=84255, meanQ=27.897240, numObservations: 9
action 4, numVisits=39, meanQ=21.038846, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.891035 0.0975222 0.821923 0.915962 0.559839 0.431423 0.489408 0.902343 0.135587 0.0424464 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 26
Initial state: 0 0.223733 0.504111 0.175137 0.306895 0.601893 0.0913535 0.440116 0.524678 0.47162 0.785539 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48936 episodes
GETTING ACTION FROM:
action 0, numVisits=48917, meanQ=59.325050, numObservations: 243
action -1, numVisits=8, meanQ=-2.362188, numObservations: 7
action 3, numVisits=5, meanQ=-3.000000, numObservations: 5
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.223733 0.504111 0.175137 0.306895 0.601893 0.0913535 0.440116 0.524678 0.47162 0.785539 w: 1
Observation: 0 0 2 0 2 0 1 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=73, meanQ=27.112666, numObservations: 41
action 4, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=6, meanQ=-1.050000, numObservations: 6
action 5, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 47345 episodes
GETTING ACTION FROM:
action 0, numVisits=47418, meanQ=59.404871, numObservations: 242
action 4, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=6, meanQ=-1.050000, numObservations: 6
action 5, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.223733 0.504111 0.175137 0.306895 0.601893 0.0913535 0.440116 0.524678 0.47162 0.785539 w: 1
Observation: 0 0 2 0 1 0 1 0 2 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=2027, meanQ=64.048851, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 104007 episodes
GETTING ACTION FROM:
action 5, numVisits=106034, meanQ=65.734297, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.223733 0.504111 0.175137 0.306895 0.601893 0.0913535 0.440116 0.524678 0.47162 0.785539 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 27
Initial state: 0 0.392835 0.0817069 0.189421 0.545336 0.497296 0.220987 0.450288 0.492048 0.700081 0.390292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88196 episodes
GETTING ACTION FROM:
action 2, numVisits=88188, meanQ=26.701451, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.392835 0.0817069 0.189421 0.545336 0.497296 0.220987 0.450288 0.492048 0.700081 0.390292 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=8234, meanQ=32.943035, numObservations: 9
action 4, numVisits=3, meanQ=26.300000, numObservations: 3
action 2, numVisits=12, meanQ=24.550417, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 34340 episodes
GETTING ACTION FROM:
action 5, numVisits=42572, meanQ=37.828442, numObservations: 9
action 2, numVisits=12, meanQ=24.550417, numObservations: 6
action 4, numVisits=5, meanQ=15.380000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 2 0.392835 0.0817069 0.189421 0.545336 0.497296 0.220987 0.450288 0.492048 0.700081 0.390292 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 28
Initial state: 0 0.443761 0.508043 0.429846 0.737017 0.164227 0.0353054 0.349329 0.859033 0.215022 0.517295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85715 episodes
GETTING ACTION FROM:
action 1, numVisits=85702, meanQ=27.241434, numObservations: 9
action 2, numVisits=8, meanQ=24.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.443761 0.508043 0.429846 0.737017 0.164227 0.0353054 0.349329 0.859033 0.215022 0.517295 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 29
Initial state: 0 0.538237 0.687636 0.616062 0.738866 0.489149 0.217773 0.544646 0.484781 0.468817 0.135502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88099 episodes
GETTING ACTION FROM:
action 3, numVisits=88084, meanQ=26.277716, numObservations: 9
action 5, numVisits=5, meanQ=15.000000, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=5, meanQ=-6.190000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.538237 0.687636 0.616062 0.738866 0.489149 0.217773 0.544646 0.484781 0.468817 0.135502 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 30
Initial state: 0 0.325047 0.330023 0.570094 0.417179 0.638745 0.576028 0.502983 0.0831854 0.611345 0.902402 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86965 episodes
GETTING ACTION FROM:
action 3, numVisits=86959, meanQ=26.066196, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.325047 0.330023 0.570094 0.417179 0.638745 0.576028 0.502983 0.0831854 0.611345 0.902402 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 31
Initial state: 0 0.271728 0.250011 0.6461 0.69075 0.561068 0.109277 0.47424 0.499042 0.737148 0.742123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87810 episodes
GETTING ACTION FROM:
action 2, numVisits=87710, meanQ=26.572516, numObservations: 9
action 4, numVisits=93, meanQ=18.264597, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.271728 0.250011 0.6461 0.69075 0.561068 0.109277 0.47424 0.499042 0.737148 0.742123 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 32
Initial state: 0 0.10712 0.360655 0.518073 0.446871 0.684351 0.934438 0.697869 0.404339 0.305978 0.382881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48279 episodes
GETTING ACTION FROM:
action 0, numVisits=48248, meanQ=57.840348, numObservations: 243
action 5, numVisits=9, meanQ=-6.349722, numObservations: 7
action -1, numVisits=18, meanQ=-6.433333, numObservations: 17
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.10712 0.360655 0.518073 0.446871 0.684351 0.934438 0.697869 0.404339 0.305978 0.382881 w: 1
Observation: 0 0 1 0 2 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=188, meanQ=43.793144, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 75260 episodes
GETTING ACTION FROM:
action 3, numVisits=75448, meanQ=58.925368, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.10712 0.360655 0.518073 0.446871 0.684351 0.934438 0.697869 0.404339 0.305978 0.382881 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 33
Initial state: 0 0.806616 0.378348 0.149229 0.653833 0.863725 0.475391 0.817384 0.504151 0.421166 0.465968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88418 episodes
GETTING ACTION FROM:
action 3, numVisits=88405, meanQ=27.251771, numObservations: 9
action 1, numVisits=8, meanQ=6.556562, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.806616 0.378348 0.149229 0.653833 0.863725 0.475391 0.817384 0.504151 0.421166 0.465968 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 34
Initial state: 0 0.419251 0.89222 0.41779 0.511419 0.480713 0.952201 0.228849 0.168019 0.624692 0.607877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82348 episodes
GETTING ACTION FROM:
action 4, numVisits=82337, meanQ=28.858150, numObservations: 9
action 2, numVisits=5, meanQ=15.190000, numObservations: 5
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.419251 0.89222 0.41779 0.511419 0.480713 0.952201 0.228849 0.168019 0.624692 0.607877 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1202, meanQ=30.369583, numObservations: 9
action -1, numVisits=96, meanQ=-3.856953, numObservations: 77
action 0, numVisits=35, meanQ=-4.282714, numObservations: 30
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=4, meanQ=-28.262500, numObservations: 3
Sampled 75861 episodes
GETTING ACTION FROM:
action 1, numVisits=77063, meanQ=4.109171, numObservations: 9
action -1, numVisits=96, meanQ=-3.856953, numObservations: 77
action 0, numVisits=35, meanQ=-4.282714, numObservations: 30
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=4, meanQ=-28.262500, numObservations: 3
action: 1
Next state: 1 0.419251 0.89222 0.41779 0.511419 0.480713 0.952201 0.228849 0.168019 0.624692 0.607877 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 35
Initial state: 0 0.102067 0.309783 0.597497 0.116902 0.454104 0.454402 0.678226 0.286057 0.644862 0.601217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89084 episodes
GETTING ACTION FROM:
action 1, numVisits=89061, meanQ=27.861101, numObservations: 9
action 2, numVisits=17, meanQ=26.114706, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.102067 0.309783 0.597497 0.116902 0.454104 0.454402 0.678226 0.286057 0.644862 0.601217 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=9156, meanQ=32.911279, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 29170 episodes
GETTING ACTION FROM:
action 5, numVisits=38326, meanQ=28.298006, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.102067 0.309783 0.597497 0.116902 0.454104 0.454402 0.678226 0.286057 0.644862 0.601217 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 36
Initial state: 0 0.432671 0.417411 0.00103015 0.709526 0.122695 0.861811 0.213733 0.730494 0.961364 0.4255 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87566 episodes
GETTING ACTION FROM:
action 2, numVisits=87536, meanQ=26.255558, numObservations: 9
action 5, numVisits=21, meanQ=13.350357, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.432671 0.417411 0.00103015 0.709526 0.122695 0.861811 0.213733 0.730494 0.961364 0.4255 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=464, meanQ=38.291188, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 105399 episodes
GETTING ACTION FROM:
action 4, numVisits=105863, meanQ=48.190669, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.432671 0.417411 0.00103015 0.709526 0.122695 0.861811 0.213733 0.730494 0.961364 0.4255 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=319, meanQ=42.909450, numObservations: 9
action 1, numVisits=8, meanQ=24.000000, numObservations: 3
action 3, numVisits=11, meanQ=21.531818, numObservations: 7
action 2, numVisits=4, meanQ=20.250000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 139124 episodes
GETTING ACTION FROM:
action 3, numVisits=138850, meanQ=68.653399, numObservations: 9
action 4, numVisits=597, meanQ=59.956725, numObservations: 9
action 2, numVisits=4, meanQ=20.250000, numObservations: 1
action 1, numVisits=15, meanQ=19.000000, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.432671 0.417411 0.00103015 0.709526 0.122695 0.861811 0.213733 0.730494 0.961364 0.4255 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 37
Initial state: 0 0.916914 0.744305 0.0200768 0.439183 0.706918 0.283555 0.91682 0.641599 0.605076 0.496982 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87222 episodes
GETTING ACTION FROM:
action 4, numVisits=87216, meanQ=26.907000, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.916914 0.744305 0.0200768 0.439183 0.706918 0.283555 0.91682 0.641599 0.605076 0.496982 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 38
Initial state: 0 0.299025 0.0264114 0.26634 0.611139 0.450606 0.808197 0.410593 0.476597 0.278637 0.694191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86470 episodes
GETTING ACTION FROM:
action 4, numVisits=86455, meanQ=26.098904, numObservations: 9
action 5, numVisits=9, meanQ=20.216667, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.299025 0.0264114 0.26634 0.611139 0.450606 0.808197 0.410593 0.476597 0.278637 0.694191 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 39
Initial state: 0 0.212006 0.821269 0.948996 0.769289 0.529242 0.527613 0.0499594 0.231164 0.229815 0.494582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86976 episodes
GETTING ACTION FROM:
action 3, numVisits=86956, meanQ=26.709356, numObservations: 9
action 2, numVisits=15, meanQ=4.333333, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.212006 0.821269 0.948996 0.769289 0.529242 0.527613 0.0499594 0.231164 0.229815 0.494582 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 40
Initial state: 0 0.413103 0.437835 0.749751 0.0835112 0.313264 0.933455 0.0882605 0.819923 0.252992 0.172743 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87260 episodes
GETTING ACTION FROM:
action 1, numVisits=87253, meanQ=27.281709, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.413103 0.437835 0.749751 0.0835112 0.313264 0.933455 0.0882605 0.819923 0.252992 0.172743 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.173068 0.510177 0.477184 0.415546 0.476927 0.883339 0.399206 0.677191 0.389966 0.59694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88683 episodes
GETTING ACTION FROM:
action 4, numVisits=88676, meanQ=26.388599, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.173068 0.510177 0.477184 0.415546 0.476927 0.883339 0.399206 0.677191 0.389966 0.59694 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=3322, meanQ=31.638748, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 41529 episodes
GETTING ACTION FROM:
action 5, numVisits=44851, meanQ=33.168800, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.173068 0.510177 0.477184 0.415546 0.476927 0.883339 0.399206 0.677191 0.389966 0.59694 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1575, meanQ=41.402957, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 42975 episodes
GETTING ACTION FROM:
action 2, numVisits=44550, meanQ=41.128425, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.173068 0.510177 0.477184 0.415546 0.476927 0.883339 0.399206 0.677191 0.389966 0.59694 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 42
Initial state: 0 0.412865 0.600465 0.18026 0.2875 0.333901 0.455148 0.0978244 0.662588 0.450132 0.504863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49185 episodes
GETTING ACTION FROM:
action 0, numVisits=49163, meanQ=58.108754, numObservations: 243
action -1, numVisits=9, meanQ=-1.266389, numObservations: 8
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=7, meanQ=-5.285714, numObservations: 6
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.412865 0.600465 0.18026 0.2875 0.333901 0.455148 0.0978244 0.662588 0.450132 0.504863 w: 1
Observation: 0 0 3 0 1 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=344, meanQ=83.747903, numObservations: 9
action 1, numVisits=7, meanQ=38.993214, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 113845 episodes
GETTING ACTION FROM:
action 5, numVisits=114189, meanQ=91.653500, numObservations: 9
action 1, numVisits=7, meanQ=38.993214, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.412865 0.600465 0.18026 0.2875 0.333901 0.455148 0.0978244 0.662588 0.450132 0.504863 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 43
Initial state: 0 0.642856 0.0257056 0.838593 0.124723 0.469734 0.525034 0.935343 0.216234 0.806946 0.443039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82316 episodes
GETTING ACTION FROM:
action 3, numVisits=82305, meanQ=28.321520, numObservations: 9
action 5, numVisits=5, meanQ=19.000000, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.642856 0.0257056 0.838593 0.124723 0.469734 0.525034 0.935343 0.216234 0.806946 0.443039 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3160, meanQ=32.521844, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 28349 episodes
GETTING ACTION FROM:
action 2, numVisits=31509, meanQ=24.831365, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.642856 0.0257056 0.838593 0.124723 0.469734 0.525034 0.935343 0.216234 0.806946 0.443039 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 44
Initial state: 0 0.874334 0.371814 0.22451 0.731775 0.109863 0.963224 0.411811 0.689813 0.529224 0.510209 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83749 episodes
GETTING ACTION FROM:
action 4, numVisits=83729, meanQ=26.975887, numObservations: 9
action -1, numVisits=3, meanQ=-1.050000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 1, numVisits=11, meanQ=-3.727273, numObservations: 6
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.874334 0.371814 0.22451 0.731775 0.109863 0.963224 0.411811 0.689813 0.529224 0.510209 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 45
Initial state: 0 0.52383 0.746461 0.169276 0.96302 0.428453 0.845001 0.363941 0.167733 0.505838 0.497162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88854 episodes
GETTING ACTION FROM:
action 4, numVisits=88837, meanQ=26.653701, numObservations: 9
action 2, numVisits=7, meanQ=22.057500, numObservations: 5
action 5, numVisits=6, meanQ=9.075417, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.52383 0.746461 0.169276 0.96302 0.428453 0.845001 0.363941 0.167733 0.505838 0.497162 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 46
Initial state: 0 0.917401 0.947849 0.0233257 0.323983 0.443786 0.529613 0.68868 0.107193 0.822766 0.980794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87973 episodes
GETTING ACTION FROM:
action 4, numVisits=87967, meanQ=26.480537, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.917401 0.947849 0.0233257 0.323983 0.443786 0.529613 0.68868 0.107193 0.822766 0.980794 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 47
Initial state: 0 0.424934 0.420327 0.500821 0.108156 0.316338 0.690712 0.0525309 0.117793 0.342398 0.0482824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49275 episodes
GETTING ACTION FROM:
action 0, numVisits=49247, meanQ=58.727695, numObservations: 243
action -1, numVisits=14, meanQ=-1.050000, numObservations: 14
action 4, numVisits=8, meanQ=-6.124688, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.424934 0.420327 0.500821 0.108156 0.316338 0.690712 0.0525309 0.117793 0.342398 0.0482824 w: 1
Observation: 0 0 2 0 1 0 3 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=263, meanQ=87.154183, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 110234 episodes
GETTING ACTION FROM:
action 1, numVisits=110497, meanQ=85.471064, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.424934 0.420327 0.500821 0.108156 0.316338 0.690712 0.0525309 0.117793 0.342398 0.0482824 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 48
Initial state: 0 0.483267 0.502247 0.855626 0.236383 0.786256 0.293428 0.890258 0.490541 0.815964 0.235018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47825 episodes
GETTING ACTION FROM:
action -1, numVisits=47753, meanQ=43.686346, numObservations: 243
action 0, numVisits=59, meanQ=-1.422754, numObservations: 52
action 1, numVisits=9, meanQ=-2.772222, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.483267 0.502247 0.855626 0.236383 0.786256 0.293428 0.890258 0.490541 0.815964 0.235018 w: 1
Observation: 0 2 0 2 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=195, meanQ=39.006769, numObservations: 9
action 5, numVisits=3, meanQ=26.300000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 111890 episodes
GETTING ACTION FROM:
action 2, numVisits=112085, meanQ=45.719484, numObservations: 9
action 5, numVisits=3, meanQ=26.300000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.483267 0.502247 0.855626 0.236383 0.786256 0.293428 0.890258 0.490541 0.815964 0.235018 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 49
Initial state: 0 0.549365 0.41286 0.128563 0.619856 0.968019 0.471745 0.816322 0.328072 0.0257748 0.636099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88043 episodes
GETTING ACTION FROM:
action 3, numVisits=88034, meanQ=26.069692, numObservations: 9
action 1, numVisits=4, meanQ=21.737500, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.549365 0.41286 0.128563 0.619856 0.968019 0.471745 0.816322 0.328072 0.0257748 0.636099 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 50
Initial state: 0 0.382494 0.683487 0.627097 0.332466 0.459773 0.415944 0.161615 0.431648 0.853414 0.572595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86473 episodes
GETTING ACTION FROM:
action 3, numVisits=86459, meanQ=26.853767, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=7, meanQ=-2.428571, numObservations: 5
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.382494 0.683487 0.627097 0.332466 0.459773 0.415944 0.161615 0.431648 0.853414 0.572595 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
[32m ProblemEnvironment.hpp 351: Done.[39m
