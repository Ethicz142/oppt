Run # 1
Initial state: 0 0.903047 0.561613 0.487696 0.374541 0.239761 0.967481 0.753023 0.532267 0.36207 0.29153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97108 episodes
GETTING ACTION FROM:
action 4, numVisits=97083, meanQ=39.591540, numObservations: 9
action 2, numVisits=19, meanQ=12.631711, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.903047 0.561613 0.487696 0.374541 0.239761 0.967481 0.753023 0.532267 0.36207 0.29153 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 2
Initial state: 0 0.719181 0.0720991 0.884854 0.750712 0.643835 0.710762 0.721893 0.0214909 0.323748 0.328381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93716 episodes
GETTING ACTION FROM:
action 3, numVisits=93707, meanQ=41.008441, numObservations: 9
action 2, numVisits=3, meanQ=25.666667, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.719181 0.0720991 0.884854 0.750712 0.643835 0.710762 0.721893 0.0214909 0.323748 0.328381 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 3
Initial state: 0 0.622813 0.254091 0.517144 0.797853 0.367314 0.331578 0.166404 0.640571 0.598161 0.947364 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98974 episodes
GETTING ACTION FROM:
action 2, numVisits=98881, meanQ=40.986122, numObservations: 9
action 5, numVisits=87, meanQ=39.900029, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.622813 0.254091 0.517144 0.797853 0.367314 0.331578 0.166404 0.640571 0.598161 0.947364 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 4
Initial state: 0 0.202285 0.160853 0.166114 0.926792 0.131067 0.163527 0.45319 0.714323 0.305041 0.332842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97852 episodes
GETTING ACTION FROM:
action 2, numVisits=97841, meanQ=40.620213, numObservations: 9
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.202285 0.160853 0.166114 0.926792 0.131067 0.163527 0.45319 0.714323 0.305041 0.332842 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 5
Initial state: 0 0.592707 0.775409 0.351827 0.398591 0.779253 0.721173 0.782953 0.573252 0.254555 0.809384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94585 episodes
GETTING ACTION FROM:
action 2, numVisits=94567, meanQ=40.352553, numObservations: 9
action 3, numVisits=11, meanQ=32.636364, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.592707 0.775409 0.351827 0.398591 0.779253 0.721173 0.782953 0.573252 0.254555 0.809384 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 6
Initial state: 0 0.847015 0.133622 0.322354 0.305077 0.902073 0.0130719 0.248183 0.118866 0.123561 0.424565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92322 episodes
GETTING ACTION FROM:
action 2, numVisits=92307, meanQ=40.213286, numObservations: 9
action 1, numVisits=3, meanQ=25.666667, numObservations: 3
action 5, numVisits=8, meanQ=24.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.847015 0.133622 0.322354 0.305077 0.902073 0.0130719 0.248183 0.118866 0.123561 0.424565 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 7
Initial state: 0 0.978107 0.473939 0.673539 0.684194 0.455871 0.949884 0.393892 0.308359 0.62175 0.847623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96249 episodes
GETTING ACTION FROM:
action 1, numVisits=96242, meanQ=40.992093, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.978107 0.473939 0.673539 0.684194 0.455871 0.949884 0.393892 0.308359 0.62175 0.847623 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 8
Initial state: 0 0.313812 0.724351 0.186155 0.968801 0.348187 0.0261421 0.313196 0.278319 0.441254 0.0130843 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97099 episodes
GETTING ACTION FROM:
action 5, numVisits=97093, meanQ=39.837852, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.313812 0.724351 0.186155 0.968801 0.348187 0.0261421 0.313196 0.278319 0.441254 0.0130843 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1481, meanQ=48.073300, numObservations: 9
action 4, numVisits=5, meanQ=37.190000, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 103627 episodes
GETTING ACTION FROM:
action 3, numVisits=105107, meanQ=28.053927, numObservations: 9
action 4, numVisits=6, meanQ=14.158333, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.313812 0.724351 0.186155 0.968801 0.348187 0.0261421 0.313196 0.278319 0.441254 0.0130843 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=63, meanQ=33.660080, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 110286 episodes
GETTING ACTION FROM:
action 1, numVisits=110349, meanQ=43.932359, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.313812 0.724351 0.186155 0.968801 0.348187 0.0261421 0.313196 0.278319 0.441254 0.0130843 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -112.603
Run # 9
Initial state: 0 0.650054 0.126325 0.886323 0.83182 0.801048 0.323892 0.743837 0.733089 0.331141 0.401344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91753 episodes
GETTING ACTION FROM:
action 3, numVisits=91746, meanQ=39.657492, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.650054 0.126325 0.886323 0.83182 0.801048 0.323892 0.743837 0.733089 0.331141 0.401344 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 10
Initial state: 0 0.644357 0.261805 0.810224 0.63473 0.536771 0.553666 0.974562 0.294369 0.39498 0.334066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91272 episodes
GETTING ACTION FROM:
action 1, numVisits=91206, meanQ=39.909270, numObservations: 9
action 3, numVisits=54, meanQ=36.719491, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action 4, numVisits=6, meanQ=29.158333, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.644357 0.261805 0.810224 0.63473 0.536771 0.553666 0.974562 0.294369 0.39498 0.334066 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 11
Initial state: 0 0.463395 0.392907 0.126275 0.107724 0.443669 0.320942 0.734355 0.613428 0.109916 0.722335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98478 episodes
GETTING ACTION FROM:
action 3, numVisits=98467, meanQ=40.516456, numObservations: 9
action 5, numVisits=5, meanQ=19.000000, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.463395 0.392907 0.126275 0.107724 0.443669 0.320942 0.734355 0.613428 0.109916 0.722335 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 12
Initial state: 0 0.915193 0.197134 0.857716 0.552762 0.334993 0.371603 0.917203 0.794325 0.847102 0.436585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97805 episodes
GETTING ACTION FROM:
action 1, numVisits=97767, meanQ=40.490176, numObservations: 9
action 2, numVisits=27, meanQ=28.730000, numObservations: 7
action 5, numVisits=3, meanQ=25.666667, numObservations: 3
action 4, numVisits=5, meanQ=19.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.915193 0.197134 0.857716 0.552762 0.334993 0.371603 0.917203 0.794325 0.847102 0.436585 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 13
Initial state: 0 0.366411 0.468854 0.908334 0.763533 0.521863 0.55158 0.324696 0.0589531 0.443849 0.38632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97378 episodes
GETTING ACTION FROM:
action 3, numVisits=97344, meanQ=39.655579, numObservations: 9
action 5, numVisits=21, meanQ=23.528929, numObservations: 8
action 2, numVisits=9, meanQ=20.111111, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.366411 0.468854 0.908334 0.763533 0.521863 0.55158 0.324696 0.0589531 0.443849 0.38632 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 14
Initial state: 0 0.855222 0.291881 0.309826 0.298239 0.648389 0.477595 0.0364387 0.303428 0.873772 0.197585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98493 episodes
GETTING ACTION FROM:
action 1, numVisits=98460, meanQ=40.243115, numObservations: 9
action -1, numVisits=24, meanQ=-5.249792, numObservations: 21
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=5, meanQ=-20.430000, numObservations: 4
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.855222 0.291881 0.309826 0.298239 0.648389 0.477595 0.0364387 0.303428 0.873772 0.197585 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 15
Initial state: 0 0.453118 0.368506 0.125625 0.487014 0.0999651 0.993708 0.268471 0.265387 0.373925 0.0906112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98498 episodes
GETTING ACTION FROM:
action 4, numVisits=98485, meanQ=39.712373, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=6, meanQ=-4.175000, numObservations: 6
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.453118 0.368506 0.125625 0.487014 0.0999651 0.993708 0.268471 0.265387 0.373925 0.0906112 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5108, meanQ=43.919475, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34634 episodes
GETTING ACTION FROM:
action 3, numVisits=39742, meanQ=37.163454, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.453118 0.368506 0.125625 0.487014 0.0999651 0.993708 0.268471 0.265387 0.373925 0.0906112 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=2796, meanQ=47.937760, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 21459 episodes
GETTING ACTION FROM:
action 2, numVisits=24255, meanQ=47.457960, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.453118 0.368506 0.125625 0.487014 0.0999651 0.993708 0.268471 0.265387 0.373925 0.0906112 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 16
Initial state: 0 0.937103 0.455065 0.803685 0.0261359 0.954662 0.0956548 0.37228 0.296122 0.191345 0.992281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91920 episodes
GETTING ACTION FROM:
action 5, numVisits=91881, meanQ=40.743110, numObservations: 9
action 4, numVisits=32, meanQ=36.200156, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.937103 0.455065 0.803685 0.0261359 0.954662 0.0956548 0.37228 0.296122 0.191345 0.992281 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=8008, meanQ=49.816420, numObservations: 9
action 2, numVisits=12, meanQ=21.079375, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 41795 episodes
GETTING ACTION FROM:
action 2, numVisits=41806, meanQ=57.991192, numObservations: 9
action 5, numVisits=8009, meanQ=49.815083, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 2 0.937103 0.455065 0.803685 0.0261359 0.954662 0.0956548 0.37228 0.296122 0.191345 0.992281 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 17
Initial state: 0 0.357882 0.340086 0.943696 0.731367 0.900061 0.3749 0.465385 0.293356 0.3496 0.000474959 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95085 episodes
GETTING ACTION FROM:
action 5, numVisits=95078, meanQ=40.935220, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.357882 0.340086 0.943696 0.731367 0.900061 0.3749 0.465385 0.293356 0.3496 0.000474959 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 18
Initial state: 0 0.0356407 0.712135 0.203053 0.0207672 0.780739 0.174821 0.507042 0.99025 0.395409 0.350398 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91851 episodes
GETTING ACTION FROM:
action 4, numVisits=91842, meanQ=41.732346, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0356407 0.712135 0.203053 0.0207672 0.780739 0.174821 0.507042 0.99025 0.395409 0.350398 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 19
Initial state: 0 0.27138 0.566406 0.669145 0.793986 0.332543 0.863709 0.418302 0.392002 0.996547 0.0967457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95515 episodes
GETTING ACTION FROM:
action 3, numVisits=95508, meanQ=40.930561, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.27138 0.566406 0.669145 0.793986 0.332543 0.863709 0.418302 0.392002 0.996547 0.0967457 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 20
Initial state: 0 0.1124 0.899751 0.549619 0.367807 0.0539723 0.326569 0.275879 0.930356 0.390623 0.307414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95322 episodes
GETTING ACTION FROM:
action 2, numVisits=95316, meanQ=41.111600, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.1124 0.899751 0.549619 0.367807 0.0539723 0.326569 0.275879 0.930356 0.390623 0.307414 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 21
Initial state: 0 0.40646 0.40092 0.0352113 0.457741 0.328969 0.0601185 0.0961809 0.795374 0.429578 0.535079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94778 episodes
GETTING ACTION FROM:
action 3, numVisits=94770, meanQ=40.699237, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.40646 0.40092 0.0352113 0.457741 0.328969 0.0601185 0.0961809 0.795374 0.429578 0.535079 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 22
Initial state: 0 0.305956 0.402401 0.720384 0.102765 0.528753 0.220814 0.365841 0.967168 0.578954 0.912592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96536 episodes
GETTING ACTION FROM:
action 4, numVisits=96505, meanQ=39.754245, numObservations: 9
action 3, numVisits=17, meanQ=31.941176, numObservations: 6
action 5, numVisits=10, meanQ=25.995250, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.305956 0.402401 0.720384 0.102765 0.528753 0.220814 0.365841 0.967168 0.578954 0.912592 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 23
Initial state: 0 0.848992 0.516575 0.412556 0.377071 0.70658 0.135899 0.407768 0.903507 0.454075 0.48677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91705 episodes
GETTING ACTION FROM:
action 5, numVisits=91684, meanQ=40.691526, numObservations: 9
action 4, numVisits=12, meanQ=23.245833, numObservations: 7
action 1, numVisits=5, meanQ=15.190000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.848992 0.516575 0.412556 0.377071 0.70658 0.135899 0.407768 0.903507 0.454075 0.48677 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 24
Initial state: 0 0.0456299 0.780569 0.229496 0.0377573 0.994343 0.624875 0.327892 0.351325 0.411992 0.463162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91717 episodes
GETTING ACTION FROM:
action 1, numVisits=91710, meanQ=40.184366, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0456299 0.780569 0.229496 0.0377573 0.994343 0.624875 0.327892 0.351325 0.411992 0.463162 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1074, meanQ=45.052376, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 120016 episodes
GETTING ACTION FROM:
action 5, numVisits=121090, meanQ=58.145309, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.0456299 0.780569 0.229496 0.0377573 0.994343 0.624875 0.327892 0.351325 0.411992 0.463162 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 25
Initial state: 0 0.451987 0.301017 0.405231 0.801564 0.635722 0.829508 0.0446856 0.797647 0.770026 0.184476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97711 episodes
GETTING ACTION FROM:
action 3, numVisits=97668, meanQ=39.768344, numObservations: 9
action 2, numVisits=37, meanQ=5.911216, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.451987 0.301017 0.405231 0.801564 0.635722 0.829508 0.0446856 0.797647 0.770026 0.184476 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 26
Initial state: 0 0.435503 0.288197 0.267345 0.663771 0.843062 0.773967 0.323933 0.275275 0.478913 0.52562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93365 episodes
GETTING ACTION FROM:
action 2, numVisits=93343, meanQ=41.092057, numObservations: 9
action 5, numVisits=17, meanQ=32.582500, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.435503 0.288197 0.267345 0.663771 0.843062 0.773967 0.323933 0.275275 0.478913 0.52562 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=7905, meanQ=64.822823, numObservations: 238
action -1, numVisits=7, meanQ=-2.549643, numObservations: 6
action 1, numVisits=10, meanQ=-2.810000, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 13504 episodes
GETTING ACTION FROM:
action 0, numVisits=21409, meanQ=49.356826, numObservations: 243
action -1, numVisits=7, meanQ=-2.549643, numObservations: 6
action 1, numVisits=10, meanQ=-2.810000, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.435503 0.288197 0.267345 0.663771 0.843062 0.773967 0.323933 0.275275 0.478913 0.52562 w: 1
Observation: 0 0 2 0 3 0 3 0 1 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=293, meanQ=87.908981, numObservations: 9
action 3, numVisits=8, meanQ=59.625000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 76028 episodes
GETTING ACTION FROM:
action 1, numVisits=76321, meanQ=93.748856, numObservations: 9
action 3, numVisits=8, meanQ=59.625000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.435503 0.288197 0.267345 0.663771 0.843062 0.773967 0.323933 0.275275 0.478913 0.52562 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 27
Initial state: 0 0.830507 0.234137 0.40082 0.358624 0.985735 0.849286 0.20946 0.569983 0.976754 0.761163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98700 episodes
GETTING ACTION FROM:
action 4, numVisits=98688, meanQ=40.012049, numObservations: 9
action 5, numVisits=4, meanQ=21.500000, numObservations: 3
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.830507 0.234137 0.40082 0.358624 0.985735 0.849286 0.20946 0.569983 0.976754 0.761163 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 28
Initial state: 0 0.400997 0.410942 0.180009 0.732285 0.764939 0.447454 0.761434 0.366483 0.720723 0.523914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49155 episodes
GETTING ACTION FROM:
action 0, numVisits=49144, meanQ=62.028818, numObservations: 243
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.400997 0.410942 0.180009 0.732285 0.764939 0.447454 0.761434 0.366483 0.720723 0.523914 w: 1
Observation: 0 0 2 0 2 0 3 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=95, meanQ=70.197592, numObservations: 6
action 4, numVisits=9, meanQ=52.544444, numObservations: 7
action 2, numVisits=52, meanQ=50.692404, numObservations: 9
action 1, numVisits=8, meanQ=46.737500, numObservations: 5
action 3, numVisits=11, meanQ=42.809091, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
Sampled 104593 episodes
GETTING ACTION FROM:
action 5, numVisits=104688, meanQ=66.605166, numObservations: 9
action 4, numVisits=9, meanQ=52.544444, numObservations: 7
action 2, numVisits=52, meanQ=50.692404, numObservations: 9
action 1, numVisits=8, meanQ=46.737500, numObservations: 5
action 3, numVisits=11, meanQ=42.809091, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 5
Next state: 1 0.400997 0.410942 0.180009 0.732285 0.764939 0.447454 0.761434 0.366483 0.720723 0.523914 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 29
Initial state: 0 0.1465 0.457713 0.172886 0.0840184 0.328118 0.331117 0.528805 0.663859 0.428715 0.0822814 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50774 episodes
GETTING ACTION FROM:
action -1, numVisits=50763, meanQ=56.070998, numObservations: 243
action 0, numVisits=6, meanQ=-1.050000, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.1465 0.457713 0.172886 0.0840184 0.328118 0.331117 0.528805 0.663859 0.428715 0.0822814 w: 1
Observation: 0 1 0 1 0 2 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=117, meanQ=40.835491, numObservations: 9
action 4, numVisits=14, meanQ=27.571429, numObservations: 3
action 1, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 116089 episodes
GETTING ACTION FROM:
action 3, numVisits=116206, meanQ=52.017554, numObservations: 9
action 4, numVisits=14, meanQ=27.571429, numObservations: 3
action 1, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.1465 0.457713 0.172886 0.0840184 0.328118 0.331117 0.528805 0.663859 0.428715 0.0822814 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 30
Initial state: 0 0.432896 0.00470344 0.0583318 0.2592 0.96114 0.446882 0.459259 0.401567 0.607565 0.525393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 99137 episodes
GETTING ACTION FROM:
action 1, numVisits=99131, meanQ=40.614285, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.432896 0.00470344 0.0583318 0.2592 0.96114 0.446882 0.459259 0.401567 0.607565 0.525393 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 31
Initial state: 0 0.795412 0.460794 0.810341 0.93806 0.448975 0.858129 0.361534 0.297198 0.0184091 0.396213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96035 episodes
GETTING ACTION FROM:
action 3, numVisits=96022, meanQ=39.809120, numObservations: 9
action 2, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 3
Next state: 1 0.795412 0.460794 0.810341 0.93806 0.448975 0.858129 0.361534 0.297198 0.0184091 0.396213 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 32
Initial state: 0 0.282629 0.566013 0.646991 0.809955 0.216294 0.828013 0.410819 0.328183 0.0658705 0.156627 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92932 episodes
GETTING ACTION FROM:
action 1, numVisits=92911, meanQ=41.115119, numObservations: 9
action 4, numVisits=15, meanQ=16.393500, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.282629 0.566013 0.646991 0.809955 0.216294 0.828013 0.410819 0.328183 0.0658705 0.156627 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 33
Initial state: 0 0.620901 0.745499 0.104009 0.912584 0.951399 0.313009 0.0771549 0.481305 0.30878 0.304999 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92240 episodes
GETTING ACTION FROM:
action 3, numVisits=92228, meanQ=40.815301, numObservations: 9
action 5, numVisits=7, meanQ=10.286071, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.620901 0.745499 0.104009 0.912584 0.951399 0.313009 0.0771549 0.481305 0.30878 0.304999 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 34
Initial state: 0 0.844201 0.148335 0.382265 0.345337 0.739173 0.908209 0.59236 0.820377 0.401665 0.0201274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98852 episodes
GETTING ACTION FROM:
action 5, numVisits=98838, meanQ=40.639137, numObservations: 9
action 1, numVisits=5, meanQ=37.000000, numObservations: 5
action 3, numVisits=3, meanQ=25.666667, numObservations: 3
action 4, numVisits=3, meanQ=25.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.844201 0.148335 0.382265 0.345337 0.739173 0.908209 0.59236 0.820377 0.401665 0.0201274 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1095, meanQ=41.789735, numObservations: 9
action 5, numVisits=4, meanQ=17.750000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
Sampled 66104 episodes
GETTING ACTION FROM:
action 1, numVisits=67199, meanQ=30.706812, numObservations: 9
action 5, numVisits=4, meanQ=17.750000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 1
Next state: 0 0.844201 0.148335 0.382265 0.345337 0.739173 0.908209 0.59236 0.820377 0.401665 0.0201274 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=241, meanQ=58.402509, numObservations: 9
action -1, numVisits=26, meanQ=-4.851827, numObservations: 24
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=9, meanQ=-11.816667, numObservations: 8
action 3, numVisits=2, meanQ=-58.500000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 101156 episodes
GETTING ACTION FROM:
action 2, numVisits=101397, meanQ=28.695885, numObservations: 9
action -1, numVisits=26, meanQ=-4.851827, numObservations: 24
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=9, meanQ=-11.816667, numObservations: 8
action 3, numVisits=2, meanQ=-58.500000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.844201 0.148335 0.382265 0.345337 0.739173 0.908209 0.59236 0.820377 0.401665 0.0201274 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 35
Initial state: 0 0.271158 0.222518 0.682613 0.612134 0.361172 0.315535 0.64024 0.180053 0.60566 0.340787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97032 episodes
GETTING ACTION FROM:
action 5, numVisits=97026, meanQ=40.471499, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.271158 0.222518 0.682613 0.612134 0.361172 0.315535 0.64024 0.180053 0.60566 0.340787 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 36
Initial state: 0 0.447185 0.613019 0.335271 0.349377 0.671893 0.757576 0.921001 0.448626 0.878101 0.176771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95194 episodes
GETTING ACTION FROM:
action 4, numVisits=95185, meanQ=40.632162, numObservations: 9
action 5, numVisits=4, meanQ=21.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.447185 0.613019 0.335271 0.349377 0.671893 0.757576 0.921001 0.448626 0.878101 0.176771 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 37
Initial state: 0 0.144945 0.0696391 0.454918 0.306831 0.0450159 0.465286 0.233971 0.749849 0.61346 0.465953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95466 episodes
GETTING ACTION FROM:
action 3, numVisits=95460, meanQ=38.485809, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.144945 0.0696391 0.454918 0.306831 0.0450159 0.465286 0.233971 0.749849 0.61346 0.465953 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=8334, meanQ=45.297621, numObservations: 9
action 1, numVisits=7, meanQ=39.271429, numObservations: 6
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 47090 episodes
GETTING ACTION FROM:
action 1, numVisits=43881, meanQ=46.054803, numObservations: 9
action 4, numVisits=11550, meanQ=43.892441, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 0 0.144945 0.0696391 0.454918 0.306831 0.0450159 0.465286 0.233971 0.749849 0.61346 0.465953 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=944, meanQ=73.074360, numObservations: 9
action 4, numVisits=5, meanQ=59.000000, numObservations: 4
action 5, numVisits=5, meanQ=54.546630, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-12.074921, numObservations: 1
action 3, numVisits=1, meanQ=-215.370823, numObservations: 1
Sampled 42096 episodes
GETTING ACTION FROM:
action 2, numVisits=43040, meanQ=66.294521, numObservations: 9
action 4, numVisits=5, meanQ=59.000000, numObservations: 4
action 5, numVisits=5, meanQ=54.546630, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-12.074921, numObservations: 1
action 3, numVisits=1, meanQ=-215.370823, numObservations: 1
action: 2
Next state: 0 0.144945 0.0696391 0.454918 0.306831 0.0450159 0.465286 0.233971 0.749849 0.61346 0.465953 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=99.000000, numObservations: 1
action 2, numVisits=560, meanQ=94.677870, numObservations: 9
action 4, numVisits=4, meanQ=49.000000, numObservations: 3
action 5, numVisits=2, meanQ=43.431952, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-12.102681, numObservations: 1
Sampled 82728 episodes
GETTING ACTION FROM:
action 2, numVisits=676, meanQ=94.508369, numObservations: 9
action 3, numVisits=26, meanQ=91.307692, numObservations: 4
action 5, numVisits=82538, meanQ=56.440802, numObservations: 9
action 4, numVisits=55, meanQ=22.636364, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-12.102681, numObservations: 1
action: 2
Next state: 1 0.144945 0.0696391 0.454918 0.306831 0.0450159 0.465286 0.233971 0.749849 0.61346 0.465953 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 53.5026
Run # 38
Initial state: 0 0.629245 0.0235449 0.580844 0.302047 0.870591 0.961393 0.41202 0.34022 0.972094 0.838062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97822 episodes
GETTING ACTION FROM:
action 3, numVisits=97805, meanQ=40.374863, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 5, numVisits=7, meanQ=-5.285714, numObservations: 6
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.629245 0.0235449 0.580844 0.302047 0.870591 0.961393 0.41202 0.34022 0.972094 0.838062 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 39
Initial state: 0 0.182387 0.933455 0.991132 0.929762 0.984153 0.962975 0.692715 0.543111 0.389365 0.279407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98681 episodes
GETTING ACTION FROM:
action 5, numVisits=98638, meanQ=40.402413, numObservations: 9
action 2, numVisits=34, meanQ=37.620588, numObservations: 9
action 3, numVisits=5, meanQ=37.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.182387 0.933455 0.991132 0.929762 0.984153 0.962975 0.692715 0.543111 0.389365 0.279407 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 40
Initial state: 0 0.8212 0.817687 0.356882 0.350065 0.484126 0.909229 0.43301 0.92909 0.776026 0.592177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49392 episodes
GETTING ACTION FROM:
action 0, numVisits=49362, meanQ=62.436498, numObservations: 243
action -1, numVisits=19, meanQ=-1.050000, numObservations: 19
action 1, numVisits=4, meanQ=-6.000000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=4, meanQ=-29.987500, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.8212 0.817687 0.356882 0.350065 0.484126 0.909229 0.43301 0.92909 0.776026 0.592177 w: 1
Observation: 0 0 3 0 1 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=218, meanQ=65.970754, numObservations: 9
action 3, numVisits=31, meanQ=50.098387, numObservations: 8
action 1, numVisits=3, meanQ=32.333333, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 102995 episodes
GETTING ACTION FROM:
action 4, numVisits=103213, meanQ=69.973992, numObservations: 9
action 3, numVisits=31, meanQ=50.098387, numObservations: 8
action 1, numVisits=3, meanQ=32.333333, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.8212 0.817687 0.356882 0.350065 0.484126 0.909229 0.43301 0.92909 0.776026 0.592177 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 41
Initial state: 0 0.361957 0.364261 0.780497 0.474249 0.340536 0.141236 0.787248 0.225616 0.165583 0.443623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97099 episodes
GETTING ACTION FROM:
action 3, numVisits=97090, meanQ=40.236119, numObservations: 9
action 1, numVisits=4, meanQ=21.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.361957 0.364261 0.780497 0.474249 0.340536 0.141236 0.787248 0.225616 0.165583 0.443623 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 42
Initial state: 0 0.26883 0.515692 0.292281 0.868706 0.844339 0.898878 0.290851 0.118021 0.379355 0.340383 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98035 episodes
GETTING ACTION FROM:
action 2, numVisits=98026, meanQ=39.746583, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.26883 0.515692 0.292281 0.868706 0.844339 0.898878 0.290851 0.118021 0.379355 0.340383 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=8502, meanQ=44.625747, numObservations: 9
action 3, numVisits=10, meanQ=28.095000, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 43887 episodes
GETTING ACTION FROM:
action 5, numVisits=52389, meanQ=46.357193, numObservations: 9
action 3, numVisits=10, meanQ=28.095000, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.26883 0.515692 0.292281 0.868706 0.844339 0.898878 0.290851 0.118021 0.379355 0.340383 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 43
Initial state: 0 0.0778136 0.576465 0.356951 0.424535 0.317358 0.369956 0.895067 0.623998 0.920754 0.735599 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92754 episodes
GETTING ACTION FROM:
action 5, numVisits=92747, meanQ=40.490119, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0778136 0.576465 0.356951 0.424535 0.317358 0.369956 0.895067 0.623998 0.920754 0.735599 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 44
Initial state: 0 0.777695 0.8056 0.480143 0.842344 0.333323 0.263015 0.316316 0.295424 0.521203 0.202915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94463 episodes
GETTING ACTION FROM:
action 5, numVisits=94427, meanQ=40.762807, numObservations: 9
action 2, numVisits=8, meanQ=21.500000, numObservations: 5
action 1, numVisits=19, meanQ=21.337237, numObservations: 9
action 4, numVisits=6, meanQ=14.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.777695 0.8056 0.480143 0.842344 0.333323 0.263015 0.316316 0.295424 0.521203 0.202915 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 45
Initial state: 0 0.332753 0.739777 0.404208 0.404613 0.0979595 0.611765 0.834217 0.190015 0.76579 0.816441 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92602 episodes
GETTING ACTION FROM:
action 4, numVisits=92589, meanQ=40.567901, numObservations: 9
action 2, numVisits=8, meanQ=21.618750, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.332753 0.739777 0.404208 0.404613 0.0979595 0.611765 0.834217 0.190015 0.76579 0.816441 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 46
Initial state: 0 0.385937 0.302647 0.940188 0.334703 0.333106 0.0693754 0.333507 0.437549 0.967839 0.96163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96625 episodes
GETTING ACTION FROM:
action 2, numVisits=96618, meanQ=40.073954, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.385937 0.302647 0.940188 0.334703 0.333106 0.0693754 0.333507 0.437549 0.967839 0.96163 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 47
Initial state: 0 0.108277 0.548725 0.079556 0.697508 0.969535 0.943999 0.35039 0.414015 0.0226476 0.342328 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98910 episodes
GETTING ACTION FROM:
action 5, numVisits=98898, meanQ=40.384328, numObservations: 9
action 2, numVisits=6, meanQ=14.158333, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.108277 0.548725 0.079556 0.697508 0.969535 0.943999 0.35039 0.414015 0.0226476 0.342328 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 48
Initial state: 0 0.858148 0.144402 0.322238 0.344873 0.523138 0.267643 0.304138 0.992181 0.975827 0.0654486 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94460 episodes
GETTING ACTION FROM:
action 1, numVisits=94454, meanQ=40.790919, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.858148 0.144402 0.322238 0.344873 0.523138 0.267643 0.304138 0.992181 0.975827 0.0654486 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 49
Initial state: 0 0.746335 0.404884 0.799611 0.132448 0.0959815 0.572875 0.366409 0.286315 0.518697 0.81862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97898 episodes
GETTING ACTION FROM:
action 3, numVisits=97866, meanQ=40.178041, numObservations: 9
action 4, numVisits=26, meanQ=12.034904, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.746335 0.404884 0.799611 0.132448 0.0959815 0.572875 0.366409 0.286315 0.518697 0.81862 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1047, meanQ=34.908121, numObservations: 9
action 4, numVisits=4, meanQ=21.737500, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 124708 episodes
GETTING ACTION FROM:
action 4, numVisits=124638, meanQ=49.032808, numObservations: 9
action 3, numVisits=1121, meanQ=37.077436, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.746335 0.404884 0.799611 0.132448 0.0959815 0.572875 0.366409 0.286315 0.518697 0.81862 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 50
Initial state: 0 0.419191 0.328142 0.225962 0.209766 0.371861 0.441889 0.587048 0.849481 0.774487 0.466659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97355 episodes
GETTING ACTION FROM:
action 2, numVisits=97337, meanQ=39.816077, numObservations: 9
action 5, numVisits=8, meanQ=32.987500, numObservations: 5
action 4, numVisits=3, meanQ=22.484167, numObservations: 2
action 3, numVisits=4, meanQ=21.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.419191 0.328142 0.225962 0.209766 0.371861 0.441889 0.587048 0.849481 0.774487 0.466659 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5092, meanQ=42.488975, numObservations: 9
action 4, numVisits=7, meanQ=10.700000, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32108 episodes
GETTING ACTION FROM:
action 3, numVisits=37200, meanQ=39.226331, numObservations: 9
action 4, numVisits=7, meanQ=10.700000, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.419191 0.328142 0.225962 0.209766 0.371861 0.441889 0.587048 0.849481 0.774487 0.466659 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
[32m ProblemEnvironment.hpp 351: Done.[39m
