Run # 1
Initial state: 0 0.446137 0.0600729 0.494419 0.278258 0.573563 0.24838 0.730097 0.874129 0.356783 0.445967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 89371 episodes
GETTING ACTION FROM:
action 5, numVisits=89337, meanQ=23.631086, numObservations: 9
action 3, numVisits=25, meanQ=2.200000, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.446137 0.0600729 0.494419 0.278258 0.573563 0.24838 0.730097 0.874129 0.356783 0.445967 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 2
Initial state: 0 0.854481 0.817248 0.0913849 0.497044 0.118256 0.93231 0.335382 0.481268 0.720054 0.473353 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 51237 episodes
GETTING ACTION FROM:
action 0, numVisits=51204, meanQ=61.791375, numObservations: 243
action -1, numVisits=15, meanQ=-1.050000, numObservations: 15
action 1, numVisits=8, meanQ=-3.500000, numObservations: 5
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=5, meanQ=-21.000000, numObservations: 4
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.854481 0.817248 0.0913849 0.497044 0.118256 0.93231 0.335382 0.481268 0.720054 0.473353 w: 1
Observation: 0 0 3 0 2 0 3 0 2 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=83, meanQ=71.969277, numObservations: 8
action 4, numVisits=12, meanQ=44.946250, numObservations: 5
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 106670 episodes
GETTING ACTION FROM:
action 3, numVisits=106753, meanQ=64.277123, numObservations: 9
action 4, numVisits=12, meanQ=44.946250, numObservations: 5
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.854481 0.817248 0.0913849 0.497044 0.118256 0.93231 0.335382 0.481268 0.720054 0.473353 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 3
Initial state: 0 0.36149 0.536307 0.333133 0.731808 0.0639681 0.835418 0.999677 0.447483 0.0598172 0.861936 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92708 episodes
GETTING ACTION FROM:
action 2, numVisits=92698, meanQ=23.598856, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.36149 0.536307 0.333133 0.731808 0.0639681 0.835418 0.999677 0.447483 0.0598172 0.861936 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 4
Initial state: 0 0.322792 0.485437 0.52488 0.114849 0.938719 0.343435 0.556174 0.517142 0.617859 0.763573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93287 episodes
GETTING ACTION FROM:
action 3, numVisits=93280, meanQ=22.305779, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.322792 0.485437 0.52488 0.114849 0.938719 0.343435 0.556174 0.517142 0.617859 0.763573 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 5
Initial state: 0 0.363397 0.505239 0.236446 0.739351 0.195757 0.362922 0.0518392 0.573471 0.421233 0.56287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91401 episodes
GETTING ACTION FROM:
action 3, numVisits=91395, meanQ=22.619094, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.363397 0.505239 0.236446 0.739351 0.195757 0.362922 0.0518392 0.573471 0.421233 0.56287 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6713, meanQ=25.130022, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 5, numVisits=6, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 28045 episodes
GETTING ACTION FROM:
action 2, numVisits=34758, meanQ=26.640893, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 5, numVisits=6, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.363397 0.505239 0.236446 0.739351 0.195757 0.362922 0.0518392 0.573471 0.421233 0.56287 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1558, meanQ=43.767462, numObservations: 9
action 4, numVisits=28, meanQ=23.030357, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 25904 episodes
GETTING ACTION FROM:
action 5, numVisits=27462, meanQ=46.650865, numObservations: 9
action 4, numVisits=28, meanQ=23.030357, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.363397 0.505239 0.236446 0.739351 0.195757 0.362922 0.0518392 0.573471 0.421233 0.56287 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 6
Initial state: 0 0.51813 0.247211 0.364204 0.459192 0.838287 0.360726 0.682046 0.646298 0.93133 0.383216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96539 episodes
GETTING ACTION FROM:
action 5, numVisits=96455, meanQ=21.974373, numObservations: 9
action 0, numVisits=49, meanQ=-1.207041, numObservations: 45
action -1, numVisits=12, meanQ=-1.212292, numObservations: 11
action 3, numVisits=18, meanQ=-3.449861, numObservations: 7
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.51813 0.247211 0.364204 0.459192 0.838287 0.360726 0.682046 0.646298 0.93133 0.383216 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 7
Initial state: 0 0.643452 0.579933 0.706601 0.533407 0.319171 0.452205 0.828515 0.515118 0.69311 0.898142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98838 episodes
GETTING ACTION FROM:
action 4, numVisits=98828, meanQ=21.192642, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.643452 0.579933 0.706601 0.533407 0.319171 0.452205 0.828515 0.515118 0.69311 0.898142 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 8
Initial state: 0 0.7046 0.176962 0.294461 0.00791331 0.375892 0.519057 0.0678261 0.302451 0.861671 0.443762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93774 episodes
GETTING ACTION FROM:
action 5, numVisits=93739, meanQ=21.827508, numObservations: 9
action -1, numVisits=3, meanQ=-1.050000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 2, numVisits=26, meanQ=-2.538462, numObservations: 9
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.7046 0.176962 0.294461 0.00791331 0.375892 0.519057 0.0678261 0.302451 0.861671 0.443762 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 9
Initial state: 0 0.732758 0.720161 0.356131 0.506721 0.670153 0.311397 0.417422 0.609136 0.761952 0.930253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88461 episodes
GETTING ACTION FROM:
action 1, numVisits=88455, meanQ=23.462020, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.732758 0.720161 0.356131 0.506721 0.670153 0.311397 0.417422 0.609136 0.761952 0.930253 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 10
Initial state: 0 0.92714 0.835693 0.650882 0.93536 0.974348 0.730236 0.274124 0.515076 0.620365 0.334492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97443 episodes
GETTING ACTION FROM:
action 4, numVisits=97430, meanQ=20.647784, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.92714 0.835693 0.650882 0.93536 0.974348 0.730236 0.274124 0.515076 0.620365 0.334492 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 11
Initial state: 0 0.912893 0.91954 0.745026 0.345483 0.102376 0.319622 0.107883 0.543294 0.274092 0.455928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94808 episodes
GETTING ACTION FROM:
action 1, numVisits=94796, meanQ=22.222730, numObservations: 9
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.912893 0.91954 0.745026 0.345483 0.102376 0.319622 0.107883 0.543294 0.274092 0.455928 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 12
Initial state: 0 0.305635 0.231625 0.496902 0.851004 0.906436 0.168429 0.936817 0.678351 0.313799 0.509612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97542 episodes
GETTING ACTION FROM:
action 1, numVisits=97512, meanQ=21.862687, numObservations: 9
action 2, numVisits=20, meanQ=8.000000, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=6, meanQ=-4.333333, numObservations: 4
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.305635 0.231625 0.496902 0.851004 0.906436 0.168429 0.936817 0.678351 0.313799 0.509612 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5410, meanQ=27.505499, numObservations: 9
action 3, numVisits=32, meanQ=10.931484, numObservations: 9
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 35401 episodes
GETTING ACTION FROM:
action 2, numVisits=40811, meanQ=36.909524, numObservations: 9
action 3, numVisits=32, meanQ=10.931484, numObservations: 9
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.305635 0.231625 0.496902 0.851004 0.906436 0.168429 0.936817 0.678351 0.313799 0.509612 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 13
Initial state: 0 0.288398 0.456592 0.991935 0.883985 0.0724347 0.87876 0.863241 0.375891 0.337451 0.043005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98071 episodes
GETTING ACTION FROM:
action 2, numVisits=98039, meanQ=21.332626, numObservations: 9
action 1, numVisits=16, meanQ=16.053125, numObservations: 7
action 4, numVisits=10, meanQ=15.285000, numObservations: 8
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 2
Next state: 1 0.288398 0.456592 0.991935 0.883985 0.0724347 0.87876 0.863241 0.375891 0.337451 0.043005 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 14
Initial state: 0 0.365323 0.4822 0.925056 0.385279 0.787777 0.466416 0.322421 0.426086 0.90072 0.834267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97431 episodes
GETTING ACTION FROM:
action 1, numVisits=97419, meanQ=20.966576, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=3, meanQ=-34.333333, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.365323 0.4822 0.925056 0.385279 0.787777 0.466416 0.322421 0.426086 0.90072 0.834267 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 15
Initial state: 0 0.243336 0.978343 0.129399 0.147834 0.316201 0.528101 0.284786 0.614769 0.199716 0.876985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96089 episodes
GETTING ACTION FROM:
action 1, numVisits=96059, meanQ=21.271822, numObservations: 9
action 4, numVisits=19, meanQ=6.889737, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=6, meanQ=-7.674583, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.243336 0.978343 0.129399 0.147834 0.316201 0.528101 0.284786 0.614769 0.199716 0.876985 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=352, meanQ=15.040625, numObservations: 175
action 3, numVisits=33, meanQ=-2.430227, numObservations: 9
action 5, numVisits=4, meanQ=-5.525000, numObservations: 4
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=6, meanQ=-17.200000, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 43270 episodes
GETTING ACTION FROM:
action 0, numVisits=43622, meanQ=6.265796, numObservations: 243
action 3, numVisits=33, meanQ=-2.430227, numObservations: 9
action 5, numVisits=4, meanQ=-5.525000, numObservations: 4
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=6, meanQ=-17.200000, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.243336 0.978343 0.129399 0.147834 0.316201 0.528101 0.284786 0.614769 0.199716 0.876985 w: 1
Observation: 0 0 3 0 1 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=99.000000, numObservations: 1
action 3, numVisits=34, meanQ=73.186257, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.854917, numObservations: 3
action 4, numVisits=3, meanQ=-4.924491, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 102329 episodes
GETTING ACTION FROM:
action 3, numVisits=102362, meanQ=88.314270, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.854917, numObservations: 3
action 4, numVisits=3, meanQ=-4.924491, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.243336 0.978343 0.129399 0.147834 0.316201 0.528101 0.284786 0.614769 0.199716 0.876985 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 16
Initial state: 0 0.385174 0.557122 0.246156 0.180946 0.631363 0.990877 0.106996 0.190859 0.281822 0.500579 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96718 episodes
GETTING ACTION FROM:
action 4, numVisits=96699, meanQ=20.625269, numObservations: 9
action 2, numVisits=5, meanQ=13.810000, numObservations: 4
action 1, numVisits=10, meanQ=8.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.385174 0.557122 0.246156 0.180946 0.631363 0.990877 0.106996 0.190859 0.281822 0.500579 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7051, meanQ=25.163470, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25189 episodes
GETTING ACTION FROM:
action 1, numVisits=32240, meanQ=24.104969, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.385174 0.557122 0.246156 0.180946 0.631363 0.990877 0.106996 0.190859 0.281822 0.500579 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 17
Initial state: 0 0.981962 0.56916 0.381031 0.78025 0.783807 0.355247 0.291089 0.540578 0.0810756 0.353041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47899 episodes
GETTING ACTION FROM:
action -1, numVisits=47836, meanQ=50.541434, numObservations: 243
action 0, numVisits=55, meanQ=-1.382500, numObservations: 50
action 5, numVisits=4, meanQ=-6.000000, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.981962 0.56916 0.381031 0.78025 0.783807 0.355247 0.291089 0.540578 0.0810756 0.353041 w: 1
Observation: 0 3 0 3 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=538, meanQ=65.249193, numObservations: 62
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 51808 episodes
GETTING ACTION FROM:
action -1, numVisits=52346, meanQ=76.867035, numObservations: 200
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.981962 0.56916 0.381031 0.78025 0.783807 0.355247 0.291089 0.540578 0.0810756 0.353041 w: 1
Observation: 0 3 0 3 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=17629, meanQ=95.663572, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 113260 episodes
GETTING ACTION FROM:
action 4, numVisits=130889, meanQ=95.863899, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.981962 0.56916 0.381031 0.78025 0.783807 0.355247 0.291089 0.540578 0.0810756 0.353041 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 18
Initial state: 0 0.283187 0.297201 0.691842 0.439686 0.442881 0.534002 0.330369 0.541328 0.566722 0.035608 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48700 episodes
GETTING ACTION FROM:
action -1, numVisits=48657, meanQ=51.208348, numObservations: 243
action 0, numVisits=22, meanQ=-1.050000, numObservations: 22
action 1, numVisits=17, meanQ=-8.058824, numObservations: 8
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.283187 0.297201 0.691842 0.439686 0.442881 0.534002 0.330369 0.541328 0.566722 0.035608 w: 1
Observation: 0 2 0 3 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=438, meanQ=46.135446, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
Sampled 107588 episodes
GETTING ACTION FROM:
action 1, numVisits=108026, meanQ=47.160611, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 1
Next state: 2 0.283187 0.297201 0.691842 0.439686 0.442881 0.534002 0.330369 0.541328 0.566722 0.035608 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 19
Initial state: 0 0.465367 0.248547 0.469714 0.685924 0.742132 0.177233 0.823385 0.46353 0.33026 0.544504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49656 episodes
GETTING ACTION FROM:
action -1, numVisits=49625, meanQ=50.778590, numObservations: 243
action 0, numVisits=15, meanQ=-1.050000, numObservations: 15
action 4, numVisits=5, meanQ=-3.000000, numObservations: 3
action 5, numVisits=8, meanQ=-4.693437, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.465367 0.248547 0.469714 0.685924 0.742132 0.177233 0.823385 0.46353 0.33026 0.544504 w: 1
Observation: 0 3 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1271, meanQ=88.931957, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 115601 episodes
GETTING ACTION FROM:
action 5, numVisits=116872, meanQ=92.164302, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.465367 0.248547 0.469714 0.685924 0.742132 0.177233 0.823385 0.46353 0.33026 0.544504 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 20
Initial state: 0 0.27626 0.453707 0.577503 0.914175 0.848039 0.0767521 0.00142397 0.11079 0.629565 0.462791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95386 episodes
GETTING ACTION FROM:
action 2, numVisits=95379, meanQ=22.922285, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.27626 0.453707 0.577503 0.914175 0.848039 0.0767521 0.00142397 0.11079 0.629565 0.462791 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 21
Initial state: 0 0.261991 0.230787 0.0297642 0.997096 0.282944 0.00741297 0.960831 0.23287 0.364374 0.481094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92951 episodes
GETTING ACTION FROM:
action 2, numVisits=92937, meanQ=22.740672, numObservations: 9
action 5, numVisits=8, meanQ=7.868750, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.261991 0.230787 0.0297642 0.997096 0.282944 0.00741297 0.960831 0.23287 0.364374 0.481094 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=5143, meanQ=64.222768, numObservations: 240
action 5, numVisits=8, meanQ=-3.262500, numObservations: 6
action -1, numVisits=13, meanQ=-8.796154, numObservations: 10
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11939 episodes
GETTING ACTION FROM:
action 0, numVisits=17082, meanQ=44.814283, numObservations: 243
action 5, numVisits=8, meanQ=-3.262500, numObservations: 6
action -1, numVisits=13, meanQ=-8.796154, numObservations: 10
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.261991 0.230787 0.0297642 0.997096 0.282944 0.00741297 0.960831 0.23287 0.364374 0.481094 w: 1
Observation: 0 0 1 0 3 0 1 0 1 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=121, meanQ=80.117580, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 88872 episodes
GETTING ACTION FROM:
action 5, numVisits=88993, meanQ=82.398104, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.261991 0.230787 0.0297642 0.997096 0.282944 0.00741297 0.960831 0.23287 0.364374 0.481094 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=99.000000, numObservations: 1
action 5, numVisits=1328, meanQ=91.601437, numObservations: 9
action 1, numVisits=2, meanQ=43.411715, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-12.146475, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 69381 episodes
GETTING ACTION FROM:
action 5, numVisits=1549, meanQ=92.252652, numObservations: 9
action 2, numVisits=7, meanQ=83.285714, numObservations: 3
action 0, numVisits=68681, meanQ=0.141571, numObservations: 212
action -1, numVisits=470, meanQ=-2.017138, numObservations: 81
action 3, numVisits=4, meanQ=-28.786619, numObservations: 2
action 1, numVisits=4, meanQ=-28.794142, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.261991 0.230787 0.0297642 0.997096 0.282944 0.00741297 0.960831 0.23287 0.364374 0.481094 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 62.0526
Run # 22
Initial state: 0 0.057496 0.157806 0.914914 0.0319747 0.339839 0.562218 0.738892 0.743423 0.777224 0.246182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49057 episodes
GETTING ACTION FROM:
action -1, numVisits=49045, meanQ=52.943497, numObservations: 243
action 0, numVisits=7, meanQ=-1.050000, numObservations: 7
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.057496 0.157806 0.914914 0.0319747 0.339839 0.562218 0.738892 0.743423 0.777224 0.246182 w: 1
Observation: 0 1 0 3 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=142, meanQ=37.166586, numObservations: 43
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 0, numVisits=28, meanQ=-4.580268, numObservations: 26
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 50730 episodes
GETTING ACTION FROM:
action -1, numVisits=50872, meanQ=73.311631, numObservations: 218
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 0, numVisits=28, meanQ=-4.580268, numObservations: 26
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.057496 0.157806 0.914914 0.0319747 0.339839 0.562218 0.738892 0.743423 0.777224 0.246182 w: 1
Observation: 0 1 0 3 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=7072, meanQ=95.259390, numObservations: 9
action 5, numVisits=5, meanQ=19.000000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 113561 episodes
GETTING ACTION FROM:
action 3, numVisits=120633, meanQ=95.878885, numObservations: 9
action 5, numVisits=5, meanQ=19.000000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.057496 0.157806 0.914914 0.0319747 0.339839 0.562218 0.738892 0.743423 0.777224 0.246182 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=879, meanQ=91.966022, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 92534 episodes
GETTING ACTION FROM:
action 3, numVisits=1092, meanQ=93.140278, numObservations: 9
action 1, numVisits=92298, meanQ=78.912405, numObservations: 9
action -1, numVisits=13, meanQ=-1.853846, numObservations: 6
action 0, numVisits=13, meanQ=-1.853846, numObservations: 11
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.057496 0.157806 0.914914 0.0319747 0.339839 0.562218 0.738892 0.743423 0.777224 0.246182 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 71.0526
Run # 23
Initial state: 0 0.184336 0.0880334 0.731349 0.531366 0.235571 0.236994 0.306272 0.476441 0.451984 0.103668 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98275 episodes
GETTING ACTION FROM:
action 3, numVisits=94523, meanQ=21.399185, numObservations: 9
action 4, numVisits=3732, meanQ=20.981659, numObservations: 9
action 1, numVisits=16, meanQ=17.125000, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.184336 0.0880334 0.731349 0.531366 0.235571 0.236994 0.306272 0.476441 0.451984 0.103668 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=6721, meanQ=27.411557, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=4, meanQ=-5.525000, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34074 episodes
GETTING ACTION FROM:
action 2, numVisits=40795, meanQ=15.614410, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=4, meanQ=-5.525000, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.184336 0.0880334 0.731349 0.531366 0.235571 0.236994 0.306272 0.476441 0.451984 0.103668 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 24
Initial state: 0 0.88534 0.662526 0.56837 0.625798 0.782082 0.0215045 0.282402 0.559979 0.789735 0.732456 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97594 episodes
GETTING ACTION FROM:
action 5, numVisits=97587, meanQ=20.695516, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.88534 0.662526 0.56837 0.625798 0.782082 0.0215045 0.282402 0.559979 0.789735 0.732456 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 25
Initial state: 0 0.3136 0.554331 0.29881 0.864554 0.22812 0.33879 0.938734 0.465944 0.122705 0.50931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48958 episodes
GETTING ACTION FROM:
action -1, numVisits=48920, meanQ=51.166612, numObservations: 243
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 0, numVisits=29, meanQ=-4.592845, numObservations: 25
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.3136 0.554331 0.29881 0.864554 0.22812 0.33879 0.938734 0.465944 0.122705 0.50931 w: 1
Observation: 0 3 0 2 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=215, meanQ=19.877837, numObservations: 102
action -1, numVisits=4, meanQ=-1.536875, numObservations: 3
action 3, numVisits=6, meanQ=-5.008333, numObservations: 5
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 51774 episodes
GETTING ACTION FROM:
action 0, numVisits=51989, meanQ=77.542250, numObservations: 243
action -1, numVisits=4, meanQ=-1.536875, numObservations: 3
action 3, numVisits=6, meanQ=-5.008333, numObservations: 5
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.3136 0.554331 0.29881 0.864554 0.22812 0.33879 0.938734 0.465944 0.122705 0.50931 w: 1
Observation: 0 0 2 0 3 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=8, meanQ=49.000000, numObservations: 4
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 112828 episodes
GETTING ACTION FROM:
action 2, numVisits=112836, meanQ=89.128720, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.3136 0.554331 0.29881 0.864554 0.22812 0.33879 0.938734 0.465944 0.122705 0.50931 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 26
Initial state: 0 0.555016 0.523702 0.659058 0.501252 0.106233 0.623679 0.615456 0.592914 0.332741 0.566204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93238 episodes
GETTING ACTION FROM:
action 2, numVisits=93217, meanQ=23.456553, numObservations: 9
action 4, numVisits=9, meanQ=7.888889, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=7, meanQ=-2.428571, numObservations: 4
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.555016 0.523702 0.659058 0.501252 0.106233 0.623679 0.615456 0.592914 0.332741 0.566204 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 27
Initial state: 0 0.945815 0.54439 0.214604 0.177981 0.991248 0.0259782 0.286135 0.528781 0.523279 0.449776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94282 episodes
GETTING ACTION FROM:
action 4, numVisits=94238, meanQ=20.717581, numObservations: 9
action 5, numVisits=37, meanQ=16.862230, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.945815 0.54439 0.214604 0.177981 0.991248 0.0259782 0.286135 0.528781 0.523279 0.449776 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 28
Initial state: 0 0.993357 0.0954059 0.611475 0.0226209 0.32535 0.471485 0.938201 0.0248464 0.307219 0.187413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50144 episodes
GETTING ACTION FROM:
action 0, numVisits=50032, meanQ=61.221909, numObservations: 243
action -1, numVisits=84, meanQ=-3.994435, numObservations: 63
action 1, numVisits=22, meanQ=-6.270455, numObservations: 8
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.993357 0.0954059 0.611475 0.0226209 0.32535 0.471485 0.938201 0.0248464 0.307219 0.187413 w: 1
Observation: 0 0 1 0 1 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=345, meanQ=83.321301, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 114412 episodes
GETTING ACTION FROM:
action 3, numVisits=114757, meanQ=91.985548, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.993357 0.0954059 0.611475 0.0226209 0.32535 0.471485 0.938201 0.0248464 0.307219 0.187413 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 29
Initial state: 0 0.79448 0.977475 0.312379 0.532248 0.727816 0.0672088 0.441244 0.419796 0.525549 0.479568 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 94188 episodes
GETTING ACTION FROM:
action 4, numVisits=94167, meanQ=21.987558, numObservations: 9
action 5, numVisits=14, meanQ=3.996607, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.79448 0.977475 0.312379 0.532248 0.727816 0.0672088 0.441244 0.419796 0.525549 0.479568 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 30
Initial state: 0 0.110115 0.444053 0.324971 0.568476 0.766559 0.584076 0.536121 0.0731898 0.919001 0.458986 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93965 episodes
GETTING ACTION FROM:
action 3, numVisits=93931, meanQ=21.791821, numObservations: 9
action 2, numVisits=28, meanQ=4.875089, numObservations: 8
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.110115 0.444053 0.324971 0.568476 0.766559 0.584076 0.536121 0.0731898 0.919001 0.458986 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 31
Initial state: 0 0.485507 0.996682 0.322563 0.493745 0.541961 0.129887 0.598813 0.84016 0.98825 0.664238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 95904 episodes
GETTING ACTION FROM:
action 3, numVisits=95886, meanQ=22.268981, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 5, numVisits=8, meanQ=-3.624688, numObservations: 6
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.485507 0.996682 0.322563 0.493745 0.541961 0.129887 0.598813 0.84016 0.98825 0.664238 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 32
Initial state: 0 0.959947 0.190216 0.675322 0.870647 0.505354 0.798928 0.793589 0.956963 0.29656 0.485125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97565 episodes
GETTING ACTION FROM:
action 1, numVisits=97543, meanQ=21.255641, numObservations: 9
action 4, numVisits=17, meanQ=2.347059, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.959947 0.190216 0.675322 0.870647 0.505354 0.798928 0.793589 0.956963 0.29656 0.485125 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 33
Initial state: 0 0.338428 0.469122 0.91268 0.718208 0.547707 0.0312318 0.0147948 0.302019 0.97533 0.514832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93893 episodes
GETTING ACTION FROM:
action 3, numVisits=93887, meanQ=21.875776, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.338428 0.469122 0.91268 0.718208 0.547707 0.0312318 0.0147948 0.302019 0.97533 0.514832 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 34
Initial state: 0 0.153467 0.897777 0.687221 0.861084 0.457641 0.0186768 0.346772 0.458445 0.83039 0.113427 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93439 episodes
GETTING ACTION FROM:
action 1, numVisits=93432, meanQ=23.280270, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.153467 0.897777 0.687221 0.861084 0.457641 0.0186768 0.346772 0.458445 0.83039 0.113427 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=5071, meanQ=26.982699, numObservations: 9
action 2, numVisits=80, meanQ=21.543406, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 28068 episodes
GETTING ACTION FROM:
action 5, numVisits=33139, meanQ=31.859294, numObservations: 9
action 2, numVisits=80, meanQ=21.543406, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.153467 0.897777 0.687221 0.861084 0.457641 0.0186768 0.346772 0.458445 0.83039 0.113427 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 35
Initial state: 0 0.663744 0.995569 0.319519 0.539803 0.29415 0.890371 0.792867 0.971959 0.939623 0.664758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98560 episodes
GETTING ACTION FROM:
action 1, numVisits=98550, meanQ=20.990394, numObservations: 9
action 2, numVisits=5, meanQ=15.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.663744 0.995569 0.319519 0.539803 0.29415 0.890371 0.792867 0.971959 0.939623 0.664758 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 36
Initial state: 0 0.00239483 0.24529 0.299536 0.468414 0.00850605 0.213198 0.168994 0.624654 0.668065 0.730536 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97226 episodes
GETTING ACTION FROM:
action 1, numVisits=97210, meanQ=20.013905, numObservations: 9
action 2, numVisits=4, meanQ=-1.000000, numObservations: 4
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=3, meanQ=-1.050000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.00239483 0.24529 0.299536 0.468414 0.00850605 0.213198 0.168994 0.624654 0.668065 0.730536 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=6954, meanQ=25.790659, numObservations: 9
action 5, numVisits=5, meanQ=15.380000, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32627 episodes
GETTING ACTION FROM:
action 4, numVisits=39577, meanQ=19.692912, numObservations: 9
action 5, numVisits=9, meanQ=8.100000, numObservations: 5
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.00239483 0.24529 0.299536 0.468414 0.00850605 0.213198 0.168994 0.624654 0.668065 0.730536 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 37
Initial state: 0 0.525704 0.464671 0.328391 0.520999 0.534364 0.105383 0.697417 0.958361 0.710558 0.695273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98714 episodes
GETTING ACTION FROM:
action 5, numVisits=98616, meanQ=21.524958, numObservations: 9
action 0, numVisits=58, meanQ=-4.837716, numObservations: 47
action -1, numVisits=19, meanQ=-6.150000, numObservations: 18
action 1, numVisits=18, meanQ=-9.333333, numObservations: 8
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.525704 0.464671 0.328391 0.520999 0.534364 0.105383 0.697417 0.958361 0.710558 0.695273 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 38
Initial state: 0 0.677629 0.743654 0.530747 0.302447 0.98404 0.881495 0.0290552 0.928549 0.353587 0.52771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 99165 episodes
GETTING ACTION FROM:
action 1, numVisits=99146, meanQ=21.180366, numObservations: 9
action 2, numVisits=10, meanQ=15.190000, numObservations: 8
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=4, meanQ=-5.762500, numObservations: 4
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.677629 0.743654 0.530747 0.302447 0.98404 0.881495 0.0290552 0.928549 0.353587 0.52771 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 39
Initial state: 0 0.10336 0.66284 0.694048 0.944904 0.852159 0.395493 0.289378 0.590214 0.364373 0.524108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48603 episodes
GETTING ACTION FROM:
action -1, numVisits=48521, meanQ=53.572163, numObservations: 243
action 0, numVisits=75, meanQ=-1.533867, numObservations: 65
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.10336 0.66284 0.694048 0.944904 0.852159 0.395493 0.289378 0.590214 0.364373 0.524108 w: 1
Observation: 0 1 0 3 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=605, meanQ=84.607294, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 113636 episodes
GETTING ACTION FROM:
action 4, numVisits=114241, meanQ=87.041117, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.10336 0.66284 0.694048 0.944904 0.852159 0.395493 0.289378 0.590214 0.364373 0.524108 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 40
Initial state: 0 0.105912 0.339431 0.360211 0.510057 0.448299 0.25282 0.139172 0.220889 0.807246 0.180692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 99087 episodes
GETTING ACTION FROM:
action 5, numVisits=99006, meanQ=21.170738, numObservations: 9
action 1, numVisits=74, meanQ=18.340709, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.105912 0.339431 0.360211 0.510057 0.448299 0.25282 0.139172 0.220889 0.807246 0.180692 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 41
Initial state: 0 0.969365 0.889033 0.782618 0.546501 0.144832 0.806758 0.358526 0.547791 0.205663 0.60237 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48788 episodes
GETTING ACTION FROM:
action -1, numVisits=48723, meanQ=52.725130, numObservations: 243
action 0, numVisits=31, meanQ=-7.301613, numObservations: 29
action 5, numVisits=28, meanQ=-8.862232, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action: -1
Next state: 0 0.969365 0.889033 0.782618 0.546501 0.144832 0.806758 0.358526 0.547791 0.205663 0.60237 w: 1
Observation: 0 3 0 3 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=525, meanQ=85.783503, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 113118 episodes
GETTING ACTION FROM:
action 5, numVisits=113643, meanQ=87.998016, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.969365 0.889033 0.782618 0.546501 0.144832 0.806758 0.358526 0.547791 0.205663 0.60237 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=451, meanQ=65.920159, numObservations: 9
action 5, numVisits=3, meanQ=26.300000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 43049 episodes
GETTING ACTION FROM:
action 3, numVisits=43500, meanQ=70.341091, numObservations: 9
action 5, numVisits=3, meanQ=26.300000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.969365 0.889033 0.782618 0.546501 0.144832 0.806758 0.358526 0.547791 0.205663 0.60237 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 0, numVisits=1872, meanQ=71.038260, numObservations: 157
action -1, numVisits=5, meanQ=-3.149500, numObservations: 4
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
Sampled 31169 episodes
GETTING ACTION FROM:
action 0, numVisits=33041, meanQ=19.875737, numObservations: 241
action -1, numVisits=5, meanQ=-3.149500, numObservations: 4
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 0
Next state: 0 0.969365 0.889033 0.782618 0.546501 0.144832 0.806758 0.358526 0.547791 0.205663 0.60237 w: 1
Observation: 0 0 3 0 3 0 3 0 2 0 3 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=99.000000, numObservations: 1
action 4, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 126202 episodes
GETTING ACTION FROM:
action 3, numVisits=28, meanQ=87.716071, numObservations: 4
action 5, numVisits=17, meanQ=87.235294, numObservations: 7
action 4, numVisits=126155, meanQ=71.519404, numObservations: 9
action 1, numVisits=3, meanQ=32.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.969365 0.889033 0.782618 0.546501 0.144832 0.806758 0.358526 0.547791 0.205663 0.60237 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 128553 episodes
GETTING ACTION FROM:
action 5, numVisits=51, meanQ=82.921569, numObservations: 5
action 3, numVisits=19, meanQ=81.723353, numObservations: 4
action 2, numVisits=128441, meanQ=78.779853, numObservations: 9
action 1, numVisits=38, meanQ=67.421053, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action: 5
Next state: 0 0.969365 0.889033 0.782618 0.546501 0.144832 0.806758 0.358526 0.547791 0.205663 0.60237 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -11
Updated belief

t = 6
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 169552 episodes
GETTING ACTION FROM:
action 3, numVisits=226, meanQ=76.363053, numObservations: 8
action 4, numVisits=169319, meanQ=65.800346, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.969365 0.889033 0.782618 0.546501 0.144832 0.806758 0.358526 0.547791 0.205663 0.60237 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 7
Improving policy...
PLANNING FROM:
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159971 episodes
GETTING ACTION FROM:
action 3, numVisits=379, meanQ=90.448555, numObservations: 8
action 2, numVisits=159587, meanQ=79.881201, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.969365 0.889033 0.782618 0.546501 0.144832 0.806758 0.358526 0.547791 0.205663 0.60237 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 8
Improving policy...
PLANNING FROM:
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225762 episodes
GETTING ACTION FROM:
action 3, numVisits=299, meanQ=93.261037, numObservations: 8
action 1, numVisits=225404, meanQ=72.748469, numObservations: 9
action 4, numVisits=53, meanQ=61.264151, numObservations: 6
action 5, numVisits=2, meanQ=44.000000, numObservations: 2
action 2, numVisits=3, meanQ=32.333333, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action: 3
Next state: 0 0.969365 0.889033 0.782618 0.546501 0.144832 0.806758 0.358526 0.547791 0.205663 0.60237 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 9
Improving policy...
PLANNING FROM:
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222204 episodes
GETTING ACTION FROM:
action 5, numVisits=783, meanQ=80.448340, numObservations: 9
action 1, numVisits=221414, meanQ=72.806534, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.969365 0.889033 0.782618 0.546501 0.144832 0.806758 0.358526 0.547791 0.205663 0.60237 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -2.23406
Run # 42
Initial state: 0 0.325959 0.0677683 0.600736 0.124129 0.310714 0.542819 0.0593656 0.640276 0.111887 0.603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91546 episodes
GETTING ACTION FROM:
action 5, numVisits=91516, meanQ=23.821237, numObservations: 9
action 1, numVisits=24, meanQ=16.793958, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.325959 0.0677683 0.600736 0.124129 0.310714 0.542819 0.0593656 0.640276 0.111887 0.603 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5146, meanQ=29.188744, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 45848 episodes
GETTING ACTION FROM:
action 1, numVisits=50994, meanQ=25.759882, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.325959 0.0677683 0.600736 0.124129 0.310714 0.542819 0.0593656 0.640276 0.111887 0.603 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 43
Initial state: 0 0.455426 0.152998 0.485695 0.482561 0.0934694 0.221827 0.30596 0.759275 0.318531 0.471517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50105 episodes
GETTING ACTION FROM:
action 0, numVisits=50060, meanQ=61.084374, numObservations: 243
action 2, numVisits=20, meanQ=-9.229750, numObservations: 8
action 1, numVisits=2, meanQ=-11.498750, numObservations: 1
action -1, numVisits=18, meanQ=-11.816667, numObservations: 16
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.455426 0.152998 0.485695 0.482561 0.0934694 0.221827 0.30596 0.759275 0.318531 0.471517 w: 1
Observation: 0 0 1 0 2 0 1 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=138, meanQ=62.798949, numObservations: 9
action 2, numVisits=78, meanQ=58.208397, numObservations: 9
action 4, numVisits=4, meanQ=43.988125, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 108496 episodes
GETTING ACTION FROM:
action 5, numVisits=108617, meanQ=56.376698, numObservations: 9
action 2, numVisits=95, meanQ=53.665842, numObservations: 9
action 4, numVisits=4, meanQ=43.988125, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.455426 0.152998 0.485695 0.482561 0.0934694 0.221827 0.30596 0.759275 0.318531 0.471517 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 44
Initial state: 0 0.351154 0.143553 0.760237 0.939925 0.60083 0.100865 0.742361 0.528165 0.286168 0.555069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98636 episodes
GETTING ACTION FROM:
action 4, numVisits=94844, meanQ=20.867944, numObservations: 9
action 5, numVisits=3785, meanQ=20.328017, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.351154 0.143553 0.760237 0.939925 0.60083 0.100865 0.742361 0.528165 0.286168 0.555069 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 45
Initial state: 0 0.353621 0.614123 0.953415 0.701966 0.677455 0.0684078 0.283021 0.486025 0.105793 0.600507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 96876 episodes
GETTING ACTION FROM:
action 2, numVisits=96870, meanQ=21.957167, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.353621 0.614123 0.953415 0.701966 0.677455 0.0684078 0.283021 0.486025 0.105793 0.600507 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 46
Initial state: 0 0.205822 0.632084 0.063468 0.0354864 0.796007 0.556469 0.817667 0.854843 0.277811 0.444805 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93971 episodes
GETTING ACTION FROM:
action 4, numVisits=93954, meanQ=21.467359, numObservations: 9
action 5, numVisits=11, meanQ=16.272727, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.205822 0.632084 0.063468 0.0354864 0.796007 0.556469 0.817667 0.854843 0.277811 0.444805 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 47
Initial state: 0 0.409153 0.301086 0.659365 0.902419 0.380109 0.211165 0.624368 0.520886 0.311002 0.470818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48918 episodes
GETTING ACTION FROM:
action -1, numVisits=48828, meanQ=53.532411, numObservations: 243
action 0, numVisits=38, meanQ=-3.978750, numObservations: 34
action 3, numVisits=46, meanQ=-5.092228, numObservations: 8
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action: -1
Next state: 0 0.409153 0.301086 0.659365 0.902419 0.380109 0.211165 0.624368 0.520886 0.311002 0.470818 w: 1
Observation: 0 3 0 3 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=308, meanQ=53.040994, numObservations: 9
action 3, numVisits=11, meanQ=44.454545, numObservations: 5
action 1, numVisits=4, meanQ=21.737500, numObservations: 2
action 4, numVisits=4, meanQ=21.737500, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
Sampled 90480 episodes
GETTING ACTION FROM:
action 5, numVisits=90788, meanQ=53.331308, numObservations: 9
action 3, numVisits=11, meanQ=44.454545, numObservations: 5
action 1, numVisits=4, meanQ=21.737500, numObservations: 2
action 4, numVisits=4, meanQ=21.737500, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 5
Next state: 1 0.409153 0.301086 0.659365 0.902419 0.380109 0.211165 0.624368 0.520886 0.311002 0.470818 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 48
Initial state: 0 0.336274 0.500256 0.946058 0.0452949 0.601948 0.234288 0.982011 0.782004 0.992291 0.617897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 93749 episodes
GETTING ACTION FROM:
action 5, numVisits=93738, meanQ=21.256674, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=5, meanQ=-3.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.336274 0.500256 0.946058 0.0452949 0.601948 0.234288 0.982011 0.782004 0.992291 0.617897 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 49
Initial state: 0 0.0521766 0.360234 0.306357 0.267711 0.939012 0.636671 0.360966 0.450891 0.560581 0.920154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 98836 episodes
GETTING ACTION FROM:
action 3, numVisits=98822, meanQ=20.946991, numObservations: 9
action 5, numVisits=8, meanQ=10.250000, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0521766 0.360234 0.306357 0.267711 0.939012 0.636671 0.360966 0.450891 0.560581 0.920154 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 50
Initial state: 0 0.451814 0.294229 0.278647 0.522088 0.944022 0.538235 0.67775 0.310187 0.361632 0.291627 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 97060 episodes
GETTING ACTION FROM:
action 4, numVisits=97013, meanQ=20.092792, numObservations: 9
action 5, numVisits=19, meanQ=12.731711, numObservations: 9
action 2, numVisits=24, meanQ=11.420833, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.451814 0.294229 0.278647 0.522088 0.944022 0.538235 0.67775 0.310187 0.361632 0.291627 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
[32m ProblemEnvironment.hpp 351: Done.[39m
