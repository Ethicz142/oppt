Run # 1
Initial state: 0 0.945906 0.388397 0.257843 0.509747 0.724421 0.225185 0.886882 0.526503 0.492662 0.52715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78693 episodes
GETTING ACTION FROM:
action 4, numVisits=78687, meanQ=18.717669, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.945906 0.388397 0.257843 0.509747 0.724421 0.225185 0.886882 0.526503 0.492662 0.52715 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 2
Initial state: 0 0.472964 0.520271 0.426725 0.793131 0.423987 0.399025 0.399243 0.454027 0.359231 0.205742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48312 episodes
GETTING ACTION FROM:
action -1, numVisits=48283, meanQ=45.825285, numObservations: 243
action 2, numVisits=22, meanQ=-0.117841, numObservations: 8
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.472964 0.520271 0.426725 0.793131 0.423987 0.399025 0.399243 0.454027 0.359231 0.205742 w: 1
Observation: 0 2 0 1 0 1 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=321, meanQ=78.721806, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 112790 episodes
GETTING ACTION FROM:
action 1, numVisits=113111, meanQ=90.517190, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.472964 0.520271 0.426725 0.793131 0.423987 0.399025 0.399243 0.454027 0.359231 0.205742 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=7487, meanQ=95.168307, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 81332 episodes
GETTING ACTION FROM:
action 1, numVisits=7711, meanQ=95.276937, numObservations: 9
action 3, numVisits=81095, meanQ=70.813733, numObservations: 9
action -1, numVisits=8, meanQ=-1.762500, numObservations: 6
action 0, numVisits=7, meanQ=-1.864286, numObservations: 6
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 1
Next state: 1 0.472964 0.520271 0.426725 0.793131 0.423987 0.399025 0.399243 0.454027 0.359231 0.205742 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 3
Initial state: 0 0.534906 0.568208 0.0419555 0.0232604 0.513748 0.192158 0.644929 0.725423 0.289669 0.501722 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48314 episodes
GETTING ACTION FROM:
action -1, numVisits=48252, meanQ=46.003132, numObservations: 243
action 1, numVisits=34, meanQ=-0.318824, numObservations: 8
action 0, numVisits=6, meanQ=-1.050000, numObservations: 6
action 2, numVisits=5, meanQ=-3.000000, numObservations: 4
action 4, numVisits=11, meanQ=-3.554545, numObservations: 7
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action: -1
Next state: 0 0.534906 0.568208 0.0419555 0.0232604 0.513748 0.192158 0.644929 0.725423 0.289669 0.501722 w: 1
Observation: 0 2 0 1 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=174, meanQ=33.182529, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 107020 episodes
GETTING ACTION FROM:
action 1, numVisits=107194, meanQ=49.584224, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.534906 0.568208 0.0419555 0.0232604 0.513748 0.192158 0.644929 0.725423 0.289669 0.501722 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 4
Initial state: 0 0.571191 0.611281 0.237305 0.0837568 0.862626 0.562452 0.320763 0.974495 0.0984032 0.396326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78120 episodes
GETTING ACTION FROM:
action 3, numVisits=77869, meanQ=20.337307, numObservations: 9
action 5, numVisits=167, meanQ=12.434786, numObservations: 9
action 4, numVisits=80, meanQ=12.264656, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.571191 0.611281 0.237305 0.0837568 0.862626 0.562452 0.320763 0.974495 0.0984032 0.396326 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 5
Initial state: 0 0.154972 0.213771 0.796277 0.274987 0.80821 0.769829 0.853182 0.973038 0.538364 0.62424 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48884 episodes
GETTING ACTION FROM:
action 0, numVisits=48862, meanQ=56.001561, numObservations: 243
action -1, numVisits=7, meanQ=-1.050000, numObservations: 7
action 1, numVisits=11, meanQ=-1.909091, numObservations: 5
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.154972 0.213771 0.796277 0.274987 0.80821 0.769829 0.853182 0.973038 0.538364 0.62424 w: 1
Observation: 0 0 1 0 1 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=268, meanQ=80.161870, numObservations: 9
action 4, numVisits=3, meanQ=62.650000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 112087 episodes
GETTING ACTION FROM:
action 5, numVisits=112355, meanQ=89.319119, numObservations: 9
action 4, numVisits=3, meanQ=62.650000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.154972 0.213771 0.796277 0.274987 0.80821 0.769829 0.853182 0.973038 0.538364 0.62424 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 6
Initial state: 0 0.178585 0.317065 0.541929 0.519763 0.547423 0.162052 0.174411 0.162948 0.67741 0.196439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48668 episodes
GETTING ACTION FROM:
action -1, numVisits=48595, meanQ=46.040571, numObservations: 243
action 0, numVisits=68, meanQ=-1.682169, numObservations: 59
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.178585 0.317065 0.541929 0.519763 0.547423 0.162052 0.174411 0.162948 0.67741 0.196439 w: 1
Observation: 0 1 0 2 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=143, meanQ=43.034056, numObservations: 9
action 0, numVisits=34, meanQ=-1.473309, numObservations: 31
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=10, meanQ=-10.934750, numObservations: 8
action 5, numVisits=5, meanQ=-21.000000, numObservations: 4
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 103789 episodes
GETTING ACTION FROM:
action 3, numVisits=103932, meanQ=29.256438, numObservations: 9
action 0, numVisits=34, meanQ=-1.473309, numObservations: 31
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=10, meanQ=-10.934750, numObservations: 8
action 5, numVisits=5, meanQ=-21.000000, numObservations: 4
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.178585 0.317065 0.541929 0.519763 0.547423 0.162052 0.174411 0.162948 0.67741 0.196439 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 7
Initial state: 0 0.118376 0.818569 0.693995 0.970671 0.556154 0.559127 0.82576 0.619027 0.56073 0.799678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48294 episodes
GETTING ACTION FROM:
action 0, numVisits=48235, meanQ=53.994519, numObservations: 243
action -1, numVisits=37, meanQ=-1.152703, numObservations: 35
action 5, numVisits=16, meanQ=-4.318750, numObservations: 8
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.118376 0.818569 0.693995 0.970671 0.556154 0.559127 0.82576 0.619027 0.56073 0.799678 w: 1
Observation: 0 0 3 0 3 0 3 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=136, meanQ=82.078033, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 108118 episodes
GETTING ACTION FROM:
action 4, numVisits=108254, meanQ=85.499142, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.118376 0.818569 0.693995 0.970671 0.556154 0.559127 0.82576 0.619027 0.56073 0.799678 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 8
Initial state: 0 0.554025 0.627649 0.24495 0.78854 0.78563 0.551176 0.272274 0.887846 0.163938 0.160085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 72630 episodes
GETTING ACTION FROM:
action 3, numVisits=72624, meanQ=23.165459, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.554025 0.627649 0.24495 0.78854 0.78563 0.551176 0.272274 0.887846 0.163938 0.160085 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 9
Initial state: 0 0.520616 0.476397 0.485819 0.173127 0.588176 0.561688 0.277281 0.96302 0.972153 0.372079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80344 episodes
GETTING ACTION FROM:
action 1, numVisits=80322, meanQ=19.467989, numObservations: 9
action -1, numVisits=9, meanQ=-1.050000, numObservations: 9
action 0, numVisits=9, meanQ=-1.050000, numObservations: 9
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.520616 0.476397 0.485819 0.173127 0.588176 0.561688 0.277281 0.96302 0.972153 0.372079 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=1500, meanQ=45.597000, numObservations: 198
action -1, numVisits=36, meanQ=-3.847222, numObservations: 33
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 19507 episodes
GETTING ACTION FROM:
action 0, numVisits=21007, meanQ=20.529020, numObservations: 243
action -1, numVisits=36, meanQ=-3.847222, numObservations: 33
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.520616 0.476397 0.485819 0.173127 0.588176 0.561688 0.277281 0.96302 0.972153 0.372079 w: 1
Observation: 0 0 1 0 1 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=39, meanQ=60.886353, numObservations: 6
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 84152 episodes
GETTING ACTION FROM:
action 3, numVisits=84148, meanQ=72.563235, numObservations: 9
action -1, numVisits=21, meanQ=-1.640357, numObservations: 16
action 5, numVisits=15, meanQ=-3.538892, numObservations: 5
action 0, numVisits=11, meanQ=-8.513455, numObservations: 6
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.520616 0.476397 0.485819 0.173127 0.588176 0.561688 0.277281 0.96302 0.972153 0.372079 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 10
Initial state: 0 0.594023 0.598228 0.865031 0.0449874 0.696526 0.123941 0.032401 0.901604 0.0689265 0.331976 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48360 episodes
GETTING ACTION FROM:
action 0, numVisits=48309, meanQ=55.313246, numObservations: 243
action -1, numVisits=41, meanQ=-1.448537, numObservations: 37
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=4, meanQ=-6.000000, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.594023 0.598228 0.865031 0.0449874 0.696526 0.123941 0.032401 0.901604 0.0689265 0.331976 w: 1
Observation: 0 0 2 0 1 0 1 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=342, meanQ=81.701948, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 109850 episodes
GETTING ACTION FROM:
action 1, numVisits=110192, meanQ=85.729396, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.594023 0.598228 0.865031 0.0449874 0.696526 0.123941 0.032401 0.901604 0.0689265 0.331976 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=931, meanQ=68.979187, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 62248 episodes
GETTING ACTION FROM:
action 1, numVisits=947, meanQ=69.169614, numObservations: 9
action -1, numVisits=62050, meanQ=2.477559, numObservations: 243
action 0, numVisits=181, meanQ=-2.467127, numObservations: 58
action 4, numVisits=2, meanQ=-11.410608, numObservations: 2
action 3, numVisits=2, meanQ=-55.525000, numObservations: 2
action 5, numVisits=2, meanQ=-55.525000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.594023 0.598228 0.865031 0.0449874 0.696526 0.123941 0.032401 0.901604 0.0689265 0.331976 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 11
Initial state: 0 0.949713 0.277532 0.531551 0.63659 0.0267157 0.738607 0.878247 0.834259 0.81927 0.218241 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79414 episodes
GETTING ACTION FROM:
action 2, numVisits=79403, meanQ=20.907800, numObservations: 9
action 4, numVisits=6, meanQ=9.233750, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.949713 0.277532 0.531551 0.63659 0.0267157 0.738607 0.878247 0.834259 0.81927 0.218241 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=3461, meanQ=23.925446, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 24500 episodes
GETTING ACTION FROM:
action 5, numVisits=27961, meanQ=21.713651, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.949713 0.277532 0.531551 0.63659 0.0267157 0.738607 0.878247 0.834259 0.81927 0.218241 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 12
Initial state: 0 0.22235 0.499739 0.244374 0.00525479 0.351014 0.398951 0.582457 0.626541 0.919877 0.856207 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77813 episodes
GETTING ACTION FROM:
action 4, numVisits=77780, meanQ=14.855185, numObservations: 9
action -1, numVisits=13, meanQ=-1.050000, numObservations: 13
action 0, numVisits=13, meanQ=-1.050000, numObservations: 13
action 3, numVisits=4, meanQ=-6.000000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.22235 0.499739 0.244374 0.00525479 0.351014 0.398951 0.582457 0.626541 0.919877 0.856207 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 13
Initial state: 0 0.188257 0.0702858 0.591564 0.491199 0.270704 0.843292 0.602565 0.802358 0.243748 0.187585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49004 episodes
GETTING ACTION FROM:
action -1, numVisits=48876, meanQ=46.120857, numObservations: 243
action 0, numVisits=120, meanQ=-5.837208, numObservations: 95
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=4, meanQ=-28.500000, numObservations: 3
action: -1
Next state: 0 0.188257 0.0702858 0.591564 0.491199 0.270704 0.843292 0.602565 0.802358 0.243748 0.187585 w: 1
Observation: 0 1 0 1 0 1 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=431, meanQ=79.484115, numObservations: 9
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 111992 episodes
GETTING ACTION FROM:
action 4, numVisits=112423, meanQ=87.331496, numObservations: 9
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.188257 0.0702858 0.591564 0.491199 0.270704 0.843292 0.602565 0.802358 0.243748 0.187585 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 14
Initial state: 0 0.703433 0.819747 0.525572 0.585222 0.261951 0.91932 0.0214478 0.678093 0.267531 0.0507992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80349 episodes
GETTING ACTION FROM:
action 3, numVisits=80317, meanQ=18.723171, numObservations: 9
action -1, numVisits=6, meanQ=-1.050000, numObservations: 6
action 0, numVisits=6, meanQ=-1.050000, numObservations: 6
action 4, numVisits=15, meanQ=-6.273000, numObservations: 8
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 3
Next state: 0 0.703433 0.819747 0.525572 0.585222 0.261951 0.91932 0.0214478 0.678093 0.267531 0.0507992 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=6918, meanQ=24.469850, numObservations: 9
action 4, numVisits=21, meanQ=14.540714, numObservations: 8
action 2, numVisits=8, meanQ=8.106250, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 27105 episodes
GETTING ACTION FROM:
action 5, numVisits=34023, meanQ=31.393846, numObservations: 9
action 4, numVisits=21, meanQ=14.540714, numObservations: 8
action 2, numVisits=8, meanQ=8.106250, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 0 0.703433 0.819747 0.525572 0.585222 0.261951 0.91932 0.0214478 0.678093 0.267531 0.0507992 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=3351, meanQ=28.033613, numObservations: 9
action 1, numVisits=5, meanQ=14.190000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 14253 episodes
GETTING ACTION FROM:
action 4, numVisits=17604, meanQ=36.600238, numObservations: 9
action 1, numVisits=5, meanQ=14.190000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.703433 0.819747 0.525572 0.585222 0.261951 0.91932 0.0214478 0.678093 0.267531 0.0507992 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=673, meanQ=64.469399, numObservations: 9
action 5, numVisits=3, meanQ=22.800833, numObservations: 2
action 2, numVisits=5, meanQ=15.380000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 28389 episodes
GETTING ACTION FROM:
action 1, numVisits=29062, meanQ=27.495767, numObservations: 9
action 5, numVisits=3, meanQ=22.800833, numObservations: 2
action 2, numVisits=5, meanQ=15.380000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 2 0.703433 0.819747 0.525572 0.585222 0.261951 0.91932 0.0214478 0.678093 0.267531 0.0507992 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -117.972
Run # 15
Initial state: 0 0.878682 0.136205 0.898961 0.496026 0.129021 0.550573 0.47098 0.594327 0.0347034 0.0575469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48570 episodes
GETTING ACTION FROM:
action 0, numVisits=48540, meanQ=55.743272, numObservations: 243
action -1, numVisits=25, meanQ=-4.926000, numObservations: 24
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.878682 0.136205 0.898961 0.496026 0.129021 0.550573 0.47098 0.594327 0.0347034 0.0575469 w: 1
Observation: 0 0 1 0 2 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=225, meanQ=47.548669, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 104297 episodes
GETTING ACTION FROM:
action 2, numVisits=104522, meanQ=51.455069, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.878682 0.136205 0.898961 0.496026 0.129021 0.550573 0.47098 0.594327 0.0347034 0.0575469 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 16
Initial state: 0 0.167937 0.842441 0.726008 0.0184693 0.943775 0.353612 0.593812 0.573825 0.768938 0.624149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79915 episodes
GETTING ACTION FROM:
action 2, numVisits=79905, meanQ=18.722376, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=5, meanQ=-3.000000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.167937 0.842441 0.726008 0.0184693 0.943775 0.353612 0.593812 0.573825 0.768938 0.624149 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 17
Initial state: 0 0.574013 0.408196 0.887724 0.0266139 0.212003 0.275001 0.094413 0.975738 0.546766 0.584924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48131 episodes
GETTING ACTION FROM:
action 0, numVisits=48069, meanQ=54.756022, numObservations: 243
action -1, numVisits=38, meanQ=-3.702500, numObservations: 35
action 5, numVisits=20, meanQ=-4.399625, numObservations: 8
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.574013 0.408196 0.887724 0.0266139 0.212003 0.275001 0.094413 0.975738 0.546766 0.584924 w: 1
Observation: 0 0 1 0 2 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=263, meanQ=80.976112, numObservations: 9
action 5, numVisits=3, meanQ=62.650000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 110980 episodes
GETTING ACTION FROM:
action 2, numVisits=111243, meanQ=86.225916, numObservations: 9
action 5, numVisits=3, meanQ=62.650000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.574013 0.408196 0.887724 0.0266139 0.212003 0.275001 0.094413 0.975738 0.546766 0.584924 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1282, meanQ=53.645751, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25300 episodes
GETTING ACTION FROM:
action 5, numVisits=26582, meanQ=57.854478, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.574013 0.408196 0.887724 0.0266139 0.212003 0.275001 0.094413 0.975738 0.546766 0.584924 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=93, meanQ=56.069368, numObservations: 8
action 4, numVisits=2, meanQ=43.479439, numObservations: 2
action 3, numVisits=2, meanQ=42.926029, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-214.362999, numObservations: 1
Sampled 80937 episodes
GETTING ACTION FROM:
action 4, numVisits=80901, meanQ=68.170946, numObservations: 9
action 5, numVisits=103, meanQ=57.550377, numObservations: 8
action 3, numVisits=30, meanQ=24.892531, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-214.362999, numObservations: 1
action: 4
Next state: 1 0.574013 0.408196 0.887724 0.0266139 0.212003 0.275001 0.094413 0.975738 0.546766 0.584924 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 62.5026
Run # 18
Initial state: 0 0.855634 0.658531 0.693449 0.322763 0.0704905 0.329509 0.810093 0.337645 0.549937 0.599442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48342 episodes
GETTING ACTION FROM:
action -1, numVisits=48315, meanQ=45.126701, numObservations: 243
action 0, numVisits=22, meanQ=-5.454545, numObservations: 21
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.855634 0.658531 0.693449 0.322763 0.0704905 0.329509 0.810093 0.337645 0.549937 0.599442 w: 1
Observation: 0 3 0 3 0 2 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=229, meanQ=82.145251, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 109235 episodes
GETTING ACTION FROM:
action 3, numVisits=109464, meanQ=78.416350, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.855634 0.658531 0.693449 0.322763 0.0704905 0.329509 0.810093 0.337645 0.549937 0.599442 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1244, meanQ=39.032858, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 22992 episodes
GETTING ACTION FROM:
action 5, numVisits=24236, meanQ=20.536282, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.855634 0.658531 0.693449 0.322763 0.0704905 0.329509 0.810093 0.337645 0.549937 0.599442 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 19
Initial state: 0 0.82566 0.628805 0.506192 0.47615 0.0791302 0.940207 0.23615 0.000448648 0.537719 0.54856 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82519 episodes
GETTING ACTION FROM:
action 2, numVisits=82512, meanQ=17.366764, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.82566 0.628805 0.506192 0.47615 0.0791302 0.940207 0.23615 0.000448648 0.537719 0.54856 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 20
Initial state: 0 0.823155 0.279764 0.678066 0.82438 0.582549 0.619858 0.27518 0.956755 0.760916 0.318446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48433 episodes
GETTING ACTION FROM:
action -1, numVisits=48414, meanQ=44.340353, numObservations: 243
action 0, numVisits=12, meanQ=-1.050000, numObservations: 12
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.823155 0.279764 0.678066 0.82438 0.582549 0.619858 0.27518 0.956755 0.760916 0.318446 w: 1
Observation: 0 3 0 3 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=212, meanQ=0.118508, numObservations: 9
action 0, numVisits=22, meanQ=-5.631591, numObservations: 19
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=13, meanQ=-10.084615, numObservations: 6
action -1, numVisits=3, meanQ=-33.350000, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 115035 episodes
GETTING ACTION FROM:
action 5, numVisits=115247, meanQ=6.062316, numObservations: 9
action 0, numVisits=22, meanQ=-5.631591, numObservations: 19
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=13, meanQ=-10.084615, numObservations: 6
action -1, numVisits=3, meanQ=-33.350000, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.823155 0.279764 0.678066 0.82438 0.582549 0.619858 0.27518 0.956755 0.760916 0.318446 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 21
Initial state: 0 0.589532 0.000494357 0.6728 0.987653 0.546935 0.537858 0.41096 0.88658 0.582267 0.438049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79117 episodes
GETTING ACTION FROM:
action 3, numVisits=79108, meanQ=20.267429, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.589532 0.000494357 0.6728 0.987653 0.546935 0.537858 0.41096 0.88658 0.582267 0.438049 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 22
Initial state: 0 0.120894 0.65348 0.548576 0.817242 0.260863 0.0119891 0.589449 0.117298 0.482852 0.535519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76184 episodes
GETTING ACTION FROM:
action 5, numVisits=76171, meanQ=20.656601, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 4, numVisits=4, meanQ=-6.000000, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.120894 0.65348 0.548576 0.817242 0.260863 0.0119891 0.589449 0.117298 0.482852 0.535519 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1214, meanQ=73.013300, numObservations: 9
action 1, numVisits=3, meanQ=26.300000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 78524 episodes
GETTING ACTION FROM:
action 5, numVisits=1268, meanQ=73.086079, numObservations: 9
action 1, numVisits=78473, meanQ=27.494828, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.120894 0.65348 0.548576 0.817242 0.260863 0.0119891 0.589449 0.117298 0.482852 0.535519 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 23
Initial state: 0 0.621669 0.731383 0.70857 0.987862 0.526707 0.58351 0.265928 0.213897 0.182227 0.121991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 76351 episodes
GETTING ACTION FROM:
action 3, numVisits=76077, meanQ=21.313837, numObservations: 9
action 4, numVisits=269, meanQ=9.756822, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.621669 0.731383 0.70857 0.987862 0.526707 0.58351 0.265928 0.213897 0.182227 0.121991 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 24
Initial state: 0 0.481388 0.613155 0.208234 0.387709 0.663787 0.246884 0.766743 0.71882 0.729387 0.118708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48333 episodes
GETTING ACTION FROM:
action -1, numVisits=48314, meanQ=44.950635, numObservations: 243
action 0, numVisits=14, meanQ=-7.971429, numObservations: 13
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.481388 0.613155 0.208234 0.387709 0.663787 0.246884 0.766743 0.71882 0.729387 0.118708 w: 1
Observation: 0 2 0 1 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=273, meanQ=75.964335, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 106916 episodes
GETTING ACTION FROM:
action 1, numVisits=107189, meanQ=82.853739, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.481388 0.613155 0.208234 0.387709 0.663787 0.246884 0.766743 0.71882 0.729387 0.118708 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 25
Initial state: 0 0.627171 0.807936 0.477766 0.479575 0.385642 0.487034 0.550837 0.126713 0.480228 0.530115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77647 episodes
GETTING ACTION FROM:
action 2, numVisits=77630, meanQ=20.665655, numObservations: 9
action 1, numVisits=12, meanQ=12.408542, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.627171 0.807936 0.477766 0.479575 0.385642 0.487034 0.550837 0.126713 0.480228 0.530115 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 26
Initial state: 0 0.0112411 0.0996074 0.274935 0.575062 0.200225 0.0712553 0.478623 0.547193 0.320515 0.384497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81879 episodes
GETTING ACTION FROM:
action 1, numVisits=81849, meanQ=19.665718, numObservations: 9
action -1, numVisits=13, meanQ=-1.050000, numObservations: 13
action 0, numVisits=13, meanQ=-1.050000, numObservations: 13
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0112411 0.0996074 0.274935 0.575062 0.200225 0.0712553 0.478623 0.547193 0.320515 0.384497 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2007, meanQ=28.496829, numObservations: 9
action 2, numVisits=6, meanQ=14.158333, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 83887 episodes
GETTING ACTION FROM:
action 5, numVisits=38733, meanQ=-1.883516, numObservations: 9
action 3, numVisits=46969, meanQ=-2.641881, numObservations: 9
action -1, numVisits=96, meanQ=-2.870833, numObservations: 62
action 0, numVisits=85, meanQ=-4.272789, numObservations: 63
action 2, numVisits=20, meanQ=-6.452500, numObservations: 6
action 4, numVisits=2, meanQ=-55.525000, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.0112411 0.0996074 0.274935 0.575062 0.200225 0.0712553 0.478623 0.547193 0.320515 0.384497 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=488, meanQ=32.549085, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-12.144274, numObservations: 1
action 4, numVisits=1, meanQ=-12.180685, numObservations: 1
action 5, numVisits=1, meanQ=-12.214191, numObservations: 1
action 1, numVisits=1, meanQ=-215.311426, numObservations: 1
Sampled 31469 episodes
GETTING ACTION FROM:
action 0, numVisits=29519, meanQ=4.032519, numObservations: 239
action -1, numVisits=258, meanQ=-2.008179, numObservations: 85
action 2, numVisits=2178, meanQ=-2.154068, numObservations: 9
action 5, numVisits=1, meanQ=-12.214191, numObservations: 1
action 4, numVisits=4, meanQ=-28.795171, numObservations: 4
action 3, numVisits=2, meanQ=-56.572137, numObservations: 2
action 1, numVisits=1, meanQ=-215.311426, numObservations: 1
action: 0
Next state: 0 0.0112411 0.0996074 0.274935 0.575062 0.200225 0.0712553 0.478623 0.547193 0.320515 0.384497 w: 1
Observation: 0 0 1 0 2 0 1 0 2 0 3 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=16, meanQ=54.937402, numObservations: 6
action 0, numVisits=3, meanQ=-5.216848, numObservations: 2
action 2, numVisits=3, meanQ=-10.717077, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-113.681568, numObservations: 1
Sampled 25803 episodes
GETTING ACTION FROM:
action -1, numVisits=25819, meanQ=16.425791, numObservations: 231
action 0, numVisits=3, meanQ=-5.216848, numObservations: 2
action 2, numVisits=3, meanQ=-10.717077, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-113.681568, numObservations: 1
action: -1
Next state: 0 0.0112411 0.0996074 0.274935 0.575062 0.200225 0.0712553 0.478623 0.547193 0.320515 0.384497 w: 1
Observation: 0 1 0 1 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=4, meanQ=99.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-12.123438, numObservations: 1
action 3, numVisits=1, meanQ=-12.452310, numObservations: 1
action 1, numVisits=1, meanQ=-113.591676, numObservations: 1
action 5, numVisits=1, meanQ=-113.613583, numObservations: 1
Sampled 42150 episodes
GETTING ACTION FROM:
action -1, numVisits=42101, meanQ=11.394375, numObservations: 225
action 0, numVisits=31, meanQ=-5.033871, numObservations: 14
action 2, numVisits=22, meanQ=-11.000000, numObservations: 5
action 4, numVisits=2, meanQ=-56.561719, numObservations: 2
action 3, numVisits=2, meanQ=-56.726155, numObservations: 2
action 1, numVisits=1, meanQ=-113.591676, numObservations: 1
action 5, numVisits=1, meanQ=-113.613583, numObservations: 1
action: -1
Next state: 0 0.0112411 0.0996074 0.274935 0.575062 0.200225 0.0712553 0.478623 0.547193 0.320515 0.384497 w: 1
Observation: 0 1 0 2 0 1 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 4, numVisits=40, meanQ=68.683590, numObservations: 5
action 2, numVisits=23, meanQ=64.217391, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-113.198304, numObservations: 1
Sampled 120377 episodes
GETTING ACTION FROM:
action 4, numVisits=120417, meanQ=77.406876, numObservations: 9
action 2, numVisits=23, meanQ=64.217391, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-113.198304, numObservations: 1
action: 4
Next state: 1 0.0112411 0.0996074 0.274935 0.575062 0.200225 0.0712553 0.478623 0.547193 0.320515 0.384497 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 50.0056
Run # 27
Initial state: 0 0.214103 0.0522548 0.548607 0.378327 0.796892 0.512412 0.647219 0.243437 0.589739 0.569374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47611 episodes
GETTING ACTION FROM:
action -1, numVisits=47523, meanQ=47.825152, numObservations: 243
action 1, numVisits=33, meanQ=-2.020909, numObservations: 9
action 0, numVisits=49, meanQ=-3.319337, numObservations: 45
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.214103 0.0522548 0.548607 0.378327 0.796892 0.512412 0.647219 0.243437 0.589739 0.569374 w: 1
Observation: 0 1 0 2 0 3 0 2 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=41, meanQ=35.947744, numObservations: 8
action 5, numVisits=24, meanQ=5.825000, numObservations: 8
action 4, numVisits=30, meanQ=5.666667, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 90431 episodes
GETTING ACTION FROM:
action 2, numVisits=90472, meanQ=25.934497, numObservations: 9
action 5, numVisits=24, meanQ=5.825000, numObservations: 8
action 4, numVisits=30, meanQ=5.666667, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.214103 0.0522548 0.548607 0.378327 0.796892 0.512412 0.647219 0.243437 0.589739 0.569374 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=3863, meanQ=54.328248, numObservations: 164
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=9, meanQ=-11.816667, numObservations: 8
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 23940 episodes
GETTING ACTION FROM:
action -1, numVisits=27803, meanQ=21.085790, numObservations: 227
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=9, meanQ=-11.816667, numObservations: 8
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.214103 0.0522548 0.548607 0.378327 0.796892 0.512412 0.647219 0.243437 0.589739 0.569374 w: 1
Observation: 0 1 0 2 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=508, meanQ=44.890268, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 104949 episodes
GETTING ACTION FROM:
action 5, numVisits=105457, meanQ=48.400950, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.214103 0.0522548 0.548607 0.378327 0.796892 0.512412 0.647219 0.243437 0.589739 0.569374 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 70.6251
Run # 28
Initial state: 0 0.360738 0.276525 0.867191 0.0947467 0.00545972 0.790828 0.186557 0.2619 0.495373 0.634691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 72556 episodes
GETTING ACTION FROM:
action 3, numVisits=72537, meanQ=23.151506, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=8, meanQ=-3.262500, numObservations: 6
action 4, numVisits=7, meanQ=-6.513929, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.360738 0.276525 0.867191 0.0947467 0.00545972 0.790828 0.186557 0.2619 0.495373 0.634691 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 29
Initial state: 0 0.898201 0.541679 0.95312 0.559912 0.0193687 0.783832 0.503459 0.560601 0.444169 0.330029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48338 episodes
GETTING ACTION FROM:
action -1, numVisits=48196, meanQ=45.524677, numObservations: 243
action 0, numVisits=133, meanQ=-1.463214, numObservations: 95
action 1, numVisits=3, meanQ=-4.333333, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.898201 0.541679 0.95312 0.559912 0.0193687 0.783832 0.503459 0.560601 0.444169 0.330029 w: 1
Observation: 0 3 0 3 0 1 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=269, meanQ=80.068512, numObservations: 9
action 5, numVisits=3, meanQ=26.300000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 111164 episodes
GETTING ACTION FROM:
action 4, numVisits=111433, meanQ=81.644907, numObservations: 9
action 5, numVisits=3, meanQ=26.300000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.898201 0.541679 0.95312 0.559912 0.0193687 0.783832 0.503459 0.560601 0.444169 0.330029 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 30
Initial state: 0 0.628109 0.381724 0.516674 0.542275 0.873261 0.213243 0.756521 0.530244 0.271439 0.573927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48111 episodes
GETTING ACTION FROM:
action -1, numVisits=48084, meanQ=45.592283, numObservations: 243
action 0, numVisits=15, meanQ=-1.749833, numObservations: 14
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=8, meanQ=-14.750000, numObservations: 5
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.628109 0.381724 0.516674 0.542275 0.873261 0.213243 0.756521 0.530244 0.271439 0.573927 w: 1
Observation: 0 3 0 2 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=230, meanQ=82.264804, numObservations: 9
action 4, numVisits=6, meanQ=65.666667, numObservations: 4
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 112392 episodes
GETTING ACTION FROM:
action 2, numVisits=112622, meanQ=80.262571, numObservations: 9
action 4, numVisits=6, meanQ=65.666667, numObservations: 4
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.628109 0.381724 0.516674 0.542275 0.873261 0.213243 0.756521 0.530244 0.271439 0.573927 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 31
Initial state: 0 0.867356 0.275741 0.862183 0.098995 0.533127 0.495956 0.935632 0.472679 0.576419 0.251279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49451 episodes
GETTING ACTION FROM:
action 0, numVisits=49417, meanQ=56.629277, numObservations: 243
action 2, numVisits=6, meanQ=-4.175000, numObservations: 4
action -1, numVisits=24, meanQ=-5.087500, numObservations: 23
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.867356 0.275741 0.862183 0.098995 0.533127 0.495956 0.935632 0.472679 0.576419 0.251279 w: 1
Observation: 0 0 1 0 1 0 2 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=335, meanQ=47.148506, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 96920 episodes
GETTING ACTION FROM:
action 3, numVisits=97255, meanQ=63.963584, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.867356 0.275741 0.862183 0.098995 0.533127 0.495956 0.935632 0.472679 0.576419 0.251279 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 32
Initial state: 0 0.899631 0.483336 0.475974 0.714757 0.237829 0.680128 0.050021 0.992785 0.577219 0.516267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82818 episodes
GETTING ACTION FROM:
action 4, numVisits=82810, meanQ=17.676906, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.899631 0.483336 0.475974 0.714757 0.237829 0.680128 0.050021 0.992785 0.577219 0.516267 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 33
Initial state: 0 0.408217 0.79765 0.898407 0.0320456 0.532861 0.507816 0.457908 0.961543 0.207387 0.961669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47030 episodes
GETTING ACTION FROM:
action 0, numVisits=47010, meanQ=54.607663, numObservations: 243
action -1, numVisits=15, meanQ=-7.510000, numObservations: 14
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.408217 0.79765 0.898407 0.0320456 0.532861 0.507816 0.457908 0.961543 0.207387 0.961669 w: 1
Observation: 0 0 3 0 1 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=184, meanQ=83.688981, numObservations: 9
action 4, numVisits=4, meanQ=49.000000, numObservations: 4
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 109439 episodes
GETTING ACTION FROM:
action 3, numVisits=109623, meanQ=88.580521, numObservations: 9
action 4, numVisits=4, meanQ=49.000000, numObservations: 4
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.408217 0.79765 0.898407 0.0320456 0.532861 0.507816 0.457908 0.961543 0.207387 0.961669 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 34
Initial state: 0 0.282832 0.0788364 0.570186 0.57734 0.74459 0.699505 0.274769 0.3204 0.0227663 0.687513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81775 episodes
GETTING ACTION FROM:
action 4, numVisits=81766, meanQ=18.499294, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.282832 0.0788364 0.570186 0.57734 0.74459 0.699505 0.274769 0.3204 0.0227663 0.687513 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12037, meanQ=25.865507, numObservations: 9
action -1, numVisits=5, meanQ=-1.050000, numObservations: 5
action 0, numVisits=5, meanQ=-1.050000, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 21528 episodes
GETTING ACTION FROM:
action 1, numVisits=33565, meanQ=25.429643, numObservations: 9
action -1, numVisits=5, meanQ=-1.050000, numObservations: 5
action 0, numVisits=5, meanQ=-1.050000, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.282832 0.0788364 0.570186 0.57734 0.74459 0.699505 0.274769 0.3204 0.0227663 0.687513 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=4034, meanQ=51.647139, numObservations: 178
action 3, numVisits=5, meanQ=-2.810000, numObservations: 3
action 2, numVisits=9, meanQ=-4.016667, numObservations: 6
action 0, numVisits=18, meanQ=-6.541528, numObservations: 16
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 6556 episodes
GETTING ACTION FROM:
action -1, numVisits=10590, meanQ=46.417464, numObservations: 222
action 3, numVisits=5, meanQ=-2.810000, numObservations: 3
action 2, numVisits=9, meanQ=-4.016667, numObservations: 6
action 0, numVisits=18, meanQ=-6.541528, numObservations: 16
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: -1
Next state: 0 0.282832 0.0788364 0.570186 0.57734 0.74459 0.699505 0.274769 0.3204 0.0227663 0.687513 w: 1
Observation: 0 1 0 2 0 3 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=256, meanQ=87.495813, numObservations: 9
action 3, numVisits=3, meanQ=62.650000, numObservations: 3
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 55722 episodes
GETTING ACTION FROM:
action 2, numVisits=55978, meanQ=88.633778, numObservations: 9
action 3, numVisits=3, meanQ=62.650000, numObservations: 3
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 0 0.282832 0.0788364 0.570186 0.57734 0.74459 0.699505 0.274769 0.3204 0.0227663 0.687513 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=2848, meanQ=95.583335, numObservations: 9
action 3, numVisits=2, meanQ=43.479783, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 116598 episodes
GETTING ACTION FROM:
action 2, numVisits=119442, meanQ=98.011487, numObservations: 9
action 3, numVisits=6, meanQ=13.826594, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.282832 0.0788364 0.570186 0.57734 0.74459 0.699505 0.274769 0.3204 0.0227663 0.687513 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 47.95
Run # 35
Initial state: 0 0.295589 0.740881 0.366906 0.879955 0.61162 0.305828 0.575638 0.551322 0.179367 0.832082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78125 episodes
GETTING ACTION FROM:
action 3, numVisits=78118, meanQ=20.857177, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.295589 0.740881 0.366906 0.879955 0.61162 0.305828 0.575638 0.551322 0.179367 0.832082 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 36
Initial state: 0 0.905278 0.857172 0.065391 0.19383 0.603264 0.61413 0.174547 0.307258 0.323047 0.173904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81789 episodes
GETTING ACTION FROM:
action 1, numVisits=81783, meanQ=17.899122, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.905278 0.857172 0.065391 0.19383 0.603264 0.61413 0.174547 0.307258 0.323047 0.173904 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 37
Initial state: 0 0.902889 0.825725 0.229486 0.989044 0.519496 0.529611 0.0563405 0.184138 0.192443 0.536694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79155 episodes
GETTING ACTION FROM:
action 3, numVisits=79141, meanQ=19.395910, numObservations: 9
action 5, numVisits=9, meanQ=12.484167, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.902889 0.825725 0.229486 0.989044 0.519496 0.529611 0.0563405 0.184138 0.192443 0.536694 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1445, meanQ=18.643071, numObservations: 9
action 0, numVisits=25, meanQ=-5.003900, numObservations: 23
action -1, numVisits=22, meanQ=-5.454545, numObservations: 21
action 5, numVisits=4, meanQ=-7.012500, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37617 episodes
GETTING ACTION FROM:
action 2, numVisits=39062, meanQ=4.526933, numObservations: 9
action 0, numVisits=25, meanQ=-5.003900, numObservations: 23
action -1, numVisits=22, meanQ=-5.454545, numObservations: 21
action 5, numVisits=4, meanQ=-7.012500, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.902889 0.825725 0.229486 0.989044 0.519496 0.529611 0.0563405 0.184138 0.192443 0.536694 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 38
Initial state: 0 0.401709 0.539023 0.195995 0.224965 0.508242 0.490493 0.72247 0.110239 0.775635 0.103484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81785 episodes
GETTING ACTION FROM:
action 4, numVisits=81735, meanQ=19.003015, numObservations: 9
action 5, numVisits=36, meanQ=8.093819, numObservations: 8
action 2, numVisits=10, meanQ=6.190000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.401709 0.539023 0.195995 0.224965 0.508242 0.490493 0.72247 0.110239 0.775635 0.103484 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 39
Initial state: 0 0.260958 0.79131 0.394507 0.507782 0.10033 0.497803 0.349252 0.289061 0.491639 0.503104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48766 episodes
GETTING ACTION FROM:
action -1, numVisits=48739, meanQ=43.989474, numObservations: 243
action 0, numVisits=16, meanQ=-1.706094, numObservations: 15
action 4, numVisits=7, meanQ=-5.285714, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.260958 0.79131 0.394507 0.507782 0.10033 0.497803 0.349252 0.289061 0.491639 0.503104 w: 1
Observation: 0 1 0 1 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=188, meanQ=29.419113, numObservations: 9
action 3, numVisits=9, meanQ=4.766667, numObservations: 5
action 2, numVisits=7, meanQ=2.529286, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=7, meanQ=-6.378214, numObservations: 3
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 59817 episodes
GETTING ACTION FROM:
action 4, numVisits=60005, meanQ=38.211811, numObservations: 9
action 3, numVisits=9, meanQ=4.766667, numObservations: 5
action 2, numVisits=7, meanQ=2.529286, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=7, meanQ=-6.378214, numObservations: 3
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 0 0.260958 0.79131 0.394507 0.507782 0.10033 0.497803 0.349252 0.289061 0.491639 0.503104 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=16460, meanQ=47.942763, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 11053 episodes
GETTING ACTION FROM:
action 3, numVisits=27513, meanQ=45.779969, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 2 0.260958 0.79131 0.394507 0.507782 0.10033 0.497803 0.349252 0.289061 0.491639 0.503104 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -103.603
Run # 40
Initial state: 0 0.109761 0.66078 0.381852 0.425677 0.637927 0.760276 0.847581 0.743788 0.481832 0.615491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74223 episodes
GETTING ACTION FROM:
action 3, numVisits=74217, meanQ=23.190623, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.109761 0.66078 0.381852 0.425677 0.637927 0.760276 0.847581 0.743788 0.481832 0.615491 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.354614 0.00971355 0.273179 0.322283 0.580728 0.602944 0.662685 0.61876 0.715681 0.00411272 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 82429 episodes
GETTING ACTION FROM:
action 2, numVisits=82417, meanQ=18.770166, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.354614 0.00971355 0.273179 0.322283 0.580728 0.602944 0.662685 0.61876 0.715681 0.00411272 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12020, meanQ=24.460992, numObservations: 9
action -1, numVisits=27, meanQ=-5.027685, numObservations: 25
action 0, numVisits=22, meanQ=-5.631591, numObservations: 19
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=4, meanQ=-28.262500, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25176 episodes
GETTING ACTION FROM:
action 1, numVisits=37196, meanQ=26.329982, numObservations: 9
action -1, numVisits=27, meanQ=-5.027685, numObservations: 25
action 0, numVisits=22, meanQ=-5.631591, numObservations: 19
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=4, meanQ=-28.262500, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.354614 0.00971355 0.273179 0.322283 0.580728 0.602944 0.662685 0.61876 0.715681 0.00411272 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=4866, meanQ=39.756334, numObservations: 9
action 4, numVisits=6, meanQ=14.158333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=5, meanQ=-2.810000, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 18696 episodes
GETTING ACTION FROM:
action 3, numVisits=23562, meanQ=33.408561, numObservations: 9
action 4, numVisits=6, meanQ=14.158333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=5, meanQ=-2.810000, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.354614 0.00971355 0.273179 0.322283 0.580728 0.602944 0.662685 0.61876 0.715681 0.00411272 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 42
Initial state: 0 0.35617 0.449214 0.491319 0.812866 0.903043 0.682418 0.529269 0.523243 0.37879 0.689669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47976 episodes
GETTING ACTION FROM:
action -1, numVisits=47951, meanQ=45.958695, numObservations: 243
action 0, numVisits=20, meanQ=-1.050000, numObservations: 20
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.35617 0.449214 0.491319 0.812866 0.903043 0.682418 0.529269 0.523243 0.37879 0.689669 w: 1
Observation: 0 1 0 3 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=118, meanQ=18.333136, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 115167 episodes
GETTING ACTION FROM:
action 2, numVisits=115283, meanQ=4.689338, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.35617 0.449214 0.491319 0.812866 0.903043 0.682418 0.529269 0.523243 0.37879 0.689669 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 43
Initial state: 0 0.193302 0.280061 0.728874 0.000761277 0.539237 0.604828 0.0465848 0.405078 0.987071 0.467548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 81541 episodes
GETTING ACTION FROM:
action 1, numVisits=81535, meanQ=18.208133, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.193302 0.280061 0.728874 0.000761277 0.539237 0.604828 0.0465848 0.405078 0.987071 0.467548 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11825, meanQ=23.686495, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 23220 episodes
GETTING ACTION FROM:
action 3, numVisits=35045, meanQ=21.423537, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.193302 0.280061 0.728874 0.000761277 0.539237 0.604828 0.0465848 0.405078 0.987071 0.467548 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 44
Initial state: 0 0.0344273 0.4583 0.57646 0.547946 0.463328 0.888695 0.185607 0.666174 0.96558 0.280632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 73494 episodes
GETTING ACTION FROM:
action 2, numVisits=73485, meanQ=21.954451, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=4, meanQ=-6.249375, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0344273 0.4583 0.57646 0.547946 0.463328 0.888695 0.185607 0.666174 0.96558 0.280632 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 45
Initial state: 0 0.446918 0.149383 0.870229 0.91773 0.646267 0.0350652 0.484057 0.526228 0.743674 0.303942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83758 episodes
GETTING ACTION FROM:
action 4, numVisits=83731, meanQ=18.671112, numObservations: 9
action 3, numVisits=8, meanQ=7.625312, numObservations: 5
action 5, numVisits=9, meanQ=5.561111, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=7, meanQ=-5.014286, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.446918 0.149383 0.870229 0.91773 0.646267 0.0350652 0.484057 0.526228 0.743674 0.303942 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 46
Initial state: 0 0.090833 0.0690081 0.560798 0.439245 0.00441893 0.810523 0.595289 0.517526 0.507411 0.293084 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80510 episodes
GETTING ACTION FROM:
action 5, numVisits=80498, meanQ=20.477093, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=7, meanQ=-5.292500, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.090833 0.0690081 0.560798 0.439245 0.00441893 0.810523 0.595289 0.517526 0.507411 0.293084 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 47
Initial state: 0 0.489573 0.612484 0.0630272 0.818402 0.91146 0.917445 0.756754 0.767847 0.207212 0.5886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84355 episodes
GETTING ACTION FROM:
action 5, numVisits=84342, meanQ=18.278416, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=6, meanQ=-5.166667, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.489573 0.612484 0.0630272 0.818402 0.91146 0.917445 0.756754 0.767847 0.207212 0.5886 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 48
Initial state: 0 0.0428185 0.0360874 0.0660794 0.326894 0.848011 0.0124165 0.553954 0.505681 0.657661 0.872528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 83062 episodes
GETTING ACTION FROM:
action 1, numVisits=83001, meanQ=19.021804, numObservations: 9
action 2, numVisits=56, meanQ=14.832679, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0428185 0.0360874 0.0660794 0.326894 0.848011 0.0124165 0.553954 0.505681 0.657661 0.872528 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11952, meanQ=25.631644, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 28222 episodes
GETTING ACTION FROM:
action 2, numVisits=40174, meanQ=25.029814, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 0 0.0428185 0.0360874 0.0660794 0.326894 0.848011 0.0124165 0.553954 0.505681 0.657661 0.872528 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=4035, meanQ=30.799368, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 20178 episodes
GETTING ACTION FROM:
action 4, numVisits=24213, meanQ=18.337068, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.0428185 0.0360874 0.0660794 0.326894 0.848011 0.0124165 0.553954 0.505681 0.657661 0.872528 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 49
Initial state: 0 0.734318 0.552839 0.388282 0.678207 0.502639 0.543677 0.142639 0.512168 0.900099 0.814806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 71070 episodes
GETTING ACTION FROM:
action 3, numVisits=71046, meanQ=23.660531, numObservations: 9
action 1, numVisits=19, meanQ=5.108289, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.734318 0.552839 0.388282 0.678207 0.502639 0.543677 0.142639 0.512168 0.900099 0.814806 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 50
Initial state: 0 0.0933306 0.488676 0.56368 0.499539 0.999209 0.990387 0.695836 0.550591 0.0730974 0.831217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79505 episodes
GETTING ACTION FROM:
action 2, numVisits=79487, meanQ=20.461926, numObservations: 9
action 3, numVisits=11, meanQ=2.113864, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0933306 0.488676 0.56368 0.499539 0.999209 0.990387 0.695836 0.550591 0.0730974 0.831217 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
[32m ProblemEnvironment.hpp 351: Done.[39m
