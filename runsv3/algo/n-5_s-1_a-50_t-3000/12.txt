Run # 1
Initial state: 0 0.783339 0.186941 0.986292 0.445807 0.653071 0.621652 0.118194 0.569119 0.488043 0.655521 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49062 episodes
GETTING ACTION FROM:
action 0, numVisits=49044, meanQ=55.200138, numObservations: 243
action -1, numVisits=13, meanQ=-8.503846, numObservations: 12
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.783339 0.186941 0.986292 0.445807 0.653071 0.621652 0.118194 0.569119 0.488043 0.655521 w: 1
Observation: 0 0 1 0 3 0 2 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=249, meanQ=45.990292, numObservations: 9
action 5, numVisits=13, meanQ=27.680769, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 101541 episodes
GETTING ACTION FROM:
action 3, numVisits=101790, meanQ=66.216243, numObservations: 9
action 5, numVisits=13, meanQ=27.680769, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.783339 0.186941 0.986292 0.445807 0.653071 0.621652 0.118194 0.569119 0.488043 0.655521 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 2
Initial state: 0 0.275753 0.0531951 0.862763 0.544101 0.551722 0.278665 0.492092 0.632639 0.925068 0.163253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49359 episodes
GETTING ACTION FROM:
action 0, numVisits=49308, meanQ=53.795393, numObservations: 243
action 3, numVisits=34, meanQ=-6.873235, numObservations: 9
action -1, numVisits=11, meanQ=-9.859091, numObservations: 10
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.275753 0.0531951 0.862763 0.544101 0.551722 0.278665 0.492092 0.632639 0.925068 0.163253 w: 1
Observation: 0 0 1 0 1 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=882, meanQ=87.266679, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 114031 episodes
GETTING ACTION FROM:
action 4, numVisits=114913, meanQ=91.025251, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.275753 0.0531951 0.862763 0.544101 0.551722 0.278665 0.492092 0.632639 0.925068 0.163253 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=1682, meanQ=39.884688, numObservations: 212
action 1, numVisits=15, meanQ=-13.266000, numObservations: 5
action 0, numVisits=6, meanQ=-17.200000, numObservations: 5
action 2, numVisits=8, meanQ=-20.711875, numObservations: 5
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 30451 episodes
GETTING ACTION FROM:
action -1, numVisits=32133, meanQ=12.025762, numObservations: 243
action 1, numVisits=15, meanQ=-13.266000, numObservations: 5
action 0, numVisits=6, meanQ=-17.200000, numObservations: 5
action 2, numVisits=8, meanQ=-20.711875, numObservations: 5
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.275753 0.0531951 0.862763 0.544101 0.551722 0.278665 0.492092 0.632639 0.925068 0.163253 w: 1
Observation: 0 1 0 3 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=2, meanQ=99.000000, numObservations: 1
action 0, numVisits=61, meanQ=31.960164, numObservations: 21
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=5, meanQ=-20.430000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 50219 episodes
GETTING ACTION FROM:
action 4, numVisits=169, meanQ=98.254734, numObservations: 6
action 0, numVisits=50113, meanQ=12.193490, numObservations: 179
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=5, meanQ=-20.430000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.275753 0.0531951 0.862763 0.544101 0.551722 0.278665 0.492092 0.632639 0.925068 0.163253 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 70.6251
Run # 3
Initial state: 0 0.314704 0.41297 0.325645 0.400988 0.507262 0.634252 0.152319 0.383106 0.141975 0.365295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 46477 episodes
GETTING ACTION FROM:
action -1, numVisits=46435, meanQ=36.543265, numObservations: 243
action 0, numVisits=34, meanQ=-4.208750, numObservations: 32
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=4, meanQ=-28.500000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.314704 0.41297 0.325645 0.400988 0.507262 0.634252 0.152319 0.383106 0.141975 0.365295 w: 1
Observation: 0 1 0 1 0 2 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=151, meanQ=70.517699, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 103474 episodes
GETTING ACTION FROM:
action 3, numVisits=103625, meanQ=80.738784, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.314704 0.41297 0.325645 0.400988 0.507262 0.634252 0.152319 0.383106 0.141975 0.365295 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 4
Initial state: 0 0.221634 0.773405 0.983069 0.237704 0.363981 0.562747 0.955034 0.241209 0.622928 0.856312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85865 episodes
GETTING ACTION FROM:
action 2, numVisits=85855, meanQ=7.398777, numObservations: 9
action -1, numVisits=3, meanQ=-1.050000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.221634 0.773405 0.983069 0.237704 0.363981 0.562747 0.955034 0.241209 0.622928 0.856312 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 5
Initial state: 0 0.489955 0.673412 0.391538 0.153727 0.076873 0.391938 0.670299 0.0458671 0.446791 0.764495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85538 episodes
GETTING ACTION FROM:
action 5, numVisits=85532, meanQ=8.210556, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.489955 0.673412 0.391538 0.153727 0.076873 0.391938 0.670299 0.0458671 0.446791 0.764495 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 6
Initial state: 0 0.749334 0.152356 0.290791 0.753423 0.515129 0.721333 0.868245 0.548754 0.850912 0.603532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84652 episodes
GETTING ACTION FROM:
action 2, numVisits=84605, meanQ=7.767775, numObservations: 9
action -1, numVisits=28, meanQ=-8.346339, numObservations: 25
action 0, numVisits=10, meanQ=-10.740000, numObservations: 9
action 4, numVisits=5, meanQ=-21.000000, numObservations: 4
action 1, numVisits=2, meanQ=-56.000000, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.749334 0.152356 0.290791 0.753423 0.515129 0.721333 0.868245 0.548754 0.850912 0.603532 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=4153, meanQ=46.115943, numObservations: 226
action 0, numVisits=7, meanQ=-1.050000, numObservations: 7
action 4, numVisits=6, meanQ=-4.016667, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11103 episodes
GETTING ACTION FROM:
action -1, numVisits=15256, meanQ=36.544811, numObservations: 243
action 0, numVisits=7, meanQ=-1.050000, numObservations: 7
action 4, numVisits=6, meanQ=-4.016667, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.749334 0.152356 0.290791 0.753423 0.515129 0.721333 0.868245 0.548754 0.850912 0.603532 w: 1
Observation: 0 3 0 3 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=25, meanQ=76.776632, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 98969 episodes
GETTING ACTION FROM:
action 3, numVisits=98994, meanQ=94.629721, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.749334 0.152356 0.290791 0.753423 0.515129 0.721333 0.868245 0.548754 0.850912 0.603532 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=99.000000, numObservations: 1
action 3, numVisits=183, meanQ=91.920678, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 67819 episodes
GETTING ACTION FROM:
action 3, numVisits=303, meanQ=92.988561, numObservations: 8
action 2, numVisits=16, meanQ=79.625000, numObservations: 2
action 0, numVisits=67517, meanQ=0.922213, numObservations: 239
action -1, numVisits=169, meanQ=-2.618379, numObservations: 44
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.749334 0.152356 0.290791 0.753423 0.515129 0.721333 0.868245 0.548754 0.850912 0.603532 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 62.0526
Run # 7
Initial state: 0 0.475561 0.587752 0.328352 0.289096 0.44282 0.101304 0.608124 0.154917 0.886997 0.355827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49752 episodes
GETTING ACTION FROM:
action 0, numVisits=49637, meanQ=54.542073, numObservations: 243
action -1, numVisits=102, meanQ=-5.514534, numObservations: 85
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=9, meanQ=-14.333333, numObservations: 7
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.475561 0.587752 0.328352 0.289096 0.44282 0.101304 0.608124 0.154917 0.886997 0.355827 w: 1
Observation: 0 0 2 0 1 0 1 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=872, meanQ=58.900871, numObservations: 74
action 1, numVisits=3, meanQ=-6.000000, numObservations: 1
action -1, numVisits=11, meanQ=-9.859091, numObservations: 10
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 52013 episodes
GETTING ACTION FROM:
action 0, numVisits=52885, meanQ=75.428228, numObservations: 187
action 1, numVisits=3, meanQ=-6.000000, numObservations: 1
action -1, numVisits=11, meanQ=-9.859091, numObservations: 10
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.475561 0.587752 0.328352 0.289096 0.44282 0.101304 0.608124 0.154917 0.886997 0.355827 w: 1
Observation: 0 0 2 0 1 0 1 0 1 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=24402, meanQ=96.022648, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 117213 episodes
GETTING ACTION FROM:
action 1, numVisits=141615, meanQ=96.542405, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.475561 0.587752 0.328352 0.289096 0.44282 0.101304 0.608124 0.154917 0.886997 0.355827 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 8
Initial state: 0 0.968373 0.0786537 0.12994 0.571826 0.696692 0.664796 0.421181 0.63576 0.0112868 0.558883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87144 episodes
GETTING ACTION FROM:
action 2, numVisits=87120, meanQ=8.348644, numObservations: 9
action -1, numVisits=10, meanQ=-1.050000, numObservations: 10
action 0, numVisits=10, meanQ=-1.050000, numObservations: 10
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.968373 0.0786537 0.12994 0.571826 0.696692 0.664796 0.421181 0.63576 0.0112868 0.558883 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=3211, meanQ=42.707326, numObservations: 235
action 0, numVisits=5, meanQ=-1.050000, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11741 episodes
GETTING ACTION FROM:
action -1, numVisits=14952, meanQ=31.881874, numObservations: 243
action 0, numVisits=5, meanQ=-1.050000, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.968373 0.0786537 0.12994 0.571826 0.696692 0.664796 0.421181 0.63576 0.0112868 0.558883 w: 1
Observation: 0 3 0 1 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=198, meanQ=85.998749, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 61693 episodes
GETTING ACTION FROM:
action 4, numVisits=61891, meanQ=80.327762, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.968373 0.0786537 0.12994 0.571826 0.696692 0.664796 0.421181 0.63576 0.0112868 0.558883 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 9
Initial state: 0 0.290486 0.892986 0.447047 0.158928 0.381737 0.960217 0.401469 0.695951 0.594311 0.530981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49303 episodes
GETTING ACTION FROM:
action 0, numVisits=49261, meanQ=54.852902, numObservations: 243
action 4, numVisits=11, meanQ=-4.268182, numObservations: 7
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action -1, numVisits=25, meanQ=-4.926000, numObservations: 24
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.290486 0.892986 0.447047 0.158928 0.381737 0.960217 0.401469 0.695951 0.594311 0.530981 w: 1
Observation: 0 0 3 0 1 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=227, meanQ=74.970442, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 111053 episodes
GETTING ACTION FROM:
action 4, numVisits=111280, meanQ=86.482851, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.290486 0.892986 0.447047 0.158928 0.381737 0.960217 0.401469 0.695951 0.594311 0.530981 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 10
Initial state: 0 0.477905 0.710146 0.294269 0.482647 0.0494291 0.0503291 0.128781 0.524865 0.905628 0.134497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49980 episodes
GETTING ACTION FROM:
action 0, numVisits=49907, meanQ=53.671647, numObservations: 243
action -1, numVisits=61, meanQ=-1.442459, numObservations: 53
action 4, numVisits=6, meanQ=-4.333333, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.477905 0.710146 0.294269 0.482647 0.0494291 0.0503291 0.128781 0.524865 0.905628 0.134497 w: 1
Observation: 0 0 2 0 1 0 1 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=502, meanQ=51.454430, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 105275 episodes
GETTING ACTION FROM:
action 5, numVisits=105777, meanQ=51.035800, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.477905 0.710146 0.294269 0.482647 0.0494291 0.0503291 0.128781 0.524865 0.905628 0.134497 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 11
Initial state: 0 0.951535 0.495014 0.903743 0.904674 0.589913 0.497813 0.249223 0.790581 0.414807 0.649409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49219 episodes
GETTING ACTION FROM:
action 0, numVisits=49184, meanQ=54.663849, numObservations: 243
action 2, numVisits=8, meanQ=-3.500000, numObservations: 5
action 5, numVisits=8, meanQ=-3.500000, numObservations: 5
action -1, numVisits=16, meanQ=-7.106250, numObservations: 15
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.951535 0.495014 0.903743 0.904674 0.589913 0.497813 0.249223 0.790581 0.414807 0.649409 w: 1
Observation: 0 0 1 0 3 0 1 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=208, meanQ=80.968921, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 115919 episodes
GETTING ACTION FROM:
action 5, numVisits=116127, meanQ=85.700819, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.951535 0.495014 0.903743 0.904674 0.589913 0.497813 0.249223 0.790581 0.414807 0.649409 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 12
Initial state: 0 0.690599 0.578533 0.996073 0.940321 0.448767 0.683946 0.110766 0.726957 0.569369 0.317595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88603 episodes
GETTING ACTION FROM:
action 5, numVisits=88580, meanQ=7.832736, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=11, meanQ=-1.909091, numObservations: 7
action 1, numVisits=8, meanQ=-3.500000, numObservations: 6
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.690599 0.578533 0.996073 0.940321 0.448767 0.683946 0.110766 0.726957 0.569369 0.317595 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 13
Initial state: 0 0.0646506 0.508423 0.464023 0.724906 0.717602 0.37013 0.374064 0.994402 0.0119 0.150629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48734 episodes
GETTING ACTION FROM:
action -1, numVisits=48680, meanQ=37.710106, numObservations: 243
action 0, numVisits=30, meanQ=-4.344917, numObservations: 28
action 5, numVisits=20, meanQ=-7.500000, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0646506 0.508423 0.464023 0.724906 0.717602 0.37013 0.374064 0.994402 0.0119 0.150629 w: 1
Observation: 0 1 0 3 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=134, meanQ=7.535224, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 113178 episodes
GETTING ACTION FROM:
action 2, numVisits=113312, meanQ=9.671122, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0646506 0.508423 0.464023 0.724906 0.717602 0.37013 0.374064 0.994402 0.0119 0.150629 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 14
Initial state: 0 0.457949 0.620524 0.74111 0.542163 0.370782 0.360703 0.865962 0.0522046 0.884342 0.946393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86938 episodes
GETTING ACTION FROM:
action 4, numVisits=86899, meanQ=7.535595, numObservations: 9
action 3, numVisits=24, meanQ=2.048437, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 5, numVisits=9, meanQ=-4.016667, numObservations: 7
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.457949 0.620524 0.74111 0.542163 0.370782 0.360703 0.865962 0.0522046 0.884342 0.946393 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 15
Initial state: 0 0.214831 0.0265962 0.956765 0.555249 0.431141 0.715718 0.127236 0.289764 0.776445 0.0524249 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77723 episodes
GETTING ACTION FROM:
action 2, numVisits=77689, meanQ=10.388212, numObservations: 9
action -1, numVisits=11, meanQ=-1.050000, numObservations: 11
action 0, numVisits=11, meanQ=-1.050000, numObservations: 11
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=7, meanQ=-15.285714, numObservations: 6
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.214831 0.0265962 0.956765 0.555249 0.431141 0.715718 0.127236 0.289764 0.776445 0.0524249 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 16
Initial state: 0 0.133658 0.527617 0.410794 0.848603 0.476944 0.70799 0.0538208 0.927179 0.380361 0.252023 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49205 episodes
GETTING ACTION FROM:
action 0, numVisits=49041, meanQ=53.652544, numObservations: 243
action 4, numVisits=124, meanQ=-5.019052, numObservations: 9
action -1, numVisits=22, meanQ=-5.543068, numObservations: 20
action 1, numVisits=13, meanQ=-10.157692, numObservations: 6
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.133658 0.527617 0.410794 0.848603 0.476944 0.70799 0.0538208 0.927179 0.380361 0.252023 w: 1
Observation: 0 0 1 0 1 0 2 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=456, meanQ=86.311479, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 115444 episodes
GETTING ACTION FROM:
action 3, numVisits=115900, meanQ=87.393826, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.133658 0.527617 0.410794 0.848603 0.476944 0.70799 0.0538208 0.927179 0.380361 0.252023 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 17
Initial state: 0 0.67939 0.469879 0.487945 0.935855 0.624032 0.556697 0.38318 0.585245 0.597493 0.0401353 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49885 episodes
GETTING ACTION FROM:
action 0, numVisits=49845, meanQ=55.228239, numObservations: 243
action 1, numVisits=7, meanQ=-2.292857, numObservations: 5
action 5, numVisits=5, meanQ=-2.810000, numObservations: 3
action 2, numVisits=15, meanQ=-3.396667, numObservations: 7
action -1, numVisits=11, meanQ=-9.859091, numObservations: 10
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.67939 0.469879 0.487945 0.935855 0.624032 0.556697 0.38318 0.585245 0.597493 0.0401353 w: 1
Observation: 0 0 2 0 3 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=253, meanQ=43.267575, numObservations: 9
action 1, numVisits=7, meanQ=10.421786, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 90206 episodes
GETTING ACTION FROM:
action 2, numVisits=90459, meanQ=51.955980, numObservations: 9
action 1, numVisits=7, meanQ=10.421786, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.67939 0.469879 0.487945 0.935855 0.624032 0.556697 0.38318 0.585245 0.597493 0.0401353 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 18
Initial state: 0 0.140143 0.862083 0.629887 0.583 0.423094 0.111118 0.435397 0.58127 0.390987 0.779026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 90521 episodes
GETTING ACTION FROM:
action 2, numVisits=90510, meanQ=6.352835, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=4, meanQ=-7.487500, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.140143 0.862083 0.629887 0.583 0.423094 0.111118 0.435397 0.58127 0.390987 0.779026 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 19
Initial state: 0 0.230435 0.560276 0.550584 0.923223 0.502791 0.688342 0.717538 0.0351215 0.604506 0.327832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86755 episodes
GETTING ACTION FROM:
action 1, numVisits=86737, meanQ=9.373394, numObservations: 9
action 2, numVisits=13, meanQ=2.773077, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.230435 0.560276 0.550584 0.923223 0.502791 0.688342 0.717538 0.0351215 0.604506 0.327832 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 20
Initial state: 0 0.186001 0.728255 0.908291 0.33551 0.419871 0.372516 0.446352 0.641149 0.266581 0.0585517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88373 episodes
GETTING ACTION FROM:
action 1, numVisits=88367, meanQ=7.695451, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.186001 0.728255 0.908291 0.33551 0.419871 0.372516 0.446352 0.641149 0.266581 0.0585517 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=3169, meanQ=11.286776, numObservations: 9
action 3, numVisits=21, meanQ=2.140476, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=5, meanQ=-2.810000, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 25462 episodes
GETTING ACTION FROM:
action 4, numVisits=28629, meanQ=12.858222, numObservations: 9
action 3, numVisits=21, meanQ=2.140476, numObservations: 8
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.525000, numObservations: 2
action 2, numVisits=5, meanQ=-2.810000, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 0 0.186001 0.728255 0.908291 0.33551 0.419871 0.372516 0.446352 0.641149 0.266581 0.0585517 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=546, meanQ=35.077474, numObservations: 113
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11691 episodes
GETTING ACTION FROM:
action -1, numVisits=12237, meanQ=15.735092, numObservations: 242
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.186001 0.728255 0.908291 0.33551 0.419871 0.372516 0.446352 0.641149 0.266581 0.0585517 w: 1
Observation: 0 1 0 3 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=3, meanQ=-1.050000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-112.957437, numObservations: 1
Sampled 56028 episodes
GETTING ACTION FROM:
action 4, numVisits=96, meanQ=83.989609, numObservations: 8
action -1, numVisits=55679, meanQ=2.137524, numObservations: 218
action 0, numVisits=260, meanQ=-2.339792, numObservations: 88
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 1, numVisits=1, meanQ=-112.957437, numObservations: 1
action: 4
Next state: 1 0.186001 0.728255 0.908291 0.33551 0.419871 0.372516 0.446352 0.641149 0.266581 0.0585517 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 61.6251
Run # 21
Initial state: 0 0.410645 0.759181 0.221995 0.55174 0.389192 0.603855 0.913925 0.734172 0.084228 0.0105702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48551 episodes
GETTING ACTION FROM:
action -1, numVisits=48513, meanQ=39.470729, numObservations: 243
action 0, numVisits=27, meanQ=-1.510926, numObservations: 25
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.410645 0.759181 0.221995 0.55174 0.389192 0.603855 0.913925 0.734172 0.084228 0.0105702 w: 1
Observation: 0 2 0 1 0 2 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=178, meanQ=43.605183, numObservations: 9
action 5, numVisits=5, meanQ=14.190000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=5, meanQ=-2.810000, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 102972 episodes
GETTING ACTION FROM:
action 3, numVisits=103150, meanQ=29.871924, numObservations: 9
action 5, numVisits=5, meanQ=14.190000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=5, meanQ=-2.810000, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.410645 0.759181 0.221995 0.55174 0.389192 0.603855 0.913925 0.734172 0.084228 0.0105702 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 22
Initial state: 0 0.808126 0.206358 0.0142493 0.0478491 0.427795 0.669933 0.165878 0.819724 0.897735 0.767957 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48928 episodes
GETTING ACTION FROM:
action -1, numVisits=48806, meanQ=39.132626, numObservations: 243
action 3, numVisits=95, meanQ=-1.386605, numObservations: 9
action 1, numVisits=8, meanQ=-3.500000, numObservations: 4
action 0, numVisits=14, meanQ=-7.971429, numObservations: 13
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.808126 0.206358 0.0142493 0.0478491 0.427795 0.669933 0.165878 0.819724 0.897735 0.767957 w: 1
Observation: 0 3 0 1 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=257, meanQ=79.741573, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 105775 episodes
GETTING ACTION FROM:
action 3, numVisits=106032, meanQ=78.446695, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.808126 0.206358 0.0142493 0.0478491 0.427795 0.669933 0.165878 0.819724 0.897735 0.767957 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 23
Initial state: 0 0.41627 0.207105 0.818436 0.252014 0.491671 0.674774 0.18277 0.417888 0.120471 0.243154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50175 episodes
GETTING ACTION FROM:
action 0, numVisits=50109, meanQ=55.805401, numObservations: 243
action -1, numVisits=54, meanQ=-2.916574, numObservations: 51
action 2, numVisits=8, meanQ=-4.693438, numObservations: 6
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.41627 0.207105 0.818436 0.252014 0.491671 0.674774 0.18277 0.417888 0.120471 0.243154 w: 1
Observation: 0 0 1 0 1 0 2 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=462, meanQ=47.020028, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 101499 episodes
GETTING ACTION FROM:
action 3, numVisits=101961, meanQ=55.113462, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.41627 0.207105 0.818436 0.252014 0.491671 0.674774 0.18277 0.417888 0.120471 0.243154 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 24
Initial state: 0 0.198676 0.685376 0.795893 0.643031 0.0990372 0.278723 0.037475 0.712628 0.380386 0.654976 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49863 episodes
GETTING ACTION FROM:
action 0, numVisits=49831, meanQ=54.470978, numObservations: 243
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action -1, numVisits=23, meanQ=-5.263043, numObservations: 22
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.198676 0.685376 0.795893 0.643031 0.0990372 0.278723 0.037475 0.712628 0.380386 0.654976 w: 1
Observation: 0 0 2 0 2 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=54, meanQ=59.705937, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 109839 episodes
GETTING ACTION FROM:
action 3, numVisits=109893, meanQ=53.047174, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.198676 0.685376 0.795893 0.643031 0.0990372 0.278723 0.037475 0.712628 0.380386 0.654976 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=674, meanQ=41.329270, numObservations: 9
action 4, numVisits=4, meanQ=20.250000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 90373 episodes
GETTING ACTION FROM:
action 1, numVisits=91035, meanQ=24.218164, numObservations: 9
action 4, numVisits=16, meanQ=16.812500, numObservations: 7
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.198676 0.685376 0.795893 0.643031 0.0990372 0.278723 0.037475 0.712628 0.380386 0.654976 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=692, meanQ=81.441241, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 100735 episodes
GETTING ACTION FROM:
action 5, numVisits=101427, meanQ=59.594975, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.198676 0.685376 0.795893 0.643031 0.0990372 0.278723 0.037475 0.712628 0.380386 0.654976 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 62.5026
Run # 25
Initial state: 0 0.0990997 0.279083 0.486887 0.735066 0.858496 0.694561 0.91098 0.148748 0.488447 0.694126 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47722 episodes
GETTING ACTION FROM:
action -1, numVisits=47678, meanQ=37.870247, numObservations: 243
action 0, numVisits=39, meanQ=-3.953590, numObservations: 34
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0990997 0.279083 0.486887 0.735066 0.858496 0.694561 0.91098 0.148748 0.488447 0.694126 w: 1
Observation: 0 1 0 2 0 3 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=172, meanQ=39.194629, numObservations: 53
action 0, numVisits=9, meanQ=-1.050000, numObservations: 9
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 51112 episodes
GETTING ACTION FROM:
action -1, numVisits=51284, meanQ=73.042181, numObservations: 227
action 0, numVisits=9, meanQ=-1.050000, numObservations: 9
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0990997 0.279083 0.486887 0.735066 0.858496 0.694561 0.91098 0.148748 0.488447 0.694126 w: 1
Observation: 0 3 0 2 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=80, meanQ=37.384031, numObservations: 30
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 49387 episodes
GETTING ACTION FROM:
action -1, numVisits=49467, meanQ=72.092332, numObservations: 223
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0990997 0.279083 0.486887 0.735066 0.858496 0.694561 0.91098 0.148748 0.488447 0.694126 w: 1
Observation: 0 1 0 2 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=3615, meanQ=64.295576, numObservations: 115
action 3, numVisits=8, meanQ=-1.000000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 57144 episodes
GETTING ACTION FROM:
action -1, numVisits=60759, meanQ=69.295616, numObservations: 193
action 3, numVisits=8, meanQ=-1.000000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0990997 0.279083 0.486887 0.735066 0.858496 0.694561 0.91098 0.148748 0.488447 0.694126 w: 1
Observation: 0 1 0 2 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=4354, meanQ=89.504245, numObservations: 9
action 4, numVisits=5, meanQ=59.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 119805 episodes
GETTING ACTION FROM:
action 2, numVisits=124159, meanQ=90.558332, numObservations: 9
action 4, numVisits=5, meanQ=59.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0990997 0.279083 0.486887 0.735066 0.858496 0.694561 0.91098 0.148748 0.488447 0.694126 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 73.2164
Run # 26
Initial state: 0 0.500935 0.55867 0.814051 0.312012 0.939296 0.620026 0.828196 0.274634 0.789985 0.67412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79392 episodes
GETTING ACTION FROM:
action 1, numVisits=79357, meanQ=10.391856, numObservations: 9
action 4, numVisits=26, meanQ=7.915577, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=5, meanQ=-7.810000, numObservations: 4
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.500935 0.55867 0.814051 0.312012 0.939296 0.620026 0.828196 0.274634 0.789985 0.67412 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=1198, meanQ=48.721246, numObservations: 189
action 4, numVisits=326, meanQ=-0.898856, numObservations: 9
action -1, numVisits=14, meanQ=-1.938929, numObservations: 12
action 3, numVisits=21, meanQ=-3.154762, numObservations: 9
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37860 episodes
GETTING ACTION FROM:
action 0, numVisits=39058, meanQ=7.488845, numObservations: 243
action 4, numVisits=326, meanQ=-0.898856, numObservations: 9
action -1, numVisits=14, meanQ=-1.938929, numObservations: 12
action 3, numVisits=21, meanQ=-3.154762, numObservations: 9
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.500935 0.55867 0.814051 0.312012 0.939296 0.620026 0.828196 0.274634 0.789985 0.67412 w: 1
Observation: 0 0 2 0 1 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=24, meanQ=51.881771, numObservations: 5
action 0, numVisits=144, meanQ=51.077286, numObservations: 35
action -1, numVisits=16, meanQ=-7.349687, numObservations: 13
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=2, meanQ=-55.525000, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 45036 episodes
GETTING ACTION FROM:
action 1, numVisits=24, meanQ=51.881771, numObservations: 5
action 0, numVisits=45180, meanQ=11.873882, numObservations: 194
action -1, numVisits=16, meanQ=-7.349687, numObservations: 13
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=2, meanQ=-55.525000, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.500935 0.55867 0.814051 0.312012 0.939296 0.620026 0.828196 0.274634 0.789985 0.67412 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 27
Initial state: 0 0.445182 0.118622 0.511367 0.634141 0.0526646 0.277586 0.231114 0.684575 0.950938 0.138546 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86245 episodes
GETTING ACTION FROM:
action 4, numVisits=86239, meanQ=7.644186, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.445182 0.118622 0.511367 0.634141 0.0526646 0.277586 0.231114 0.684575 0.950938 0.138546 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3129, meanQ=12.047115, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32325 episodes
GETTING ACTION FROM:
action 2, numVisits=35454, meanQ=13.461618, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.445182 0.118622 0.511367 0.634141 0.0526646 0.277586 0.231114 0.684575 0.950938 0.138546 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 28
Initial state: 0 0.799436 0.267981 0.924423 0.50357 0.321778 0.890091 0.627895 0.218461 0.500192 0.706426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86729 episodes
GETTING ACTION FROM:
action 3, numVisits=86723, meanQ=7.724508, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.799436 0.267981 0.924423 0.50357 0.321778 0.890091 0.627895 0.218461 0.500192 0.706426 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=4309, meanQ=15.767937, numObservations: 9
action 4, numVisits=12, meanQ=10.817083, numObservations: 7
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 27279 episodes
GETTING ACTION FROM:
action 5, numVisits=31588, meanQ=22.726835, numObservations: 9
action 4, numVisits=12, meanQ=10.817083, numObservations: 7
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.799436 0.267981 0.924423 0.50357 0.321778 0.890091 0.627895 0.218461 0.500192 0.706426 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 29
Initial state: 0 0.673684 0.443345 0.217727 0.814811 0.879565 0.17035 0.524282 0.581656 0.744003 0.0506579 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49560 episodes
GETTING ACTION FROM:
action 0, numVisits=49463, meanQ=52.964197, numObservations: 243
action -1, numVisits=75, meanQ=-7.891267, numObservations: 64
action 4, numVisits=18, meanQ=-9.122222, numObservations: 7
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.673684 0.443345 0.217727 0.814811 0.879565 0.17035 0.524282 0.581656 0.744003 0.0506579 w: 1
Observation: 0 0 1 0 2 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=493, meanQ=36.914417, numObservations: 62
action -1, numVisits=6, meanQ=-1.050000, numObservations: 6
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 48902 episodes
GETTING ACTION FROM:
action 0, numVisits=49395, meanQ=53.076008, numObservations: 204
action -1, numVisits=6, meanQ=-1.050000, numObservations: 6
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.673684 0.443345 0.217727 0.814811 0.879565 0.17035 0.524282 0.581656 0.744003 0.0506579 w: 1
Observation: 0 0 1 0 2 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=16662, meanQ=52.712724, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 93290 episodes
GETTING ACTION FROM:
action 4, numVisits=109952, meanQ=54.215851, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.673684 0.443345 0.217727 0.814811 0.879565 0.17035 0.524282 0.581656 0.744003 0.0506579 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=4496, meanQ=68.692719, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 117326 episodes
GETTING ACTION FROM:
action 4, numVisits=4523, meanQ=68.780311, numObservations: 9
action 2, numVisits=117302, meanQ=44.689792, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.673684 0.443345 0.217727 0.814811 0.879565 0.17035 0.524282 0.581656 0.744003 0.0506579 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 71.0526
Run # 30
Initial state: 0 0.654374 0.852094 0.901669 0.532689 0.371735 0.719854 0.583752 0.99161 0.927844 0.205256 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 91506 episodes
GETTING ACTION FROM:
action 2, numVisits=91497, meanQ=5.718963, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.654374 0.852094 0.901669 0.532689 0.371735 0.719854 0.583752 0.99161 0.927844 0.205256 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 31
Initial state: 0 0.278666 0.60525 0.647437 0.234282 0.861135 0.851168 0.146707 0.26449 0.405621 0.703823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 46836 episodes
GETTING ACTION FROM:
action -1, numVisits=46770, meanQ=37.642636, numObservations: 243
action 0, numVisits=33, meanQ=-4.160530, numObservations: 29
action 4, numVisits=21, meanQ=-5.030595, numObservations: 8
action 5, numVisits=9, meanQ=-5.394167, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.278666 0.60525 0.647437 0.234282 0.861135 0.851168 0.146707 0.26449 0.405621 0.703823 w: 1
Observation: 0 1 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=302, meanQ=74.273717, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 114850 episodes
GETTING ACTION FROM:
action 5, numVisits=115152, meanQ=84.329855, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.278666 0.60525 0.647437 0.234282 0.861135 0.851168 0.146707 0.26449 0.405621 0.703823 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 32
Initial state: 0 0.943252 0.351493 0.384895 0.60658 0.796347 0.480652 0.569897 0.443718 0.0617926 0.809108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 85883 episodes
GETTING ACTION FROM:
action 2, numVisits=85858, meanQ=8.706128, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 1, numVisits=14, meanQ=-3.931786, numObservations: 5
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.943252 0.351493 0.384895 0.60658 0.796347 0.480652 0.569897 0.443718 0.0617926 0.809108 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 33
Initial state: 0 0.394102 0.605459 0.592645 0.705886 0.695336 0.538667 0.458266 0.737654 0.692115 0.980404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 87393 episodes
GETTING ACTION FROM:
action 2, numVisits=87372, meanQ=7.261000, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=16, meanQ=-2.250000, numObservations: 7
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.394102 0.605459 0.592645 0.705886 0.695336 0.538667 0.458266 0.737654 0.692115 0.980404 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 34
Initial state: 0 0.539249 0.432809 0.530318 0.62896 0.197768 0.815345 0.727258 0.585551 0.518634 0.301837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 88331 episodes
GETTING ACTION FROM:
action 5, numVisits=88311, meanQ=6.460612, numObservations: 9
action 1, numVisits=15, meanQ=0.030167, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.539249 0.432809 0.530318 0.62896 0.197768 0.815345 0.727258 0.585551 0.518634 0.301837 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 35
Initial state: 0 0.860742 0.690738 0.150774 0.424469 0.255279 0.510606 0.369419 0.577365 0.13284 0.39145 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84151 episodes
GETTING ACTION FROM:
action 4, numVisits=84010, meanQ=8.360871, numObservations: 9
action 0, numVisits=77, meanQ=-2.744578, numObservations: 63
action 5, numVisits=28, meanQ=-2.781875, numObservations: 8
action -1, numVisits=30, meanQ=-4.280000, numObservations: 29
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=4, meanQ=-28.262500, numObservations: 4
action: 4
Next state: 1 0.860742 0.690738 0.150774 0.424469 0.255279 0.510606 0.369419 0.577365 0.13284 0.39145 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 36
Initial state: 0 0.44833 0.585263 0.244722 0.622826 0.192445 0.0160809 0.546025 0.894938 0.607163 0.899367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47903 episodes
GETTING ACTION FROM:
action -1, numVisits=47859, meanQ=37.520970, numObservations: 243
action 0, numVisits=20, meanQ=-5.895000, numObservations: 19
action 1, numVisits=18, meanQ=-8.222222, numObservations: 8
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.44833 0.585263 0.244722 0.622826 0.192445 0.0160809 0.546025 0.894938 0.607163 0.899367 w: 1
Observation: 0 3 0 1 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=103, meanQ=8.063617, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 49478 episodes
GETTING ACTION FROM:
action -1, numVisits=49442, meanQ=62.644164, numObservations: 228
action 4, numVisits=130, meanQ=-0.245731, numObservations: 9
action 0, numVisits=11, meanQ=-1.050000, numObservations: 11
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.44833 0.585263 0.244722 0.622826 0.192445 0.0160809 0.546025 0.894938 0.607163 0.899367 w: 1
Observation: 0 2 0 1 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=4029, meanQ=92.875098, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 116795 episodes
GETTING ACTION FROM:
action 1, numVisits=120824, meanQ=93.317463, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.44833 0.585263 0.244722 0.622826 0.192445 0.0160809 0.546025 0.894938 0.607163 0.899367 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 37
Initial state: 0 0.708552 0.468861 0.46743 0.128218 0.532515 0.642926 0.968186 0.621272 0.308783 0.0186556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49186 episodes
GETTING ACTION FROM:
action 0, numVisits=49148, meanQ=53.941428, numObservations: 243
action -1, numVisits=33, meanQ=-7.040758, numObservations: 29
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.708552 0.468861 0.46743 0.128218 0.532515 0.642926 0.968186 0.621272 0.308783 0.0186556 w: 1
Observation: 0 0 1 0 1 0 2 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=482, meanQ=83.328516, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 111981 episodes
GETTING ACTION FROM:
action 3, numVisits=112463, meanQ=83.903887, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.708552 0.468861 0.46743 0.128218 0.532515 0.642926 0.968186 0.621272 0.308783 0.0186556 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=876, meanQ=44.144715, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 69414 episodes
GETTING ACTION FROM:
action 4, numVisits=70290, meanQ=51.832203, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.708552 0.468861 0.46743 0.128218 0.532515 0.642926 0.968186 0.621272 0.308783 0.0186556 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 38
Initial state: 0 0.958266 0.0481677 0.361117 0.613432 0.181306 0.786422 0.805785 0.454665 0.947055 0.738154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 84328 episodes
GETTING ACTION FROM:
action 2, numVisits=84313, meanQ=8.645281, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 5, numVisits=7, meanQ=-5.014286, numObservations: 5
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.958266 0.0481677 0.361117 0.613432 0.181306 0.786422 0.805785 0.454665 0.947055 0.738154 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 39
Initial state: 0 0.970685 0.709735 0.482714 0.0448814 0.410702 0.693837 0.05245 0.300257 0.137211 0.709351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 86964 episodes
GETTING ACTION FROM:
action 4, numVisits=86945, meanQ=7.335748, numObservations: 9
action 2, numVisits=14, meanQ=-0.071071, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.970685 0.709735 0.482714 0.0448814 0.410702 0.693837 0.05245 0.300257 0.137211 0.709351 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11158, meanQ=15.809713, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=8, meanQ=-3.262500, numObservations: 5
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18676 episodes
GETTING ACTION FROM:
action 2, numVisits=29830, meanQ=8.429283, numObservations: 9
action -1, numVisits=3, meanQ=-1.366667, numObservations: 3
action 0, numVisits=3, meanQ=-1.366667, numObservations: 3
action 1, numVisits=8, meanQ=-3.262500, numObservations: 5
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.970685 0.709735 0.482714 0.0448814 0.410702 0.693837 0.05245 0.300257 0.137211 0.709351 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 40
Initial state: 0 0.932232 0.0783181 0.820656 0.872796 0.775044 0.24946 0.62031 0.427356 0.374406 0.681095 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 77703 episodes
GETTING ACTION FROM:
action 1, numVisits=77691, meanQ=12.940209, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.932232 0.0783181 0.820656 0.872796 0.775044 0.24946 0.62031 0.427356 0.374406 0.681095 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 41
Initial state: 0 0.705201 0.522266 0.956917 0.793384 0.449057 0.707954 0.573848 0.235021 0.887475 0.116202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 80097 episodes
GETTING ACTION FROM:
action 2, numVisits=80042, meanQ=11.734578, numObservations: 9
action -1, numVisits=8, meanQ=-1.050000, numObservations: 8
action 0, numVisits=8, meanQ=-1.050000, numObservations: 8
action 4, numVisits=18, meanQ=-2.441667, numObservations: 7
action 3, numVisits=19, meanQ=-4.036579, numObservations: 7
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.705201 0.522266 0.956917 0.793384 0.449057 0.707954 0.573848 0.235021 0.887475 0.116202 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 42
Initial state: 0 0.588661 0.312862 0.948445 0.952709 0.454186 0.636288 0.110795 0.930995 0.909018 0.360245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 92257 episodes
GETTING ACTION FROM:
action 1, numVisits=92199, meanQ=6.679858, numObservations: 9
action 5, numVisits=48, meanQ=-0.498958, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.588661 0.312862 0.948445 0.952709 0.454186 0.636288 0.110795 0.930995 0.909018 0.360245 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 43
Initial state: 0 0.197033 0.194007 0.0221528 0.577091 0.123352 0.42841 0.482441 0.612085 0.777484 0.812759 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 78395 episodes
GETTING ACTION FROM:
action 2, numVisits=78388, meanQ=12.553713, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.197033 0.194007 0.0221528 0.577091 0.123352 0.42841 0.482441 0.612085 0.777484 0.812759 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=9847, meanQ=59.266915, numObservations: 238
action 4, numVisits=6, meanQ=-4.341250, numObservations: 3
action -1, numVisits=21, meanQ=-5.757024, numObservations: 19
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 9916 episodes
GETTING ACTION FROM:
action 0, numVisits=19763, meanQ=54.841433, numObservations: 243
action 4, numVisits=6, meanQ=-4.341250, numObservations: 3
action -1, numVisits=21, meanQ=-5.757024, numObservations: 19
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.197033 0.194007 0.0221528 0.577091 0.123352 0.42841 0.482441 0.612085 0.777484 0.812759 w: 1
Observation: 0 0 1 0 2 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=5, meanQ=37.190000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=4, meanQ=-6.032946, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33509 episodes
GETTING ACTION FROM:
action 5, numVisits=33514, meanQ=65.081169, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=4, meanQ=-6.032946, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.197033 0.194007 0.0221528 0.577091 0.123352 0.42841 0.482441 0.612085 0.777484 0.812759 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 44
Initial state: 0 0.380459 0.718535 0.507681 0.520548 0.470527 0.504675 0.647275 0.446308 0.340577 0.630445 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48096 episodes
GETTING ACTION FROM:
action -1, numVisits=48052, meanQ=35.896006, numObservations: 243
action 0, numVisits=17, meanQ=-6.750000, numObservations: 16
action 2, numVisits=13, meanQ=-10.230769, numObservations: 5
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=9, meanQ=-12.111111, numObservations: 7
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.380459 0.718535 0.507681 0.520548 0.470527 0.504675 0.647275 0.446308 0.340577 0.630445 w: 1
Observation: 0 2 0 2 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=161, meanQ=37.845792, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 101636 episodes
GETTING ACTION FROM:
action 2, numVisits=101797, meanQ=31.155267, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.380459 0.718535 0.507681 0.520548 0.470527 0.504675 0.647275 0.446308 0.340577 0.630445 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 45
Initial state: 0 0.583644 0.587749 0.430953 0.571716 0.0554707 0.568954 0.00118143 0.0484492 0.0843035 0.22747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49847 episodes
GETTING ACTION FROM:
action 0, numVisits=49806, meanQ=56.007506, numObservations: 243
action -1, numVisits=34, meanQ=-4.208750, numObservations: 32
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.583644 0.587749 0.430953 0.571716 0.0554707 0.568954 0.00118143 0.0484492 0.0843035 0.22747 w: 1
Observation: 0 0 2 0 2 0 3 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=242, meanQ=50.041321, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 105132 episodes
GETTING ACTION FROM:
action 2, numVisits=105374, meanQ=53.310345, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.583644 0.587749 0.430953 0.571716 0.0554707 0.568954 0.00118143 0.0484492 0.0843035 0.22747 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 46
Initial state: 0 0.475127 0.568227 0.196331 0.249965 0.53852 0.765868 0.663378 0.747949 0.895699 0.971921 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48287 episodes
GETTING ACTION FROM:
action -1, numVisits=48260, meanQ=37.437538, numObservations: 243
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 4, numVisits=9, meanQ=-4.333333, numObservations: 6
action 0, numVisits=10, meanQ=-10.740000, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.475127 0.568227 0.196331 0.249965 0.53852 0.765868 0.663378 0.747949 0.895699 0.971921 w: 1
Observation: 0 2 0 1 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=217, meanQ=33.206673, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 96048 episodes
GETTING ACTION FROM:
action 1, numVisits=96265, meanQ=25.154152, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.475127 0.568227 0.196331 0.249965 0.53852 0.765868 0.663378 0.747949 0.895699 0.971921 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 47
Initial state: 0 0.205989 0.165806 0.27941 0.815902 0.449937 0.957461 0.371875 0.650541 0.655861 0.488521 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48766 episodes
GETTING ACTION FROM:
action -1, numVisits=48707, meanQ=39.453040, numObservations: 243
action 0, numVisits=54, meanQ=-1.651667, numObservations: 46
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.205989 0.165806 0.27941 0.815902 0.449937 0.957461 0.371875 0.650541 0.655861 0.488521 w: 1
Observation: 0 2 0 1 0 2 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=84, meanQ=15.773699, numObservations: 36
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 0, numVisits=32, meanQ=-4.467031, numObservations: 29
action 2, numVisits=5, meanQ=-6.819500, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 44806 episodes
GETTING ACTION FROM:
action -1, numVisits=44890, meanQ=35.856062, numObservations: 241
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 0, numVisits=32, meanQ=-4.467031, numObservations: 29
action 2, numVisits=5, meanQ=-6.819500, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.205989 0.165806 0.27941 0.815902 0.449937 0.957461 0.371875 0.650541 0.655861 0.488521 w: 1
Observation: 0 1 0 1 0 2 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=2165, meanQ=36.847135, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 116564 episodes
GETTING ACTION FROM:
action 4, numVisits=118729, meanQ=44.138069, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.205989 0.165806 0.27941 0.815902 0.449937 0.957461 0.371875 0.650541 0.655861 0.488521 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 48
Initial state: 0 0.135886 0.53598 0.153788 0.600099 0.063489 0.0727897 0.759161 0.746629 0.397857 0.65964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48233 episodes
GETTING ACTION FROM:
action -1, numVisits=48205, meanQ=39.232728, numObservations: 243
action 0, numVisits=20, meanQ=-5.895000, numObservations: 19
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=4, meanQ=-28.500000, numObservations: 4
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.135886 0.53598 0.153788 0.600099 0.063489 0.0727897 0.759161 0.746629 0.397857 0.65964 w: 1
Observation: 0 1 0 1 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=105, meanQ=31.710358, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 66300 episodes
GETTING ACTION FROM:
action 3, numVisits=66405, meanQ=43.901999, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.135886 0.53598 0.153788 0.600099 0.063489 0.0727897 0.759161 0.746629 0.397857 0.65964 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=14410, meanQ=61.302150, numObservations: 207
action 4, numVisits=12, meanQ=-3.004167, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=6, meanQ=-17.200000, numObservations: 5
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 10805 episodes
GETTING ACTION FROM:
action -1, numVisits=25215, meanQ=59.575053, numObservations: 221
action 4, numVisits=12, meanQ=-3.004167, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=6, meanQ=-17.200000, numObservations: 5
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.135886 0.53598 0.153788 0.600099 0.063489 0.0727897 0.759161 0.746629 0.397857 0.65964 w: 1
Observation: 0 1 0 1 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=1993, meanQ=74.285751, numObservations: 83
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 27666 episodes
GETTING ACTION FROM:
action -1, numVisits=29659, meanQ=75.500512, numObservations: 175
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.135886 0.53598 0.153788 0.600099 0.063489 0.0727897 0.759161 0.746629 0.397857 0.65964 w: 1
Observation: 0 1 0 1 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=12476, meanQ=96.626241, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 109557 episodes
GETTING ACTION FROM:
action 5, numVisits=122033, meanQ=95.701511, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.135886 0.53598 0.153788 0.600099 0.063489 0.0727897 0.759161 0.746629 0.397857 0.65964 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 64.6664
Run # 49
Initial state: 0 0.521568 0.569323 0.991481 0.14246 0.267036 0.492864 0.957783 0.243713 0.540349 0.944003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 50232 episodes
GETTING ACTION FROM:
action 0, numVisits=50176, meanQ=55.664991, numObservations: 243
action -1, numVisits=40, meanQ=-3.783625, numObservations: 37
action 4, numVisits=9, meanQ=-4.333333, numObservations: 8
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=4, meanQ=-28.500000, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.521568 0.569323 0.991481 0.14246 0.267036 0.492864 0.957783 0.243713 0.540349 0.944003 w: 1
Observation: 0 0 2 0 1 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=456, meanQ=86.029705, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 114792 episodes
GETTING ACTION FROM:
action 1, numVisits=115248, meanQ=88.088089, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.521568 0.569323 0.991481 0.14246 0.267036 0.492864 0.957783 0.243713 0.540349 0.944003 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 50
Initial state: 0 0.263374 0.848365 0.398673 0.694127 0.512933 0.304086 0.833233 0.0735543 0.548908 0.0598323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 79819 episodes
GETTING ACTION FROM:
action 3, numVisits=79770, meanQ=9.257389, numObservations: 9
action 0, numVisits=28, meanQ=-4.955179, numObservations: 25
action -1, numVisits=15, meanQ=-7.510000, numObservations: 14
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.263374 0.848365 0.398673 0.694127 0.512933 0.304086 0.833233 0.0735543 0.548908 0.0598323 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
[32m ProblemEnvironment.hpp 351: Done.[39m
