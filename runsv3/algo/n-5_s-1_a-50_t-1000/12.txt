Run # 1
Initial state: 0 0.462496 0.804633 0.425007 0.973126 0.0398324 0.94425 0.546167 0.508504 0.577901 0.678572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16571 episodes
GETTING ACTION FROM:
action 0, numVisits=16555, meanQ=59.594768, numObservations: 243
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=9, meanQ=-11.816667, numObservations: 8
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.462496 0.804633 0.425007 0.973126 0.0398324 0.94425 0.546167 0.508504 0.577901 0.678572 w: 1
Observation: 0 0 3 0 3 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=18, meanQ=74.550278, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32452 episodes
GETTING ACTION FROM:
action 5, numVisits=32470, meanQ=67.855691, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.462496 0.804633 0.425007 0.973126 0.0398324 0.94425 0.546167 0.508504 0.577901 0.678572 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 2
Initial state: 0 0.638004 0.0424922 0.19725 0.0460242 0.474095 0.161677 0.798312 0.925595 0.554831 0.74247 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27287 episodes
GETTING ACTION FROM:
action 4, numVisits=27272, meanQ=4.984228, numObservations: 9
action 0, numVisits=7, meanQ=-1.050000, numObservations: 7
action -1, numVisits=4, meanQ=-1.536875, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.638004 0.0424922 0.19725 0.0460242 0.474095 0.161677 0.798312 0.925595 0.554831 0.74247 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 3
Initial state: 0 0.14717 0.233374 0.516912 0.208899 0.801818 0.0359095 0.581493 0.651519 0.274507 0.0640061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17005 episodes
GETTING ACTION FROM:
action 0, numVisits=16968, meanQ=54.979914, numObservations: 243
action -1, numVisits=32, meanQ=-1.378047, numObservations: 31
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.14717 0.233374 0.516912 0.208899 0.801818 0.0359095 0.581493 0.651519 0.274507 0.0640061 w: 1
Observation: 0 0 1 0 1 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=466, meanQ=59.907452, numObservations: 48
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=9, meanQ=-11.816667, numObservations: 8
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18124 episodes
GETTING ACTION FROM:
action 0, numVisits=18590, meanQ=76.394324, numObservations: 136
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=9, meanQ=-11.816667, numObservations: 8
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.14717 0.233374 0.516912 0.208899 0.801818 0.0359095 0.581493 0.651519 0.274507 0.0640061 w: 1
Observation: 0 0 1 0 1 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=9619, meanQ=96.326098, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37246 episodes
GETTING ACTION FROM:
action 4, numVisits=46865, meanQ=96.746875, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.14717 0.233374 0.516912 0.208899 0.801818 0.0359095 0.581493 0.651519 0.274507 0.0640061 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 4
Initial state: 0 0.257327 0.0175489 0.447515 0.73814 0.219001 0.512292 0.941829 0.975532 0.134699 0.0457098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17343 episodes
GETTING ACTION FROM:
action -1, numVisits=17305, meanQ=38.009090, numObservations: 243
action 0, numVisits=24, meanQ=-5.606042, numObservations: 21
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=7, meanQ=-18.007143, numObservations: 5
action 1, numVisits=4, meanQ=-28.500000, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.257327 0.0175489 0.447515 0.73814 0.219001 0.512292 0.941829 0.975532 0.134699 0.0457098 w: 1
Observation: 0 1 0 1 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=99, meanQ=33.502652, numObservations: 36
action 1, numVisits=3, meanQ=-6.000000, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=9, meanQ=-12.033056, numObservations: 7
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17425 episodes
GETTING ACTION FROM:
action -1, numVisits=17524, meanQ=67.791799, numObservations: 197
action 1, numVisits=3, meanQ=-6.000000, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=9, meanQ=-12.033056, numObservations: 7
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.257327 0.0175489 0.447515 0.73814 0.219001 0.512292 0.941829 0.975532 0.134699 0.0457098 w: 1
Observation: 0 1 0 2 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=68, meanQ=5.711765, numObservations: 42
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=5, meanQ=-21.000000, numObservations: 3
action -1, numVisits=3, meanQ=-33.350000, numObservations: 2
Sampled 17315 episodes
GETTING ACTION FROM:
action 0, numVisits=17383, meanQ=76.128188, numObservations: 227
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=5, meanQ=-21.000000, numObservations: 3
action -1, numVisits=3, meanQ=-33.350000, numObservations: 2
action: 0
Next state: 0 0.257327 0.0175489 0.447515 0.73814 0.219001 0.512292 0.941829 0.975532 0.134699 0.0457098 w: 1
Observation: 0 0 1 0 3 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=19, meanQ=18.623684, numObservations: 8
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34792 episodes
GETTING ACTION FROM:
action 2, numVisits=34811, meanQ=84.822447, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.257327 0.0175489 0.447515 0.73814 0.219001 0.512292 0.941829 0.975532 0.134699 0.0457098 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 79.1751
Run # 5
Initial state: 0 0.693326 0.300991 0.459875 0.234096 0.270121 0.65347 0.441107 0.720018 0.238744 0.0360874 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16330 episodes
GETTING ACTION FROM:
action 0, numVisits=16320, meanQ=59.723459, numObservations: 243
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=5, meanQ=-20.430000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.693326 0.300991 0.459875 0.234096 0.270121 0.65347 0.441107 0.720018 0.238744 0.0360874 w: 1
Observation: 0 0 1 0 1 0 1 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=94, meanQ=69.349145, numObservations: 9
action 2, numVisits=7, meanQ=38.993214, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 29043 episodes
GETTING ACTION FROM:
action 4, numVisits=29137, meanQ=64.012417, numObservations: 9
action 2, numVisits=7, meanQ=38.993214, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.693326 0.300991 0.459875 0.234096 0.270121 0.65347 0.441107 0.720018 0.238744 0.0360874 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 6
Initial state: 0 0.0817199 0.0398436 0.479098 0.720174 0.201832 0.469879 0.520259 0.586454 0.70479 0.710422 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17043 episodes
GETTING ACTION FROM:
action 0, numVisits=17024, meanQ=54.568089, numObservations: 243
action -1, numVisits=9, meanQ=-11.816667, numObservations: 8
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=3, meanQ=-40.683333, numObservations: 2
action 2, numVisits=2, meanQ=-56.000000, numObservations: 2
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0817199 0.0398436 0.479098 0.720174 0.201832 0.469879 0.520259 0.586454 0.70479 0.710422 w: 1
Observation: 0 0 1 0 2 0 1 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=156, meanQ=53.909391, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 30346 episodes
GETTING ACTION FROM:
action 5, numVisits=30502, meanQ=47.597675, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.0817199 0.0398436 0.479098 0.720174 0.201832 0.469879 0.520259 0.586454 0.70479 0.710422 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 7
Initial state: 0 0.54345 0.642929 0.840959 0.402304 0.713245 0.176303 0.28254 0.992872 0.909037 0.42398 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25110 episodes
GETTING ACTION FROM:
action 5, numVisits=25054, meanQ=10.552316, numObservations: 9
action -1, numVisits=33, meanQ=-3.986364, numObservations: 32
action 1, numVisits=7, meanQ=-7.600000, numObservations: 6
action 0, numVisits=13, meanQ=-8.503846, numObservations: 12
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.54345 0.642929 0.840959 0.402304 0.713245 0.176303 0.28254 0.992872 0.909037 0.42398 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 8
Initial state: 0 0.782309 0.525369 0.227147 0.460263 0.54026 0.657454 0.277359 0.176418 0.184843 0.774075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26875 episodes
GETTING ACTION FROM:
action 1, numVisits=26869, meanQ=6.798926, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.782309 0.525369 0.227147 0.460263 0.54026 0.657454 0.277359 0.176418 0.184843 0.774075 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 9
Initial state: 0 0.409625 0.394977 0.0746764 0.394703 0.651075 0.562446 0.452167 0.705054 0.747961 0.44848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17428 episodes
GETTING ACTION FROM:
action -1, numVisits=17412, meanQ=40.786147, numObservations: 243
action 0, numVisits=11, meanQ=-10.813409, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.409625 0.394977 0.0746764 0.394703 0.651075 0.562446 0.452167 0.705054 0.747961 0.44848 w: 1
Observation: 0 1 0 3 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=109, meanQ=77.800046, numObservations: 8
action 1, numVisits=2, meanQ=44.475000, numObservations: 2
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34486 episodes
GETTING ACTION FROM:
action 4, numVisits=34595, meanQ=84.239846, numObservations: 9
action 1, numVisits=2, meanQ=44.475000, numObservations: 2
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.409625 0.394977 0.0746764 0.394703 0.651075 0.562446 0.452167 0.705054 0.747961 0.44848 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 10
Initial state: 0 0.335681 0.144851 0.227569 0.273899 0.392965 0.0121739 0.441533 0.72838 0.892217 0.464822 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17023 episodes
GETTING ACTION FROM:
action -1, numVisits=17005, meanQ=39.752136, numObservations: 243
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 0, numVisits=11, meanQ=-9.859091, numObservations: 10
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.335681 0.144851 0.227569 0.273899 0.392965 0.0121739 0.441533 0.72838 0.892217 0.464822 w: 1
Observation: 0 1 0 3 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=95, meanQ=78.019632, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35753 episodes
GETTING ACTION FROM:
action 4, numVisits=35848, meanQ=86.210641, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.335681 0.144851 0.227569 0.273899 0.392965 0.0121739 0.441533 0.72838 0.892217 0.464822 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 11
Initial state: 0 0.149671 0.233719 0.351728 0.990463 0.441248 0.663281 0.673548 0.870544 0.974245 0.420159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16337 episodes
GETTING ACTION FROM:
action -1, numVisits=16328, meanQ=38.959673, numObservations: 243
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=4, meanQ=-25.275000, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.149671 0.233719 0.351728 0.990463 0.441248 0.663281 0.673548 0.870544 0.974245 0.420159 w: 1
Observation: 0 1 0 1 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=89, meanQ=71.534916, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35959 episodes
GETTING ACTION FROM:
action 3, numVisits=36048, meanQ=82.828575, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.149671 0.233719 0.351728 0.990463 0.441248 0.663281 0.673548 0.870544 0.974245 0.420159 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=703, meanQ=36.652713, numObservations: 9
action 3, numVisits=10, meanQ=8.095000, numObservations: 5
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 16804 episodes
GETTING ACTION FROM:
action 2, numVisits=17507, meanQ=28.490349, numObservations: 9
action 3, numVisits=10, meanQ=8.095000, numObservations: 5
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.149671 0.233719 0.351728 0.990463 0.441248 0.663281 0.673548 0.870544 0.974245 0.420159 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=399, meanQ=45.831389, numObservations: 9
action 5, numVisits=4, meanQ=21.737500, numObservations: 3
action 2, numVisits=4, meanQ=20.250000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 19843 episodes
GETTING ACTION FROM:
action 1, numVisits=20242, meanQ=53.369653, numObservations: 9
action 5, numVisits=4, meanQ=21.737500, numObservations: 3
action 2, numVisits=4, meanQ=20.250000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.149671 0.233719 0.351728 0.990463 0.441248 0.663281 0.673548 0.870544 0.974245 0.420159 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=761, meanQ=59.120175, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37662 episodes
GETTING ACTION FROM:
action 5, numVisits=38423, meanQ=49.124904, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.149671 0.233719 0.351728 0.990463 0.441248 0.663281 0.673548 0.870544 0.974245 0.420159 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -114.074
Run # 12
Initial state: 0 0.565695 0.823175 0.750782 0.299544 0.499802 0.743374 0.103895 0.609914 0.387171 0.445158 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16676 episodes
GETTING ACTION FROM:
action 0, numVisits=16622, meanQ=53.271409, numObservations: 243
action -1, numVisits=49, meanQ=-5.687551, numObservations: 43
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.565695 0.823175 0.750782 0.299544 0.499802 0.743374 0.103895 0.609914 0.387171 0.445158 w: 1
Observation: 0 0 3 0 1 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=182, meanQ=60.881232, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 29146 episodes
GETTING ACTION FROM:
action 1, numVisits=29328, meanQ=50.794658, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.565695 0.823175 0.750782 0.299544 0.499802 0.743374 0.103895 0.609914 0.387171 0.445158 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 13
Initial state: 0 0.00319124 0.43052 0.519938 0.549641 0.478247 0.991266 0.506454 0.743081 0.756251 0.663171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27072 episodes
GETTING ACTION FROM:
action 1, numVisits=27043, meanQ=4.282892, numObservations: 9
action -1, numVisits=5, meanQ=-1.050000, numObservations: 5
action 0, numVisits=5, meanQ=-1.050000, numObservations: 5
action 2, numVisits=7, meanQ=-2.428571, numObservations: 4
action 5, numVisits=10, meanQ=-7.359750, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.00319124 0.43052 0.519938 0.549641 0.478247 0.991266 0.506454 0.743081 0.756251 0.663171 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4694, meanQ=9.238798, numObservations: 9
action 0, numVisits=14, meanQ=-1.799821, numObservations: 13
action -1, numVisits=19, meanQ=-6.150000, numObservations: 18
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 6228 episodes
GETTING ACTION FROM:
action 4, numVisits=10922, meanQ=8.851074, numObservations: 9
action 0, numVisits=14, meanQ=-1.799821, numObservations: 13
action -1, numVisits=19, meanQ=-6.150000, numObservations: 18
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.00319124 0.43052 0.519938 0.549641 0.478247 0.991266 0.506454 0.743081 0.756251 0.663171 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 14
Initial state: 0 0.0067802 0.338195 0.786754 0.891999 0.742089 0.662498 0.483702 0.582672 0.501379 0.641484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16995 episodes
GETTING ACTION FROM:
action -1, numVisits=16860, meanQ=38.511275, numObservations: 243
action 4, numVisits=112, meanQ=-4.013591, numObservations: 9
action 0, numVisits=19, meanQ=-6.702500, numObservations: 17
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0067802 0.338195 0.786754 0.891999 0.742089 0.662498 0.483702 0.582672 0.501379 0.641484 w: 1
Observation: 0 1 0 1 0 3 0 2 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=74, meanQ=29.745716, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 21020 episodes
GETTING ACTION FROM:
action 2, numVisits=21094, meanQ=10.552529, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0067802 0.338195 0.786754 0.891999 0.742089 0.662498 0.483702 0.582672 0.501379 0.641484 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 15
Initial state: 0 0.0444033 0.19117 0.47048 0.734736 0.492913 0.0960834 0.779409 0.949363 0.12236 0.964159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16354 episodes
GETTING ACTION FROM:
action -1, numVisits=16319, meanQ=38.333181, numObservations: 243
action 5, numVisits=6, meanQ=-5.924583, numObservations: 4
action 1, numVisits=18, meanQ=-7.063611, numObservations: 8
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=8, meanQ=-13.162500, numObservations: 7
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0444033 0.19117 0.47048 0.734736 0.492913 0.0960834 0.779409 0.949363 0.12236 0.964159 w: 1
Observation: 0 1 0 1 0 2 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=68, meanQ=17.799479, numObservations: 34
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=4, meanQ=-25.275000, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 14385 episodes
GETTING ACTION FROM:
action -1, numVisits=14453, meanQ=41.232776, numObservations: 200
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=4, meanQ=-25.275000, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0444033 0.19117 0.47048 0.734736 0.492913 0.0960834 0.779409 0.949363 0.12236 0.964159 w: 1
Observation: 0 1 0 2 0 2 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=244, meanQ=35.460421, numObservations: 41
action 0, numVisits=18, meanQ=-2.427500, numObservations: 14
action 3, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 15779 episodes
GETTING ACTION FROM:
action -1, numVisits=16023, meanQ=44.290865, numObservations: 163
action 0, numVisits=18, meanQ=-2.427500, numObservations: 14
action 3, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0444033 0.19117 0.47048 0.734736 0.492913 0.0960834 0.779409 0.949363 0.12236 0.964159 w: 1
Observation: 0 1 0 2 0 2 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=78, meanQ=20.034147, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 20179 episodes
GETTING ACTION FROM:
action 2, numVisits=20257, meanQ=38.773521, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0444033 0.19117 0.47048 0.734736 0.492913 0.0960834 0.779409 0.949363 0.12236 0.964159 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 79.1751
Run # 16
Initial state: 0 0.636902 0.364161 0.394877 0.449006 0.453278 0.909711 0.808815 0.18164 0.476451 0.652686 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17232 episodes
GETTING ACTION FROM:
action 0, numVisits=17211, meanQ=57.722131, numObservations: 243
action -1, numVisits=12, meanQ=-9.125000, numObservations: 11
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=5, meanQ=-24.810000, numObservations: 4
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.636902 0.364161 0.394877 0.449006 0.453278 0.909711 0.808815 0.18164 0.476451 0.652686 w: 1
Observation: 0 0 1 0 1 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=190, meanQ=87.732421, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37032 episodes
GETTING ACTION FROM:
action 5, numVisits=37222, meanQ=89.977036, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.636902 0.364161 0.394877 0.449006 0.453278 0.909711 0.808815 0.18164 0.476451 0.652686 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 17
Initial state: 0 0.345835 0.380204 0.499302 0.661272 0.0944879 0.0920365 0.799406 0.98455 0.325453 0.856953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27322 episodes
GETTING ACTION FROM:
action 4, numVisits=27211, meanQ=4.734045, numObservations: 9
action 2, numVisits=102, meanQ=1.464446, numObservations: 9
action -1, numVisits=3, meanQ=-1.050000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.345835 0.380204 0.499302 0.661272 0.0944879 0.0920365 0.799406 0.98455 0.325453 0.856953 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 18
Initial state: 0 0.451223 0.333349 0.210608 0.259985 0.97691 0.503337 0.485674 0.719057 0.913378 0.894604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25757 episodes
GETTING ACTION FROM:
action 4, numVisits=25751, meanQ=8.745984, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.451223 0.333349 0.210608 0.259985 0.97691 0.503337 0.485674 0.719057 0.913378 0.894604 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 19
Initial state: 0 0.772744 0.0536986 0.0930645 0.856653 0.812837 0.347497 0.581579 0.710147 0.647056 0.754512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17045 episodes
GETTING ACTION FROM:
action 0, numVisits=17014, meanQ=55.446434, numObservations: 243
action -1, numVisits=22, meanQ=-1.050000, numObservations: 22
action 2, numVisits=5, meanQ=-7.000000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.772744 0.0536986 0.0930645 0.856653 0.812837 0.347497 0.581579 0.710147 0.647056 0.754512 w: 1
Observation: 0 0 1 0 3 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=177, meanQ=86.905720, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37262 episodes
GETTING ACTION FROM:
action 4, numVisits=37439, meanQ=89.397438, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.772744 0.0536986 0.0930645 0.856653 0.812837 0.347497 0.581579 0.710147 0.647056 0.754512 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 20
Initial state: 0 0.17803 0.400789 0.743682 0.545377 0.045532 0.664347 0.52419 0.685221 0.7003 0.667831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25051 episodes
GETTING ACTION FROM:
action 3, numVisits=25030, meanQ=6.876316, numObservations: 9
action -1, numVisits=3, meanQ=-1.050000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 5, numVisits=10, meanQ=-6.504750, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 3
Next state: 0 0.17803 0.400789 0.743682 0.545377 0.045532 0.664347 0.52419 0.685221 0.7003 0.667831 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=703, meanQ=13.401286, numObservations: 9
action -1, numVisits=9, meanQ=-1.050000, numObservations: 9
action 0, numVisits=9, meanQ=-1.050000, numObservations: 9
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 9221 episodes
GETTING ACTION FROM:
action 5, numVisits=9908, meanQ=2.911127, numObservations: 9
action -1, numVisits=19, meanQ=-1.200000, numObservations: 19
action 0, numVisits=15, meanQ=-2.096095, numObservations: 14
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.17803 0.400789 0.743682 0.545377 0.045532 0.664347 0.52419 0.685221 0.7003 0.667831 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 21
Initial state: 0 0.528459 0.71883 0.128613 0.742861 0.198998 0.248497 0.326908 0.374705 0.32103 0.138049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16852 episodes
GETTING ACTION FROM:
action 0, numVisits=16774, meanQ=60.093971, numObservations: 243
action -1, numVisits=53, meanQ=-3.347925, numObservations: 48
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=17, meanQ=-4.643971, numObservations: 7
action 5, numVisits=3, meanQ=-6.316667, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.528459 0.71883 0.128613 0.742861 0.198998 0.248497 0.326908 0.374705 0.32103 0.138049 w: 1
Observation: 0 0 2 0 1 0 1 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=442, meanQ=82.441020, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 36150 episodes
GETTING ACTION FROM:
action 1, numVisits=36592, meanQ=92.001262, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.528459 0.71883 0.128613 0.742861 0.198998 0.248497 0.326908 0.374705 0.32103 0.138049 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 22
Initial state: 0 0.52853 0.736386 0.884859 0.361952 0.20785 0.829077 0.867117 0.668107 0.750056 0.780097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25441 episodes
GETTING ACTION FROM:
action 2, numVisits=25386, meanQ=9.616055, numObservations: 9
action 1, numVisits=34, meanQ=-7.714265, numObservations: 8
action 0, numVisits=14, meanQ=-8.110536, numObservations: 12
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=4, meanQ=-25.275000, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.52853 0.736386 0.884859 0.361952 0.20785 0.829077 0.867117 0.668107 0.750056 0.780097 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 23
Initial state: 0 0.735517 0.388933 0.312118 0.337267 0.897313 0.960922 0.542815 0.679124 0.397214 0.502747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26282 episodes
GETTING ACTION FROM:
action 2, numVisits=26265, meanQ=4.143918, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 4, numVisits=10, meanQ=-4.595000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.735517 0.388933 0.312118 0.337267 0.897313 0.960922 0.542815 0.679124 0.397214 0.502747 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4638, meanQ=12.639719, numObservations: 9
action 3, numVisits=8, meanQ=8.375000, numObservations: 5
action 5, numVisits=22, meanQ=5.818182, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 7341 episodes
GETTING ACTION FROM:
action 4, numVisits=11973, meanQ=9.989160, numObservations: 9
action 5, numVisits=22, meanQ=5.818182, numObservations: 8
action 3, numVisits=12, meanQ=5.250000, numObservations: 7
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.735517 0.388933 0.312118 0.337267 0.897313 0.960922 0.542815 0.679124 0.397214 0.502747 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 24
Initial state: 0 0.44307 0.644316 0.786421 0.987372 0.194755 0.911644 0.917523 0.34878 0.235304 0.307329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16137 episodes
GETTING ACTION FROM:
action 0, numVisits=16098, meanQ=53.656390, numObservations: 243
action 3, numVisits=18, meanQ=-6.729722, numObservations: 7
action -1, numVisits=14, meanQ=-7.971429, numObservations: 13
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=4, meanQ=-28.262500, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.44307 0.644316 0.786421 0.987372 0.194755 0.911644 0.917523 0.34878 0.235304 0.307329 w: 1
Observation: 0 0 2 0 3 0 3 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=67, meanQ=80.250037, numObservations: 8
action 3, numVisits=3, meanQ=62.650000, numObservations: 3
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 34817 episodes
GETTING ACTION FROM:
action 1, numVisits=34884, meanQ=82.949109, numObservations: 9
action 3, numVisits=3, meanQ=62.650000, numObservations: 3
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.44307 0.644316 0.786421 0.987372 0.194755 0.911644 0.917523 0.34878 0.235304 0.307329 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 25
Initial state: 0 0.491849 0.639062 0.406727 0.580202 0.908352 0.117119 0.294837 0.174273 0.529709 0.968509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27620 episodes
GETTING ACTION FROM:
action 5, numVisits=27610, meanQ=5.265753, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.491849 0.639062 0.406727 0.580202 0.908352 0.117119 0.294837 0.174273 0.529709 0.968509 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 26
Initial state: 0 0.496158 0.665436 0.342799 0.73027 0.739658 0.205438 0.403437 0.341549 0.95207 0.508466 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16981 episodes
GETTING ACTION FROM:
action -1, numVisits=16930, meanQ=38.891016, numObservations: 243
action 0, numVisits=43, meanQ=-1.319535, numObservations: 37
action 4, numVisits=4, meanQ=-6.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.496158 0.665436 0.342799 0.73027 0.739658 0.205438 0.403437 0.341549 0.95207 0.508466 w: 1
Observation: 0 2 0 1 0 3 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=60, meanQ=2.421458, numObservations: 38
action -1, numVisits=11, meanQ=-9.859091, numObservations: 10
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=5, meanQ=-21.000000, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17224 episodes
GETTING ACTION FROM:
action 0, numVisits=17284, meanQ=72.776910, numObservations: 235
action -1, numVisits=11, meanQ=-9.859091, numObservations: 10
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=5, meanQ=-21.000000, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.496158 0.665436 0.342799 0.73027 0.739658 0.205438 0.403437 0.341549 0.95207 0.508466 w: 1
Observation: 0 0 2 0 2 0 3 0 1 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=69, meanQ=89.665254, numObservations: 6
action 3, numVisits=6, meanQ=65.666667, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 36408 episodes
GETTING ACTION FROM:
action 1, numVisits=36477, meanQ=91.207124, numObservations: 9
action 3, numVisits=6, meanQ=65.666667, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.496158 0.665436 0.342799 0.73027 0.739658 0.205438 0.403437 0.341549 0.95207 0.508466 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 27
Initial state: 0 0.624065 0.681097 0.507689 0.677158 0.74891 0.831524 0.481597 0.761497 0.233397 0.731956 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17368 episodes
GETTING ACTION FROM:
action 0, numVisits=17291, meanQ=59.183642, numObservations: 243
action 1, numVisits=25, meanQ=-2.529500, numObservations: 8
action 5, numVisits=23, meanQ=-4.462717, numObservations: 9
action -1, numVisits=24, meanQ=-5.168646, numObservations: 22
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.624065 0.681097 0.507689 0.677158 0.74891 0.831524 0.481597 0.761497 0.233397 0.731956 w: 1
Observation: 0 0 3 0 2 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=24, meanQ=2.310625, numObservations: 21
action 0, numVisits=6, meanQ=-2.799583, numObservations: 5
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17711 episodes
GETTING ACTION FROM:
action -1, numVisits=17733, meanQ=66.645573, numObservations: 243
action 0, numVisits=8, meanQ=-2.605625, numObservations: 6
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.624065 0.681097 0.507689 0.677158 0.74891 0.831524 0.481597 0.761497 0.233397 0.731956 w: 1
Observation: 0 3 0 3 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=7, meanQ=41.857143, numObservations: 4
action 5, numVisits=3, meanQ=26.300000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 27436 episodes
GETTING ACTION FROM:
action 5, numVisits=27431, meanQ=45.730745, numObservations: 9
action 2, numVisits=15, meanQ=23.030167, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.624065 0.681097 0.507689 0.677158 0.74891 0.831524 0.481597 0.761497 0.233397 0.731956 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=4922, meanQ=75.634362, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 26712 episodes
GETTING ACTION FROM:
action 2, numVisits=31634, meanQ=69.298975, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.624065 0.681097 0.507689 0.677158 0.74891 0.831524 0.481597 0.761497 0.233397 0.731956 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 71.0526
Run # 28
Initial state: 0 0.380336 0.642739 0.574682 0.723972 0.671483 0.135641 0.73274 0.0968987 0.980419 0.0214366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16743 episodes
GETTING ACTION FROM:
action -1, numVisits=16715, meanQ=38.949048, numObservations: 243
action 0, numVisits=20, meanQ=-5.895000, numObservations: 19
action 1, numVisits=4, meanQ=-6.000000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.380336 0.642739 0.574682 0.723972 0.671483 0.135641 0.73274 0.0968987 0.980419 0.0214366 w: 1
Observation: 0 2 0 2 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=58, meanQ=27.188017, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=9, meanQ=-2.005556, numObservations: 4
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34645 episodes
GETTING ACTION FROM:
action 1, numVisits=34703, meanQ=59.633190, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=9, meanQ=-2.005556, numObservations: 4
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.380336 0.642739 0.574682 0.723972 0.671483 0.135641 0.73274 0.0968987 0.980419 0.0214366 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 29
Initial state: 0 0.538661 0.725092 0.440937 0.525323 0.414268 0.286815 0.918963 0.137761 0.182243 0.523029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17323 episodes
GETTING ACTION FROM:
action -1, numVisits=17271, meanQ=41.603592, numObservations: 243
action 1, numVisits=24, meanQ=-4.147708, numObservations: 9
action 0, numVisits=18, meanQ=-6.433333, numObservations: 17
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=7, meanQ=-18.142857, numObservations: 6
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.538661 0.725092 0.440937 0.525323 0.414268 0.286815 0.918963 0.137761 0.182243 0.523029 w: 1
Observation: 0 2 0 2 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=53, meanQ=28.549105, numObservations: 24
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=6, meanQ=-17.200000, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 16152 episodes
GETTING ACTION FROM:
action -1, numVisits=16205, meanQ=46.242920, numObservations: 211
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=6, meanQ=-17.200000, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.538661 0.725092 0.440937 0.525323 0.414268 0.286815 0.918963 0.137761 0.182243 0.523029 w: 1
Observation: 0 2 0 2 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=362, meanQ=62.912965, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34954 episodes
GETTING ACTION FROM:
action 2, numVisits=35316, meanQ=55.508957, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.538661 0.725092 0.440937 0.525323 0.414268 0.286815 0.918963 0.137761 0.182243 0.523029 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=1995, meanQ=79.970552, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 36461 episodes
GETTING ACTION FROM:
action 1, numVisits=38456, meanQ=71.484603, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.538661 0.725092 0.440937 0.525323 0.414268 0.286815 0.918963 0.137761 0.182243 0.523029 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 71.0526
Run # 30
Initial state: 0 0.145095 0.338553 0.999177 0.831047 0.575765 0.778308 0.453205 0.729216 0.567309 0.13259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26853 episodes
GETTING ACTION FROM:
action 3, numVisits=26834, meanQ=4.018545, numObservations: 9
action -1, numVisits=3, meanQ=-1.050000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 1, numVisits=10, meanQ=-4.620000, numObservations: 6
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.145095 0.338553 0.999177 0.831047 0.575765 0.778308 0.453205 0.729216 0.567309 0.13259 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 31
Initial state: 0 0.00274303 0.862516 0.722811 0.92425 0.720749 0.797301 0.430798 0.0965711 0.448123 0.711745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17357 episodes
GETTING ACTION FROM:
action -1, numVisits=17328, meanQ=39.454487, numObservations: 243
action 0, numVisits=24, meanQ=-5.168646, numObservations: 22
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.00274303 0.862516 0.722811 0.92425 0.720749 0.797301 0.430798 0.0965711 0.448123 0.711745 w: 1
Observation: 0 1 0 1 0 3 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=21, meanQ=3.383333, numObservations: 20
action -1, numVisits=7, meanQ=-1.328214, numObservations: 6
action 5, numVisits=5, meanQ=-2.810000, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 16853 episodes
GETTING ACTION FROM:
action 0, numVisits=16863, meanQ=60.002335, numObservations: 239
action -1, numVisits=17, meanQ=-2.229118, numObservations: 11
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=6, meanQ=-19.175000, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.00274303 0.862516 0.722811 0.92425 0.720749 0.797301 0.430798 0.0965711 0.448123 0.711745 w: 1
Observation: 0 0 1 0 3 0 3 0 1 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=12, meanQ=47.491667, numObservations: 5
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action 3, numVisits=2, meanQ=44.475000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37247 episodes
GETTING ACTION FROM:
action 5, numVisits=37259, meanQ=52.814690, numObservations: 9
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action 3, numVisits=2, meanQ=44.475000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.00274303 0.862516 0.722811 0.92425 0.720749 0.797301 0.430798 0.0965711 0.448123 0.711745 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 32
Initial state: 0 0.561746 0.649553 0.551805 0.0360483 0.627236 0.227217 0.15889 0.815329 0.830818 0.571836 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16561 episodes
GETTING ACTION FROM:
action -1, numVisits=16494, meanQ=39.932866, numObservations: 243
action 3, numVisits=33, meanQ=-4.020909, numObservations: 8
action 0, numVisits=30, meanQ=-4.344917, numObservations: 28
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.561746 0.649553 0.551805 0.0360483 0.627236 0.227217 0.15889 0.815329 0.830818 0.571836 w: 1
Observation: 0 2 0 2 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=37, meanQ=20.099279, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.016667, numObservations: 2
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 16361 episodes
GETTING ACTION FROM:
action 4, numVisits=16396, meanQ=11.115403, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=3, meanQ=-4.016667, numObservations: 2
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.561746 0.649553 0.551805 0.0360483 0.627236 0.227217 0.15889 0.815329 0.830818 0.571836 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2085, meanQ=28.301849, numObservations: 9
action -1, numVisits=12, meanQ=-1.683333, numObservations: 8
action 2, numVisits=10, meanQ=-5.669750, numObservations: 5
action 0, numVisits=8, meanQ=-13.162500, numObservations: 7
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11263 episodes
GETTING ACTION FROM:
action 1, numVisits=13348, meanQ=24.476693, numObservations: 9
action -1, numVisits=12, meanQ=-1.683333, numObservations: 8
action 2, numVisits=10, meanQ=-5.669750, numObservations: 5
action 0, numVisits=8, meanQ=-13.162500, numObservations: 7
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.561746 0.649553 0.551805 0.0360483 0.627236 0.227217 0.15889 0.815329 0.830818 0.571836 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 33
Initial state: 0 0.476246 0.735991 0.31008 0.915541 0.577873 0.0856287 0.121092 0.656009 0.552761 0.757686 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17067 episodes
GETTING ACTION FROM:
action -1, numVisits=17036, meanQ=38.766919, numObservations: 243
action 0, numVisits=26, meanQ=-5.180673, numObservations: 24
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.476246 0.735991 0.31008 0.915541 0.577873 0.0856287 0.121092 0.656009 0.552761 0.757686 w: 1
Observation: 0 2 0 1 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=15, meanQ=33.520333, numObservations: 5
action 5, numVisits=23, meanQ=23.906522, numObservations: 8
action 1, numVisits=7, meanQ=10.700000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 32106 episodes
GETTING ACTION FROM:
action 5, numVisits=32127, meanQ=34.538295, numObservations: 9
action 3, numVisits=17, meanQ=22.988529, numObservations: 5
action 1, numVisits=7, meanQ=10.700000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 2 0.476246 0.735991 0.31008 0.915541 0.577873 0.0856287 0.121092 0.656009 0.552761 0.757686 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 34
Initial state: 0 0.679629 0.676142 0.0608368 0.579743 0.486685 0.672268 0.62522 0.234093 0.0976028 0.401408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16994 episodes
GETTING ACTION FROM:
action 0, numVisits=16976, meanQ=58.755225, numObservations: 243
action -1, numVisits=13, meanQ=-1.050000, numObservations: 13
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.679629 0.676142 0.0608368 0.579743 0.486685 0.672268 0.62522 0.234093 0.0976028 0.401408 w: 1
Observation: 0 0 2 0 1 0 3 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=174, meanQ=83.737083, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action 3, numVisits=4, meanQ=44.475000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37053 episodes
GETTING ACTION FROM:
action 1, numVisits=37227, meanQ=88.123137, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action 3, numVisits=4, meanQ=44.475000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.679629 0.676142 0.0608368 0.579743 0.486685 0.672268 0.62522 0.234093 0.0976028 0.401408 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 35
Initial state: 0 0.595386 0.905175 0.124673 0.866293 0.489771 0.642734 0.739361 0.826582 0.600323 0.898057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17018 episodes
GETTING ACTION FROM:
action -1, numVisits=16975, meanQ=38.769070, numObservations: 243
action 0, numVisits=38, meanQ=-3.851250, numObservations: 32
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.595386 0.905175 0.124673 0.866293 0.489771 0.642734 0.739361 0.826582 0.600323 0.898057 w: 1
Observation: 0 3 0 1 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=68, meanQ=13.433309, numObservations: 41
action -1, numVisits=7, meanQ=-1.328214, numObservations: 6
action 4, numVisits=10, meanQ=-3.004750, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17227 episodes
GETTING ACTION FROM:
action 0, numVisits=17295, meanQ=78.061636, numObservations: 237
action -1, numVisits=7, meanQ=-1.328214, numObservations: 6
action 4, numVisits=10, meanQ=-3.004750, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.595386 0.905175 0.124673 0.866293 0.489771 0.642734 0.739361 0.826582 0.600323 0.898057 w: 1
Observation: 0 0 2 0 3 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=42, meanQ=70.428571, numObservations: 4
action 4, numVisits=6, meanQ=65.666667, numObservations: 3
action 3, numVisits=8, meanQ=60.368750, numObservations: 3
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 41241 episodes
GETTING ACTION FROM:
action 4, numVisits=41235, meanQ=75.011643, numObservations: 9
action 1, numVisits=54, meanQ=67.333333, numObservations: 6
action 3, numVisits=8, meanQ=60.368750, numObservations: 3
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.595386 0.905175 0.124673 0.866293 0.489771 0.642734 0.739361 0.826582 0.600323 0.898057 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 36
Initial state: 0 0.137186 0.572007 0.545125 0.654184 0.405139 0.404473 0.637635 0.906293 0.779024 0.880063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26348 episodes
GETTING ACTION FROM:
action 4, numVisits=26320, meanQ=4.467073, numObservations: 9
action -1, numVisits=10, meanQ=-1.050000, numObservations: 10
action 0, numVisits=10, meanQ=-1.050000, numObservations: 10
action 2, numVisits=5, meanQ=-2.810000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.137186 0.572007 0.545125 0.654184 0.405139 0.404473 0.637635 0.906293 0.779024 0.880063 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 37
Initial state: 0 0.446917 0.948869 0.804728 0.661848 0.493457 0.741675 0.628727 0.908598 0.53998 0.587302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 24887 episodes
GETTING ACTION FROM:
action 2, numVisits=24850, meanQ=9.404329, numObservations: 9
action -1, numVisits=13, meanQ=-1.050000, numObservations: 13
action 0, numVisits=13, meanQ=-1.050000, numObservations: 13
action 1, numVisits=8, meanQ=-3.500000, numObservations: 6
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.446917 0.948869 0.804728 0.661848 0.493457 0.741675 0.628727 0.908598 0.53998 0.587302 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 38
Initial state: 0 0.109266 0.465302 0.110422 0.744963 0.616205 0.365101 0.527099 0.72839 0.139007 0.913393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16701 episodes
GETTING ACTION FROM:
action -1, numVisits=16638, meanQ=39.295315, numObservations: 243
action 0, numVisits=58, meanQ=-2.878750, numObservations: 43
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.109266 0.465302 0.110422 0.744963 0.616205 0.365101 0.527099 0.72839 0.139007 0.913393 w: 1
Observation: 0 3 0 1 0 2 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23, meanQ=32.602174, numObservations: 6
action 4, numVisits=39, meanQ=18.252692, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 30850 episodes
GETTING ACTION FROM:
action 3, numVisits=30873, meanQ=52.564762, numObservations: 9
action 4, numVisits=39, meanQ=18.252692, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.109266 0.465302 0.110422 0.744963 0.616205 0.365101 0.527099 0.72839 0.139007 0.913393 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 39
Initial state: 0 0.459469 0.988478 0.0118838 0.214056 0.442087 0.654043 0.879911 0.361367 0.984869 0.79479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 24002 episodes
GETTING ACTION FROM:
action 2, numVisits=23920, meanQ=2.292905, numObservations: 9
action 4, numVisits=69, meanQ=0.943569, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.459469 0.988478 0.0118838 0.214056 0.442087 0.654043 0.879911 0.361367 0.984869 0.79479 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=4178, meanQ=15.785355, numObservations: 9
action -1, numVisits=15, meanQ=-1.749833, numObservations: 14
action 0, numVisits=9, meanQ=-2.216389, numObservations: 8
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 6971 episodes
GETTING ACTION FROM:
action 4, numVisits=11149, meanQ=17.408093, numObservations: 9
action -1, numVisits=15, meanQ=-1.749833, numObservations: 14
action 0, numVisits=9, meanQ=-2.216389, numObservations: 8
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.459469 0.988478 0.0118838 0.214056 0.442087 0.654043 0.879911 0.361367 0.984869 0.79479 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 40
Initial state: 0 0.949748 0.487926 0.675079 0.904057 0.21732 0.179459 0.897625 0.139275 0.565306 0.717783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17065 episodes
GETTING ACTION FROM:
action -1, numVisits=17032, meanQ=40.304251, numObservations: 243
action 1, numVisits=11, meanQ=-5.181591, numObservations: 5
action 0, numVisits=18, meanQ=-6.433333, numObservations: 17
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.949748 0.487926 0.675079 0.904057 0.21732 0.179459 0.897625 0.139275 0.565306 0.717783 w: 1
Observation: 0 3 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=72, meanQ=30.814972, numObservations: 26
action 3, numVisits=5, meanQ=-2.810000, numObservations: 3
action 0, numVisits=4, meanQ=-25.275000, numObservations: 3
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17333 episodes
GETTING ACTION FROM:
action -1, numVisits=17405, meanQ=72.177507, numObservations: 190
action 3, numVisits=5, meanQ=-2.810000, numObservations: 3
action 0, numVisits=4, meanQ=-25.275000, numObservations: 3
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.949748 0.487926 0.675079 0.904057 0.21732 0.179459 0.897625 0.139275 0.565306 0.717783 w: 1
Observation: 0 3 0 2 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=106, meanQ=60.445825, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34283 episodes
GETTING ACTION FROM:
action 5, numVisits=34389, meanQ=72.816672, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.949748 0.487926 0.675079 0.904057 0.21732 0.179459 0.897625 0.139275 0.565306 0.717783 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 41
Initial state: 0 0.231532 0.245267 0.983351 0.181457 0.794858 0.814538 0.0250336 0.414125 0.581031 0.722481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25849 episodes
GETTING ACTION FROM:
action 1, numVisits=25839, meanQ=3.158310, numObservations: 9
action -1, numVisits=3, meanQ=-1.050000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.231532 0.245267 0.983351 0.181457 0.794858 0.814538 0.0250336 0.414125 0.581031 0.722481 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=601, meanQ=20.078253, numObservations: 200
action 0, numVisits=37, meanQ=-4.602230, numObservations: 27
action 4, numVisits=20, meanQ=-4.907375, numObservations: 8
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 7701 episodes
GETTING ACTION FROM:
action -1, numVisits=8302, meanQ=16.880159, numObservations: 243
action 0, numVisits=37, meanQ=-4.602230, numObservations: 27
action 4, numVisits=20, meanQ=-4.907375, numObservations: 8
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.231532 0.245267 0.983351 0.181457 0.794858 0.814538 0.0250336 0.414125 0.581031 0.722481 w: 1
Observation: 0 1 0 3 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=12, meanQ=56.358956, numObservations: 3
action 4, numVisits=2, meanQ=43.071619, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-212.722757, numObservations: 1
Sampled 20163 episodes
GETTING ACTION FROM:
action 5, numVisits=20174, meanQ=72.429553, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.952254, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-212.722757, numObservations: 1
action: 5
Next state: 1 0.231532 0.245267 0.983351 0.181457 0.794858 0.814538 0.0250336 0.414125 0.581031 0.722481 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 42
Initial state: 0 0.147446 0.0305381 0.485484 0.68024 0.540886 0.250219 0.699437 0.898622 0.287559 0.277827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17417 episodes
GETTING ACTION FROM:
action 0, numVisits=17399, meanQ=58.593777, numObservations: 243
action -1, numVisits=11, meanQ=-2.004318, numObservations: 10
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.147446 0.0305381 0.485484 0.68024 0.540886 0.250219 0.699437 0.898622 0.287559 0.277827 w: 1
Observation: 0 0 1 0 2 0 1 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=194, meanQ=80.002423, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36831 episodes
GETTING ACTION FROM:
action 2, numVisits=37025, meanQ=89.160407, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.147446 0.0305381 0.485484 0.68024 0.540886 0.250219 0.699437 0.898622 0.287559 0.277827 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 43
Initial state: 0 0.441694 0.377534 0.0463805 0.69662 0.813452 0.925669 0.121076 0.0548012 0.584256 0.705855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25254 episodes
GETTING ACTION FROM:
action 1, numVisits=25246, meanQ=7.561220, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.441694 0.377534 0.0463805 0.69662 0.813452 0.925669 0.121076 0.0548012 0.584256 0.705855 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 44
Initial state: 0 0.628154 0.707209 0.691497 0.695053 0.449831 0.820118 0.52218 0.700123 0.645783 0.897684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27283 episodes
GETTING ACTION FROM:
action 1, numVisits=27126, meanQ=3.258234, numObservations: 9
action -1, numVisits=82, meanQ=-5.422896, numObservations: 66
action 0, numVisits=46, meanQ=-5.430326, numObservations: 40
action 2, numVisits=26, meanQ=-5.496154, numObservations: 9
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.628154 0.707209 0.691497 0.695053 0.449831 0.820118 0.52218 0.700123 0.645783 0.897684 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 45
Initial state: 0 0.686629 0.964674 0.884264 0.951588 0.43049 0.0491949 0.271997 0.338649 0.484516 0.729377 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17088 episodes
GETTING ACTION FROM:
action -1, numVisits=17001, meanQ=40.094946, numObservations: 243
action 3, numVisits=35, meanQ=-5.163857, numObservations: 8
action 0, numVisits=48, meanQ=-5.626823, numObservations: 37
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.686629 0.964674 0.884264 0.951588 0.43049 0.0491949 0.271997 0.338649 0.484516 0.729377 w: 1
Observation: 0 3 0 3 0 1 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=19, meanQ=-1.910000, numObservations: 15
action -1, numVisits=13, meanQ=-2.665000, numObservations: 11
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17257 episodes
GETTING ACTION FROM:
action 0, numVisits=17276, meanQ=64.481526, numObservations: 242
action -1, numVisits=13, meanQ=-2.665000, numObservations: 11
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.686629 0.964674 0.884264 0.951588 0.43049 0.0491949 0.271997 0.338649 0.484516 0.729377 w: 1
Observation: 0 0 3 0 3 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=16, meanQ=72.868750, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36715 episodes
GETTING ACTION FROM:
action 5, numVisits=36731, meanQ=87.972609, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.686629 0.964674 0.884264 0.951588 0.43049 0.0491949 0.271997 0.338649 0.484516 0.729377 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 46
Initial state: 0 0.655959 0.354868 0.0429093 0.906339 0.413099 0.0477786 0.445013 0.714441 0.839864 0.0959134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16543 episodes
GETTING ACTION FROM:
action 0, numVisits=16430, meanQ=57.174835, numObservations: 243
action 5, numVisits=94, meanQ=-2.290213, numObservations: 9
action -1, numVisits=15, meanQ=-7.510000, numObservations: 14
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.655959 0.354868 0.0429093 0.906339 0.413099 0.0477786 0.445013 0.714441 0.839864 0.0959134 w: 1
Observation: 0 0 1 0 3 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=69, meanQ=91.263080, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35769 episodes
GETTING ACTION FROM:
action 4, numVisits=35838, meanQ=85.529673, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.655959 0.354868 0.0429093 0.906339 0.413099 0.0477786 0.445013 0.714441 0.839864 0.0959134 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 47
Initial state: 0 0.841966 0.555694 0.0165564 0.0699427 0.0108981 0.306303 0.486776 0.708413 0.206299 0.879882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27518 episodes
GETTING ACTION FROM:
action 2, numVisits=27508, meanQ=3.568258, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.841966 0.555694 0.0165564 0.0699427 0.0108981 0.306303 0.486776 0.708413 0.206299 0.879882 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4809, meanQ=12.553567, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 7676 episodes
GETTING ACTION FROM:
action 3, numVisits=12480, meanQ=5.917411, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=3, meanQ=-33.350000, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.841966 0.555694 0.0165564 0.0699427 0.0108981 0.306303 0.486776 0.708413 0.206299 0.879882 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 48
Initial state: 0 0.557417 0.668847 0.409032 0.972258 0.196828 0.315096 0.0458711 0.854045 0.712185 0.0564998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17052 episodes
GETTING ACTION FROM:
action -1, numVisits=16955, meanQ=37.778669, numObservations: 243
action 3, numVisits=61, meanQ=-3.894816, numObservations: 9
action 0, numVisits=32, meanQ=-4.257734, numObservations: 28
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.557417 0.668847 0.409032 0.972258 0.196828 0.315096 0.0458711 0.854045 0.712185 0.0564998 w: 1
Observation: 0 2 0 1 0 1 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=43, meanQ=16.880698, numObservations: 23
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=10, meanQ=-10.934750, numObservations: 8
action 1, numVisits=4, meanQ=-28.262500, numObservations: 4
Sampled 16368 episodes
GETTING ACTION FROM:
action -1, numVisits=16411, meanQ=48.182084, numObservations: 206
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=10, meanQ=-10.934750, numObservations: 8
action 1, numVisits=4, meanQ=-28.262500, numObservations: 4
action: -1
Next state: 0 0.557417 0.668847 0.409032 0.972258 0.196828 0.315096 0.0458711 0.854045 0.712185 0.0564998 w: 1
Observation: 0 3 0 3 0 3 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30055 episodes
GETTING ACTION FROM:
action 2, numVisits=30048, meanQ=22.304491, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.557417 0.668847 0.409032 0.972258 0.196828 0.315096 0.0458711 0.854045 0.712185 0.0564998 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=2105, meanQ=66.546859, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 21779 episodes
GETTING ACTION FROM:
action 5, numVisits=23884, meanQ=49.931935, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 2 0.557417 0.668847 0.409032 0.972258 0.196828 0.315096 0.0458711 0.854045 0.712185 0.0564998 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -100.422
Run # 49
Initial state: 0 0.344075 0.737031 0.573115 0.61869 0.566242 0.682413 0.933429 0.392982 0.092267 0.584554 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17121 episodes
GETTING ACTION FROM:
action 0, numVisits=17055, meanQ=56.379294, numObservations: 243
action -1, numVisits=53, meanQ=-3.060236, numObservations: 47
action 1, numVisits=9, meanQ=-5.550000, numObservations: 6
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.344075 0.737031 0.573115 0.61869 0.566242 0.682413 0.933429 0.392982 0.092267 0.584554 w: 1
Observation: 0 0 1 0 1 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=453, meanQ=86.022928, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36385 episodes
GETTING ACTION FROM:
action 3, numVisits=36838, meanQ=91.739847, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.344075 0.737031 0.573115 0.61869 0.566242 0.682413 0.933429 0.392982 0.092267 0.584554 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 50
Initial state: 0 0.165553 0.904592 0.292459 0.780409 0.0944896 0.628074 0.939881 0.237621 0.484143 0.710909 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27342 episodes
GETTING ACTION FROM:
action 5, numVisits=27281, meanQ=3.134185, numObservations: 9
action -1, numVisits=44, meanQ=-8.178239, numObservations: 38
action 0, numVisits=13, meanQ=-8.503846, numObservations: 12
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.165553 0.904592 0.292459 0.780409 0.0944896 0.628074 0.939881 0.237621 0.484143 0.710909 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
[32m ProblemEnvironment.hpp 351: Done.[39m
