Run # 1
Initial state: 0 0.273717 0.794259 0.959382 0.588903 0.984937 0.423408 0.406559 0.756313 0.430113 0.533931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17322 episodes
GETTING ACTION FROM:
action -1, numVisits=17252, meanQ=49.874838, numObservations: 243
action 1, numVisits=17, meanQ=-2.764706, numObservations: 7
action 0, numVisits=43, meanQ=-3.391860, numObservations: 40
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=7, meanQ=-15.285714, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.273717 0.794259 0.959382 0.588903 0.984937 0.423408 0.406559 0.756313 0.430113 0.533931 w: 1
Observation: 0 1 0 3 0 3 0 2 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=73, meanQ=50.076298, numObservations: 7
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35478 episodes
GETTING ACTION FROM:
action 5, numVisits=34985, meanQ=39.083851, numObservations: 9
action 1, numVisits=569, meanQ=23.887284, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.273717 0.794259 0.959382 0.588903 0.984937 0.423408 0.406559 0.756313 0.430113 0.533931 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 2
Initial state: 0 0.368996 0.328059 0.149983 0.988962 0.372812 0.494272 0.985176 0.494474 0.0316154 0.63233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31547 episodes
GETTING ACTION FROM:
action 5, numVisits=31539, meanQ=18.602723, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.368996 0.328059 0.149983 0.988962 0.372812 0.494272 0.985176 0.494474 0.0316154 0.63233 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=1758, meanQ=54.344593, numObservations: 219
action -1, numVisits=17, meanQ=-1.782059, numObservations: 15
action 3, numVisits=12, meanQ=-4.891458, numObservations: 8
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5662 episodes
GETTING ACTION FROM:
action 0, numVisits=7420, meanQ=39.023678, numObservations: 243
action -1, numVisits=17, meanQ=-1.782059, numObservations: 15
action 3, numVisits=12, meanQ=-4.891458, numObservations: 8
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.368996 0.328059 0.149983 0.988962 0.372812 0.494272 0.985176 0.494474 0.0316154 0.63233 w: 1
Observation: 0 0 1 0 3 0 2 0 1 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=31, meanQ=68.028705, numObservations: 6
action 2, numVisits=17, meanQ=60.502120, numObservations: 5
action 5, numVisits=2, meanQ=44.475000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 28637 episodes
GETTING ACTION FROM:
action 3, numVisits=28668, meanQ=87.876933, numObservations: 9
action 2, numVisits=17, meanQ=60.502120, numObservations: 5
action 5, numVisits=2, meanQ=44.475000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.368996 0.328059 0.149983 0.988962 0.372812 0.494272 0.985176 0.494474 0.0316154 0.63233 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 3
Initial state: 0 0.412388 0.393676 0.160458 0.484068 0.340272 0.31718 0.766493 0.67446 0.424888 0.50215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31089 episodes
GETTING ACTION FROM:
action 3, numVisits=31083, meanQ=18.527088, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.412388 0.393676 0.160458 0.484068 0.340272 0.31718 0.766493 0.67446 0.424888 0.50215 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 4
Initial state: 0 0.947179 0.926906 0.863104 0.0804289 0.0912858 0.228794 0.408977 0.473069 0.742178 0.28863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31453 episodes
GETTING ACTION FROM:
action 1, numVisits=31446, meanQ=18.838134, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.947179 0.926906 0.863104 0.0804289 0.0912858 0.228794 0.408977 0.473069 0.742178 0.28863 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 5
Initial state: 0 0.484021 0.496299 0.656194 0.496533 0.395364 0.573215 0.712896 0.022852 0.770506 0.259354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29224 episodes
GETTING ACTION FROM:
action 1, numVisits=29171, meanQ=19.938199, numObservations: 9
action 2, numVisits=48, meanQ=11.813750, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.484021 0.496299 0.656194 0.496533 0.395364 0.573215 0.712896 0.022852 0.770506 0.259354 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 6
Initial state: 0 0.485596 0.0461109 0.810247 0.816241 0.998806 0.535876 0.409866 0.476006 0.125855 0.161833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17192 episodes
GETTING ACTION FROM:
action -1, numVisits=17144, meanQ=45.761663, numObservations: 243
action 3, numVisits=36, meanQ=-4.669097, numObservations: 8
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=6, meanQ=-17.200000, numObservations: 5
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.485596 0.0461109 0.810247 0.816241 0.998806 0.535876 0.409866 0.476006 0.125855 0.161833 w: 1
Observation: 0 3 0 3 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=154, meanQ=7.342549, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 40209 episodes
GETTING ACTION FROM:
action 2, numVisits=40356, meanQ=2.076245, numObservations: 9
action 0, numVisits=5, meanQ=-1.050000, numObservations: 5
action -1, numVisits=4, meanQ=-3.674375, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.485596 0.0461109 0.810247 0.816241 0.998806 0.535876 0.409866 0.476006 0.125855 0.161833 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 7
Initial state: 0 0.421576 0.0135191 0.425402 0.542717 0.287069 0.248768 0.501883 0.308041 0.858554 0.309908 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32070 episodes
GETTING ACTION FROM:
action 1, numVisits=31779, meanQ=17.396956, numObservations: 9
action 2, numVisits=278, meanQ=11.579879, numObservations: 9
action 3, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=4, meanQ=-6.000000, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.421576 0.0135191 0.425402 0.542717 0.287069 0.248768 0.501883 0.308041 0.858554 0.309908 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=218, meanQ=28.164239, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37737 episodes
GETTING ACTION FROM:
action 4, numVisits=37955, meanQ=32.895695, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.421576 0.0135191 0.425402 0.542717 0.287069 0.248768 0.501883 0.308041 0.858554 0.309908 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 8
Initial state: 0 0.916385 0.563628 0.329866 0.566331 0.204116 0.587456 0.823829 0.382225 0.0172716 0.305755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18008 episodes
GETTING ACTION FROM:
action 0, numVisits=17902, meanQ=58.721752, numObservations: 243
action -1, numVisits=96, meanQ=-3.815885, numObservations: 70
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=6, meanQ=-19.333333, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.916385 0.563628 0.329866 0.566331 0.204116 0.587456 0.823829 0.382225 0.0172716 0.305755 w: 1
Observation: 0 0 2 0 2 0 2 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31, meanQ=63.898468, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36228 episodes
GETTING ACTION FROM:
action 2, numVisits=36259, meanQ=55.894093, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.916385 0.563628 0.329866 0.566331 0.204116 0.587456 0.823829 0.382225 0.0172716 0.305755 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1155, meanQ=89.600274, numObservations: 9
action 3, numVisits=3, meanQ=62.650000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35765 episodes
GETTING ACTION FROM:
action 2, numVisits=1273, meanQ=89.665955, numObservations: 9
action 3, numVisits=35636, meanQ=25.832619, numObservations: 9
action -1, numVisits=8, meanQ=-1.881250, numObservations: 8
action 0, numVisits=8, meanQ=-1.881250, numObservations: 8
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.916385 0.563628 0.329866 0.566331 0.204116 0.587456 0.823829 0.382225 0.0172716 0.305755 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 9
Initial state: 0 0.444464 0.616671 0.953533 0.723954 0.694923 0.080269 0.439512 0.41228 0.396941 0.817979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31646 episodes
GETTING ACTION FROM:
action 3, numVisits=31595, meanQ=17.663834, numObservations: 9
action 5, numVisits=39, meanQ=16.210256, numObservations: 9
action 1, numVisits=8, meanQ=10.250000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.444464 0.616671 0.953533 0.723954 0.694923 0.080269 0.439512 0.41228 0.396941 0.817979 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 10
Initial state: 0 0.880194 0.72526 0.764082 0.0819976 0.323663 0.482265 0.950142 0.436362 0.259851 0.541529 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17565 episodes
GETTING ACTION FROM:
action -1, numVisits=17543, meanQ=45.048059, numObservations: 243
action 0, numVisits=15, meanQ=-7.510000, numObservations: 14
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.880194 0.72526 0.764082 0.0819976 0.323663 0.482265 0.950142 0.436362 0.259851 0.541529 w: 1
Observation: 0 3 0 1 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=144, meanQ=80.561840, numObservations: 7
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37613 episodes
GETTING ACTION FROM:
action 3, numVisits=37757, meanQ=77.887189, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.880194 0.72526 0.764082 0.0819976 0.323663 0.482265 0.950142 0.436362 0.259851 0.541529 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 11
Initial state: 0 0.955393 0.718085 0.11221 0.780893 0.424219 0.53759 0.915821 0.781603 0.713268 0.547379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17641 episodes
GETTING ACTION FROM:
action 0, numVisits=17599, meanQ=59.620737, numObservations: 243
action -1, numVisits=16, meanQ=-7.106250, numObservations: 15
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=13, meanQ=-11.073077, numObservations: 6
action 5, numVisits=10, meanQ=-14.000000, numObservations: 5
action: 0
Next state: 0 0.955393 0.718085 0.11221 0.780893 0.424219 0.53759 0.915821 0.781603 0.713268 0.547379 w: 1
Observation: 0 0 3 0 3 0 2 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=14, meanQ=76.925000, numObservations: 7
action 2, numVisits=24, meanQ=71.835521, numObservations: 7
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32329 episodes
GETTING ACTION FROM:
action 2, numVisits=31932, meanQ=55.955757, numObservations: 9
action 3, numVisits=435, meanQ=54.151626, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.955393 0.718085 0.11221 0.780893 0.424219 0.53759 0.915821 0.781603 0.713268 0.547379 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=677, meanQ=69.828050, numObservations: 9
action 5, numVisits=8, meanQ=45.425312, numObservations: 4
action 3, numVisits=7, meanQ=41.857143, numObservations: 5
action 4, numVisits=5, meanQ=37.190000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 37275 episodes
GETTING ACTION FROM:
action 1, numVisits=37952, meanQ=61.993543, numObservations: 9
action 5, numVisits=8, meanQ=45.425312, numObservations: 4
action 3, numVisits=7, meanQ=41.857143, numObservations: 5
action 4, numVisits=5, meanQ=37.190000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.955393 0.718085 0.11221 0.780893 0.424219 0.53759 0.915821 0.781603 0.713268 0.547379 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 12
Initial state: 0 0.435167 0.559814 0.123619 0.454859 0.820702 0.0580474 0.91808 0.934885 0.0264447 0.791954 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17778 episodes
GETTING ACTION FROM:
action 0, numVisits=17733, meanQ=58.317135, numObservations: 243
action -1, numVisits=19, meanQ=-1.050000, numObservations: 19
action 5, numVisits=9, meanQ=-2.772222, numObservations: 5
action 3, numVisits=11, meanQ=-3.727273, numObservations: 7
action 4, numVisits=4, meanQ=-6.000000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.435167 0.559814 0.123619 0.454859 0.820702 0.0580474 0.91808 0.934885 0.0264447 0.791954 w: 1
Observation: 0 0 2 0 3 0 1 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=73, meanQ=77.168596, numObservations: 9
action 2, numVisits=11, meanQ=42.632045, numObservations: 3
action 5, numVisits=4, meanQ=21.737500, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 37699 episodes
GETTING ACTION FROM:
action 1, numVisits=37772, meanQ=88.171970, numObservations: 9
action 2, numVisits=11, meanQ=42.632045, numObservations: 3
action 5, numVisits=4, meanQ=21.737500, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.435167 0.559814 0.123619 0.454859 0.820702 0.0580474 0.91808 0.934885 0.0264447 0.791954 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 13
Initial state: 0 0.955448 0.934687 0.745544 0.52437 0.627973 0.86939 0.168935 0.95788 0.337155 0.521641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31183 episodes
GETTING ACTION FROM:
action 5, numVisits=31177, meanQ=16.918925, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.955448 0.934687 0.745544 0.52437 0.627973 0.86939 0.168935 0.95788 0.337155 0.521641 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 14
Initial state: 0 0.722674 0.00844855 0.954052 0.170952 0.259939 0.269855 0.831352 0.932479 0.314162 0.506539 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32250 episodes
GETTING ACTION FROM:
action 5, numVisits=32236, meanQ=17.855875, numObservations: 9
action -1, numVisits=5, meanQ=-1.050000, numObservations: 5
action 0, numVisits=5, meanQ=-1.050000, numObservations: 5
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.722674 0.00844855 0.954052 0.170952 0.259939 0.269855 0.831352 0.932479 0.314162 0.506539 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 15
Initial state: 0 0.975717 0.0440619 0.502627 0.136937 0.263696 0.975863 0.347955 0.521327 0.0530352 0.0446978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31330 episodes
GETTING ACTION FROM:
action 1, numVisits=31318, meanQ=18.714090, numObservations: 9
action 2, numVisits=7, meanQ=10.428571, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.975717 0.0440619 0.502627 0.136937 0.263696 0.975863 0.347955 0.521327 0.0530352 0.0446978 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 16
Initial state: 0 0.293965 0.607416 0.203301 0.422233 0.953179 0.176479 0.420652 0.505457 0.487944 0.687042 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31126 episodes
GETTING ACTION FROM:
action 2, numVisits=31116, meanQ=18.434846, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.293965 0.607416 0.203301 0.422233 0.953179 0.176479 0.420652 0.505457 0.487944 0.687042 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2695, meanQ=21.171487, numObservations: 9
action 3, numVisits=8, meanQ=-1.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11078 episodes
GETTING ACTION FROM:
action 5, numVisits=13773, meanQ=18.244493, numObservations: 9
action 3, numVisits=8, meanQ=-1.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.293965 0.607416 0.203301 0.422233 0.953179 0.176479 0.420652 0.505457 0.487944 0.687042 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 17
Initial state: 0 0.184153 0.277865 0.613991 0.726181 0.309204 0.793908 0.438142 0.587086 0.47816 0.972056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31957 episodes
GETTING ACTION FROM:
action 5, numVisits=31951, meanQ=18.391424, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.184153 0.277865 0.613991 0.726181 0.309204 0.793908 0.438142 0.587086 0.47816 0.972056 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 18
Initial state: 0 0.391815 0.612543 0.713204 0.455988 0.286748 0.764351 0.413722 0.853841 0.772277 0.799714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32698 episodes
GETTING ACTION FROM:
action 3, numVisits=32684, meanQ=16.546640, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.391815 0.612543 0.713204 0.455988 0.286748 0.764351 0.413722 0.853841 0.772277 0.799714 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2798, meanQ=21.501907, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11671 episodes
GETTING ACTION FROM:
action 5, numVisits=14469, meanQ=23.480700, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.391815 0.612543 0.713204 0.455988 0.286748 0.764351 0.413722 0.853841 0.772277 0.799714 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 19
Initial state: 0 0.204373 0.0986328 0.521188 0.556163 0.417581 0.486847 0.0583671 0.527277 0.318411 0.681471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17252 episodes
GETTING ACTION FROM:
action -1, numVisits=17242, meanQ=48.322117, numObservations: 243
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.204373 0.0986328 0.521188 0.556163 0.417581 0.486847 0.0583671 0.527277 0.318411 0.681471 w: 1
Observation: 0 1 0 3 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=40, meanQ=27.354417, numObservations: 8
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 20611 episodes
GETTING ACTION FROM:
action 4, numVisits=20651, meanQ=20.662617, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.204373 0.0986328 0.521188 0.556163 0.417581 0.486847 0.0583671 0.527277 0.318411 0.681471 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=136, meanQ=21.393493, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 23204 episodes
GETTING ACTION FROM:
action 5, numVisits=23340, meanQ=30.923876, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.204373 0.0986328 0.521188 0.556163 0.417581 0.486847 0.0583671 0.527277 0.318411 0.681471 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 20
Initial state: 0 0.941115 0.553096 0.114236 0.521084 0.397268 0.770963 0.204836 0.567955 0.443455 0.579306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32209 episodes
GETTING ACTION FROM:
action 3, numVisits=32116, meanQ=18.171761, numObservations: 9
action 2, numVisits=75, meanQ=12.510100, numObservations: 9
action 5, numVisits=9, meanQ=6.222222, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=4, meanQ=-5.762500, numObservations: 4
action: 3
Next state: 2 0.941115 0.553096 0.114236 0.521084 0.397268 0.770963 0.204836 0.567955 0.443455 0.579306 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 21
Initial state: 0 0.208846 0.282852 0.264538 0.705172 0.882103 0.10131 0.962358 0.14845 0.308464 0.489187 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32094 episodes
GETTING ACTION FROM:
action 1, numVisits=32088, meanQ=17.380431, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.208846 0.282852 0.264538 0.705172 0.882103 0.10131 0.962358 0.14845 0.308464 0.489187 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2843, meanQ=23.944789, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 9481 episodes
GETTING ACTION FROM:
action 2, numVisits=12324, meanQ=18.539632, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.208846 0.282852 0.264538 0.705172 0.882103 0.10131 0.962358 0.14845 0.308464 0.489187 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 22
Initial state: 0 0.382759 0.481797 0.070599 0.738751 0.629233 0.331406 0.123196 0.67998 0.926347 0.586308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17556 episodes
GETTING ACTION FROM:
action -1, numVisits=17536, meanQ=47.192268, numObservations: 243
action 0, numVisits=15, meanQ=-7.510000, numObservations: 14
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.382759 0.481797 0.070599 0.738751 0.629233 0.331406 0.123196 0.67998 0.926347 0.586308 w: 1
Observation: 0 2 0 1 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=83, meanQ=32.067590, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37381 episodes
GETTING ACTION FROM:
action 5, numVisits=37464, meanQ=41.208720, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.382759 0.481797 0.070599 0.738751 0.629233 0.331406 0.123196 0.67998 0.926347 0.586308 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 23
Initial state: 0 0.0447794 0.79506 0.425412 0.555336 0.0527493 0.213586 0.509505 0.726364 0.572888 0.64983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31330 episodes
GETTING ACTION FROM:
action 2, numVisits=31300, meanQ=18.744643, numObservations: 9
action -1, numVisits=12, meanQ=-9.125000, numObservations: 11
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=7, meanQ=-14.892857, numObservations: 6
action 5, numVisits=6, meanQ=-21.991667, numObservations: 3
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 2
Next state: 1 0.0447794 0.79506 0.425412 0.555336 0.0527493 0.213586 0.509505 0.726364 0.572888 0.64983 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 24
Initial state: 0 0.454724 0.540162 0.239875 0.683003 0.202146 0.0217958 0.388633 0.515437 0.541824 0.933993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17825 episodes
GETTING ACTION FROM:
action -1, numVisits=17730, meanQ=47.904811, numObservations: 243
action 0, numVisits=87, meanQ=-3.806638, numObservations: 70
action 5, numVisits=4, meanQ=-6.000000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.454724 0.540162 0.239875 0.683003 0.202146 0.0217958 0.388633 0.515437 0.541824 0.933993 w: 1
Observation: 0 1 0 1 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=28, meanQ=38.852054, numObservations: 8
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 23936 episodes
GETTING ACTION FROM:
action 2, numVisits=23964, meanQ=46.383518, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.454724 0.540162 0.239875 0.683003 0.202146 0.0217958 0.388633 0.515437 0.541824 0.933993 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=2685, meanQ=47.506787, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 27079 episodes
GETTING ACTION FROM:
action 4, numVisits=29764, meanQ=53.506611, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.454724 0.540162 0.239875 0.683003 0.202146 0.0217958 0.388633 0.515437 0.541824 0.933993 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 25
Initial state: 0 0.912926 0.944027 0.00137972 0.600934 0.942129 0.647151 0.241227 0.948705 0.443965 0.488405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29568 episodes
GETTING ACTION FROM:
action 4, numVisits=29561, meanQ=19.972959, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.912926 0.944027 0.00137972 0.600934 0.942129 0.647151 0.241227 0.948705 0.443965 0.488405 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=152, meanQ=25.238247, numObservations: 9
action 2, numVisits=11, meanQ=16.359091, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32314 episodes
GETTING ACTION FROM:
action 1, numVisits=32465, meanQ=19.047989, numObservations: 9
action 2, numVisits=12, meanQ=6.579167, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.912926 0.944027 0.00137972 0.600934 0.942129 0.647151 0.241227 0.948705 0.443965 0.488405 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 26
Initial state: 0 0.482715 0.234791 0.853672 0.858391 0.398691 0.567288 0.605415 0.339287 0.620889 0.412876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17741 episodes
GETTING ACTION FROM:
action 0, numVisits=17719, meanQ=60.406274, numObservations: 243
action -1, numVisits=17, meanQ=-1.164559, numObservations: 16
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.482715 0.234791 0.853672 0.858391 0.398691 0.567288 0.605415 0.339287 0.620889 0.412876 w: 1
Observation: 0 0 1 0 3 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=96, meanQ=79.285417, numObservations: 9
action 2, numVisits=17, meanQ=61.347353, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37673 episodes
GETTING ACTION FROM:
action 3, numVisits=37769, meanQ=89.199749, numObservations: 9
action 2, numVisits=17, meanQ=61.347353, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.482715 0.234791 0.853672 0.858391 0.398691 0.567288 0.605415 0.339287 0.620889 0.412876 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 27
Initial state: 0 0.166394 0.290025 0.324154 0.484006 0.194995 0.92362 0.241603 0.565108 0.155904 0.93583 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17298 episodes
GETTING ACTION FROM:
action -1, numVisits=17247, meanQ=44.922793, numObservations: 243
action 0, numVisits=24, meanQ=-1.487396, numObservations: 23
action 3, numVisits=13, meanQ=-3.161538, numObservations: 7
action 5, numVisits=9, meanQ=-5.394167, numObservations: 5
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.166394 0.290025 0.324154 0.484006 0.194995 0.92362 0.241603 0.565108 0.155904 0.93583 w: 1
Observation: 0 1 0 2 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=25, meanQ=-1.127900, numObservations: 24
action -1, numVisits=7, meanQ=-1.884643, numObservations: 4
action 2, numVisits=3, meanQ=-6.000000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 17701 episodes
GETTING ACTION FROM:
action -1, numVisits=17702, meanQ=69.385701, numObservations: 233
action 0, numVisits=31, meanQ=-1.451452, numObservations: 29
action 2, numVisits=3, meanQ=-6.000000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: -1
Next state: 0 0.166394 0.290025 0.324154 0.484006 0.194995 0.92362 0.241603 0.565108 0.155904 0.93583 w: 1
Observation: 0 1 0 2 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=3250, meanQ=94.358990, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 38230 episodes
GETTING ACTION FROM:
action 2, numVisits=41480, meanQ=95.364436, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.166394 0.290025 0.324154 0.484006 0.194995 0.92362 0.241603 0.565108 0.155904 0.93583 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 28
Initial state: 0 0.339925 0.552261 0.845293 0.283083 0.884084 0.976664 0.980564 0.701352 0.903619 0.212199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17855 episodes
GETTING ACTION FROM:
action -1, numVisits=17791, meanQ=47.756475, numObservations: 243
action 5, numVisits=5, meanQ=-3.000000, numObservations: 4
action 3, numVisits=32, meanQ=-3.232734, numObservations: 9
action 0, numVisits=24, meanQ=-5.087500, numObservations: 23
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.339925 0.552261 0.845293 0.283083 0.884084 0.976664 0.980564 0.701352 0.903619 0.212199 w: 1
Observation: 0 2 0 3 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=148, meanQ=12.131571, numObservations: 84
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=4, meanQ=-25.275000, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17977 episodes
GETTING ACTION FROM:
action 0, numVisits=18125, meanQ=79.528552, numObservations: 243
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=4, meanQ=-25.275000, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.339925 0.552261 0.845293 0.283083 0.884084 0.976664 0.980564 0.701352 0.903619 0.212199 w: 1
Observation: 0 0 3 0 1 0 3 0 3 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=20, meanQ=83.547500, numObservations: 4
action 1, numVisits=3, meanQ=62.650000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 42036 episodes
GETTING ACTION FROM:
action 4, numVisits=42056, meanQ=72.271341, numObservations: 9
action 1, numVisits=3, meanQ=62.650000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.339925 0.552261 0.845293 0.283083 0.884084 0.976664 0.980564 0.701352 0.903619 0.212199 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 29
Initial state: 0 0.497133 0.27767 0.0305405 0.382198 0.571868 0.108573 0.432539 0.560843 0.999785 0.743611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32011 episodes
GETTING ACTION FROM:
action 3, numVisits=32002, meanQ=17.892572, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=4, meanQ=-8.386875, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.497133 0.27767 0.0305405 0.382198 0.571868 0.108573 0.432539 0.560843 0.999785 0.743611 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 30
Initial state: 0 0.472909 0.623954 0.311465 0.607071 0.0608881 0.0455608 0.913556 0.685373 0.720159 0.872896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31062 episodes
GETTING ACTION FROM:
action 5, numVisits=31050, meanQ=17.636331, numObservations: 9
action -1, numVisits=3, meanQ=-1.050000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.472909 0.623954 0.311465 0.607071 0.0608881 0.0455608 0.913556 0.685373 0.720159 0.872896 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 31
Initial state: 0 0.638357 0.18165 0.160777 0.747137 0.361959 0.555336 0.00116379 0.0547233 0.710557 0.148288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32058 episodes
GETTING ACTION FROM:
action 2, numVisits=31937, meanQ=17.996053, numObservations: 9
action 0, numVisits=66, meanQ=-2.952879, numObservations: 59
action -1, numVisits=51, meanQ=-3.548873, numObservations: 43
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.638357 0.18165 0.160777 0.747137 0.361959 0.555336 0.00116379 0.0547233 0.710557 0.148288 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1811, meanQ=25.412340, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=4, meanQ=-5.525000, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 11651 episodes
GETTING ACTION FROM:
action 4, numVisits=13462, meanQ=33.107981, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=4, meanQ=-5.525000, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 0 0.638357 0.18165 0.160777 0.747137 0.361959 0.555336 0.00116379 0.0547233 0.710557 0.148288 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=817, meanQ=14.588139, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 10945 episodes
GETTING ACTION FROM:
action 5, numVisits=11760, meanQ=9.450400, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.525000, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.638357 0.18165 0.160777 0.747137 0.361959 0.555336 0.00116379 0.0547233 0.710557 0.148288 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -112.603
Run # 32
Initial state: 0 0.585019 0.333825 0.771876 0.148663 0.958706 0.364132 0.14498 0.663697 0.429984 0.517118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32294 episodes
GETTING ACTION FROM:
action 3, numVisits=32282, meanQ=17.358101, numObservations: 9
action 5, numVisits=7, meanQ=10.428571, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.585019 0.333825 0.771876 0.148663 0.958706 0.364132 0.14498 0.663697 0.429984 0.517118 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 33
Initial state: 0 0.716401 0.360987 0.85157 0.984884 0.636674 0.00400231 0.377585 0.559764 0.558898 0.924094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31692 episodes
GETTING ACTION FROM:
action 5, numVisits=31686, meanQ=16.976306, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.716401 0.360987 0.85157 0.984884 0.636674 0.00400231 0.377585 0.559764 0.558898 0.924094 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 34
Initial state: 0 0.335106 0.587023 0.665332 0.0454865 0.503245 0.959386 0.83143 0.0685497 0.110717 0.241309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17719 episodes
GETTING ACTION FROM:
action -1, numVisits=17660, meanQ=48.565905, numObservations: 243
action 0, numVisits=43, meanQ=-3.683488, numObservations: 38
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 4, numVisits=10, meanQ=-4.595000, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.335106 0.587023 0.665332 0.0454865 0.503245 0.959386 0.83143 0.0685497 0.110717 0.241309 w: 1
Observation: 0 2 0 3 0 3 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=77, meanQ=81.376721, numObservations: 8
action 3, numVisits=4, meanQ=21.737500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38058 episodes
GETTING ACTION FROM:
action 1, numVisits=38135, meanQ=81.546497, numObservations: 9
action 3, numVisits=4, meanQ=21.737500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.335106 0.587023 0.665332 0.0454865 0.503245 0.959386 0.83143 0.0685497 0.110717 0.241309 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 35
Initial state: 0 0.396161 0.522302 0.85227 0.95814 0.0968076 0.426765 0.42398 0.916223 0.619779 0.0854528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29918 episodes
GETTING ACTION FROM:
action 3, numVisits=29894, meanQ=18.023972, numObservations: 9
action -1, numVisits=6, meanQ=-1.050000, numObservations: 6
action 0, numVisits=4, meanQ=-1.536875, numObservations: 3
action 2, numVisits=7, meanQ=-2.428571, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 3
Next state: 0 0.396161 0.522302 0.85227 0.95814 0.0968076 0.426765 0.42398 0.916223 0.619779 0.0854528 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=2620, meanQ=46.901250, numObservations: 216
action 5, numVisits=3, meanQ=-4.016667, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=8, meanQ=-13.162500, numObservations: 7
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 3543 episodes
GETTING ACTION FROM:
action -1, numVisits=6163, meanQ=41.858002, numObservations: 240
action 5, numVisits=3, meanQ=-4.016667, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=8, meanQ=-13.162500, numObservations: 7
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.396161 0.522302 0.85227 0.95814 0.0968076 0.426765 0.42398 0.916223 0.619779 0.0854528 w: 1
Observation: 0 1 0 2 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=44, meanQ=67.181818, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-6.000000, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33315 episodes
GETTING ACTION FROM:
action 5, numVisits=33359, meanQ=38.788257, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-6.000000, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.396161 0.522302 0.85227 0.95814 0.0968076 0.426765 0.42398 0.916223 0.619779 0.0854528 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -104.053
Run # 36
Initial state: 0 0.307193 0.48257 0.113341 0.995657 0.019052 0.201883 0.241346 0.0865904 0.517378 0.00589573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32163 episodes
GETTING ACTION FROM:
action 1, numVisits=32122, meanQ=18.071388, numObservations: 9
action 5, numVisits=22, meanQ=11.359091, numObservations: 9
action 3, numVisits=15, meanQ=8.793333, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.307193 0.48257 0.113341 0.995657 0.019052 0.201883 0.241346 0.0865904 0.517378 0.00589573 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=496, meanQ=77.150538, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 29300 episodes
GETTING ACTION FROM:
action 1, numVisits=566, meanQ=78.503316, numObservations: 9
action 4, numVisits=29170, meanQ=20.062175, numObservations: 9
action -1, numVisits=16, meanQ=-1.821875, numObservations: 15
action 0, numVisits=14, meanQ=-1.932143, numObservations: 12
action 2, numVisits=22, meanQ=-6.060631, numObservations: 6
action 3, numVisits=16, meanQ=-7.950699, numObservations: 6
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.307193 0.48257 0.113341 0.995657 0.019052 0.201883 0.241346 0.0865904 0.517378 0.00589573 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 37
Initial state: 0 0.231351 0.536201 0.185082 0.467388 0.335588 0.549906 0.855605 0.0324445 0.979497 0.607695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32030 episodes
GETTING ACTION FROM:
action 2, numVisits=32003, meanQ=17.738008, numObservations: 9
action 1, numVisits=17, meanQ=15.470588, numObservations: 6
action 5, numVisits=6, meanQ=14.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.231351 0.536201 0.185082 0.467388 0.335588 0.549906 0.855605 0.0324445 0.979497 0.607695 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=856, meanQ=20.893330, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=5, meanQ=-4.000000, numObservations: 4
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 13447 episodes
GETTING ACTION FROM:
action 5, numVisits=14303, meanQ=22.381741, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=5, meanQ=-4.000000, numObservations: 4
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.231351 0.536201 0.185082 0.467388 0.335588 0.549906 0.855605 0.0324445 0.979497 0.607695 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 38
Initial state: 0 0.67814 0.320527 0.450228 0.674525 0.438972 0.601189 0.618383 0.608943 0.437731 0.0760234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17995 episodes
GETTING ACTION FROM:
action 0, numVisits=17953, meanQ=60.592578, numObservations: 243
action -1, numVisits=37, meanQ=-3.952635, numObservations: 35
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.67814 0.320527 0.450228 0.674525 0.438972 0.601189 0.618383 0.608943 0.437731 0.0760234 w: 1
Observation: 0 0 1 0 3 0 2 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=50, meanQ=27.529350, numObservations: 7
action 3, numVisits=15, meanQ=23.856667, numObservations: 6
action 2, numVisits=4, meanQ=21.737500, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35539 episodes
GETTING ACTION FROM:
action 4, numVisits=35589, meanQ=46.616121, numObservations: 9
action 3, numVisits=15, meanQ=23.856667, numObservations: 6
action 2, numVisits=4, meanQ=21.737500, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.67814 0.320527 0.450228 0.674525 0.438972 0.601189 0.618383 0.608943 0.437731 0.0760234 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 39
Initial state: 0 0.0849409 0.332592 0.674464 0.0308398 0.0831894 0.124768 0.75979 0.342548 0.376857 0.613027 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30984 episodes
GETTING ACTION FROM:
action 2, numVisits=30978, meanQ=17.811062, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.0849409 0.332592 0.674464 0.0308398 0.0831894 0.124768 0.75979 0.342548 0.376857 0.613027 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 40
Initial state: 0 0.110688 0.865255 0.491198 0.898109 0.488463 0.233078 0.341741 0.565286 0.674453 0.19412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18027 episodes
GETTING ACTION FROM:
action 0, numVisits=17969, meanQ=62.310278, numObservations: 243
action -1, numVisits=51, meanQ=-1.519412, numObservations: 43
action 4, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.110688 0.865255 0.491198 0.898109 0.488463 0.233078 0.341741 0.565286 0.674453 0.19412 w: 1
Observation: 0 0 3 0 3 0 1 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=22, meanQ=74.561477, numObservations: 5
action 2, numVisits=3, meanQ=62.650000, numObservations: 2
action 1, numVisits=4, meanQ=49.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 34417 episodes
GETTING ACTION FROM:
action 4, numVisits=34436, meanQ=65.830273, numObservations: 9
action 1, numVisits=4, meanQ=49.000000, numObservations: 4
action 2, numVisits=6, meanQ=47.491667, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.110688 0.865255 0.491198 0.898109 0.488463 0.233078 0.341741 0.565286 0.674453 0.19412 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 41
Initial state: 0 0.588204 0.349299 0.442822 0.545968 0.601994 0.458109 0.0608263 0.266391 0.364713 0.916225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17803 episodes
GETTING ACTION FROM:
action -1, numVisits=17769, meanQ=49.396210, numObservations: 243
action 2, numVisits=9, meanQ=-2.111111, numObservations: 6
action 1, numVisits=13, meanQ=-3.307692, numObservations: 6
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=7, meanQ=-14.892857, numObservations: 6
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.588204 0.349299 0.442822 0.545968 0.601994 0.458109 0.0608263 0.266391 0.364713 0.916225 w: 1
Observation: 0 3 0 2 0 3 0 2 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=52, meanQ=45.275144, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33144 episodes
GETTING ACTION FROM:
action 2, numVisits=33196, meanQ=37.680984, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.588204 0.349299 0.442822 0.545968 0.601994 0.458109 0.0608263 0.266391 0.364713 0.916225 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 42
Initial state: 0 0.377882 0.256137 0.306218 0.560763 0.533051 0.175139 0.0696906 0.11165 0.989425 0.904248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17772 episodes
GETTING ACTION FROM:
action -1, numVisits=17729, meanQ=48.123025, numObservations: 243
action 0, numVisits=34, meanQ=-1.724779, numObservations: 31
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.377882 0.256137 0.306218 0.560763 0.533051 0.175139 0.0696906 0.11165 0.989425 0.904248 w: 1
Observation: 0 2 0 2 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=49, meanQ=28.980612, numObservations: 8
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=5, meanQ=-2.810000, numObservations: 4
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35222 episodes
GETTING ACTION FROM:
action 4, numVisits=35271, meanQ=27.824593, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=5, meanQ=-2.810000, numObservations: 4
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.377882 0.256137 0.306218 0.560763 0.533051 0.175139 0.0696906 0.11165 0.989425 0.904248 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1821, meanQ=9.350199, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 4160 episodes
GETTING ACTION FROM:
action -1, numVisits=4093, meanQ=32.343747, numObservations: 154
action 5, numVisits=1889, meanQ=9.386388, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: -1
Next state: 0 0.377882 0.256137 0.306218 0.560763 0.533051 0.175139 0.0696906 0.11165 0.989425 0.904248 w: 1
Observation: 0 2 0 2 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=42, meanQ=18.047619, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-12.253946, numObservations: 1
action 1, numVisits=1, meanQ=-12.372722, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-215.975880, numObservations: 1
Sampled 7323 episodes
GETTING ACTION FROM:
action 0, numVisits=7304, meanQ=67.479045, numObservations: 205
action 3, numVisits=55, meanQ=-1.290000, numObservations: 7
action -1, numVisits=8, meanQ=-1.406250, numObservations: 6
action 2, numVisits=1, meanQ=-12.253946, numObservations: 1
action 1, numVisits=1, meanQ=-12.372722, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-215.975880, numObservations: 1
action: 0
Next state: 0 0.377882 0.256137 0.306218 0.560763 0.533051 0.175139 0.0696906 0.11165 0.989425 0.904248 w: 1
Observation: 0 0 1 0 2 0 1 0 1 0 1 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=9, meanQ=86.646387, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-216.423566, numObservations: 1
Sampled 29745 episodes
GETTING ACTION FROM:
action 1, numVisits=29754, meanQ=44.937628, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-216.423566, numObservations: 1
action: 1
Next state: 2 0.377882 0.256137 0.306218 0.560763 0.533051 0.175139 0.0696906 0.11165 0.989425 0.904248 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -98.2349
Run # 43
Initial state: 0 0.311217 0.481889 0.391442 0.442004 0.245733 0.38539 0.610371 0.0485558 0.237788 0.10768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32020 episodes
GETTING ACTION FROM:
action 3, numVisits=27328, meanQ=18.004887, numObservations: 9
action 5, numVisits=4682, meanQ=17.470218, numObservations: 9
action 2, numVisits=6, meanQ=10.658750, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.311217 0.481889 0.391442 0.442004 0.245733 0.38539 0.610371 0.0485558 0.237788 0.10768 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2344, meanQ=23.098051, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 13058 episodes
GETTING ACTION FROM:
action 5, numVisits=15402, meanQ=12.977015, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.311217 0.481889 0.391442 0.442004 0.245733 0.38539 0.610371 0.0485558 0.237788 0.10768 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=304, meanQ=19.586107, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 18685 episodes
GETTING ACTION FROM:
action 4, numVisits=18984, meanQ=5.749712, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=4, meanQ=-1.525000, numObservations: 4
action 0, numVisits=3, meanQ=-1.683333, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 2 0.311217 0.481889 0.391442 0.442004 0.245733 0.38539 0.610371 0.0485558 0.237788 0.10768 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -112.603
Run # 44
Initial state: 0 0.0682839 0.391983 0.41108 0.471034 0.0488661 0.021371 0.126889 0.123615 0.755688 0.855934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17596 episodes
GETTING ACTION FROM:
action -1, numVisits=17566, meanQ=47.954676, numObservations: 243
action 0, numVisits=23, meanQ=-5.263043, numObservations: 22
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0682839 0.391983 0.41108 0.471034 0.0488661 0.021371 0.126889 0.123615 0.755688 0.855934 w: 1
Observation: 0 1 0 1 0 1 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=6, meanQ=-1.050000, numObservations: 6
action 4, numVisits=6, meanQ=-4.341250, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=5, meanQ=-20.430000, numObservations: 4
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17290 episodes
GETTING ACTION FROM:
action 0, numVisits=17296, meanQ=62.842655, numObservations: 243
action 4, numVisits=6, meanQ=-4.341250, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=5, meanQ=-20.430000, numObservations: 4
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0682839 0.391983 0.41108 0.471034 0.0488661 0.021371 0.126889 0.123615 0.755688 0.855934 w: 1
Observation: 0 0 1 0 2 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=51, meanQ=85.743284, numObservations: 7
action 5, numVisits=4, meanQ=71.737500, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34864 episodes
GETTING ACTION FROM:
action 2, numVisits=34915, meanQ=81.647283, numObservations: 9
action 5, numVisits=4, meanQ=71.737500, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.0682839 0.391983 0.41108 0.471034 0.0488661 0.021371 0.126889 0.123615 0.755688 0.855934 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=321, meanQ=49.214533, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 39936 episodes
GETTING ACTION FROM:
action 5, numVisits=40257, meanQ=54.714320, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0682839 0.391983 0.41108 0.471034 0.0488661 0.021371 0.126889 0.123615 0.755688 0.855934 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 71.0526
Run # 45
Initial state: 0 0.12929 0.019059 0.426132 0.492847 0.284793 0.699484 0.0524059 0.0663334 0.345669 0.931284 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31447 episodes
GETTING ACTION FROM:
action 4, numVisits=31437, meanQ=19.142449, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=4, meanQ=-6.000000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.12929 0.019059 0.426132 0.492847 0.284793 0.699484 0.0524059 0.0663334 0.345669 0.931284 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2678, meanQ=21.886338, numObservations: 9
action 5, numVisits=39, meanQ=20.584744, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 10390 episodes
GETTING ACTION FROM:
action 2, numVisits=13056, meanQ=17.514811, numObservations: 9
action 5, numVisits=51, meanQ=14.665699, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.12929 0.019059 0.426132 0.492847 0.284793 0.699484 0.0524059 0.0663334 0.345669 0.931284 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 46
Initial state: 0 0.308725 0.190095 0.470557 0.418518 0.902483 0.491488 0.75403 0.00503829 0.416772 0.561713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31500 episodes
GETTING ACTION FROM:
action 4, numVisits=31467, meanQ=18.823657, numObservations: 9
action 1, numVisits=28, meanQ=13.775268, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.308725 0.190095 0.470557 0.418518 0.902483 0.491488 0.75403 0.00503829 0.416772 0.561713 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 47
Initial state: 0 0.388536 0.715062 0.947271 0.968987 0.64572 0.635468 0.381583 0.615461 0.530197 0.974481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31955 episodes
GETTING ACTION FROM:
action 1, numVisits=31949, meanQ=17.669013, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.388536 0.715062 0.947271 0.968987 0.64572 0.635468 0.381583 0.615461 0.530197 0.974481 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 48
Initial state: 0 0.267395 0.00640165 0.403315 0.124458 0.867943 0.495752 0.34445 0.604088 0.634856 0.799161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31759 episodes
GETTING ACTION FROM:
action 3, numVisits=31697, meanQ=16.563488, numObservations: 9
action -1, numVisits=29, meanQ=-7.799914, numObservations: 26
action 0, numVisits=29, meanQ=-7.799914, numObservations: 26
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.267395 0.00640165 0.403315 0.124458 0.867943 0.495752 0.34445 0.604088 0.634856 0.799161 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 49
Initial state: 0 0.424346 0.00449705 0.305239 0.498326 0.308494 0.384801 0.0916852 0.506627 0.625881 0.865103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17891 episodes
GETTING ACTION FROM:
action 0, numVisits=17781, meanQ=57.295477, numObservations: 243
action -1, numVisits=96, meanQ=-3.865365, numObservations: 72
action 1, numVisits=10, meanQ=-5.954750, numObservations: 7
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.424346 0.00449705 0.305239 0.498326 0.308494 0.384801 0.0916852 0.506627 0.625881 0.865103 w: 1
Observation: 0 0 1 0 2 0 1 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=47, meanQ=9.411168, numObservations: 26
action -1, numVisits=15, meanQ=-7.510000, numObservations: 14
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17496 episodes
GETTING ACTION FROM:
action 0, numVisits=17543, meanQ=58.905427, numObservations: 216
action -1, numVisits=15, meanQ=-7.510000, numObservations: 14
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.424346 0.00449705 0.305239 0.498326 0.308494 0.384801 0.0916852 0.506627 0.625881 0.865103 w: 1
Observation: 0 0 1 0 2 0 1 0 2 0 3 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=3756, meanQ=55.271908, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33362 episodes
GETTING ACTION FROM:
action 2, numVisits=37118, meanQ=55.185086, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.424346 0.00449705 0.305239 0.498326 0.308494 0.384801 0.0916852 0.506627 0.625881 0.865103 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 50
Initial state: 0 0.0532751 0.393949 0.200925 0.286035 0.436417 0.0189339 0.53888 0.868277 0.404875 0.466552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17702 episodes
GETTING ACTION FROM:
action -1, numVisits=17659, meanQ=50.256572, numObservations: 243
action 0, numVisits=19, meanQ=-1.050000, numObservations: 19
action 1, numVisits=20, meanQ=-3.149625, numObservations: 8
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0532751 0.393949 0.200925 0.286035 0.436417 0.0189339 0.53888 0.868277 0.404875 0.466552 w: 1
Observation: 0 1 0 3 0 2 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=57, meanQ=-4.970833, numObservations: 44
action 1, numVisits=2, meanQ=-10.050000, numObservations: 2
action -1, numVisits=6, meanQ=-17.200000, numObservations: 5
action 2, numVisits=5, meanQ=-21.000000, numObservations: 2
action 4, numVisits=5, meanQ=-21.000000, numObservations: 3
action 5, numVisits=5, meanQ=-21.000000, numObservations: 2
action 3, numVisits=4, meanQ=-28.262500, numObservations: 2
Sampled 21517 episodes
GETTING ACTION FROM:
action 1, numVisits=21519, meanQ=31.992061, numObservations: 9
action 0, numVisits=57, meanQ=-4.970833, numObservations: 44
action -1, numVisits=6, meanQ=-17.200000, numObservations: 5
action 2, numVisits=5, meanQ=-21.000000, numObservations: 2
action 4, numVisits=5, meanQ=-21.000000, numObservations: 3
action 5, numVisits=5, meanQ=-21.000000, numObservations: 2
action 3, numVisits=4, meanQ=-28.262500, numObservations: 2
action: 1
Next state: 0 0.0532751 0.393949 0.200925 0.286035 0.436417 0.0189339 0.53888 0.868277 0.404875 0.466552 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=4538, meanQ=62.188113, numObservations: 9
action 5, numVisits=18, meanQ=38.519722, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 13105 episodes
GETTING ACTION FROM:
action 3, numVisits=17643, meanQ=64.657517, numObservations: 9
action 5, numVisits=18, meanQ=38.519722, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.0532751 0.393949 0.200925 0.286035 0.436417 0.0189339 0.53888 0.868277 0.404875 0.466552 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=207, meanQ=50.315166, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 27158 episodes
GETTING ACTION FROM:
action 5, numVisits=27365, meanQ=46.700524, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.0532751 0.393949 0.200925 0.286035 0.436417 0.0189339 0.53888 0.868277 0.404875 0.466552 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 62.5026
[32m ProblemEnvironment.hpp 351: Done.[39m
