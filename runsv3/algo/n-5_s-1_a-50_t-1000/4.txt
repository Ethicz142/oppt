Run # 1
Initial state: 0 0.631206 0.679821 0.957445 0.673636 0.780271 0.480364 0.182946 0.440295 0.445292 0.420574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17505 episodes
GETTING ACTION FROM:
action -1, numVisits=17441, meanQ=52.754829, numObservations: 243
action 0, numVisits=38, meanQ=-1.150000, numObservations: 36
action 5, numVisits=22, meanQ=-6.270455, numObservations: 8
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.631206 0.679821 0.957445 0.673636 0.780271 0.480364 0.182946 0.440295 0.445292 0.420574 w: 1
Observation: 0 3 0 1 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=91, meanQ=87.584615, numObservations: 7
action 2, numVisits=2, meanQ=44.475000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 39101 episodes
GETTING ACTION FROM:
action 5, numVisits=39192, meanQ=86.904698, numObservations: 9
action 2, numVisits=2, meanQ=44.475000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.631206 0.679821 0.957445 0.673636 0.780271 0.480364 0.182946 0.440295 0.445292 0.420574 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 2
Initial state: 0 0.634096 0.189034 0.432912 0.489303 0.331006 0.729997 0.904928 0.529452 0.791637 0.593549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31438 episodes
GETTING ACTION FROM:
action 2, numVisits=31432, meanQ=28.773961, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.634096 0.189034 0.432912 0.489303 0.331006 0.729997 0.904928 0.529452 0.791637 0.593549 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 3
Initial state: 0 0.0446852 0.568981 0.461955 0.508343 0.0416621 0.906044 0.0580195 0.753832 0.694077 0.299061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30166 episodes
GETTING ACTION FROM:
action 1, numVisits=30156, meanQ=26.589898, numObservations: 9
action 2, numVisits=4, meanQ=-1.000000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0446852 0.568981 0.461955 0.508343 0.0416621 0.906044 0.0580195 0.753832 0.694077 0.299061 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2734, meanQ=36.957616, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 13789 episodes
GETTING ACTION FROM:
action 5, numVisits=13762, meanQ=43.536073, numObservations: 9
action 1, numVisits=2735, meanQ=36.974469, numObservations: 9
action 0, numVisits=13, meanQ=-1.342308, numObservations: 11
action -1, numVisits=12, meanQ=-1.445833, numObservations: 12
action 3, numVisits=6, meanQ=-20.393895, numObservations: 4
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.0446852 0.568981 0.461955 0.508343 0.0416621 0.906044 0.0580195 0.753832 0.694077 0.299061 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 4
Initial state: 0 0.415299 0.530866 0.526856 0.06931 0.744994 0.116823 0.967222 0.347169 0.458267 0.588036 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18106 episodes
GETTING ACTION FROM:
action -1, numVisits=18081, meanQ=52.514466, numObservations: 243
action 0, numVisits=8, meanQ=-1.050000, numObservations: 8
action 1, numVisits=7, meanQ=-2.428571, numObservations: 6
action 3, numVisits=7, meanQ=-2.428571, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.415299 0.530866 0.526856 0.06931 0.744994 0.116823 0.967222 0.347169 0.458267 0.588036 w: 1
Observation: 0 2 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=56, meanQ=25.142054, numObservations: 9
action 5, numVisits=20, meanQ=6.995250, numObservations: 7
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35929 episodes
GETTING ACTION FROM:
action 1, numVisits=35985, meanQ=41.385991, numObservations: 9
action 5, numVisits=20, meanQ=6.995250, numObservations: 7
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.415299 0.530866 0.526856 0.06931 0.744994 0.116823 0.967222 0.347169 0.458267 0.588036 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 5
Initial state: 0 0.416981 0.856171 0.206801 0.174841 0.427415 0.983003 0.944767 0.595955 0.438557 0.512647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31584 episodes
GETTING ACTION FROM:
action 1, numVisits=31550, meanQ=27.662907, numObservations: 9
action 3, numVisits=28, meanQ=17.834018, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.416981 0.856171 0.206801 0.174841 0.427415 0.983003 0.944767 0.595955 0.438557 0.512647 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 6
Initial state: 0 0.435726 0.512165 0.361177 0.462013 0.386096 0.869388 0.773475 0.295592 0.725555 0.593699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31571 episodes
GETTING ACTION FROM:
action 4, numVisits=31561, meanQ=28.555088, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=5, meanQ=-8.719500, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.435726 0.512165 0.361177 0.462013 0.386096 0.869388 0.773475 0.295592 0.725555 0.593699 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 7
Initial state: 0 0.64018 0.585225 0.0627729 0.842201 0.47039 0.531747 0.812527 0.638458 0.202967 0.702852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30976 episodes
GETTING ACTION FROM:
action 5, numVisits=30966, meanQ=27.789172, numObservations: 9
action -1, numVisits=3, meanQ=-1.050000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.64018 0.585225 0.0627729 0.842201 0.47039 0.531747 0.812527 0.638458 0.202967 0.702852 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2805, meanQ=31.449275, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11201 episodes
GETTING ACTION FROM:
action 1, numVisits=14006, meanQ=40.090673, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.64018 0.585225 0.0627729 0.842201 0.47039 0.531747 0.812527 0.638458 0.202967 0.702852 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 8
Initial state: 0 0.396656 0.508334 0.972117 0.806705 0.973385 0.885313 0.553522 0.200991 0.982625 0.646369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31181 episodes
GETTING ACTION FROM:
action 2, numVisits=31173, meanQ=27.617819, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.396656 0.508334 0.972117 0.806705 0.973385 0.885313 0.553522 0.200991 0.982625 0.646369 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 9
Initial state: 0 0.0103367 0.7689 0.959236 0.266437 0.554125 0.426551 0.654052 0.27593 0.49931 0.508993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31633 episodes
GETTING ACTION FROM:
action 1, numVisits=31625, meanQ=28.167197, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0103367 0.7689 0.959236 0.266437 0.554125 0.426551 0.654052 0.27593 0.49931 0.508993 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2774, meanQ=34.723166, numObservations: 9
action 1, numVisits=3, meanQ=26.300000, numObservations: 2
action 3, numVisits=7, meanQ=26.278571, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11476 episodes
GETTING ACTION FROM:
action 2, numVisits=14250, meanQ=40.555613, numObservations: 9
action 1, numVisits=3, meanQ=26.300000, numObservations: 2
action 3, numVisits=7, meanQ=26.278571, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.0103367 0.7689 0.959236 0.266437 0.554125 0.426551 0.654052 0.27593 0.49931 0.508993 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 10
Initial state: 0 0.399587 0.513479 0.650704 0.306376 0.251866 0.946627 0.611983 0.31699 0.814959 0.729559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31467 episodes
GETTING ACTION FROM:
action 2, numVisits=31457, meanQ=28.381259, numObservations: 9
action 4, numVisits=5, meanQ=15.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.399587 0.513479 0.650704 0.306376 0.251866 0.946627 0.611983 0.31699 0.814959 0.729559 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 11
Initial state: 0 0.945326 0.250504 0.95297 0.932358 0.486409 0.397547 0.669776 0.713949 0.809629 0.425066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29515 episodes
GETTING ACTION FROM:
action 2, numVisits=29312, meanQ=28.475223, numObservations: 9
action 4, numVisits=174, meanQ=16.579399, numObservations: 9
action 3, numVisits=23, meanQ=15.139783, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.945326 0.250504 0.95297 0.932358 0.486409 0.397547 0.669776 0.713949 0.809629 0.425066 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 12
Initial state: 0 0.971709 0.98892 0.965017 0.426474 0.419501 0.421692 0.198286 0.339326 0.693961 0.236379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30125 episodes
GETTING ACTION FROM:
action 4, numVisits=30113, meanQ=28.354511, numObservations: 9
action 5, numVisits=5, meanQ=15.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.971709 0.98892 0.965017 0.426474 0.419501 0.421692 0.198286 0.339326 0.693961 0.236379 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2843, meanQ=32.867902, numObservations: 9
action 2, numVisits=10, meanQ=17.190000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 10828 episodes
GETTING ACTION FROM:
action 5, numVisits=13671, meanQ=28.199571, numObservations: 9
action 2, numVisits=10, meanQ=17.190000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 2 0.971709 0.98892 0.965017 0.426474 0.419501 0.421692 0.198286 0.339326 0.693961 0.236379 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 13
Initial state: 0 0.0450498 0.739461 0.406551 0.56596 0.769199 0.864056 0.452463 0.513152 0.980342 0.339915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30998 episodes
GETTING ACTION FROM:
action 2, numVisits=30984, meanQ=27.079339, numObservations: 9
action 1, numVisits=6, meanQ=14.000000, numObservations: 4
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.0450498 0.739461 0.406551 0.56596 0.769199 0.864056 0.452463 0.513152 0.980342 0.339915 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 14
Initial state: 0 0.464846 0.275427 0.538589 0.510384 0.425574 0.477886 0.193491 0.716923 0.184834 0.693205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31670 episodes
GETTING ACTION FROM:
action 5, numVisits=31602, meanQ=27.598155, numObservations: 9
action 4, numVisits=24, meanQ=17.827188, numObservations: 9
action 2, numVisits=26, meanQ=17.605962, numObservations: 9
action 3, numVisits=15, meanQ=15.330167, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.464846 0.275427 0.538589 0.510384 0.425574 0.477886 0.193491 0.716923 0.184834 0.693205 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2805, meanQ=34.784405, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=4, meanQ=-5.525000, numObservations: 4
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 15488 episodes
GETTING ACTION FROM:
action 1, numVisits=18293, meanQ=37.732632, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=4, meanQ=-5.525000, numObservations: 4
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 0 0.464846 0.275427 0.538589 0.510384 0.425574 0.477886 0.193491 0.716923 0.184834 0.693205 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=151, meanQ=9.792261, numObservations: 75
action 0, numVisits=15, meanQ=-1.050000, numObservations: 15
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 8288 episodes
GETTING ACTION FROM:
action -1, numVisits=8439, meanQ=9.053763, numObservations: 243
action 0, numVisits=15, meanQ=-1.050000, numObservations: 15
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.464846 0.275427 0.538589 0.510384 0.425574 0.477886 0.193491 0.716923 0.184834 0.693205 w: 1
Observation: 0 2 0 3 0 2 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=3, meanQ=99.000000, numObservations: 2
action 3, numVisits=2, meanQ=99.000000, numObservations: 2
action 4, numVisits=3, meanQ=99.000000, numObservations: 2
action 5, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-113.492814, numObservations: 1
Sampled 37028 episodes
GETTING ACTION FROM:
action 3, numVisits=37004, meanQ=67.293828, numObservations: 9
action 4, numVisits=12, meanQ=32.333333, numObservations: 6
action 5, numVisits=13, meanQ=29.000000, numObservations: 3
action 2, numVisits=8, meanQ=24.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-113.492814, numObservations: 1
action: 3
Next state: 1 0.464846 0.275427 0.538589 0.510384 0.425574 0.477886 0.193491 0.716923 0.184834 0.693205 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 61.6251
Run # 15
Initial state: 0 0.242765 0.305172 0.564917 0.110901 0.589954 0.788761 0.41247 0.50789 0.817329 0.659046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29938 episodes
GETTING ACTION FROM:
action 4, numVisits=29927, meanQ=29.079220, numObservations: 9
action 3, numVisits=6, meanQ=14.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.242765 0.305172 0.564917 0.110901 0.589954 0.788761 0.41247 0.50789 0.817329 0.659046 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 16
Initial state: 0 0.217385 0.206379 0.590561 0.824196 0.370235 0.968582 0.510931 0.409605 0.495135 0.726752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29707 episodes
GETTING ACTION FROM:
action 4, numVisits=29698, meanQ=29.083425, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.217385 0.206379 0.590561 0.824196 0.370235 0.968582 0.510931 0.409605 0.495135 0.726752 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 17
Initial state: 0 0.331798 0.850284 0.894312 0.173847 0.644343 0.327297 0.738835 0.462035 0.394524 0.463449 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17839 episodes
GETTING ACTION FROM:
action 0, numVisits=17811, meanQ=59.620633, numObservations: 243
action -1, numVisits=21, meanQ=-1.050000, numObservations: 21
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.331798 0.850284 0.894312 0.173847 0.644343 0.327297 0.738835 0.462035 0.394524 0.463449 w: 1
Observation: 0 0 3 0 1 0 1 0 2 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=58, meanQ=63.800991, numObservations: 9
action 5, numVisits=4, meanQ=49.000000, numObservations: 2
action 1, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36626 episodes
GETTING ACTION FROM:
action 4, numVisits=36684, meanQ=66.396092, numObservations: 9
action 5, numVisits=4, meanQ=49.000000, numObservations: 2
action 1, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.331798 0.850284 0.894312 0.173847 0.644343 0.327297 0.738835 0.462035 0.394524 0.463449 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 18
Initial state: 0 0.955017 0.625925 0.565587 0.448687 0.413298 0.399104 0.152058 0.15155 0.298185 0.667725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29874 episodes
GETTING ACTION FROM:
action 3, numVisits=29784, meanQ=28.115375, numObservations: 9
action 2, numVisits=81, meanQ=23.649599, numObservations: 9
action 1, numVisits=5, meanQ=15.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.955017 0.625925 0.565587 0.448687 0.413298 0.399104 0.152058 0.15155 0.298185 0.667725 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 19
Initial state: 0 0.471997 0.477441 0.557591 0.472146 0.869993 0.130731 0.713321 0.86774 0.49641 0.257755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31550 episodes
GETTING ACTION FROM:
action 4, numVisits=31544, meanQ=28.185198, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.471997 0.477441 0.557591 0.472146 0.869993 0.130731 0.713321 0.86774 0.49641 0.257755 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 20
Initial state: 0 0.448475 0.398089 0.883081 0.49864 0.664362 0.787614 0.649256 0.293853 0.483707 0.114677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31508 episodes
GETTING ACTION FROM:
action 2, numVisits=31500, meanQ=27.455637, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.448475 0.398089 0.883081 0.49864 0.664362 0.787614 0.649256 0.293853 0.483707 0.114677 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 21
Initial state: 0 0.770917 0.0204599 0.179747 0.651911 0.990168 0.476511 0.719671 0.600376 0.462363 0.527384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31620 episodes
GETTING ACTION FROM:
action 5, numVisits=31610, meanQ=27.691692, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.770917 0.0204599 0.179747 0.651911 0.990168 0.476511 0.719671 0.600376 0.462363 0.527384 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 22
Initial state: 0 0.433613 0.487714 0.195407 0.795056 0.0836143 0.538724 0.561726 0.891155 0.318115 0.925364 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30383 episodes
GETTING ACTION FROM:
action 2, numVisits=30359, meanQ=28.045820, numObservations: 9
action 4, numVisits=8, meanQ=21.500000, numObservations: 6
action 5, numVisits=9, meanQ=18.338889, numObservations: 5
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.433613 0.487714 0.195407 0.795056 0.0836143 0.538724 0.561726 0.891155 0.318115 0.925364 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2515, meanQ=45.702426, numObservations: 9
action 3, numVisits=45, meanQ=37.596722, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 12361 episodes
GETTING ACTION FROM:
action 3, numVisits=12402, meanQ=45.706923, numObservations: 9
action 2, numVisits=2519, meanQ=45.598288, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.433613 0.487714 0.195407 0.795056 0.0836143 0.538724 0.561726 0.891155 0.318115 0.925364 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=423, meanQ=42.575856, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-12.065718, numObservations: 1
action 3, numVisits=1, meanQ=-12.282863, numObservations: 1
action 2, numVisits=1, meanQ=-215.272867, numObservations: 1
Sampled 10739 episodes
GETTING ACTION FROM:
action 1, numVisits=11161, meanQ=38.078938, numObservations: 9
action 4, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-12.065718, numObservations: 1
action 3, numVisits=1, meanQ=-12.282863, numObservations: 1
action 2, numVisits=1, meanQ=-215.272867, numObservations: 1
action: 1
Next state: 1 0.433613 0.487714 0.195407 0.795056 0.0836143 0.538724 0.561726 0.891155 0.318115 0.925364 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 23
Initial state: 0 0.873314 0.949582 0.469406 0.294672 0.406617 0.527321 0.145549 0.533595 0.543141 0.506944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29358 episodes
GETTING ACTION FROM:
action 2, numVisits=29348, meanQ=27.662969, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=4, meanQ=-6.000000, numObservations: 4
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.873314 0.949582 0.469406 0.294672 0.406617 0.527321 0.145549 0.533595 0.543141 0.506944 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=403, meanQ=30.962083, numObservations: 135
action 2, numVisits=9, meanQ=-4.016667, numObservations: 7
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=9, meanQ=-11.816667, numObservations: 8
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 8372 episodes
GETTING ACTION FROM:
action 0, numVisits=8775, meanQ=18.990525, numObservations: 243
action 2, numVisits=9, meanQ=-4.016667, numObservations: 7
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=9, meanQ=-11.816667, numObservations: 8
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.873314 0.949582 0.469406 0.294672 0.406617 0.527321 0.145549 0.533595 0.543141 0.506944 w: 1
Observation: 0 0 3 0 1 0 2 0 2 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=11, meanQ=62.636364, numObservations: 6
action 5, numVisits=2, meanQ=43.320266, numObservations: 2
action 1, numVisits=2, meanQ=43.220645, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32365 episodes
GETTING ACTION FROM:
action 4, numVisits=32374, meanQ=40.801150, numObservations: 9
action 5, numVisits=3, meanQ=24.606324, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.852904, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.873314 0.949582 0.469406 0.294672 0.406617 0.527321 0.145549 0.533595 0.543141 0.506944 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=40, meanQ=62.051449, numObservations: 7
action 0, numVisits=11, meanQ=-10.964954, numObservations: 9
action 4, numVisits=1, meanQ=-12.137198, numObservations: 1
action -1, numVisits=5, meanQ=-20.430000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-214.128945, numObservations: 1
Sampled 34423 episodes
GETTING ACTION FROM:
action 1, numVisits=34463, meanQ=51.683253, numObservations: 9
action 0, numVisits=11, meanQ=-10.964954, numObservations: 9
action 4, numVisits=1, meanQ=-12.137198, numObservations: 1
action -1, numVisits=5, meanQ=-20.430000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-214.128945, numObservations: 1
action: 1
Next state: 1 0.873314 0.949582 0.469406 0.294672 0.406617 0.527321 0.145549 0.533595 0.543141 0.506944 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 62.0526
Run # 24
Initial state: 0 0.426518 0.39474 0.876945 0.769576 0.124573 0.397185 0.490901 0.710039 0.914846 0.804915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18027 episodes
GETTING ACTION FROM:
action 0, numVisits=17978, meanQ=60.204551, numObservations: 243
action -1, numVisits=42, meanQ=-3.588988, numObservations: 36
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.426518 0.39474 0.876945 0.769576 0.124573 0.397185 0.490901 0.710039 0.914846 0.804915 w: 1
Observation: 0 0 2 0 3 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=75, meanQ=54.324167, numObservations: 9
action 2, numVisits=14, meanQ=45.885893, numObservations: 6
action 5, numVisits=7, meanQ=39.271429, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
Sampled 34980 episodes
GETTING ACTION FROM:
action 4, numVisits=35055, meanQ=68.248463, numObservations: 9
action 2, numVisits=14, meanQ=45.885893, numObservations: 6
action 5, numVisits=7, meanQ=39.271429, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 4
Next state: 1 0.426518 0.39474 0.876945 0.769576 0.124573 0.397185 0.490901 0.710039 0.914846 0.804915 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 25
Initial state: 0 0.463329 0.683116 0.529497 0.318511 0.626868 0.599434 0.410268 0.408317 0.459571 0.910915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31195 episodes
GETTING ACTION FROM:
action 5, numVisits=31188, meanQ=28.616896, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.463329 0.683116 0.529497 0.318511 0.626868 0.599434 0.410268 0.408317 0.459571 0.910915 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 26
Initial state: 0 0.0481887 0.579413 0.415285 0.437398 0.398436 0.316524 0.958184 0.399019 0.00869166 0.912477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31444 episodes
GETTING ACTION FROM:
action 2, numVisits=31422, meanQ=28.879886, numObservations: 9
action 1, numVisits=14, meanQ=0.318393, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0481887 0.579413 0.415285 0.437398 0.398436 0.316524 0.958184 0.399019 0.00869166 0.912477 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 27
Initial state: 0 0.265229 0.992674 0.171148 0.867008 0.653134 0.898633 0.279966 0.955622 0.503565 0.412731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18060 episodes
GETTING ACTION FROM:
action 0, numVisits=18011, meanQ=58.398264, numObservations: 243
action -1, numVisits=44, meanQ=-3.338636, numObservations: 41
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.265229 0.992674 0.171148 0.867008 0.653134 0.898633 0.279966 0.955622 0.503565 0.412731 w: 1
Observation: 0 0 3 0 3 0 3 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=55, meanQ=76.368182, numObservations: 9
action 4, numVisits=7, meanQ=66.343214, numObservations: 4
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34761 episodes
GETTING ACTION FROM:
action 2, numVisits=34815, meanQ=69.345076, numObservations: 9
action 4, numVisits=8, meanQ=56.794062, numObservations: 4
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.265229 0.992674 0.171148 0.867008 0.653134 0.898633 0.279966 0.955622 0.503565 0.412731 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=4361, meanQ=77.710688, numObservations: 9
action 4, numVisits=5, meanQ=59.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 14603 episodes
GETTING ACTION FROM:
action 1, numVisits=18964, meanQ=79.769008, numObservations: 9
action 4, numVisits=5, meanQ=59.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.265229 0.992674 0.171148 0.867008 0.653134 0.898633 0.279966 0.955622 0.503565 0.412731 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 28
Initial state: 0 0.141552 0.459223 0.867795 0.919094 0.425304 0.0390437 0.582568 0.23076 0.42854 0.414347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29423 episodes
GETTING ACTION FROM:
action 2, numVisits=29413, meanQ=30.105858, numObservations: 9
action 1, numVisits=5, meanQ=15.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.141552 0.459223 0.867795 0.919094 0.425304 0.0390437 0.582568 0.23076 0.42854 0.414347 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 29
Initial state: 0 0.567011 0.0267254 0.00991679 0.124654 0.300212 0.770717 0.234459 0.789355 0.443599 0.505549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17913 episodes
GETTING ACTION FROM:
action 0, numVisits=17872, meanQ=59.216284, numObservations: 243
action -1, numVisits=29, meanQ=-1.117155, numObservations: 28
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=6, meanQ=-4.499583, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.567011 0.0267254 0.00991679 0.124654 0.300212 0.770717 0.234459 0.789355 0.443599 0.505549 w: 1
Observation: 0 0 1 0 1 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=84, meanQ=88.086369, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38530 episodes
GETTING ACTION FROM:
action 5, numVisits=38614, meanQ=85.150642, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.567011 0.0267254 0.00991679 0.124654 0.300212 0.770717 0.234459 0.789355 0.443599 0.505549 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 30
Initial state: 0 0.467776 0.531214 0.540549 0.635128 0.780037 0.891253 0.0510163 0.469677 0.644792 0.692505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31298 episodes
GETTING ACTION FROM:
action 2, numVisits=31292, meanQ=27.245162, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.467776 0.531214 0.540549 0.635128 0.780037 0.891253 0.0510163 0.469677 0.644792 0.692505 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 31
Initial state: 0 0.619063 0.31742 0.280471 0.447249 0.262717 0.216263 0.375349 0.957439 0.457418 0.466409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31025 episodes
GETTING ACTION FROM:
action 5, numVisits=31006, meanQ=28.295437, numObservations: 9
action 4, numVisits=7, meanQ=13.285714, numObservations: 5
action 3, numVisits=6, meanQ=9.075417, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.619063 0.31742 0.280471 0.447249 0.262717 0.216263 0.375349 0.957439 0.457418 0.466409 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 32
Initial state: 0 0.510451 0.455871 0.461004 0.772776 0.0724607 0.734948 0.495919 0.0115093 0.810147 0.939132 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30042 episodes
GETTING ACTION FROM:
action 1, numVisits=30028, meanQ=28.195175, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=7, meanQ=-3.278571, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.510451 0.455871 0.461004 0.772776 0.0724607 0.734948 0.495919 0.0115093 0.810147 0.939132 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 33
Initial state: 0 0.372702 0.690403 0.45808 0.457323 0.859432 0.800068 0.215036 0.976577 0.457788 0.18458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28408 episodes
GETTING ACTION FROM:
action 5, numVisits=28400, meanQ=29.804537, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.372702 0.690403 0.45808 0.457323 0.859432 0.800068 0.215036 0.976577 0.457788 0.18458 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 34
Initial state: 0 0.380137 0.204774 0.498484 0.513258 0.0117931 0.225123 0.224484 0.478189 0.366879 0.474873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17836 episodes
GETTING ACTION FROM:
action -1, numVisits=17820, meanQ=52.421395, numObservations: 243
action 0, numVisits=11, meanQ=-1.050000, numObservations: 11
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.380137 0.204774 0.498484 0.513258 0.0117931 0.225123 0.224484 0.478189 0.366879 0.474873 w: 1
Observation: 0 1 0 2 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=60, meanQ=75.629292, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37584 episodes
GETTING ACTION FROM:
action 2, numVisits=37644, meanQ=86.881763, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.380137 0.204774 0.498484 0.513258 0.0117931 0.225123 0.224484 0.478189 0.366879 0.474873 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 35
Initial state: 0 0.610232 0.694564 0.505733 0.713475 0.512532 0.419022 0.60848 0.347726 0.684167 0.571717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29888 episodes
GETTING ACTION FROM:
action 2, numVisits=29881, meanQ=28.399313, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.610232 0.694564 0.505733 0.713475 0.512532 0.419022 0.60848 0.347726 0.684167 0.571717 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 36
Initial state: 0 0.449626 0.499982 0.567138 0.652792 0.0829008 0.293685 0.445572 0.592393 0.180575 0.919341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17689 episodes
GETTING ACTION FROM:
action 0, numVisits=17662, meanQ=59.406471, numObservations: 243
action -1, numVisits=17, meanQ=-1.050000, numObservations: 17
action 3, numVisits=4, meanQ=-6.000000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 0
Next state: 0 0.449626 0.499982 0.567138 0.652792 0.0829008 0.293685 0.445572 0.592393 0.180575 0.919341 w: 1
Observation: 0 0 2 0 1 0 1 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=40, meanQ=57.545125, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35862 episodes
GETTING ACTION FROM:
action 4, numVisits=35902, meanQ=61.796787, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.449626 0.499982 0.567138 0.652792 0.0829008 0.293685 0.445572 0.592393 0.180575 0.919341 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 37
Initial state: 0 0.492844 0.907092 0.955371 0.560723 0.40624 0.422899 0.993055 0.648135 0.0165961 0.6219 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30087 episodes
GETTING ACTION FROM:
action 3, numVisits=30078, meanQ=28.941937, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.492844 0.907092 0.955371 0.560723 0.40624 0.422899 0.993055 0.648135 0.0165961 0.6219 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 38
Initial state: 0 0.307202 0.0253008 0.409021 0.455568 0.330621 0.93419 0.086506 0.738629 0.143341 0.391394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29768 episodes
GETTING ACTION FROM:
action 4, numVisits=29749, meanQ=28.680111, numObservations: 9
action 2, numVisits=11, meanQ=4.363864, numObservations: 8
action 3, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.307202 0.0253008 0.409021 0.455568 0.330621 0.93419 0.086506 0.738629 0.143341 0.391394 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=2572, meanQ=54.857345, numObservations: 210
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 0, numVisits=13, meanQ=-8.503846, numObservations: 12
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 4853 episodes
GETTING ACTION FROM:
action -1, numVisits=7425, meanQ=41.622522, numObservations: 243
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 0, numVisits=13, meanQ=-8.503846, numObservations: 12
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.307202 0.0253008 0.409021 0.455568 0.330621 0.93419 0.086506 0.738629 0.143341 0.391394 w: 1
Observation: 0 1 0 2 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-12.047753, numObservations: 1
action 4, numVisits=1, meanQ=-215.404363, numObservations: 1
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 33707 episodes
GETTING ACTION FROM:
action 2, numVisits=33704, meanQ=90.861758, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 5, numVisits=1, meanQ=-12.047753, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-215.404363, numObservations: 1
action: 2
Next state: 1 0.307202 0.0253008 0.409021 0.455568 0.330621 0.93419 0.086506 0.738629 0.143341 0.391394 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 39
Initial state: 0 0.200983 0.199211 0.238525 0.929532 0.8129 0.369567 0.655791 0.865126 0.415463 0.457453 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31249 episodes
GETTING ACTION FROM:
action 4, numVisits=31238, meanQ=28.015886, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-6.316667, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.200983 0.199211 0.238525 0.929532 0.8129 0.369567 0.655791 0.865126 0.415463 0.457453 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 40
Initial state: 0 0.849144 0.599711 0.898998 0.242456 0.427215 0.921414 0.427412 0.435301 0.953021 0.822161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29650 episodes
GETTING ACTION FROM:
action 2, numVisits=29642, meanQ=28.583716, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.849144 0.599711 0.898998 0.242456 0.427215 0.921414 0.427412 0.435301 0.953021 0.822161 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 41
Initial state: 0 0.793814 0.813929 0.459836 0.410697 0.048035 0.140951 0.57438 0.04555 0.468321 0.08548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28676 episodes
GETTING ACTION FROM:
action 4, numVisits=28668, meanQ=30.160302, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.793814 0.813929 0.459836 0.410697 0.048035 0.140951 0.57438 0.04555 0.468321 0.08548 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 42
Initial state: 0 0.804004 0.566013 0.433538 0.396514 0.302454 0.296389 0.858296 0.216462 0.658847 0.0210175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29990 episodes
GETTING ACTION FROM:
action 2, numVisits=29982, meanQ=29.100004, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.804004 0.566013 0.433538 0.396514 0.302454 0.296389 0.858296 0.216462 0.658847 0.0210175 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 43
Initial state: 0 0.791232 0.0269858 0.021846 0.63917 0.424044 0.371477 0.503513 0.53159 0.737559 0.536074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28498 episodes
GETTING ACTION FROM:
action 3, numVisits=28486, meanQ=31.438928, numObservations: 9
action 1, numVisits=4, meanQ=21.500000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 3
Next state: 2 0.791232 0.0269858 0.021846 0.63917 0.424044 0.371477 0.503513 0.53159 0.737559 0.536074 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 44
Initial state: 0 0.851406 0.511441 0.490743 0.308986 0.915144 0.090114 0.515432 0.536436 0.812065 0.292322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31325 episodes
GETTING ACTION FROM:
action 3, numVisits=31318, meanQ=27.943763, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.851406 0.511441 0.490743 0.308986 0.915144 0.090114 0.515432 0.536436 0.812065 0.292322 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 45
Initial state: 0 0.450693 0.537142 0.125785 0.753903 0.376532 0.430376 0.698226 0.935986 0.431283 0.0245562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31030 episodes
GETTING ACTION FROM:
action 4, numVisits=31013, meanQ=27.524400, numObservations: 9
action 2, numVisits=11, meanQ=16.272727, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.450693 0.537142 0.125785 0.753903 0.376532 0.430376 0.698226 0.935986 0.431283 0.0245562 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 46
Initial state: 0 0.787452 0.174908 0.850139 0.74646 0.912988 0.677495 0.89855 0.412066 0.475845 0.413001 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31535 episodes
GETTING ACTION FROM:
action 5, numVisits=31519, meanQ=28.105396, numObservations: 9
action 3, numVisits=8, meanQ=19.625000, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.787452 0.174908 0.850139 0.74646 0.912988 0.677495 0.89855 0.412066 0.475845 0.413001 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 47
Initial state: 0 0.395052 0.495249 0.90585 0.691942 0.351361 0.524436 0.716737 0.129168 0.819517 0.561679 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18285 episodes
GETTING ACTION FROM:
action 0, numVisits=18206, meanQ=60.249776, numObservations: 243
action -1, numVisits=51, meanQ=-1.237206, numObservations: 46
action 4, numVisits=15, meanQ=-3.000000, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=6, meanQ=-19.333333, numObservations: 5
action 3, numVisits=5, meanQ=-21.000000, numObservations: 4
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.395052 0.495249 0.90585 0.691942 0.351361 0.524436 0.716737 0.129168 0.819517 0.561679 w: 1
Observation: 0 0 2 0 3 0 2 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=75, meanQ=47.005400, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36136 episodes
GETTING ACTION FROM:
action 1, numVisits=36211, meanQ=62.291033, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.395052 0.495249 0.90585 0.691942 0.351361 0.524436 0.716737 0.129168 0.819517 0.561679 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=1358, meanQ=88.063399, numObservations: 9
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 35099 episodes
GETTING ACTION FROM:
action 1, numVisits=1366, meanQ=88.103752, numObservations: 9
action 2, numVisits=35093, meanQ=81.516503, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.395052 0.495249 0.90585 0.691942 0.351361 0.524436 0.716737 0.129168 0.819517 0.561679 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 48
Initial state: 0 0.145093 0.633097 0.416642 0.507211 0.744905 0.597893 0.877997 0.555665 0.962667 0.574612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 31472 episodes
GETTING ACTION FROM:
action 4, numVisits=31459, meanQ=27.735204, numObservations: 9
action 1, numVisits=8, meanQ=21.500000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.145093 0.633097 0.416642 0.507211 0.744905 0.597893 0.877997 0.555665 0.962667 0.574612 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 49
Initial state: 0 0.840694 0.0213469 0.778585 0.348102 0.141224 0.639685 0.425519 0.501836 0.288891 0.712996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18005 episodes
GETTING ACTION FROM:
action 0, numVisits=17988, meanQ=57.189708, numObservations: 243
action 5, numVisits=4, meanQ=-5.762500, numObservations: 3
action 3, numVisits=4, meanQ=-6.249375, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=6, meanQ=-17.200000, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.840694 0.0213469 0.778585 0.348102 0.141224 0.639685 0.425519 0.501836 0.288891 0.712996 w: 1
Observation: 0 0 1 0 1 0 3 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=100, meanQ=66.336600, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32460 episodes
GETTING ACTION FROM:
action 3, numVisits=32560, meanQ=66.293666, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.840694 0.0213469 0.778585 0.348102 0.141224 0.639685 0.425519 0.501836 0.288891 0.712996 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 50
Initial state: 0 0.448391 0.443016 0.707196 0.29043 0.968144 0.360917 0.275097 0.824904 0.662418 0.169545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30112 episodes
GETTING ACTION FROM:
action 2, numVisits=30074, meanQ=28.741738, numObservations: 9
action -1, numVisits=14, meanQ=-1.050000, numObservations: 14
action 0, numVisits=14, meanQ=-1.050000, numObservations: 14
action 5, numVisits=5, meanQ=-3.000000, numObservations: 4
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.448391 0.443016 0.707196 0.29043 0.968144 0.360917 0.275097 0.824904 0.662418 0.169545 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
[32m ProblemEnvironment.hpp 351: Done.[39m
