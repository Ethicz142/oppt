Run # 1
Initial state: 0 0.496564 0.994735 0.0678662 0.236853 0.186515 0.744194 0.547958 0.828501 0.551653 0.605642 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17444 episodes
GETTING ACTION FROM:
action 0, numVisits=17400, meanQ=52.164740, numObservations: 243
action -1, numVisits=37, meanQ=-4.288986, numObservations: 33
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.496564 0.994735 0.0678662 0.236853 0.186515 0.744194 0.547958 0.828501 0.551653 0.605642 w: 1
Observation: 0 0 3 0 1 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=58, meanQ=87.300043, numObservations: 7
action 4, numVisits=3, meanQ=62.650000, numObservations: 2
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36756 episodes
GETTING ACTION FROM:
action 5, numVisits=36814, meanQ=84.256177, numObservations: 9
action 4, numVisits=3, meanQ=62.650000, numObservations: 2
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.496564 0.994735 0.0678662 0.236853 0.186515 0.744194 0.547958 0.828501 0.551653 0.605642 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 2
Initial state: 0 0.0149955 0.988796 0.557672 0.459445 0.663609 0.587753 0.808835 0.325299 0.139086 0.272563 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17800 episodes
GETTING ACTION FROM:
action 0, numVisits=17781, meanQ=53.003000, numObservations: 243
action -1, numVisits=14, meanQ=-1.799821, numObservations: 13
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0149955 0.988796 0.557672 0.459445 0.663609 0.587753 0.808835 0.325299 0.139086 0.272563 w: 1
Observation: 0 0 3 0 1 0 1 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=57, meanQ=58.950482, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 26969 episodes
GETTING ACTION FROM:
action 1, numVisits=27026, meanQ=60.278693, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 0 0.0149955 0.988796 0.557672 0.459445 0.663609 0.587753 0.808835 0.325299 0.139086 0.272563 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=5466, meanQ=63.569053, numObservations: 159
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=8, meanQ=-13.162500, numObservations: 7
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5562 episodes
GETTING ACTION FROM:
action 0, numVisits=11028, meanQ=54.422457, numObservations: 187
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=8, meanQ=-13.162500, numObservations: 7
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.0149955 0.988796 0.557672 0.459445 0.663609 0.587753 0.808835 0.325299 0.139086 0.272563 w: 1
Observation: 0 0 3 0 1 0 2 0 1 0 2 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=203, meanQ=74.680456, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 24339 episodes
GETTING ACTION FROM:
action 3, numVisits=24542, meanQ=76.882432, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.0149955 0.988796 0.557672 0.459445 0.663609 0.587753 0.808835 0.325299 0.139086 0.272563 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 70.6251
Run # 3
Initial state: 0 0.660958 0.0690504 0.694308 0.728166 0.0178639 0.0315261 0.00150594 0.523797 0.586394 0.57523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17483 episodes
GETTING ACTION FROM:
action 0, numVisits=17464, meanQ=54.444319, numObservations: 243
action -1, numVisits=14, meanQ=-1.467321, numObservations: 11
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.660958 0.0690504 0.694308 0.728166 0.0178639 0.0315261 0.00150594 0.523797 0.586394 0.57523 w: 1
Observation: 0 0 1 0 3 0 1 0 2 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=63, meanQ=44.189841, numObservations: 8
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32887 episodes
GETTING ACTION FROM:
action 5, numVisits=32950, meanQ=56.077597, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.660958 0.0690504 0.694308 0.728166 0.0178639 0.0315261 0.00150594 0.523797 0.586394 0.57523 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 4
Initial state: 0 0.481653 0.326135 0.512066 0.90903 0.47393 0.471549 0.678232 0.537685 0.915307 0.48138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17955 episodes
GETTING ACTION FROM:
action -1, numVisits=17897, meanQ=44.847774, numObservations: 243
action 3, numVisits=46, meanQ=-1.415109, numObservations: 8
action 0, numVisits=8, meanQ=-2.362188, numObservations: 7
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.481653 0.326135 0.512066 0.90903 0.47393 0.471549 0.678232 0.537685 0.915307 0.48138 w: 1
Observation: 0 1 0 3 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=37, meanQ=22.062230, numObservations: 8
action 0, numVisits=27, meanQ=-4.927407, numObservations: 22
action -1, numVisits=12, meanQ=-9.287292, numObservations: 10
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38232 episodes
GETTING ACTION FROM:
action 5, numVisits=38269, meanQ=13.824622, numObservations: 9
action 0, numVisits=27, meanQ=-4.927407, numObservations: 22
action -1, numVisits=12, meanQ=-9.287292, numObservations: 10
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.481653 0.326135 0.512066 0.90903 0.47393 0.471549 0.678232 0.537685 0.915307 0.48138 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 5
Initial state: 0 0.0995964 0.800859 0.639194 0.522447 0.957296 0.96597 0.869769 0.793817 0.564025 0.045218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25579 episodes
GETTING ACTION FROM:
action 4, numVisits=25568, meanQ=23.237557, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0995964 0.800859 0.639194 0.522447 0.957296 0.96597 0.869769 0.793817 0.564025 0.045218 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 6
Initial state: 0 0.79892 0.500884 0.59053 0.195857 0.50976 0.564312 0.577411 0.130634 0.73871 0.0576609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26100 episodes
GETTING ACTION FROM:
action 1, numVisits=26091, meanQ=23.377371, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.79892 0.500884 0.59053 0.195857 0.50976 0.564312 0.577411 0.130634 0.73871 0.0576609 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 7
Initial state: 0 0.0279734 0.332879 0.502156 0.484606 0.439701 0.191453 0.55965 0.415628 0.908817 0.913958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27259 episodes
GETTING ACTION FROM:
action 3, numVisits=27252, meanQ=21.368886, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.0279734 0.332879 0.502156 0.484606 0.439701 0.191453 0.55965 0.415628 0.908817 0.913958 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 8
Initial state: 0 0.188651 0.570587 0.846616 0.218433 0.641442 0.476756 0.889134 0.675869 0.180749 0.336203 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27438 episodes
GETTING ACTION FROM:
action 1, numVisits=27345, meanQ=21.047759, numObservations: 9
action 0, numVisits=61, meanQ=-2.842541, numObservations: 58
action -1, numVisits=28, meanQ=-4.955179, numObservations: 25
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.188651 0.570587 0.846616 0.218433 0.641442 0.476756 0.889134 0.675869 0.180749 0.336203 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 9
Initial state: 0 0.598596 0.140702 0.637786 0.498256 0.844555 0.670283 0.320411 0.582334 0.461812 0.661093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17895 episodes
GETTING ACTION FROM:
action 0, numVisits=17867, meanQ=55.113465, numObservations: 243
action -1, numVisits=21, meanQ=-1.230952, numObservations: 19
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.598596 0.140702 0.637786 0.498256 0.844555 0.670283 0.320411 0.582334 0.461812 0.661093 w: 1
Observation: 0 0 1 0 2 0 3 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=53, meanQ=74.852358, numObservations: 7
action 4, numVisits=7, meanQ=54.850000, numObservations: 5
action 5, numVisits=7, meanQ=54.850000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31537 episodes
GETTING ACTION FROM:
action 3, numVisits=31576, meanQ=55.472297, numObservations: 9
action 4, numVisits=8, meanQ=46.737500, numObservations: 5
action 5, numVisits=20, meanQ=45.770250, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.598596 0.140702 0.637786 0.498256 0.844555 0.670283 0.320411 0.582334 0.461812 0.661093 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 10
Initial state: 0 0.991744 0.689551 0.506836 0.511104 0.995656 0.445133 0.942096 0.515807 0.934595 0.271657 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28322 episodes
GETTING ACTION FROM:
action 1, numVisits=28296, meanQ=19.389050, numObservations: 9
action 5, numVisits=5, meanQ=15.190000, numObservations: 4
action 4, numVisits=16, meanQ=14.084688, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.991744 0.689551 0.506836 0.511104 0.995656 0.445133 0.942096 0.515807 0.934595 0.271657 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 11
Initial state: 0 0.51231 0.507731 0.521991 0.200576 0.62051 0.231437 0.525537 0.357374 0.75059 0.970631 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25721 episodes
GETTING ACTION FROM:
action 5, numVisits=25700, meanQ=23.718775, numObservations: 9
action 1, numVisits=12, meanQ=19.000000, numObservations: 6
action 4, numVisits=4, meanQ=16.975000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.51231 0.507731 0.521991 0.200576 0.62051 0.231437 0.525537 0.357374 0.75059 0.970631 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 12
Initial state: 0 0.500125 0.400543 0.505705 0.592959 0.229786 0.433561 0.0789411 0.0498287 0.0416251 0.0180033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26955 episodes
GETTING ACTION FROM:
action 5, numVisits=25694, meanQ=19.789719, numObservations: 9
action 4, numVisits=1164, meanQ=16.232311, numObservations: 9
action 3, numVisits=82, meanQ=14.492144, numObservations: 9
action 1, numVisits=12, meanQ=10.575625, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.500125 0.400543 0.505705 0.592959 0.229786 0.433561 0.0789411 0.0498287 0.0416251 0.0180033 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3883, meanQ=26.565420, numObservations: 9
action 3, numVisits=6, meanQ=14.158333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 8439 episodes
GETTING ACTION FROM:
action 2, numVisits=12322, meanQ=26.418292, numObservations: 9
action 3, numVisits=6, meanQ=14.158333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.500125 0.400543 0.505705 0.592959 0.229786 0.433561 0.0789411 0.0498287 0.0416251 0.0180033 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 13
Initial state: 0 0.600482 0.5941 0.410199 0.447623 0.180264 0.592933 0.421841 0.169096 0.579061 0.0526888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28133 episodes
GETTING ACTION FROM:
action 3, numVisits=28122, meanQ=20.090109, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=5, meanQ=-7.000000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.600482 0.5941 0.410199 0.447623 0.180264 0.592933 0.421841 0.169096 0.579061 0.0526888 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1458, meanQ=21.348289, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5986 episodes
GETTING ACTION FROM:
action 4, numVisits=7444, meanQ=21.920156, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.600482 0.5941 0.410199 0.447623 0.180264 0.592933 0.421841 0.169096 0.579061 0.0526888 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=948, meanQ=51.437400, numObservations: 123
action 0, numVisits=6, meanQ=-1.050000, numObservations: 6
action 1, numVisits=7, meanQ=-3.142857, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 2621 episodes
GETTING ACTION FROM:
action -1, numVisits=3569, meanQ=42.193878, numObservations: 187
action 0, numVisits=6, meanQ=-1.050000, numObservations: 6
action 1, numVisits=7, meanQ=-3.142857, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.600482 0.5941 0.410199 0.447623 0.180264 0.592933 0.421841 0.169096 0.579061 0.0526888 w: 1
Observation: 0 2 0 3 0 1 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=18, meanQ=29.772822, numObservations: 6
action 2, numVisits=17, meanQ=-8.256684, numObservations: 8
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=9, meanQ=-13.337305, numObservations: 7
action 0, numVisits=7, meanQ=-15.171071, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 12057 episodes
GETTING ACTION FROM:
action 5, numVisits=12075, meanQ=34.217251, numObservations: 9
action 2, numVisits=17, meanQ=-8.256684, numObservations: 8
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=9, meanQ=-13.337305, numObservations: 7
action 0, numVisits=7, meanQ=-15.171071, numObservations: 5
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.600482 0.5941 0.410199 0.447623 0.180264 0.592933 0.421841 0.169096 0.579061 0.0526888 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -109.85
Run # 14
Initial state: 0 0.517093 0.831942 0.178863 0.374678 0.697167 0.343368 0.509592 0.53532 0.107639 0.210775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 24980 episodes
GETTING ACTION FROM:
action 2, numVisits=24972, meanQ=23.175708, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.517093 0.831942 0.178863 0.374678 0.697167 0.343368 0.509592 0.53532 0.107639 0.210775 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=3723, meanQ=45.497468, numObservations: 223
action 0, numVisits=13, meanQ=-1.857500, numObservations: 12
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 3900 episodes
GETTING ACTION FROM:
action -1, numVisits=7623, meanQ=41.768140, numObservations: 241
action 0, numVisits=13, meanQ=-1.857500, numObservations: 12
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: -1
Next state: 0 0.517093 0.831942 0.178863 0.374678 0.697167 0.343368 0.509592 0.53532 0.107639 0.210775 w: 1
Observation: 0 2 0 3 0 2 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=99.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 12785 episodes
GETTING ACTION FROM:
action 3, numVisits=12711, meanQ=30.021114, numObservations: 9
action -1, numVisits=64, meanQ=-0.699003, numObservations: 38
action 0, numVisits=8, meanQ=-1.768437, numObservations: 6
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.517093 0.831942 0.178863 0.374678 0.697167 0.343368 0.509592 0.53532 0.107639 0.210775 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -104.053
Run # 15
Initial state: 0 0.590365 0.60962 0.198988 0.748521 0.73169 0.420953 0.48095 0.849184 0.0305478 0.203837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17625 episodes
GETTING ACTION FROM:
action -1, numVisits=17598, meanQ=42.187460, numObservations: 243
action 0, numVisits=15, meanQ=-7.510000, numObservations: 14
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=8, meanQ=-14.750000, numObservations: 5
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.590365 0.60962 0.198988 0.748521 0.73169 0.420953 0.48095 0.849184 0.0305478 0.203837 w: 1
Observation: 0 3 0 1 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=77, meanQ=13.996753, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35657 episodes
GETTING ACTION FROM:
action 1, numVisits=35734, meanQ=19.570758, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.590365 0.60962 0.198988 0.748521 0.73169 0.420953 0.48095 0.849184 0.0305478 0.203837 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=265, meanQ=51.667604, numObservations: 58
action 3, numVisits=20, meanQ=-8.560000, numObservations: 8
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=5, meanQ=-20.430000, numObservations: 4
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 15284 episodes
GETTING ACTION FROM:
action -1, numVisits=15549, meanQ=5.416091, numObservations: 198
action 3, numVisits=20, meanQ=-8.560000, numObservations: 8
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=5, meanQ=-20.430000, numObservations: 4
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.590365 0.60962 0.198988 0.748521 0.73169 0.420953 0.48095 0.849184 0.0305478 0.203837 w: 1
Observation: 0 2 0 1 0 3 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=4, meanQ=99.000000, numObservations: 4
action -1, numVisits=119, meanQ=47.452516, numObservations: 27
action 0, numVisits=13, meanQ=-2.016828, numObservations: 12
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 20185 episodes
GETTING ACTION FROM:
action 1, numVisits=5, meanQ=59.000000, numObservations: 4
action -1, numVisits=20303, meanQ=13.175498, numObservations: 168
action 0, numVisits=13, meanQ=-2.016828, numObservations: 12
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.590365 0.60962 0.198988 0.748521 0.73169 0.420953 0.48095 0.849184 0.0305478 0.203837 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 70.6251
Run # 16
Initial state: 0 0.140498 0.569936 0.792722 0.781189 0.437333 0.0235427 0.597212 0.56535 0.530068 0.171017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17682 episodes
GETTING ACTION FROM:
action 0, numVisits=17644, meanQ=52.853003, numObservations: 243
action -1, numVisits=14, meanQ=-1.799821, numObservations: 13
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=18, meanQ=-4.499583, numObservations: 7
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.140498 0.569936 0.792722 0.781189 0.437333 0.0235427 0.597212 0.56535 0.530068 0.171017 w: 1
Observation: 0 0 2 0 1 0 1 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=92, meanQ=54.482853, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 30793 episodes
GETTING ACTION FROM:
action 1, numVisits=30885, meanQ=46.095227, numObservations: 9
action 4, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.140498 0.569936 0.792722 0.781189 0.437333 0.0235427 0.597212 0.56535 0.530068 0.171017 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 17
Initial state: 0 0.879379 0.868469 0.514732 0.574625 0.704828 0.307923 0.910923 0.429642 0.209271 0.975869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27539 episodes
GETTING ACTION FROM:
action 4, numVisits=27533, meanQ=20.816091, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.879379 0.868469 0.514732 0.574625 0.704828 0.307923 0.910923 0.429642 0.209271 0.975869 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 18
Initial state: 0 0.699736 0.0255083 0.642309 0.17694 0.602784 0.832461 0.554667 0.488683 0.853494 0.262941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27204 episodes
GETTING ACTION FROM:
action 3, numVisits=27192, meanQ=21.467544, numObservations: 9
action 2, numVisits=4, meanQ=-1.000000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.699736 0.0255083 0.642309 0.17694 0.602784 0.832461 0.554667 0.488683 0.853494 0.262941 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 19
Initial state: 0 0.825423 0.938777 0.993536 0.440981 0.658724 0.584781 0.395478 0.826466 0.296462 0.639258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25842 episodes
GETTING ACTION FROM:
action 1, numVisits=25829, meanQ=24.711834, numObservations: 9
action 5, numVisits=7, meanQ=9.578571, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.825423 0.938777 0.993536 0.440981 0.658724 0.584781 0.395478 0.826466 0.296462 0.639258 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 20
Initial state: 0 0.423559 0.395351 0.154698 0.24769 0.12994 0.535164 0.740441 0.708631 0.584814 0.490199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28061 episodes
GETTING ACTION FROM:
action 1, numVisits=28039, meanQ=19.101658, numObservations: 9
action -1, numVisits=9, meanQ=-1.050000, numObservations: 9
action 0, numVisits=9, meanQ=-1.050000, numObservations: 9
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.423559 0.395351 0.154698 0.24769 0.12994 0.535164 0.740441 0.708631 0.584814 0.490199 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=4189, meanQ=24.927953, numObservations: 9
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 6585 episodes
GETTING ACTION FROM:
action 5, numVisits=10774, meanQ=23.813964, numObservations: 9
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.423559 0.395351 0.154698 0.24769 0.12994 0.535164 0.740441 0.708631 0.584814 0.490199 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 21
Initial state: 0 0.602237 0.626163 0.21529 0.136274 0.42748 0.292456 0.22701 0.199899 0.763261 0.177311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27945 episodes
GETTING ACTION FROM:
action 1, numVisits=27936, meanQ=19.088403, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=4, meanQ=-5.762500, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.602237 0.626163 0.21529 0.136274 0.42748 0.292456 0.22701 0.199899 0.763261 0.177311 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 22
Initial state: 0 0.674985 0.567355 0.205813 0.825238 0.910257 0.911459 0.845341 0.00731335 0.371823 0.247696 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17804 episodes
GETTING ACTION FROM:
action -1, numVisits=17777, meanQ=44.017727, numObservations: 243
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 0, numVisits=20, meanQ=-5.895000, numObservations: 19
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.674985 0.567355 0.205813 0.825238 0.910257 0.911459 0.845341 0.00731335 0.371823 0.247696 w: 1
Observation: 0 2 0 1 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=89, meanQ=74.657893, numObservations: 8
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 37780 episodes
GETTING ACTION FROM:
action 1, numVisits=37869, meanQ=84.665367, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.674985 0.567355 0.205813 0.825238 0.910257 0.911459 0.845341 0.00731335 0.371823 0.247696 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 23
Initial state: 0 0.609696 0.734634 0.615035 0.557765 0.460435 0.903567 0.74951 0.564339 0.948485 0.0224662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27995 episodes
GETTING ACTION FROM:
action 4, numVisits=27905, meanQ=19.671834, numObservations: 9
action 5, numVisits=77, meanQ=14.450455, numObservations: 9
action 1, numVisits=9, meanQ=4.555556, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.609696 0.734634 0.615035 0.557765 0.460435 0.903567 0.74951 0.564339 0.948485 0.0224662 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 24
Initial state: 0 0.648258 0.378239 0.567443 0.548675 0.689657 0.0650829 0.92786 0.445915 0.759634 0.363013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17701 episodes
GETTING ACTION FROM:
action 0, numVisits=17662, meanQ=51.828671, numObservations: 243
action -1, numVisits=34, meanQ=-4.071838, numObservations: 30
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.648258 0.378239 0.567443 0.548675 0.689657 0.0650829 0.92786 0.445915 0.759634 0.363013 w: 1
Observation: 0 0 1 0 2 0 1 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=153, meanQ=80.191944, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38069 episodes
GETTING ACTION FROM:
action 2, numVisits=38222, meanQ=89.556045, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.648258 0.378239 0.567443 0.548675 0.689657 0.0650829 0.92786 0.445915 0.759634 0.363013 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 25
Initial state: 0 0.592201 0.93071 0.202313 0.996178 0.68074 0.517235 0.850702 0.689927 0.840251 0.893256 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27775 episodes
GETTING ACTION FROM:
action 5, numVisits=27769, meanQ=18.439959, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.592201 0.93071 0.202313 0.996178 0.68074 0.517235 0.850702 0.689927 0.840251 0.893256 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 26
Initial state: 0 0.745191 0.72405 0.820372 0.551133 0.420795 0.310127 0.596553 0.511254 0.759388 0.958577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17617 episodes
GETTING ACTION FROM:
action -1, numVisits=17597, meanQ=44.594546, numObservations: 243
action 0, numVisits=15, meanQ=-1.179833, numObservations: 14
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.745191 0.72405 0.820372 0.551133 0.420795 0.310127 0.596553 0.511254 0.759388 0.958577 w: 1
Observation: 0 2 0 3 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=38, meanQ=56.973816, numObservations: 6
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35983 episodes
GETTING ACTION FROM:
action 4, numVisits=36021, meanQ=54.926097, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.745191 0.72405 0.820372 0.551133 0.420795 0.310127 0.596553 0.511254 0.759388 0.958577 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 27
Initial state: 0 0.633491 0.126479 0.112447 0.721827 0.663953 0.532366 0.101369 0.994904 0.247081 0.115429 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26451 episodes
GETTING ACTION FROM:
action 5, numVisits=26440, meanQ=21.052090, numObservations: 9
action 1, numVisits=6, meanQ=9.675000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.633491 0.126479 0.112447 0.721827 0.663953 0.532366 0.101369 0.994904 0.247081 0.115429 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3996, meanQ=26.694444, numObservations: 9
action 1, numVisits=28, meanQ=16.835982, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 6468 episodes
GETTING ACTION FROM:
action 2, numVisits=10464, meanQ=23.139666, numObservations: 9
action 1, numVisits=28, meanQ=16.835982, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.633491 0.126479 0.112447 0.721827 0.663953 0.532366 0.101369 0.994904 0.247081 0.115429 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=879, meanQ=45.336881, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 5614 episodes
GETTING ACTION FROM:
action 2, numVisits=880, meanQ=45.307171, numObservations: 9
action 3, numVisits=5603, meanQ=42.706974, numObservations: 9
action 0, numVisits=8, meanQ=-1.287500, numObservations: 8
action -1, numVisits=6, meanQ=-1.525000, numObservations: 6
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 0 0.633491 0.126479 0.112447 0.721827 0.663953 0.532366 0.101369 0.994904 0.247081 0.115429 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=445, meanQ=31.781506, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 8852 episodes
GETTING ACTION FROM:
action 3, numVisits=9297, meanQ=43.279675, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.633491 0.126479 0.112447 0.721827 0.663953 0.532366 0.101369 0.994904 0.247081 0.115429 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 53.5026
Run # 28
Initial state: 0 0.910825 0.718982 0.582332 0.607142 0.269494 0.869177 0.400629 0.602419 0.850514 0.272866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25230 episodes
GETTING ACTION FROM:
action 1, numVisits=25224, meanQ=25.427080, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.910825 0.718982 0.582332 0.607142 0.269494 0.869177 0.400629 0.602419 0.850514 0.272866 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 29
Initial state: 0 0.576538 0.498291 0.389321 0.608836 0.442717 0.774711 0.192274 0.371025 0.296887 0.482925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17920 episodes
GETTING ACTION FROM:
action -1, numVisits=17891, meanQ=47.264692, numObservations: 243
action 0, numVisits=24, meanQ=-5.249792, numObservations: 21
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.576538 0.498291 0.389321 0.608836 0.442717 0.774711 0.192274 0.371025 0.296887 0.482925 w: 1
Observation: 0 1 0 1 0 3 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=45, meanQ=11.730000, numObservations: 7
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 36465 episodes
GETTING ACTION FROM:
action 3, numVisits=36510, meanQ=42.475014, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.576538 0.498291 0.389321 0.608836 0.442717 0.774711 0.192274 0.371025 0.296887 0.482925 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 30
Initial state: 0 0.00378167 0.979769 0.20281 0.536191 0.922812 0.240517 0.62479 0.521358 0.938189 0.532188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27019 episodes
GETTING ACTION FROM:
action 5, numVisits=26995, meanQ=20.011276, numObservations: 9
action -1, numVisits=10, meanQ=-1.050000, numObservations: 10
action 0, numVisits=10, meanQ=-1.050000, numObservations: 10
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.00378167 0.979769 0.20281 0.536191 0.922812 0.240517 0.62479 0.521358 0.938189 0.532188 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 31
Initial state: 0 0.0371171 0.920875 0.64166 0.881494 0.584503 0.505284 0.936751 0.47907 0.132941 0.298247 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25454 episodes
GETTING ACTION FROM:
action 3, numVisits=25448, meanQ=22.709104, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.0371171 0.920875 0.64166 0.881494 0.584503 0.505284 0.936751 0.47907 0.132941 0.298247 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 32
Initial state: 0 0.910535 0.970105 0.219271 0.288493 0.131925 0.00733769 0.772773 0.100643 0.6457 0.519873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 24908 episodes
GETTING ACTION FROM:
action 5, numVisits=24832, meanQ=23.128580, numObservations: 9
action 1, numVisits=57, meanQ=12.724956, numObservations: 9
action 3, numVisits=13, meanQ=11.234615, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.910535 0.970105 0.219271 0.288493 0.131925 0.00733769 0.772773 0.100643 0.6457 0.519873 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 33
Initial state: 0 0.168321 0.408707 0.440791 0.968437 0.58766 0.584029 0.261719 0.880667 0.579881 0.239751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27573 episodes
GETTING ACTION FROM:
action 2, numVisits=27546, meanQ=20.598752, numObservations: 9
action 3, numVisits=21, meanQ=13.431071, numObservations: 8
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.168321 0.408707 0.440791 0.968437 0.58766 0.584029 0.261719 0.880667 0.579881 0.239751 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4138, meanQ=27.922596, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 7629 episodes
GETTING ACTION FROM:
action 1, numVisits=11541, meanQ=22.701320, numObservations: 9
action 3, numVisits=199, meanQ=20.626855, numObservations: 9
action 0, numVisits=17, meanQ=-4.958722, numObservations: 14
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action -1, numVisits=13, meanQ=-13.882598, numObservations: 11
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.168321 0.408707 0.440791 0.968437 0.58766 0.584029 0.261719 0.880667 0.579881 0.239751 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=172, meanQ=24.082049, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 15415 episodes
GETTING ACTION FROM:
action 3, numVisits=15470, meanQ=5.606464, numObservations: 9
action 5, numVisits=106, meanQ=0.371955, numObservations: 9
action -1, numVisits=7, meanQ=-1.864286, numObservations: 7
action 0, numVisits=7, meanQ=-1.864286, numObservations: 6
action 4, numVisits=5, meanQ=-3.259084, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.168321 0.408707 0.440791 0.968437 0.58766 0.584029 0.261719 0.880667 0.579881 0.239751 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 34
Initial state: 0 0.455078 0.401106 0.500379 0.591606 0.375585 0.821075 0.839895 0.46881 0.169281 0.380691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17753 episodes
GETTING ACTION FROM:
action -1, numVisits=17732, meanQ=41.862642, numObservations: 243
action 0, numVisits=13, meanQ=-2.007308, numObservations: 11
action 2, numVisits=4, meanQ=-6.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.455078 0.401106 0.500379 0.591606 0.375585 0.821075 0.839895 0.46881 0.169281 0.380691 w: 1
Observation: 0 1 0 2 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=156, meanQ=73.436161, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 38054 episodes
GETTING ACTION FROM:
action 2, numVisits=38210, meanQ=86.787361, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.455078 0.401106 0.500379 0.591606 0.375585 0.821075 0.839895 0.46881 0.169281 0.380691 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 35
Initial state: 0 0.417875 0.0413817 0.796158 0.708079 0.513025 0.583854 0.277912 0.610868 0.497352 0.122025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25447 episodes
GETTING ACTION FROM:
action 3, numVisits=25415, meanQ=22.873853, numObservations: 9
action 4, numVisits=27, meanQ=14.550370, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.417875 0.0413817 0.796158 0.708079 0.513025 0.583854 0.277912 0.610868 0.497352 0.122025 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 36
Initial state: 0 0.43663 0.103493 0.235671 0.40602 0.229438 0.823624 0.155623 0.803889 0.671448 0.477173 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17899 episodes
GETTING ACTION FROM:
action -1, numVisits=17856, meanQ=45.681773, numObservations: 243
action 0, numVisits=35, meanQ=-4.174143, numObservations: 32
action 5, numVisits=4, meanQ=-6.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.43663 0.103493 0.235671 0.40602 0.229438 0.823624 0.155623 0.803889 0.671448 0.477173 w: 1
Observation: 0 3 0 3 0 1 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=44, meanQ=68.063636, numObservations: 6
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 2, numVisits=3, meanQ=-4.016667, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 4, numVisits=3, meanQ=-34.333333, numObservations: 1
Sampled 37149 episodes
GETTING ACTION FROM:
action 5, numVisits=37193, meanQ=76.681979, numObservations: 9
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 0, numVisits=4, meanQ=-1.050000, numObservations: 4
action 2, numVisits=3, meanQ=-4.016667, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 4, numVisits=3, meanQ=-34.333333, numObservations: 1
action: 5
Next state: 0 0.43663 0.103493 0.235671 0.40602 0.229438 0.823624 0.155623 0.803889 0.671448 0.477173 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=2184, meanQ=91.990095, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 39562 episodes
GETTING ACTION FROM:
action 5, numVisits=2205, meanQ=92.047286, numObservations: 9
action 1, numVisits=39540, meanQ=25.393778, numObservations: 9
action -1, numVisits=2, meanQ=-1.525000, numObservations: 2
action 0, numVisits=2, meanQ=-1.525000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action: 5
Next state: 0 0.43663 0.103493 0.235671 0.40602 0.229438 0.823624 0.155623 0.803889 0.671448 0.477173 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=139, meanQ=93.576978, numObservations: 5
action 3, numVisits=3, meanQ=62.650000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 41544 episodes
GETTING ACTION FROM:
action 5, numVisits=832, meanQ=98.074820, numObservations: 9
action 3, numVisits=40854, meanQ=72.080932, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.43663 0.103493 0.235671 0.40602 0.229438 0.823624 0.155623 0.803889 0.671448 0.477173 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 62.5026
Run # 37
Initial state: 0 0.297368 0.966995 0.51385 0.797466 0.544368 0.600416 0.268916 0.0607089 0.355422 0.440698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17670 episodes
GETTING ACTION FROM:
action -1, numVisits=17594, meanQ=41.321202, numObservations: 243
action 0, numVisits=51, meanQ=-3.139069, numObservations: 45
action 3, numVisits=12, meanQ=-4.333333, numObservations: 9
action 4, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=8, meanQ=-14.750000, numObservations: 5
action: -1
Next state: 0 0.297368 0.966995 0.51385 0.797466 0.544368 0.600416 0.268916 0.0607089 0.355422 0.440698 w: 1
Observation: 0 1 0 2 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=185, meanQ=72.959851, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37386 episodes
GETTING ACTION FROM:
action 2, numVisits=37571, meanQ=82.734224, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.297368 0.966995 0.51385 0.797466 0.544368 0.600416 0.268916 0.0607089 0.355422 0.440698 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 38
Initial state: 0 0.691473 0.259349 0.620162 0.177368 0.581214 0.553434 0.596456 0.658745 0.0327325 0.733783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25301 episodes
GETTING ACTION FROM:
action 3, numVisits=25295, meanQ=23.649542, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.691473 0.259349 0.620162 0.177368 0.581214 0.553434 0.596456 0.658745 0.0327325 0.733783 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 39
Initial state: 0 0.450313 0.65726 0.982551 0.46682 0.585961 0.253525 0.0315706 0.383297 0.639265 0.538333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17640 episodes
GETTING ACTION FROM:
action -1, numVisits=17616, meanQ=43.181175, numObservations: 243
action 0, numVisits=19, meanQ=-6.150000, numObservations: 18
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.450313 0.65726 0.982551 0.46682 0.585961 0.253525 0.0315706 0.383297 0.639265 0.538333 w: 1
Observation: 0 1 0 3 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=83, meanQ=24.902620, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36603 episodes
GETTING ACTION FROM:
action 3, numVisits=36686, meanQ=62.067232, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.450313 0.65726 0.982551 0.46682 0.585961 0.253525 0.0315706 0.383297 0.639265 0.538333 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=967, meanQ=40.804937, numObservations: 118
action 0, numVisits=6, meanQ=-1.050000, numObservations: 6
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 9513 episodes
GETTING ACTION FROM:
action -1, numVisits=10480, meanQ=14.726617, numObservations: 201
action 0, numVisits=6, meanQ=-1.050000, numObservations: 6
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.450313 0.65726 0.982551 0.46682 0.585961 0.253525 0.0315706 0.383297 0.639265 0.538333 w: 1
Observation: 0 1 0 3 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=10, meanQ=99.000000, numObservations: 4
action 2, numVisits=3, meanQ=32.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-12.972458, numObservations: 1
action 3, numVisits=1, meanQ=-214.231920, numObservations: 1
Sampled 22054 episodes
GETTING ACTION FROM:
action 5, numVisits=22063, meanQ=57.511880, numObservations: 9
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-12.972458, numObservations: 1
action 3, numVisits=1, meanQ=-214.231920, numObservations: 1
action: 5
Next state: 1 0.450313 0.65726 0.982551 0.46682 0.585961 0.253525 0.0315706 0.383297 0.639265 0.538333 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 70.6251
Run # 40
Initial state: 0 0.591019 0.507637 0.458918 0.988933 0.0522711 0.138177 0.478482 0.00520921 0.643083 0.972138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28439 episodes
GETTING ACTION FROM:
action 2, numVisits=28421, meanQ=20.225108, numObservations: 9
action 3, numVisits=13, meanQ=15.989038, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.591019 0.507637 0.458918 0.988933 0.0522711 0.138177 0.478482 0.00520921 0.643083 0.972138 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2640, meanQ=26.637298, numObservations: 9
action 1, numVisits=5, meanQ=15.380000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 8104 episodes
GETTING ACTION FROM:
action 5, numVisits=10744, meanQ=31.904043, numObservations: 9
action 1, numVisits=5, meanQ=15.380000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 2 0.591019 0.507637 0.458918 0.988933 0.0522711 0.138177 0.478482 0.00520921 0.643083 0.972138 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 41
Initial state: 0 0.00542664 0.477896 0.139835 0.620262 0.689738 0.283144 0.385944 0.99668 0.601802 0.534271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27354 episodes
GETTING ACTION FROM:
action 3, numVisits=27347, meanQ=19.660952, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.00542664 0.477896 0.139835 0.620262 0.689738 0.283144 0.385944 0.99668 0.601802 0.534271 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 42
Initial state: 0 0.650105 0.514965 0.866224 0.901128 0.575945 0.233682 0.649091 0.688528 0.396428 0.238165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17424 episodes
GETTING ACTION FROM:
action 0, numVisits=17390, meanQ=53.707129, numObservations: 243
action 4, numVisits=10, meanQ=-3.000000, numObservations: 5
action 3, numVisits=4, meanQ=-6.000000, numObservations: 4
action -1, numVisits=15, meanQ=-7.510000, numObservations: 14
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.650105 0.514965 0.866224 0.901128 0.575945 0.233682 0.649091 0.688528 0.396428 0.238165 w: 1
Observation: 0 0 2 0 3 0 1 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=103, meanQ=84.911723, numObservations: 8
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36921 episodes
GETTING ACTION FROM:
action 1, numVisits=37024, meanQ=86.159090, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.650105 0.514965 0.866224 0.901128 0.575945 0.233682 0.649091 0.688528 0.396428 0.238165 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 43
Initial state: 0 0.423638 0.0410569 0.924289 0.752467 0.661969 0.574777 0.631938 0.39034 0.694855 0.306381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17540 episodes
GETTING ACTION FROM:
action -1, numVisits=17501, meanQ=44.975866, numObservations: 243
action 0, numVisits=31, meanQ=-5.254516, numObservations: 26
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=4, meanQ=-28.500000, numObservations: 4
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.423638 0.0410569 0.924289 0.752467 0.661969 0.574777 0.631938 0.39034 0.694855 0.306381 w: 1
Observation: 0 1 0 3 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=44, meanQ=75.952386, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38055 episodes
GETTING ACTION FROM:
action 4, numVisits=38099, meanQ=78.472572, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.423638 0.0410569 0.924289 0.752467 0.661969 0.574777 0.631938 0.39034 0.694855 0.306381 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 44
Initial state: 0 0.244371 0.25203 0.207388 0.60475 0.282254 0.913637 0.105512 0.815039 0.558619 0.495045 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18042 episodes
GETTING ACTION FROM:
action -1, numVisits=18028, meanQ=43.660687, numObservations: 243
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=9, meanQ=-11.816667, numObservations: 8
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.244371 0.25203 0.207388 0.60475 0.282254 0.913637 0.105512 0.815039 0.558619 0.495045 w: 1
Observation: 0 1 0 1 0 1 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=62, meanQ=52.670437, numObservations: 7
action 1, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 20082 episodes
GETTING ACTION FROM:
action 4, numVisits=20144, meanQ=34.374284, numObservations: 9
action 1, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.244371 0.25203 0.207388 0.60475 0.282254 0.913637 0.105512 0.815039 0.558619 0.495045 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 45
Initial state: 0 0.95542 0.94577 0.540246 0.474696 0.770462 0.190502 0.0954913 0.747989 0.366513 0.313964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17782 episodes
GETTING ACTION FROM:
action -1, numVisits=17731, meanQ=43.290853, numObservations: 243
action 0, numVisits=27, meanQ=-1.122130, numObservations: 26
action 1, numVisits=20, meanQ=-4.432250, numObservations: 9
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.95542 0.94577 0.540246 0.474696 0.770462 0.190502 0.0954913 0.747989 0.366513 0.313964 w: 1
Observation: 0 3 0 2 0 3 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=86, meanQ=77.730872, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37480 episodes
GETTING ACTION FROM:
action 2, numVisits=37566, meanQ=79.401642, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.95542 0.94577 0.540246 0.474696 0.770462 0.190502 0.0954913 0.747989 0.366513 0.313964 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 46
Initial state: 0 0.24235 0.034804 0.556936 0.531381 0.870254 0.132745 0.453472 0.724454 0.766094 0.465947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26314 episodes
GETTING ACTION FROM:
action 2, numVisits=26308, meanQ=21.181997, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.24235 0.034804 0.556936 0.531381 0.870254 0.132745 0.453472 0.724454 0.766094 0.465947 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 47
Initial state: 0 0.514789 0.544151 0.101686 0.936181 0.623249 0.135179 0.917103 0.0296412 0.998785 0.241753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25741 episodes
GETTING ACTION FROM:
action 4, numVisits=25686, meanQ=23.819483, numObservations: 9
action 0, numVisits=7, meanQ=-1.050000, numObservations: 7
action -1, numVisits=40, meanQ=-1.145000, numObservations: 38
action 3, numVisits=5, meanQ=-2.810000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.514789 0.544151 0.101686 0.936181 0.623249 0.135179 0.917103 0.0296412 0.998785 0.241753 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 48
Initial state: 0 0.287119 0.488014 0.886796 0.671489 0.568053 0.52231 0.763687 0.996987 0.217233 0.0580838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27433 episodes
GETTING ACTION FROM:
action 4, numVisits=27427, meanQ=21.777265, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.287119 0.488014 0.886796 0.671489 0.568053 0.52231 0.763687 0.996987 0.217233 0.0580838 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 49
Initial state: 0 0.830265 0.649117 0.656237 0.548669 0.389007 0.874299 0.948739 0.839164 0.0849622 0.42567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26988 episodes
GETTING ACTION FROM:
action 3, numVisits=26977, meanQ=20.667271, numObservations: 9
action 2, numVisits=6, meanQ=8.325000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.830265 0.649117 0.656237 0.548669 0.389007 0.874299 0.948739 0.839164 0.0849622 0.42567 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2488, meanQ=50.096957, numObservations: 9
action 4, numVisits=7, meanQ=9.200357, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 8844 episodes
GETTING ACTION FROM:
action 3, numVisits=2490, meanQ=50.113378, numObservations: 9
action 4, numVisits=8768, meanQ=41.856626, numObservations: 9
action 0, numVisits=57, meanQ=-1.781459, numObservations: 45
action -1, numVisits=24, meanQ=-2.296965, numObservations: 20
action 1, numVisits=2, meanQ=-55.525000, numObservations: 2
action 2, numVisits=2, meanQ=-55.525000, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.830265 0.649117 0.656237 0.548669 0.389007 0.874299 0.948739 0.839164 0.0849622 0.42567 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=191, meanQ=22.910844, numObservations: 9
action 0, numVisits=31, meanQ=-1.633790, numObservations: 26
action -1, numVisits=29, meanQ=-1.741207, numObservations: 23
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 7759 episodes
GETTING ACTION FROM:
action 4, numVisits=7950, meanQ=37.738923, numObservations: 9
action 0, numVisits=31, meanQ=-1.633790, numObservations: 26
action -1, numVisits=29, meanQ=-1.741207, numObservations: 23
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.830265 0.649117 0.656237 0.548669 0.389007 0.874299 0.948739 0.839164 0.0849622 0.42567 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -112.603
Run # 50
Initial state: 0 0.445933 0.000263908 0.594514 0.917116 0.7103 0.110773 0.917153 0.515289 0.657123 0.483176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17751 episodes
GETTING ACTION FROM:
action -1, numVisits=17692, meanQ=43.274395, numObservations: 243
action 0, numVisits=21, meanQ=-1.050000, numObservations: 21
action 1, numVisits=30, meanQ=-1.168250, numObservations: 9
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.445933 0.000263908 0.594514 0.917116 0.7103 0.110773 0.917153 0.515289 0.657123 0.483176 w: 1
Observation: 0 1 0 2 0 2 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=38, meanQ=1.400000, numObservations: 37
action -1, numVisits=6, meanQ=-3.124167, numObservations: 4
action 3, numVisits=9, meanQ=-4.016667, numObservations: 5
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17735 episodes
GETTING ACTION FROM:
action 0, numVisits=17771, meanQ=66.268973, numObservations: 243
action -1, numVisits=7, meanQ=-4.327500, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=10, meanQ=-13.715000, numObservations: 5
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.445933 0.000263908 0.594514 0.917116 0.7103 0.110773 0.917153 0.515289 0.657123 0.483176 w: 1
Observation: 0 0 1 0 1 0 2 0 2 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=13, meanQ=6.111538, numObservations: 12
action 0, numVisits=5, meanQ=-1.050000, numObservations: 5
action 5, numVisits=3, meanQ=-6.000000, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18333 episodes
GETTING ACTION FROM:
action -1, numVisits=18342, meanQ=65.959092, numObservations: 215
action 0, numVisits=9, meanQ=-2.216389, numObservations: 8
action 5, numVisits=3, meanQ=-6.000000, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.445933 0.000263908 0.594514 0.917116 0.7103 0.110773 0.917153 0.515289 0.657123 0.483176 w: 1
Observation: 0 1 0 3 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=107, meanQ=46.379977, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37317 episodes
GETTING ACTION FROM:
action 5, numVisits=37424, meanQ=53.902961, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.445933 0.000263908 0.594514 0.917116 0.7103 0.110773 0.917153 0.515289 0.657123 0.483176 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 79.1751
[32m ProblemEnvironment.hpp 351: Done.[39m
