Run # 1
Initial state: 0 0.154687 0.777431 0.85939 0.428508 0.149534 0.398029 0.129308 0.184457 0.432579 0.452135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16897 episodes
GETTING ACTION FROM:
action -1, numVisits=16807, meanQ=47.739593, numObservations: 243
action 2, numVisits=33, meanQ=-1.145379, numObservations: 9
action 0, numVisits=47, meanQ=-1.476489, numObservations: 41
action 4, numVisits=7, meanQ=-5.285714, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.154687 0.777431 0.85939 0.428508 0.149534 0.398029 0.129308 0.184457 0.432579 0.452135 w: 1
Observation: 0 1 0 3 0 1 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=63, meanQ=75.718333, numObservations: 8
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action 2, numVisits=6, meanQ=32.333333, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 37817 episodes
GETTING ACTION FROM:
action 5, numVisits=37880, meanQ=82.548068, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action 2, numVisits=6, meanQ=32.333333, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.154687 0.777431 0.85939 0.428508 0.149534 0.398029 0.129308 0.184457 0.432579 0.452135 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 2
Initial state: 0 0.872238 0.778528 0.578416 0.414015 0.912626 0.456592 0.755051 0.744025 0.804022 0.179546 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28481 episodes
GETTING ACTION FROM:
action 1, numVisits=28449, meanQ=27.146048, numObservations: 9
action 2, numVisits=3, meanQ=22.484167, numObservations: 2
action 4, numVisits=24, meanQ=20.741875, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.872238 0.778528 0.578416 0.414015 0.912626 0.456592 0.755051 0.744025 0.804022 0.179546 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 3
Initial state: 0 0.257175 0.192796 0.71095 0.728886 0.246673 0.151154 0.45086 0.38476 0.0809754 0.603308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29722 episodes
GETTING ACTION FROM:
action 2, numVisits=29716, meanQ=29.951477, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.257175 0.192796 0.71095 0.728886 0.246673 0.151154 0.45086 0.38476 0.0809754 0.603308 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 4
Initial state: 0 0.452196 0.876509 0.919769 0.150513 0.551805 0.480306 0.97153 0.219545 0.70271 0.536412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27516 episodes
GETTING ACTION FROM:
action 1, numVisits=27509, meanQ=29.104826, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.452196 0.876509 0.919769 0.150513 0.551805 0.480306 0.97153 0.219545 0.70271 0.536412 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 5
Initial state: 0 0.145307 0.543358 0.747319 0.667647 0.477628 0.495641 0.748991 0.551056 0.041795 0.478531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30337 episodes
GETTING ACTION FROM:
action 5, numVisits=30330, meanQ=28.823789, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.145307 0.543358 0.747319 0.667647 0.477628 0.495641 0.748991 0.551056 0.041795 0.478531 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1031, meanQ=38.434076, numObservations: 9
action 5, numVisits=3, meanQ=26.300000, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 11839 episodes
GETTING ACTION FROM:
action 3, numVisits=12870, meanQ=36.055265, numObservations: 9
action 5, numVisits=3, meanQ=26.300000, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.145307 0.543358 0.747319 0.667647 0.477628 0.495641 0.748991 0.551056 0.041795 0.478531 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 6
Initial state: 0 0.534993 0.157602 0.90306 0.495619 0.452353 0.423677 0.425036 0.0510073 0.451183 0.133087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29579 episodes
GETTING ACTION FROM:
action 3, numVisits=29569, meanQ=29.265198, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.534993 0.157602 0.90306 0.495619 0.452353 0.423677 0.425036 0.0510073 0.451183 0.133087 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 7
Initial state: 0 0.43708 0.179912 0.236559 0.242378 0.355615 0.349973 0.314042 0.188741 0.526228 0.424655 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17966 episodes
GETTING ACTION FROM:
action -1, numVisits=17941, meanQ=47.982049, numObservations: 243
action 0, numVisits=18, meanQ=-1.266389, numObservations: 16
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.43708 0.179912 0.236559 0.242378 0.355615 0.349973 0.314042 0.188741 0.526228 0.424655 w: 1
Observation: 0 2 0 1 0 1 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=58, meanQ=23.407845, numObservations: 8
action 1, numVisits=4, meanQ=21.737500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 34759 episodes
GETTING ACTION FROM:
action 1, numVisits=34763, meanQ=46.359087, numObservations: 9
action 5, numVisits=58, meanQ=23.407845, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 2 0.43708 0.179912 0.236559 0.242378 0.355615 0.349973 0.314042 0.188741 0.526228 0.424655 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 8
Initial state: 0 0.125375 0.580448 0.804717 0.166751 0.471197 0.543943 0.55638 0.384571 0.989255 0.509224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28011 episodes
GETTING ACTION FROM:
action 1, numVisits=28000, meanQ=27.718096, numObservations: 9
action 3, numVisits=5, meanQ=15.190000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.125375 0.580448 0.804717 0.166751 0.471197 0.543943 0.55638 0.384571 0.989255 0.509224 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=2844, meanQ=57.317806, numObservations: 222
action -1, numVisits=7, meanQ=-2.549643, numObservations: 6
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 4852 episodes
GETTING ACTION FROM:
action 0, numVisits=7696, meanQ=44.958452, numObservations: 241
action -1, numVisits=7, meanQ=-2.549643, numObservations: 6
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.125375 0.580448 0.804717 0.166751 0.471197 0.543943 0.55638 0.384571 0.989255 0.509224 w: 1
Observation: 0 0 2 0 1 0 3 0 2 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-12.159266, numObservations: 1
action 5, numVisits=1, meanQ=-12.237009, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18016 episodes
GETTING ACTION FROM:
action 4, numVisits=18016, meanQ=86.087371, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-12.159266, numObservations: 1
action 5, numVisits=1, meanQ=-12.237009, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.125375 0.580448 0.804717 0.166751 0.471197 0.543943 0.55638 0.384571 0.989255 0.509224 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 9
Initial state: 0 0.282502 0.0937251 0.439021 0.536843 0.957406 0.475627 0.191531 0.552202 0.577207 0.497726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28259 episodes
GETTING ACTION FROM:
action 2, numVisits=28252, meanQ=30.871542, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.282502 0.0937251 0.439021 0.536843 0.957406 0.475627 0.191531 0.552202 0.577207 0.497726 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 10
Initial state: 0 0.123315 0.737065 0.328772 0.874783 0.147462 0.127147 0.435014 0.485204 0.585691 0.742652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28452 episodes
GETTING ACTION FROM:
action 2, numVisits=28444, meanQ=30.764786, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.123315 0.737065 0.328772 0.874783 0.147462 0.127147 0.435014 0.485204 0.585691 0.742652 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2824, meanQ=33.623189, numObservations: 9
action 5, numVisits=3, meanQ=26.300000, numObservations: 3
action 1, numVisits=4, meanQ=21.737500, numObservations: 4
action 3, numVisits=4, meanQ=21.737500, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 2
Sampled 12384 episodes
GETTING ACTION FROM:
action 4, numVisits=15208, meanQ=40.931213, numObservations: 9
action 5, numVisits=3, meanQ=26.300000, numObservations: 3
action 1, numVisits=4, meanQ=21.737500, numObservations: 4
action 3, numVisits=4, meanQ=21.737500, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.016667, numObservations: 2
action: 4
Next state: 1 0.123315 0.737065 0.328772 0.874783 0.147462 0.127147 0.435014 0.485204 0.585691 0.742652 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 11
Initial state: 0 0.42646 0.492564 0.883183 0.768238 0.697125 0.78118 0.199026 0.244201 0.744581 0.763718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29974 episodes
GETTING ACTION FROM:
action 2, numVisits=29959, meanQ=30.140789, numObservations: 9
action 1, numVisits=7, meanQ=8.214643, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.42646 0.492564 0.883183 0.768238 0.697125 0.78118 0.199026 0.244201 0.744581 0.763718 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 12
Initial state: 0 0.861628 0.598353 0.740053 0.883667 0.0309006 0.469841 0.510878 0.451728 0.403919 0.486249 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28684 episodes
GETTING ACTION FROM:
action 1, numVisits=28674, meanQ=29.812354, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.861628 0.598353 0.740053 0.883667 0.0309006 0.469841 0.510878 0.451728 0.403919 0.486249 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 13
Initial state: 0 0.211972 0.21817 0.53475 0.425922 0.822104 0.830764 0.486241 0.323693 0.411165 0.142899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28333 episodes
GETTING ACTION FROM:
action 5, numVisits=28324, meanQ=30.012470, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.211972 0.21817 0.53475 0.425922 0.822104 0.830764 0.486241 0.323693 0.411165 0.142899 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 14
Initial state: 0 0.220829 0.00790061 0.674886 0.35777 0.707693 0.698216 0.552021 0.399851 0.293216 0.251208 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29459 episodes
GETTING ACTION FROM:
action 4, numVisits=29451, meanQ=30.022075, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.220829 0.00790061 0.674886 0.35777 0.707693 0.698216 0.552021 0.399851 0.293216 0.251208 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 15
Initial state: 0 0.505845 0.479543 0.507555 0.336174 0.382215 0.515731 0.139242 0.535851 0.62122 0.396581 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28638 episodes
GETTING ACTION FROM:
action 4, numVisits=28612, meanQ=31.284207, numObservations: 9
action -1, numVisits=10, meanQ=-1.050000, numObservations: 10
action 0, numVisits=10, meanQ=-1.050000, numObservations: 10
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.505845 0.479543 0.507555 0.336174 0.382215 0.515731 0.139242 0.535851 0.62122 0.396581 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=171, meanQ=35.958291, numObservations: 9
action 3, numVisits=13, meanQ=3.100192, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 28601 episodes
GETTING ACTION FROM:
action 1, numVisits=28772, meanQ=41.315249, numObservations: 9
action 3, numVisits=13, meanQ=3.100192, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.505845 0.479543 0.507555 0.336174 0.382215 0.515731 0.139242 0.535851 0.62122 0.396581 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 16
Initial state: 0 0.250647 0.755757 0.220602 0.408816 0.408905 0.465379 0.229967 0.650698 0.672737 0.811617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28537 episodes
GETTING ACTION FROM:
action 2, numVisits=28518, meanQ=30.148230, numObservations: 9
action 5, numVisits=9, meanQ=14.605833, numObservations: 3
action 4, numVisits=6, meanQ=14.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.250647 0.755757 0.220602 0.408816 0.408905 0.465379 0.229967 0.650698 0.672737 0.811617 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1004, meanQ=40.240377, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 8066 episodes
GETTING ACTION FROM:
action 1, numVisits=9070, meanQ=32.280352, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.250647 0.755757 0.220602 0.408816 0.408905 0.465379 0.229967 0.650698 0.672737 0.811617 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=712, meanQ=50.241043, numObservations: 9
action 4, numVisits=45, meanQ=44.432333, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 7595 episodes
GETTING ACTION FROM:
action 1, numVisits=718, meanQ=50.558638, numObservations: 9
action 4, numVisits=7634, meanQ=42.690467, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 0 0.250647 0.755757 0.220602 0.408816 0.408905 0.465379 0.229967 0.650698 0.672737 0.811617 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=320, meanQ=47.873580, numObservations: 9
action 5, numVisits=29, meanQ=26.248820, numObservations: 8
action 1, numVisits=3, meanQ=25.650833, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 14381 episodes
GETTING ACTION FROM:
action 3, numVisits=14701, meanQ=52.576825, numObservations: 9
action 5, numVisits=29, meanQ=26.248820, numObservations: 8
action 1, numVisits=3, meanQ=25.650833, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.250647 0.755757 0.220602 0.408816 0.408905 0.465379 0.229967 0.650698 0.672737 0.811617 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 53.5026
Run # 17
Initial state: 0 0.417842 0.400875 0.382557 0.78376 0.701026 0.819599 0.375555 0.748418 0.202995 0.116444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17805 episodes
GETTING ACTION FROM:
action -1, numVisits=17764, meanQ=47.846742, numObservations: 243
action 0, numVisits=30, meanQ=-1.594667, numObservations: 26
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=4, meanQ=-28.500000, numObservations: 4
action 2, numVisits=4, meanQ=-28.500000, numObservations: 3
action: -1
Next state: 0 0.417842 0.400875 0.382557 0.78376 0.701026 0.819599 0.375555 0.748418 0.202995 0.116444 w: 1
Observation: 0 2 0 1 0 3 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=78, meanQ=52.532543, numObservations: 9
action 5, numVisits=5, meanQ=14.190000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 23114 episodes
GETTING ACTION FROM:
action 2, numVisits=23192, meanQ=56.152851, numObservations: 9
action 5, numVisits=5, meanQ=14.190000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.417842 0.400875 0.382557 0.78376 0.701026 0.819599 0.375555 0.748418 0.202995 0.116444 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=231, meanQ=84.290456, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 23972 episodes
GETTING ACTION FROM:
action 1, numVisits=24203, meanQ=81.495818, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.417842 0.400875 0.382557 0.78376 0.701026 0.819599 0.375555 0.748418 0.202995 0.116444 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 18
Initial state: 0 0.276157 0.568331 0.261842 0.166203 0.924263 0.0995761 0.117848 0.842753 0.448934 0.399482 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29412 episodes
GETTING ACTION FROM:
action 3, numVisits=29397, meanQ=29.232014, numObservations: 9
action 4, numVisits=10, meanQ=6.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.276157 0.568331 0.261842 0.166203 0.924263 0.0995761 0.117848 0.842753 0.448934 0.399482 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 19
Initial state: 0 0.577617 0.405715 0.899101 0.0911965 0.780247 0.868984 0.950354 0.516072 0.772885 0.903938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28448 episodes
GETTING ACTION FROM:
action 2, numVisits=28424, meanQ=30.221470, numObservations: 9
action 5, numVisits=14, meanQ=22.639286, numObservations: 7
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.577617 0.405715 0.899101 0.0911965 0.780247 0.868984 0.950354 0.516072 0.772885 0.903938 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 20
Initial state: 0 0.531692 0.762159 0.813138 0.191477 0.443588 0.498254 0.893398 0.311882 0.307526 0.473902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29967 episodes
GETTING ACTION FROM:
action 5, numVisits=29957, meanQ=28.444512, numObservations: 9
action 3, numVisits=4, meanQ=21.500000, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.531692 0.762159 0.813138 0.191477 0.443588 0.498254 0.893398 0.311882 0.307526 0.473902 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=959, meanQ=36.767790, numObservations: 9
action 2, numVisits=91, meanQ=13.481813, numObservations: 9
action 3, numVisits=11, meanQ=10.982500, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 10385 episodes
GETTING ACTION FROM:
action 1, numVisits=11344, meanQ=34.565041, numObservations: 9
action 2, numVisits=91, meanQ=13.481813, numObservations: 9
action 3, numVisits=11, meanQ=10.982500, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.531692 0.762159 0.813138 0.191477 0.443588 0.498254 0.893398 0.311882 0.307526 0.473902 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 21
Initial state: 0 0.901398 0.297936 0.775048 0.0864255 0.328908 0.700931 0.416981 0.454868 0.297469 0.493786 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28716 episodes
GETTING ACTION FROM:
action 5, numVisits=28709, meanQ=29.211609, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.901398 0.297936 0.775048 0.0864255 0.328908 0.700931 0.416981 0.454868 0.297469 0.493786 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=992, meanQ=42.815959, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 12595 episodes
GETTING ACTION FROM:
action 4, numVisits=13587, meanQ=37.030500, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.901398 0.297936 0.775048 0.0864255 0.328908 0.700931 0.416981 0.454868 0.297469 0.493786 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 22
Initial state: 0 0.0388057 0.619048 0.588342 0.461169 0.231799 0.761205 0.458994 0.861082 0.251402 0.0145913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28424 episodes
GETTING ACTION FROM:
action 2, numVisits=28417, meanQ=29.599935, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0388057 0.619048 0.588342 0.461169 0.231799 0.761205 0.458994 0.861082 0.251402 0.0145913 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 23
Initial state: 0 0.123336 0.026496 0.210161 0.746005 0.508317 0.450365 0.109936 0.82342 0.855668 0.209514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29542 episodes
GETTING ACTION FROM:
action 2, numVisits=29523, meanQ=27.667670, numObservations: 9
action 1, numVisits=4, meanQ=21.500000, numObservations: 4
action 5, numVisits=4, meanQ=21.500000, numObservations: 4
action 3, numVisits=8, meanQ=10.250000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.123336 0.026496 0.210161 0.746005 0.508317 0.450365 0.109936 0.82342 0.855668 0.209514 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 24
Initial state: 0 0.443273 0.38599 0.177798 0.466396 0.232284 0.447136 0.769074 0.484175 0.465604 0.914081 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17040 episodes
GETTING ACTION FROM:
action 0, numVisits=16985, meanQ=59.487524, numObservations: 243
action -1, numVisits=50, meanQ=-3.273950, numObservations: 46
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.443273 0.38599 0.177798 0.466396 0.232284 0.447136 0.769074 0.484175 0.465604 0.914081 w: 1
Observation: 0 0 2 0 2 0 2 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=99.000000, numObservations: 1
action 2, numVisits=1, meanQ=99.000000, numObservations: 1
action 3, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29781 episodes
GETTING ACTION FROM:
action 2, numVisits=29776, meanQ=40.350765, numObservations: 9
action 1, numVisits=4, meanQ=21.737500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.443273 0.38599 0.177798 0.466396 0.232284 0.447136 0.769074 0.484175 0.465604 0.914081 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=3250, meanQ=69.741761, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 14817 episodes
GETTING ACTION FROM:
action 4, numVisits=18067, meanQ=58.836319, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.443273 0.38599 0.177798 0.466396 0.232284 0.447136 0.769074 0.484175 0.465604 0.914081 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -103.603
Run # 25
Initial state: 0 0.624119 0.676509 0.224687 0.403174 0.195672 0.121272 0.460702 0.412333 0.00105248 0.919534 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28836 episodes
GETTING ACTION FROM:
action 2, numVisits=28824, meanQ=31.890230, numObservations: 9
action 3, numVisits=7, meanQ=7.564643, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.624119 0.676509 0.224687 0.403174 0.195672 0.121272 0.460702 0.412333 0.00105248 0.919534 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1021, meanQ=35.316414, numObservations: 9
action 4, numVisits=7, meanQ=26.278571, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 12486 episodes
GETTING ACTION FROM:
action 1, numVisits=13506, meanQ=24.811508, numObservations: 9
action 4, numVisits=8, meanQ=10.368750, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.624119 0.676509 0.224687 0.403174 0.195672 0.121272 0.460702 0.412333 0.00105248 0.919534 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 26
Initial state: 0 0.333703 0.365908 0.814566 0.77346 0.0973195 0.920399 0.656593 0.108856 0.517338 0.49451 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28867 episodes
GETTING ACTION FROM:
action 3, numVisits=28860, meanQ=29.385900, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.333703 0.365908 0.814566 0.77346 0.0973195 0.920399 0.656593 0.108856 0.517338 0.49451 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 27
Initial state: 0 0.552416 0.402214 0.767763 0.45574 0.254526 0.418909 0.0328804 0.693074 0.409219 0.591239 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27579 episodes
GETTING ACTION FROM:
action 1, numVisits=27572, meanQ=29.609594, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.552416 0.402214 0.767763 0.45574 0.254526 0.418909 0.0328804 0.693074 0.409219 0.591239 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 28
Initial state: 0 0.279916 0.963123 0.545492 0.175813 0.977894 0.670535 0.933122 0.412487 0.454271 0.431595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17549 episodes
GETTING ACTION FROM:
action 0, numVisits=17395, meanQ=59.228703, numObservations: 243
action -1, numVisits=135, meanQ=-3.165685, numObservations: 112
action 2, numVisits=15, meanQ=-4.063333, numObservations: 9
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.279916 0.963123 0.545492 0.175813 0.977894 0.670535 0.933122 0.412487 0.454271 0.431595 w: 1
Observation: 0 0 2 0 2 0 3 0 2 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9, meanQ=51.883333, numObservations: 6
action 1, numVisits=2, meanQ=44.475000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33515 episodes
GETTING ACTION FROM:
action 3, numVisits=33522, meanQ=54.870091, numObservations: 9
action 1, numVisits=4, meanQ=43.988125, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.279916 0.963123 0.545492 0.175813 0.977894 0.670535 0.933122 0.412487 0.454271 0.431595 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 29
Initial state: 0 0.960246 0.933437 0.653186 0.869738 0.15697 0.78937 0.492847 0.390347 0.509271 0.664624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29112 episodes
GETTING ACTION FROM:
action 1, numVisits=29075, meanQ=29.829938, numObservations: 9
action 4, numVisits=27, meanQ=12.833519, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=5, meanQ=-3.000000, numObservations: 5
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.960246 0.933437 0.653186 0.869738 0.15697 0.78937 0.492847 0.390347 0.509271 0.664624 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 30
Initial state: 0 0.881368 0.102376 0.227185 0.931608 0.313108 0.511352 0.376766 0.0545845 0.506424 0.455466 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29663 episodes
GETTING ACTION FROM:
action 5, numVisits=29653, meanQ=29.720326, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.881368 0.102376 0.227185 0.931608 0.313108 0.511352 0.376766 0.0545845 0.506424 0.455466 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=158, meanQ=38.043638, numObservations: 9
action 1, numVisits=5, meanQ=19.000000, numObservations: 2
action 3, numVisits=6, meanQ=13.166667, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 30335 episodes
GETTING ACTION FROM:
action 4, numVisits=30493, meanQ=35.236127, numObservations: 9
action 1, numVisits=5, meanQ=19.000000, numObservations: 2
action 3, numVisits=6, meanQ=13.166667, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 0 0.881368 0.102376 0.227185 0.931608 0.313108 0.511352 0.376766 0.0545845 0.506424 0.455466 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=24, meanQ=55.934538, numObservations: 8
action 2, numVisits=7, meanQ=41.857143, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-12.701331, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 30699 episodes
GETTING ACTION FROM:
action 2, numVisits=30571, meanQ=54.149483, numObservations: 9
action 3, numVisits=159, meanQ=20.801440, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-12.701331, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.881368 0.102376 0.227185 0.931608 0.313108 0.511352 0.376766 0.0545845 0.506424 0.455466 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=1, meanQ=99.000000, numObservations: 1
action 1, numVisits=62, meanQ=82.281608, numObservations: 8
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-12.563272, numObservations: 1
action 5, numVisits=1, meanQ=-113.184542, numObservations: 1
Sampled 40356 episodes
GETTING ACTION FROM:
action 1, numVisits=40414, meanQ=55.312552, numObservations: 9
action 4, numVisits=5, meanQ=37.000000, numObservations: 3
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-12.563272, numObservations: 1
action 5, numVisits=1, meanQ=-113.184542, numObservations: 1
action: 1
Next state: 0 0.881368 0.102376 0.227185 0.931608 0.313108 0.511352 0.376766 0.0545845 0.506424 0.455466 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-12.529668, numObservations: 1
action 2, numVisits=1, meanQ=-79.547181, numObservations: 1
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 57892 episodes
GETTING ACTION FROM:
action 4, numVisits=57850, meanQ=53.994373, numObservations: 9
action -1, numVisits=18, meanQ=-1.947222, numObservations: 13
action 0, numVisits=18, meanQ=-1.947222, numObservations: 12
action 1, numVisits=1, meanQ=-12.529668, numObservations: 1
action 3, numVisits=7, meanQ=-15.285714, numObservations: 4
action 2, numVisits=1, meanQ=-79.547181, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.881368 0.102376 0.227185 0.931608 0.313108 0.511352 0.376766 0.0545845 0.506424 0.455466 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 3, numVisits=17, meanQ=99.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-62.787818, numObservations: 1
action 1, numVisits=1, meanQ=-62.810631, numObservations: 1
action 4, numVisits=1, meanQ=-62.951848, numObservations: 1
action 5, numVisits=1, meanQ=-62.968554, numObservations: 1
Sampled 37818 episodes
GETTING ACTION FROM:
action 0, numVisits=35863, meanQ=-1.754349, numObservations: 231
action -1, numVisits=1897, meanQ=-2.024448, numObservations: 141
action 3, numVisits=77, meanQ=-4.896104, numObservations: 9
action 2, numVisits=1, meanQ=-62.787818, numObservations: 1
action 1, numVisits=1, meanQ=-62.810631, numObservations: 1
action 4, numVisits=1, meanQ=-62.951848, numObservations: 1
action 5, numVisits=1, meanQ=-62.968554, numObservations: 1
action: 0
Next state: 0 0.881368 0.102376 0.227185 0.931608 0.313108 0.511352 0.376766 0.0545845 0.506424 0.455466 w: 1
Observation: 0 0 1 0 3 0 1 0 1 0 2 
Immediate reward: -2
Updated belief

t = 6
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 74473 episodes
GETTING ACTION FROM:
action 5, numVisits=74466, meanQ=81.357049, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.881368 0.102376 0.227185 0.931608 0.313108 0.511352 0.376766 0.0545845 0.506424 0.455466 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.4583
Run # 31
Initial state: 0 0.287191 0.347523 0.430826 0.506964 0.716059 0.387128 0.694625 0.703508 0.554288 0.83815 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17282 episodes
GETTING ACTION FROM:
action 0, numVisits=17244, meanQ=57.074386, numObservations: 243
action -1, numVisits=24, meanQ=-1.924792, numObservations: 22
action 3, numVisits=10, meanQ=-5.954750, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.287191 0.347523 0.430826 0.506964 0.716059 0.387128 0.694625 0.703508 0.554288 0.83815 w: 1
Observation: 0 0 1 0 3 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=106, meanQ=67.404422, numObservations: 8
action 4, numVisits=7, meanQ=51.707857, numObservations: 4
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31808 episodes
GETTING ACTION FROM:
action 2, numVisits=31914, meanQ=65.525690, numObservations: 9
action 4, numVisits=7, meanQ=51.707857, numObservations: 4
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.287191 0.347523 0.430826 0.506964 0.716059 0.387128 0.694625 0.703508 0.554288 0.83815 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 32
Initial state: 0 0.837722 0.444566 0.751754 0.199279 0.156119 0.10169 0.065939 0.103751 0.470049 0.412701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28535 episodes
GETTING ACTION FROM:
action 2, numVisits=28528, meanQ=29.710367, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.837722 0.444566 0.751754 0.199279 0.156119 0.10169 0.065939 0.103751 0.470049 0.412701 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 33
Initial state: 0 0.530018 0.49279 0.0508701 0.472663 0.0447181 0.289039 0.574004 0.212118 0.533347 0.315787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29538 episodes
GETTING ACTION FROM:
action 3, numVisits=29526, meanQ=29.230706, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=5, meanQ=-3.000000, numObservations: 4
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.530018 0.49279 0.0508701 0.472663 0.0447181 0.289039 0.574004 0.212118 0.533347 0.315787 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=2845, meanQ=37.134220, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 9823 episodes
GETTING ACTION FROM:
action 4, numVisits=12668, meanQ=32.922849, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 2 0.530018 0.49279 0.0508701 0.472663 0.0447181 0.289039 0.574004 0.212118 0.533347 0.315787 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 34
Initial state: 0 0.524279 0.461072 0.620404 0.485767 0.408103 0.123483 0.11942 0.537334 0.902006 0.460374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17753 episodes
GETTING ACTION FROM:
action -1, numVisits=17734, meanQ=47.837266, numObservations: 243
action 0, numVisits=12, meanQ=-1.050000, numObservations: 12
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.524279 0.461072 0.620404 0.485767 0.408103 0.123483 0.11942 0.537334 0.902006 0.460374 w: 1
Observation: 0 2 0 3 0 2 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=73, meanQ=26.025342, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36300 episodes
GETTING ACTION FROM:
action 5, numVisits=36371, meanQ=8.395573, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.524279 0.461072 0.620404 0.485767 0.408103 0.123483 0.11942 0.537334 0.902006 0.460374 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 35
Initial state: 0 0.803741 0.836645 0.866386 0.235586 0.357939 0.164403 0.505086 0.405739 0.720386 0.458779 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30328 episodes
GETTING ACTION FROM:
action 1, numVisits=30281, meanQ=29.107830, numObservations: 9
action 3, numVisits=17, meanQ=14.347206, numObservations: 8
action 4, numVisits=7, meanQ=10.286071, numObservations: 5
action 2, numVisits=17, meanQ=8.494265, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=4, meanQ=-8.386875, numObservations: 3
action: 1
Next state: 1 0.803741 0.836645 0.866386 0.235586 0.357939 0.164403 0.505086 0.405739 0.720386 0.458779 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 36
Initial state: 0 0.0438225 0.559626 0.419707 0.0842906 0.608497 0.373608 0.411728 0.455998 0.512093 0.223584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27909 episodes
GETTING ACTION FROM:
action 3, numVisits=27902, meanQ=29.563137, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.0438225 0.559626 0.419707 0.0842906 0.608497 0.373608 0.411728 0.455998 0.512093 0.223584 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 37
Initial state: 0 0.671112 0.0434223 0.249136 0.984928 0.430793 0.433883 0.649892 0.109498 0.0785916 0.0967342 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28709 episodes
GETTING ACTION FROM:
action 3, numVisits=28589, meanQ=28.012015, numObservations: 9
action 1, numVisits=115, meanQ=18.606125, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.671112 0.0434223 0.249136 0.984928 0.430793 0.433883 0.649892 0.109498 0.0785916 0.0967342 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 38
Initial state: 0 0.272876 0.997352 0.976925 0.816631 0.414362 0.591254 0.55409 0.446395 0.965409 0.388485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17096 episodes
GETTING ACTION FROM:
action 0, numVisits=17033, meanQ=59.029357, numObservations: 243
action -1, numVisits=58, meanQ=-3.215345, numObservations: 51
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.272876 0.997352 0.976925 0.816631 0.414362 0.591254 0.55409 0.446395 0.965409 0.388485 w: 1
Observation: 0 0 3 0 3 0 3 0 2 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=76, meanQ=61.761776, numObservations: 9
action 3, numVisits=6, meanQ=32.333333, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32660 episodes
GETTING ACTION FROM:
action 2, numVisits=32736, meanQ=65.636267, numObservations: 9
action 3, numVisits=6, meanQ=32.333333, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.272876 0.997352 0.976925 0.816631 0.414362 0.591254 0.55409 0.446395 0.965409 0.388485 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 39
Initial state: 0 0.694567 0.795713 0.282533 0.292697 0.188061 0.48771 0.880902 0.121539 0.481209 0.436174 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29520 episodes
GETTING ACTION FROM:
action 4, numVisits=29512, meanQ=28.062264, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.694567 0.795713 0.282533 0.292697 0.188061 0.48771 0.880902 0.121539 0.481209 0.436174 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 40
Initial state: 0 0.0617604 0.0233599 0.14533 0.0105298 0.94125 0.927981 0.0882115 0.829145 0.589392 0.481229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29715 episodes
GETTING ACTION FROM:
action 4, numVisits=29708, meanQ=29.565571, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0617604 0.0233599 0.14533 0.0105298 0.94125 0.927981 0.0882115 0.829145 0.589392 0.481229 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.83938 0.565139 0.25462 0.65212 0.575838 0.486142 0.998386 0.935768 0.446006 0.0727981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27259 episodes
GETTING ACTION FROM:
action 5, numVisits=27244, meanQ=28.958343, numObservations: 9
action 4, numVisits=8, meanQ=7.243750, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-6.316667, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.83938 0.565139 0.25462 0.65212 0.575838 0.486142 0.998386 0.935768 0.446006 0.0727981 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 42
Initial state: 0 0.534605 0.506322 0.709154 0.786012 0.846576 0.681773 0.892023 0.207855 0.755006 0.201166 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30172 episodes
GETTING ACTION FROM:
action 5, numVisits=30162, meanQ=29.594518, numObservations: 9
action 1, numVisits=5, meanQ=14.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.534605 0.506322 0.709154 0.786012 0.846576 0.681773 0.892023 0.207855 0.755006 0.201166 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 43
Initial state: 0 0.527396 0.381463 0.601884 0.624035 0.133026 0.404356 0.148901 0.294943 0.824378 0.328277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30160 episodes
GETTING ACTION FROM:
action 2, numVisits=30151, meanQ=28.882101, numObservations: 9
action 3, numVisits=4, meanQ=16.488125, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.527396 0.381463 0.601884 0.624035 0.133026 0.404356 0.148901 0.294943 0.824378 0.328277 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 44
Initial state: 0 0.238183 0.517453 0.222107 0.430453 0.597465 0.725237 0.159991 0.899065 0.434929 0.385137 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29933 episodes
GETTING ACTION FROM:
action 2, numVisits=29890, meanQ=29.086090, numObservations: 9
action 4, numVisits=24, meanQ=26.189792, numObservations: 8
action 1, numVisits=4, meanQ=21.500000, numObservations: 3
action 3, numVisits=12, meanQ=19.746250, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.238183 0.517453 0.222107 0.430453 0.597465 0.725237 0.159991 0.899065 0.434929 0.385137 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 45
Initial state: 0 0.00911906 0.845955 0.668911 0.971516 0.553138 0.471345 0.954947 0.781339 0.366189 0.834613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28257 episodes
GETTING ACTION FROM:
action 1, numVisits=28250, meanQ=30.124903, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.00911906 0.845955 0.668911 0.971516 0.553138 0.471345 0.954947 0.781339 0.366189 0.834613 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=2726, meanQ=52.439521, numObservations: 216
action 0, numVisits=18, meanQ=-6.433333, numObservations: 17
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5218 episodes
GETTING ACTION FROM:
action -1, numVisits=7944, meanQ=38.384801, numObservations: 242
action 0, numVisits=18, meanQ=-6.433333, numObservations: 17
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.00911906 0.845955 0.668911 0.971516 0.553138 0.471345 0.954947 0.781339 0.366189 0.834613 w: 1
Observation: 0 3 0 3 0 2 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1, meanQ=99.000000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32780 episodes
GETTING ACTION FROM:
action 2, numVisits=32742, meanQ=44.545627, numObservations: 9
action 1, numVisits=7, meanQ=38.857500, numObservations: 4
action 4, numVisits=26, meanQ=2.435366, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.525000, numObservations: 2
action 0, numVisits=2, meanQ=-1.525000, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.00911906 0.845955 0.668911 0.971516 0.553138 0.471345 0.954947 0.781339 0.366189 0.834613 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 46
Initial state: 0 0.907229 0.15943 0.855312 0.10983 0.712323 0.870293 0.0404012 0.59643 0.414962 0.510661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29436 episodes
GETTING ACTION FROM:
action 1, numVisits=29429, meanQ=28.866279, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.907229 0.15943 0.855312 0.10983 0.712323 0.870293 0.0404012 0.59643 0.414962 0.510661 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 47
Initial state: 0 0.337578 0.0800143 0.131604 0.0462881 0.784856 0.326425 0.476626 0.396114 0.878153 0.365781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28987 episodes
GETTING ACTION FROM:
action 1, numVisits=28978, meanQ=28.649599, numObservations: 9
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.337578 0.0800143 0.131604 0.0462881 0.784856 0.326425 0.476626 0.396114 0.878153 0.365781 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2890, meanQ=35.118946, numObservations: 9
action 3, numVisits=10, meanQ=6.285000, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 10119 episodes
GETTING ACTION FROM:
action 5, numVisits=13009, meanQ=26.028995, numObservations: 9
action 3, numVisits=10, meanQ=6.285000, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.337578 0.0800143 0.131604 0.0462881 0.784856 0.326425 0.476626 0.396114 0.878153 0.365781 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=208, meanQ=45.200997, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18406 episodes
GETTING ACTION FROM:
action 4, numVisits=18614, meanQ=15.375451, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.337578 0.0800143 0.131604 0.0462881 0.784856 0.326425 0.476626 0.396114 0.878153 0.365781 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 48
Initial state: 0 0.492764 0.459076 0.688087 0.0474618 0.486734 0.803799 0.189793 0.611999 0.510039 0.559635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29499 episodes
GETTING ACTION FROM:
action 4, numVisits=28839, meanQ=28.993212, numObservations: 9
action 2, numVisits=655, meanQ=21.647394, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.492764 0.459076 0.688087 0.0474618 0.486734 0.803799 0.189793 0.611999 0.510039 0.559635 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2923, meanQ=35.955824, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 9244 episodes
GETTING ACTION FROM:
action 2, numVisits=12167, meanQ=29.943747, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.492764 0.459076 0.688087 0.0474618 0.486734 0.803799 0.189793 0.611999 0.510039 0.559635 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 49
Initial state: 0 0.693469 0.135059 0.174019 0.580785 0.246916 0.957364 0.26479 0.092689 0.445412 0.39602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28894 episodes
GETTING ACTION FROM:
action 4, numVisits=28879, meanQ=27.972669, numObservations: 9
action 3, numVisits=10, meanQ=7.405000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.693469 0.135059 0.174019 0.580785 0.246916 0.957364 0.26479 0.092689 0.445412 0.39602 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2798, meanQ=33.358681, numObservations: 9
action 2, numVisits=9, meanQ=29.661111, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 8760 episodes
GETTING ACTION FROM:
action 3, numVisits=11557, meanQ=28.228220, numObservations: 9
action 2, numVisits=10, meanQ=16.595000, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.693469 0.135059 0.174019 0.580785 0.246916 0.957364 0.26479 0.092689 0.445412 0.39602 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=955, meanQ=48.965638, numObservations: 9
action 1, numVisits=8, meanQ=29.531562, numObservations: 5
action 5, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 9432 episodes
GETTING ACTION FROM:
action 1, numVisits=9400, meanQ=52.057864, numObservations: 9
action 3, numVisits=956, meanQ=48.946415, numObservations: 9
action 0, numVisits=25, meanQ=-6.340418, numObservations: 19
action -1, numVisits=14, meanQ=-8.381964, numObservations: 11
action 5, numVisits=5, meanQ=-24.620000, numObservations: 5
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.693469 0.135059 0.174019 0.580785 0.246916 0.957364 0.26479 0.092689 0.445412 0.39602 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -112.603
Run # 50
Initial state: 0 0.882688 0.195537 0.577926 0.425266 0.123854 0.660118 0.637384 0.102079 0.434416 0.550408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28674 episodes
GETTING ACTION FROM:
action 2, numVisits=28659, meanQ=29.286602, numObservations: 9
action 4, numVisits=7, meanQ=22.435714, numObservations: 4
action 3, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.882688 0.195537 0.577926 0.425266 0.123854 0.660118 0.637384 0.102079 0.434416 0.550408 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
[32m ProblemEnvironment.hpp 351: Done.[39m
