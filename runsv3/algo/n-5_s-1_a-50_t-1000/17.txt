Run # 1
Initial state: 0 0.060204 0.329479 0.621193 0.832841 0.235261 0.302761 0.427536 0.113225 0.681331 0.392853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17065 episodes
GETTING ACTION FROM:
action 0, numVisits=17046, meanQ=59.401702, numObservations: 243
action -1, numVisits=14, meanQ=-1.799821, numObservations: 13
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.060204 0.329479 0.621193 0.832841 0.235261 0.302761 0.427536 0.113225 0.681331 0.392853 w: 1
Observation: 0 0 2 0 3 0 1 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=46, meanQ=36.313370, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33729 episodes
GETTING ACTION FROM:
action 1, numVisits=33775, meanQ=79.742780, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.060204 0.329479 0.621193 0.832841 0.235261 0.302761 0.427536 0.113225 0.681331 0.392853 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=1607, meanQ=81.653594, numObservations: 9
action 2, numVisits=9, meanQ=62.433611, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 19292 episodes
GETTING ACTION FROM:
action 5, numVisits=20899, meanQ=75.829702, numObservations: 9
action 2, numVisits=9, meanQ=62.433611, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 0 0.060204 0.329479 0.621193 0.832841 0.235261 0.302761 0.427536 0.113225 0.681331 0.392853 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=97, meanQ=87.392504, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 16325 episodes
GETTING ACTION FROM:
action 5, numVisits=108, meanQ=88.427064, numObservations: 9
action 2, numVisits=16269, meanQ=76.967894, numObservations: 9
action -1, numVisits=24, meanQ=-1.920833, numObservations: 15
action 0, numVisits=24, meanQ=-1.920833, numObservations: 15
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.060204 0.329479 0.621193 0.832841 0.235261 0.302761 0.427536 0.113225 0.681331 0.392853 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 62.5026
Run # 2
Initial state: 0 0.6722 0.621299 0.952979 0.240172 0.385932 0.203065 0.644669 0.362063 0.168298 0.0419783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26152 episodes
GETTING ACTION FROM:
action 5, numVisits=26126, meanQ=41.885398, numObservations: 9
action 2, numVisits=20, meanQ=15.320125, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.6722 0.621299 0.952979 0.240172 0.385932 0.203065 0.644669 0.362063 0.168298 0.0419783 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1332, meanQ=46.462658, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5883 episodes
GETTING ACTION FROM:
action 1, numVisits=7215, meanQ=50.639121, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.6722 0.621299 0.952979 0.240172 0.385932 0.203065 0.644669 0.362063 0.168298 0.0419783 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 3
Initial state: 0 0.628816 0.226139 0.808875 0.769868 0.631003 0.372183 0.794275 0.102037 0.643907 0.784703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17122 episodes
GETTING ACTION FROM:
action -1, numVisits=17103, meanQ=56.751581, numObservations: 243
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action 0, numVisits=12, meanQ=-9.125000, numObservations: 11
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.628816 0.226139 0.808875 0.769868 0.631003 0.372183 0.794275 0.102037 0.643907 0.784703 w: 1
Observation: 0 2 0 3 0 2 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16683 episodes
GETTING ACTION FROM:
action -1, numVisits=16660, meanQ=57.998981, numObservations: 242
action 0, numVisits=17, meanQ=-1.164559, numObservations: 16
action 3, numVisits=4, meanQ=-6.000000, numObservations: 4
action 2, numVisits=5, meanQ=-21.000000, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.628816 0.226139 0.808875 0.769868 0.631003 0.372183 0.794275 0.102037 0.643907 0.784703 w: 1
Observation: 0 2 0 3 0 2 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=150, meanQ=62.239367, numObservations: 9
action 4, numVisits=6, meanQ=32.333333, numObservations: 3
action 5, numVisits=6, meanQ=32.333333, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33792 episodes
GETTING ACTION FROM:
action 1, numVisits=33942, meanQ=66.152824, numObservations: 9
action 4, numVisits=6, meanQ=32.333333, numObservations: 3
action 5, numVisits=6, meanQ=32.333333, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.628816 0.226139 0.808875 0.769868 0.631003 0.372183 0.794275 0.102037 0.643907 0.784703 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=863, meanQ=90.942889, numObservations: 9
action 4, numVisits=34, meanQ=33.761765, numObservations: 7
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 46216 episodes
GETTING ACTION FROM:
action 1, numVisits=896, meanQ=91.211545, numObservations: 9
action 4, numVisits=46216, meanQ=39.590076, numObservations: 9
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 2 0.628816 0.226139 0.808875 0.769868 0.631003 0.372183 0.794275 0.102037 0.643907 0.784703 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -100.422
Run # 4
Initial state: 0 0.0517337 0.771495 0.73718 0.865146 0.90994 0.705011 0.660321 0.354344 0.680301 0.156384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26601 episodes
GETTING ACTION FROM:
action 3, numVisits=26571, meanQ=42.108022, numObservations: 9
action -1, numVisits=13, meanQ=-1.050000, numObservations: 13
action 0, numVisits=13, meanQ=-1.050000, numObservations: 13
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.0517337 0.771495 0.73718 0.865146 0.90994 0.705011 0.660321 0.354344 0.680301 0.156384 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 5
Initial state: 0 0.642588 0.353549 0.616091 0.42717 0.646667 0.951631 0.0557415 0.604227 0.211159 0.806014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26347 episodes
GETTING ACTION FROM:
action 4, numVisits=26337, meanQ=40.111883, numObservations: 9
action 3, numVisits=4, meanQ=21.500000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.642588 0.353549 0.616091 0.42717 0.646667 0.951631 0.0557415 0.604227 0.211159 0.806014 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 6
Initial state: 0 0.961476 0.306811 0.135394 0.67271 0.87638 0.530907 0.634218 0.394583 0.638612 0.255669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 23687 episodes
GETTING ACTION FROM:
action 3, numVisits=23681, meanQ=41.415496, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.961476 0.306811 0.135394 0.67271 0.87638 0.530907 0.634218 0.394583 0.638612 0.255669 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 7
Initial state: 0 0.688988 0.352544 0.557976 0.153089 0.167415 0.987844 0.805069 0.325553 0.0450922 0.752725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25307 episodes
GETTING ACTION FROM:
action 5, numVisits=25301, meanQ=40.287213, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.688988 0.352544 0.557976 0.153089 0.167415 0.987844 0.805069 0.325553 0.0450922 0.752725 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 8
Initial state: 0 0.666823 0.352592 0.921983 0.614634 0.498318 0.379081 0.132021 0.797951 0.98513 0.41123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16939 episodes
GETTING ACTION FROM:
action 0, numVisits=16911, meanQ=57.694978, numObservations: 243
action -1, numVisits=23, meanQ=-1.756304, numObservations: 19
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.666823 0.352592 0.921983 0.614634 0.498318 0.379081 0.132021 0.797951 0.98513 0.41123 w: 1
Observation: 0 0 2 0 3 0 2 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=31, meanQ=80.988790, numObservations: 5
action 2, numVisits=8, meanQ=71.494063, numObservations: 2
action 1, numVisits=3, meanQ=62.650000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 21047 episodes
GETTING ACTION FROM:
action 4, numVisits=21065, meanQ=59.689199, numObservations: 9
action 2, numVisits=15, meanQ=54.330167, numObservations: 4
action 1, numVisits=9, meanQ=50.772222, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.666823 0.352592 0.921983 0.614634 0.498318 0.379081 0.132021 0.797951 0.98513 0.41123 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=514, meanQ=51.106627, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 8716 episodes
GETTING ACTION FROM:
action 3, numVisits=9230, meanQ=54.475469, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 0 0.666823 0.352592 0.921983 0.614634 0.498318 0.379081 0.132021 0.797951 0.98513 0.41123 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=565, meanQ=76.703825, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 14975 episodes
GETTING ACTION FROM:
action 5, numVisits=15540, meanQ=76.403151, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.666823 0.352592 0.921983 0.614634 0.498318 0.379081 0.132021 0.797951 0.98513 0.41123 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 62.5026
Run # 9
Initial state: 0 0.676031 0.431199 0.707215 0.912629 0.65864 0.923356 0.789575 0.105707 0.42142 0.925906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26182 episodes
GETTING ACTION FROM:
action 2, numVisits=26171, meanQ=41.551863, numObservations: 9
action 3, numVisits=5, meanQ=7.181000, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.676031 0.431199 0.707215 0.912629 0.65864 0.923356 0.789575 0.105707 0.42142 0.925906 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 10
Initial state: 0 0.762613 0.2101 0.902365 0.509979 0.651869 0.634936 0.940426 0.263125 0.714969 0.412509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 23742 episodes
GETTING ACTION FROM:
action 1, numVisits=23727, meanQ=41.266747, numObservations: 9
action 2, numVisits=10, meanQ=8.000000, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.762613 0.2101 0.902365 0.509979 0.651869 0.634936 0.940426 0.263125 0.714969 0.412509 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 11
Initial state: 0 0.561394 0.508331 0.29973 0.174941 0.244401 0.500521 0.641024 0.42081 0.594022 0.86497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26202 episodes
GETTING ACTION FROM:
action 5, numVisits=26196, meanQ=42.034784, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.561394 0.508331 0.29973 0.174941 0.244401 0.500521 0.641024 0.42081 0.594022 0.86497 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4710, meanQ=46.360333, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 8485 episodes
GETTING ACTION FROM:
action 1, numVisits=13195, meanQ=49.212036, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.561394 0.508331 0.29973 0.174941 0.244401 0.500521 0.641024 0.42081 0.594022 0.86497 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1695, meanQ=50.176205, numObservations: 9
action 3, numVisits=4, meanQ=43.936905, numObservations: 4
action 4, numVisits=5, meanQ=37.190000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 5256 episodes
GETTING ACTION FROM:
action 2, numVisits=6951, meanQ=60.553362, numObservations: 9
action 3, numVisits=4, meanQ=43.936905, numObservations: 4
action 4, numVisits=5, meanQ=37.190000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 0 0.561394 0.508331 0.29973 0.174941 0.244401 0.500521 0.641024 0.42081 0.594022 0.86497 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=496, meanQ=53.124809, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 7157 episodes
GETTING ACTION FROM:
action 4, numVisits=7653, meanQ=50.458899, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.561394 0.508331 0.29973 0.174941 0.244401 0.500521 0.641024 0.42081 0.594022 0.86497 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 53.5026
Run # 12
Initial state: 0 0.415496 0.686275 0.235081 0.19317 0.376369 0.187321 0.71179 0.341701 0.545831 0.212607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26310 episodes
GETTING ACTION FROM:
action 3, numVisits=26303, meanQ=40.988223, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.415496 0.686275 0.235081 0.19317 0.376369 0.187321 0.71179 0.341701 0.545831 0.212607 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=4658, meanQ=46.828644, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 9951 episodes
GETTING ACTION FROM:
action 5, numVisits=14609, meanQ=54.106548, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.415496 0.686275 0.235081 0.19317 0.376369 0.187321 0.71179 0.341701 0.545831 0.212607 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=119, meanQ=34.418895, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11800 episodes
GETTING ACTION FROM:
action 4, numVisits=11919, meanQ=26.314960, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.415496 0.686275 0.235081 0.19317 0.376369 0.187321 0.71179 0.341701 0.545831 0.212607 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 13
Initial state: 0 0.89177 0.0823798 0.415441 0.0168455 0.679648 0.486185 0.657572 0.404724 0.604133 0.259104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26649 episodes
GETTING ACTION FROM:
action 2, numVisits=26618, meanQ=43.041641, numObservations: 9
action 5, numVisits=8, meanQ=21.375312, numObservations: 5
action 3, numVisits=19, meanQ=21.147763, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.89177 0.0823798 0.415441 0.0168455 0.679648 0.486185 0.657572 0.404724 0.604133 0.259104 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3387, meanQ=49.243940, numObservations: 9
action 3, numVisits=2, meanQ=44.475000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5679 episodes
GETTING ACTION FROM:
action 1, numVisits=9049, meanQ=45.408285, numObservations: 9
action 3, numVisits=19, meanQ=38.247864, numObservations: 8
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.89177 0.0823798 0.415441 0.0168455 0.679648 0.486185 0.657572 0.404724 0.604133 0.259104 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 14
Initial state: 0 0.483789 0.406563 0.708487 0.822822 0.417023 0.147463 0.68121 0.39644 0.417039 0.152324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26223 episodes
GETTING ACTION FROM:
action 4, numVisits=26215, meanQ=40.774883, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.483789 0.406563 0.708487 0.822822 0.417023 0.147463 0.68121 0.39644 0.417039 0.152324 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 15
Initial state: 0 0.335359 0.126463 0.448333 0.546108 0.658857 0.434063 0.76431 0.150052 0.739203 0.192859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17048 episodes
GETTING ACTION FROM:
action 0, numVisits=17029, meanQ=61.958064, numObservations: 243
action -1, numVisits=14, meanQ=-1.799821, numObservations: 13
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.335359 0.126463 0.448333 0.546108 0.658857 0.434063 0.76431 0.150052 0.739203 0.192859 w: 1
Observation: 0 0 1 0 3 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=54, meanQ=63.756574, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34744 episodes
GETTING ACTION FROM:
action 3, numVisits=34798, meanQ=87.752836, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.335359 0.126463 0.448333 0.546108 0.658857 0.434063 0.76431 0.150052 0.739203 0.192859 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 16
Initial state: 0 0.504375 0.11578 0.889817 0.902993 0.941357 0.458874 0.0601275 0.664631 0.720771 0.35866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 22887 episodes
GETTING ACTION FROM:
action 3, numVisits=22871, meanQ=43.864735, numObservations: 9
action 4, numVisits=8, meanQ=18.044062, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=4, meanQ=-5.762500, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.504375 0.11578 0.889817 0.902993 0.941357 0.458874 0.0601275 0.664631 0.720771 0.35866 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 17
Initial state: 0 0.984896 0.000922782 0.30479 0.0790776 0.880138 0.733694 0.458863 0.167289 0.64232 0.396008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25560 episodes
GETTING ACTION FROM:
action 4, numVisits=25552, meanQ=41.838700, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.984896 0.000922782 0.30479 0.0790776 0.880138 0.733694 0.458863 0.167289 0.64232 0.396008 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=3337, meanQ=50.015801, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 6571 episodes
GETTING ACTION FROM:
action 5, numVisits=9908, meanQ=44.628151, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.984896 0.000922782 0.30479 0.0790776 0.880138 0.733694 0.458863 0.167289 0.64232 0.396008 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 18
Initial state: 0 0.404271 0.315252 0.967193 0.279892 0.637748 0.99281 0.564802 0.696524 0.645971 0.415484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26776 episodes
GETTING ACTION FROM:
action 5, numVisits=26770, meanQ=42.923484, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.404271 0.315252 0.967193 0.279892 0.637748 0.99281 0.564802 0.696524 0.645971 0.415484 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 19
Initial state: 0 0.648454 0.999729 0.546309 0.436414 0.229048 0.439004 0.117911 0.598276 0.643187 0.429335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26683 episodes
GETTING ACTION FROM:
action 5, numVisits=26677, meanQ=40.219928, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.648454 0.999729 0.546309 0.436414 0.229048 0.439004 0.117911 0.598276 0.643187 0.429335 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 20
Initial state: 0 0.996929 0.439066 0.26545 0.219287 0.672996 0.364432 0.95394 0.887021 0.0827593 0.666732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26113 episodes
GETTING ACTION FROM:
action 5, numVisits=26107, meanQ=40.198446, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.996929 0.439066 0.26545 0.219287 0.672996 0.364432 0.95394 0.887021 0.0827593 0.666732 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4678, meanQ=45.513701, numObservations: 9
action 5, numVisits=3, meanQ=25.650833, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 7296 episodes
GETTING ACTION FROM:
action 1, numVisits=11974, meanQ=46.491867, numObservations: 9
action 5, numVisits=3, meanQ=25.650833, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.996929 0.439066 0.26545 0.219287 0.672996 0.364432 0.95394 0.887021 0.0827593 0.666732 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 21
Initial state: 0 0.535311 0.196008 0.169388 0.784208 0.909169 0.217499 0.457436 0.302054 0.627062 0.343385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26281 episodes
GETTING ACTION FROM:
action 4, numVisits=26275, meanQ=39.812608, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.535311 0.196008 0.169388 0.784208 0.909169 0.217499 0.457436 0.302054 0.627062 0.343385 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=3323, meanQ=46.180415, numObservations: 9
action 2, numVisits=5, meanQ=37.190000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 4908 episodes
GETTING ACTION FROM:
action 5, numVisits=8231, meanQ=44.953777, numObservations: 9
action 2, numVisits=5, meanQ=37.190000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.535311 0.196008 0.169388 0.784208 0.909169 0.217499 0.457436 0.302054 0.627062 0.343385 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 22
Initial state: 0 0.644428 0.378465 0.535301 0.366922 0.254248 0.688153 0.815812 0.0378929 0.0628902 0.031886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25178 episodes
GETTING ACTION FROM:
action 4, numVisits=24765, meanQ=40.263625, numObservations: 9
action 1, numVisits=392, meanQ=31.565933, numObservations: 9
action 3, numVisits=9, meanQ=30.000278, numObservations: 4
action 2, numVisits=7, meanQ=21.278571, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 4
Next state: 2 0.644428 0.378465 0.535301 0.366922 0.254248 0.688153 0.815812 0.0378929 0.0628902 0.031886 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 23
Initial state: 0 0.406466 0.0862599 0.963729 0.308123 0.629267 0.371315 0.28323 0.692035 0.388406 0.184933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26191 episodes
GETTING ACTION FROM:
action 5, numVisits=26184, meanQ=39.775550, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.406466 0.0862599 0.963729 0.308123 0.629267 0.371315 0.28323 0.692035 0.388406 0.184933 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3385, meanQ=46.278117, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 6420 episodes
GETTING ACTION FROM:
action 1, numVisits=9805, meanQ=43.726052, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.406466 0.0862599 0.963729 0.308123 0.629267 0.371315 0.28323 0.692035 0.388406 0.184933 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1117, meanQ=53.220776, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 4185 episodes
GETTING ACTION FROM:
action 3, numVisits=5302, meanQ=47.265037, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.406466 0.0862599 0.963729 0.308123 0.629267 0.371315 0.28323 0.692035 0.388406 0.184933 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 24
Initial state: 0 0.241696 0.776954 0.703972 0.419532 0.698079 0.617338 0.959528 0.713294 0.676372 0.196992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 24217 episodes
GETTING ACTION FROM:
action 3, numVisits=24209, meanQ=42.341954, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.241696 0.776954 0.703972 0.419532 0.698079 0.617338 0.959528 0.713294 0.676372 0.196992 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 25
Initial state: 0 0.724634 0.334662 0.927674 0.684605 0.229145 0.677035 0.253523 0.617342 0.865469 0.0287425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26007 episodes
GETTING ACTION FROM:
action 1, numVisits=25982, meanQ=40.229138, numObservations: 9
action 3, numVisits=10, meanQ=12.990500, numObservations: 5
action 5, numVisits=9, meanQ=3.939444, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.724634 0.334662 0.927674 0.684605 0.229145 0.677035 0.253523 0.617342 0.865469 0.0287425 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 26
Initial state: 0 0.849057 0.259742 0.285377 0.356367 0.68338 0.558415 0.725145 0.402723 0.552593 0.28984 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25223 episodes
GETTING ACTION FROM:
action 4, numVisits=25209, meanQ=40.945944, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=6, meanQ=-5.325000, numObservations: 4
action 1, numVisits=4, meanQ=-6.000000, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.849057 0.259742 0.285377 0.356367 0.68338 0.558415 0.725145 0.402723 0.552593 0.28984 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 27
Initial state: 0 0.655721 0.381877 0.638462 0.149918 0.280203 0.777187 0.513827 0.477473 0.668697 0.496878 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 23363 episodes
GETTING ACTION FROM:
action 5, numVisits=23357, meanQ=40.866981, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.655721 0.381877 0.638462 0.149918 0.280203 0.777187 0.513827 0.477473 0.668697 0.496878 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 28
Initial state: 0 0.972107 0.889874 0.697983 0.395564 0.46924 0.57345 0.409643 0.556903 0.863324 0.649009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17218 episodes
GETTING ACTION FROM:
action 0, numVisits=17190, meanQ=61.515104, numObservations: 243
action -1, numVisits=17, meanQ=-1.667500, numObservations: 16
action 1, numVisits=7, meanQ=-6.135714, numObservations: 6
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.972107 0.889874 0.697983 0.395564 0.46924 0.57345 0.409643 0.556903 0.863324 0.649009 w: 1
Observation: 0 0 3 0 2 0 3 0 2 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22, meanQ=54.654886, numObservations: 5
action 1, numVisits=20, meanQ=49.918125, numObservations: 6
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 24842 episodes
GETTING ACTION FROM:
action 3, numVisits=24863, meanQ=53.966990, numObservations: 9
action 1, numVisits=21, meanQ=46.969762, numObservations: 6
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.972107 0.889874 0.697983 0.395564 0.46924 0.57345 0.409643 0.556903 0.863324 0.649009 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 29
Initial state: 0 0.0865108 0.653954 0.886559 0.779197 0.689267 0.427385 0.490544 0.189871 0.30741 0.152837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 24537 episodes
GETTING ACTION FROM:
action 2, numVisits=24530, meanQ=42.168304, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0865108 0.653954 0.886559 0.779197 0.689267 0.427385 0.490544 0.189871 0.30741 0.152837 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 30
Initial state: 0 0.735775 0.846587 0.657795 0.381157 0.259635 0.600705 0.519438 0.951975 0.849735 0.0622492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26078 episodes
GETTING ACTION FROM:
action 1, numVisits=26058, meanQ=39.791262, numObservations: 9
action 2, numVisits=14, meanQ=23.793036, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.735775 0.846587 0.657795 0.381157 0.259635 0.600705 0.519438 0.951975 0.849735 0.0622492 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 31
Initial state: 0 0.459459 0.0271652 0.716762 0.364458 0.552066 0.121645 0.462487 0.426623 0.922308 0.134464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26524 episodes
GETTING ACTION FROM:
action 4, numVisits=26516, meanQ=41.712445, numObservations: 9
action 1, numVisits=3, meanQ=25.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.459459 0.0271652 0.716762 0.364458 0.552066 0.121645 0.462487 0.426623 0.922308 0.134464 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 32
Initial state: 0 0.724771 0.0576898 0.343702 0.678719 0.779896 0.156911 0.0230277 0.561118 0.634845 0.370747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26740 episodes
GETTING ACTION FROM:
action 2, numVisits=26728, meanQ=40.777367, numObservations: 9
action 4, numVisits=5, meanQ=31.280500, numObservations: 4
action 5, numVisits=3, meanQ=22.484167, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.724771 0.0576898 0.343702 0.678719 0.779896 0.156911 0.0230277 0.561118 0.634845 0.370747 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4729, meanQ=46.804925, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 8006 episodes
GETTING ACTION FROM:
action 3, numVisits=12735, meanQ=50.045616, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 0 0.724771 0.0576898 0.343702 0.678719 0.779896 0.156911 0.0230277 0.561118 0.634845 0.370747 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=122, meanQ=14.086003, numObservations: 59
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=5, meanQ=-20.430000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 8726 episodes
GETTING ACTION FROM:
action -1, numVisits=8848, meanQ=8.513794, numObservations: 214
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=5, meanQ=-20.430000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.724771 0.0576898 0.343702 0.678719 0.779896 0.156911 0.0230277 0.561118 0.634845 0.370747 w: 1
Observation: 0 2 0 3 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32975 episodes
GETTING ACTION FROM:
action 1, numVisits=32969, meanQ=37.186626, numObservations: 9
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.724771 0.0576898 0.343702 0.678719 0.779896 0.156911 0.0230277 0.561118 0.634845 0.370747 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -109.85
Run # 33
Initial state: 0 0.654976 0.400555 0.692926 0.180941 0.846359 0.678917 0.779296 0.0598878 0.85126 0.881231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17374 episodes
GETTING ACTION FROM:
action -1, numVisits=17342, meanQ=62.099578, numObservations: 243
action 0, numVisits=25, meanQ=-1.202000, numObservations: 23
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.654976 0.400555 0.692926 0.180941 0.846359 0.678917 0.779296 0.0598878 0.85126 0.881231 w: 1
Observation: 0 3 0 2 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17782 episodes
GETTING ACTION FROM:
action -1, numVisits=17694, meanQ=72.112420, numObservations: 226
action 1, numVisits=90, meanQ=0.296833, numObservations: 9
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.654976 0.400555 0.692926 0.180941 0.846359 0.678917 0.779296 0.0598878 0.85126 0.881231 w: 1
Observation: 0 2 0 2 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=503, meanQ=86.545349, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37424 episodes
GETTING ACTION FROM:
action 2, numVisits=37927, meanQ=91.959554, numObservations: 9
action 5, numVisits=3, meanQ=32.333333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.654976 0.400555 0.692926 0.180941 0.846359 0.678917 0.779296 0.0598878 0.85126 0.881231 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -95.0525
Run # 34
Initial state: 0 0.293589 0.984412 0.674703 0.366245 0.592017 0.48772 0.462553 0.83233 0.339882 0.654189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 24900 episodes
GETTING ACTION FROM:
action 1, numVisits=24894, meanQ=40.532463, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.293589 0.984412 0.674703 0.366245 0.592017 0.48772 0.462553 0.83233 0.339882 0.654189 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4461, meanQ=44.434256, numObservations: 9
action 4, numVisits=5, meanQ=37.190000, numObservations: 3
action 5, numVisits=16, meanQ=34.237500, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 7930 episodes
GETTING ACTION FROM:
action 2, numVisits=12391, meanQ=48.695907, numObservations: 9
action 4, numVisits=5, meanQ=37.190000, numObservations: 3
action 5, numVisits=16, meanQ=34.237500, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.293589 0.984412 0.674703 0.366245 0.592017 0.48772 0.462553 0.83233 0.339882 0.654189 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 35
Initial state: 0 0.700092 0.346697 0.583316 0.229203 0.00794143 0.592772 0.214836 0.859558 0.767944 0.116664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 24011 episodes
GETTING ACTION FROM:
action 1, numVisits=23997, meanQ=43.231877, numObservations: 9
action 3, numVisits=7, meanQ=26.142857, numObservations: 6
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.700092 0.346697 0.583316 0.229203 0.00794143 0.592772 0.214836 0.859558 0.767944 0.116664 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 36
Initial state: 0 0.348939 0.224195 0.238604 0.473417 0.978446 0.566853 0.640396 0.375948 0.72555 0.0394535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26414 episodes
GETTING ACTION FROM:
action 4, numVisits=26219, meanQ=41.422596, numObservations: 9
action 2, numVisits=190, meanQ=34.302759, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.348939 0.224195 0.238604 0.473417 0.978446 0.566853 0.640396 0.375948 0.72555 0.0394535 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 37
Initial state: 0 0.634102 0.800619 0.750991 0.953389 0.839866 0.167831 0.877833 0.0957673 0.656206 0.431828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25217 episodes
GETTING ACTION FROM:
action 2, numVisits=25199, meanQ=41.044951, numObservations: 9
action 4, numVisits=4, meanQ=21.500000, numObservations: 4
action 5, numVisits=4, meanQ=21.500000, numObservations: 2
action 3, numVisits=7, meanQ=10.428571, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.634102 0.800619 0.750991 0.953389 0.839866 0.167831 0.877833 0.0957673 0.656206 0.431828 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 38
Initial state: 0 0.626328 0.433831 0.913645 0.114808 0.837337 0.766751 0.596923 0.701268 0.470653 0.607217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26069 episodes
GETTING ACTION FROM:
action 1, numVisits=26049, meanQ=41.013133, numObservations: 9
action 2, numVisits=10, meanQ=34.140250, numObservations: 7
action 4, numVisits=6, meanQ=29.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.626328 0.433831 0.913645 0.114808 0.837337 0.766751 0.596923 0.701268 0.470653 0.607217 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 39
Initial state: 0 0.409372 0.25699 0.164752 0.773975 0.0560773 0.238617 0.332694 0.157805 0.662829 0.388545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25812 episodes
GETTING ACTION FROM:
action 3, numVisits=25798, meanQ=40.686472, numObservations: 9
action 2, numVisits=7, meanQ=26.142857, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.409372 0.25699 0.164752 0.773975 0.0560773 0.238617 0.332694 0.157805 0.662829 0.388545 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3341, meanQ=41.548569, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5111 episodes
GETTING ACTION FROM:
action 2, numVisits=8452, meanQ=39.123390, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.409372 0.25699 0.164752 0.773975 0.0560773 0.238617 0.332694 0.157805 0.662829 0.388545 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 40
Initial state: 0 0.878729 0.528915 0.209144 0.482029 0.695522 0.33494 0.856438 0.472176 0.303544 0.105529 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 24325 episodes
GETTING ACTION FROM:
action 3, numVisits=24314, meanQ=42.979618, numObservations: 9
action 4, numVisits=6, meanQ=22.642500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.878729 0.528915 0.209144 0.482029 0.695522 0.33494 0.856438 0.472176 0.303544 0.105529 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.283344 0.949879 0.731675 0.53562 0.67192 0.40866 0.891232 0.368881 0.191866 0.95949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 16673 episodes
GETTING ACTION FROM:
action -1, numVisits=16664, meanQ=58.926116, numObservations: 243
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 0, numVisits=4, meanQ=-25.275000, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.283344 0.949879 0.731675 0.53562 0.67192 0.40866 0.891232 0.368881 0.191866 0.95949 w: 1
Observation: 0 1 0 3 0 2 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=71, meanQ=77.423944, numObservations: 9
action 2, numVisits=8, meanQ=49.000000, numObservations: 5
action 1, numVisits=2, meanQ=44.475000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 35743 episodes
GETTING ACTION FROM:
action 3, numVisits=35814, meanQ=90.202252, numObservations: 9
action 2, numVisits=8, meanQ=49.000000, numObservations: 5
action 1, numVisits=2, meanQ=44.475000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 1 0.283344 0.949879 0.731675 0.53562 0.67192 0.40866 0.891232 0.368881 0.191866 0.95949 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 42
Initial state: 0 0.128599 0.926503 0.26107 0.505297 0.740826 0.207643 0.694644 0.3378 0.0264767 0.463368 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 23034 episodes
GETTING ACTION FROM:
action 4, numVisits=23015, meanQ=42.042767, numObservations: 9
action 3, numVisits=5, meanQ=33.000000, numObservations: 4
action 1, numVisits=7, meanQ=26.142857, numObservations: 5
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action: 4
Next state: 1 0.128599 0.926503 0.26107 0.505297 0.740826 0.207643 0.694644 0.3378 0.0264767 0.463368 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 43
Initial state: 0 0.265376 0.253453 0.504989 0.0348855 0.938097 0.854472 0.717528 0.384414 0.473973 0.192021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26180 episodes
GETTING ACTION FROM:
action 3, numVisits=26142, meanQ=39.401254, numObservations: 9
action 2, numVisits=14, meanQ=21.779107, numObservations: 6
action 1, numVisits=17, meanQ=21.694706, numObservations: 7
action 5, numVisits=4, meanQ=16.975000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.265376 0.253453 0.504989 0.0348855 0.938097 0.854472 0.717528 0.384414 0.473973 0.192021 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 44
Initial state: 0 0.626162 0.326743 0.681122 0.728489 0.310089 0.788765 0.897507 0.372356 0.266028 0.113591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26250 episodes
GETTING ACTION FROM:
action 4, numVisits=26244, meanQ=41.823763, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.626162 0.326743 0.681122 0.728489 0.310089 0.788765 0.897507 0.372356 0.266028 0.113591 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 45
Initial state: 0 0.785225 0.309376 0.973093 0.134026 0.843839 0.997815 0.299602 0.246008 0.682569 0.412358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17224 episodes
GETTING ACTION FROM:
action -1, numVisits=17204, meanQ=57.171791, numObservations: 243
action 0, numVisits=9, meanQ=-2.216389, numObservations: 8
action 2, numVisits=5, meanQ=-3.000000, numObservations: 3
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.785225 0.309376 0.973093 0.134026 0.843839 0.997815 0.299602 0.246008 0.682569 0.412358 w: 1
Observation: 0 3 0 3 0 2 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3, meanQ=62.650000, numObservations: 2
action 5, numVisits=4, meanQ=49.000000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35875 episodes
GETTING ACTION FROM:
action 2, numVisits=35876, meanQ=22.613924, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=6, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.785225 0.309376 0.973093 0.134026 0.843839 0.997815 0.299602 0.246008 0.682569 0.412358 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 46
Initial state: 0 0.69072 0.685638 0.653244 0.342942 0.903922 0.637731 0.304202 0.594958 0.37657 0.208589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26470 episodes
GETTING ACTION FROM:
action 4, numVisits=26440, meanQ=41.904828, numObservations: 9
action -1, numVisits=13, meanQ=-1.050000, numObservations: 13
action 0, numVisits=13, meanQ=-1.050000, numObservations: 13
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.69072 0.685638 0.653244 0.342942 0.903922 0.637731 0.304202 0.594958 0.37657 0.208589 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 47
Initial state: 0 0.715048 0.410291 0.585099 0.808361 0.453847 0.255897 0.439756 0.835514 0.56613 0.0865513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 24226 episodes
GETTING ACTION FROM:
action 1, numVisits=24192, meanQ=41.279515, numObservations: 9
action 2, numVisits=18, meanQ=10.597500, numObservations: 8
action 4, numVisits=12, meanQ=10.504375, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.715048 0.410291 0.585099 0.808361 0.453847 0.255897 0.439756 0.835514 0.56613 0.0865513 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 48
Initial state: 0 0.307338 0.922864 0.0293456 0.595406 0.669138 0.357316 0.609469 0.88655 0.215095 0.274107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 24311 episodes
GETTING ACTION FROM:
action 3, numVisits=24296, meanQ=42.919074, numObservations: 9
action 1, numVisits=10, meanQ=14.905000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.307338 0.922864 0.0293456 0.595406 0.669138 0.357316 0.609469 0.88655 0.215095 0.274107 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 49
Initial state: 0 0.350593 0.18182 0.855539 0.869481 0.0523878 0.691726 0.718546 0.358439 0.250913 0.424097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17082 episodes
GETTING ACTION FROM:
action -1, numVisits=17049, meanQ=61.483964, numObservations: 243
action 0, numVisits=25, meanQ=-4.926000, numObservations: 24
action 3, numVisits=4, meanQ=-6.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.350593 0.18182 0.855539 0.869481 0.0523878 0.691726 0.718546 0.358439 0.250913 0.424097 w: 1
Observation: 0 1 0 1 0 1 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=107, meanQ=63.834726, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 21356 episodes
GETTING ACTION FROM:
action 3, numVisits=21463, meanQ=53.107184, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.350593 0.18182 0.855539 0.869481 0.0523878 0.691726 0.718546 0.358439 0.250913 0.424097 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=108, meanQ=39.471814, numObservations: 37
action 0, numVisits=5, meanQ=-1.050000, numObservations: 5
action 4, numVisits=5, meanQ=-8.529500, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 5932 episodes
GETTING ACTION FROM:
action -1, numVisits=6040, meanQ=36.288746, numObservations: 151
action 0, numVisits=5, meanQ=-1.050000, numObservations: 5
action 4, numVisits=5, meanQ=-8.529500, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: -1
Next state: 0 0.350593 0.18182 0.855539 0.869481 0.0523878 0.691726 0.718546 0.358439 0.250913 0.424097 w: 1
Observation: 0 1 0 3 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 11102 episodes
GETTING ACTION FROM:
action 2, numVisits=11094, meanQ=61.058939, numObservations: 9
action 1, numVisits=3, meanQ=24.985161, numObservations: 2
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.350593 0.18182 0.855539 0.869481 0.0523878 0.691726 0.718546 0.358439 0.250913 0.424097 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 70.6251
Run # 50
Initial state: 0 0.988403 0.983861 0.232021 0.409867 0.681706 0.322918 0.384509 0.0522982 0.738924 0.111972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25042 episodes
GETTING ACTION FROM:
action 2, numVisits=25033, meanQ=40.024001, numObservations: 9
action 4, numVisits=4, meanQ=21.737500, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.988403 0.983861 0.232021 0.409867 0.681706 0.322918 0.384509 0.0522982 0.738924 0.111972 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1284, meanQ=46.663890, numObservations: 9
action 2, numVisits=3, meanQ=22.800833, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 5474 episodes
GETTING ACTION FROM:
action 1, numVisits=6758, meanQ=40.480077, numObservations: 9
action 2, numVisits=3, meanQ=22.800833, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.988403 0.983861 0.232021 0.409867 0.681706 0.322918 0.384509 0.0522982 0.738924 0.111972 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
[32m ProblemEnvironment.hpp 351: Done.[39m
