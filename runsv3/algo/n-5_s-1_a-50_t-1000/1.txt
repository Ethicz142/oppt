Run # 1
Initial state: 0 0.809985 0.677653 0.677887 0.258302 0.778929 0.998734 0.386703 0.443831 0.600853 0.562451 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17230 episodes
GETTING ACTION FROM:
action -1, numVisits=17187, meanQ=45.890020, numObservations: 243
action 0, numVisits=28, meanQ=-4.646429, numObservations: 25
action 5, numVisits=11, meanQ=-9.285227, numObservations: 5
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.809985 0.677653 0.677887 0.258302 0.778929 0.998734 0.386703 0.443831 0.600853 0.562451 w: 1
Observation: 0 3 0 3 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=93, meanQ=78.955968, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 36954 episodes
GETTING ACTION FROM:
action 5, numVisits=37047, meanQ=79.424068, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.809985 0.677653 0.677887 0.258302 0.778929 0.998734 0.386703 0.443831 0.600853 0.562451 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 2
Initial state: 0 0.487498 0.503206 0.244611 0.83586 0.503267 0.690639 0.173031 0.0405546 0.614565 0.712104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26739 episodes
GETTING ACTION FROM:
action 3, numVisits=26733, meanQ=15.345699, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.487498 0.503206 0.244611 0.83586 0.503267 0.690639 0.173031 0.0405546 0.614565 0.712104 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 3
Initial state: 0 0.312735 0.982664 0.968971 0.99099 0.887518 0.817905 0.0993315 0.0831578 0.515654 0.627794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17560 episodes
GETTING ACTION FROM:
action 0, numVisits=17536, meanQ=51.478705, numObservations: 243
action -1, numVisits=14, meanQ=-1.189107, numObservations: 13
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=6, meanQ=-19.333333, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.312735 0.982664 0.968971 0.99099 0.887518 0.817905 0.0993315 0.0831578 0.515654 0.627794 w: 1
Observation: 0 0 3 0 1 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=49, meanQ=69.715561, numObservations: 8
action 1, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36917 episodes
GETTING ACTION FROM:
action 5, numVisits=36966, meanQ=85.702336, numObservations: 9
action 1, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.312735 0.982664 0.968971 0.99099 0.887518 0.817905 0.0993315 0.0831578 0.515654 0.627794 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 4
Initial state: 0 0.580535 0.580023 0.036304 0.716019 0.14204 0.497164 0.252137 0.79806 0.694109 0.103922 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17466 episodes
GETTING ACTION FROM:
action 0, numVisits=17456, meanQ=52.487700, numObservations: 243
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=5, meanQ=-20.430000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.580535 0.580023 0.036304 0.716019 0.14204 0.497164 0.252137 0.79806 0.694109 0.103922 w: 1
Observation: 0 0 2 0 3 0 1 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=71, meanQ=83.134542, numObservations: 8
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37003 episodes
GETTING ACTION FROM:
action 1, numVisits=37074, meanQ=84.147789, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.580535 0.580023 0.036304 0.716019 0.14204 0.497164 0.252137 0.79806 0.694109 0.103922 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 5
Initial state: 0 0.772427 0.158812 0.509151 0.0336196 0.600742 0.674575 0.724065 0.387888 0.183287 0.978718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27375 episodes
GETTING ACTION FROM:
action 5, numVisits=25714, meanQ=14.461109, numObservations: 9
action 1, numVisits=1655, meanQ=12.896455, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.772427 0.158812 0.509151 0.0336196 0.600742 0.674575 0.724065 0.387888 0.183287 0.978718 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1922, meanQ=32.746962, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 10084 episodes
GETTING ACTION FROM:
action 2, numVisits=10041, meanQ=34.054330, numObservations: 9
action 5, numVisits=1931, meanQ=33.010891, numObservations: 9
action 0, numVisits=21, meanQ=-1.185714, numObservations: 21
action -1, numVisits=16, meanQ=-1.409219, numObservations: 15
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 2 0.772427 0.158812 0.509151 0.0336196 0.600742 0.674575 0.724065 0.387888 0.183287 0.978718 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 6
Initial state: 0 0.0113082 0.564905 0.87159 0.0544038 0.534032 0.612329 0.290857 0.00153405 0.460067 0.392901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27696 episodes
GETTING ACTION FROM:
action 2, numVisits=27689, meanQ=15.285167, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.0113082 0.564905 0.87159 0.0544038 0.534032 0.612329 0.290857 0.00153405 0.460067 0.392901 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 7
Initial state: 0 0.413886 0.0894196 0.54821 0.628159 0.823963 0.165298 0.630748 0.0867232 0.955199 0.708395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17369 episodes
GETTING ACTION FROM:
action 0, numVisits=17344, meanQ=50.694078, numObservations: 243
action 3, numVisits=4, meanQ=-6.000000, numObservations: 4
action 5, numVisits=8, meanQ=-6.743750, numObservations: 7
action -1, numVisits=10, meanQ=-10.740000, numObservations: 9
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.413886 0.0894196 0.54821 0.628159 0.823963 0.165298 0.630748 0.0867232 0.955199 0.708395 w: 1
Observation: 0 0 1 0 2 0 1 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=140, meanQ=76.752893, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37078 episodes
GETTING ACTION FROM:
action 2, numVisits=37218, meanQ=86.611725, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.413886 0.0894196 0.54821 0.628159 0.823963 0.165298 0.630748 0.0867232 0.955199 0.708395 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 8
Initial state: 0 0.26425 0.335239 0.224563 0.0123454 0.696421 0.431606 0.496473 0.632532 0.959583 0.749873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27982 episodes
GETTING ACTION FROM:
action 5, numVisits=27964, meanQ=15.015379, numObservations: 9
action 1, numVisits=8, meanQ=7.862812, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=5, meanQ=-6.620000, numObservations: 4
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.26425 0.335239 0.224563 0.0123454 0.696421 0.431606 0.496473 0.632532 0.959583 0.749873 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 9
Initial state: 0 0.415958 0.0443923 0.666355 0.172643 0.549808 0.611246 0.4173 0.247306 0.832348 0.93568 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27348 episodes
GETTING ACTION FROM:
action 5, numVisits=27325, meanQ=16.534112, numObservations: 9
action 2, numVisits=10, meanQ=3.700750, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=9, meanQ=-4.227778, numObservations: 6
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.415958 0.0443923 0.666355 0.172643 0.549808 0.611246 0.4173 0.247306 0.832348 0.93568 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 10
Initial state: 0 0.538615 0.64265 0.681959 0.432644 0.715879 0.487622 0.075091 0.137356 0.300303 0.623076 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27970 episodes
GETTING ACTION FROM:
action 4, numVisits=27956, meanQ=13.927774, numObservations: 9
action -1, numVisits=5, meanQ=-1.050000, numObservations: 5
action 0, numVisits=5, meanQ=-1.050000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.538615 0.64265 0.681959 0.432644 0.715879 0.487622 0.075091 0.137356 0.300303 0.623076 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2157, meanQ=22.168253, numObservations: 9
action 1, numVisits=5, meanQ=15.380000, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 10120 episodes
GETTING ACTION FROM:
action 5, numVisits=12277, meanQ=31.198583, numObservations: 9
action 1, numVisits=5, meanQ=15.380000, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 0 0.538615 0.64265 0.681959 0.432644 0.715879 0.487622 0.075091 0.137356 0.300303 0.623076 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=190, meanQ=51.672131, numObservations: 9
action 3, numVisits=214, meanQ=18.157225, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 10196 episodes
GETTING ACTION FROM:
action 1, numVisits=10386, meanQ=57.390917, numObservations: 9
action 3, numVisits=214, meanQ=18.157225, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 1 0.538615 0.64265 0.681959 0.432644 0.715879 0.487622 0.075091 0.137356 0.300303 0.623076 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 67.8975
Run # 11
Initial state: 0 0.70086 0.875278 0.66248 0.352368 0.403458 0.69545 0.523094 0.564294 0.842816 0.130949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26364 episodes
GETTING ACTION FROM:
action 4, numVisits=26323, meanQ=18.701013, numObservations: 9
action 3, numVisits=34, meanQ=12.953162, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.70086 0.875278 0.66248 0.352368 0.403458 0.69545 0.523094 0.564294 0.842816 0.130949 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 12
Initial state: 0 0.477734 0.404163 0.517832 0.577872 0.675461 0.532727 0.314031 0.174782 0.692009 0.961929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27768 episodes
GETTING ACTION FROM:
action 5, numVisits=23626, meanQ=16.260662, numObservations: 9
action 2, numVisits=4134, meanQ=12.419071, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.477734 0.404163 0.517832 0.577872 0.675461 0.532727 0.314031 0.174782 0.692009 0.961929 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 13
Initial state: 0 0.593677 0.634136 0.790518 0.326866 0.595832 0.370856 0.439651 0.884265 0.792586 0.504997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17607 episodes
GETTING ACTION FROM:
action -1, numVisits=17586, meanQ=46.587585, numObservations: 243
action 0, numVisits=16, meanQ=-1.706094, numObservations: 15
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.593677 0.634136 0.790518 0.326866 0.595832 0.370856 0.439651 0.884265 0.792586 0.504997 w: 1
Observation: 0 2 0 3 0 2 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=28, meanQ=36.176786, numObservations: 6
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=8, meanQ=-3.262500, numObservations: 5
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32368 episodes
GETTING ACTION FROM:
action 3, numVisits=32396, meanQ=65.931940, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=8, meanQ=-3.262500, numObservations: 5
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.593677 0.634136 0.790518 0.326866 0.595832 0.370856 0.439651 0.884265 0.792586 0.504997 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=409, meanQ=79.683307, numObservations: 9
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33844 episodes
GETTING ACTION FROM:
action 1, numVisits=34253, meanQ=72.066903, numObservations: 9
action 5, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.593677 0.634136 0.790518 0.326866 0.595832 0.370856 0.439651 0.884265 0.792586 0.504997 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 14
Initial state: 0 0.575668 0.783708 0.511672 0.246254 0.563286 0.621218 0.472203 0.45703 0.285634 0.704036 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25525 episodes
GETTING ACTION FROM:
action 5, numVisits=25454, meanQ=17.336250, numObservations: 9
action 0, numVisits=61, meanQ=-3.094836, numObservations: 50
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action -1, numVisits=4, meanQ=-25.275000, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.575668 0.783708 0.511672 0.246254 0.563286 0.621218 0.472203 0.45703 0.285634 0.704036 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=132, meanQ=30.666201, numObservations: 9
action 1, numVisits=11, meanQ=23.177273, numObservations: 5
action 3, numVisits=8, meanQ=19.743750, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 32235 episodes
GETTING ACTION FROM:
action 4, numVisits=32365, meanQ=28.299487, numObservations: 9
action 3, numVisits=8, meanQ=19.743750, numObservations: 4
action 1, numVisits=13, meanQ=19.457692, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.575668 0.783708 0.511672 0.246254 0.563286 0.621218 0.472203 0.45703 0.285634 0.704036 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=415, meanQ=50.313998, numObservations: 9
action 1, numVisits=10, meanQ=3.686830, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.016667, numObservations: 2
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 19636 episodes
GETTING ACTION FROM:
action 2, numVisits=20051, meanQ=32.270329, numObservations: 9
action 1, numVisits=10, meanQ=3.686830, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.016667, numObservations: 2
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.575668 0.783708 0.511672 0.246254 0.563286 0.621218 0.472203 0.45703 0.285634 0.704036 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -112.603
Run # 15
Initial state: 0 0.414831 0.959385 0.581239 0.608002 0.898241 0.140027 0.856395 0.673344 0.803259 0.626098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17602 episodes
GETTING ACTION FROM:
action -1, numVisits=17515, meanQ=46.952792, numObservations: 243
action 5, numVisits=40, meanQ=-2.677188, numObservations: 8
action 0, numVisits=43, meanQ=-3.391860, numObservations: 40
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.414831 0.959385 0.581239 0.608002 0.898241 0.140027 0.856395 0.673344 0.803259 0.626098 w: 1
Observation: 0 1 0 2 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=91, meanQ=77.931401, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37518 episodes
GETTING ACTION FROM:
action 2, numVisits=37609, meanQ=83.494728, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.414831 0.959385 0.581239 0.608002 0.898241 0.140027 0.856395 0.673344 0.803259 0.626098 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 16
Initial state: 0 0.412752 0.181366 0.523736 0.806387 0.929067 0.742038 0.709975 0.523876 0.586156 0.645686 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17331 episodes
GETTING ACTION FROM:
action -1, numVisits=17294, meanQ=44.960892, numObservations: 243
action 0, numVisits=19, meanQ=-1.602500, numObservations: 18
action 1, numVisits=5, meanQ=-2.810000, numObservations: 5
action 4, numVisits=8, meanQ=-4.243750, numObservations: 6
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.412752 0.181366 0.523736 0.806387 0.929067 0.742038 0.709975 0.523876 0.586156 0.645686 w: 1
Observation: 0 1 0 2 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=49, meanQ=44.629694, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34912 episodes
GETTING ACTION FROM:
action 5, numVisits=34961, meanQ=39.030463, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.412752 0.181366 0.523736 0.806387 0.929067 0.742038 0.709975 0.523876 0.586156 0.645686 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=223, meanQ=28.885023, numObservations: 55
action 0, numVisits=7, meanQ=-2.549643, numObservations: 6
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 15088 episodes
GETTING ACTION FROM:
action -1, numVisits=15311, meanQ=4.338124, numObservations: 212
action 0, numVisits=7, meanQ=-2.549643, numObservations: 6
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.412752 0.181366 0.523736 0.806387 0.929067 0.742038 0.709975 0.523876 0.586156 0.645686 w: 1
Observation: 0 1 0 2 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=383, meanQ=46.400542, numObservations: 49
action 0, numVisits=13, meanQ=-1.634615, numObservations: 9
action 3, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 16411 episodes
GETTING ACTION FROM:
action -1, numVisits=16794, meanQ=12.498493, numObservations: 150
action 0, numVisits=13, meanQ=-1.634615, numObservations: 9
action 3, numVisits=3, meanQ=-4.016667, numObservations: 2
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.412752 0.181366 0.523736 0.806387 0.929067 0.742038 0.709975 0.523876 0.586156 0.645686 w: 1
Observation: 0 2 0 2 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=3, meanQ=29.983333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-12.378637, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18335 episodes
GETTING ACTION FROM:
action 5, numVisits=14, meanQ=27.571429, numObservations: 8
action -1, numVisits=18325, meanQ=13.528819, numObservations: 166
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-12.378637, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.412752 0.181366 0.523736 0.806387 0.929067 0.742038 0.709975 0.523876 0.586156 0.645686 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 64.6664
Run # 17
Initial state: 0 0.430373 0.89808 0.653511 0.250554 0.662937 0.34008 0.781654 0.317568 0.576681 0.60827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26365 episodes
GETTING ACTION FROM:
action 4, numVisits=26340, meanQ=17.706927, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=18, meanQ=-3.222222, numObservations: 9
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.430373 0.89808 0.653511 0.250554 0.662937 0.34008 0.781654 0.317568 0.576681 0.60827 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 18
Initial state: 0 0.0999055 0.527634 0.449877 0.789904 0.316013 0.187743 0.515683 0.425429 0.569462 0.671851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26695 episodes
GETTING ACTION FROM:
action 4, numVisits=26660, meanQ=14.028552, numObservations: 9
action 2, numVisits=20, meanQ=0.115250, numObservations: 8
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=9, meanQ=-6.455000, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.0999055 0.527634 0.449877 0.789904 0.316013 0.187743 0.515683 0.425429 0.569462 0.671851 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4146, meanQ=18.835341, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 7437 episodes
GETTING ACTION FROM:
action 2, numVisits=11583, meanQ=14.803616, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.0999055 0.527634 0.449877 0.789904 0.316013 0.187743 0.515683 0.425429 0.569462 0.671851 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=709, meanQ=45.123099, numObservations: 133
action 2, numVisits=12, meanQ=-2.811042, numObservations: 4
action -1, numVisits=14, meanQ=-8.110536, numObservations: 12
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 2990 episodes
GETTING ACTION FROM:
action 0, numVisits=3699, meanQ=35.498860, numObservations: 201
action 2, numVisits=12, meanQ=-2.811042, numObservations: 4
action -1, numVisits=14, meanQ=-8.110536, numObservations: 12
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 0
Next state: 0 0.0999055 0.527634 0.449877 0.789904 0.316013 0.187743 0.515683 0.425429 0.569462 0.671851 w: 1
Observation: 0 0 2 0 3 0 1 0 1 0 2 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=61, meanQ=55.110324, numObservations: 8
action 5, numVisits=10, meanQ=16.783600, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-12.195748, numObservations: 1
action 2, numVisits=1, meanQ=-12.473562, numObservations: 1
Sampled 17427 episodes
GETTING ACTION FROM:
action 1, numVisits=17488, meanQ=61.195257, numObservations: 9
action 5, numVisits=10, meanQ=16.783600, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-12.195748, numObservations: 1
action 2, numVisits=1, meanQ=-12.473562, numObservations: 1
action: 1
Next state: 0 0.0999055 0.527634 0.449877 0.789904 0.316013 0.187743 0.515683 0.425429 0.569462 0.671851 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 5, numVisits=1118, meanQ=91.489647, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-12.150639, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-113.808996, numObservations: 1
action 2, numVisits=1, meanQ=-113.845244, numObservations: 1
Sampled 31459 episodes
GETTING ACTION FROM:
action 5, numVisits=32577, meanQ=81.718419, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-12.150639, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-113.808996, numObservations: 1
action 2, numVisits=1, meanQ=-113.845244, numObservations: 1
action: 5
Next state: 1 0.0999055 0.527634 0.449877 0.789904 0.316013 0.187743 0.515683 0.425429 0.569462 0.671851 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 47.95
Run # 19
Initial state: 0 0.0198639 0.462357 0.513489 0.576485 0.192499 0.560229 0.927988 0.101167 0.340627 0.2537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26162 episodes
GETTING ACTION FROM:
action 5, numVisits=26150, meanQ=17.600416, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=5, meanQ=-2.810000, numObservations: 3
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.0198639 0.462357 0.513489 0.576485 0.192499 0.560229 0.927988 0.101167 0.340627 0.2537 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=4199, meanQ=50.705114, numObservations: 231
action -1, numVisits=14, meanQ=-1.321429, numObservations: 12
action 3, numVisits=19, meanQ=-4.212895, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 4509 episodes
GETTING ACTION FROM:
action 0, numVisits=8708, meanQ=47.620733, numObservations: 241
action -1, numVisits=14, meanQ=-1.321429, numObservations: 12
action 3, numVisits=19, meanQ=-4.212895, numObservations: 4
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 0
Next state: 0 0.0198639 0.462357 0.513489 0.576485 0.192499 0.560229 0.927988 0.101167 0.340627 0.2537 w: 1
Observation: 0 0 1 0 2 0 2 0 1 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=126, meanQ=45.300046, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 11736 episodes
GETTING ACTION FROM:
action 3, numVisits=11862, meanQ=50.860478, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 2 0.0198639 0.462357 0.513489 0.576485 0.192499 0.560229 0.927988 0.101167 0.340627 0.2537 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -104.053
Run # 20
Initial state: 0 0.267951 0.161073 0.392383 0.859359 0.648485 0.100697 0.65036 0.765385 0.516497 0.686622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28732 episodes
GETTING ACTION FROM:
action 3, numVisits=28622, meanQ=14.645264, numObservations: 9
action 0, numVisits=77, meanQ=0.598929, numObservations: 62
action 5, numVisits=24, meanQ=-0.670417, numObservations: 8
action -1, numVisits=4, meanQ=-1.050000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.267951 0.161073 0.392383 0.859359 0.648485 0.100697 0.65036 0.765385 0.516497 0.686622 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 21
Initial state: 0 0.274444 0.959041 0.188805 0.617908 0.73089 0.861128 0.361766 0.67383 0.599327 0.694222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17195 episodes
GETTING ACTION FROM:
action -1, numVisits=17175, meanQ=47.116953, numObservations: 243
action 0, numVisits=15, meanQ=-1.050000, numObservations: 15
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.274444 0.959041 0.188805 0.617908 0.73089 0.861128 0.361766 0.67383 0.599327 0.694222 w: 1
Observation: 0 1 0 1 0 3 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=138, meanQ=78.030960, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35973 episodes
GETTING ACTION FROM:
action 5, numVisits=36111, meanQ=85.376600, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.274444 0.959041 0.188805 0.617908 0.73089 0.861128 0.361766 0.67383 0.599327 0.694222 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 22
Initial state: 0 0.00956382 0.692015 0.748313 0.393725 0.705884 0.966074 0.842571 0.157257 0.582373 0.564163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27083 episodes
GETTING ACTION FROM:
action 4, numVisits=27068, meanQ=15.708011, numObservations: 9
action 1, numVisits=10, meanQ=5.995250, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.00956382 0.692015 0.748313 0.393725 0.705884 0.966074 0.842571 0.157257 0.582373 0.564163 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 23
Initial state: 0 0.590013 0.588972 0.280363 0.470846 0.347073 0.515094 0.673729 0.50419 0.942121 0.352538 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17349 episodes
GETTING ACTION FROM:
action 0, numVisits=17334, meanQ=51.779741, numObservations: 243
action -1, numVisits=10, meanQ=-10.740000, numObservations: 9
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.590013 0.588972 0.280363 0.470846 0.347073 0.515094 0.673729 0.50419 0.942121 0.352538 w: 1
Observation: 0 0 2 0 1 0 2 0 2 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=71, meanQ=39.988768, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 29868 episodes
GETTING ACTION FROM:
action 1, numVisits=29939, meanQ=25.165318, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.590013 0.588972 0.280363 0.470846 0.347073 0.515094 0.673729 0.50419 0.942121 0.352538 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=5033, meanQ=73.255220, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17255 episodes
GETTING ACTION FROM:
action 3, numVisits=22288, meanQ=68.569741, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.590013 0.588972 0.280363 0.470846 0.347073 0.515094 0.673729 0.50419 0.942121 0.352538 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=901, meanQ=91.243879, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 19443 episodes
GETTING ACTION FROM:
action 3, numVisits=1051, meanQ=91.878666, numObservations: 9
action -1, numVisits=19265, meanQ=1.666915, numObservations: 229
action 0, numVisits=20, meanQ=-6.750000, numObservations: 9
action 4, numVisits=7, meanQ=-15.285714, numObservations: 5
action 5, numVisits=6, meanQ=-19.175000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.590013 0.588972 0.280363 0.470846 0.347073 0.515094 0.673729 0.50419 0.942121 0.352538 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action -1, numVisits=6, meanQ=14.466667, numObservations: 5
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.889680, numObservations: 1
action 4, numVisits=1, meanQ=-12.111346, numObservations: 1
action 0, numVisits=4, meanQ=-25.275000, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 28166 episodes
GETTING ACTION FROM:
action -1, numVisits=28169, meanQ=-0.523280, numObservations: 236
action 0, numVisits=4, meanQ=-25.275000, numObservations: 3
action 1, numVisits=2, meanQ=-55.525000, numObservations: 2
action 2, numVisits=2, meanQ=-56.444840, numObservations: 2
action 4, numVisits=2, meanQ=-56.555673, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.590013 0.588972 0.280363 0.470846 0.347073 0.515094 0.673729 0.50419 0.942121 0.352538 w: 1
Observation: 0 3 0 1 0 1 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 41550 episodes
GETTING ACTION FROM:
action 3, numVisits=156, meanQ=93.737196, numObservations: 6
action 2, numVisits=41389, meanQ=70.514219, numObservations: 9
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.590013 0.588972 0.280363 0.470846 0.347073 0.515094 0.673729 0.50419 0.942121 0.352538 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 6
Improving policy...
PLANNING FROM:
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 36335 episodes
GETTING ACTION FROM:
action 2, numVisits=36156, meanQ=63.231188, numObservations: 9
action 3, numVisits=17, meanQ=33.355882, numObservations: 5
action 0, numVisits=154, meanQ=-1.339935, numObservations: 37
action -1, numVisits=6, meanQ=-19.780352, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.590013 0.588972 0.280363 0.470846 0.347073 0.515094 0.673729 0.50419 0.942121 0.352538 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 7
Improving policy...
PLANNING FROM:
action 1, numVisits=1, meanQ=99.000000, numObservations: 1
action 4, numVisits=1136, meanQ=95.176108, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-12.577025, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-113.449544, numObservations: 1
Sampled 40391 episodes
GETTING ACTION FROM:
action 4, numVisits=41526, meanQ=17.351531, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-12.577025, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-113.449544, numObservations: 1
action: 4
Next state: 2 0.590013 0.588972 0.280363 0.470846 0.347073 0.515094 0.673729 0.50419 0.942121 0.352538 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -120.567
Run # 24
Initial state: 0 0.332975 0.392786 0.56947 0.112843 0.476853 0.303265 0.52173 0.513772 0.304104 0.586469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17770 episodes
GETTING ACTION FROM:
action -1, numVisits=17737, meanQ=47.180199, numObservations: 243
action 0, numVisits=25, meanQ=-1.050000, numObservations: 25
action 4, numVisits=4, meanQ=-6.000000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.332975 0.392786 0.56947 0.112843 0.476853 0.303265 0.52173 0.513772 0.304104 0.586469 w: 1
Observation: 0 1 0 2 0 1 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=77, meanQ=29.354773, numObservations: 9
action 4, numVisits=11, meanQ=16.359091, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 35353 episodes
GETTING ACTION FROM:
action 2, numVisits=35430, meanQ=53.668155, numObservations: 9
action 4, numVisits=11, meanQ=16.359091, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 2 0.332975 0.392786 0.56947 0.112843 0.476853 0.303265 0.52173 0.513772 0.304104 0.586469 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 25
Initial state: 0 0.28787 0.984771 0.362314 0.192955 0.583756 0.976098 0.497905 0.641612 0.50972 0.756683 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17493 episodes
GETTING ACTION FROM:
action 0, numVisits=17473, meanQ=49.454786, numObservations: 243
action 1, numVisits=4, meanQ=-6.000000, numObservations: 4
action -1, numVisits=10, meanQ=-10.740000, numObservations: 9
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.28787 0.984771 0.362314 0.192955 0.583756 0.976098 0.497905 0.641612 0.50972 0.756683 w: 1
Observation: 0 0 3 0 1 0 3 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=34, meanQ=86.394191, numObservations: 7
action 3, numVisits=11, meanQ=69.454545, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 35952 episodes
GETTING ACTION FROM:
action 4, numVisits=35986, meanQ=84.789651, numObservations: 9
action 3, numVisits=11, meanQ=69.454545, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.28787 0.984771 0.362314 0.192955 0.583756 0.976098 0.497905 0.641612 0.50972 0.756683 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 26
Initial state: 0 0.902021 0.642662 0.281344 0.589588 0.579796 0.60531 0.156302 0.536702 0.479352 0.733163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27164 episodes
GETTING ACTION FROM:
action 2, numVisits=27156, meanQ=16.358728, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.902021 0.642662 0.281344 0.589588 0.579796 0.60531 0.156302 0.536702 0.479352 0.733163 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=1443, meanQ=48.086001, numObservations: 181
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=8, meanQ=-13.162500, numObservations: 7
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 4378 episodes
GETTING ACTION FROM:
action -1, numVisits=5821, meanQ=37.174550, numObservations: 234
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 0, numVisits=8, meanQ=-13.162500, numObservations: 7
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.902021 0.642662 0.281344 0.589588 0.579796 0.60531 0.156302 0.536702 0.479352 0.733163 w: 1
Observation: 0 3 0 1 0 2 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=59, meanQ=80.189345, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 19576 episodes
GETTING ACTION FROM:
action 5, numVisits=19635, meanQ=57.982421, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.902021 0.642662 0.281344 0.589588 0.579796 0.60531 0.156302 0.536702 0.479352 0.733163 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -104.053
Run # 27
Initial state: 0 0.461886 0.186613 0.414721 0.178833 0.976914 0.923792 0.952851 0.68674 0.520178 0.666492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28245 episodes
GETTING ACTION FROM:
action 4, numVisits=28226, meanQ=15.905740, numObservations: 9
action 2, numVisits=14, meanQ=1.071607, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.461886 0.186613 0.414721 0.178833 0.976914 0.923792 0.952851 0.68674 0.520178 0.666492 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 28
Initial state: 0 0.570913 0.682599 0.424081 0.327806 0.232153 0.754906 0.292087 0.363959 0.943209 0.439017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28390 episodes
GETTING ACTION FROM:
action 3, numVisits=28355, meanQ=14.317148, numObservations: 9
action 5, numVisits=29, meanQ=8.597069, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.570913 0.682599 0.424081 0.327806 0.232153 0.754906 0.292087 0.363959 0.943209 0.439017 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=4405, meanQ=22.220151, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 8538 episodes
GETTING ACTION FROM:
action 5, numVisits=12943, meanQ=17.056400, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 2 0.570913 0.682599 0.424081 0.327806 0.232153 0.754906 0.292087 0.363959 0.943209 0.439017 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 29
Initial state: 0 0.510074 0.520337 0.77153 0.794827 0.382551 0.621531 0.100053 0.979198 0.0132158 0.973111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17525 episodes
GETTING ACTION FROM:
action -1, numVisits=17504, meanQ=43.549036, numObservations: 243
action 0, numVisits=16, meanQ=-7.106250, numObservations: 15
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.510074 0.520337 0.77153 0.794827 0.382551 0.621531 0.100053 0.979198 0.0132158 0.973111 w: 1
Observation: 0 2 0 3 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=133, meanQ=87.531617, numObservations: 8
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 38100 episodes
GETTING ACTION FROM:
action 1, numVisits=38233, meanQ=88.283615, numObservations: 9
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action 2, numVisits=3, meanQ=32.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 1
Next state: 0 0.510074 0.520337 0.77153 0.794827 0.382551 0.621531 0.100053 0.979198 0.0132158 0.973111 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2468, meanQ=93.646506, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31440 episodes
GETTING ACTION FROM:
action 1, numVisits=2770, meanQ=94.078181, numObservations: 9
action 5, numVisits=31123, meanQ=65.493573, numObservations: 9
action -1, numVisits=9, meanQ=-1.894444, numObservations: 5
action 0, numVisits=9, meanQ=-1.894444, numObservations: 7
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.510074 0.520337 0.77153 0.794827 0.382551 0.621531 0.100053 0.979198 0.0132158 0.973111 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 30
Initial state: 0 0.730194 0.937705 0.776219 0.0802498 0.501717 0.691329 0.285158 0.315315 0.337576 0.689247 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26467 episodes
GETTING ACTION FROM:
action 5, numVisits=25470, meanQ=18.363738, numObservations: 9
action 3, numVisits=992, meanQ=8.908291, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.730194 0.937705 0.776219 0.0802498 0.501717 0.691329 0.285158 0.315315 0.337576 0.689247 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=1377, meanQ=48.714562, numObservations: 187
action 0, numVisits=7, meanQ=-1.050000, numObservations: 7
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
Sampled 4219 episodes
GETTING ACTION FROM:
action -1, numVisits=5596, meanQ=34.680071, numObservations: 237
action 0, numVisits=7, meanQ=-1.050000, numObservations: 7
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action: -1
Next state: 0 0.730194 0.937705 0.776219 0.0802498 0.501717 0.691329 0.285158 0.315315 0.337576 0.689247 w: 1
Observation: 0 3 0 3 0 2 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=44, meanQ=70.036972, numObservations: 8
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 19838 episodes
GETTING ACTION FROM:
action 3, numVisits=19882, meanQ=70.136284, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.730194 0.937705 0.776219 0.0802498 0.501717 0.691329 0.285158 0.315315 0.337576 0.689247 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 31
Initial state: 0 0.978792 0.265597 0.266165 0.4551 0.600887 0.529119 0.487677 0.477442 0.87807 0.85721 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28062 episodes
GETTING ACTION FROM:
action 1, numVisits=28055, meanQ=13.713041, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.978792 0.265597 0.266165 0.4551 0.600887 0.529119 0.487677 0.477442 0.87807 0.85721 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 32
Initial state: 0 0.897127 0.583277 0.142399 0.451017 0.593516 0.57046 0.313016 0.219396 0.0636761 0.824528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27390 episodes
GETTING ACTION FROM:
action 1, numVisits=27382, meanQ=14.986721, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.897127 0.583277 0.142399 0.451017 0.593516 0.57046 0.313016 0.219396 0.0636761 0.824528 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 33
Initial state: 0 0.996743 0.158551 0.00200708 0.70217 0.204512 0.440299 0.573675 0.595489 0.786731 0.535344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17572 episodes
GETTING ACTION FROM:
action 0, numVisits=17528, meanQ=50.562732, numObservations: 243
action 4, numVisits=5, meanQ=-3.000000, numObservations: 5
action 5, numVisits=12, meanQ=-4.499583, numObservations: 7
action -1, numVisits=24, meanQ=-5.087500, numObservations: 23
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.996743 0.158551 0.00200708 0.70217 0.204512 0.440299 0.573675 0.595489 0.786731 0.535344 w: 1
Observation: 0 0 1 0 3 0 1 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=16, meanQ=77.556250, numObservations: 4
action 2, numVisits=48, meanQ=62.197031, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35612 episodes
GETTING ACTION FROM:
action 5, numVisits=35628, meanQ=81.811565, numObservations: 9
action 2, numVisits=48, meanQ=62.197031, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.996743 0.158551 0.00200708 0.70217 0.204512 0.440299 0.573675 0.595489 0.786731 0.535344 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 34
Initial state: 0 0.599383 0.669164 0.263149 0.960118 0.846565 0.331758 0.202762 0.464427 0.667843 0.835816 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25700 episodes
GETTING ACTION FROM:
action 1, numVisits=25679, meanQ=17.520444, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 4, numVisits=14, meanQ=-3.925000, numObservations: 7
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.599383 0.669164 0.263149 0.960118 0.846565 0.331758 0.202762 0.464427 0.667843 0.835816 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 35
Initial state: 0 0.440217 0.930398 0.610233 0.491424 0.175747 0.39842 0.508207 0.632262 0.653235 0.604572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17310 episodes
GETTING ACTION FROM:
action -1, numVisits=17225, meanQ=45.913286, numObservations: 243
action 0, numVisits=72, meanQ=-5.896319, numObservations: 61
action 5, numVisits=6, meanQ=-6.916250, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=4, meanQ=-28.500000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.440217 0.930398 0.610233 0.491424 0.175747 0.39842 0.508207 0.632262 0.653235 0.604572 w: 1
Observation: 0 2 0 3 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=45, meanQ=36.636889, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34906 episodes
GETTING ACTION FROM:
action 4, numVisits=34951, meanQ=44.564292, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.440217 0.930398 0.610233 0.491424 0.175747 0.39842 0.508207 0.632262 0.653235 0.604572 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 36
Initial state: 0 0.586714 0.534275 0.844998 0.208283 0.791682 0.912777 0.263108 0.596879 0.515643 0.450893 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 25628 episodes
GETTING ACTION FROM:
action 2, numVisits=25612, meanQ=18.003509, numObservations: 9
action 5, numVisits=9, meanQ=6.828056, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.586714 0.534275 0.844998 0.208283 0.791682 0.912777 0.263108 0.596879 0.515643 0.450893 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 37
Initial state: 0 0.532753 0.798723 0.5927 0.700767 0.0815066 0.839043 0.792797 0.919384 0.527942 0.659857 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27771 episodes
GETTING ACTION FROM:
action 2, numVisits=27706, meanQ=14.299434, numObservations: 9
action 4, numVisits=41, meanQ=11.987988, numObservations: 9
action 1, numVisits=7, meanQ=10.428571, numObservations: 5
action 3, numVisits=14, meanQ=10.068036, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.532753 0.798723 0.5927 0.700767 0.0815066 0.839043 0.792797 0.919384 0.527942 0.659857 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 38
Initial state: 0 0.329304 0.00625682 0.783523 0.677728 0.61973 0.349241 0.602242 0.655337 0.0861844 0.504431 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17707 episodes
GETTING ACTION FROM:
action -1, numVisits=17671, meanQ=49.613025, numObservations: 243
action 2, numVisits=16, meanQ=-5.230938, numObservations: 7
action 0, numVisits=12, meanQ=-9.125000, numObservations: 11
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=5, meanQ=-21.000000, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.329304 0.00625682 0.783523 0.677728 0.61973 0.349241 0.602242 0.655337 0.0861844 0.504431 w: 1
Observation: 0 2 0 3 0 3 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=27, meanQ=-1.050000, numObservations: 27
action 3, numVisits=15, meanQ=-1.603333, numObservations: 5
action -1, numVisits=6, meanQ=-2.023750, numObservations: 3
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 4, numVisits=11, meanQ=-4.422500, numObservations: 7
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 16256 episodes
GETTING ACTION FROM:
action -1, numVisits=16255, meanQ=50.767514, numObservations: 212
action 0, numVisits=32, meanQ=-1.110859, numObservations: 31
action 4, numVisits=11, meanQ=-4.422500, numObservations: 7
action 3, numVisits=16, meanQ=-7.815625, numObservations: 5
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=4, meanQ=-28.262500, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.329304 0.00625682 0.783523 0.677728 0.61973 0.349241 0.602242 0.655337 0.0861844 0.504431 w: 1
Observation: 0 1 0 3 0 2 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=111, meanQ=63.025698, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37248 episodes
GETTING ACTION FROM:
action 4, numVisits=37359, meanQ=75.956034, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.329304 0.00625682 0.783523 0.677728 0.61973 0.349241 0.602242 0.655337 0.0861844 0.504431 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
Run # 39
Initial state: 0 0.644444 0.921155 0.907765 0.422571 0.951403 0.126169 0.548752 0.674195 0.620465 0.0948286 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17762 episodes
GETTING ACTION FROM:
action -1, numVisits=17670, meanQ=46.795560, numObservations: 243
action 0, numVisits=58, meanQ=-1.675690, numObservations: 48
action 1, numVisits=30, meanQ=-3.154667, numObservations: 9
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.644444 0.921155 0.907765 0.422571 0.951403 0.126169 0.548752 0.674195 0.620465 0.0948286 w: 1
Observation: 0 3 0 3 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=67, meanQ=71.437351, numObservations: 8
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 37788 episodes
GETTING ACTION FROM:
action 4, numVisits=37855, meanQ=86.669319, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.644444 0.921155 0.907765 0.422571 0.951403 0.126169 0.548752 0.674195 0.620465 0.0948286 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 40
Initial state: 0 0.587838 0.624669 0.93411 0.255052 0.861658 0.825134 0.36417 0.903205 0.247294 0.994596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27405 episodes
GETTING ACTION FROM:
action 1, numVisits=27398, meanQ=16.581445, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.587838 0.624669 0.93411 0.255052 0.861658 0.825134 0.36417 0.903205 0.247294 0.994596 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 41
Initial state: 0 0.564656 0.683646 0.214982 0.150054 0.95639 0.19601 0.895522 0.337714 0.851077 0.0528252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28168 episodes
GETTING ACTION FROM:
action 3, numVisits=28162, meanQ=13.557951, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.564656 0.683646 0.214982 0.150054 0.95639 0.19601 0.895522 0.337714 0.851077 0.0528252 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 42
Initial state: 0 0.891488 0.763127 0.918825 0.220238 0.374379 0.080447 0.526822 0.691194 0.755588 0.815662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17641 episodes
GETTING ACTION FROM:
action 0, numVisits=17551, meanQ=51.431347, numObservations: 243
action -1, numVisits=68, meanQ=-6.307132, numObservations: 57
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=9, meanQ=-17.116389, numObservations: 5
action 4, numVisits=7, meanQ=-18.007143, numObservations: 6
action 1, numVisits=4, meanQ=-28.262500, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.891488 0.763127 0.918825 0.220238 0.374379 0.080447 0.526822 0.691194 0.755588 0.815662 w: 1
Observation: 0 0 3 0 1 0 1 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=82, meanQ=79.386738, numObservations: 8
action 1, numVisits=3, meanQ=62.650000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 34563 episodes
GETTING ACTION FROM:
action 4, numVisits=34645, meanQ=75.414068, numObservations: 9
action 1, numVisits=3, meanQ=62.650000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.891488 0.763127 0.918825 0.220238 0.374379 0.080447 0.526822 0.691194 0.755588 0.815662 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1910, meanQ=87.791683, numObservations: 9
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 27345 episodes
GETTING ACTION FROM:
action 4, numVisits=1923, meanQ=87.846438, numObservations: 9
action 2, numVisits=27334, meanQ=24.748009, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.891488 0.763127 0.918825 0.220238 0.374379 0.080447 0.526822 0.691194 0.755588 0.815662 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 43
Initial state: 0 0.594901 0.649397 0.396993 0.784392 0.111856 0.792916 0.050137 0.949643 0.924344 0.175839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27454 episodes
GETTING ACTION FROM:
action 3, numVisits=27379, meanQ=15.376747, numObservations: 9
action 0, numVisits=52, meanQ=-4.978798, numObservations: 49
action 1, numVisits=4, meanQ=-6.000000, numObservations: 4
action -1, numVisits=11, meanQ=-9.859091, numObservations: 10
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=6, meanQ=-19.175000, numObservations: 5
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.594901 0.649397 0.396993 0.784392 0.111856 0.792916 0.050137 0.949643 0.924344 0.175839 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=2057, meanQ=50.510073, numObservations: 224
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5200 episodes
GETTING ACTION FROM:
action 0, numVisits=7257, meanQ=40.030564, numObservations: 241
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.594901 0.649397 0.396993 0.784392 0.111856 0.792916 0.050137 0.949643 0.924344 0.175839 w: 1
Observation: 0 0 2 0 3 0 3 0 3 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=12, meanQ=33.490661, numObservations: 6
action 5, numVisits=3, meanQ=25.603216, numObservations: 3
action 4, numVisits=3, meanQ=25.537667, numObservations: 3
action 1, numVisits=4, meanQ=21.737500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 15633 episodes
GETTING ACTION FROM:
action 2, numVisits=15645, meanQ=56.863636, numObservations: 9
action 5, numVisits=3, meanQ=25.603216, numObservations: 3
action 4, numVisits=3, meanQ=25.537667, numObservations: 3
action 1, numVisits=4, meanQ=21.737500, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.594901 0.649397 0.396993 0.784392 0.111856 0.792916 0.050137 0.949643 0.924344 0.175839 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 44
Initial state: 0 0.588767 0.672399 0.349016 0.813624 0.910066 0.404244 0.149598 0.624961 0.00963972 0.825331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17476 episodes
GETTING ACTION FROM:
action 0, numVisits=17456, meanQ=52.933105, numObservations: 243
action -1, numVisits=15, meanQ=-7.510000, numObservations: 14
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.588767 0.672399 0.349016 0.813624 0.910066 0.404244 0.149598 0.624961 0.00963972 0.825331 w: 1
Observation: 0 0 2 0 3 0 1 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=20, meanQ=57.297500, numObservations: 8
action 5, numVisits=35, meanQ=53.557571, numObservations: 8
action 4, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 26395 episodes
GETTING ACTION FROM:
action 5, numVisits=26421, meanQ=48.054513, numObservations: 9
action 1, numVisits=28, meanQ=42.716071, numObservations: 9
action 4, numVisits=3, meanQ=26.300000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.588767 0.672399 0.349016 0.813624 0.910066 0.404244 0.149598 0.624961 0.00963972 0.825331 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 45
Initial state: 0 0.336157 0.300213 0.332999 0.678715 0.431545 0.571834 0.316067 0.0250279 0.480871 0.523941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17475 episodes
GETTING ACTION FROM:
action 0, numVisits=17404, meanQ=52.308004, numObservations: 243
action -1, numVisits=58, meanQ=-2.935259, numObservations: 55
action 2, numVisits=9, meanQ=-3.883333, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.336157 0.300213 0.332999 0.678715 0.431545 0.571834 0.316067 0.0250279 0.480871 0.523941 w: 1
Observation: 0 0 1 0 2 0 2 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=66, meanQ=35.210758, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 33610 episodes
GETTING ACTION FROM:
action 3, numVisits=33676, meanQ=37.680811, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.336157 0.300213 0.332999 0.678715 0.431545 0.571834 0.316067 0.0250279 0.480871 0.523941 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 46
Initial state: 0 0.948361 0.109145 0.793819 0.532902 0.0891895 0.312655 0.515858 0.534411 0.104227 0.817937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28344 episodes
GETTING ACTION FROM:
action 3, numVisits=28337, meanQ=14.657256, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.948361 0.109145 0.793819 0.532902 0.0891895 0.312655 0.515858 0.534411 0.104227 0.817937 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=565, meanQ=22.223178, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.016667, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 11601 episodes
GETTING ACTION FROM:
action 1, numVisits=10952, meanQ=10.913233, numObservations: 9
action 4, numVisits=1213, meanQ=6.358556, numObservations: 9
action -1, numVisits=2, meanQ=-1.525000, numObservations: 2
action 0, numVisits=2, meanQ=-1.525000, numObservations: 2
action 5, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.948361 0.109145 0.793819 0.532902 0.0891895 0.312655 0.515858 0.534411 0.104227 0.817937 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 47
Initial state: 0 0.988994 0.250735 0.795457 0.614076 0.504649 0.568435 0.0650219 0.00689248 0.255823 0.341164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27796 episodes
GETTING ACTION FROM:
action 3, numVisits=27789, meanQ=15.538444, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.988994 0.250735 0.795457 0.614076 0.504649 0.568435 0.0650219 0.00689248 0.255823 0.341164 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 48
Initial state: 0 0.138723 0.55976 0.519801 0.58131 0.739282 0.84673 0.388691 0.0490769 0.788142 0.379545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28216 episodes
GETTING ACTION FROM:
action 5, numVisits=28002, meanQ=12.914132, numObservations: 9
action 4, numVisits=165, meanQ=11.960481, numObservations: 9
action 1, numVisits=44, meanQ=11.329773, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.138723 0.55976 0.519801 0.58131 0.739282 0.84673 0.388691 0.0490769 0.788142 0.379545 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 49
Initial state: 0 0.588159 0.671065 0.164393 0.773201 0.119957 0.444244 0.619564 0.592233 0.87424 0.952166 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27180 episodes
GETTING ACTION FROM:
action 2, numVisits=27172, meanQ=16.048358, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.588159 0.671065 0.164393 0.773201 0.119957 0.444244 0.619564 0.592233 0.87424 0.952166 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2045, meanQ=44.530517, numObservations: 9
action 5, numVisits=5, meanQ=37.190000, numObservations: 4
action 1, numVisits=3, meanQ=25.650833, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 9121 episodes
GETTING ACTION FROM:
action 5, numVisits=9125, meanQ=47.177356, numObservations: 9
action 2, numVisits=2046, meanQ=44.524674, numObservations: 9
action 1, numVisits=3, meanQ=25.650833, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.588159 0.671065 0.164393 0.773201 0.119957 0.444244 0.619564 0.592233 0.87424 0.952166 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 50
Initial state: 0 0.484008 0.6051 0.39388 0.570398 0.947197 0.00437229 0.801823 0.638985 0.201211 0.307587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17509 episodes
GETTING ACTION FROM:
action -1, numVisits=17462, meanQ=46.614879, numObservations: 243
action 0, numVisits=42, meanQ=-4.697321, numObservations: 34
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.484008 0.6051 0.39388 0.570398 0.947197 0.00437229 0.801823 0.638985 0.201211 0.307587 w: 1
Observation: 0 3 0 1 0 3 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=35, meanQ=4.050143, numObservations: 29
action 3, numVisits=13, meanQ=-8.692308, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action -1, numVisits=2, meanQ=-49.500000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 17949 episodes
GETTING ACTION FROM:
action 0, numVisits=17984, meanQ=61.559978, numObservations: 243
action 3, numVisits=13, meanQ=-8.692308, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=3, meanQ=-34.333333, numObservations: 3
action -1, numVisits=2, meanQ=-49.500000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.484008 0.6051 0.39388 0.570398 0.947197 0.00437229 0.801823 0.638985 0.201211 0.307587 w: 1
Observation: 0 0 2 0 2 0 1 0 2 0 2 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=25, meanQ=42.276000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38107 episodes
GETTING ACTION FROM:
action 1, numVisits=38132, meanQ=51.907556, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.484008 0.6051 0.39388 0.570398 0.947197 0.00437229 0.801823 0.638985 0.201211 0.307587 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 85.4475
[32m ProblemEnvironment.hpp 351: Done.[39m
