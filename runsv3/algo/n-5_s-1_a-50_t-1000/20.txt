Run # 1
Initial state: 0 0.413732 0.7189 0.827203 0.52544 0.356174 0.228496 0.000363571 0.969622 0.483914 0.510201 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29413 episodes
GETTING ACTION FROM:
action 3, numVisits=29397, meanQ=27.278322, numObservations: 9
action 5, numVisits=4, meanQ=21.500000, numObservations: 4
action 2, numVisits=6, meanQ=14.158333, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.413732 0.7189 0.827203 0.52544 0.356174 0.228496 0.000363571 0.969622 0.483914 0.510201 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2986, meanQ=33.044613, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=8, meanQ=-3.262500, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 12428 episodes
GETTING ACTION FROM:
action 5, numVisits=15414, meanQ=25.085958, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=8, meanQ=-3.262500, numObservations: 5
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.413732 0.7189 0.827203 0.52544 0.356174 0.228496 0.000363571 0.969622 0.483914 0.510201 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 2
Initial state: 0 0.048547 0.93745 0.437395 0.463426 0.0213769 0.442897 0.589601 0.492007 0.104745 0.966231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29620 episodes
GETTING ACTION FROM:
action 2, numVisits=29601, meanQ=26.384995, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 4, numVisits=3, meanQ=-4.333333, numObservations: 2
action 5, numVisits=10, meanQ=-5.504750, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.048547 0.93745 0.437395 0.463426 0.0213769 0.442897 0.589601 0.492007 0.104745 0.966231 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 3
Initial state: 0 0.600421 0.351554 0.462739 0.80632 0.441787 0.411381 0.132166 0.941111 0.532104 0.339425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30276 episodes
GETTING ACTION FROM:
action 4, numVisits=24516, meanQ=27.570783, numObservations: 9
action 1, numVisits=5724, meanQ=25.560670, numObservations: 9
action 2, numVisits=18, meanQ=23.444444, numObservations: 8
action 5, numVisits=15, meanQ=21.460000, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.600421 0.351554 0.462739 0.80632 0.441787 0.411381 0.132166 0.941111 0.532104 0.339425 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2121, meanQ=37.714889, numObservations: 9
action 2, numVisits=15, meanQ=31.126667, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 13660 episodes
GETTING ACTION FROM:
action 5, numVisits=15781, meanQ=36.921962, numObservations: 9
action 2, numVisits=15, meanQ=31.126667, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 2 0.600421 0.351554 0.462739 0.80632 0.441787 0.411381 0.132166 0.941111 0.532104 0.339425 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 4
Initial state: 0 0.483825 0.439876 0.52635 0.723485 0.563465 0.485387 0.748123 0.132381 0.643196 0.54658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29148 episodes
GETTING ACTION FROM:
action 1, numVisits=29129, meanQ=27.000012, numObservations: 9
action 4, numVisits=11, meanQ=14.454545, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=4, meanQ=-6.000000, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.483825 0.439876 0.52635 0.723485 0.563465 0.485387 0.748123 0.132381 0.643196 0.54658 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 5
Initial state: 0 0.446908 0.540674 0.974893 0.0294191 0.290001 0.000974193 0.602752 0.888242 0.850145 0.113895 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28905 episodes
GETTING ACTION FROM:
action 1, numVisits=28880, meanQ=28.746027, numObservations: 9
action 5, numVisits=16, meanQ=9.178125, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=5, meanQ=-3.000000, numObservations: 5
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.446908 0.540674 0.974893 0.0294191 0.290001 0.000974193 0.602752 0.888242 0.850145 0.113895 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 6
Initial state: 0 0.817035 0.897185 0.339734 0.875265 0.4231 0.426401 0.591368 0.492887 0.857794 0.341141 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30657 episodes
GETTING ACTION FROM:
action 3, numVisits=30647, meanQ=26.783077, numObservations: 9
action 5, numVisits=4, meanQ=21.500000, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.817035 0.897185 0.339734 0.875265 0.4231 0.426401 0.591368 0.492887 0.857794 0.341141 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 7
Initial state: 0 0.454332 0.579184 0.413552 0.479074 0.533825 0.397796 0.350789 0.455962 0.959838 0.108864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29005 episodes
GETTING ACTION FROM:
action 1, numVisits=28937, meanQ=28.653603, numObservations: 9
action -1, numVisits=23, meanQ=-1.050000, numObservations: 23
action 0, numVisits=23, meanQ=-1.050000, numObservations: 23
action 3, numVisits=14, meanQ=-3.928393, numObservations: 8
action 4, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=4, meanQ=-6.000000, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.454332 0.579184 0.413552 0.479074 0.533825 0.397796 0.350789 0.455962 0.959838 0.108864 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 8
Initial state: 0 0.832362 0.873847 0.131608 0.26501 0.890811 0.657223 0.497287 0.106398 0.446842 0.476491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30384 episodes
GETTING ACTION FROM:
action 1, numVisits=30378, meanQ=27.256482, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.832362 0.873847 0.131608 0.26501 0.890811 0.657223 0.497287 0.106398 0.446842 0.476491 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 9
Initial state: 0 0.172213 0.422375 0.820436 0.296051 0.87102 0.265837 0.461765 0.390695 0.579471 0.476894 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17924 episodes
GETTING ACTION FROM:
action -1, numVisits=17895, meanQ=50.458580, numObservations: 243
action 0, numVisits=14, meanQ=-7.971429, numObservations: 13
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=5, meanQ=-21.000000, numObservations: 4
action 3, numVisits=5, meanQ=-21.000000, numObservations: 4
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.172213 0.422375 0.820436 0.296051 0.87102 0.265837 0.461765 0.390695 0.579471 0.476894 w: 1
Observation: 0 1 0 3 0 3 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=132, meanQ=83.352652, numObservations: 9
action 3, numVisits=5, meanQ=59.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38298 episodes
GETTING ACTION FROM:
action 4, numVisits=38430, meanQ=89.659710, numObservations: 9
action 3, numVisits=5, meanQ=59.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.172213 0.422375 0.820436 0.296051 0.87102 0.265837 0.461765 0.390695 0.579471 0.476894 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 10
Initial state: 0 0.764009 0.399729 0.189821 0.0123891 0.5479 0.00932521 0.481903 0.541356 0.830814 0.709502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18152 episodes
GETTING ACTION FROM:
action 0, numVisits=18055, meanQ=56.179002, numObservations: 243
action -1, numVisits=90, meanQ=-1.140250, numObservations: 72
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.764009 0.399729 0.189821 0.0123891 0.5479 0.00932521 0.481903 0.541356 0.830814 0.709502 w: 1
Observation: 0 0 2 0 1 0 1 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=15, meanQ=49.330167, numObservations: 6
action 4, numVisits=62, meanQ=43.042097, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35796 episodes
GETTING ACTION FROM:
action 4, numVisits=35856, meanQ=64.535199, numObservations: 9
action 1, numVisits=17, meanQ=31.644265, numObservations: 6
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.764009 0.399729 0.189821 0.0123891 0.5479 0.00932521 0.481903 0.541356 0.830814 0.709502 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 11
Initial state: 0 0.569617 0.587523 0.508562 0.427348 0.30508 0.244808 0.514502 0.127981 0.840633 0.367803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28621 episodes
GETTING ACTION FROM:
action 5, numVisits=28612, meanQ=28.549198, numObservations: 9
action 2, numVisits=4, meanQ=14.350625, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.569617 0.587523 0.508562 0.427348 0.30508 0.244808 0.514502 0.127981 0.840633 0.367803 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=557, meanQ=36.819065, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 19800 episodes
GETTING ACTION FROM:
action -1, numVisits=12115, meanQ=3.173074, numObservations: 242
action 0, numVisits=318, meanQ=-1.986434, numObservations: 125
action 4, numVisits=7761, meanQ=-2.126123, numObservations: 9
action 3, numVisits=153, meanQ=-3.238882, numObservations: 9
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=13, meanQ=-10.255048, numObservations: 7
action 1, numVisits=4, meanQ=-28.262500, numObservations: 3
action: -1
Next state: 0 0.569617 0.587523 0.508562 0.427348 0.30508 0.244808 0.514502 0.127981 0.840633 0.367803 w: 1
Observation: 0 3 0 2 0 1 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=99.000000, numObservations: 1
action 4, numVisits=1, meanQ=99.000000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-12.241349, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 32848 episodes
GETTING ACTION FROM:
action 2, numVisits=32822, meanQ=42.117128, numObservations: 9
action 4, numVisits=24, meanQ=2.750000, numObservations: 8
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.525000, numObservations: 1
action 3, numVisits=1, meanQ=-12.241349, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.569617 0.587523 0.508562 0.427348 0.30508 0.244808 0.514502 0.127981 0.840633 0.367803 w: 1
Observation: 0 0 0 1 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 12
Initial state: 0 0.482201 0.427246 0.514586 0.164769 0.49837 0.227344 0.161677 0.163552 0.855174 0.791969 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29462 episodes
GETTING ACTION FROM:
action 1, numVisits=29426, meanQ=26.556684, numObservations: 9
action 5, numVisits=29, meanQ=23.686293, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.482201 0.427246 0.514586 0.164769 0.49837 0.227344 0.161677 0.163552 0.855174 0.791969 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 13
Initial state: 0 0.582391 0.0403402 0.143055 0.0259669 0.262153 0.361072 0.257072 0.123023 0.436006 0.422971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27136 episodes
GETTING ACTION FROM:
action 4, numVisits=27101, meanQ=29.118786, numObservations: 9
action 1, numVisits=19, meanQ=7.894868, numObservations: 7
action 5, numVisits=10, meanQ=3.000000, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.582391 0.0403402 0.143055 0.0259669 0.262153 0.361072 0.257072 0.123023 0.436006 0.422971 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=2602, meanQ=56.116096, numObservations: 218
action 0, numVisits=54, meanQ=-1.408889, numObservations: 44
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
Sampled 5069 episodes
GETTING ACTION FROM:
action -1, numVisits=7671, meanQ=49.000898, numObservations: 240
action 0, numVisits=54, meanQ=-1.408889, numObservations: 44
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action: -1
Next state: 0 0.582391 0.0403402 0.143055 0.0259669 0.262153 0.361072 0.257072 0.123023 0.436006 0.422971 w: 1
Observation: 0 3 0 1 0 1 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=91, meanQ=87.129162, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 26943 episodes
GETTING ACTION FROM:
action 5, numVisits=27034, meanQ=80.027594, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 1 0.582391 0.0403402 0.143055 0.0259669 0.262153 0.361072 0.257072 0.123023 0.436006 0.422971 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 14
Initial state: 0 0.88907 0.922786 0.465816 0.819492 0.523777 0.383838 0.157316 0.0177376 0.0641812 0.446472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30481 episodes
GETTING ACTION FROM:
action 4, numVisits=27224, meanQ=27.174004, numObservations: 9
action 3, numVisits=3252, meanQ=27.061639, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.88907 0.922786 0.465816 0.819492 0.523777 0.383838 0.157316 0.0177376 0.0641812 0.446472 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=2689, meanQ=32.521511, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 10706 episodes
GETTING ACTION FROM:
action 1, numVisits=13395, meanQ=29.657012, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.88907 0.922786 0.465816 0.819492 0.523777 0.383838 0.157316 0.0177376 0.0641812 0.446472 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 15
Initial state: 0 0.807094 0.0916439 0.393263 0.825433 0.659256 0.672856 0.32153 0.339194 0.42565 0.526248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28378 episodes
GETTING ACTION FROM:
action 4, numVisits=28348, meanQ=29.106279, numObservations: 9
action 3, numVisits=25, meanQ=4.122100, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.807094 0.0916439 0.393263 0.825433 0.659256 0.672856 0.32153 0.339194 0.42565 0.526248 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=2817, meanQ=56.606441, numObservations: 217
action 0, numVisits=16, meanQ=-1.706094, numObservations: 15
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 4248 episodes
GETTING ACTION FROM:
action -1, numVisits=7065, meanQ=50.972576, numObservations: 242
action 0, numVisits=16, meanQ=-1.706094, numObservations: 15
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.807094 0.0916439 0.393263 0.825433 0.659256 0.672856 0.32153 0.339194 0.42565 0.526248 w: 1
Observation: 0 3 0 1 0 3 0 3 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1, meanQ=99.000000, numObservations: 1
action 3, numVisits=1, meanQ=99.000000, numObservations: 1
action 5, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29325 episodes
GETTING ACTION FROM:
action 5, numVisits=29321, meanQ=77.977749, numObservations: 9
action 3, numVisits=2, meanQ=44.000000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.807094 0.0916439 0.393263 0.825433 0.659256 0.672856 0.32153 0.339194 0.42565 0.526248 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 16
Initial state: 0 0.0221551 0.446744 0.359272 0.835872 0.250494 0.211471 0.412162 0.572032 0.200154 0.463687 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17630 episodes
GETTING ACTION FROM:
action -1, numVisits=17598, meanQ=53.592897, numObservations: 243
action 0, numVisits=14, meanQ=-1.799821, numObservations: 13
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=12, meanQ=-5.049792, numObservations: 7
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.0221551 0.446744 0.359272 0.835872 0.250494 0.211471 0.412162 0.572032 0.200154 0.463687 w: 1
Observation: 0 1 0 1 0 1 0 2 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=92, meanQ=77.958777, numObservations: 9
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 35984 episodes
GETTING ACTION FROM:
action 4, numVisits=36076, meanQ=84.395333, numObservations: 9
action 1, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.0221551 0.446744 0.359272 0.835872 0.250494 0.211471 0.412162 0.572032 0.200154 0.463687 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 17
Initial state: 0 0.48727 0.522004 0.0325938 0.206713 0.659383 0.889013 0.713847 0.219085 0.337088 0.188405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30106 episodes
GETTING ACTION FROM:
action 2, numVisits=30022, meanQ=28.027526, numObservations: 9
action 5, numVisits=20, meanQ=10.415125, numObservations: 7
action 1, numVisits=39, meanQ=9.228397, numObservations: 9
action 4, numVisits=12, meanQ=4.833333, numObservations: 6
action 3, numVisits=11, meanQ=2.805000, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 2
Next state: 0 0.48727 0.522004 0.0325938 0.206713 0.659383 0.889013 0.713847 0.219085 0.337088 0.188405 w: 1
Observation: 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2974, meanQ=39.202024, numObservations: 9
action 4, numVisits=4, meanQ=21.737500, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 11485 episodes
GETTING ACTION FROM:
action 5, numVisits=14459, meanQ=31.698759, numObservations: 9
action 4, numVisits=4, meanQ=21.737500, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 5
Next state: 0 0.48727 0.522004 0.0325938 0.206713 0.659383 0.889013 0.713847 0.219085 0.337088 0.188405 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1073, meanQ=39.352397, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 6980 episodes
GETTING ACTION FROM:
action 3, numVisits=8053, meanQ=17.844045, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 3
Next state: 2 0.48727 0.522004 0.0325938 0.206713 0.659383 0.889013 0.713847 0.219085 0.337088 0.188405 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -112.603
Run # 18
Initial state: 0 0.592775 0.552081 0.447616 0.559362 0.615728 0.998809 0.336021 0.983012 0.558575 0.487474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29334 episodes
GETTING ACTION FROM:
action 2, numVisits=29317, meanQ=29.352416, numObservations: 9
action 4, numVisits=12, meanQ=2.529375, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.592775 0.552081 0.447616 0.559362 0.615728 0.998809 0.336021 0.983012 0.558575 0.487474 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=519, meanQ=66.961919, numObservations: 9
action 1, numVisits=3, meanQ=26.300000, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 28693 episodes
GETTING ACTION FROM:
action 2, numVisits=520, meanQ=66.949043, numObservations: 9
action 1, numVisits=28695, meanQ=40.009384, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 2
Next state: 1 0.592775 0.552081 0.447616 0.559362 0.615728 0.998809 0.336021 0.983012 0.558575 0.487474 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 19
Initial state: 0 0.363588 0.362377 0.831891 0.0626457 0.775474 0.82843 0.523576 0.457422 0.46184 0.591983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17885 episodes
GETTING ACTION FROM:
action -1, numVisits=17846, meanQ=55.438301, numObservations: 243
action 0, numVisits=21, meanQ=-1.549881, numObservations: 20
action 4, numVisits=11, meanQ=-3.727273, numObservations: 8
action 2, numVisits=4, meanQ=-6.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.363588 0.362377 0.831891 0.0626457 0.775474 0.82843 0.523576 0.457422 0.46184 0.591983 w: 1
Observation: 0 1 0 3 0 3 0 2 0 2 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=56, meanQ=70.266964, numObservations: 8
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action 2, numVisits=8, meanQ=24.000000, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
Sampled 34201 episodes
GETTING ACTION FROM:
action 4, numVisits=34257, meanQ=43.869922, numObservations: 9
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action 2, numVisits=8, meanQ=24.000000, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action: 4
Next state: 1 0.363588 0.362377 0.831891 0.0626457 0.775474 0.82843 0.523576 0.457422 0.46184 0.591983 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 20
Initial state: 0 0.452123 0.0898223 0.443468 0.548242 0.240932 0.953485 0.85949 0.137231 0.839465 0.292274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27739 episodes
GETTING ACTION FROM:
action 2, numVisits=27728, meanQ=29.220979, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.452123 0.0898223 0.443468 0.548242 0.240932 0.953485 0.85949 0.137231 0.839465 0.292274 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 21
Initial state: 0 0.608804 0.988676 0.903207 0.227807 0.854098 0.506739 0.315532 0.887169 0.505488 0.491203 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30330 episodes
GETTING ACTION FROM:
action 2, numVisits=30323, meanQ=26.054112, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.608804 0.988676 0.903207 0.227807 0.854098 0.506739 0.315532 0.887169 0.505488 0.491203 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=67, meanQ=27.131530, numObservations: 9
action 5, numVisits=81, meanQ=13.682160, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 28703 episodes
GETTING ACTION FROM:
action 1, numVisits=28770, meanQ=32.870176, numObservations: 9
action 5, numVisits=81, meanQ=13.682160, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.608804 0.988676 0.903207 0.227807 0.854098 0.506739 0.315532 0.887169 0.505488 0.491203 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 22
Initial state: 0 0.21918 0.769593 0.511191 0.105716 0.410728 0.929602 0.527324 0.457132 0.731537 0.817577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28377 episodes
GETTING ACTION FROM:
action 2, numVisits=28366, meanQ=28.329303, numObservations: 9
action 3, numVisits=5, meanQ=15.190000, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.21918 0.769593 0.511191 0.105716 0.410728 0.929602 0.527324 0.457132 0.731537 0.817577 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 23
Initial state: 0 0.30884 0.533933 0.766559 0.254622 0.807964 0.76764 0.302087 0.777027 0.445676 0.550331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17457 episodes
GETTING ACTION FROM:
action 0, numVisits=17419, meanQ=55.939081, numObservations: 243
action -1, numVisits=23, meanQ=-5.719457, numObservations: 21
action 1, numVisits=11, meanQ=-6.327045, numObservations: 7
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.30884 0.533933 0.766559 0.254622 0.807964 0.76764 0.302087 0.777027 0.445676 0.550331 w: 1
Observation: 0 0 2 0 1 0 3 0 1 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=54, meanQ=49.268796, numObservations: 8
action 3, numVisits=11, meanQ=41.163636, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31247 episodes
GETTING ACTION FROM:
action 5, numVisits=31301, meanQ=45.805857, numObservations: 9
action 3, numVisits=11, meanQ=41.163636, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.016667, numObservations: 3
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.30884 0.533933 0.766559 0.254622 0.807964 0.76764 0.302087 0.777027 0.445676 0.550331 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 24
Initial state: 0 0.348665 0.085566 0.321777 0.618693 0.976015 0.0828593 0.986753 0.681269 0.523065 0.423311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18086 episodes
GETTING ACTION FROM:
action 0, numVisits=18028, meanQ=57.906137, numObservations: 243
action -1, numVisits=45, meanQ=-3.799722, numObservations: 39
action 4, numVisits=7, meanQ=-15.285714, numObservations: 6
action 5, numVisits=3, meanQ=-34.333333, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.348665 0.085566 0.321777 0.618693 0.976015 0.0828593 0.986753 0.681269 0.523065 0.423311 w: 1
Observation: 0 0 1 0 3 0 1 0 3 0 2 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=79, meanQ=83.393703, numObservations: 8
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 36316 episodes
GETTING ACTION FROM:
action 5, numVisits=36395, meanQ=83.406448, numObservations: 9
action 2, numVisits=2, meanQ=44.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.348665 0.085566 0.321777 0.618693 0.976015 0.0828593 0.986753 0.681269 0.523065 0.423311 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 25
Initial state: 0 0.485493 0.385793 0.425959 0.651186 0.0981605 0.531901 0.479254 0.661079 0.704402 0.662172 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29037 episodes
GETTING ACTION FROM:
action 4, numVisits=29026, meanQ=29.000007, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.485493 0.385793 0.425959 0.651186 0.0981605 0.531901 0.479254 0.661079 0.704402 0.662172 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 26
Initial state: 0 0.00968012 0.438444 0.746613 0.421143 0.278705 0.929071 0.756242 0.853011 0.445802 0.570331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28572 episodes
GETTING ACTION FROM:
action 2, numVisits=28564, meanQ=26.603483, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.00968012 0.438444 0.746613 0.421143 0.278705 0.929071 0.756242 0.853011 0.445802 0.570331 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 27
Initial state: 0 0.835911 0.931047 0.576913 0.812874 0.435019 0.988493 0.460438 0.550969 0.725873 0.787979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30572 episodes
GETTING ACTION FROM:
action 4, numVisits=30470, meanQ=27.339241, numObservations: 9
action 1, numVisits=87, meanQ=25.682557, numObservations: 9
action 2, numVisits=11, meanQ=14.627273, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.835911 0.931047 0.576913 0.812874 0.435019 0.988493 0.460438 0.550969 0.725873 0.787979 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 28
Initial state: 0 0.0453169 0.524731 0.084674 0.401708 0.396035 0.860175 0.949221 0.858926 0.420104 0.492957 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30430 episodes
GETTING ACTION FROM:
action 5, numVisits=30424, meanQ=26.715653, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0453169 0.524731 0.084674 0.401708 0.396035 0.860175 0.949221 0.858926 0.420104 0.492957 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 29
Initial state: 0 0.427079 0.383304 0.74018 0.727639 0.391992 0.396379 0.576153 0.780856 0.0409641 0.210098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17514 episodes
GETTING ACTION FROM:
action 0, numVisits=17485, meanQ=57.033288, numObservations: 243
action -1, numVisits=24, meanQ=-5.087500, numObservations: 23
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.427079 0.383304 0.74018 0.727639 0.391992 0.396379 0.576153 0.780856 0.0409641 0.210098 w: 1
Observation: 0 0 2 0 1 0 2 0 3 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=73, meanQ=65.638365, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 31062 episodes
GETTING ACTION FROM:
action 4, numVisits=31135, meanQ=65.530030, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.427079 0.383304 0.74018 0.727639 0.391992 0.396379 0.576153 0.780856 0.0409641 0.210098 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 30
Initial state: 0 0.460241 0.552391 0.0123417 0.736427 0.9373 0.0405816 0.597068 0.742951 0.821815 0.391167 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30324 episodes
GETTING ACTION FROM:
action 4, numVisits=30309, meanQ=26.636396, numObservations: 9
action 2, numVisits=5, meanQ=15.380000, numObservations: 3
action 1, numVisits=6, meanQ=14.000000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.460241 0.552391 0.0123417 0.736427 0.9373 0.0405816 0.597068 0.742951 0.821815 0.391167 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 31
Initial state: 0 0.445865 0.574533 0.113973 0.539934 0.430548 0.938222 0.688213 0.72949 0.718105 0.273417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28652 episodes
GETTING ACTION FROM:
action 4, numVisits=28577, meanQ=26.890478, numObservations: 9
action -1, numVisits=29, meanQ=-1.050000, numObservations: 29
action 0, numVisits=29, meanQ=-1.050000, numObservations: 29
action 1, numVisits=9, meanQ=-4.333333, numObservations: 7
action 5, numVisits=4, meanQ=-6.000000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action: 4
Next state: 1 0.445865 0.574533 0.113973 0.539934 0.430548 0.938222 0.688213 0.72949 0.718105 0.273417 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 32
Initial state: 0 0.255244 0.207088 0.861027 0.426285 0.446092 0.535885 0.558963 0.304618 0.300762 0.131184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30544 episodes
GETTING ACTION FROM:
action 2, numVisits=30519, meanQ=27.752497, numObservations: 9
action 4, numVisits=5, meanQ=15.000000, numObservations: 3
action 5, numVisits=13, meanQ=12.150000, numObservations: 8
action 3, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.255244 0.207088 0.861027 0.426285 0.446092 0.535885 0.558963 0.304618 0.300762 0.131184 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 33
Initial state: 0 0.493418 0.564063 0.891837 0.541077 0.318683 0.614737 0.618138 0.757749 0.017292 0.580076 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29737 episodes
GETTING ACTION FROM:
action 2, numVisits=29730, meanQ=27.037398, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.493418 0.564063 0.891837 0.541077 0.318683 0.614737 0.618138 0.757749 0.017292 0.580076 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 34
Initial state: 0 0.514964 0.777671 0.880751 0.180358 0.48154 0.514691 0.452598 0.618432 0.156622 0.307498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30070 episodes
GETTING ACTION FROM:
action 2, numVisits=30056, meanQ=26.562390, numObservations: 9
action 4, numVisits=7, meanQ=8.150000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.514964 0.777671 0.880751 0.180358 0.48154 0.514691 0.452598 0.618432 0.156622 0.307498 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 35
Initial state: 0 0.190782 0.356372 0.228585 0.719807 0.124347 0.558987 0.177853 0.747813 0.472505 0.530308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29467 episodes
GETTING ACTION FROM:
action 3, numVisits=29424, meanQ=28.372523, numObservations: 9
action 2, numVisits=25, meanQ=22.318300, numObservations: 8
action 4, numVisits=13, meanQ=18.411731, numObservations: 8
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.190782 0.356372 0.228585 0.719807 0.124347 0.558987 0.177853 0.747813 0.472505 0.530308 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 36
Initial state: 0 0.326244 0.587161 0.286129 0.123489 0.586078 0.725743 0.175142 0.189375 0.477653 0.544105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 27702 episodes
GETTING ACTION FROM:
action 1, numVisits=27694, meanQ=29.587955, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.326244 0.587161 0.286129 0.123489 0.586078 0.725743 0.175142 0.189375 0.477653 0.544105 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=2352, meanQ=56.017687, numObservations: 197
action 0, numVisits=16, meanQ=-1.050000, numObservations: 16
action 2, numVisits=12, meanQ=-2.508333, numObservations: 7
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5103 episodes
GETTING ACTION FROM:
action -1, numVisits=7455, meanQ=42.834491, numObservations: 241
action 0, numVisits=16, meanQ=-1.050000, numObservations: 16
action 2, numVisits=12, meanQ=-2.508333, numObservations: 7
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.326244 0.587161 0.286129 0.123489 0.586078 0.725743 0.175142 0.189375 0.477653 0.544105 w: 1
Observation: 0 1 0 3 0 1 0 1 0 2 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=29, meanQ=61.710345, numObservations: 5
action 5, numVisits=40, meanQ=59.023027, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 24025 episodes
GETTING ACTION FROM:
action 5, numVisits=24062, meanQ=90.748425, numObservations: 9
action 1, numVisits=32, meanQ=64.707812, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.326244 0.587161 0.286129 0.123489 0.586078 0.725743 0.175142 0.189375 0.477653 0.544105 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.4475
Run # 37
Initial state: 0 0.678602 0.190561 0.104577 0.277195 0.0296458 0.958248 0.449984 0.380932 0.667798 0.882359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28970 episodes
GETTING ACTION FROM:
action 4, numVisits=28964, meanQ=25.751474, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.678602 0.190561 0.104577 0.277195 0.0296458 0.958248 0.449984 0.380932 0.667798 0.882359 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 38
Initial state: 0 0.210475 0.472722 0.527652 0.983644 0.201544 0.360425 0.455469 0.462401 0.502533 0.00764181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28721 episodes
GETTING ACTION FROM:
action 5, numVisits=28707, meanQ=27.786192, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=8, meanQ=-5.887187, numObservations: 6
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.210475 0.472722 0.527652 0.983644 0.201544 0.360425 0.455469 0.462401 0.502533 0.00764181 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 39
Initial state: 0 0.433372 0.419261 0.0768902 0.716338 0.935263 0.946904 0.904361 0.63034 0.675719 0.484907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30591 episodes
GETTING ACTION FROM:
action 1, numVisits=30585, meanQ=26.097704, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.433372 0.419261 0.0768902 0.716338 0.935263 0.946904 0.904361 0.63034 0.675719 0.484907 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 40
Initial state: 0 0.974731 0.893222 0.429101 0.469505 0.509548 0.0954846 0.312267 0.19577 0.4686 0.210849 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 30459 episodes
GETTING ACTION FROM:
action 5, numVisits=30450, meanQ=25.865672, numObservations: 9
action 2, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.974731 0.893222 0.429101 0.469505 0.509548 0.0954846 0.312267 0.19577 0.4686 0.210849 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 41
Initial state: 0 0.833876 0.222756 0.439312 0.423617 0.721714 0.47071 0.371149 0.222721 0.897952 0.886709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28823 episodes
GETTING ACTION FROM:
action 3, numVisits=28816, meanQ=29.888341, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.833876 0.222756 0.439312 0.423617 0.721714 0.47071 0.371149 0.222721 0.897952 0.886709 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 42
Initial state: 0 0.426996 0.499692 0.17743 0.581793 0.385698 0.772425 0.852661 0.880548 0.784651 0.591565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29241 episodes
GETTING ACTION FROM:
action 5, numVisits=29233, meanQ=28.149980, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.426996 0.499692 0.17743 0.581793 0.385698 0.772425 0.852661 0.880548 0.784651 0.591565 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 43
Initial state: 0 0.621843 0.0770174 0.0238987 0.279156 0.567241 0.854792 0.461512 0.427598 0.896653 0.0397157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17738 episodes
GETTING ACTION FROM:
action -1, numVisits=17684, meanQ=54.330826, numObservations: 243
action 0, numVisits=46, meanQ=-5.305380, numObservations: 43
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=4, meanQ=-29.987500, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.621843 0.0770174 0.0238987 0.279156 0.567241 0.854792 0.461512 0.427598 0.896653 0.0397157 w: 1
Observation: 0 3 0 1 0 2 0 2 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=48, meanQ=40.992813, numObservations: 8
action 2, numVisits=22, meanQ=36.095682, numObservations: 6
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 35941 episodes
GETTING ACTION FROM:
action 3, numVisits=34705, meanQ=58.231776, numObservations: 9
action 2, numVisits=1306, meanQ=32.121017, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.621843 0.0770174 0.0238987 0.279156 0.567241 0.854792 0.461512 0.427598 0.896653 0.0397157 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 44
Initial state: 0 0.601408 0.133307 0.422494 0.139032 0.431388 0.513334 0.0389163 0.108372 0.0432606 0.907546 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18042 episodes
GETTING ACTION FROM:
action -1, numVisits=17975, meanQ=51.790426, numObservations: 243
action 1, numVisits=47, meanQ=-2.948670, numObservations: 9
action 0, numVisits=16, meanQ=-7.106250, numObservations: 15
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.601408 0.133307 0.422494 0.139032 0.431388 0.513334 0.0389163 0.108372 0.0432606 0.907546 w: 1
Observation: 0 3 0 2 0 1 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=101, meanQ=6.151064, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 38693 episodes
GETTING ACTION FROM:
action 1, numVisits=38794, meanQ=13.409767, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.601408 0.133307 0.422494 0.139032 0.431388 0.513334 0.0389163 0.108372 0.0432606 0.907546 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 45
Initial state: 0 0.346805 0.536787 0.378347 0.64707 0.735253 0.370963 0.919275 0.411679 0.530976 0.535659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29677 episodes
GETTING ACTION FROM:
action 2, numVisits=29639, meanQ=27.128105, numObservations: 9
action 1, numVisits=31, meanQ=9.326210, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.346805 0.536787 0.378347 0.64707 0.735253 0.370963 0.919275 0.411679 0.530976 0.535659 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=2591, meanQ=37.273185, numObservations: 9
action 3, numVisits=12, meanQ=30.825000, numObservations: 7
action 1, numVisits=4, meanQ=21.737500, numObservations: 4
action 4, numVisits=6, meanQ=14.158333, numObservations: 5
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
Sampled 12449 episodes
GETTING ACTION FROM:
action 3, numVisits=12458, meanQ=50.417922, numObservations: 9
action 2, numVisits=2593, meanQ=37.280458, numObservations: 9
action 4, numVisits=6, meanQ=14.158333, numObservations: 5
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=5, meanQ=-2.810000, numObservations: 4
action: 3
Next state: 2 0.346805 0.536787 0.378347 0.64707 0.735253 0.370963 0.919275 0.411679 0.530976 0.535659 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 46
Initial state: 0 0.377279 0.825528 0.515308 0.384285 0.697765 0.111123 0.406127 0.102298 0.0940558 0.733067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29638 episodes
GETTING ACTION FROM:
action 2, numVisits=29632, meanQ=28.022039, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.377279 0.825528 0.515308 0.384285 0.697765 0.111123 0.406127 0.102298 0.0940558 0.733067 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 47
Initial state: 0 0.90777 0.162565 0.239711 0.267587 0.589537 0.807556 0.459281 0.418375 0.0951269 0.880374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29179 episodes
GETTING ACTION FROM:
action 3, numVisits=29173, meanQ=27.582495, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 1 0.90777 0.162565 0.239711 0.267587 0.589537 0.807556 0.459281 0.418375 0.0951269 0.880374 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 48
Initial state: 0 0.103753 0.72076 0.485298 0.53637 0.981653 0.0406463 0.484286 0.712529 0.726776 0.671958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 28536 episodes
GETTING ACTION FROM:
action 5, numVisits=28526, meanQ=29.459968, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.103753 0.72076 0.485298 0.53637 0.981653 0.0406463 0.484286 0.712529 0.726776 0.671958 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 49
Initial state: 0 0.838866 0.278304 0.501381 0.48377 0.241909 0.934492 0.125776 0.632369 0.0977194 0.148181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29673 episodes
GETTING ACTION FROM:
action 4, numVisits=29667, meanQ=26.813424, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.838866 0.278304 0.501381 0.48377 0.241909 0.934492 0.125776 0.632369 0.0977194 0.148181 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 50
Initial state: 0 0.120623 0.740361 0.328096 0.954441 0.467815 0.543184 0.0481353 0.616659 0.609848 0.576591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 29502 episodes
GETTING ACTION FROM:
action 5, numVisits=29495, meanQ=27.790597, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.120623 0.740361 0.328096 0.954441 0.467815 0.543184 0.0481353 0.616659 0.609848 0.576591 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
[32m ProblemEnvironment.hpp 351: Done.[39m
