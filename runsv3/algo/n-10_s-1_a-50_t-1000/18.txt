Run # 1
Initial state: 0 0.589953 0.907973 0.718995 0.057974 0.619663 0.0571797 0.849006 0.752915 0.405882 0.437173 0.943144 0.604976 0.195684 0.118715 0.822863 0.990503 0.379889 0.635453 0.945043 0.0270027 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17899 episodes
GETTING ACTION FROM:
action 10, numVisits=17773, meanQ=21.079866, numObservations: 9
action 6, numVisits=108, meanQ=20.078981, numObservations: 9
action 2, numVisits=6, meanQ=14.000000, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 7, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 10
Next state: 2 0.589953 0.907973 0.718995 0.057974 0.619663 0.0571797 0.849006 0.752915 0.405882 0.437173 0.943144 0.604976 0.195684 0.118715 0.822863 0.990503 0.379889 0.635453 0.945043 0.0270027 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 2
Initial state: 0 0.966132 0.272701 0.304557 0.231741 0.419729 0.438977 0.446056 0.852616 0.627167 0.321102 0.332393 0.508958 0.630851 0.949196 0.0416518 0.608677 0.446193 0.925324 0.401468 0.202472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18388 episodes
GETTING ACTION FROM:
action 2, numVisits=18352, meanQ=24.465216, numObservations: 9
action 6, numVisits=19, meanQ=13.736842, numObservations: 7
action 9, numVisits=7, meanQ=10.428571, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.966132 0.272701 0.304557 0.231741 0.419729 0.438977 0.446056 0.852616 0.627167 0.321102 0.332393 0.508958 0.630851 0.949196 0.0416518 0.608677 0.446193 0.925324 0.401468 0.202472 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 3
Initial state: 0 0.386184 0.469304 0.35338 0.38824 0.420838 0.862744 0.228584 0.836422 0.155005 0.198813 0.686137 0.290625 0.265058 0.218175 0.381251 0.105398 0.116191 0.84762 0.574461 0.45352 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20527 episodes
GETTING ACTION FROM:
action 8, numVisits=20496, meanQ=23.326195, numObservations: 9
action -1, numVisits=5, meanQ=-1.050000, numObservations: 5
action 0, numVisits=5, meanQ=-1.050000, numObservations: 5
action 2, numVisits=5, meanQ=-3.000000, numObservations: 5
action 4, numVisits=5, meanQ=-3.000000, numObservations: 5
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 10, numVisits=3, meanQ=-4.333333, numObservations: 2
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 2 0.386184 0.469304 0.35338 0.38824 0.420838 0.862744 0.228584 0.836422 0.155005 0.198813 0.686137 0.290625 0.265058 0.218175 0.381251 0.105398 0.116191 0.84762 0.574461 0.45352 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 4
Initial state: 0 0.840093 0.373522 0.508221 0.972694 0.817968 0.940346 0.198843 0.437505 0.178047 0.480882 0.946886 0.163107 0.583062 0.440846 0.783137 0.975075 0.26254 0.00497997 0.306541 0.445432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19798 episodes
GETTING ACTION FROM:
action 8, numVisits=19703, meanQ=24.629804, numObservations: 9
action 5, numVisits=53, meanQ=16.043443, numObservations: 9
action 9, numVisits=10, meanQ=14.140250, numObservations: 5
action 4, numVisits=13, meanQ=13.688462, numObservations: 7
action 7, numVisits=10, meanQ=6.095000, numObservations: 6
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 2 0.840093 0.373522 0.508221 0.972694 0.817968 0.940346 0.198843 0.437505 0.178047 0.480882 0.946886 0.163107 0.583062 0.440846 0.783137 0.975075 0.26254 0.00497997 0.306541 0.445432 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 5
Initial state: 0 0.486015 0.729114 0.398589 0.448031 0.033355 0.423604 0.405989 0.127781 0.903106 0.500159 0.838757 0.321201 0.127669 0.966709 0.0902088 0.369301 0.067276 0.689512 0.483172 0.600442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18555 episodes
GETTING ACTION FROM:
action 2, numVisits=18533, meanQ=22.892568, numObservations: 9
action 8, numVisits=6, meanQ=14.000000, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=5, meanQ=-3.000000, numObservations: 4
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.486015 0.729114 0.398589 0.448031 0.033355 0.423604 0.405989 0.127781 0.903106 0.500159 0.838757 0.321201 0.127669 0.966709 0.0902088 0.369301 0.067276 0.689512 0.483172 0.600442 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=84, meanQ=43.569845, numObservations: 9
action 10, numVisits=8, meanQ=10.368750, numObservations: 4
action 7, numVisits=9, meanQ=8.100000, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=5, meanQ=-2.810000, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 6, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18024 episodes
GETTING ACTION FROM:
action 2, numVisits=133, meanQ=45.451241, numObservations: 9
action 10, numVisits=17983, meanQ=35.414603, numObservations: 9
action 7, numVisits=9, meanQ=8.100000, numObservations: 7
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=5, meanQ=-2.810000, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 6, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.486015 0.729114 0.398589 0.448031 0.033355 0.423604 0.405989 0.127781 0.903106 0.500159 0.838757 0.321201 0.127669 0.966709 0.0902088 0.369301 0.067276 0.689512 0.483172 0.600442 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 6
Initial state: 0 0.385908 0.374276 0.730557 0.729398 0.0369161 0.114729 0.762795 0.991082 0.511713 0.593508 0.830793 0.0343114 0.411258 0.175252 0.596866 0.6574 0.496233 0.940835 0.431042 0.602169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18061 episodes
GETTING ACTION FROM:
action 10, numVisits=18043, meanQ=23.752198, numObservations: 9
action -1, numVisits=3, meanQ=-1.050000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 1, numVisits=4, meanQ=-6.000000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 10
Next state: 1 0.385908 0.374276 0.730557 0.729398 0.0369161 0.114729 0.762795 0.991082 0.511713 0.593508 0.830793 0.0343114 0.411258 0.175252 0.596866 0.6574 0.496233 0.940835 0.431042 0.602169 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 7
Initial state: 0 0.555878 0.719336 0.114541 0.116881 0.328189 0.949256 0.130475 0.805436 0.87654 0.796232 0.273044 0.446429 0.865226 0.444598 0.350109 0.430756 0.607953 0.0375763 0.0437547 0.499202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18852 episodes
GETTING ACTION FROM:
action 1, numVisits=18836, meanQ=24.250632, numObservations: 9
action 5, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 6, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.555878 0.719336 0.114541 0.116881 0.328189 0.949256 0.130475 0.805436 0.87654 0.796232 0.273044 0.446429 0.865226 0.444598 0.350109 0.430756 0.607953 0.0375763 0.0437547 0.499202 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 8
Initial state: 0 0.430932 0.647849 0.61554 0.00833102 0.578618 0.509307 0.559452 0.0714764 0.972967 0.147913 0.433265 0.258708 0.201786 0.691409 0.9153 0.831068 0.420227 0.461609 0.989183 0.229389 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19524 episodes
GETTING ACTION FROM:
action 1, numVisits=19505, meanQ=23.336297, numObservations: 9
action 2, numVisits=7, meanQ=9.714286, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.430932 0.647849 0.61554 0.00833102 0.578618 0.509307 0.559452 0.0714764 0.972967 0.147913 0.433265 0.258708 0.201786 0.691409 0.9153 0.831068 0.420227 0.461609 0.989183 0.229389 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 9
Initial state: 0 0.215889 0.83712 0.652002 0.635914 0.842011 0.8016 0.0318638 0.0946065 0.975886 0.664811 0.896002 0.89251 0.0477218 0.399971 0.433361 0.398698 0.79985 0.896645 0.807478 0.983547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20435 episodes
GETTING ACTION FROM:
action 2, numVisits=20410, meanQ=22.719122, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 5, numVisits=5, meanQ=-3.000000, numObservations: 5
action 10, numVisits=8, meanQ=-3.624688, numObservations: 5
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.215889 0.83712 0.652002 0.635914 0.842011 0.8016 0.0318638 0.0946065 0.975886 0.664811 0.896002 0.89251 0.0477218 0.399971 0.433361 0.398698 0.79985 0.896645 0.807478 0.983547 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 10
Initial state: 0 0.391067 0.957297 0.772559 0.375786 0.719315 0.486803 0.426162 0.263922 0.340072 0.385251 0.259964 0.0426469 0.30729 0.25197 0.435507 0.565787 0.721049 0.034517 0.0625347 0.027423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18593 episodes
GETTING ACTION FROM:
action 10, numVisits=18558, meanQ=19.423898, numObservations: 9
action 4, numVisits=24, meanQ=17.243750, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 10
Next state: 0 0.391067 0.957297 0.772559 0.375786 0.719315 0.486803 0.426162 0.263922 0.340072 0.385251 0.259964 0.0426469 0.30729 0.25197 0.435507 0.565787 0.721049 0.034517 0.0625347 0.027423 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=991, meanQ=-0.892450, numObservations: 955
action 0, numVisits=231, meanQ=-1.942835, numObservations: 227
action 3, numVisits=4, meanQ=-5.525000, numObservations: 4
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 10, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 8, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 3065 episodes
GETTING ACTION FROM:
action -1, numVisits=4042, meanQ=4.018496, numObservations: 3120
action 0, numVisits=231, meanQ=-1.942835, numObservations: 227
action 5, numVisits=14, meanQ=-3.858151, numObservations: 7
action 3, numVisits=4, meanQ=-5.525000, numObservations: 4
action 10, numVisits=2, meanQ=-16.356851, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 2
action 8, numVisits=3, meanQ=-34.333333, numObservations: 2
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.391067 0.957297 0.772559 0.375786 0.719315 0.486803 0.426162 0.263922 0.340072 0.385251 0.259964 0.0426469 0.30729 0.25197 0.435507 0.565787 0.721049 0.034517 0.0625347 0.027423 w: 1
Observation: 0 2 0 1 0 3 0 2 0 2 0 1 0 2 0 2 0 3 0 1 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 26729 episodes
GETTING ACTION FROM:
action 7, numVisits=26718, meanQ=36.824458, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 0 0.391067 0.957297 0.772559 0.375786 0.719315 0.486803 0.426162 0.263922 0.340072 0.385251 0.259964 0.0426469 0.30729 0.25197 0.435507 0.565787 0.721049 0.034517 0.0625347 0.027423 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=26, meanQ=57.394101, numObservations: 7
action 6, numVisits=21, meanQ=48.453858, numObservations: 7
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action 9, numVisits=9, meanQ=32.333333, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.563062, numObservations: 3
action 1, numVisits=1, meanQ=-11.530027, numObservations: 1
action 8, numVisits=1, meanQ=-11.679659, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25763 episodes
GETTING ACTION FROM:
action 4, numVisits=25789, meanQ=87.479983, numObservations: 9
action 6, numVisits=21, meanQ=48.453858, numObservations: 7
action 3, numVisits=3, meanQ=32.333333, numObservations: 2
action 9, numVisits=9, meanQ=32.333333, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.563062, numObservations: 3
action 1, numVisits=1, meanQ=-11.530027, numObservations: 1
action 8, numVisits=1, meanQ=-11.679659, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.391067 0.957297 0.772559 0.375786 0.719315 0.486803 0.426162 0.263922 0.340072 0.385251 0.259964 0.0426469 0.30729 0.25197 0.435507 0.565787 0.721049 0.034517 0.0625347 0.027423 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 3, numVisits=1, meanQ=99.000000, numObservations: 1
action 4, numVisits=1, meanQ=99.000000, numObservations: 1
action 9, numVisits=1, meanQ=99.000000, numObservations: 1
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 46607 episodes
GETTING ACTION FROM:
action 1, numVisits=46373, meanQ=76.992391, numObservations: 9
action 10, numVisits=219, meanQ=72.854110, numObservations: 7
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 6, numVisits=3, meanQ=32.333333, numObservations: 2
action 8, numVisits=3, meanQ=32.333333, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-2.000000, numObservations: 1
action 0, numVisits=1, meanQ=-2.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.391067 0.957297 0.772559 0.375786 0.719315 0.486803 0.426162 0.263922 0.340072 0.385251 0.259964 0.0426469 0.30729 0.25197 0.435507 0.565787 0.721049 0.034517 0.0625347 0.027423 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 48.3775
Run # 11
Initial state: 0 0.0623888 0.531535 0.421639 0.380576 0.234394 0.860439 0.52115 0.961446 0.767436 0.659132 0.659436 0.913984 0.831346 0.484058 0.0284833 0.155465 0.65878 0.189948 0.467473 0.471626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20442 episodes
GETTING ACTION FROM:
action 9, numVisits=20367, meanQ=23.598233, numObservations: 9
action 3, numVisits=59, meanQ=5.050169, numObservations: 9
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 9
Next state: 2 0.0623888 0.531535 0.421639 0.380576 0.234394 0.860439 0.52115 0.961446 0.767436 0.659132 0.659436 0.913984 0.831346 0.484058 0.0284833 0.155465 0.65878 0.189948 0.467473 0.471626 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 12
Initial state: 0 0.361791 0.399778 0.359468 0.064844 0.725601 0.770442 0.827905 0.771471 0.101119 0.439846 0.14799 0.244416 0.177334 0.575714 0.211358 0.73694 0.293258 0.14041 0.964639 0.87404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18526 episodes
GETTING ACTION FROM:
action 8, numVisits=18466, meanQ=22.742086, numObservations: 9
action 3, numVisits=31, meanQ=19.653226, numObservations: 8
action 6, numVisits=9, meanQ=17.994444, numObservations: 7
action 10, numVisits=5, meanQ=14.800500, numObservations: 3
action 9, numVisits=6, meanQ=14.158333, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 1 0.361791 0.399778 0.359468 0.064844 0.725601 0.770442 0.827905 0.771471 0.101119 0.439846 0.14799 0.244416 0.177334 0.575714 0.211358 0.73694 0.293258 0.14041 0.964639 0.87404 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 13
Initial state: 0 0.856245 0.462644 0.219348 0.0937326 0.173605 0.826309 0.843795 0.78682 0.369835 0.398819 0.638062 0.08217 0.335889 0.973683 0.170073 0.128262 0.640178 0.25336 0.476984 0.393925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19049 episodes
GETTING ACTION FROM:
action 7, numVisits=18997, meanQ=18.579626, numObservations: 9
action 1, numVisits=11, meanQ=16.272727, numObservations: 6
action 4, numVisits=28, meanQ=14.585804, numObservations: 7
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 9, numVisits=4, meanQ=-6.000000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 1 0.856245 0.462644 0.219348 0.0937326 0.173605 0.826309 0.843795 0.78682 0.369835 0.398819 0.638062 0.08217 0.335889 0.973683 0.170073 0.128262 0.640178 0.25336 0.476984 0.393925 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 14
Initial state: 0 0.154843 0.0832927 0.416951 0.607149 0.176321 0.478344 0.293581 0.400794 0.860371 0.30069 0.773146 0.761213 0.761427 0.063518 0.171692 0.413813 0.0961209 0.680651 0.33727 0.878859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19827 episodes
GETTING ACTION FROM:
action 9, numVisits=19794, meanQ=23.867228, numObservations: 9
action -1, numVisits=10, meanQ=-1.050000, numObservations: 10
action 0, numVisits=10, meanQ=-1.050000, numObservations: 10
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 10, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 9
Next state: 1 0.154843 0.0832927 0.416951 0.607149 0.176321 0.478344 0.293581 0.400794 0.860371 0.30069 0.773146 0.761213 0.761427 0.063518 0.171692 0.413813 0.0961209 0.680651 0.33727 0.878859 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 15
Initial state: 0 0.571284 0.942399 0.586171 0.315872 0.790489 0.133964 0.19361 0.111627 0.366347 0.453872 0.891338 0.488832 0.258416 0.0160963 0.506935 0.73998 0.305659 0.768117 0.705917 0.311507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18482 episodes
GETTING ACTION FROM:
action 8, numVisits=18446, meanQ=21.876569, numObservations: 9
action 4, numVisits=4, meanQ=17.512500, numObservations: 3
action 2, numVisits=12, meanQ=14.158333, numObservations: 6
action 1, numVisits=7, meanQ=13.285714, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=5, meanQ=-2.810000, numObservations: 5
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 1 0.571284 0.942399 0.586171 0.315872 0.790489 0.133964 0.19361 0.111627 0.366347 0.453872 0.891338 0.488832 0.258416 0.0160963 0.506935 0.73998 0.305659 0.768117 0.705917 0.311507 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 16
Initial state: 0 0.474818 0.150999 0.571444 0.461415 0.780973 0.433602 0.155987 0.302259 0.454555 0.310898 0.367353 0.412021 0.0484336 0.438427 0.560695 0.716475 0.641324 0.690202 0.334205 0.965296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19409 episodes
GETTING ACTION FROM:
action 2, numVisits=19395, meanQ=23.299483, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.474818 0.150999 0.571444 0.461415 0.780973 0.433602 0.155987 0.302259 0.454555 0.310898 0.367353 0.412021 0.0484336 0.438427 0.560695 0.716475 0.641324 0.690202 0.334205 0.965296 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 17
Initial state: 0 0.12909 0.423843 0.792433 0.339339 0.968714 0.565119 0.326426 0.802891 0.778502 0.342408 0.971025 0.344598 0.437487 0.454655 0.0105896 0.315577 0.386766 0.660001 0.0139843 0.889489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19490 episodes
GETTING ACTION FROM:
action 1, numVisits=19468, meanQ=24.913698, numObservations: 9
action 5, numVisits=8, meanQ=10.368750, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.12909 0.423843 0.792433 0.339339 0.968714 0.565119 0.326426 0.802891 0.778502 0.342408 0.971025 0.344598 0.437487 0.454655 0.0105896 0.315577 0.386766 0.660001 0.0139843 0.889489 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 7, numVisits=293, meanQ=37.443720, numObservations: 9
action 6, numVisits=71, meanQ=18.895810, numObservations: 9
action 4, numVisits=20, meanQ=18.095000, numObservations: 8
action 3, numVisits=34, meanQ=17.872132, numObservations: 9
action 9, numVisits=4, meanQ=16.725625, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 10, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5685 episodes
GETTING ACTION FROM:
action 7, numVisits=5914, meanQ=17.110850, numObservations: 9
action 6, numVisits=75, meanQ=14.955367, numObservations: 9
action 9, numVisits=62, meanQ=14.508818, numObservations: 9
action 3, numVisits=35, meanQ=14.475786, numObservations: 9
action 4, numVisits=21, meanQ=12.423810, numObservations: 8
action 5, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 10, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 1 0.12909 0.423843 0.792433 0.339339 0.968714 0.565119 0.326426 0.802891 0.778502 0.342408 0.971025 0.344598 0.437487 0.454655 0.0105896 0.315577 0.386766 0.660001 0.0139843 0.889489 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 18
Initial state: 0 0.730529 0.739262 0.0879558 0.117425 0.0657792 0.621741 0.311583 0.444355 0.721128 0.525755 0.150646 0.309788 0.0587746 0.77496 0.026048 0.100366 0.401327 0.593411 0.941487 0.3605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19052 episodes
GETTING ACTION FROM:
action 7, numVisits=19028, meanQ=23.122797, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=5, meanQ=-3.000000, numObservations: 5
action 4, numVisits=5, meanQ=-3.000000, numObservations: 3
action 6, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 1 0.730529 0.739262 0.0879558 0.117425 0.0657792 0.621741 0.311583 0.444355 0.721128 0.525755 0.150646 0.309788 0.0587746 0.77496 0.026048 0.100366 0.401327 0.593411 0.941487 0.3605 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 19
Initial state: 0 0.284652 0.96949 0.330069 0.0331798 0.118477 0.474459 0.36813 0.923432 0.424548 0.283086 0.313821 0.462369 0.862867 0.639401 0.354275 0.515586 0.690088 0.830145 0.580739 0.00745383 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20355 episodes
GETTING ACTION FROM:
action 8, numVisits=20305, meanQ=22.145153, numObservations: 9
action 3, numVisits=20, meanQ=17.142500, numObservations: 8
action 1, numVisits=6, meanQ=14.000000, numObservations: 3
action 5, numVisits=7, meanQ=10.428571, numObservations: 6
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 6, numVisits=3, meanQ=-4.333333, numObservations: 3
action 9, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=4, meanQ=-5.762500, numObservations: 4
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 1 0.284652 0.96949 0.330069 0.0331798 0.118477 0.474459 0.36813 0.923432 0.424548 0.283086 0.313821 0.462369 0.862867 0.639401 0.354275 0.515586 0.690088 0.830145 0.580739 0.00745383 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 20
Initial state: 0 0.949311 0.454465 0.51153 0.319219 0.38404 0.345515 0.782831 0.152175 0.554104 0.0184397 0.386486 0.383624 0.221263 0.66711 0.35781 0.00977512 0.278763 0.832175 0.214536 0.215561 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 4464 episodes
GETTING ACTION FROM:
action -1, numVisits=4263, meanQ=0.753563, numObservations: 3873
action 0, numVisits=163, meanQ=-1.050000, numObservations: 163
action 3, numVisits=12, meanQ=-2.666667, numObservations: 7
action 2, numVisits=10, meanQ=-2.810000, numObservations: 7
action 10, numVisits=7, meanQ=-6.278214, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.949311 0.454465 0.51153 0.319219 0.38404 0.345515 0.782831 0.152175 0.554104 0.0184397 0.386486 0.383624 0.221263 0.66711 0.35781 0.00977512 0.278763 0.832175 0.214536 0.215561 w: 1
Observation: 0 3 0 3 0 2 0 3 0 3 0 2 0 1 0 2 0 1 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 22618 episodes
GETTING ACTION FROM:
action 3, numVisits=22601, meanQ=84.057634, numObservations: 9
action 2, numVisits=3, meanQ=32.333333, numObservations: 1
action 4, numVisits=3, meanQ=32.333333, numObservations: 3
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.949311 0.454465 0.51153 0.319219 0.38404 0.345515 0.782831 0.152175 0.554104 0.0184397 0.386486 0.383624 0.221263 0.66711 0.35781 0.00977512 0.278763 0.832175 0.214536 0.215561 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 21
Initial state: 0 0.24781 0.216242 0.174883 0.701502 0.750111 0.0912305 0.351031 0.772526 0.341226 0.89461 0.395967 0.379563 0.510155 0.572268 0.496391 0.420434 0.651589 0.346935 0.401219 0.167654 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18258 episodes
GETTING ACTION FROM:
action 6, numVisits=18149, meanQ=24.923851, numObservations: 9
action 7, numVisits=80, meanQ=23.338813, numObservations: 9
action 10, numVisits=16, meanQ=22.153281, numObservations: 8
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 8, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 1 0.24781 0.216242 0.174883 0.701502 0.750111 0.0912305 0.351031 0.772526 0.341226 0.89461 0.395967 0.379563 0.510155 0.572268 0.496391 0.420434 0.651589 0.346935 0.401219 0.167654 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 22
Initial state: 0 0.364285 0.969202 0.667875 0.95033 0.869939 0.10335 0.738189 0.460041 0.25956 0.752174 0.0694489 0.154947 0.359724 0.447754 0.309845 0.965537 0.822016 0.0817608 0.946782 0.501521 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18370 episodes
GETTING ACTION FROM:
action 4, numVisits=18354, meanQ=20.374829, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 8, numVisits=3, meanQ=-4.333333, numObservations: 3
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.364285 0.969202 0.667875 0.95033 0.869939 0.10335 0.738189 0.460041 0.25956 0.752174 0.0694489 0.154947 0.359724 0.447754 0.309845 0.965537 0.822016 0.0817608 0.946782 0.501521 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 23
Initial state: 0 0.293189 0.579921 0.925843 0.858539 0.0117237 0.38939 0.377306 0.444235 0.308246 0.52738 0.854557 0.182358 0.719688 0.815479 0.64656 0.371563 0.557214 0.376169 0.364314 0.112931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19778 episodes
GETTING ACTION FROM:
action 8, numVisits=19749, meanQ=24.923382, numObservations: 9
action 7, numVisits=5, meanQ=15.000000, numObservations: 4
action 5, numVisits=6, meanQ=14.000000, numObservations: 5
action 4, numVisits=10, meanQ=8.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 1 0.293189 0.579921 0.925843 0.858539 0.0117237 0.38939 0.377306 0.444235 0.308246 0.52738 0.854557 0.182358 0.719688 0.815479 0.64656 0.371563 0.557214 0.376169 0.364314 0.112931 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 24
Initial state: 0 0.967161 0.0720669 0.807533 0.154448 0.341784 0.440236 0.855019 0.0249283 0.907194 0.512726 0.243273 0.177119 0.112555 0.728291 0.390957 0.899937 0.0263001 0.391099 0.951565 0.620318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19220 episodes
GETTING ACTION FROM:
action 8, numVisits=19203, meanQ=21.033858, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 2 0.967161 0.0720669 0.807533 0.154448 0.341784 0.440236 0.855019 0.0249283 0.907194 0.512726 0.243273 0.177119 0.112555 0.728291 0.390957 0.899937 0.0263001 0.391099 0.951565 0.620318 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 25
Initial state: 0 0.705615 0.0058464 0.586262 0.128255 0.999594 0.711465 0.500332 0.886217 0.334273 0.704431 0.058903 0.166262 0.934913 0.200077 0.460532 0.690177 0.315698 0.433816 0.0105737 0.823135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19590 episodes
GETTING ACTION FROM:
action 10, numVisits=19547, meanQ=22.511261, numObservations: 9
action 8, numVisits=13, meanQ=19.804038, numObservations: 5
action 1, numVisits=5, meanQ=15.380000, numObservations: 4
action 6, numVisits=12, meanQ=14.079167, numObservations: 6
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=3, meanQ=-6.316667, numObservations: 2
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 10
Next state: 1 0.705615 0.0058464 0.586262 0.128255 0.999594 0.711465 0.500332 0.886217 0.334273 0.704431 0.058903 0.166262 0.934913 0.200077 0.460532 0.690177 0.315698 0.433816 0.0105737 0.823135 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 26
Initial state: 0 0.397311 0.128103 0.720449 0.867299 0.120855 0.79431 0.0743799 0.0250452 0.337369 0.169695 0.332155 0.408006 0.829389 0.689083 0.684733 0.603774 0.64825 0.0679855 0.554231 0.771883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18390 episodes
GETTING ACTION FROM:
action 5, numVisits=18357, meanQ=23.799091, numObservations: 9
action 10, numVisits=11, meanQ=14.454545, numObservations: 5
action 7, numVisits=6, meanQ=14.000000, numObservations: 6
action 3, numVisits=7, meanQ=9.578571, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 0 0.397311 0.128103 0.720449 0.867299 0.120855 0.79431 0.0743799 0.0250452 0.337369 0.169695 0.332155 0.408006 0.829389 0.689083 0.684733 0.603774 0.64825 0.0679855 0.554231 0.771883 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=283, meanQ=39.199140, numObservations: 9
action 8, numVisits=14, meanQ=26.278571, numObservations: 6
action 10, numVisits=4, meanQ=21.737500, numObservations: 4
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 6, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 12204 episodes
GETTING ACTION FROM:
action 2, numVisits=12334, meanQ=7.768857, numObservations: 9
action 10, numVisits=146, meanQ=6.730749, numObservations: 9
action 8, numVisits=21, meanQ=2.900000, numObservations: 6
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=3, meanQ=-1.366667, numObservations: 3
action 0, numVisits=3, meanQ=-1.366667, numObservations: 3
action 6, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.397311 0.128103 0.720449 0.867299 0.120855 0.79431 0.0743799 0.0250452 0.337369 0.169695 0.332155 0.408006 0.829389 0.689083 0.684733 0.603774 0.64825 0.0679855 0.554231 0.771883 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 27
Initial state: 0 0.946405 0.892594 0.48538 0.718838 0.0914818 0.564623 0.451205 0.770209 0.352596 0.467351 0.68459 0.892391 0.306154 0.370357 0.149688 0.620681 0.468492 0.073536 0.323044 0.786452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19907 episodes
GETTING ACTION FROM:
action 4, numVisits=16008, meanQ=25.308071, numObservations: 9
action 2, numVisits=3885, meanQ=24.917737, numObservations: 9
action 8, numVisits=4, meanQ=21.500000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.946405 0.892594 0.48538 0.718838 0.0914818 0.564623 0.451205 0.770209 0.352596 0.467351 0.68459 0.892391 0.306154 0.370357 0.149688 0.620681 0.468492 0.073536 0.323044 0.786452 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 28
Initial state: 0 0.380603 0.93905 0.0155785 0.795642 0.094603 0.16185 0.366881 0.444586 0.45122 0.89203 0.10266 0.133027 0.728243 0.408344 0.208783 0.356002 0.66599 0.621627 0.410561 0.740974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19773 episodes
GETTING ACTION FROM:
action 7, numVisits=19745, meanQ=22.893273, numObservations: 9
action 4, numVisits=6, meanQ=14.000000, numObservations: 5
action 6, numVisits=6, meanQ=14.000000, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 1 0.380603 0.93905 0.0155785 0.795642 0.094603 0.16185 0.366881 0.444586 0.45122 0.89203 0.10266 0.133027 0.728243 0.408344 0.208783 0.356002 0.66599 0.621627 0.410561 0.740974 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 29
Initial state: 0 0.85935 0.604966 0.448272 0.319147 0.393442 0.436986 0.0383382 0.625886 0.175386 0.529026 0.422005 0.134467 0.00392882 0.499276 0.148299 0.266581 0.081529 0.83515 0.555685 0.251409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17601 episodes
GETTING ACTION FROM:
action 10, numVisits=17588, meanQ=20.077461, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 10
Next state: 2 0.85935 0.604966 0.448272 0.319147 0.393442 0.436986 0.0383382 0.625886 0.175386 0.529026 0.422005 0.134467 0.00392882 0.499276 0.148299 0.266581 0.081529 0.83515 0.555685 0.251409 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 30
Initial state: 0 0.0299531 0.297728 0.310426 0.461649 0.0269474 0.442769 0.469539 0.765151 0.00395368 0.644096 0.185592 0.402743 0.512629 0.992199 0.124552 0.46727 0.600506 0.21908 0.0123842 0.111115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19330 episodes
GETTING ACTION FROM:
action 5, numVisits=19219, meanQ=22.166601, numObservations: 9
action 6, numVisits=79, meanQ=18.839905, numObservations: 9
action 8, numVisits=16, meanQ=17.184375, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=4, meanQ=-6.000000, numObservations: 4
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0299531 0.297728 0.310426 0.461649 0.0269474 0.442769 0.469539 0.765151 0.00395368 0.644096 0.185592 0.402743 0.512629 0.992199 0.124552 0.46727 0.600506 0.21908 0.0123842 0.111115 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=81, meanQ=34.427870, numObservations: 9
action 4, numVisits=14, meanQ=24.846607, numObservations: 6
action 7, numVisits=4, meanQ=21.737500, numObservations: 3
action 10, numVisits=6, meanQ=14.158333, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 14729 episodes
GETTING ACTION FROM:
action 3, numVisits=14810, meanQ=33.499238, numObservations: 9
action 4, numVisits=14, meanQ=24.846607, numObservations: 6
action 7, numVisits=4, meanQ=21.737500, numObservations: 3
action 10, numVisits=6, meanQ=14.158333, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.0299531 0.297728 0.310426 0.461649 0.0269474 0.442769 0.469539 0.765151 0.00395368 0.644096 0.185592 0.402743 0.512629 0.992199 0.124552 0.46727 0.600506 0.21908 0.0123842 0.111115 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=17, meanQ=25.106251, numObservations: 7
action 7, numVisits=19, meanQ=17.905506, numObservations: 6
action 4, numVisits=6, meanQ=13.670721, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-12.811255, numObservations: 1
action 8, numVisits=1, meanQ=-13.185779, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-204.022294, numObservations: 1
Sampled 15328 episodes
GETTING ACTION FROM:
action 1, numVisits=15342, meanQ=16.750596, numObservations: 9
action 7, numVisits=21, meanQ=6.581172, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=7, meanQ=-2.710810, numObservations: 5
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-12.811255, numObservations: 1
action 8, numVisits=1, meanQ=-13.185779, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-204.022294, numObservations: 1
action: 1
Next state: 0 0.0299531 0.297728 0.310426 0.461649 0.0269474 0.442769 0.469539 0.765151 0.00395368 0.644096 0.185592 0.402743 0.512629 0.992199 0.124552 0.46727 0.600506 0.21908 0.0123842 0.111115 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 8, numVisits=9, meanQ=60.810406, numObservations: 4
action 7, numVisits=14, meanQ=41.857143, numObservations: 6
action 2, numVisits=3, meanQ=32.333333, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-12.793016, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-108.619835, numObservations: 1
action 5, numVisits=1, meanQ=-108.910096, numObservations: 1
Sampled 35860 episodes
GETTING ACTION FROM:
action 7, numVisits=35775, meanQ=28.116849, numObservations: 9
action 8, numVisits=105, meanQ=19.536130, numObservations: 9
action 2, numVisits=6, meanQ=-1.000000, numObservations: 4
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-12.793016, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-108.619835, numObservations: 1
action 5, numVisits=1, meanQ=-108.910096, numObservations: 1
action: 7
Next state: 1 0.0299531 0.297728 0.310426 0.461649 0.0269474 0.442769 0.469539 0.765151 0.00395368 0.644096 0.185592 0.402743 0.512629 0.992199 0.124552 0.46727 0.600506 0.21908 0.0123842 0.111115 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 53.5026
Run # 31
Initial state: 0 0.840676 0.276807 0.118846 0.617445 0.418131 0.997408 0.0892693 0.311089 0.0190392 0.0696165 0.370321 0.963987 0.0304175 0.383887 0.530677 0.206423 0.382811 0.414841 0.655338 0.283793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20015 episodes
GETTING ACTION FROM:
action 1, numVisits=19949, meanQ=23.056905, numObservations: 9
action 9, numVisits=48, meanQ=20.134531, numObservations: 9
action 4, numVisits=5, meanQ=19.000000, numObservations: 3
action 10, numVisits=4, meanQ=16.737500, numObservations: 4
action 6, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.840676 0.276807 0.118846 0.617445 0.418131 0.997408 0.0892693 0.311089 0.0190392 0.0696165 0.370321 0.963987 0.0304175 0.383887 0.530677 0.206423 0.382811 0.414841 0.655338 0.283793 w: 1
Observation: 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 32
Initial state: 0 0.824349 0.839453 0.296395 0.0358215 0.122151 0.131511 0.0511281 0.14109 0.157913 0.881244 0.353087 0.36442 0.680941 0.719686 0.638269 0.680613 0.172264 0.757186 0.524214 0.248788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18770 episodes
GETTING ACTION FROM:
action 10, numVisits=18757, meanQ=23.237652, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 10
Next state: 2 0.824349 0.839453 0.296395 0.0358215 0.122151 0.131511 0.0511281 0.14109 0.157913 0.881244 0.353087 0.36442 0.680941 0.719686 0.638269 0.680613 0.172264 0.757186 0.524214 0.248788 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 33
Initial state: 0 0.24516 0.357582 0.707142 0.696576 0.712974 0.572305 0.404765 0.84835 0.231487 0.827158 0.655724 0.26951 0.442484 0.430982 0.00978029 0.663589 0.435141 0.950673 0.546815 0.65261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20570 episodes
GETTING ACTION FROM:
action 4, numVisits=12718, meanQ=23.136098, numObservations: 9
action 2, numVisits=7821, meanQ=23.006706, numObservations: 9
action 5, numVisits=18, meanQ=19.277778, numObservations: 7
action 10, numVisits=4, meanQ=16.975000, numObservations: 4
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.24516 0.357582 0.707142 0.696576 0.712974 0.572305 0.404765 0.84835 0.231487 0.827158 0.655724 0.26951 0.442484 0.430982 0.00978029 0.663589 0.435141 0.950673 0.546815 0.65261 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 34
Initial state: 0 0.215675 0.130156 0.98528 0.306552 0.329872 0.40448 0.485212 0.275486 0.602416 0.0349142 0.215803 0.514857 0.200731 0.524813 0.311401 0.00260432 0.807731 0.517712 0.734316 0.352512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18696 episodes
GETTING ACTION FROM:
action 2, numVisits=18656, meanQ=22.826591, numObservations: 9
action 3, numVisits=9, meanQ=20.216667, numObservations: 6
action 8, numVisits=20, meanQ=18.095000, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.215675 0.130156 0.98528 0.306552 0.329872 0.40448 0.485212 0.275486 0.602416 0.0349142 0.215803 0.514857 0.200731 0.524813 0.311401 0.00260432 0.807731 0.517712 0.734316 0.352512 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 35
Initial state: 0 0.869863 0.00982365 0.700127 0.303773 0.831961 0.173091 0.626529 0.0762775 0.323196 0.783221 0.844696 0.730076 0.179137 0.0842845 0.669554 0.591094 0.431836 0.43242 0.981989 0.966078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18999 episodes
GETTING ACTION FROM:
action 3, numVisits=18943, meanQ=23.353450, numObservations: 9
action 8, numVisits=28, meanQ=9.712679, numObservations: 9
action 5, numVisits=17, meanQ=9.111765, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=3, meanQ=-4.333333, numObservations: 3
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.869863 0.00982365 0.700127 0.303773 0.831961 0.173091 0.626529 0.0762775 0.323196 0.783221 0.844696 0.730076 0.179137 0.0842845 0.669554 0.591094 0.431836 0.43242 0.981989 0.966078 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 36
Initial state: 0 0.336554 0.501967 0.530577 0.623671 0.982879 0.845856 0.113781 0.208236 0.128076 0.828819 0.344472 0.443471 0.761607 0.207862 0.199581 0.453084 0.382379 0.0930898 0.881573 0.207011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18186 episodes
GETTING ACTION FROM:
action 5, numVisits=18147, meanQ=23.740288, numObservations: 9
action 10, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=24, meanQ=-1.118750, numObservations: 8
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.336554 0.501967 0.530577 0.623671 0.982879 0.845856 0.113781 0.208236 0.128076 0.828819 0.344472 0.443471 0.761607 0.207862 0.199581 0.453084 0.382379 0.0930898 0.881573 0.207011 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 37
Initial state: 0 0.412876 0.38872 0.139656 0.353578 0.692607 0.0756545 0.89107 0.222768 0.313247 0.011489 0.0557212 0.973518 0.84772 0.519327 0.940503 0.0176258 0.97435 0.579743 0.737174 0.487795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19354 episodes
GETTING ACTION FROM:
action 7, numVisits=19336, meanQ=24.326555, numObservations: 9
action 2, numVisits=5, meanQ=19.000000, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 1 0.412876 0.38872 0.139656 0.353578 0.692607 0.0756545 0.89107 0.222768 0.313247 0.011489 0.0557212 0.973518 0.84772 0.519327 0.940503 0.0176258 0.97435 0.579743 0.737174 0.487795 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 38
Initial state: 0 0.873795 0.108545 0.127039 0.468636 0.532605 0.803115 0.0940498 0.840169 0.469645 0.342278 0.298253 0.539617 0.315281 0.417106 0.132743 0.101806 0.0584256 0.673468 0.774981 0.955274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19337 episodes
GETTING ACTION FROM:
action 7, numVisits=15793, meanQ=25.492355, numObservations: 9
action 3, numVisits=3527, meanQ=25.281620, numObservations: 9
action 5, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=4, meanQ=-6.000000, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 1 0.873795 0.108545 0.127039 0.468636 0.532605 0.803115 0.0940498 0.840169 0.469645 0.342278 0.298253 0.539617 0.315281 0.417106 0.132743 0.101806 0.0584256 0.673468 0.774981 0.955274 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 39
Initial state: 0 0.270885 0.999962 0.262452 0.251471 0.406536 0.136582 0.149194 0.392357 0.440703 0.412645 0.035366 0.276208 0.926071 0.18845 0.122392 0.387449 0.0287352 0.477479 0.634918 0.807873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19531 episodes
GETTING ACTION FROM:
action 5, numVisits=19505, meanQ=23.123862, numObservations: 9
action 6, numVisits=6, meanQ=-1.000000, numObservations: 5
action -1, numVisits=5, meanQ=-1.050000, numObservations: 5
action 0, numVisits=5, meanQ=-1.050000, numObservations: 5
action 10, numVisits=3, meanQ=-4.016667, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.270885 0.999962 0.262452 0.251471 0.406536 0.136582 0.149194 0.392357 0.440703 0.412645 0.035366 0.276208 0.926071 0.18845 0.122392 0.387449 0.0287352 0.477479 0.634918 0.807873 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 40
Initial state: 0 0.241706 0.87068 0.328453 0.559067 0.352307 0.147999 0.655084 0.738867 0.658381 0.857374 0.0962009 0.524087 0.585243 0.401063 0.310458 0.651816 0.420771 0.419505 0.702107 0.765056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 4469 episodes
GETTING ACTION FROM:
action 0, numVisits=4243, meanQ=0.734368, numObservations: 3855
action -1, numVisits=188, meanQ=-1.050000, numObservations: 188
action 8, numVisits=10, meanQ=-3.099750, numObservations: 4
action 10, numVisits=11, meanQ=-3.359091, numObservations: 5
action 2, numVisits=6, meanQ=-4.333333, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=5, meanQ=-21.000000, numObservations: 5
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.241706 0.87068 0.328453 0.559067 0.352307 0.147999 0.655084 0.738867 0.658381 0.857374 0.0962009 0.524087 0.585243 0.401063 0.310458 0.651816 0.420771 0.419505 0.702107 0.765056 w: 1
Observation: 0 0 3 0 3 0 3 0 3 0 3 0 3 0 2 0 2 0 2 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 22564 episodes
GETTING ACTION FROM:
action 5, numVisits=22535, meanQ=72.648454, numObservations: 9
action 10, numVisits=14, meanQ=54.714286, numObservations: 4
action 8, numVisits=4, meanQ=49.000000, numObservations: 2
action 2, numVisits=2, meanQ=44.000000, numObservations: 1
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.241706 0.87068 0.328453 0.559067 0.352307 0.147999 0.655084 0.738867 0.658381 0.857374 0.0962009 0.524087 0.585243 0.401063 0.310458 0.651816 0.420771 0.419505 0.702107 0.765056 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 41
Initial state: 0 0.380336 0.850039 0.566486 0.853652 0.828377 0.772926 0.340155 0.701945 0.818611 0.702754 0.402665 0.46373 0.669576 0.763221 0.555158 0.689477 0.489119 0.159536 0.630355 0.673635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18482 episodes
GETTING ACTION FROM:
action 9, numVisits=18467, meanQ=24.595876, numObservations: 9
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 6, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 9
Next state: 2 0.380336 0.850039 0.566486 0.853652 0.828377 0.772926 0.340155 0.701945 0.818611 0.702754 0.402665 0.46373 0.669576 0.763221 0.555158 0.689477 0.489119 0.159536 0.630355 0.673635 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 42
Initial state: 0 0.0868512 0.883255 0.325387 0.407881 0.465427 0.212275 0.431365 0.64208 0.495334 0.357597 0.851892 0.66947 0.382103 0.550837 0.0377493 0.671233 0.587371 0.265424 0.133901 0.183865 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18334 episodes
GETTING ACTION FROM:
action 1, numVisits=18286, meanQ=25.280103, numObservations: 9
action 3, numVisits=5, meanQ=15.000000, numObservations: 4
action 9, numVisits=24, meanQ=14.625521, numObservations: 8
action 5, numVisits=6, meanQ=14.000000, numObservations: 5
action 2, numVisits=6, meanQ=10.825000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.0868512 0.883255 0.325387 0.407881 0.465427 0.212275 0.431365 0.64208 0.495334 0.357597 0.851892 0.66947 0.382103 0.550837 0.0377493 0.671233 0.587371 0.265424 0.133901 0.183865 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 43
Initial state: 0 0.752588 0.718246 0.269615 0.0668104 0.812749 0.134029 0.384745 0.42582 0.609027 0.0899787 0.602046 0.517834 0.155049 0.64473 0.888841 0.271242 0.483467 0.913637 0.947385 0.644374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19540 episodes
GETTING ACTION FROM:
action 6, numVisits=19518, meanQ=24.300222, numObservations: 9
action 2, numVisits=4, meanQ=16.975000, numObservations: 4
action 4, numVisits=7, meanQ=13.285714, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 2 0.752588 0.718246 0.269615 0.0668104 0.812749 0.134029 0.384745 0.42582 0.609027 0.0899787 0.602046 0.517834 0.155049 0.64473 0.888841 0.271242 0.483467 0.913637 0.947385 0.644374 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 44
Initial state: 0 0.530593 0.634443 0.171 0.263416 0.415396 0.418942 0.0888563 0.816029 0.0440337 0.788078 0.675637 0.140719 0.261703 0.687618 0.835204 0.531109 0.965574 0.458806 0.919434 0.612376 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20028 episodes
GETTING ACTION FROM:
action 6, numVisits=19999, meanQ=22.476810, numObservations: 9
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 1, numVisits=13, meanQ=-2.996154, numObservations: 7
action 10, numVisits=5, meanQ=-7.199500, numObservations: 4
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 2 0.530593 0.634443 0.171 0.263416 0.415396 0.418942 0.0888563 0.816029 0.0440337 0.788078 0.675637 0.140719 0.261703 0.687618 0.835204 0.531109 0.965574 0.458806 0.919434 0.612376 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 45
Initial state: 0 0.625511 0.282176 0.476609 0.66613 0.127145 0.619868 0.366491 0.458659 0.183799 0.449235 0.0532092 0.0393251 0.28949 0.00167936 0.432244 0.790617 0.00102258 0.247402 0.178299 0.490646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19183 episodes
GETTING ACTION FROM:
action 4, numVisits=19159, meanQ=22.275772, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 6, numVisits=12, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.625511 0.282176 0.476609 0.66613 0.127145 0.619868 0.366491 0.458659 0.183799 0.449235 0.0532092 0.0393251 0.28949 0.00167936 0.432244 0.790617 0.00102258 0.247402 0.178299 0.490646 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 46
Initial state: 0 0.713262 0.123294 0.455799 0.712091 0.564561 0.784115 0.43143 0.3602 0.198662 0.9135 0.670691 0.253749 0.928169 0.180854 0.598827 0.241572 0.123393 0.916398 0.381205 0.489905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18782 episodes
GETTING ACTION FROM:
action 3, numVisits=18710, meanQ=18.814188, numObservations: 9
action 5, numVisits=14, meanQ=16.075000, numObservations: 6
action 4, numVisits=49, meanQ=15.835765, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.713262 0.123294 0.455799 0.712091 0.564561 0.784115 0.43143 0.3602 0.198662 0.9135 0.670691 0.253749 0.928169 0.180854 0.598827 0.241572 0.123393 0.916398 0.381205 0.489905 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 47
Initial state: 0 0.173619 0.591397 0.337222 0.268087 0.976962 0.534564 0.0210135 0.566931 0.417337 0.788344 0.429624 0.35768 0.0845009 0.514282 0.533156 0.897535 0.556061 0.178842 0.520944 0.549439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19518 episodes
GETTING ACTION FROM:
action 4, numVisits=19483, meanQ=24.791759, numObservations: 9
action 1, numVisits=10, meanQ=19.000000, numObservations: 6
action 8, numVisits=9, meanQ=18.338889, numObservations: 6
action 9, numVisits=5, meanQ=15.000000, numObservations: 4
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.173619 0.591397 0.337222 0.268087 0.976962 0.534564 0.0210135 0.566931 0.417337 0.788344 0.429624 0.35768 0.0845009 0.514282 0.533156 0.897535 0.556061 0.178842 0.520944 0.549439 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1435, meanQ=44.684572, numObservations: 9
action 1, numVisits=59, meanQ=27.663644, numObservations: 9
action 2, numVisits=82, meanQ=27.362226, numObservations: 9
action 8, numVisits=7, meanQ=26.278571, numObservations: 5
action 5, numVisits=4, meanQ=21.737500, numObservations: 4
action 7, numVisits=4, meanQ=21.737500, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 9, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 7359 episodes
GETTING ACTION FROM:
action 4, numVisits=1439, meanQ=44.776574, numObservations: 9
action 1, numVisits=7380, meanQ=38.333633, numObservations: 9
action 2, numVisits=95, meanQ=25.314294, numObservations: 9
action 8, numVisits=12, meanQ=21.916667, numObservations: 6
action 5, numVisits=14, meanQ=19.782143, numObservations: 7
action 7, numVisits=10, meanQ=16.989327, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 9, numVisits=3, meanQ=-4.016667, numObservations: 3
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.173619 0.591397 0.337222 0.268087 0.976962 0.534564 0.0210135 0.566931 0.417337 0.788344 0.429624 0.35768 0.0845009 0.514282 0.533156 0.897535 0.556061 0.178842 0.520944 0.549439 w: 1
Observation: 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=27, meanQ=34.440741, numObservations: 9
action 5, numVisits=10, meanQ=25.690000, numObservations: 5
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 7, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 8719 episodes
GETTING ACTION FROM:
action 5, numVisits=8686, meanQ=36.871490, numObservations: 9
action 2, numVisits=70, meanQ=23.713607, numObservations: 9
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 7, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.173619 0.591397 0.337222 0.268087 0.976962 0.534564 0.0210135 0.566931 0.417337 0.788344 0.429624 0.35768 0.0845009 0.514282 0.533156 0.897535 0.556061 0.178842 0.520944 0.549439 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -112.603
Run # 48
Initial state: 0 0.523207 0.272106 0.183858 0.0836956 0.225066 0.716496 0.174373 0.816885 0.162242 0.900751 0.439355 0.451747 0.613369 0.873541 0.477252 0.379708 0.242641 0.488104 0.855583 0.0100931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19656 episodes
GETTING ACTION FROM:
action 8, numVisits=10129, meanQ=22.774101, numObservations: 9
action 2, numVisits=9503, meanQ=22.497203, numObservations: 9
action 4, numVisits=12, meanQ=13.996042, numObservations: 6
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 1 0.523207 0.272106 0.183858 0.0836956 0.225066 0.716496 0.174373 0.816885 0.162242 0.900751 0.439355 0.451747 0.613369 0.873541 0.477252 0.379708 0.242641 0.488104 0.855583 0.0100931 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 49
Initial state: 0 0.331067 0.899964 0.870665 0.269883 0.477269 0.195162 0.95725 0.988364 0.832242 0.435536 0.678421 0.109123 0.33672 0.583207 0.449059 0.431039 0.0840064 0.62098 0.461401 0.643512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20430 episodes
GETTING ACTION FROM:
action 2, numVisits=20403, meanQ=22.944618, numObservations: 9
action 9, numVisits=9, meanQ=20.111111, numObservations: 5
action 4, numVisits=5, meanQ=15.190000, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.331067 0.899964 0.870665 0.269883 0.477269 0.195162 0.95725 0.988364 0.832242 0.435536 0.678421 0.109123 0.33672 0.583207 0.449059 0.431039 0.0840064 0.62098 0.461401 0.643512 w: 1
Observation: 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 50
Initial state: 0 0.524381 0.73853 0.680647 0.80439 0.349465 0.041038 0.0416105 0.940665 0.119601 0.448477 0.337071 0.109876 0.352222 0.421344 0.549622 0.661259 0.173853 0.112565 0.0870013 0.691522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20251 episodes
GETTING ACTION FROM:
action 8, numVisits=20202, meanQ=23.511009, numObservations: 9
action 7, numVisits=27, meanQ=15.966667, numObservations: 8
action 9, numVisits=13, meanQ=13.615385, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 1 0.524381 0.73853 0.680647 0.80439 0.349465 0.041038 0.0416105 0.940665 0.119601 0.448477 0.337071 0.109876 0.352222 0.421344 0.549622 0.661259 0.173853 0.112565 0.0870013 0.691522 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
[32m ProblemEnvironment.hpp 351: Done.[39m
