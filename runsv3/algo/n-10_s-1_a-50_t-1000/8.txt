Run # 1
Initial state: 0 0.800287 0.782239 0.98296 0.227424 0.272881 0.895473 0.896548 0.299239 0.278407 0.361944 0.358768 0.52061 0.209908 0.954677 0.992626 0.605733 0.781362 0.0799205 0.478066 0.292805 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20093 episodes
GETTING ACTION FROM:
action 3, numVisits=20021, meanQ=22.132733, numObservations: 9
action 6, numVisits=42, meanQ=11.448810, numObservations: 9
action 8, numVisits=18, meanQ=11.327778, numObservations: 9
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.800287 0.782239 0.98296 0.227424 0.272881 0.895473 0.896548 0.299239 0.278407 0.361944 0.358768 0.52061 0.209908 0.954677 0.992626 0.605733 0.781362 0.0799205 0.478066 0.292805 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 2
Initial state: 0 0.724846 0.302742 0.345977 0.440443 0.163553 0.141179 0.932099 0.0312944 0.53505 0.300852 0.155402 0.436885 0.431734 0.0284978 0.852267 0.361823 0.960785 0.887584 0.449336 0.661488 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 4390 episodes
GETTING ACTION FROM:
action 0, numVisits=4191, meanQ=0.193104, numObservations: 3892
action -1, numVisits=158, meanQ=-1.663291, numObservations: 157
action 1, numVisits=12, meanQ=-10.662500, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=8, meanQ=-14.750000, numObservations: 4
action 3, numVisits=6, meanQ=-19.333333, numObservations: 3
action 7, numVisits=5, meanQ=-21.000000, numObservations: 4
action 5, numVisits=3, meanQ=-34.333333, numObservations: 2
action 8, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.724846 0.302742 0.345977 0.440443 0.163553 0.141179 0.932099 0.0312944 0.53505 0.300852 0.155402 0.436885 0.431734 0.0284978 0.852267 0.361823 0.960785 0.887584 0.449336 0.661488 w: 1
Observation: 0 0 1 0 2 0 1 0 1 0 1 0 2 0 1 0 2 0 3 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19448 episodes
GETTING ACTION FROM:
action 9, numVisits=19402, meanQ=59.958263, numObservations: 9
action 8, numVisits=27, meanQ=22.631574, numObservations: 9
action 1, numVisits=5, meanQ=19.000000, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 4
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 9
Next state: 1 0.724846 0.302742 0.345977 0.440443 0.163553 0.141179 0.932099 0.0312944 0.53505 0.300852 0.155402 0.436885 0.431734 0.0284978 0.852267 0.361823 0.960785 0.887584 0.449336 0.661488 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 92.05
Run # 3
Initial state: 0 0.160136 0.436494 0.0530262 0.867733 0.299238 0.412235 0.0988748 0.449739 0.255014 0.660334 0.155442 0.0503417 0.701363 0.747628 0.555333 0.912771 0.835206 0.282611 0.0680327 0.436774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20650 episodes
GETTING ACTION FROM:
action 1, numVisits=20605, meanQ=20.764856, numObservations: 9
action 7, numVisits=28, meanQ=8.642857, numObservations: 8
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 9, numVisits=7, meanQ=-2.428571, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.160136 0.436494 0.0530262 0.867733 0.299238 0.412235 0.0988748 0.449739 0.255014 0.660334 0.155442 0.0503417 0.701363 0.747628 0.555333 0.912771 0.835206 0.282611 0.0680327 0.436774 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 4
Initial state: 0 0.281305 0.45113 0.945043 0.851858 0.197034 0.531783 0.484888 0.580325 0.734647 0.784352 0.847523 0.23217 0.387739 0.0419068 0.409891 0.649591 0.142676 0.342526 0.701627 0.691585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 4192 episodes
GETTING ACTION FROM:
action 0, numVisits=4069, meanQ=-0.331500, numObservations: 3817
action -1, numVisits=80, meanQ=-2.261250, numObservations: 79
action 4, numVisits=15, meanQ=-3.000000, numObservations: 6
action 7, numVisits=10, meanQ=-5.099750, numObservations: 8
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=8, meanQ=-14.631250, numObservations: 5
action 6, numVisits=4, meanQ=-28.500000, numObservations: 3
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 0
Next state: 0 0.281305 0.45113 0.945043 0.851858 0.197034 0.531783 0.484888 0.580325 0.734647 0.784352 0.847523 0.23217 0.387739 0.0419068 0.409891 0.649591 0.142676 0.342526 0.701627 0.691585 w: 1
Observation: 0 0 2 0 3 0 3 0 3 0 3 0 1 0 1 0 3 0 1 0 3 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 21209 episodes
GETTING ACTION FROM:
action 3, numVisits=21193, meanQ=62.621739, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.281305 0.45113 0.945043 0.851858 0.197034 0.531783 0.484888 0.580325 0.734647 0.784352 0.847523 0.23217 0.387739 0.0419068 0.409891 0.649591 0.142676 0.342526 0.701627 0.691585 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=97, meanQ=66.875851, numObservations: 9
action 1, numVisits=7, meanQ=54.850000, numObservations: 4
action 4, numVisits=8, meanQ=49.000000, numObservations: 4
action 6, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 10, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18634 episodes
GETTING ACTION FROM:
action 2, numVisits=18714, meanQ=48.552093, numObservations: 9
action 1, numVisits=23, meanQ=42.084783, numObservations: 7
action 4, numVisits=9, meanQ=32.333333, numObservations: 5
action 6, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 10, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.281305 0.45113 0.945043 0.851858 0.197034 0.531783 0.484888 0.580325 0.734647 0.784352 0.847523 0.23217 0.387739 0.0419068 0.409891 0.649591 0.142676 0.342526 0.701627 0.691585 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 76.8975
Run # 5
Initial state: 0 0.360326 0.452664 0.72234 0.0315603 0.187405 0.887391 0.119203 0.930312 0.569724 0.785834 0.302552 0.687324 0.104093 0.778389 0.459878 0.801571 0.306367 0.634242 0.096052 0.528666 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20368 episodes
GETTING ACTION FROM:
action 2, numVisits=20336, meanQ=21.169124, numObservations: 9
action 9, numVisits=17, meanQ=14.532353, numObservations: 7
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 8, numVisits=3, meanQ=-4.333333, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.360326 0.452664 0.72234 0.0315603 0.187405 0.887391 0.119203 0.930312 0.569724 0.785834 0.302552 0.687324 0.104093 0.778389 0.459878 0.801571 0.306367 0.634242 0.096052 0.528666 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 6
Initial state: 0 0.315459 0.368533 0.648791 0.107782 0.894881 0.885805 0.551457 0.0796389 0.629878 0.227232 0.326757 0.949415 0.529964 0.233844 0.91179 0.129315 0.0943721 0.0371746 0.316252 0.812237 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19357 episodes
GETTING ACTION FROM:
action 1, numVisits=19339, meanQ=21.771644, numObservations: 9
action 8, numVisits=6, meanQ=10.666667, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 1 0.315459 0.368533 0.648791 0.107782 0.894881 0.885805 0.551457 0.0796389 0.629878 0.227232 0.326757 0.949415 0.529964 0.233844 0.91179 0.129315 0.0943721 0.0371746 0.316252 0.812237 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 7
Initial state: 0 0.314444 0.511079 0.216768 0.873921 0.779281 0.951111 0.018151 0.841774 0.0107845 0.139862 0.241686 0.158296 0.849442 0.772486 0.167897 0.0383567 0.696753 0.420692 0.206132 0.355731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20016 episodes
GETTING ACTION FROM:
action 6, numVisits=19993, meanQ=21.294892, numObservations: 9
action 4, numVisits=8, meanQ=10.250000, numObservations: 6
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 7, numVisits=5, meanQ=-3.000000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 0 0.314444 0.511079 0.216768 0.873921 0.779281 0.951111 0.018151 0.841774 0.0107845 0.139862 0.241686 0.158296 0.849442 0.772486 0.167897 0.0383567 0.696753 0.420692 0.206132 0.355731 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 9, numVisits=1172, meanQ=31.447366, numObservations: 9
action 2, numVisits=36, meanQ=29.551597, numObservations: 9
action 5, numVisits=23, meanQ=23.906522, numObservations: 7
action 7, numVisits=4, meanQ=21.737500, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 6, numVisits=1, meanQ=-10.050000, numObservations: 1
action 10, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5739 episodes
GETTING ACTION FROM:
action 9, numVisits=6757, meanQ=17.895810, numObservations: 9
action 5, numVisits=145, meanQ=16.551906, numObservations: 9
action 2, numVisits=67, meanQ=14.747102, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 7, numVisits=5, meanQ=-2.810000, numObservations: 3
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 6, numVisits=1, meanQ=-10.050000, numObservations: 1
action 10, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 9
Next state: 2 0.314444 0.511079 0.216768 0.873921 0.779281 0.951111 0.018151 0.841774 0.0107845 0.139862 0.241686 0.158296 0.849442 0.772486 0.167897 0.0383567 0.696753 0.420692 0.206132 0.355731 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 8
Initial state: 0 0.419096 0.904864 0.908782 0.290183 0.648855 0.182154 0.358232 0.365411 0.0969073 0.982584 0.00372571 0.267608 0.344308 0.181403 0.859568 0.607448 0.684275 0.413984 0.633258 0.510435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18963 episodes
GETTING ACTION FROM:
action 1, numVisits=18845, meanQ=20.218296, numObservations: 9
action 6, numVisits=94, meanQ=15.900133, numObservations: 9
action 10, numVisits=13, meanQ=10.611538, numObservations: 7
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 2 0.419096 0.904864 0.908782 0.290183 0.648855 0.182154 0.358232 0.365411 0.0969073 0.982584 0.00372571 0.267608 0.344308 0.181403 0.859568 0.607448 0.684275 0.413984 0.633258 0.510435 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 9
Initial state: 0 0.740721 0.498448 0.938395 0.517425 0.0462216 0.374114 0.786732 0.351661 0.302403 0.425023 0.644775 0.456725 0.566464 0.579173 0.843471 0.37072 0.901603 0.617505 0.511301 0.499819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19681 episodes
GETTING ACTION FROM:
action 2, numVisits=19620, meanQ=21.199983, numObservations: 9
action 8, numVisits=38, meanQ=19.431645, numObservations: 9
action 3, numVisits=14, meanQ=17.671607, numObservations: 8
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.740721 0.498448 0.938395 0.517425 0.0462216 0.374114 0.786732 0.351661 0.302403 0.425023 0.644775 0.456725 0.566464 0.579173 0.843471 0.37072 0.901603 0.617505 0.511301 0.499819 w: 1
Observation: 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 10
Initial state: 0 0.0926239 0.747646 0.817515 0.734169 0.717452 0.978187 0.458297 0.660694 0.545263 0.893699 0.760904 0.412061 0.580739 0.0359511 0.326135 0.456719 0.70903 0.260517 0.746084 0.414046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19730 episodes
GETTING ACTION FROM:
action 2, numVisits=19684, meanQ=22.386761, numObservations: 9
action 5, numVisits=7, meanQ=13.285714, numObservations: 4
action 1, numVisits=15, meanQ=10.523333, numObservations: 7
action 7, numVisits=15, meanQ=9.396667, numObservations: 7
action 9, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0926239 0.747646 0.817515 0.734169 0.717452 0.978187 0.458297 0.660694 0.545263 0.893699 0.760904 0.412061 0.580739 0.0359511 0.326135 0.456719 0.70903 0.260517 0.746084 0.414046 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 11
Initial state: 0 0.956535 0.679917 0.577951 0.491562 0.0729369 0.779449 0.977766 0.194775 0.174328 0.617026 0.29826 0.425531 0.963228 0.525928 0.457366 0.281105 0.38786 0.0913294 0.425712 0.676993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20707 episodes
GETTING ACTION FROM:
action 7, numVisits=20687, meanQ=20.248424, numObservations: 9
action 6, numVisits=10, meanQ=17.190000, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 2 0.956535 0.679917 0.577951 0.491562 0.0729369 0.779449 0.977766 0.194775 0.174328 0.617026 0.29826 0.425531 0.963228 0.525928 0.457366 0.281105 0.38786 0.0913294 0.425712 0.676993 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 12
Initial state: 0 0.467273 0.514985 0.269124 0.431505 0.917051 0.919178 0.806656 0.791291 0.353357 0.117082 0.140086 0.280426 0.00533547 0.957431 0.947806 0.0390897 0.124552 0.630433 0.89329 0.192304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19091 episodes
GETTING ACTION FROM:
action 6, numVisits=19057, meanQ=21.788725, numObservations: 9
action 4, numVisits=10, meanQ=7.405000, numObservations: 5
action 1, numVisits=11, meanQ=6.445455, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 9, numVisits=3, meanQ=-4.333333, numObservations: 2
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 0 0.467273 0.514985 0.269124 0.431505 0.917051 0.919178 0.806656 0.791291 0.353357 0.117082 0.140086 0.280426 0.00533547 0.957431 0.947806 0.0390897 0.124552 0.630433 0.89329 0.192304 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=1139, meanQ=29.297961, numObservations: 9
action 7, numVisits=12, meanQ=11.775208, numObservations: 7
action 1, numVisits=9, meanQ=10.111111, numObservations: 7
action 4, numVisits=15, meanQ=9.186833, numObservations: 6
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 6, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 6679 episodes
GETTING ACTION FROM:
action 5, numVisits=7818, meanQ=17.095983, numObservations: 9
action 7, numVisits=12, meanQ=11.775208, numObservations: 7
action 1, numVisits=9, meanQ=10.111111, numObservations: 7
action 4, numVisits=15, meanQ=9.186833, numObservations: 6
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 6, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.467273 0.514985 0.269124 0.431505 0.917051 0.919178 0.806656 0.791291 0.353357 0.117082 0.140086 0.280426 0.00533547 0.957431 0.947806 0.0390897 0.124552 0.630433 0.89329 0.192304 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 13
Initial state: 0 0.0824643 0.162565 0.0452672 0.548905 0.0252949 0.639424 0.595722 0.564935 0.795161 0.254146 0.28187 0.483699 0.530825 0.815238 0.662048 0.514327 0.24631 0.384829 0.823438 0.252172 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19455 episodes
GETTING ACTION FROM:
action 2, numVisits=19364, meanQ=21.362056, numObservations: 9
action 10, numVisits=62, meanQ=16.063831, numObservations: 9
action 3, numVisits=16, meanQ=10.250000, numObservations: 5
action 4, numVisits=4, meanQ=-1.000000, numObservations: 2
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 1 0.0824643 0.162565 0.0452672 0.548905 0.0252949 0.639424 0.595722 0.564935 0.795161 0.254146 0.28187 0.483699 0.530825 0.815238 0.662048 0.514327 0.24631 0.384829 0.823438 0.252172 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 14
Initial state: 0 0.336878 0.502825 0.250599 0.365486 0.236542 0.455421 0.332549 0.244876 0.357552 0.224575 0.665039 0.463462 0.901654 0.310956 0.451245 0.479762 0.287686 0.965581 0.506515 0.40764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20202 episodes
GETTING ACTION FROM:
action 2, numVisits=20186, meanQ=19.084810, numObservations: 9
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.336878 0.502825 0.250599 0.365486 0.236542 0.455421 0.332549 0.244876 0.357552 0.224575 0.665039 0.463462 0.901654 0.310956 0.451245 0.479762 0.287686 0.965581 0.506515 0.40764 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 10, numVisits=1337, meanQ=28.222311, numObservations: 9
action 8, numVisits=14, meanQ=4.203571, numObservations: 7
action 6, numVisits=2, meanQ=-1.000000, numObservations: 2
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=4, meanQ=-7.012500, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 5424 episodes
GETTING ACTION FROM:
action 10, numVisits=6761, meanQ=27.685573, numObservations: 9
action 8, numVisits=14, meanQ=4.203571, numObservations: 7
action 6, numVisits=2, meanQ=-1.000000, numObservations: 2
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=4, meanQ=-7.012500, numObservations: 2
action 3, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 10
Next state: 2 0.336878 0.502825 0.250599 0.365486 0.236542 0.455421 0.332549 0.244876 0.357552 0.224575 0.665039 0.463462 0.901654 0.310956 0.451245 0.479762 0.287686 0.965581 0.506515 0.40764 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 15
Initial state: 0 0.510272 0.40106 0.426729 0.27424 0.630776 0.841249 0.453702 0.173203 0.292316 0.482167 0.557063 0.881903 0.966397 0.171803 0.10714 0.867302 0.81674 0.146616 0.915008 0.888465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19338 episodes
GETTING ACTION FROM:
action 9, numVisits=19287, meanQ=20.234522, numObservations: 9
action 7, numVisits=28, meanQ=13.978839, numObservations: 8
action 5, numVisits=14, meanQ=12.564821, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 9
Next state: 2 0.510272 0.40106 0.426729 0.27424 0.630776 0.841249 0.453702 0.173203 0.292316 0.482167 0.557063 0.881903 0.966397 0.171803 0.10714 0.867302 0.81674 0.146616 0.915008 0.888465 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 16
Initial state: 0 0.879361 0.621583 0.861604 0.771164 0.677023 0.943141 0.557051 0.300625 0.132331 0.771286 0.00913617 0.0181399 0.640158 0.656185 0.286147 0.507747 0.234791 0.822391 0.432491 0.635182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20246 episodes
GETTING ACTION FROM:
action 9, numVisits=20166, meanQ=20.306002, numObservations: 9
action 8, numVisits=19, meanQ=18.623684, numObservations: 9
action 4, numVisits=46, meanQ=18.544565, numObservations: 9
action 6, numVisits=5, meanQ=12.000000, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 9
Next state: 0 0.879361 0.621583 0.861604 0.771164 0.677023 0.943141 0.557051 0.300625 0.132331 0.771286 0.00913617 0.0181399 0.640158 0.656185 0.286147 0.507747 0.234791 0.822391 0.432491 0.635182 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=1246, meanQ=22.301255, numObservations: 9
action 5, numVisits=46, meanQ=-0.494402, numObservations: 9
action -1, numVisits=6, meanQ=-1.050000, numObservations: 6
action 0, numVisits=6, meanQ=-1.050000, numObservations: 6
action 1, numVisits=34, meanQ=-1.226324, numObservations: 7
action 6, numVisits=31, meanQ=-2.214435, numObservations: 8
action 8, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 10, numVisits=5, meanQ=-21.000000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 9504 episodes
GETTING ACTION FROM:
action 4, numVisits=10750, meanQ=25.163103, numObservations: 9
action 5, numVisits=46, meanQ=-0.494402, numObservations: 9
action -1, numVisits=6, meanQ=-1.050000, numObservations: 6
action 0, numVisits=6, meanQ=-1.050000, numObservations: 6
action 1, numVisits=34, meanQ=-1.226324, numObservations: 7
action 6, numVisits=31, meanQ=-2.214435, numObservations: 8
action 8, numVisits=3, meanQ=-4.016667, numObservations: 3
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 10, numVisits=5, meanQ=-21.000000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.879361 0.621583 0.861604 0.771164 0.677023 0.943141 0.557051 0.300625 0.132331 0.771286 0.00913617 0.0181399 0.640158 0.656185 0.286147 0.507747 0.234791 0.822391 0.432491 0.635182 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 17
Initial state: 0 0.0294108 0.25499 0.0214903 0.995786 0.0925363 0.198123 0.118857 0.678139 0.88631 0.913798 0.728946 0.409881 0.270584 0.452139 0.144981 0.490274 0.928342 0.606255 0.0502001 0.189963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20320 episodes
GETTING ACTION FROM:
action 8, numVisits=16677, meanQ=20.496404, numObservations: 9
action 10, numVisits=3488, meanQ=20.325559, numObservations: 9
action 1, numVisits=60, meanQ=19.006792, numObservations: 9
action 9, numVisits=34, meanQ=18.200074, numObservations: 8
action 7, numVisits=49, meanQ=17.667449, numObservations: 9
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=5, meanQ=-2.810000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 0 0.0294108 0.25499 0.0214903 0.995786 0.0925363 0.198123 0.118857 0.678139 0.88631 0.913798 0.728946 0.409881 0.270584 0.452139 0.144981 0.490274 0.928342 0.606255 0.0502001 0.189963 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1099, meanQ=30.159727, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 8573 episodes
GETTING ACTION FROM:
action 2, numVisits=9672, meanQ=35.759828, numObservations: 9
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.0294108 0.25499 0.0214903 0.995786 0.0925363 0.198123 0.118857 0.678139 0.88631 0.913798 0.728946 0.409881 0.270584 0.452139 0.144981 0.490274 0.928342 0.606255 0.0502001 0.189963 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=294, meanQ=67.681515, numObservations: 8
action 10, numVisits=4, meanQ=44.475000, numObservations: 4
action 7, numVisits=5, meanQ=37.190000, numObservations: 4
action 3, numVisits=3, meanQ=32.333333, numObservations: 3
action 8, numVisits=3, meanQ=26.300000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 14501 episodes
GETTING ACTION FROM:
action 2, numVisits=303, meanQ=68.400802, numObservations: 8
action 7, numVisits=14493, meanQ=28.584629, numObservations: 9
action 8, numVisits=3, meanQ=26.300000, numObservations: 2
action 10, numVisits=5, meanQ=15.380000, numObservations: 4
action 3, numVisits=6, meanQ=13.860143, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 0 0.0294108 0.25499 0.0214903 0.995786 0.0925363 0.198123 0.118857 0.678139 0.88631 0.913798 0.728946 0.409881 0.270584 0.452139 0.144981 0.490274 0.928342 0.606255 0.0502001 0.189963 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=90, meanQ=48.502634, numObservations: 8
action 4, numVisits=21, meanQ=34.845627, numObservations: 7
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action 6, numVisits=3, meanQ=32.333333, numObservations: 2
action 9, numVisits=3, meanQ=32.333333, numObservations: 3
action 7, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-6.000000, numObservations: 2
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 15304 episodes
GETTING ACTION FROM:
action 3, numVisits=15394, meanQ=50.461239, numObservations: 9
action 4, numVisits=21, meanQ=34.845627, numObservations: 7
action 5, numVisits=3, meanQ=32.333333, numObservations: 3
action 6, numVisits=3, meanQ=32.333333, numObservations: 2
action 9, numVisits=3, meanQ=32.333333, numObservations: 3
action 7, numVisits=5, meanQ=19.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-6.000000, numObservations: 2
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 0 0.0294108 0.25499 0.0214903 0.995786 0.0925363 0.198123 0.118857 0.678139 0.88631 0.913798 0.728946 0.409881 0.270584 0.452139 0.144981 0.490274 0.928342 0.606255 0.0502001 0.189963 w: 1
Observation: 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 6, numVisits=20, meanQ=53.440595, numObservations: 5
action 7, numVisits=5, meanQ=36.820838, numObservations: 2
action 5, numVisits=3, meanQ=32.333333, numObservations: 1
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-111.171041, numObservations: 1
action 8, numVisits=1, meanQ=-111.176250, numObservations: 1
Sampled 26000 episodes
GETTING ACTION FROM:
action 6, numVisits=26013, meanQ=27.224031, numObservations: 9
action 7, numVisits=11, meanQ=16.191290, numObservations: 3
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-111.171041, numObservations: 1
action 8, numVisits=1, meanQ=-111.176250, numObservations: 1
action: 6
Next state: 1 0.0294108 0.25499 0.0214903 0.995786 0.0925363 0.198123 0.118857 0.678139 0.88631 0.913798 0.728946 0.409881 0.270584 0.452139 0.144981 0.490274 0.928342 0.606255 0.0502001 0.189963 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 39.8275
Run # 18
Initial state: 0 0.177663 0.522786 0.59051 0.752117 0.305318 0.778617 0.836021 0.234622 0.364461 0.923666 0.689586 0.217212 0.371325 0.386331 0.573066 0.195761 0.793105 0.22236 0.917008 0.499319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 4554 episodes
GETTING ACTION FROM:
action -1, numVisits=4190, meanQ=4.352462, numObservations: 3468
action 0, numVisits=313, meanQ=-1.393123, numObservations: 311
action 6, numVisits=29, meanQ=-3.446552, numObservations: 8
action 8, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=8, meanQ=-14.631250, numObservations: 4
action 1, numVisits=3, meanQ=-34.333333, numObservations: 2
action 10, numVisits=3, meanQ=-34.333333, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.177663 0.522786 0.59051 0.752117 0.305318 0.778617 0.836021 0.234622 0.364461 0.923666 0.689586 0.217212 0.371325 0.386331 0.573066 0.195761 0.793105 0.22236 0.917008 0.499319 w: 1
Observation: 0 1 0 3 0 3 0 3 0 2 0 3 0 1 0 3 0 3 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 21652 episodes
GETTING ACTION FROM:
action 5, numVisits=21628, meanQ=59.077241, numObservations: 9
action 3, numVisits=6, meanQ=32.333333, numObservations: 2
action 6, numVisits=3, meanQ=32.333333, numObservations: 2
action 10, numVisits=6, meanQ=32.333333, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.177663 0.522786 0.59051 0.752117 0.305318 0.778617 0.836021 0.234622 0.364461 0.923666 0.689586 0.217212 0.371325 0.386331 0.573066 0.195761 0.793105 0.22236 0.917008 0.499319 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -97.95
Run # 19
Initial state: 0 0.421388 0.150576 0.184578 0.249598 0.0846612 0.904889 0.411898 0.155408 0.648977 0.375785 0.587964 0.966515 0.283445 0.490272 0.86515 0.0836485 0.651645 0.421051 0.576839 0.935315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19257 episodes
GETTING ACTION FROM:
action 9, numVisits=12477, meanQ=23.511313, numObservations: 9
action 1, numVisits=6740, meanQ=23.307205, numObservations: 9
action 3, numVisits=20, meanQ=21.845000, numObservations: 7
action 2, numVisits=9, meanQ=20.111111, numObservations: 7
action 10, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 9
Next state: 1 0.421388 0.150576 0.184578 0.249598 0.0846612 0.904889 0.411898 0.155408 0.648977 0.375785 0.587964 0.966515 0.283445 0.490272 0.86515 0.0836485 0.651645 0.421051 0.576839 0.935315 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 20
Initial state: 0 0.387271 0.474295 0.830561 0.279942 0.0686546 0.362049 0.296637 0.343689 0.366014 0.485174 0.46186 0.911661 0.0202014 0.366581 0.693239 0.416102 0.156114 0.317558 0.373138 0.771661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19737 episodes
GETTING ACTION FROM:
action 3, numVisits=19714, meanQ=19.544594, numObservations: 9
action 5, numVisits=6, meanQ=14.158333, numObservations: 4
action 9, numVisits=7, meanQ=10.564286, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.387271 0.474295 0.830561 0.279942 0.0686546 0.362049 0.296637 0.343689 0.366014 0.485174 0.46186 0.911661 0.0202014 0.366581 0.693239 0.416102 0.156114 0.317558 0.373138 0.771661 w: 1
Observation: 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 21
Initial state: 0 0.541385 0.511673 0.436508 0.503957 0.93772 0.00958943 0.148973 0.265312 0.075351 0.743035 0.623336 0.00667981 0.895676 0.156713 0.351359 0.409491 0.82922 0.624546 0.388796 0.798751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18899 episodes
GETTING ACTION FROM:
action 6, numVisits=18862, meanQ=19.787390, numObservations: 9
action 7, numVisits=15, meanQ=13.696833, numObservations: 7
action 1, numVisits=7, meanQ=10.564286, numObservations: 4
action 10, numVisits=7, meanQ=10.564286, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 2 0.541385 0.511673 0.436508 0.503957 0.93772 0.00958943 0.148973 0.265312 0.075351 0.743035 0.623336 0.00667981 0.895676 0.156713 0.351359 0.409491 0.82922 0.624546 0.388796 0.798751 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 22
Initial state: 0 0.0898888 0.948293 0.357498 0.648801 0.448943 0.502967 0.741738 0.532007 0.662987 0.742489 0.297924 0.431006 0.550504 0.371704 0.247074 0.591431 0.918955 0.170694 0.58491 0.463246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 21066 episodes
GETTING ACTION FROM:
action 8, numVisits=16030, meanQ=22.075540, numObservations: 9
action 5, numVisits=5009, meanQ=21.385792, numObservations: 9
action 3, numVisits=12, meanQ=14.000000, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 6, numVisits=5, meanQ=-3.000000, numObservations: 4
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 0 0.0898888 0.948293 0.357498 0.648801 0.448943 0.502967 0.741738 0.532007 0.662987 0.742489 0.297924 0.431006 0.550504 0.371704 0.247074 0.591431 0.918955 0.170694 0.58491 0.463246 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 10, numVisits=1028, meanQ=28.452900, numObservations: 9
action 7, numVisits=9, meanQ=20.216667, numObservations: 7
action 5, numVisits=13, meanQ=12.296154, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 7627 episodes
GETTING ACTION FROM:
action 10, numVisits=8655, meanQ=27.583754, numObservations: 9
action 7, numVisits=9, meanQ=20.216667, numObservations: 7
action 5, numVisits=13, meanQ=12.296154, numObservations: 7
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 10
Next state: 2 0.0898888 0.948293 0.357498 0.648801 0.448943 0.502967 0.741738 0.532007 0.662987 0.742489 0.297924 0.431006 0.550504 0.371704 0.247074 0.591431 0.918955 0.170694 0.58491 0.463246 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 23
Initial state: 0 0.0415946 0.454479 0.194786 0.227202 0.303094 0.450287 0.53353 0.65367 0.149605 0.21393 0.698801 0.376803 0.689279 0.134895 0.979449 0.460511 0.12272 0.369275 0.38461 0.606022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19491 episodes
GETTING ACTION FROM:
action 1, numVisits=19469, meanQ=18.733666, numObservations: 9
action 5, numVisits=11, meanQ=14.454545, numObservations: 6
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.0415946 0.454479 0.194786 0.227202 0.303094 0.450287 0.53353 0.65367 0.149605 0.21393 0.698801 0.376803 0.689279 0.134895 0.979449 0.460511 0.12272 0.369275 0.38461 0.606022 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 6, numVisits=505, meanQ=32.297906, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 8, numVisits=5, meanQ=-2.810000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 8187 episodes
GETTING ACTION FROM:
action 6, numVisits=8692, meanQ=22.491271, numObservations: 9
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 8, numVisits=5, meanQ=-2.810000, numObservations: 4
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 1 0.0415946 0.454479 0.194786 0.227202 0.303094 0.450287 0.53353 0.65367 0.149605 0.21393 0.698801 0.376803 0.689279 0.134895 0.979449 0.460511 0.12272 0.369275 0.38461 0.606022 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 24
Initial state: 0 0.573367 0.131145 0.6334 0.889767 0.672786 0.575981 0.00948502 0.393656 0.80759 0.996051 0.933955 0.972995 0.281755 0.00300246 0.318659 0.396248 0.0575857 0.364299 0.621866 0.966425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 21096 episodes
GETTING ACTION FROM:
action 7, numVisits=13439, meanQ=21.927244, numObservations: 9
action 3, numVisits=7627, meanQ=21.555914, numObservations: 9
action 4, numVisits=13, meanQ=18.261923, numObservations: 6
action 6, numVisits=7, meanQ=10.286071, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 2 0.573367 0.131145 0.6334 0.889767 0.672786 0.575981 0.00948502 0.393656 0.80759 0.996051 0.933955 0.972995 0.281755 0.00300246 0.318659 0.396248 0.0575857 0.364299 0.621866 0.966425 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 25
Initial state: 0 0.320384 0.47925 0.943515 0.224566 0.67695 0.622827 0.681216 0.609473 0.249322 0.350059 0.260273 0.18124 0.54197 0.701466 0.0653671 0.890008 0.809169 0.318703 0.373511 0.70469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20628 episodes
GETTING ACTION FROM:
action 9, numVisits=20568, meanQ=20.725123, numObservations: 9
action 5, numVisits=42, meanQ=7.497619, numObservations: 8
action 4, numVisits=9, meanQ=7.227778, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 9
Next state: 2 0.320384 0.47925 0.943515 0.224566 0.67695 0.622827 0.681216 0.609473 0.249322 0.350059 0.260273 0.18124 0.54197 0.701466 0.0653671 0.890008 0.809169 0.318703 0.373511 0.70469 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 26
Initial state: 0 0.688538 0.317951 0.329581 0.15127 0.98691 0.497455 0.297942 0.475124 0.895563 0.908253 0.879275 0.0975872 0.18177 0.887877 0.0748103 0.851106 0.270753 0.23372 0.056496 0.892434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18907 episodes
GETTING ACTION FROM:
action 1, numVisits=18793, meanQ=18.092876, numObservations: 9
action 8, numVisits=47, meanQ=13.508511, numObservations: 9
action 10, numVisits=38, meanQ=11.873816, numObservations: 9
action 7, numVisits=7, meanQ=10.564286, numObservations: 4
action 9, numVisits=8, meanQ=10.250000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 4, numVisits=4, meanQ=-1.000000, numObservations: 3
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 6, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action: 1
Next state: 2 0.688538 0.317951 0.329581 0.15127 0.98691 0.497455 0.297942 0.475124 0.895563 0.908253 0.879275 0.0975872 0.18177 0.887877 0.0748103 0.851106 0.270753 0.23372 0.056496 0.892434 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 27
Initial state: 0 0.917681 0.295973 0.0882085 0.568882 0.582677 0.589263 0.74469 0.910229 0.413409 0.570725 0.0989734 0.284805 0.811605 0.434958 0.38134 0.940395 0.265555 0.425339 0.585981 0.396308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20302 episodes
GETTING ACTION FROM:
action 10, numVisits=20282, meanQ=21.937535, numObservations: 9
action 5, numVisits=5, meanQ=19.000000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 6, numVisits=5, meanQ=-3.000000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 10
Next state: 1 0.917681 0.295973 0.0882085 0.568882 0.582677 0.589263 0.74469 0.910229 0.413409 0.570725 0.0989734 0.284805 0.811605 0.434958 0.38134 0.940395 0.265555 0.425339 0.585981 0.396308 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 28
Initial state: 0 0.792352 0.946822 0.810549 0.121026 0.135969 0.960781 0.494062 0.235067 0.274116 0.0795672 0.329417 0.443387 0.89645 0.965988 0.844382 0.903791 0.32535 0.245044 0.689168 0.33523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19384 episodes
GETTING ACTION FROM:
action 8, numVisits=19353, meanQ=21.207839, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 2, numVisits=6, meanQ=-4.333333, numObservations: 5
action 3, numVisits=10, meanQ=-5.405000, numObservations: 5
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 1 0.792352 0.946822 0.810549 0.121026 0.135969 0.960781 0.494062 0.235067 0.274116 0.0795672 0.329417 0.443387 0.89645 0.965988 0.844382 0.903791 0.32535 0.245044 0.689168 0.33523 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 29
Initial state: 0 0.711051 0.901198 0.919405 0.739199 0.0938708 0.926744 0.178328 0.796849 0.831041 0.46393 0.867008 0.408827 0.836873 0.996659 0.035582 0.453175 0.330646 0.0664972 0.340335 0.377979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20538 episodes
GETTING ACTION FROM:
action 4, numVisits=20519, meanQ=20.377569, numObservations: 9
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 9, numVisits=8, meanQ=-3.500000, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.711051 0.901198 0.919405 0.739199 0.0938708 0.926744 0.178328 0.796849 0.831041 0.46393 0.867008 0.408827 0.836873 0.996659 0.035582 0.453175 0.330646 0.0664972 0.340335 0.377979 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 6, numVisits=88, meanQ=33.620511, numObservations: 9
action 3, numVisits=26, meanQ=11.069231, numObservations: 9
action 1, numVisits=7, meanQ=8.114286, numObservations: 5
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 10, numVisits=7, meanQ=-2.292857, numObservations: 5
action 4, numVisits=5, meanQ=-5.190000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 24603 episodes
GETTING ACTION FROM:
action 6, numVisits=24691, meanQ=31.954919, numObservations: 9
action 3, numVisits=26, meanQ=11.069231, numObservations: 9
action 1, numVisits=7, meanQ=8.114286, numObservations: 5
action 7, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 10, numVisits=7, meanQ=-2.292857, numObservations: 5
action 4, numVisits=5, meanQ=-5.190000, numObservations: 1
action 2, numVisits=1, meanQ=-10.050000, numObservations: 1
action 5, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 1 0.711051 0.901198 0.919405 0.739199 0.0938708 0.926744 0.178328 0.796849 0.831041 0.46393 0.867008 0.408827 0.836873 0.996659 0.035582 0.453175 0.330646 0.0664972 0.340335 0.377979 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 30
Initial state: 0 0.979588 0.212776 0.71991 0.969271 0.952962 0.439828 0.0376778 0.308503 0.348209 0.199833 0.0174963 0.440749 0.151525 0.688212 0.0763358 0.668868 0.264257 0.375258 0.279704 0.835803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19701 episodes
GETTING ACTION FROM:
action 8, numVisits=19676, meanQ=22.643306, numObservations: 9
action 9, numVisits=5, meanQ=11.380000, numObservations: 4
action 6, numVisits=2, meanQ=-1.000000, numObservations: 1
action 7, numVisits=6, meanQ=-1.000000, numObservations: 5
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=5, meanQ=-3.000000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 1 0.979588 0.212776 0.71991 0.969271 0.952962 0.439828 0.0376778 0.308503 0.348209 0.199833 0.0174963 0.440749 0.151525 0.688212 0.0763358 0.668868 0.264257 0.375258 0.279704 0.835803 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 31
Initial state: 0 0.220744 0.0984889 0.10851 0.868347 0.539135 0.375321 0.0637422 0.0382294 0.948532 0.316828 0.895447 0.750351 0.629014 0.101478 0.317769 0.449805 0.470664 0.31778 0.946568 0.594733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20026 episodes
GETTING ACTION FROM:
action 3, numVisits=19996, meanQ=21.699067, numObservations: 9
action 4, numVisits=11, meanQ=13.045682, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 6, numVisits=2, meanQ=-1.000000, numObservations: 2
action 7, numVisits=4, meanQ=-1.000000, numObservations: 3
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.220744 0.0984889 0.10851 0.868347 0.539135 0.375321 0.0637422 0.0382294 0.948532 0.316828 0.895447 0.750351 0.629014 0.101478 0.317769 0.449805 0.470664 0.31778 0.946568 0.594733 w: 1
Observation: 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 32
Initial state: 0 0.937632 0.616629 0.171075 0.541313 0.316211 0.462588 0.0602621 0.506951 0.503663 0.697662 0.706515 0.36389 0.367424 0.0955035 0.0934684 0.81176 0.155421 0.333453 0.44683 0.948958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19707 episodes
GETTING ACTION FROM:
action 6, numVisits=19694, meanQ=21.243727, numObservations: 9
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 1 0.937632 0.616629 0.171075 0.541313 0.316211 0.462588 0.0602621 0.506951 0.503663 0.697662 0.706515 0.36389 0.367424 0.0955035 0.0934684 0.81176 0.155421 0.333453 0.44683 0.948958 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 33
Initial state: 0 0.387376 0.141261 0.505141 0.236359 0.564109 0.446214 0.129607 0.616461 0.0514515 0.841819 0.312438 0.387585 0.668207 0.867125 0.579399 0.127365 0.565857 0.756075 0.0551793 0.528692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19025 episodes
GETTING ACTION FROM:
action 8, numVisits=18958, meanQ=22.442694, numObservations: 9
action 7, numVisits=46, meanQ=19.330489, numObservations: 9
action 10, numVisits=10, meanQ=19.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 2 0.387376 0.141261 0.505141 0.236359 0.564109 0.446214 0.129607 0.616461 0.0514515 0.841819 0.312438 0.387585 0.668207 0.867125 0.579399 0.127365 0.565857 0.756075 0.0551793 0.528692 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 34
Initial state: 0 0.621973 0.313822 0.782793 0.266573 0.879147 0.0574498 0.0608296 0.580864 0.727895 0.862877 0.116792 0.134897 0.629131 0.958925 0.793196 0.9993 0.279859 0.483951 0.716089 0.977428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18828 episodes
GETTING ACTION FROM:
action 4, numVisits=18767, meanQ=22.956000, numObservations: 9
action 9, numVisits=35, meanQ=1.115714, numObservations: 7
action 1, numVisits=4, meanQ=-1.000000, numObservations: 4
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 5, numVisits=11, meanQ=-1.909091, numObservations: 5
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 0 0.621973 0.313822 0.782793 0.266573 0.879147 0.0574498 0.0608296 0.580864 0.727895 0.862877 0.116792 0.134897 0.629131 0.958925 0.793196 0.9993 0.279859 0.483951 0.716089 0.977428 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=59, meanQ=37.344958, numObservations: 9
action 7, numVisits=51, meanQ=24.468775, numObservations: 9
action 10, numVisits=7, meanQ=22.842857, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 25546 episodes
GETTING ACTION FROM:
action 3, numVisits=25604, meanQ=30.885918, numObservations: 9
action 7, numVisits=51, meanQ=24.468775, numObservations: 9
action 10, numVisits=8, meanQ=7.362500, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.621973 0.313822 0.782793 0.266573 0.879147 0.0574498 0.0608296 0.580864 0.727895 0.862877 0.116792 0.134897 0.629131 0.958925 0.793196 0.9993 0.279859 0.483951 0.716089 0.977428 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 35
Initial state: 0 0.0699618 0.453261 0.766367 0.937345 0.0553808 0.937441 0.247208 0.219161 0.0961234 0.376193 0.281343 0.556241 0.544908 0.597132 0.911669 0.155999 0.72541 0.117957 0.326453 0.441924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20531 episodes
GETTING ACTION FROM:
action 5, numVisits=20497, meanQ=20.612092, numObservations: 9
action 3, numVisits=20, meanQ=2.500000, numObservations: 6
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 7, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 2 0.0699618 0.453261 0.766367 0.937345 0.0553808 0.937441 0.247208 0.219161 0.0961234 0.376193 0.281343 0.556241 0.544908 0.597132 0.911669 0.155999 0.72541 0.117957 0.326453 0.441924 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 36
Initial state: 0 0.0973726 0.516692 0.237886 0.930077 0.558655 0.30676 0.0141399 0.951388 0.287734 0.366748 0.31961 0.91149 0.249175 0.127506 0.453978 0.649077 0.859658 0.88814 0.0585573 0.613821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19948 episodes
GETTING ACTION FROM:
action 5, numVisits=19908, meanQ=20.826066, numObservations: 9
action 7, numVisits=6, meanQ=-1.000000, numObservations: 4
action 8, numVisits=6, meanQ=-1.000000, numObservations: 5
action -1, numVisits=3, meanQ=-1.050000, numObservations: 3
action 0, numVisits=3, meanQ=-1.050000, numObservations: 3
action 1, numVisits=5, meanQ=-3.000000, numObservations: 5
action 10, numVisits=5, meanQ=-3.000000, numObservations: 3
action 6, numVisits=8, meanQ=-3.500000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 5
Next state: 1 0.0973726 0.516692 0.237886 0.930077 0.558655 0.30676 0.0141399 0.951388 0.287734 0.366748 0.31961 0.91149 0.249175 0.127506 0.453978 0.649077 0.859658 0.88814 0.0585573 0.613821 w: 1
Observation: 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 37
Initial state: 0 0.824413 0.716254 0.613503 0.373737 0.0931888 0.0784074 0.142358 0.508981 0.806451 0.534284 0.468904 0.885725 0.394207 0.963697 0.555034 0.101607 0.475191 0.736337 0.349232 0.501398 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18475 episodes
GETTING ACTION FROM:
action 9, numVisits=18443, meanQ=23.186959, numObservations: 9
action 7, numVisits=15, meanQ=16.460000, numObservations: 6
action 8, numVisits=5, meanQ=15.000000, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 9
Next state: 1 0.824413 0.716254 0.613503 0.373737 0.0931888 0.0784074 0.142358 0.508981 0.806451 0.534284 0.468904 0.885725 0.394207 0.963697 0.555034 0.101607 0.475191 0.736337 0.349232 0.501398 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 38
Initial state: 0 0.349071 0.110495 0.557549 0.104746 0.171781 0.401024 0.323328 0.487093 0.0321207 0.809267 0.411464 0.317051 0.552086 0.7918 0.516533 0.86533 0.621917 0.239018 0.790707 0.172418 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20178 episodes
GETTING ACTION FROM:
action 6, numVisits=20135, meanQ=18.054262, numObservations: 9
action 10, numVisits=11, meanQ=5.731818, numObservations: 6
action 8, numVisits=11, meanQ=3.263636, numObservations: 6
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=12, meanQ=-2.587500, numObservations: 6
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 2 0.349071 0.110495 0.557549 0.104746 0.171781 0.401024 0.323328 0.487093 0.0321207 0.809267 0.411464 0.317051 0.552086 0.7918 0.516533 0.86533 0.621917 0.239018 0.790707 0.172418 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 39
Initial state: 0 0.559057 0.643122 0.875977 0.694639 0.175116 0.459344 0.643538 0.426783 0.421178 0.840793 0.22131 0.856522 0.868136 0.544041 0.182088 0.533765 0.883079 0.352179 0.350977 0.507026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20303 episodes
GETTING ACTION FROM:
action 7, numVisits=20270, meanQ=21.057729, numObservations: 9
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=11, meanQ=-1.822727, numObservations: 6
action 8, numVisits=8, meanQ=-4.693438, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 2 0.559057 0.643122 0.875977 0.694639 0.175116 0.459344 0.643538 0.426783 0.421178 0.840793 0.22131 0.856522 0.868136 0.544041 0.182088 0.533765 0.883079 0.352179 0.350977 0.507026 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 40
Initial state: 0 0.937268 0.990538 0.529285 0.512667 0.560327 0.295117 0.369306 0.546045 0.643983 0.0424255 0.642113 0.0690885 0.933857 0.925404 0.373791 0.442743 0.643686 0.75879 0.749631 0.0516374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20621 episodes
GETTING ACTION FROM:
action 3, numVisits=20534, meanQ=20.498449, numObservations: 9
action 8, numVisits=73, meanQ=8.952842, numObservations: 9
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 6, numVisits=3, meanQ=-4.333333, numObservations: 3
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.937268 0.990538 0.529285 0.512667 0.560327 0.295117 0.369306 0.546045 0.643983 0.0424255 0.642113 0.0690885 0.933857 0.925404 0.373791 0.442743 0.643686 0.75879 0.749631 0.0516374 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 41
Initial state: 0 0.653687 0.670702 0.585339 0.170124 0.932918 0.611937 0.6181 0.407682 0.604705 0.572228 0.259358 0.398404 0.147991 0.420594 0.918582 0.285274 0.920478 0.215243 0.232523 0.649051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20581 episodes
GETTING ACTION FROM:
action 7, numVisits=20534, meanQ=21.883821, numObservations: 9
action 8, numVisits=35, meanQ=9.428571, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 7
Next state: 0 0.653687 0.670702 0.585339 0.170124 0.932918 0.611937 0.6181 0.407682 0.604705 0.572228 0.259358 0.398404 0.147991 0.420594 0.918582 0.285274 0.920478 0.215243 0.232523 0.649051 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=54, meanQ=38.650972, numObservations: 9
action 6, numVisits=11, meanQ=24.086364, numObservations: 5
action 8, numVisits=8, meanQ=24.000000, numObservations: 6
action 5, numVisits=4, meanQ=21.737500, numObservations: 4
action 9, numVisits=6, meanQ=11.141667, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 7, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 23156 episodes
GETTING ACTION FROM:
action 2, numVisits=23121, meanQ=18.365832, numObservations: 9
action 6, numVisits=71, meanQ=15.397871, numObservations: 9
action 5, numVisits=32, meanQ=14.342188, numObservations: 8
action 9, numVisits=6, meanQ=11.141667, numObservations: 5
action 8, numVisits=9, meanQ=10.111111, numObservations: 6
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 7, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.653687 0.670702 0.585339 0.170124 0.932918 0.611937 0.6181 0.407682 0.604705 0.572228 0.259358 0.398404 0.147991 0.420594 0.918582 0.285274 0.920478 0.215243 0.232523 0.649051 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 42
Initial state: 0 0.401674 0.761125 0.533539 0.236541 0.312696 0.486738 0.305341 0.194175 0.177218 0.0697755 0.315763 0.307234 0.585855 0.961026 0.244468 0.27616 0.952311 0.57847 0.339588 0.768954 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20363 episodes
GETTING ACTION FROM:
action 6, numVisits=20255, meanQ=21.417991, numObservations: 9
action 10, numVisits=50, meanQ=15.847050, numObservations: 9
action 5, numVisits=37, meanQ=15.227162, numObservations: 7
action 8, numVisits=6, meanQ=14.000000, numObservations: 4
action 4, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=5, meanQ=-2.810000, numObservations: 4
action 3, numVisits=3, meanQ=-6.316667, numObservations: 2
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 2 0.401674 0.761125 0.533539 0.236541 0.312696 0.486738 0.305341 0.194175 0.177218 0.0697755 0.315763 0.307234 0.585855 0.961026 0.244468 0.27616 0.952311 0.57847 0.339588 0.768954 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 43
Initial state: 0 0.231586 0.186812 0.475621 0.240419 0.320973 0.416733 0.148878 0.272434 0.495263 0.942378 0.00516755 0.82564 0.0861846 0.0133773 0.544243 0.176236 0.907771 0.592964 0.817084 0.527572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20812 episodes
GETTING ACTION FROM:
action 1, numVisits=20789, meanQ=20.490967, numObservations: 9
action 9, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 4, numVisits=10, meanQ=-3.000000, numObservations: 9
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 1
Next state: 0 0.231586 0.186812 0.475621 0.240419 0.320973 0.416733 0.148878 0.272434 0.495263 0.942378 0.00516755 0.82564 0.0861846 0.0133773 0.544243 0.176236 0.907771 0.592964 0.817084 0.527572 w: 1
Observation: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1291, meanQ=25.662082, numObservations: 9
action 9, numVisits=4, meanQ=21.737500, numObservations: 3
action 6, numVisits=13, meanQ=20.684615, numObservations: 7
action 3, numVisits=9, meanQ=20.216667, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 6946 episodes
GETTING ACTION FROM:
action 2, numVisits=8195, meanQ=18.576809, numObservations: 9
action 9, numVisits=44, meanQ=14.223713, numObservations: 9
action 6, numVisits=14, meanQ=11.992857, numObservations: 7
action 3, numVisits=10, meanQ=8.095000, numObservations: 5
action 4, numVisits=2, meanQ=-1.000000, numObservations: 2
action 8, numVisits=2, meanQ=-1.000000, numObservations: 2
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 2
Next state: 2 0.231586 0.186812 0.475621 0.240419 0.320973 0.416733 0.148878 0.272434 0.495263 0.942378 0.00516755 0.82564 0.0861846 0.0133773 0.544243 0.176236 0.907771 0.592964 0.817084 0.527572 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 44
Initial state: 0 0.674761 0.929246 0.0274906 0.562647 0.885976 0.809533 0.870939 0.756203 0.631197 0.320236 0.902052 0.826338 0.725668 0.908193 0.289748 0.467151 0.980959 0.824057 0.25011 0.716433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19374 episodes
GETTING ACTION FROM:
action 4, numVisits=19262, meanQ=20.214851, numObservations: 9
action 8, numVisits=86, meanQ=18.265203, numObservations: 9
action 7, numVisits=11, meanQ=16.272727, numObservations: 7
action 1, numVisits=6, meanQ=14.000000, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.674761 0.929246 0.0274906 0.562647 0.885976 0.809533 0.870939 0.756203 0.631197 0.320236 0.902052 0.826338 0.725668 0.908193 0.289748 0.467151 0.980959 0.824057 0.25011 0.716433 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 45
Initial state: 0 0.293194 0.718001 0.140924 0.179183 0.599679 0.357212 0.908562 0.271215 0.413564 0.828633 0.292985 0.58718 0.65326 0.691522 0.307955 0.379595 0.892685 0.474657 0.954148 0.594919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18621 episodes
GETTING ACTION FROM:
action 3, numVisits=18564, meanQ=20.231828, numObservations: 9
action 10, numVisits=30, meanQ=0.936667, numObservations: 8
action 9, numVisits=4, meanQ=-1.000000, numObservations: 4
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 8, numVisits=11, meanQ=-1.822727, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=3, meanQ=-34.333333, numObservations: 3
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 3
Next state: 2 0.293194 0.718001 0.140924 0.179183 0.599679 0.357212 0.908562 0.271215 0.413564 0.828633 0.292985 0.58718 0.65326 0.691522 0.307955 0.379595 0.892685 0.474657 0.954148 0.594919 w: 1
Observation: 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -101
Run # 46
Initial state: 0 0.615532 0.72501 0.639955 0.906875 0.961556 0.467533 0.371813 0.460611 0.771923 0.137031 0.0569362 0.452705 0.703974 0.654681 0.413985 0.142204 0.0607907 0.261046 0.516508 0.956308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 4680 episodes
GETTING ACTION FROM:
action -1, numVisits=4304, meanQ=3.726476, numObservations: 3543
action 0, numVisits=296, meanQ=-1.069417, numObservations: 293
action 6, numVisits=31, meanQ=-4.257984, numObservations: 9
action 4, numVisits=28, meanQ=-4.319464, numObservations: 8
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 10, numVisits=3, meanQ=-4.333333, numObservations: 2
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=6, meanQ=-19.175000, numObservations: 6
action 5, numVisits=5, meanQ=-21.000000, numObservations: 4
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action: -1
Next state: 0 0.615532 0.72501 0.639955 0.906875 0.961556 0.467533 0.371813 0.460611 0.771923 0.137031 0.0569362 0.452705 0.703974 0.654681 0.413985 0.142204 0.0607907 0.261046 0.516508 0.956308 w: 1
Observation: 0 3 0 3 0 3 0 1 0 3 0 1 0 3 0 3 0 1 0 3 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18178 episodes
GETTING ACTION FROM:
action 9, numVisits=18155, meanQ=74.545885, numObservations: 9
action 3, numVisits=7, meanQ=41.857143, numObservations: 4
action 7, numVisits=3, meanQ=32.333333, numObservations: 1
action 4, numVisits=4, meanQ=21.500000, numObservations: 3
action 10, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 9
Next state: 0 0.615532 0.72501 0.639955 0.906875 0.961556 0.467533 0.371813 0.460611 0.771923 0.137031 0.0569362 0.452705 0.703974 0.654681 0.413985 0.142204 0.0607907 0.261046 0.516508 0.956308 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -11
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 6, numVisits=1308, meanQ=85.988120, numObservations: 9
action 5, numVisits=685, meanQ=47.877456, numObservations: 9
action 10, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 8248 episodes
GETTING ACTION FROM:
action 6, numVisits=9556, meanQ=81.405270, numObservations: 9
action 5, numVisits=685, meanQ=47.877456, numObservations: 9
action 10, numVisits=3, meanQ=32.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 4, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 7, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 0 0.615532 0.72501 0.639955 0.906875 0.961556 0.467533 0.371813 0.460611 0.771923 0.137031 0.0569362 0.452705 0.703974 0.654681 0.413985 0.142204 0.0607907 0.261046 0.516508 0.956308 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 
Immediate reward: -11
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=37, meanQ=42.199406, numObservations: 8
action 1, numVisits=21, meanQ=13.285714, numObservations: 4
action 6, numVisits=10, meanQ=4.321330, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 7, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 12123 episodes
GETTING ACTION FROM:
action 4, numVisits=12160, meanQ=51.177522, numObservations: 9
action 1, numVisits=21, meanQ=13.285714, numObservations: 4
action 6, numVisits=10, meanQ=4.321330, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action 7, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.615532 0.72501 0.639955 0.906875 0.961556 0.467533 0.371813 0.460611 0.771923 0.137031 0.0569362 0.452705 0.703974 0.654681 0.413985 0.142204 0.0607907 0.261046 0.516508 0.956308 w: 1
Observation: 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 62.5026
Run # 47
Initial state: 0 0.817994 0.540935 0.362462 0.869713 0.945082 0.124755 0.269571 0.0518245 0.534014 0.603208 0.723582 0.464753 0.382963 0.253696 0.00242198 0.871405 0.347909 0.403445 0.0839751 0.910809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20013 episodes
GETTING ACTION FROM:
action 8, numVisits=19997, meanQ=20.662202, numObservations: 9
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 9, numVisits=6, meanQ=-4.175000, numObservations: 4
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 8
Next state: 0 0.817994 0.540935 0.362462 0.869713 0.945082 0.124755 0.269571 0.0518245 0.534014 0.603208 0.723582 0.464753 0.382963 0.253696 0.00242198 0.871405 0.347909 0.403445 0.0839751 0.910809 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=486, meanQ=24.556154, numObservations: 9
action 6, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 7, numVisits=7, meanQ=-2.292857, numObservations: 6
action 10, numVisits=23, meanQ=-2.967391, numObservations: 9
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 6617 episodes
GETTING ACTION FROM:
action 4, numVisits=7103, meanQ=21.013581, numObservations: 9
action 6, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.050000, numObservations: 2
action 0, numVisits=2, meanQ=-1.050000, numObservations: 2
action 7, numVisits=7, meanQ=-2.292857, numObservations: 6
action 10, numVisits=23, meanQ=-2.967391, numObservations: 9
action 5, numVisits=3, meanQ=-4.016667, numObservations: 3
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 9, numVisits=1, meanQ=-10.050000, numObservations: 1
action 1, numVisits=3, meanQ=-34.333333, numObservations: 3
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 2 0.817994 0.540935 0.362462 0.869713 0.945082 0.124755 0.269571 0.0518245 0.534014 0.603208 0.723582 0.464753 0.382963 0.253696 0.00242198 0.871405 0.347909 0.403445 0.0839751 0.910809 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -101
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -106.95
Run # 48
Initial state: 0 0.479825 0.840256 0.615012 0.767344 0.279593 0.485906 0.270624 0.550845 0.538788 0.959641 0.920745 0.329968 0.638802 0.790348 0.280065 0.930735 0.230704 0.941175 0.548262 0.971658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20460 episodes
GETTING ACTION FROM:
action 9, numVisits=20417, meanQ=19.796999, numObservations: 9
action 4, numVisits=28, meanQ=14.832232, numObservations: 7
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 5, numVisits=5, meanQ=-3.000000, numObservations: 5
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 6, numVisits=1, meanQ=-101.000000, numObservations: 1
action 8, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 9
Next state: 0 0.479825 0.840256 0.615012 0.767344 0.279593 0.485906 0.270624 0.550845 0.538788 0.959641 0.920745 0.329968 0.638802 0.790348 0.280065 0.930735 0.230704 0.941175 0.548262 0.971658 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 
Immediate reward: -11
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=55, meanQ=-1.050000, numObservations: 55
action 0, numVisits=55, meanQ=-1.050000, numObservations: 55
action 7, numVisits=7, meanQ=-2.292857, numObservations: 5
action 6, numVisits=23, meanQ=-3.052065, numObservations: 9
action 3, numVisits=3, meanQ=-4.016667, numObservations: 3
action 4, numVisits=3, meanQ=-4.016667, numObservations: 3
action 9, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 10, numVisits=1, meanQ=-10.050000, numObservations: 1
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
Sampled 18823 episodes
GETTING ACTION FROM:
action 4, numVisits=18825, meanQ=39.012727, numObservations: 9
action -1, numVisits=55, meanQ=-1.050000, numObservations: 55
action 0, numVisits=55, meanQ=-1.050000, numObservations: 55
action 7, numVisits=7, meanQ=-2.292857, numObservations: 5
action 6, numVisits=23, meanQ=-3.052065, numObservations: 9
action 9, numVisits=3, meanQ=-4.016667, numObservations: 3
action 1, numVisits=1, meanQ=-10.050000, numObservations: 1
action 8, numVisits=1, meanQ=-10.050000, numObservations: 1
action 10, numVisits=1, meanQ=-10.050000, numObservations: 1
action 3, numVisits=4, meanQ=-28.262500, numObservations: 4
action 2, numVisits=1, meanQ=-101.000000, numObservations: 1
action 5, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 4
Next state: 1 0.479825 0.840256 0.615012 0.767344 0.279593 0.485906 0.270624 0.550845 0.538788 0.959641 0.920745 0.329968 0.638802 0.790348 0.280065 0.930735 0.230704 0.941175 0.548262 0.971658 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 83.05
Run # 49
Initial state: 0 0.160463 0.28506 0.909085 0.961084 0.470426 0.868774 0.883211 0.347088 0.332485 0.836357 0.340045 0.380247 0.893252 0.433548 0.187509 0.689741 0.67998 0.681165 0.769719 0.892606 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 20057 episodes
GETTING ACTION FROM:
action 6, numVisits=20031, meanQ=19.338310, numObservations: 9
action 1, numVisits=5, meanQ=15.190000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 5, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 7, numVisits=5, meanQ=-2.810000, numObservations: 4
action 8, numVisits=5, meanQ=-3.000000, numObservations: 5
action 4, numVisits=1, meanQ=-101.000000, numObservations: 1
action 9, numVisits=1, meanQ=-101.000000, numObservations: 1
action 10, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 6
Next state: 1 0.160463 0.28506 0.909085 0.961084 0.470426 0.868774 0.883211 0.347088 0.332485 0.836357 0.340045 0.380247 0.893252 0.433548 0.187509 0.689741 0.67998 0.681165 0.769719 0.892606 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
Run # 50
Initial state: 0 0.0824851 0.19014 0.172417 0.498513 0.249757 0.779195 0.492963 0.802578 0.636308 0.555524 0.752381 0.463334 0.303052 0.704816 0.187637 0.263663 0.553635 0.235205 0.374516 0.417055 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19764 episodes
GETTING ACTION FROM:
action 10, numVisits=5138, meanQ=22.061808, numObservations: 9
action 6, numVisits=7418, meanQ=21.621850, numObservations: 9
action 9, numVisits=7136, meanQ=21.609546, numObservations: 9
action 4, numVisits=26, meanQ=20.034615, numObservations: 7
action 7, numVisits=27, meanQ=17.790833, numObservations: 8
action 5, numVisits=11, meanQ=14.540909, numObservations: 6
action -1, numVisits=1, meanQ=-1.050000, numObservations: 1
action 0, numVisits=1, meanQ=-1.050000, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 1, numVisits=1, meanQ=-101.000000, numObservations: 1
action 3, numVisits=1, meanQ=-101.000000, numObservations: 1
action: 10
Next state: 1 0.0824851 0.19014 0.172417 0.498513 0.249757 0.779195 0.492963 0.802578 0.636308 0.555524 0.752381 0.463334 0.303052 0.704816 0.187637 0.263663 0.553635 0.235205 0.374516 0.417055 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 
Immediate reward: 99
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 99
[32m ProblemEnvironment.hpp 351: Done.[39m
