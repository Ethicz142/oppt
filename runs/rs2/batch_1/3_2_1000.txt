Run # 1
Initial state: 0 0.620247 0.824135 0.463124 0.291442 0.56312 0.827442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221546 episodes
GETTING ACTION FROM:
action 3, numVisits=221540, meanQ=4.963639, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.620247 0.824135 0.463124 0.291442 0.56312 0.827442 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.577402 0.8853 0.697874 0.878427 0.0188244 0.107929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 233932 episodes
GETTING ACTION FROM:
action 3, numVisits=233856, meanQ=5.127741, numObservations: 4
action 0, numVisits=54, meanQ=4.155629, numObservations: 1
action -1, numVisits=18, meanQ=3.449492, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.577402 0.8853 0.697874 0.878427 0.0188244 0.107929 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=22830, meanQ=8.535669, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 290702 episodes
GETTING ACTION FROM:
action 2, numVisits=313501, meanQ=5.897374, numObservations: 4
action 1, numVisits=31, meanQ=4.483874, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.577402 0.8853 0.697874 0.878427 0.0188244 0.107929 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=6615, meanQ=7.726697, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 297099 episodes
GETTING ACTION FROM:
action 2, numVisits=303712, meanQ=5.092999, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.577402 0.8853 0.697874 0.878427 0.0188244 0.107929 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 3
Initial state: 0 0.660057 0.810666 0.992696 0.837801 0.638954 0.878758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231877 episodes
GETTING ACTION FROM:
action 3, numVisits=231806, meanQ=4.991812, numObservations: 5
action 0, numVisits=41, meanQ=3.836833, numObservations: 1
action 1, numVisits=26, meanQ=3.229619, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.660057 0.810666 0.992696 0.837801 0.638954 0.878758 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 4
Initial state: 0 0.29317 0.595766 0.507898 0.887673 0.509977 0.848064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 235778 episodes
GETTING ACTION FROM:
action 1, numVisits=235755, meanQ=4.964364, numObservations: 4
action 3, numVisits=15, meanQ=2.460020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=4, meanQ=-2.005000, numObservations: 3
action: 1
Next state: 0 0.29317 0.595766 0.507898 0.887673 0.509977 0.848064 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=35649, meanQ=8.308427, numObservations: 4
action 2, numVisits=8, meanQ=5.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 291641 episodes
GETTING ACTION FROM:
action 2, numVisits=11475, meanQ=6.046784, numObservations: 4
action 3, numVisits=315821, meanQ=6.036620, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.29317 0.595766 0.507898 0.887673 0.509977 0.848064 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=18, meanQ=8.105556, numObservations: 2
action 3, numVisits=3, meanQ=2.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 298292 episodes
GETTING ACTION FROM:
action 2, numVisits=298305, meanQ=5.574459, numObservations: 4
action 3, numVisits=6, meanQ=2.333333, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.29317 0.595766 0.507898 0.887673 0.509977 0.848064 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 5
Initial state: 0 0.732962 0.297956 0.552062 0.876279 0.549082 0.885996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227704 episodes
GETTING ACTION FROM:
action 2, numVisits=218998, meanQ=4.997713, numObservations: 5
action 0, numVisits=8683, meanQ=2.949250, numObservations: 1
action 3, numVisits=16, meanQ=0.749375, numObservations: 2
action 1, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.732962 0.297956 0.552062 0.876279 0.549082 0.885996 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 6
Initial state: 0 0.623388 0.855188 0.212156 0.569068 0.554175 0.861329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 233873 episodes
GETTING ACTION FROM:
action 3, numVisits=233866, meanQ=4.872298, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.623388 0.855188 0.212156 0.569068 0.554175 0.861329 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 7
Initial state: 0 0.661369 0.89439 0.535769 0.807427 0.973477 0.155559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 232965 episodes
GETTING ACTION FROM:
action 1, numVisits=232911, meanQ=4.997587, numObservations: 5
action -1, numVisits=27, meanQ=3.611672, numObservations: 1
action 0, numVisits=15, meanQ=3.052460, numObservations: 1
action 2, numVisits=10, meanQ=2.598000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 1 0.661369 0.89439 0.535769 0.807427 0.973477 0.155559 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 8
Initial state: 0 0.446648 0.317751 0.519489 0.820628 0.581842 0.813193 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 232352 episodes
GETTING ACTION FROM:
action 3, numVisits=232345, meanQ=5.007646, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.446648 0.317751 0.519489 0.820628 0.581842 0.813193 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 9
Initial state: 0 0.931064 0.496627 0.630761 0.828694 0.668268 0.86866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 235611 episodes
GETTING ACTION FROM:
action 1, numVisits=235573, meanQ=4.982527, numObservations: 4
action -1, numVisits=31, meanQ=3.707855, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.931064 0.496627 0.630761 0.828694 0.668268 0.86866 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=17390, meanQ=5.567733, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 279356 episodes
GETTING ACTION FROM:
action 1, numVisits=296744, meanQ=5.241924, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 2 0.931064 0.496627 0.630761 0.828694 0.668268 0.86866 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 10
Initial state: 0 0.146049 0.336654 0.613604 0.827499 0.505894 0.804498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229175 episodes
GETTING ACTION FROM:
action 1, numVisits=188398, meanQ=4.999123, numObservations: 5
action 3, numVisits=40772, meanQ=4.806438, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.146049 0.336654 0.613604 0.827499 0.505894 0.804498 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4832, meanQ=7.816361, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 295601 episodes
GETTING ACTION FROM:
action 2, numVisits=300431, meanQ=5.737014, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.146049 0.336654 0.613604 0.827499 0.505894 0.804498 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 11
Initial state: 0 0.58089 0.815779 0.699888 0.850983 0.523009 0.222656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231495 episodes
GETTING ACTION FROM:
action 3, numVisits=231455, meanQ=5.115232, numObservations: 5
action 0, numVisits=34, meanQ=3.922264, numObservations: 1
action 2, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.58089 0.815779 0.699888 0.850983 0.523009 0.222656 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 12
Initial state: 0 0.651652 0.851299 0.552418 0.88563 0.370902 0.921512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 235039 episodes
GETTING ACTION FROM:
action 3, numVisits=235019, meanQ=4.969969, numObservations: 4
action 1, numVisits=15, meanQ=2.860687, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.651652 0.851299 0.552418 0.88563 0.370902 0.921512 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=17284, meanQ=5.575337, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 271446 episodes
GETTING ACTION FROM:
action 3, numVisits=288728, meanQ=4.948350, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.651652 0.851299 0.552418 0.88563 0.370902 0.921512 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=6608, meanQ=6.492617, numObservations: 4
action 2, numVisits=12, meanQ=2.999167, numObservations: 3
action 3, numVisits=4, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 296707 episodes
GETTING ACTION FROM:
action 1, numVisits=303257, meanQ=5.992901, numObservations: 4
action 3, numVisits=60, meanQ=5.066840, numObservations: 4
action 2, numVisits=12, meanQ=2.999167, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.651652 0.851299 0.552418 0.88563 0.370902 0.921512 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 13
Initial state: 0 0.611004 0.842289 0.569662 0.852039 0.376856 0.542391 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 232854 episodes
GETTING ACTION FROM:
action 1, numVisits=232786, meanQ=4.885471, numObservations: 4
action -1, numVisits=63, meanQ=4.011023, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.611004 0.842289 0.569662 0.852039 0.376856 0.542391 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 14
Initial state: 0 0.437545 0.161624 0.577903 0.887622 0.637131 0.854298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215855 episodes
GETTING ACTION FROM:
action 1, numVisits=215849, meanQ=4.855248, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.437545 0.161624 0.577903 0.887622 0.637131 0.854298 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.536277 0.814628 0.681023 0.865475 0.125707 0.326948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215397 episodes
GETTING ACTION FROM:
action 1, numVisits=215339, meanQ=5.002233, numObservations: 4
action 0, numVisits=23, meanQ=3.553293, numObservations: 1
action 3, numVisits=22, meanQ=3.181832, numObservations: 3
action 2, numVisits=11, meanQ=1.907282, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.536277 0.814628 0.681023 0.865475 0.125707 0.326948 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 16
Initial state: 0 0.42006 0.787137 0.677679 0.868147 0.516976 0.896124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226313 episodes
GETTING ACTION FROM:
action 1, numVisits=226244, meanQ=4.920913, numObservations: 4
action 0, numVisits=36, meanQ=3.747200, numObservations: 1
action -1, numVisits=30, meanQ=3.583703, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.42006 0.787137 0.677679 0.868147 0.516976 0.896124 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22113, meanQ=8.536332, numObservations: 3
action 2, numVisits=21, meanQ=7.189529, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 273273 episodes
GETTING ACTION FROM:
action 3, numVisits=295186, meanQ=6.093584, numObservations: 5
action 2, numVisits=221, meanQ=5.622670, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.42006 0.787137 0.677679 0.868147 0.516976 0.896124 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 17
Initial state: 0 0.629599 0.838773 0.659892 0.875702 0.944809 0.265531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 216683 episodes
GETTING ACTION FROM:
action 2, numVisits=216671, meanQ=4.980692, numObservations: 5
action 1, numVisits=7, meanQ=-0.145714, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.629599 0.838773 0.659892 0.875702 0.944809 0.265531 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 18
Initial state: 0 0.98068 0.982972 0.593687 0.876988 0.604759 0.845055 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228624 episodes
GETTING ACTION FROM:
action 3, numVisits=228494, meanQ=4.991070, numObservations: 4
action -1, numVisits=110, meanQ=4.326562, numObservations: 1
action 2, numVisits=11, meanQ=2.100000, numObservations: 3
action 1, numVisits=7, meanQ=1.014286, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.98068 0.982972 0.593687 0.876988 0.604759 0.845055 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 19
Initial state: 0 0.675749 0.868111 0.896185 0.59529 0.532358 0.849578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164974 episodes
GETTING ACTION FROM:
action 0, numVisits=164905, meanQ=5.440001, numObservations: 2
action -1, numVisits=65, meanQ=2.594122, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.675749 0.868111 0.896185 0.59529 0.532358 0.849578 w: 1
Observation: 0 0 0.950926 0 0.585078 0 0.862828 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=124012, meanQ=7.370156, numObservations: 4
action 2, numVisits=1725, meanQ=4.920638, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 255350 episodes
GETTING ACTION FROM:
action 1, numVisits=379360, meanQ=6.015871, numObservations: 4
action 2, numVisits=1725, meanQ=4.920638, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.675749 0.868111 0.896185 0.59529 0.532358 0.849578 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 20
Initial state: 0 0.592091 0.813131 0.699574 0.890281 0.0986505 0.432551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231252 episodes
GETTING ACTION FROM:
action 1, numVisits=230428, meanQ=5.005341, numObservations: 5
action 2, numVisits=819, meanQ=4.769459, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.592091 0.813131 0.699574 0.890281 0.0986505 0.432551 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 21
Initial state: 0 0.579629 0.864272 0.96454 0.821599 0.605659 0.895701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 216209 episodes
GETTING ACTION FROM:
action 3, numVisits=216168, meanQ=4.878339, numObservations: 5
action 0, numVisits=37, meanQ=3.713453, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.579629 0.864272 0.96454 0.821599 0.605659 0.895701 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 22
Initial state: 0 0.808828 0.903309 0.687306 0.843267 0.665653 0.875435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 210365 episodes
GETTING ACTION FROM:
action 2, numVisits=210070, meanQ=4.901913, numObservations: 5
action 3, numVisits=226, meanQ=4.408604, numObservations: 5
action -1, numVisits=51, meanQ=3.908080, numObservations: 1
action 1, numVisits=16, meanQ=2.255625, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.808828 0.903309 0.687306 0.843267 0.665653 0.875435 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 23
Initial state: 0 0.695779 0.886953 0.567593 0.969112 0.635866 0.881943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 148613 episodes
GETTING ACTION FROM:
action 0, numVisits=148412, meanQ=5.234202, numObservations: 3
action -1, numVisits=193, meanQ=3.261162, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.695779 0.886953 0.567593 0.969112 0.635866 0.881943 w: 1
Observation: 0 0 0.901569 0 0.895786 0 0.889662 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=60934, meanQ=7.648127, numObservations: 4
action 2, numVisits=4, meanQ=2.995000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 255866 episodes
GETTING ACTION FROM:
action 3, numVisits=316729, meanQ=5.437386, numObservations: 4
action -1, numVisits=48, meanQ=4.404991, numObservations: 1
action 0, numVisits=24, meanQ=3.961045, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 1 0.695779 0.886953 0.567593 0.969112 0.635866 0.881943 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 24
Initial state: 0 0.621826 0.822353 0.580127 0.828035 0.0712048 0.212593 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 234307 episodes
GETTING ACTION FROM:
action 1, numVisits=234296, meanQ=4.907318, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.621826 0.822353 0.580127 0.828035 0.0712048 0.212593 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 25
Initial state: 0 0.661137 0.850004 0.177524 0.539072 0.531116 0.899117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 235163 episodes
GETTING ACTION FROM:
action 1, numVisits=171075, meanQ=4.941278, numObservations: 3
action 3, numVisits=64016, meanQ=4.919591, numObservations: 4
action 0, numVisits=49, meanQ=3.911177, numObservations: 1
action 2, numVisits=21, meanQ=3.085238, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.661137 0.850004 0.177524 0.539072 0.531116 0.899117 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 26
Initial state: 0 0.629944 0.828842 0.569272 0.128896 0.611615 0.811184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230864 episodes
GETTING ACTION FROM:
action 3, numVisits=230851, meanQ=4.926912, numObservations: 5
action 2, numVisits=8, meanQ=1.500000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.629944 0.828842 0.569272 0.128896 0.611615 0.811184 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 27
Initial state: 0 0.672561 0.895235 0.508393 0.870326 0.782661 0.928478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231143 episodes
GETTING ACTION FROM:
action 2, numVisits=222650, meanQ=4.884568, numObservations: 4
action -1, numVisits=8464, meanQ=2.940277, numObservations: 1
action 1, numVisits=22, meanQ=1.277277, numObservations: 3
action 3, numVisits=5, meanQ=0.196000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.672561 0.895235 0.508393 0.870326 0.782661 0.928478 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 28
Initial state: 0 0.652353 0.846624 0.400377 0.484578 0.660641 0.81655 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 236014 episodes
GETTING ACTION FROM:
action 1, numVisits=235806, meanQ=4.997899, numObservations: 4
action -1, numVisits=204, meanQ=1.771875, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.652353 0.846624 0.400377 0.484578 0.660641 0.81655 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 29
Initial state: 0 0.691602 0.698261 0.517643 0.867881 0.60289 0.867799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226614 episodes
GETTING ACTION FROM:
action 2, numVisits=226550, meanQ=4.898520, numObservations: 4
action 0, numVisits=29, meanQ=3.564811, numObservations: 1
action 1, numVisits=32, meanQ=2.732187, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.691602 0.698261 0.517643 0.867881 0.60289 0.867799 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 30
Initial state: 0 0.604765 0.813384 0.694466 0.819172 0.519463 0.298872 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 232758 episodes
GETTING ACTION FROM:
action 1, numVisits=227934, meanQ=5.001439, numObservations: 4
action -1, numVisits=4816, meanQ=3.034728, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.604765 0.813384 0.694466 0.819172 0.519463 0.298872 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 31
Initial state: 0 0.535357 0.82043 0.532053 0.898107 0.413342 0.842008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225550 episodes
GETTING ACTION FROM:
action 1, numVisits=225493, meanQ=4.855284, numObservations: 5
action 0, numVisits=52, meanQ=3.863930, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.535357 0.82043 0.532053 0.898107 0.413342 0.842008 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 32
Initial state: 0 0.676315 0.604043 0.578506 0.845951 0.596969 0.884124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 232497 episodes
GETTING ACTION FROM:
action 1, numVisits=232489, meanQ=4.982184, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.676315 0.604043 0.578506 0.845951 0.596969 0.884124 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 33
Initial state: 0 0.437002 0.173284 0.651893 0.866006 0.605959 0.804978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167701 episodes
GETTING ACTION FROM:
action 0, numVisits=157307, meanQ=5.765666, numObservations: 2
action 1, numVisits=9884, meanQ=5.011180, numObservations: 5
action 3, numVisits=507, meanQ=4.650892, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.437002 0.173284 0.651893 0.866006 0.605959 0.804978 w: 1
Observation: 0 0 0.17974 0 0.951216 0 0.814268 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=110116, meanQ=7.728774, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 252064 episodes
GETTING ACTION FROM:
action 3, numVisits=362178, meanQ=5.701727, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.437002 0.173284 0.651893 0.866006 0.605959 0.804978 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 34
Initial state: 0 0.646344 0.87398 0.61826 0.801126 0.835008 0.564524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231910 episodes
GETTING ACTION FROM:
action 1, numVisits=231861, meanQ=4.888988, numObservations: 4
action 0, numVisits=21, meanQ=3.313220, numObservations: 1
action 3, numVisits=25, meanQ=1.878812, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.646344 0.87398 0.61826 0.801126 0.835008 0.564524 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 35
Initial state: 0 0.825633 0.493742 0.510959 0.818099 0.555341 0.833839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 236344 episodes
GETTING ACTION FROM:
action 1, numVisits=236316, meanQ=4.975581, numObservations: 3
action 2, numVisits=23, meanQ=3.260009, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.825633 0.493742 0.510959 0.818099 0.555341 0.833839 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 36
Initial state: 0 0.000943001 0.412475 0.647564 0.843523 0.537466 0.825501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 236786 episodes
GETTING ACTION FROM:
action 2, numVisits=236475, meanQ=4.986687, numObservations: 4
action -1, numVisits=304, meanQ=1.443216, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=2, meanQ=-4.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.000943001 0.412475 0.647564 0.843523 0.537466 0.825501 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 37
Initial state: 0 0.517279 0.891603 0.61224 0.847603 0.66245 0.613513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231307 episodes
GETTING ACTION FROM:
action 1, numVisits=136357, meanQ=4.978579, numObservations: 4
action 2, numVisits=94945, meanQ=4.837937, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.517279 0.891603 0.61224 0.847603 0.66245 0.613513 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 38
Initial state: 0 0.563568 0.891965 0.289679 0.484588 0.694756 0.838787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229320 episodes
GETTING ACTION FROM:
action 2, numVisits=229311, meanQ=4.957019, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.563568 0.891965 0.289679 0.484588 0.694756 0.838787 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 39
Initial state: 0 0.645288 0.851261 0.737705 0.377746 0.531414 0.890347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 235690 episodes
GETTING ACTION FROM:
action 2, numVisits=235683, meanQ=4.998398, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.645288 0.851261 0.737705 0.377746 0.531414 0.890347 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.766118 0.372559 0.552959 0.825301 0.607143 0.823141 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 235809 episodes
GETTING ACTION FROM:
action 3, numVisits=235802, meanQ=4.997681, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.766118 0.372559 0.552959 0.825301 0.607143 0.823141 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 41
Initial state: 0 0.682921 0.885378 0.654139 0.818724 0.0935471 0.333404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231313 episodes
GETTING ACTION FROM:
action 3, numVisits=231250, meanQ=4.917197, numObservations: 4
action 0, numVisits=53, meanQ=3.962640, numObservations: 1
action 2, numVisits=7, meanQ=0.711443, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.682921 0.885378 0.654139 0.818724 0.0935471 0.333404 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=24732, meanQ=8.333973, numObservations: 3
action 2, numVisits=10438, meanQ=8.307738, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 293728 episodes
GETTING ACTION FROM:
action 1, numVisits=163309, meanQ=6.183023, numObservations: 3
action 2, numVisits=165589, meanQ=6.182847, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.682921 0.885378 0.654139 0.818724 0.0935471 0.333404 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 42
Initial state: 0 0.882355 0.552953 0.576525 0.801936 0.69422 0.862478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227474 episodes
GETTING ACTION FROM:
action 3, numVisits=213221, meanQ=4.867467, numObservations: 3
action 0, numVisits=14241, meanQ=2.910397, numObservations: 1
action 1, numVisits=7, meanQ=0.427171, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.882355 0.552953 0.576525 0.801936 0.69422 0.862478 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=15368, meanQ=4.584758, numObservations: 4
action 0, numVisits=396, meanQ=2.086306, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 290620 episodes
GETTING ACTION FROM:
action 2, numVisits=305988, meanQ=5.742740, numObservations: 4
action 0, numVisits=396, meanQ=2.086306, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.882355 0.552953 0.576525 0.801936 0.69422 0.862478 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 43
Initial state: 0 0.505988 0.890952 0.182809 0.607388 0.66361 0.895298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226196 episodes
GETTING ACTION FROM:
action 1, numVisits=74206, meanQ=4.956721, numObservations: 5
action 3, numVisits=149286, meanQ=4.875991, numObservations: 4
action 2, numVisits=2649, meanQ=4.695522, numObservations: 4
action -1, numVisits=53, meanQ=3.897235, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.505988 0.890952 0.182809 0.607388 0.66361 0.895298 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 44
Initial state: 0 0.0212578 0.781989 0.692384 0.897494 0.594262 0.826904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161539 episodes
GETTING ACTION FROM:
action -1, numVisits=161519, meanQ=2.931490, numObservations: 1
action 1, numVisits=11, meanQ=-1.182727, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=4, meanQ=-2.977500, numObservations: 2
action: -1
Next state: 0 0.0212578 0.781989 0.692384 0.897494 0.594262 0.826904 w: 1
Observation: 0 0.105611 0 0.607776 0 0.575897 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=161456, meanQ=4.991279, numObservations: 4
action 0, numVisits=37, meanQ=3.823788, numObservations: 1
action 3, numVisits=15, meanQ=2.065333, numObservations: 4
action 2, numVisits=8, meanQ=1.500000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 252615 episodes
GETTING ACTION FROM:
action 1, numVisits=414070, meanQ=4.989191, numObservations: 4
action 0, numVisits=38, meanQ=3.781124, numObservations: 1
action 3, numVisits=15, meanQ=2.065333, numObservations: 4
action 2, numVisits=8, meanQ=1.500000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.0212578 0.781989 0.692384 0.897494 0.594262 0.826904 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 45
Initial state: 0 0.54906 0.820851 0.40757 0.568052 0.613502 0.817682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 236304 episodes
GETTING ACTION FROM:
action 2, numVisits=236255, meanQ=4.909800, numObservations: 4
action -1, numVisits=44, meanQ=3.814355, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.54906 0.820851 0.40757 0.568052 0.613502 0.817682 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23181, meanQ=8.539803, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 295012 episodes
GETTING ACTION FROM:
action 3, numVisits=318193, meanQ=6.228190, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.54906 0.820851 0.40757 0.568052 0.613502 0.817682 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 46
Initial state: 0 0.696477 0.868391 0.0413212 0.432092 0.547479 0.847481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 234706 episodes
GETTING ACTION FROM:
action 2, numVisits=234638, meanQ=4.883430, numObservations: 3
action -1, numVisits=51, meanQ=3.860786, numObservations: 1
action 1, numVisits=14, meanQ=2.856436, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.696477 0.868391 0.0413212 0.432092 0.547479 0.847481 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=35654, meanQ=8.336167, numObservations: 3
action 3, numVisits=19, meanQ=6.478421, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 293191 episodes
GETTING ACTION FROM:
action 1, numVisits=328795, meanQ=6.453230, numObservations: 3
action 3, numVisits=69, meanQ=5.494059, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.696477 0.868391 0.0413212 0.432092 0.547479 0.847481 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 47
Initial state: 0 0.754729 0.247627 0.661401 0.8294 0.527998 0.832559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158841 episodes
GETTING ACTION FROM:
action 0, numVisits=158237, meanQ=2.915968, numObservations: 1
action -1, numVisits=596, meanQ=2.649632, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.754729 0.247627 0.661401 0.8294 0.527998 0.832559 w: 1
Observation: 0 0 0.214937 0 0.744345 0 0.845416 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=153648, meanQ=4.976197, numObservations: 5
action 2, numVisits=4580, meanQ=4.835509, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 248681 episodes
GETTING ACTION FROM:
action 2, numVisits=184838, meanQ=5.091013, numObservations: 4
action 3, numVisits=222071, meanQ=4.924205, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.754729 0.247627 0.661401 0.8294 0.527998 0.832559 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 48
Initial state: 0 0.551283 0.847253 0.67654 0.848105 0.0518612 0.182441 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230791 episodes
GETTING ACTION FROM:
action 3, numVisits=230785, meanQ=4.971335, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.551283 0.847253 0.67654 0.848105 0.0518612 0.182441 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 49
Initial state: 0 0.622194 0.872841 0.6375 0.818037 0.676101 0.261976 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 232595 episodes
GETTING ACTION FROM:
action 1, numVisits=232513, meanQ=4.854504, numObservations: 4
action 2, numVisits=75, meanQ=3.035204, numObservations: 4
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.622194 0.872841 0.6375 0.818037 0.676101 0.261976 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 50
Initial state: 0 0.66311 0.815265 0.664654 0.895168 0.947841 0.466512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230734 episodes
GETTING ACTION FROM:
action 1, numVisits=230636, meanQ=4.962333, numObservations: 5
action 0, numVisits=65, meanQ=3.837973, numObservations: 1
action 2, numVisits=22, meanQ=2.990909, numObservations: 3
action 3, numVisits=9, meanQ=2.332244, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.66311 0.815265 0.664654 0.895168 0.947841 0.466512 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 51
Initial state: 0 0.625653 0.886135 0.135668 0.0801395 0.683937 0.878533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224495 episodes
GETTING ACTION FROM:
action 3, numVisits=224486, meanQ=4.838310, numObservations: 5
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.625653 0.886135 0.135668 0.0801395 0.683937 0.878533 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 52
Initial state: 0 0.647709 0.822924 0.516578 0.815169 0.647568 0.0533572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237609 episodes
GETTING ACTION FROM:
action 2, numVisits=237551, meanQ=4.923065, numObservations: 3
action -1, numVisits=31, meanQ=3.640122, numObservations: 1
action 3, numVisits=24, meanQ=3.161667, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.647709 0.822924 0.516578 0.815169 0.647568 0.0533572 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 53
Initial state: 0 0.299679 0.910856 0.536898 0.838801 0.641962 0.882214 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231196 episodes
GETTING ACTION FROM:
action 2, numVisits=231118, meanQ=4.918522, numObservations: 5
action -1, numVisits=43, meanQ=3.806933, numObservations: 1
action 0, numVisits=23, meanQ=3.430178, numObservations: 1
action 1, numVisits=11, meanQ=2.453636, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.299679 0.910856 0.536898 0.838801 0.641962 0.882214 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=17135, meanQ=4.652686, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 288304 episodes
GETTING ACTION FROM:
action 3, numVisits=305439, meanQ=5.654766, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.299679 0.910856 0.536898 0.838801 0.641962 0.882214 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 54
Initial state: 0 0.0447801 0.808606 0.672424 0.866145 0.553299 0.888225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 236963 episodes
GETTING ACTION FROM:
action 1, numVisits=236914, meanQ=4.929776, numObservations: 3
action -1, numVisits=45, meanQ=3.883345, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0447801 0.808606 0.672424 0.866145 0.553299 0.888225 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=36034, meanQ=8.324640, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 293176 episodes
GETTING ACTION FROM:
action 3, numVisits=329210, meanQ=6.349676, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0447801 0.808606 0.672424 0.866145 0.553299 0.888225 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 55
Initial state: 0 0.662813 0.834312 0.528946 0.810485 0.187905 0.616783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 234367 episodes
GETTING ACTION FROM:
action 2, numVisits=234273, meanQ=4.978723, numObservations: 4
action 0, numVisits=67, meanQ=4.127229, numObservations: 1
action -1, numVisits=25, meanQ=3.578012, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.662813 0.834312 0.528946 0.810485 0.187905 0.616783 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 56
Initial state: 0 0.949044 0.218807 0.665359 0.888158 0.661947 0.857232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237012 episodes
GETTING ACTION FROM:
action 3, numVisits=236873, meanQ=4.995943, numObservations: 3
action 0, numVisits=98, meanQ=4.288282, numObservations: 1
action -1, numVisits=39, meanQ=3.873786, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.949044 0.218807 0.665359 0.888158 0.661947 0.857232 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 57
Initial state: 0 0.13931 0.00409017 0.665889 0.896477 0.691508 0.821854 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229424 episodes
GETTING ACTION FROM:
action 2, numVisits=229201, meanQ=4.899152, numObservations: 5
action -1, numVisits=219, meanQ=2.157915, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.13931 0.00409017 0.665889 0.896477 0.691508 0.821854 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 58
Initial state: 0 0.643877 0.873642 0.68014 0.888537 0.990868 0.872347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 236013 episodes
GETTING ACTION FROM:
action 1, numVisits=235934, meanQ=4.941494, numObservations: 3
action 3, numVisits=50, meanQ=3.836002, numObservations: 4
action 0, numVisits=23, meanQ=3.476271, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.643877 0.873642 0.68014 0.888537 0.990868 0.872347 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 59
Initial state: 0 0.596314 0.89969 0.341144 0.31062 0.688561 0.822637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157338 episodes
GETTING ACTION FROM:
action -1, numVisits=156328, meanQ=2.775965, numObservations: 1
action 0, numVisits=1005, meanQ=2.575182, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.596314 0.89969 0.341144 0.31062 0.688561 0.822637 w: 1
Observation: 0 0.542179 0 0.434373 0 0.707637 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=156265, meanQ=4.835078, numObservations: 4
action 0, numVisits=58, meanQ=3.937991, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 243968 episodes
GETTING ACTION FROM:
action 1, numVisits=400223, meanQ=4.739607, numObservations: 4
action 0, numVisits=68, meanQ=3.867322, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.596314 0.89969 0.341144 0.31062 0.688561 0.822637 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 60
Initial state: 0 0.500981 0.886535 0.0471287 0.0377189 0.678579 0.820461 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 234016 episodes
GETTING ACTION FROM:
action 1, numVisits=233987, meanQ=4.914667, numObservations: 4
action 0, numVisits=21, meanQ=3.337886, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.500981 0.886535 0.0471287 0.0377189 0.678579 0.820461 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 61
Initial state: 0 0.568139 0.818049 0.522967 0.842191 0.079888 0.27512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225320 episodes
GETTING ACTION FROM:
action 1, numVisits=225309, meanQ=4.860387, numObservations: 5
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.568139 0.818049 0.522967 0.842191 0.079888 0.27512 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 62
Initial state: 0 0.605346 0.810438 0.94459 0.154628 0.54921 0.820054 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 235120 episodes
GETTING ACTION FROM:
action 3, numVisits=234375, meanQ=5.010726, numObservations: 4
action 2, numVisits=724, meanQ=4.760881, numObservations: 5
action -1, numVisits=18, meanQ=3.286533, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.605346 0.810438 0.94459 0.154628 0.54921 0.820054 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 63
Initial state: 0 0.531353 0.856014 0.0118256 0.857436 0.681659 0.833301 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225691 episodes
GETTING ACTION FROM:
action 1, numVisits=225663, meanQ=4.816464, numObservations: 5
action -1, numVisits=18, meanQ=3.047883, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.531353 0.856014 0.0118256 0.857436 0.681659 0.833301 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12307, meanQ=7.848936, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 292117 episodes
GETTING ACTION FROM:
action 3, numVisits=192479, meanQ=5.992072, numObservations: 4
action 2, numVisits=111945, meanQ=5.971970, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.531353 0.856014 0.0118256 0.857436 0.681659 0.833301 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 64
Initial state: 0 0.534434 0.802876 0.682344 0.363462 0.557387 0.806711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 237197 episodes
GETTING ACTION FROM:
action 1, numVisits=237191, meanQ=4.987747, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.534434 0.802876 0.682344 0.363462 0.557387 0.806711 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 65
Initial state: 0 0.609916 0.839828 0.647166 0.801123 0.221794 0.958274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 235868 episodes
GETTING ACTION FROM:
action 3, numVisits=235862, meanQ=4.932424, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.609916 0.839828 0.647166 0.801123 0.221794 0.958274 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=1987, meanQ=3.755470, numObservations: 1
action 2, numVisits=6, meanQ=-2.001650, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 279181 episodes
GETTING ACTION FROM:
action 1, numVisits=278383, meanQ=5.790681, numObservations: 5
action 0, numVisits=2786, meanQ=2.516780, numObservations: 1
action 2, numVisits=6, meanQ=-2.001650, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.609916 0.839828 0.647166 0.801123 0.221794 0.958274 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 66
Initial state: 0 0.909849 0.625894 0.541211 0.882761 0.50883 0.875695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227087 episodes
GETTING ACTION FROM:
action 2, numVisits=227081, meanQ=5.026021, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.909849 0.625894 0.541211 0.882761 0.50883 0.875695 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 67
Initial state: 0 0.693617 0.822148 0.696362 0.856923 0.865334 0.456974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217664 episodes
GETTING ACTION FROM:
action 1, numVisits=217658, meanQ=4.752642, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.693617 0.822148 0.696362 0.856923 0.865334 0.456974 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 68
Initial state: 0 0.15155 0.47508 0.559606 0.877819 0.511308 0.803186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229934 episodes
GETTING ACTION FROM:
action 2, numVisits=229846, meanQ=4.965829, numObservations: 3
action 0, numVisits=55, meanQ=4.017215, numObservations: 1
action -1, numVisits=30, meanQ=3.678656, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.15155 0.47508 0.559606 0.877819 0.511308 0.803186 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 69
Initial state: 0 0.925008 0.959566 0.694274 0.88133 0.50104 0.886542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157494 episodes
GETTING ACTION FROM:
action 0, numVisits=142222, meanQ=2.848187, numObservations: 1
action -1, numVisits=15253, meanQ=2.825013, numObservations: 1
action 3, numVisits=15, meanQ=0.719333, numObservations: 4
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.925008 0.959566 0.694274 0.88133 0.50104 0.886542 w: 1
Observation: 0 0 1 0 0.955007 0 0.87784 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=142210, meanQ=4.921798, numObservations: 3
action 3, numVisits=5, meanQ=-0.201980, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 247365 episodes
GETTING ACTION FROM:
action 2, numVisits=389575, meanQ=4.860278, numObservations: 3
action 3, numVisits=5, meanQ=-0.201980, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.925008 0.959566 0.694274 0.88133 0.50104 0.886542 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 70
Initial state: 0 0.524496 0.883862 0.937094 0.564292 0.542308 0.854849 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225819 episodes
GETTING ACTION FROM:
action 3, numVisits=225615, meanQ=4.925456, numObservations: 5
action 1, numVisits=154, meanQ=4.231032, numObservations: 3
action 0, numVisits=47, meanQ=3.886766, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.524496 0.883862 0.937094 0.564292 0.542308 0.854849 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 71
Initial state: 0 0.615606 0.899097 0.369546 0.889384 0.649281 0.865243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226105 episodes
GETTING ACTION FROM:
action 1, numVisits=226020, meanQ=4.922829, numObservations: 4
action 0, numVisits=62, meanQ=4.021965, numObservations: 1
action 3, numVisits=20, meanQ=3.004000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.615606 0.899097 0.369546 0.889384 0.649281 0.865243 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 72
Initial state: 0 0.472473 0.7957 0.527403 0.83758 0.686221 0.861853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153983 episodes
GETTING ACTION FROM:
action 0, numVisits=153977, meanQ=2.905089, numObservations: 1
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.472473 0.7957 0.527403 0.83758 0.686221 0.861853 w: 1
Observation: 0 0 0.81258 0 0.838185 0 0.762067 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=153790, meanQ=4.944145, numObservations: 5
action 0, numVisits=152, meanQ=4.384454, numObservations: 1
action 2, numVisits=12, meanQ=1.998333, numObservations: 3
action 1, numVisits=20, meanQ=1.904505, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 240853 episodes
GETTING ACTION FROM:
action 3, numVisits=394631, meanQ=4.839067, numObservations: 5
action 0, numVisits=164, meanQ=4.287178, numObservations: 1
action 2, numVisits=12, meanQ=1.998333, numObservations: 3
action 1, numVisits=20, meanQ=1.904505, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.472473 0.7957 0.527403 0.83758 0.686221 0.861853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 73
Initial state: 0 0.734515 0.283439 0.659357 0.823837 0.534926 0.885021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225259 episodes
GETTING ACTION FROM:
action 3, numVisits=225251, meanQ=4.995689, numObservations: 5
action 2, numVisits=3, meanQ=-0.329967, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.734515 0.283439 0.659357 0.823837 0.534926 0.885021 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 74
Initial state: 0 0.630081 0.862553 0.637726 0.895675 0.618687 0.81885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225882 episodes
GETTING ACTION FROM:
action 3, numVisits=225181, meanQ=4.975658, numObservations: 5
action -1, numVisits=686, meanQ=1.877279, numObservations: 1
action 2, numVisits=10, meanQ=0.399010, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.630081 0.862553 0.637726 0.895675 0.618687 0.81885 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 75
Initial state: 0 0.554873 0.847043 0.0528712 0.334237 0.573036 0.839472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223045 episodes
GETTING ACTION FROM:
action 1, numVisits=222859, meanQ=4.821293, numObservations: 3
action -1, numVisits=144, meanQ=4.240331, numObservations: 1
action 0, numVisits=40, meanQ=3.690609, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.554873 0.847043 0.0528712 0.334237 0.573036 0.839472 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 76
Initial state: 0 0.691746 0.87272 0.598087 0.851981 0.756328 0.807937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222500 episodes
GETTING ACTION FROM:
action 1, numVisits=212839, meanQ=4.937566, numObservations: 4
action 0, numVisits=9652, meanQ=2.986697, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.691746 0.87272 0.598087 0.851981 0.756328 0.807937 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=15620, meanQ=4.540053, numObservations: 4
action 0, numVisits=21, meanQ=3.141796, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 282319 episodes
GETTING ACTION FROM:
action 3, numVisits=297939, meanQ=5.642888, numObservations: 4
action 0, numVisits=21, meanQ=3.141796, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.691746 0.87272 0.598087 0.851981 0.756328 0.807937 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 77
Initial state: 0 0.636156 0.88959 0.589559 0.89669 0.15202 0.0595233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227079 episodes
GETTING ACTION FROM:
action 2, numVisits=227067, meanQ=4.974365, numObservations: 4
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.636156 0.88959 0.589559 0.89669 0.15202 0.0595233 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16554, meanQ=5.688908, numObservations: 4
action 3, numVisits=6, meanQ=2.333333, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 263407 episodes
GETTING ACTION FROM:
action 2, numVisits=279958, meanQ=4.816013, numObservations: 4
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 3, numVisits=7, meanQ=0.428571, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.636156 0.88959 0.589559 0.89669 0.15202 0.0595233 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 78
Initial state: 0 0.369842 0.661662 0.624199 0.871163 0.641927 0.849612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220757 episodes
GETTING ACTION FROM:
action 3, numVisits=208594, meanQ=4.886532, numObservations: 4
action -1, numVisits=12139, meanQ=2.780198, numObservations: 1
action 1, numVisits=15, meanQ=0.732000, numObservations: 3
action 2, numVisits=7, meanQ=0.428571, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.369842 0.661662 0.624199 0.871163 0.641927 0.849612 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10782, meanQ=3.941940, numObservations: 4
action -1, numVisits=1505, meanQ=2.432389, numObservations: 1
action 0, numVisits=939, meanQ=2.393795, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285345 episodes
GETTING ACTION FROM:
action 1, numVisits=296127, meanQ=5.971277, numObservations: 4
action -1, numVisits=1505, meanQ=2.432389, numObservations: 1
action 0, numVisits=939, meanQ=2.393795, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.369842 0.661662 0.624199 0.871163 0.641927 0.849612 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=6085, meanQ=8.278550, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 298512 episodes
GETTING ACTION FROM:
action 2, numVisits=304597, meanQ=6.169179, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.369842 0.661662 0.624199 0.871163 0.641927 0.849612 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 79
Initial state: 0 0.302413 0.768424 0.609823 0.857313 0.675736 0.815744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227718 episodes
GETTING ACTION FROM:
action 1, numVisits=227602, meanQ=5.012081, numObservations: 5
action 0, numVisits=104, meanQ=4.326970, numObservations: 1
action 3, numVisits=9, meanQ=2.333333, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.302413 0.768424 0.609823 0.857313 0.675736 0.815744 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12295, meanQ=7.963794, numObservations: 3
action 3, numVisits=5, meanQ=5.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 290750 episodes
GETTING ACTION FROM:
action 2, numVisits=303010, meanQ=6.226984, numObservations: 3
action 3, numVisits=40, meanQ=5.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.302413 0.768424 0.609823 0.857313 0.675736 0.815744 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 80
Initial state: 0 0.582644 0.0398447 0.538769 0.857508 0.639502 0.891392 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222452 episodes
GETTING ACTION FROM:
action 1, numVisits=222429, meanQ=4.841086, numObservations: 4
action -1, numVisits=19, meanQ=3.218536, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.582644 0.0398447 0.538769 0.857508 0.639502 0.891392 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 81
Initial state: 0 0.422881 0.422736 0.651509 0.813003 0.580145 0.837358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225884 episodes
GETTING ACTION FROM:
action 1, numVisits=122001, meanQ=5.165064, numObservations: 5
action 3, numVisits=103770, meanQ=4.896541, numObservations: 4
action 0, numVisits=109, meanQ=4.263843, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.422881 0.422736 0.651509 0.813003 0.580145 0.837358 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11926, meanQ=8.530664, numObservations: 3
action 2, numVisits=9, meanQ=6.110011, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 281343 episodes
GETTING ACTION FROM:
action 3, numVisits=293265, meanQ=6.130706, numObservations: 5
action 2, numVisits=13, meanQ=3.922315, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.422881 0.422736 0.651509 0.813003 0.580145 0.837358 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 82
Initial state: 0 0.644908 0.843014 0.635947 0.872452 0.864728 0.0116293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220368 episodes
GETTING ACTION FROM:
action 3, numVisits=220318, meanQ=4.734173, numObservations: 4
action 0, numVisits=28, meanQ=3.420190, numObservations: 1
action 1, numVisits=12, meanQ=2.333342, numObservations: 4
action 2, numVisits=8, meanQ=0.988763, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.644908 0.843014 0.635947 0.872452 0.864728 0.0116293 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 83
Initial state: 0 0.839974 0.422605 0.541832 0.873173 0.505324 0.836259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230908 episodes
GETTING ACTION FROM:
action 2, numVisits=230780, meanQ=4.901149, numObservations: 3
action -1, numVisits=116, meanQ=4.183901, numObservations: 1
action 3, numVisits=9, meanQ=2.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.839974 0.422605 0.541832 0.873173 0.505324 0.836259 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 84
Initial state: 0 0.308987 0.592448 0.67791 0.871773 0.507095 0.842219 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226841 episodes
GETTING ACTION FROM:
action 3, numVisits=226800, meanQ=4.990926, numObservations: 3
action 1, numVisits=23, meanQ=3.418696, numObservations: 3
action 2, numVisits=14, meanQ=2.998571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.308987 0.592448 0.67791 0.871773 0.507095 0.842219 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 85
Initial state: 0 0.355134 0.829586 0.571586 0.814941 0.610318 0.89736 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160825 episodes
GETTING ACTION FROM:
action 0, numVisits=160795, meanQ=5.883856, numObservations: 3
action 1, numVisits=26, meanQ=1.914623, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.355134 0.829586 0.571586 0.814941 0.610318 0.89736 w: 1
Observation: 0 0 0.767529 0 0.734226 0 0.816895 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=58016, meanQ=7.833690, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 245655 episodes
GETTING ACTION FROM:
action 1, numVisits=303595, meanQ=5.661174, numObservations: 5
action 0, numVisits=39, meanQ=4.531125, numObservations: 1
action -1, numVisits=39, meanQ=4.508572, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.355134 0.829586 0.571586 0.814941 0.610318 0.89736 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=16971, meanQ=7.921740, numObservations: 4
action 2, numVisits=39, meanQ=6.948721, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 282550 episodes
GETTING ACTION FROM:
action 3, numVisits=299445, meanQ=6.014440, numObservations: 4
action 2, numVisits=103, meanQ=5.269127, numObservations: 4
action 1, numVisits=11, meanQ=3.180000, numObservations: 2
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.355134 0.829586 0.571586 0.814941 0.610318 0.89736 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 86
Initial state: 0 0.57276 0.883288 0.679489 0.818031 0.23792 0.422658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224359 episodes
GETTING ACTION FROM:
action 3, numVisits=215127, meanQ=4.976904, numObservations: 4
action -1, numVisits=9224, meanQ=2.970430, numObservations: 1
action 2, numVisits=5, meanQ=-1.402000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.57276 0.883288 0.679489 0.818031 0.23792 0.422658 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=27160, meanQ=8.387904, numObservations: 4
action 1, numVisits=136, meanQ=7.845517, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 284065 episodes
GETTING ACTION FROM:
action 2, numVisits=310860, meanQ=6.195413, numObservations: 4
action 1, numVisits=501, meanQ=5.881976, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.57276 0.883288 0.679489 0.818031 0.23792 0.422658 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 87
Initial state: 0 0.761048 0.0627906 0.545569 0.898035 0.508413 0.871938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231421 episodes
GETTING ACTION FROM:
action 2, numVisits=231338, meanQ=5.010692, numObservations: 3
action 0, numVisits=40, meanQ=3.904639, numObservations: 1
action 1, numVisits=40, meanQ=3.088000, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.761048 0.0627906 0.545569 0.898035 0.508413 0.871938 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 88
Initial state: 0 0.557315 0.80465 0.619735 0.871931 0.848884 0.537044 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221900 episodes
GETTING ACTION FROM:
action 1, numVisits=221893, meanQ=4.834404, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.557315 0.80465 0.619735 0.871931 0.848884 0.537044 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 89
Initial state: 0 0.595946 0.851217 0.405972 7.82144e-05 0.638453 0.877093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217998 episodes
GETTING ACTION FROM:
action 2, numVisits=213027, meanQ=4.863921, numObservations: 5
action -1, numVisits=4965, meanQ=2.742091, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.595946 0.851217 0.405972 7.82144e-05 0.638453 0.877093 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=20706, meanQ=8.416878, numObservations: 5
action 3, numVisits=6199, meanQ=8.333416, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 281802 episodes
GETTING ACTION FROM:
action 1, numVisits=254970, meanQ=6.007350, numObservations: 5
action 3, numVisits=53735, meanQ=5.990044, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.595946 0.851217 0.405972 7.82144e-05 0.638453 0.877093 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 90
Initial state: 0 0.771707 0.46241 0.524972 0.853079 0.582605 0.805013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221836 episodes
GETTING ACTION FROM:
action 1, numVisits=221718, meanQ=4.844824, numObservations: 4
action -1, numVisits=110, meanQ=4.188949, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.771707 0.46241 0.524972 0.853079 0.582605 0.805013 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 91
Initial state: 0 0.573248 0.842487 0.418328 0.862674 0.589217 0.870912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229586 episodes
GETTING ACTION FROM:
action 1, numVisits=229550, meanQ=4.936170, numObservations: 4
action 0, numVisits=18, meanQ=3.284164, numObservations: 1
action 2, numVisits=9, meanQ=2.332244, numObservations: 2
action 3, numVisits=7, meanQ=2.127143, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.573248 0.842487 0.418328 0.862674 0.589217 0.870912 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 92
Initial state: 0 0.568655 0.878535 0.56344 0.989747 0.520327 0.864901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229003 episodes
GETTING ACTION FROM:
action 2, numVisits=228930, meanQ=5.027952, numObservations: 5
action 3, numVisits=52, meanQ=3.992504, numObservations: 4
action -1, numVisits=15, meanQ=3.221293, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.568655 0.878535 0.56344 0.989747 0.520327 0.864901 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 93
Initial state: 0 0.977307 0.00170009 0.536714 0.806286 0.68121 0.844075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225516 episodes
GETTING ACTION FROM:
action 2, numVisits=225484, meanQ=4.993279, numObservations: 5
action 1, numVisits=27, meanQ=3.590007, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.977307 0.00170009 0.536714 0.806286 0.68121 0.844075 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16491, meanQ=5.608562, numObservations: 3
action 1, numVisits=17, meanQ=3.805882, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 265580 episodes
GETTING ACTION FROM:
action 2, numVisits=282066, meanQ=5.192918, numObservations: 3
action 1, numVisits=20, meanQ=3.585000, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.977307 0.00170009 0.536714 0.806286 0.68121 0.844075 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 94
Initial state: 0 0.583826 0.897399 0.827931 0.213589 0.65437 0.894844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220325 episodes
GETTING ACTION FROM:
action 3, numVisits=220285, meanQ=4.800899, numObservations: 4
action -1, numVisits=36, meanQ=3.517218, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.583826 0.897399 0.827931 0.213589 0.65437 0.894844 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9320, meanQ=4.455750, numObservations: 4
action 0, numVisits=7242, meanQ=0.694407, numObservations: 1
action 1, numVisits=9, meanQ=-1.670000, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
Sampled 279851 episodes
GETTING ACTION FROM:
action 2, numVisits=289171, meanQ=5.842152, numObservations: 4
action 0, numVisits=7242, meanQ=0.694407, numObservations: 1
action 1, numVisits=9, meanQ=-1.670000, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 2
Next state: 2 0.583826 0.897399 0.827931 0.213589 0.65437 0.894844 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 95
Initial state: 0 0.566798 0.868316 0.541791 0.8131 0.675446 0.508911 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224288 episodes
GETTING ACTION FROM:
action 3, numVisits=224228, meanQ=4.856027, numObservations: 4
action -1, numVisits=31, meanQ=3.590699, numObservations: 1
action 2, numVisits=25, meanQ=2.196008, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.566798 0.868316 0.541791 0.8131 0.675446 0.508911 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=12190, meanQ=5.889672, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 280677 episodes
GETTING ACTION FROM:
action 1, numVisits=271568, meanQ=6.032007, numObservations: 5
action -1, numVisits=21299, meanQ=3.260623, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.566798 0.868316 0.541791 0.8131 0.675446 0.508911 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 96
Initial state: 0 0.723717 0.601587 0.569891 0.818348 0.680683 0.833933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230135 episodes
GETTING ACTION FROM:
action 1, numVisits=230107, meanQ=5.097585, numObservations: 4
action 0, numVisits=23, meanQ=3.596737, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.723717 0.601587 0.569891 0.818348 0.680683 0.833933 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 97
Initial state: 0 0.601729 0.896354 0.874965 0.708631 0.656959 0.849442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221575 episodes
GETTING ACTION FROM:
action 3, numVisits=221477, meanQ=4.879841, numObservations: 5
action 1, numVisits=89, meanQ=4.109104, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.601729 0.896354 0.874965 0.708631 0.656959 0.849442 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 98
Initial state: 0 0.664519 0.842576 0.588791 0.804233 0.550872 0.861639 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230234 episodes
GETTING ACTION FROM:
action 2, numVisits=230216, meanQ=4.966226, numObservations: 3
action 3, numVisits=10, meanQ=2.189000, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.664519 0.842576 0.588791 0.804233 0.550872 0.861639 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 99
Initial state: 0 0.562386 0.862622 0.511023 0.893702 0.548144 0.427336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230092 episodes
GETTING ACTION FROM:
action 2, numVisits=229935, meanQ=4.962025, numObservations: 4
action 3, numVisits=107, meanQ=4.256451, numObservations: 5
action -1, numVisits=30, meanQ=3.641378, numObservations: 1
action 0, numVisits=16, meanQ=3.144355, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action: 2
Next state: 1 0.562386 0.862622 0.511023 0.893702 0.548144 0.427336 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 100
Initial state: 0 0.587414 0.845559 0.617146 0.794279 0.51537 0.890115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223924 episodes
GETTING ACTION FROM:
action 3, numVisits=223849, meanQ=4.934096, numObservations: 5
action 0, numVisits=39, meanQ=3.790031, numObservations: 1
action -1, numVisits=30, meanQ=3.653521, numObservations: 1
action 2, numVisits=5, meanQ=1.780000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.587414 0.845559 0.617146 0.794279 0.51537 0.890115 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 101
Initial state: 0 0.548339 0.865777 0.890167 0.772504 0.54873 0.813946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229021 episodes
GETTING ACTION FROM:
action 2, numVisits=229015, meanQ=4.919080, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.548339 0.865777 0.890167 0.772504 0.54873 0.813946 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 102
Initial state: 0 0.844242 0.696633 0.592459 0.863375 0.598934 0.847399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229114 episodes
GETTING ACTION FROM:
action 1, numVisits=229076, meanQ=4.982836, numObservations: 4
action 0, numVisits=34, meanQ=3.706058, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.844242 0.696633 0.592459 0.863375 0.598934 0.847399 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 103
Initial state: 0 0.378896 0.352976 0.616563 0.824959 0.508742 0.857997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161721 episodes
GETTING ACTION FROM:
action 0, numVisits=161716, meanQ=5.396166, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.378896 0.352976 0.616563 0.824959 0.508742 0.857997 w: 1
Observation: 0 0 0.317254 0 0.875985 0 0.900758 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=52122, meanQ=7.085574, numObservations: 3
action 2, numVisits=15, meanQ=4.992000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 250780 episodes
GETTING ACTION FROM:
action 3, numVisits=302859, meanQ=5.296587, numObservations: 3
action 0, numVisits=31, meanQ=4.023949, numObservations: 1
action 2, numVisits=27, meanQ=3.807781, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.378896 0.352976 0.616563 0.824959 0.508742 0.857997 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 104
Initial state: 0 0.533993 0.874245 0.616994 0.80115 0.16365 0.537868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225931 episodes
GETTING ACTION FROM:
action 2, numVisits=225911, meanQ=4.897093, numObservations: 4
action 3, numVisits=11, meanQ=1.907282, numObservations: 4
action 1, numVisits=5, meanQ=0.602040, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.533993 0.874245 0.616994 0.80115 0.16365 0.537868 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 105
Initial state: 0 0.566169 0.853471 0.576653 0.895919 0.986283 0.964757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225498 episodes
GETTING ACTION FROM:
action 1, numVisits=225480, meanQ=4.891459, numObservations: 5
action 3, numVisits=13, meanQ=1.922308, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.566169 0.853471 0.576653 0.895919 0.986283 0.964757 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 106
Initial state: 0 0.582359 0.398643 0.679459 0.806417 0.577423 0.826281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225311 episodes
GETTING ACTION FROM:
action 1, numVisits=225212, meanQ=4.932207, numObservations: 5
action 3, numVisits=91, meanQ=3.538763, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.582359 0.398643 0.679459 0.806417 0.577423 0.826281 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 107
Initial state: 0 0.620874 0.38784 0.628049 0.816661 0.568698 0.877156 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163316 episodes
GETTING ACTION FROM:
action 0, numVisits=157230, meanQ=5.859153, numObservations: 3
action 1, numVisits=5966, meanQ=4.809849, numObservations: 3
action -1, numVisits=118, meanQ=4.349027, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.620874 0.38784 0.628049 0.816661 0.568698 0.877156 w: 1
Observation: 0 0 0.327892 0 0.820012 0 0.852946 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=49561, meanQ=8.077847, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 249575 episodes
GETTING ACTION FROM:
action 2, numVisits=299086, meanQ=5.539919, numObservations: 4
action 0, numVisits=50, meanQ=4.543530, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.620874 0.38784 0.628049 0.816661 0.568698 0.877156 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 108
Initial state: 0 0.5178 0.860214 0.582546 0.534046 0.556174 0.87162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226304 episodes
GETTING ACTION FROM:
action 1, numVisits=226277, meanQ=5.105670, numObservations: 5
action -1, numVisits=23, meanQ=3.634709, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.5178 0.860214 0.582546 0.534046 0.556174 0.87162 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 109
Initial state: 0 0.669152 0.390431 0.620371 0.887282 0.668621 0.80444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227628 episodes
GETTING ACTION FROM:
action 2, numVisits=226445, meanQ=5.114855, numObservations: 4
action -1, numVisits=1178, meanQ=2.851146, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.669152 0.390431 0.620371 0.887282 0.668621 0.80444 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 110
Initial state: 0 0.608823 0.882992 0.97409 0.014198 0.601947 0.827033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155267 episodes
GETTING ACTION FROM:
action 0, numVisits=155255, meanQ=2.932902, numObservations: 1
action 1, numVisits=8, meanQ=-0.512500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.608823 0.882992 0.97409 0.014198 0.601947 0.827033 w: 1
Observation: 0 0 0.980294 0 0.0974806 0 0.750211 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=155218, meanQ=4.975072, numObservations: 5
action 0, numVisits=32, meanQ=3.715126, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 246676 episodes
GETTING ACTION FROM:
action 3, numVisits=401894, meanQ=5.149721, numObservations: 5
action 0, numVisits=32, meanQ=3.715126, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.608823 0.882992 0.97409 0.014198 0.601947 0.827033 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 111
Initial state: 0 0.643332 0.877519 0.648974 0.867579 0.0915545 0.264785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231198 episodes
GETTING ACTION FROM:
action 1, numVisits=227827, meanQ=5.012923, numObservations: 3
action -1, numVisits=3366, meanQ=2.932509, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.643332 0.877519 0.648974 0.867579 0.0915545 0.264785 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 112
Initial state: 0 0.55926 0.884362 0.449301 0.61895 0.692742 0.822947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224561 episodes
GETTING ACTION FROM:
action 2, numVisits=224555, meanQ=4.927442, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.55926 0.884362 0.449301 0.61895 0.692742 0.822947 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13771, meanQ=8.546751, numObservations: 3
action 1, numVisits=8054, meanQ=8.497288, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 281681 episodes
GETTING ACTION FROM:
action 3, numVisits=251334, meanQ=6.108868, numObservations: 5
action 1, numVisits=52172, meanQ=6.091451, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.55926 0.884362 0.449301 0.61895 0.692742 0.822947 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2517, meanQ=7.799495, numObservations: 4
action 1, numVisits=3081, meanQ=7.335564, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 292257 episodes
GETTING ACTION FROM:
action 3, numVisits=194309, meanQ=5.839833, numObservations: 4
action 1, numVisits=103544, meanQ=5.833231, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.55926 0.884362 0.449301 0.61895 0.692742 0.822947 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 113
Initial state: 0 0.0314367 0.687624 0.515427 0.865043 0.601318 0.813677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225648 episodes
GETTING ACTION FROM:
action 2, numVisits=225633, meanQ=4.968387, numObservations: 5
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.0314367 0.687624 0.515427 0.865043 0.601318 0.813677 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 114
Initial state: 0 0.50607 0.800649 0.125159 0.13293 0.673257 0.80553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226757 episodes
GETTING ACTION FROM:
action 2, numVisits=226726, meanQ=4.976920, numObservations: 5
action 1, numVisits=23, meanQ=0.386974, numObservations: 4
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.50607 0.800649 0.125159 0.13293 0.673257 0.80553 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=22573, meanQ=8.385914, numObservations: 5
action 3, numVisits=6254, meanQ=8.335320, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 282119 episodes
GETTING ACTION FROM:
action 3, numVisits=152462, meanQ=6.208947, numObservations: 4
action 1, numVisits=158484, meanQ=6.208312, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.50607 0.800649 0.125159 0.13293 0.673257 0.80553 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1750, meanQ=7.294698, numObservations: 3
action 1, numVisits=1257, meanQ=7.257465, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 295842 episodes
GETTING ACTION FROM:
action 1, numVisits=285661, meanQ=6.048285, numObservations: 3
action 3, numVisits=13186, meanQ=5.997415, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.50607 0.800649 0.125159 0.13293 0.673257 0.80553 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 115
Initial state: 0 0.193262 0.776933 0.536044 0.851051 0.60491 0.806699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226474 episodes
GETTING ACTION FROM:
action 3, numVisits=226238, meanQ=4.903897, numObservations: 5
action -1, numVisits=223, meanQ=4.441639, numObservations: 1
action 2, numVisits=10, meanQ=2.209000, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.193262 0.776933 0.536044 0.851051 0.60491 0.806699 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 116
Initial state: 0 0.699652 0.827617 0.611872 0.83067 0.719905 0.144129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226458 episodes
GETTING ACTION FROM:
action 3, numVisits=226388, meanQ=4.987332, numObservations: 5
action 0, numVisits=35, meanQ=3.803502, numObservations: 1
action -1, numVisits=33, meanQ=3.763153, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.699652 0.827617 0.611872 0.83067 0.719905 0.144129 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 117
Initial state: 0 0.14739 0.328981 0.668311 0.83508 0.538453 0.866807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 232335 episodes
GETTING ACTION FROM:
action 1, numVisits=232329, meanQ=4.998820, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.14739 0.328981 0.668311 0.83508 0.538453 0.866807 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=35264, meanQ=8.319446, numObservations: 5
action 3, numVisits=8, meanQ=5.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282499 episodes
GETTING ACTION FROM:
action 2, numVisits=317530, meanQ=6.019327, numObservations: 5
action 3, numVisits=239, meanQ=5.533181, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.14739 0.328981 0.668311 0.83508 0.538453 0.866807 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 118
Initial state: 0 0.255253 0.988908 0.693875 0.898708 0.567288 0.817199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227972 episodes
GETTING ACTION FROM:
action 1, numVisits=227874, meanQ=4.873263, numObservations: 4
action 0, numVisits=63, meanQ=3.996065, numObservations: 1
action 3, numVisits=29, meanQ=2.508286, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.255253 0.988908 0.693875 0.898708 0.567288 0.817199 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 119
Initial state: 0 0.68286 0.823158 0.186395 0.63221 0.513225 0.848315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228856 episodes
GETTING ACTION FROM:
action 1, numVisits=228797, meanQ=4.986770, numObservations: 4
action -1, numVisits=36, meanQ=3.797379, numObservations: 1
action 2, numVisits=20, meanQ=3.195005, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.68286 0.823158 0.186395 0.63221 0.513225 0.848315 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 120
Initial state: 0 0.00566486 0.368781 0.552452 0.89672 0.606013 0.860442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 232600 episodes
GETTING ACTION FROM:
action 1, numVisits=232483, meanQ=5.001100, numObservations: 3
action 0, numVisits=46, meanQ=3.963789, numObservations: 1
action -1, numVisits=31, meanQ=3.737195, numObservations: 1
action 2, numVisits=39, meanQ=3.458974, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.00566486 0.368781 0.552452 0.89672 0.606013 0.860442 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=35265, meanQ=8.315787, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289039 episodes
GETTING ACTION FROM:
action 3, numVisits=324302, meanQ=6.027068, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.00566486 0.368781 0.552452 0.89672 0.606013 0.860442 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 121
Initial state: 0 0.641984 0.81575 0.58884 0.899728 0.565338 0.117604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225543 episodes
GETTING ACTION FROM:
action 3, numVisits=225475, meanQ=4.905881, numObservations: 5
action 0, numVisits=64, meanQ=4.041103, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.641984 0.81575 0.58884 0.899728 0.565338 0.117604 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 122
Initial state: 0 0.662803 0.833935 0.894599 0.413462 0.533082 0.893464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224192 episodes
GETTING ACTION FROM:
action 2, numVisits=224022, meanQ=4.979793, numObservations: 5
action -1, numVisits=158, meanQ=4.429794, numObservations: 1
action 3, numVisits=9, meanQ=1.665567, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.662803 0.833935 0.894599 0.413462 0.533082 0.893464 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 123
Initial state: 0 0.963753 0.101779 0.592486 0.811361 0.636754 0.833852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225791 episodes
GETTING ACTION FROM:
action 2, numVisits=225785, meanQ=4.883631, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.963753 0.101779 0.592486 0.811361 0.636754 0.833852 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 124
Initial state: 0 0.633465 0.865903 0.72339 0.823403 0.572624 0.816783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225340 episodes
GETTING ACTION FROM:
action 3, numVisits=225328, meanQ=4.976247, numObservations: 4
action 2, numVisits=7, meanQ=2.155714, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.633465 0.865903 0.72339 0.823403 0.572624 0.816783 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 125
Initial state: 0 0.595265 0.890991 0.665647 0.857171 0.427535 0.463012 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229047 episodes
GETTING ACTION FROM:
action 2, numVisits=229034, meanQ=4.925367, numObservations: 4
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.595265 0.890991 0.665647 0.857171 0.427535 0.463012 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 126
Initial state: 0 0.445397 0.0565051 0.662865 0.879139 0.613241 0.86421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224407 episodes
GETTING ACTION FROM:
action 3, numVisits=223688, meanQ=4.920790, numObservations: 5
action 0, numVisits=714, meanQ=2.629389, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.445397 0.0565051 0.662865 0.879139 0.613241 0.86421 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 127
Initial state: 0 0.698294 0.830155 0.6196 0.828689 0.187279 0.434905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229105 episodes
GETTING ACTION FROM:
action 1, numVisits=229092, meanQ=4.978560, numObservations: 4
action 2, numVisits=7, meanQ=-0.145714, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.698294 0.830155 0.6196 0.828689 0.187279 0.434905 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 128
Initial state: 0 0.932366 0.884163 0.595994 0.842023 0.588109 0.836471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227868 episodes
GETTING ACTION FROM:
action 2, numVisits=227842, meanQ=4.969227, numObservations: 4
action 0, numVisits=19, meanQ=3.321801, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.932366 0.884163 0.595994 0.842023 0.588109 0.836471 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 129
Initial state: 0 0.59558 0.831132 0.600664 0.131175 0.629525 0.836065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226373 episodes
GETTING ACTION FROM:
action 2, numVisits=226362, meanQ=4.888341, numObservations: 4
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.59558 0.831132 0.600664 0.131175 0.629525 0.836065 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 130
Initial state: 0 0.466128 0.792984 0.672982 0.861712 0.57286 0.842498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228042 episodes
GETTING ACTION FROM:
action 3, numVisits=228002, meanQ=4.893305, numObservations: 4
action -1, numVisits=23, meanQ=3.417172, numObservations: 1
action 1, numVisits=10, meanQ=1.780000, numObservations: 2
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.466128 0.792984 0.672982 0.861712 0.57286 0.842498 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 131
Initial state: 0 0.952522 0.0298635 0.60119 0.804316 0.649181 0.899255 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154908 episodes
GETTING ACTION FROM:
action 0, numVisits=154887, meanQ=2.820260, numObservations: 1
action 1, numVisits=9, meanQ=0.110022, numObservations: 2
action 3, numVisits=8, meanQ=-1.502500, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.952522 0.0298635 0.60119 0.804316 0.649181 0.899255 w: 1
Observation: 0 0 0 0 0.885417 0 0.823602 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=154795, meanQ=4.903362, numObservations: 5
action 0, numVisits=87, meanQ=4.161208, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 245251 episodes
GETTING ACTION FROM:
action 3, numVisits=400032, meanQ=4.792758, numObservations: 5
action 0, numVisits=101, meanQ=4.085278, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.952522 0.0298635 0.60119 0.804316 0.649181 0.899255 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 132
Initial state: 0 0.393421 0.00129192 0.650837 0.854967 0.589716 0.885999 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223888 episodes
GETTING ACTION FROM:
action 2, numVisits=223837, meanQ=4.758721, numObservations: 3
action -1, numVisits=47, meanQ=3.736047, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.393421 0.00129192 0.650837 0.854967 0.589716 0.885999 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 133
Initial state: 0 0.0144918 0.0372108 0.564231 0.811375 0.508301 0.853505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227049 episodes
GETTING ACTION FROM:
action 1, numVisits=227001, meanQ=4.970906, numObservations: 5
action 0, numVisits=41, meanQ=3.863308, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0144918 0.0372108 0.564231 0.811375 0.508301 0.853505 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=20741, meanQ=8.530902, numObservations: 3
action 2, numVisits=1486, meanQ=8.409847, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 283499 episodes
GETTING ACTION FROM:
action 3, numVisits=197861, meanQ=6.081847, numObservations: 5
action 2, numVisits=107865, meanQ=6.081393, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.0144918 0.0372108 0.564231 0.811375 0.508301 0.853505 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=4416, meanQ=7.568726, numObservations: 3
action 3, numVisits=538, meanQ=7.396619, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 297252 episodes
GETTING ACTION FROM:
action 2, numVisits=295655, meanQ=6.195159, numObservations: 3
action 3, numVisits=6551, meanQ=6.116286, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0144918 0.0372108 0.564231 0.811375 0.508301 0.853505 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 134
Initial state: 0 0.660652 0.874165 0.327427 0.395278 0.532395 0.878653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224172 episodes
GETTING ACTION FROM:
action 3, numVisits=218898, meanQ=4.961837, numObservations: 5
action -1, numVisits=5265, meanQ=2.764404, numObservations: 1
action 1, numVisits=5, meanQ=-1.402000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.660652 0.874165 0.327427 0.395278 0.532395 0.878653 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 135
Initial state: 0 0.656942 0.87228 0.63722 0.841128 0.971634 0.142297 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223600 episodes
GETTING ACTION FROM:
action 2, numVisits=219884, meanQ=4.879259, numObservations: 4
action 0, numVisits=3712, meanQ=2.960727, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.656942 0.87228 0.63722 0.841128 0.971634 0.142297 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 136
Initial state: 0 0.197401 0.122216 0.698017 0.840963 0.566121 0.877624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227264 episodes
GETTING ACTION FROM:
action 1, numVisits=227258, meanQ=4.852906, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.197401 0.122216 0.698017 0.840963 0.566121 0.877624 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=28917, meanQ=8.345816, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282201 episodes
GETTING ACTION FROM:
action 2, numVisits=310847, meanQ=6.237328, numObservations: 5
action 3, numVisits=273, meanQ=5.818938, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.197401 0.122216 0.698017 0.840963 0.566121 0.877624 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 137
Initial state: 0 0.923561 0.492465 0.662362 0.880354 0.500411 0.895327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228710 episodes
GETTING ACTION FROM:
action 2, numVisits=228637, meanQ=5.009945, numObservations: 5
action -1, numVisits=69, meanQ=4.167763, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.923561 0.492465 0.662362 0.880354 0.500411 0.895327 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 138
Initial state: 0 0.518327 0.838675 0.607498 0.844745 0.348213 0.30735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224092 episodes
GETTING ACTION FROM:
action 1, numVisits=224067, meanQ=4.953429, numObservations: 5
action 0, numVisits=17, meanQ=3.069072, numObservations: 1
action 2, numVisits=5, meanQ=1.000020, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.518327 0.838675 0.607498 0.844745 0.348213 0.30735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 139
Initial state: 0 0.659068 0.854848 0.645059 0.81677 0.737254 0.180236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219256 episodes
GETTING ACTION FROM:
action 2, numVisits=219209, meanQ=4.986053, numObservations: 5
action 0, numVisits=43, meanQ=3.891805, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.659068 0.854848 0.645059 0.81677 0.737254 0.180236 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 140
Initial state: 0 0.658812 0.86274 0.0609949 0.318071 0.663036 0.849205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154661 episodes
GETTING ACTION FROM:
action 0, numVisits=154655, meanQ=2.921084, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.658812 0.86274 0.0609949 0.318071 0.663036 0.849205 w: 1
Observation: 0 0 0.85816 0 0.386957 0 0.86577 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=154639, meanQ=5.002862, numObservations: 4
action 1, numVisits=9, meanQ=1.886667, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 244600 episodes
GETTING ACTION FROM:
action 2, numVisits=399239, meanQ=4.693756, numObservations: 4
action 1, numVisits=9, meanQ=1.886667, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.658812 0.86274 0.0609949 0.318071 0.663036 0.849205 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=55400, meanQ=8.402948, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284617 episodes
GETTING ACTION FROM:
action 3, numVisits=340017, meanQ=6.300899, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.658812 0.86274 0.0609949 0.318071 0.663036 0.849205 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 141
Initial state: 0 0.638463 0.891443 0.506446 0.884057 0.350412 0.941222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229057 episodes
GETTING ACTION FROM:
action 2, numVisits=229018, meanQ=4.980799, numObservations: 4
action 0, numVisits=32, meanQ=3.618402, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.638463 0.891443 0.506446 0.884057 0.350412 0.941222 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 142
Initial state: 0 0.278152 0.797831 0.506266 0.814891 0.683139 0.881754 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228708 episodes
GETTING ACTION FROM:
action 3, numVisits=228699, meanQ=4.862079, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.278152 0.797831 0.506266 0.814891 0.683139 0.881754 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 143
Initial state: 0 0.753039 0.961114 0.612696 0.82074 0.606049 0.88026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226060 episodes
GETTING ACTION FROM:
action 3, numVisits=226038, meanQ=4.953196, numObservations: 5
action 2, numVisits=9, meanQ=2.121122, numObservations: 2
action 1, numVisits=9, meanQ=1.886667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.753039 0.961114 0.612696 0.82074 0.606049 0.88026 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 144
Initial state: 0 0.56311 0.812936 0.97589 0.0345281 0.691592 0.884004 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219821 episodes
GETTING ACTION FROM:
action 1, numVisits=219814, meanQ=4.864020, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.56311 0.812936 0.97589 0.0345281 0.691592 0.884004 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 145
Initial state: 0 0.620751 0.846793 0.735502 0.938533 0.642523 0.866225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227095 episodes
GETTING ACTION FROM:
action 1, numVisits=227087, meanQ=4.910676, numObservations: 4
action -1, numVisits=4, meanQ=-2.502425, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.620751 0.846793 0.735502 0.938533 0.642523 0.866225 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 146
Initial state: 0 0.957266 0.662551 0.673045 0.810804 0.55162 0.883865 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230924 episodes
GETTING ACTION FROM:
action 3, numVisits=230916, meanQ=5.013556, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.957266 0.662551 0.673045 0.810804 0.55162 0.883865 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 147
Initial state: 0 0.552466 0.896975 0.626981 0.467701 0.504242 0.896235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225521 episodes
GETTING ACTION FROM:
action 2, numVisits=225513, meanQ=4.967516, numObservations: 5
action 1, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.552466 0.896975 0.626981 0.467701 0.504242 0.896235 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 148
Initial state: 0 0.643487 0.853823 0.766698 0.332868 0.671173 0.849945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219138 episodes
GETTING ACTION FROM:
action 2, numVisits=219132, meanQ=4.739191, numObservations: 5
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.643487 0.853823 0.766698 0.332868 0.671173 0.849945 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 149
Initial state: 0 0.273208 0.0328281 0.654141 0.818071 0.676049 0.809726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227796 episodes
GETTING ACTION FROM:
action 1, numVisits=227790, meanQ=4.970925, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.273208 0.0328281 0.654141 0.818071 0.676049 0.809726 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 150
Initial state: 0 0.359775 0.632646 0.654131 0.835172 0.525362 0.878634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228752 episodes
GETTING ACTION FROM:
action 3, numVisits=228707, meanQ=4.973442, numObservations: 4
action 0, numVisits=41, meanQ=3.868646, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.359775 0.632646 0.654131 0.835172 0.525362 0.878634 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 151
Initial state: 0 0.647298 0.887338 0.5807 0.874034 0.197491 0.398905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227436 episodes
GETTING ACTION FROM:
action 3, numVisits=227394, meanQ=4.899282, numObservations: 4
action 0, numVisits=35, meanQ=3.723294, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.647298 0.887338 0.5807 0.874034 0.197491 0.398905 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=23016, meanQ=8.382463, numObservations: 4
action 1, numVisits=5928, meanQ=8.323440, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286508 episodes
GETTING ACTION FROM:
action 2, numVisits=250652, meanQ=6.019959, numObservations: 4
action 1, numVisits=64798, meanQ=6.005860, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.647298 0.887338 0.5807 0.874034 0.197491 0.398905 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 152
Initial state: 0 0.34162 0.626017 0.581327 0.896696 0.526363 0.814251 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229616 episodes
GETTING ACTION FROM:
action 2, numVisits=229608, meanQ=5.000273, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.34162 0.626017 0.581327 0.896696 0.526363 0.814251 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 153
Initial state: 0 0.837806 0.563718 0.540431 0.88262 0.544197 0.893063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227334 episodes
GETTING ACTION FROM:
action 2, numVisits=227308, meanQ=4.971139, numObservations: 5
action 0, numVisits=13, meanQ=2.992423, numObservations: 1
action 1, numVisits=9, meanQ=2.333344, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.837806 0.563718 0.540431 0.88262 0.544197 0.893063 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 154
Initial state: 0 0.560973 0.83337 0.562108 0.430861 0.652317 0.888371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229633 episodes
GETTING ACTION FROM:
action 1, numVisits=227779, meanQ=5.005763, numObservations: 4
action 3, numVisits=1849, meanQ=4.848537, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.560973 0.83337 0.562108 0.430861 0.652317 0.888371 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 155
Initial state: 0 0.524127 0.874093 0.649257 0.876339 0.613034 0.208558 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224821 episodes
GETTING ACTION FROM:
action 1, numVisits=224796, meanQ=4.981779, numObservations: 5
action -1, numVisits=19, meanQ=3.332698, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.524127 0.874093 0.649257 0.876339 0.613034 0.208558 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 156
Initial state: 0 0.593354 0.880195 0.847942 0.0185575 0.629669 0.877436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229512 episodes
GETTING ACTION FROM:
action 3, numVisits=229504, meanQ=5.106620, numObservations: 4
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.593354 0.880195 0.847942 0.0185575 0.629669 0.877436 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 157
Initial state: 0 0.310527 0.833863 0.598704 0.847905 0.530865 0.829086 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228973 episodes
GETTING ACTION FROM:
action 2, numVisits=228967, meanQ=4.917565, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.310527 0.833863 0.598704 0.847905 0.530865 0.829086 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 158
Initial state: 0 0.501644 0.803076 0.525698 0.805524 0.543242 0.600021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226851 episodes
GETTING ACTION FROM:
action 1, numVisits=226800, meanQ=4.902283, numObservations: 5
action 0, numVisits=47, meanQ=3.872476, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.501644 0.803076 0.525698 0.805524 0.543242 0.600021 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 159
Initial state: 0 0.942178 0.282417 0.625726 0.862781 0.542782 0.803853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226107 episodes
GETTING ACTION FROM:
action 3, numVisits=226019, meanQ=4.932997, numObservations: 5
action -1, numVisits=72, meanQ=4.101909, numObservations: 1
action 1, numVisits=13, meanQ=2.846162, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.942178 0.282417 0.625726 0.862781 0.542782 0.803853 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 160
Initial state: 0 0.0460591 0.470586 0.652603 0.883597 0.632178 0.89388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228073 episodes
GETTING ACTION FROM:
action 1, numVisits=228008, meanQ=4.880851, numObservations: 4
action -1, numVisits=58, meanQ=3.880062, numObservations: 1
action 3, numVisits=4, meanQ=-0.007500, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0460591 0.470586 0.652603 0.883597 0.632178 0.89388 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=34544, meanQ=8.320983, numObservations: 3
action 2, numVisits=6, meanQ=4.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289428 episodes
GETTING ACTION FROM:
action 3, numVisits=323950, meanQ=6.250163, numObservations: 3
action 2, numVisits=28, meanQ=4.710000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0460591 0.470586 0.652603 0.883597 0.632178 0.89388 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 161
Initial state: 0 0.697803 0.868544 0.673784 0.865697 0.373049 0.624414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228030 episodes
GETTING ACTION FROM:
action 1, numVisits=202405, meanQ=4.990648, numObservations: 5
action 2, numVisits=25401, meanQ=4.957921, numObservations: 4
action -1, numVisits=216, meanQ=4.311622, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.697803 0.868544 0.673784 0.865697 0.373049 0.624414 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 162
Initial state: 0 0.0368165 0.411731 0.511847 0.883421 0.590035 0.890256 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226928 episodes
GETTING ACTION FROM:
action 1, numVisits=225239, meanQ=5.002863, numObservations: 5
action 2, numVisits=1598, meanQ=4.841772, numObservations: 3
action -1, numVisits=43, meanQ=3.940848, numObservations: 1
action 0, numVisits=41, meanQ=3.871153, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action: 1
Next state: 0 0.0368165 0.411731 0.511847 0.883421 0.590035 0.890256 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=27998, meanQ=8.411063, numObservations: 5
action 2, numVisits=506, meanQ=8.157351, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 281165 episodes
GETTING ACTION FROM:
action 3, numVisits=299107, meanQ=6.065718, numObservations: 5
action 2, numVisits=10560, meanQ=6.013977, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0368165 0.411731 0.511847 0.883421 0.590035 0.890256 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 163
Initial state: 0 0.504269 0.802915 0.541077 0.81036 0.915944 0.510051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229644 episodes
GETTING ACTION FROM:
action 2, numVisits=229514, meanQ=4.991568, numObservations: 4
action -1, numVisits=125, meanQ=2.424977, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.504269 0.802915 0.541077 0.81036 0.915944 0.510051 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 164
Initial state: 0 0.643673 0.828015 0.373047 0.767087 0.541422 0.876783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226432 episodes
GETTING ACTION FROM:
action 1, numVisits=226426, meanQ=4.954777, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.643673 0.828015 0.373047 0.767087 0.541422 0.876783 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 165
Initial state: 0 0.213408 0.131429 0.561846 0.803273 0.595873 0.87099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230030 episodes
GETTING ACTION FROM:
action 1, numVisits=228772, meanQ=4.994858, numObservations: 4
action 2, numVisits=1195, meanQ=4.797099, numObservations: 4
action -1, numVisits=59, meanQ=4.090316, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.213408 0.131429 0.561846 0.803273 0.595873 0.87099 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=32282, meanQ=8.312094, numObservations: 4
action 3, numVisits=2710, meanQ=8.221565, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 281736 episodes
GETTING ACTION FROM:
action 2, numVisits=299975, meanQ=6.068598, numObservations: 4
action 3, numVisits=16751, meanQ=6.025552, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.213408 0.131429 0.561846 0.803273 0.595873 0.87099 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 166
Initial state: 0 0.323583 0.130176 0.519209 0.849697 0.574883 0.889397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223699 episodes
GETTING ACTION FROM:
action 2, numVisits=216928, meanQ=4.972333, numObservations: 4
action 0, numVisits=6757, meanQ=2.857609, numObservations: 1
action 1, numVisits=11, meanQ=0.990000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.323583 0.130176 0.519209 0.849697 0.574883 0.889397 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 167
Initial state: 0 0.685348 0.863153 0.619134 0.884768 0.0588999 0.753784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224797 episodes
GETTING ACTION FROM:
action 3, numVisits=224756, meanQ=4.908800, numObservations: 5
action 0, numVisits=37, meanQ=3.725953, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.685348 0.863153 0.619134 0.884768 0.0588999 0.753784 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 168
Initial state: 0 0.446566 0.929769 0.698752 0.8409 0.520612 0.876897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229455 episodes
GETTING ACTION FROM:
action 3, numVisits=229410, meanQ=4.924460, numObservations: 4
action -1, numVisits=36, meanQ=3.747595, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.446566 0.929769 0.698752 0.8409 0.520612 0.876897 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 169
Initial state: 0 0.627355 0.82995 0.539665 0.845028 0.281405 0.554005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225544 episodes
GETTING ACTION FROM:
action 2, numVisits=225507, meanQ=4.903812, numObservations: 5
action 0, numVisits=26, meanQ=3.523663, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.627355 0.82995 0.539665 0.845028 0.281405 0.554005 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16650, meanQ=4.575228, numObservations: 4
action -1, numVisits=79, meanQ=3.840694, numObservations: 1
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286581 episodes
GETTING ACTION FROM:
action 1, numVisits=303231, meanQ=5.564236, numObservations: 4
action -1, numVisits=79, meanQ=3.840694, numObservations: 1
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.627355 0.82995 0.539665 0.845028 0.281405 0.554005 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 170
Initial state: 0 0.547335 0.823136 0.66538 0.825159 0.757998 0.0152617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162251 episodes
GETTING ACTION FROM:
action 0, numVisits=157839, meanQ=5.747814, numObservations: 3
action 2, numVisits=4379, meanQ=4.694288, numObservations: 5
action -1, numVisits=27, meanQ=3.558983, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 0
Next state: 0 0.547335 0.823136 0.66538 0.825159 0.757998 0.0152617 w: 1
Observation: 0 0 0.847421 0 0.797944 0 0.0671427 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=42167, meanQ=8.282725, numObservations: 5
action 2, numVisits=19, meanQ=6.683158, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 245428 episodes
GETTING ACTION FROM:
action 1, numVisits=286735, meanQ=5.324897, numObservations: 5
action 2, numVisits=736, meanQ=5.073239, numObservations: 4
action -1, numVisits=80, meanQ=4.537768, numObservations: 1
action 0, numVisits=65, meanQ=4.457577, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.547335 0.823136 0.66538 0.825159 0.757998 0.0152617 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 171
Initial state: 0 0.508844 0.835948 0.632173 0.815607 0.566696 0.767946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156049 episodes
GETTING ACTION FROM:
action 0, numVisits=156003, meanQ=2.856051, numObservations: 1
action -1, numVisits=42, meanQ=0.402026, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.508844 0.835948 0.632173 0.815607 0.566696 0.767946 w: 1
Observation: 0 0 0.857572 0 0.840703 0 0.755933 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=152683, meanQ=4.934947, numObservations: 4
action -1, numVisits=3308, meanQ=2.927849, numObservations: 1
action 3, numVisits=8, meanQ=0.486250, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 247870 episodes
GETTING ACTION FROM:
action 2, numVisits=400553, meanQ=4.808298, numObservations: 4
action -1, numVisits=3308, meanQ=2.927849, numObservations: 1
action 3, numVisits=8, meanQ=0.486250, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.508844 0.835948 0.632173 0.815607 0.566696 0.767946 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 172
Initial state: 0 0.763431 0.368162 0.692047 0.841138 0.511086 0.840172 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227281 episodes
GETTING ACTION FROM:
action 1, numVisits=227274, meanQ=5.004461, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.763431 0.368162 0.692047 0.841138 0.511086 0.840172 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 173
Initial state: 0 0.883617 0.545095 0.676658 0.889047 0.623985 0.873371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228481 episodes
GETTING ACTION FROM:
action 1, numVisits=228458, meanQ=4.898746, numObservations: 4
action 2, numVisits=14, meanQ=3.007864, numObservations: 3
action 3, numVisits=5, meanQ=0.196000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.883617 0.545095 0.676658 0.889047 0.623985 0.873371 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 174
Initial state: 0 0.48125 0.167888 0.652393 0.848216 0.534792 0.81423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230752 episodes
GETTING ACTION FROM:
action 1, numVisits=230695, meanQ=4.936918, numObservations: 3
action 0, numVisits=23, meanQ=3.472955, numObservations: 1
action 2, numVisits=28, meanQ=3.356432, numObservations: 3
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.48125 0.167888 0.652393 0.848216 0.534792 0.81423 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=35112, meanQ=8.275394, numObservations: 4
action 3, numVisits=47, meanQ=7.285745, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287835 episodes
GETTING ACTION FROM:
action 2, numVisits=322837, meanQ=6.395297, numObservations: 4
action 3, numVisits=157, meanQ=5.811594, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.48125 0.167888 0.652393 0.848216 0.534792 0.81423 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 175
Initial state: 0 0.799378 0.613877 0.698609 0.881695 0.536713 0.865648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226851 episodes
GETTING ACTION FROM:
action 1, numVisits=219846, meanQ=4.982162, numObservations: 5
action 2, numVisits=6896, meanQ=4.895166, numObservations: 3
action 0, numVisits=89, meanQ=4.240349, numObservations: 1
action -1, numVisits=19, meanQ=3.315327, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.799378 0.613877 0.698609 0.881695 0.536713 0.865648 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 176
Initial state: 0 0.756003 0.0665728 0.53342 0.882635 0.684462 0.850768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221942 episodes
GETTING ACTION FROM:
action 3, numVisits=207699, meanQ=4.984548, numObservations: 4
action -1, numVisits=14234, meanQ=3.123329, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.756003 0.0665728 0.53342 0.882635 0.684462 0.850768 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 177
Initial state: 0 0.590967 0.823713 0.641201 0.896041 0.122308 0.749091 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227206 episodes
GETTING ACTION FROM:
action 2, numVisits=226559, meanQ=4.903820, numObservations: 5
action 3, numVisits=642, meanQ=4.575951, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.590967 0.823713 0.641201 0.896041 0.122308 0.749091 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 178
Initial state: 0 0.122275 0.772558 0.605319 0.886331 0.577704 0.848188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220214 episodes
GETTING ACTION FROM:
action 1, numVisits=220162, meanQ=4.899020, numObservations: 3
action -1, numVisits=42, meanQ=3.805303, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action 3, numVisits=3, meanQ=-2.966667, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.122275 0.772558 0.605319 0.886331 0.577704 0.848188 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=33252, meanQ=8.303120, numObservations: 5
action 2, numVisits=18, meanQ=6.771111, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 281377 episodes
GETTING ACTION FROM:
action 3, numVisits=314578, meanQ=6.092426, numObservations: 5
action 2, numVisits=66, meanQ=5.117879, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.122275 0.772558 0.605319 0.886331 0.577704 0.848188 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 179
Initial state: 0 0.644933 0.871668 0.575593 0.861562 0.226505 0.107233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231146 episodes
GETTING ACTION FROM:
action 1, numVisits=231138, meanQ=4.910208, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.644933 0.871668 0.575593 0.861562 0.226505 0.107233 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=17036, meanQ=4.587547, numObservations: 4
action 0, numVisits=47, meanQ=3.707316, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 284352 episodes
GETTING ACTION FROM:
action 3, numVisits=301388, meanQ=6.120361, numObservations: 4
action 0, numVisits=47, meanQ=3.707316, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.644933 0.871668 0.575593 0.861562 0.226505 0.107233 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=7451, meanQ=8.247294, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 293594 episodes
GETTING ACTION FROM:
action 2, numVisits=301044, meanQ=6.097411, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.644933 0.871668 0.575593 0.861562 0.226505 0.107233 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 180
Initial state: 0 0.541809 0.816895 0.544285 0.815829 0.97429 0.150862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219415 episodes
GETTING ACTION FROM:
action 2, numVisits=219384, meanQ=4.906176, numObservations: 4
action -1, numVisits=26, meanQ=3.445311, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.541809 0.816895 0.544285 0.815829 0.97429 0.150862 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 181
Initial state: 0 0.37907 0.56116 0.696737 0.851767 0.628448 0.89744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228135 episodes
GETTING ACTION FROM:
action 1, numVisits=228068, meanQ=5.138818, numObservations: 4
action -1, numVisits=61, meanQ=4.252345, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.37907 0.56116 0.696737 0.851767 0.628448 0.89744 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22558, meanQ=8.550942, numObservations: 3
action 2, numVisits=4, meanQ=2.497525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285283 episodes
GETTING ACTION FROM:
action 3, numVisits=307839, meanQ=6.084295, numObservations: 4
action 2, numVisits=4, meanQ=2.497525, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.37907 0.56116 0.696737 0.851767 0.628448 0.89744 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 182
Initial state: 0 0.508775 0.889059 0.831467 0.498727 0.639188 0.846155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230391 episodes
GETTING ACTION FROM:
action 1, numVisits=230352, meanQ=4.998579, numObservations: 4
action 0, numVisits=31, meanQ=3.729711, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.508775 0.889059 0.831467 0.498727 0.639188 0.846155 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.67433 0.805654 0.608403 0.875468 0.0340921 0.271514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230015 episodes
GETTING ACTION FROM:
action 1, numVisits=229929, meanQ=4.925543, numObservations: 4
action -1, numVisits=81, meanQ=4.145321, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.67433 0.805654 0.608403 0.875468 0.0340921 0.271514 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 184
Initial state: 0 0.70371 0.23115 0.665362 0.859903 0.654182 0.835154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230063 episodes
GETTING ACTION FROM:
action 1, numVisits=230057, meanQ=4.869914, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.70371 0.23115 0.665362 0.859903 0.654182 0.835154 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 185
Initial state: 0 0.577943 0.866569 0.912888 0.502557 0.575338 0.834891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223640 episodes
GETTING ACTION FROM:
action 3, numVisits=223627, meanQ=4.827022, numObservations: 3
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.577943 0.866569 0.912888 0.502557 0.575338 0.834891 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 186
Initial state: 0 0.679527 0.825975 0.649331 0.801443 0.498859 0.461106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161207 episodes
GETTING ACTION FROM:
action 0, numVisits=161202, meanQ=5.846296, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.679527 0.825975 0.649331 0.801443 0.498859 0.461106 w: 1
Observation: 0 0 0.870031 0 0.742519 0 0.560248 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=45962, meanQ=8.244479, numObservations: 4
action 1, numVisits=110, meanQ=7.626183, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 247967 episodes
GETTING ACTION FROM:
action 2, numVisits=293519, meanQ=5.710360, numObservations: 4
action 1, numVisits=518, meanQ=5.394703, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.679527 0.825975 0.649331 0.801443 0.498859 0.461106 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 187
Initial state: 0 0.605349 0.866754 0.928861 0.561324 0.574819 0.835757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 232002 episodes
GETTING ACTION FROM:
action 2, numVisits=231979, meanQ=4.969196, numObservations: 3
action -1, numVisits=19, meanQ=3.314444, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.605349 0.866754 0.928861 0.561324 0.574819 0.835757 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=17045, meanQ=5.623114, numObservations: 4
action 1, numVisits=9, meanQ=3.221111, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 263495 episodes
GETTING ACTION FROM:
action 2, numVisits=280536, meanQ=4.673643, numObservations: 5
action 1, numVisits=11, meanQ=2.453636, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.605349 0.866754 0.928861 0.561324 0.574819 0.835757 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=608, meanQ=4.515982, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 290917 episodes
GETTING ACTION FROM:
action 1, numVisits=290584, meanQ=6.111499, numObservations: 4
action -1, numVisits=942, meanQ=2.530892, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.605349 0.866754 0.928861 0.561324 0.574819 0.835757 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 188
Initial state: 0 0.457456 0.989757 0.612542 0.879043 0.606369 0.814084 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226217 episodes
GETTING ACTION FROM:
action 2, numVisits=225804, meanQ=5.032860, numObservations: 5
action 0, numVisits=409, meanQ=2.420654, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.457456 0.989757 0.612542 0.879043 0.606369 0.814084 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 189
Initial state: 0 0.693179 0.843271 0.677189 0.898625 0.808281 0.432296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228790 episodes
GETTING ACTION FROM:
action 3, numVisits=228754, meanQ=4.941177, numObservations: 4
action 2, numVisits=23, meanQ=2.129570, numObservations: 4
action 1, numVisits=9, meanQ=1.432222, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.693179 0.843271 0.677189 0.898625 0.808281 0.432296 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 190
Initial state: 0 0.964401 0.380552 0.561202 0.87707 0.517735 0.859176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229339 episodes
GETTING ACTION FROM:
action 1, numVisits=229302, meanQ=4.989140, numObservations: 4
action 2, numVisits=31, meanQ=3.434523, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.964401 0.380552 0.561202 0.87707 0.517735 0.859176 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16884, meanQ=5.623323, numObservations: 4
action 2, numVisits=57, meanQ=4.355442, numObservations: 4
action 3, numVisits=19, meanQ=3.525263, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 282603 episodes
GETTING ACTION FROM:
action 2, numVisits=260096, meanQ=5.622478, numObservations: 4
action 1, numVisits=39446, meanQ=5.184472, numObservations: 5
action 3, numVisits=19, meanQ=3.525263, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.964401 0.380552 0.561202 0.87707 0.517735 0.859176 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 191
Initial state: 0 0.544462 0.855458 0.507675 0.846091 0.180164 0.265436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230731 episodes
GETTING ACTION FROM:
action 2, numVisits=230671, meanQ=4.957256, numObservations: 4
action 0, numVisits=35, meanQ=3.730714, numObservations: 1
action -1, numVisits=23, meanQ=3.491762, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.544462 0.855458 0.507675 0.846091 0.180164 0.265436 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 192
Initial state: 0 0.80316 0.847337 0.69056 0.895925 0.646754 0.84019 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225280 episodes
GETTING ACTION FROM:
action 2, numVisits=225226, meanQ=4.927857, numObservations: 5
action 0, numVisits=36, meanQ=3.731557, numObservations: 1
action 1, numVisits=15, meanQ=2.192673, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.80316 0.847337 0.69056 0.895925 0.646754 0.84019 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 193
Initial state: 0 0.519926 0.888753 0.525695 0.890126 0.979529 0.464858 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163920 episodes
GETTING ACTION FROM:
action 0, numVisits=153606, meanQ=5.816691, numObservations: 3
action 3, numVisits=10106, meanQ=5.008334, numObservations: 4
action 1, numVisits=205, meanQ=4.289079, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.519926 0.888753 0.525695 0.890126 0.979529 0.464858 w: 1
Observation: 0 0 0.976007 0 0.793055 0 0.497492 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=64716, meanQ=7.476081, numObservations: 4
action 2, numVisits=24, meanQ=5.408337, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 249634 episodes
GETTING ACTION FROM:
action 1, numVisits=314046, meanQ=5.805267, numObservations: 4
action 2, numVisits=326, meanQ=5.422141, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.519926 0.888753 0.525695 0.890126 0.979529 0.464858 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 194
Initial state: 0 0.594841 0.847013 0.547621 0.81016 0.725974 0.130399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159243 episodes
GETTING ACTION FROM:
action 0, numVisits=159227, meanQ=5.327395, numObservations: 2
action 1, numVisits=11, meanQ=1.008182, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.594841 0.847013 0.547621 0.81016 0.725974 0.130399 w: 1
Observation: 0 0 0.825623 0 0.83102 0 0.106738 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=37297, meanQ=8.450965, numObservations: 3
action 2, numVisits=6, meanQ=4.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 232789 episodes
GETTING ACTION FROM:
action 1, numVisits=269960, meanQ=5.067888, numObservations: 3
action 0, numVisits=53, meanQ=4.099980, numObservations: 1
action -1, numVisits=52, meanQ=4.094731, numObservations: 1
action 2, numVisits=29, meanQ=3.412417, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.594841 0.847013 0.547621 0.81016 0.725974 0.130399 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 195
Initial state: 0 0.599221 0.880826 0.55284 0.85516 0.449645 0.976101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219771 episodes
GETTING ACTION FROM:
action 2, numVisits=219673, meanQ=4.749994, numObservations: 4
action -1, numVisits=93, meanQ=4.027443, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.599221 0.880826 0.55284 0.85516 0.449645 0.976101 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 196
Initial state: 0 0.931818 0.828972 0.601999 0.886262 0.608392 0.842406 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 125194 episodes
GETTING ACTION FROM:
action -1, numVisits=125184, meanQ=3.618024, numObservations: 1
action 3, numVisits=4, meanQ=-0.999975, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: -1
Next state: 0 0.931818 0.828972 0.601999 0.886262 0.608392 0.842406 w: 1
Observation: 0 0.972421 0 0.60448 0 0.607067 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=115003, meanQ=5.806584, numObservations: 3
action 3, numVisits=10176, meanQ=5.004404, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 171287 episodes
GETTING ACTION FROM:
action 0, numVisits=286290, meanQ=5.859162, numObservations: 3
action 3, numVisits=10176, meanQ=5.004404, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.931818 0.828972 0.601999 0.886262 0.608392 0.842406 w: 1
Observation: 0 0 0.880401 0 0.95201 0 0.833476 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=111495, meanQ=7.670966, numObservations: 3
action 3, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 252439 episodes
GETTING ACTION FROM:
action 2, numVisits=363867, meanQ=5.717511, numObservations: 3
action -1, numVisits=65, meanQ=4.838785, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.931818 0.828972 0.601999 0.886262 0.608392 0.842406 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 197
Initial state: 0 0.638643 0.807527 0.395 0.449756 0.696137 0.802167 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228770 episodes
GETTING ACTION FROM:
action 1, numVisits=228688, meanQ=4.989975, numObservations: 4
action 0, numVisits=77, meanQ=4.174452, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.638643 0.807527 0.395 0.449756 0.696137 0.802167 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 198
Initial state: 0 0.558253 0.844745 0.58222 0.828086 0.580071 0.519863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223675 episodes
GETTING ACTION FROM:
action 3, numVisits=214509, meanQ=4.960283, numObservations: 4
action 0, numVisits=9157, meanQ=3.016754, numObservations: 1
action 2, numVisits=6, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.558253 0.844745 0.58222 0.828086 0.580071 0.519863 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 199
Initial state: 0 0.63421 0.860953 0.561107 0.868763 0.73015 0.0219427 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225580 episodes
GETTING ACTION FROM:
action 1, numVisits=225547, meanQ=4.972846, numObservations: 5
action 0, numVisits=26, meanQ=3.600537, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.63421 0.860953 0.561107 0.868763 0.73015 0.0219427 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 200
Initial state: 0 0.629971 0.823156 0.692685 0.822681 0.23899 0.737664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225747 episodes
GETTING ACTION FROM:
action 2, numVisits=225691, meanQ=4.913259, numObservations: 5
action -1, numVisits=37, meanQ=3.762408, numObservations: 1
action 1, numVisits=13, meanQ=2.846162, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.629971 0.823156 0.692685 0.822681 0.23899 0.737664 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 201
Initial state: 0 0.68625 0.858145 0.548012 0.851294 0.511107 0.605496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226193 episodes
GETTING ACTION FROM:
action 3, numVisits=226140, meanQ=4.917801, numObservations: 5
action 0, numVisits=49, meanQ=3.902005, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.68625 0.858145 0.548012 0.851294 0.511107 0.605496 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 202
Initial state: 0 0.550135 0.86173 0.683028 0.85197 0.341231 0.0596228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222338 episodes
GETTING ACTION FROM:
action 1, numVisits=222331, meanQ=4.923372, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.550135 0.86173 0.683028 0.85197 0.341231 0.0596228 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 203
Initial state: 0 0.551213 0.852913 0.566762 0.82174 0.942132 0.227484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228874 episodes
GETTING ACTION FROM:
action 1, numVisits=228860, meanQ=4.901391, numObservations: 4
action 3, numVisits=9, meanQ=1.886667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.551213 0.852913 0.566762 0.82174 0.942132 0.227484 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 204
Initial state: 0 0.720408 0.200162 0.681691 0.821833 0.560139 0.823808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223010 episodes
GETTING ACTION FROM:
action 2, numVisits=222926, meanQ=4.829639, numObservations: 4
action -1, numVisits=59, meanQ=3.900346, numObservations: 1
action 1, numVisits=22, meanQ=2.816818, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.720408 0.200162 0.681691 0.821833 0.560139 0.823808 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 205
Initial state: 0 0.328206 0.456808 0.563163 0.866169 0.580727 0.893958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227012 episodes
GETTING ACTION FROM:
action 1, numVisits=226952, meanQ=5.033589, numObservations: 4
action 0, numVisits=56, meanQ=4.084212, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.328206 0.456808 0.563163 0.866169 0.580727 0.893958 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=34194, meanQ=8.303458, numObservations: 4
action 2, numVisits=57, meanQ=7.419302, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284649 episodes
GETTING ACTION FROM:
action 3, numVisits=318685, meanQ=6.001513, numObservations: 4
action 2, numVisits=212, meanQ=5.450615, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.328206 0.456808 0.563163 0.866169 0.580727 0.893958 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 206
Initial state: 0 0.529578 0.803351 0.520066 0.829882 0.559213 0.448202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226124 episodes
GETTING ACTION FROM:
action 3, numVisits=226042, meanQ=4.914762, numObservations: 4
action 0, numVisits=41, meanQ=3.630746, numObservations: 1
action 1, numVisits=35, meanQ=3.147143, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.529578 0.803351 0.520066 0.829882 0.559213 0.448202 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 207
Initial state: 0 0.760588 0.149307 0.636347 0.824431 0.667921 0.822244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229219 episodes
GETTING ACTION FROM:
action 1, numVisits=228799, meanQ=4.942226, numObservations: 4
action 3, numVisits=415, meanQ=4.488202, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.760588 0.149307 0.636347 0.824431 0.667921 0.822244 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 208
Initial state: 0 0.728849 0.459764 0.524724 0.804545 0.503628 0.806884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228588 episodes
GETTING ACTION FROM:
action 3, numVisits=228582, meanQ=4.979164, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.728849 0.459764 0.524724 0.804545 0.503628 0.806884 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 209
Initial state: 0 0.450848 0.905291 0.693017 0.846362 0.699368 0.826035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229304 episodes
GETTING ACTION FROM:
action 1, numVisits=229224, meanQ=4.985632, numObservations: 4
action -1, numVisits=56, meanQ=4.025386, numObservations: 1
action 3, numVisits=20, meanQ=3.195005, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.450848 0.905291 0.693017 0.846362 0.699368 0.826035 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 210
Initial state: 0 0.788842 0.137336 0.534736 0.813615 0.526036 0.813116 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228955 episodes
GETTING ACTION FROM:
action 1, numVisits=228870, meanQ=4.973581, numObservations: 4
action 3, numVisits=69, meanQ=3.861749, numObservations: 4
action 2, numVisits=12, meanQ=1.998333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.788842 0.137336 0.534736 0.813615 0.526036 0.813116 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 211
Initial state: 0 0.584847 0.856207 0.101651 0.040133 0.683676 0.883745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224510 episodes
GETTING ACTION FROM:
action 3, numVisits=221099, meanQ=4.924281, numObservations: 5
action 0, numVisits=3404, meanQ=2.596505, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 3
Next state: 1 0.584847 0.856207 0.101651 0.040133 0.683676 0.883745 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 212
Initial state: 0 0.677188 0.827369 0.635918 0.841279 0.99503 0.0994036 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227762 episodes
GETTING ACTION FROM:
action 2, numVisits=227735, meanQ=4.971123, numObservations: 5
action -1, numVisits=23, meanQ=3.405386, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.677188 0.827369 0.635918 0.841279 0.99503 0.0994036 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 213
Initial state: 0 0.682134 0.801209 0.576552 0.865854 0.423333 0.708335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230253 episodes
GETTING ACTION FROM:
action 3, numVisits=223650, meanQ=4.947104, numObservations: 3
action 2, numVisits=6462, meanQ=4.840693, numObservations: 5
action -1, numVisits=114, meanQ=4.296241, numObservations: 1
action 0, numVisits=26, meanQ=3.483751, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.682134 0.801209 0.576552 0.865854 0.423333 0.708335 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=33951, meanQ=8.298930, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 284013 episodes
GETTING ACTION FROM:
action 2, numVisits=317964, meanQ=6.280355, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.682134 0.801209 0.576552 0.865854 0.423333 0.708335 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 214
Initial state: 0 0.548529 0.845732 0.561558 0.8719 0.767481 0.200427 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231665 episodes
GETTING ACTION FROM:
action 2, numVisits=231659, meanQ=4.914118, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.548529 0.845732 0.561558 0.8719 0.767481 0.200427 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 215
Initial state: 0 0.576848 0.816211 0.595118 0.329645 0.508404 0.83817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229107 episodes
GETTING ACTION FROM:
action 1, numVisits=229098, meanQ=5.009499, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.576848 0.816211 0.595118 0.329645 0.508404 0.83817 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 216
Initial state: 0 0.579852 0.838575 0.639253 0.818258 0.6035 0.720395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227112 episodes
GETTING ACTION FROM:
action 3, numVisits=227042, meanQ=5.037486, numObservations: 5
action -1, numVisits=35, meanQ=3.804796, numObservations: 1
action 1, numVisits=32, meanQ=3.061566, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.579852 0.838575 0.639253 0.818258 0.6035 0.720395 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 217
Initial state: 0 0.549052 0.862859 0.504006 0.864735 0.366183 0.667347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164543 episodes
GETTING ACTION FROM:
action 0, numVisits=153252, meanQ=5.836431, numObservations: 3
action 3, numVisits=11269, meanQ=5.040760, numObservations: 4
action -1, numVisits=18, meanQ=3.659434, numObservations: 1
action 1, numVisits=3, meanQ=0.993333, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.549052 0.862859 0.504006 0.864735 0.366183 0.667347 w: 1
Observation: 0 0 0.905781 0 0.913818 0 0.632299 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=47082, meanQ=8.075481, numObservations: 4
action 1, numVisits=21, meanQ=5.284767, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 248330 episodes
GETTING ACTION FROM:
action 2, numVisits=295389, meanQ=5.526590, numObservations: 4
action 1, numVisits=30, meanQ=3.732343, numObservations: 4
action -1, numVisits=14, meanQ=3.634377, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.549052 0.862859 0.504006 0.864735 0.366183 0.667347 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 218
Initial state: 0 0.636422 0.89382 0.692312 0.896269 0.812165 0.366817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228981 episodes
GETTING ACTION FROM:
action 3, numVisits=228975, meanQ=4.980492, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.636422 0.89382 0.692312 0.896269 0.812165 0.366817 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 219
Initial state: 0 0.0657869 0.725914 0.586648 0.893543 0.613399 0.894976 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224867 episodes
GETTING ACTION FROM:
action 1, numVisits=224832, meanQ=4.921515, numObservations: 5
action 0, numVisits=20, meanQ=3.363338, numObservations: 1
action 2, numVisits=12, meanQ=2.840008, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0657869 0.725914 0.586648 0.893543 0.613399 0.894976 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=28472, meanQ=8.407326, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285685 episodes
GETTING ACTION FROM:
action 2, numVisits=314155, meanQ=5.939889, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0657869 0.725914 0.586648 0.893543 0.613399 0.894976 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 220
Initial state: 0 0.269985 0.258253 0.682203 0.865941 0.609457 0.807702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156521 episodes
GETTING ACTION FROM:
action -1, numVisits=154860, meanQ=2.959217, numObservations: 1
action 0, numVisits=1644, meanQ=1.711976, numObservations: 1
action 2, numVisits=11, meanQ=0.088209, numObservations: 3
action 3, numVisits=4, meanQ=-0.999975, numObservations: 2
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action: -1
Next state: 0 0.269985 0.258253 0.682203 0.865941 0.609457 0.807702 w: 1
Observation: 0 0.174718 0 0.720111 0 0.620898 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=154591, meanQ=5.020554, numObservations: 5
action 3, numVisits=247, meanQ=4.565057, numObservations: 3
action 1, numVisits=17, meanQ=3.234124, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 249501 episodes
GETTING ACTION FROM:
action 3, numVisits=219490, meanQ=5.070633, numObservations: 3
action 2, numVisits=184849, meanQ=4.992015, numObservations: 5
action 1, numVisits=17, meanQ=3.234124, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.269985 0.258253 0.682203 0.865941 0.609457 0.807702 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 221
Initial state: 0 0.107451 0.696399 0.648624 0.863473 0.629395 0.882927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224423 episodes
GETTING ACTION FROM:
action 3, numVisits=224417, meanQ=4.880096, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.107451 0.696399 0.648624 0.863473 0.629395 0.882927 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 222
Initial state: 0 0.611096 0.882896 0.621209 0.864936 0.232704 0.780696 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226316 episodes
GETTING ACTION FROM:
action 3, numVisits=226298, meanQ=4.874854, numObservations: 5
action 1, numVisits=11, meanQ=-1.183618, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.611096 0.882896 0.621209 0.864936 0.232704 0.780696 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=28535, meanQ=8.389317, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287062 episodes
GETTING ACTION FROM:
action 1, numVisits=315560, meanQ=5.979110, numObservations: 3
action 2, numVisits=37, meanQ=4.729192, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.611096 0.882896 0.621209 0.864936 0.232704 0.780696 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 223
Initial state: 0 0.717586 0.241365 0.648433 0.89119 0.524595 0.829227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164848 episodes
GETTING ACTION FROM:
action 0, numVisits=154696, meanQ=5.808843, numObservations: 3
action 3, numVisits=10143, meanQ=5.003207, numObservations: 5
action 2, numVisits=6, meanQ=1.663333, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.717586 0.241365 0.648433 0.89119 0.524595 0.829227 w: 1
Observation: 0 0 0.316516 0 0.953745 0 0.902665 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=58975, meanQ=7.702474, numObservations: 3
action 3, numVisits=49, meanQ=2.670831, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 254257 episodes
GETTING ACTION FROM:
action 2, numVisits=313213, meanQ=5.364246, numObservations: 3
action -1, numVisits=19, meanQ=3.729470, numObservations: 1
action 3, numVisits=49, meanQ=2.670831, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.717586 0.241365 0.648433 0.89119 0.524595 0.829227 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 224
Initial state: 0 0.964061 0.736649 0.530072 0.81084 0.544874 0.802437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224161 episodes
GETTING ACTION FROM:
action 2, numVisits=224067, meanQ=4.910604, numObservations: 5
action -1, numVisits=72, meanQ=4.024210, numObservations: 1
action 1, numVisits=18, meanQ=1.882778, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.964061 0.736649 0.530072 0.81084 0.544874 0.802437 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 225
Initial state: 0 0.5882 0.822626 0.882232 0.563151 0.514922 0.845362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230435 episodes
GETTING ACTION FROM:
action 1, numVisits=230356, meanQ=4.898411, numObservations: 3
action -1, numVisits=74, meanQ=4.082770, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.5882 0.822626 0.882232 0.563151 0.514922 0.845362 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 226
Initial state: 0 0.447538 0.742792 0.595398 0.803088 0.610157 0.84602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228021 episodes
GETTING ACTION FROM:
action 1, numVisits=228013, meanQ=4.996006, numObservations: 4
action 2, numVisits=3, meanQ=0.330033, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.447538 0.742792 0.595398 0.803088 0.610157 0.84602 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=22366, meanQ=8.530030, numObservations: 3
action 3, numVisits=26, meanQ=6.922704, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289714 episodes
GETTING ACTION FROM:
action 2, numVisits=311492, meanQ=6.136511, numObservations: 3
action 3, numVisits=614, meanQ=5.859211, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.447538 0.742792 0.595398 0.803088 0.610157 0.84602 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 227
Initial state: 0 0.528075 0.866982 0.511409 0.805498 0.922034 0.229194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226385 episodes
GETTING ACTION FROM:
action 1, numVisits=226372, meanQ=4.999679, numObservations: 4
action 2, numVisits=7, meanQ=1.852871, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.528075 0.866982 0.511409 0.805498 0.922034 0.229194 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 228
Initial state: 0 0.615131 0.809785 0.400338 0.0519906 0.575449 0.883861 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228761 episodes
GETTING ACTION FROM:
action 1, numVisits=228635, meanQ=4.959516, numObservations: 4
action -1, numVisits=122, meanQ=4.327929, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.615131 0.809785 0.400338 0.0519906 0.575449 0.883861 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 229
Initial state: 0 0.121428 0.49648 0.667925 0.822276 0.642241 0.893688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229112 episodes
GETTING ACTION FROM:
action 2, numVisits=229034, meanQ=4.986350, numObservations: 4
action 0, numVisits=67, meanQ=4.135220, numObservations: 1
action 1, numVisits=8, meanQ=2.475000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.121428 0.49648 0.667925 0.822276 0.642241 0.893688 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16646, meanQ=5.599269, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 263699 episodes
GETTING ACTION FROM:
action 2, numVisits=280343, meanQ=4.978221, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.121428 0.49648 0.667925 0.822276 0.642241 0.893688 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 230
Initial state: 0 0.526502 0.221912 0.552108 0.871905 0.504087 0.812198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215307 episodes
GETTING ACTION FROM:
action 1, numVisits=214999, meanQ=4.646455, numObservations: 3
action -1, numVisits=281, meanQ=4.233675, numObservations: 1
action 2, numVisits=24, meanQ=2.999167, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.526502 0.221912 0.552108 0.871905 0.504087 0.812198 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=15753, meanQ=5.569667, numObservations: 4
action 2, numVisits=13, meanQ=3.460015, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 266740 episodes
GETTING ACTION FROM:
action 1, numVisits=282478, meanQ=4.955283, numObservations: 4
action 2, numVisits=26, meanQ=3.460392, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 2 0.526502 0.221912 0.552108 0.871905 0.504087 0.812198 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 231
Initial state: 0 0.502007 0.869034 0.450216 0.162754 0.502801 0.889154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228584 episodes
GETTING ACTION FROM:
action 2, numVisits=228574, meanQ=5.125936, numObservations: 4
action 3, numVisits=5, meanQ=1.000020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.502007 0.869034 0.450216 0.162754 0.502801 0.889154 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=22350, meanQ=8.537364, numObservations: 3
action 3, numVisits=23, meanQ=6.916957, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286648 episodes
GETTING ACTION FROM:
action 1, numVisits=308912, meanQ=6.125650, numObservations: 4
action 3, numVisits=109, meanQ=5.366147, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.502007 0.869034 0.450216 0.162754 0.502801 0.889154 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 232
Initial state: 0 0.575323 0.878101 0.177952 0.319804 0.667932 0.819545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230064 episodes
GETTING ACTION FROM:
action 1, numVisits=229571, meanQ=4.974010, numObservations: 4
action 2, numVisits=444, meanQ=4.613938, numObservations: 4
action -1, numVisits=46, meanQ=3.943673, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.575323 0.878101 0.177952 0.319804 0.667932 0.819545 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 233
Initial state: 0 0.522067 0.822985 0.597207 0.825919 0.674714 0.223067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 233064 episodes
GETTING ACTION FROM:
action 1, numVisits=233058, meanQ=4.997628, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.522067 0.822985 0.597207 0.825919 0.674714 0.223067 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 234
Initial state: 0 0.567412 0.842765 0.929263 0.464315 0.528928 0.810022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228958 episodes
GETTING ACTION FROM:
action 1, numVisits=228884, meanQ=4.965619, numObservations: 4
action 0, numVisits=51, meanQ=3.995148, numObservations: 1
action -1, numVisits=12, meanQ=2.317092, numObservations: 1
action 2, numVisits=8, meanQ=1.500000, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 1
Next state: 1 0.567412 0.842765 0.929263 0.464315 0.528928 0.810022 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 235
Initial state: 0 0.823955 0.701265 0.547389 0.881577 0.522081 0.83712 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225313 episodes
GETTING ACTION FROM:
action 3, numVisits=225285, meanQ=4.898665, numObservations: 5
action 0, numVisits=24, meanQ=3.403455, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.823955 0.701265 0.547389 0.881577 0.522081 0.83712 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 236
Initial state: 0 0.446132 0.171336 0.638612 0.815899 0.571752 0.806233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228396 episodes
GETTING ACTION FROM:
action 2, numVisits=228357, meanQ=4.928031, numObservations: 4
action 0, numVisits=33, meanQ=3.660462, numObservations: 2
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.446132 0.171336 0.638612 0.815899 0.571752 0.806233 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 237
Initial state: 0 0.998033 0.064033 0.520549 0.851197 0.654827 0.887189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228343 episodes
GETTING ACTION FROM:
action 3, numVisits=228260, meanQ=4.985404, numObservations: 4
action 0, numVisits=79, meanQ=4.203615, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.998033 0.064033 0.520549 0.851197 0.654827 0.887189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 238
Initial state: 0 0.374507 0.512414 0.694123 0.883315 0.565049 0.86092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223573 episodes
GETTING ACTION FROM:
action 3, numVisits=215025, meanQ=4.960263, numObservations: 5
action -1, numVisits=8542, meanQ=2.933242, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.374507 0.512414 0.694123 0.883315 0.565049 0.86092 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 239
Initial state: 0 0.0351853 0.19599 0.511818 0.841894 0.546745 0.828598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226294 episodes
GETTING ACTION FROM:
action 3, numVisits=226205, meanQ=4.976467, numObservations: 4
action -1, numVisits=67, meanQ=4.126847, numObservations: 1
action 2, numVisits=19, meanQ=3.103705, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0351853 0.19599 0.511818 0.841894 0.546745 0.828598 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 240
Initial state: 0 0.520847 0.893931 0.521237 0.828452 0.579366 0.646234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231025 episodes
GETTING ACTION FROM:
action 2, numVisits=230987, meanQ=5.014783, numObservations: 4
action -1, numVisits=29, meanQ=3.695865, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.520847 0.893931 0.521237 0.828452 0.579366 0.646234 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 241
Initial state: 0 0.95726 0.0702663 0.645033 0.831957 0.587663 0.87487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 131071 episodes
GETTING ACTION FROM:
action 0, numVisits=131064, meanQ=4.157808, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.95726 0.0702663 0.645033 0.831957 0.587663 0.87487 w: 1
Observation: 0 0 0.0390244 0 0.916056 0 0.936904 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=34557, meanQ=8.314251, numObservations: 3
action 3, numVisits=15, meanQ=6.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 251460 episodes
GETTING ACTION FROM:
action 2, numVisits=285741, meanQ=5.451964, numObservations: 3
action 3, numVisits=289, meanQ=5.028851, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.95726 0.0702663 0.645033 0.831957 0.587663 0.87487 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=19480, meanQ=5.842237, numObservations: 4
action 3, numVisits=2378, meanQ=5.749785, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282927 episodes
GETTING ACTION FROM:
action 3, numVisits=284823, meanQ=6.021923, numObservations: 4
action 2, numVisits=19960, meanQ=5.814883, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.95726 0.0702663 0.645033 0.831957 0.587663 0.87487 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 242
Initial state: 0 0.545015 0.701787 0.637144 0.863453 0.58201 0.81417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227831 episodes
GETTING ACTION FROM:
action 3, numVisits=227780, meanQ=4.957694, numObservations: 3
action -1, numVisits=26, meanQ=3.582916, numObservations: 1
action 1, numVisits=11, meanQ=2.453636, numObservations: 3
action 2, numVisits=12, meanQ=1.992508, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.545015 0.701787 0.637144 0.863453 0.58201 0.81417 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 243
Initial state: 0 0.599567 0.840383 0.670787 0.66417 0.639675 0.822698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226008 episodes
GETTING ACTION FROM:
action 3, numVisits=225934, meanQ=4.959653, numObservations: 5
action -1, numVisits=54, meanQ=4.003362, numObservations: 1
action 1, numVisits=17, meanQ=3.117076, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.599567 0.840383 0.670787 0.66417 0.639675 0.822698 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 244
Initial state: 0 0.558215 0.852182 0.584603 0.850154 0.368321 0.223346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225648 episodes
GETTING ACTION FROM:
action 3, numVisits=225586, meanQ=4.977211, numObservations: 4
action 0, numVisits=58, meanQ=4.060904, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.558215 0.852182 0.584603 0.850154 0.368321 0.223346 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=21001, meanQ=8.535801, numObservations: 3
action 2, numVisits=1182, meanQ=8.393592, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 282038 episodes
GETTING ACTION FROM:
action 1, numVisits=283727, meanQ=6.120938, numObservations: 4
action 2, numVisits=20494, meanQ=6.084500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.558215 0.852182 0.584603 0.850154 0.368321 0.223346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 245
Initial state: 0 0.582706 0.866322 0.665219 0.812326 0.0559287 0.1405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229215 episodes
GETTING ACTION FROM:
action 1, numVisits=229201, meanQ=4.966797, numObservations: 4
action 3, numVisits=9, meanQ=0.998889, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.582706 0.866322 0.665219 0.812326 0.0559287 0.1405 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 246
Initial state: 0 0.382154 0.888245 0.517044 0.805465 0.556046 0.893521 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223359 episodes
GETTING ACTION FROM:
action 1, numVisits=223300, meanQ=4.843194, numObservations: 3
action -1, numVisits=40, meanQ=3.706688, numObservations: 1
action 3, numVisits=13, meanQ=2.536923, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.382154 0.888245 0.517044 0.805465 0.556046 0.893521 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 247
Initial state: 0 0.880285 0.801593 0.600368 0.841796 0.675313 0.822671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227788 episodes
GETTING ACTION FROM:
action 2, numVisits=227781, meanQ=4.864361, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.880285 0.801593 0.600368 0.841796 0.675313 0.822671 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 248
Initial state: 0 0.621055 0.821121 0.694356 0.82005 0.506192 0.0307984 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228969 episodes
GETTING ACTION FROM:
action 1, numVisits=228963, meanQ=5.002350, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.621055 0.821121 0.694356 0.82005 0.506192 0.0307984 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 249
Initial state: 0 0.0833133 0.596396 0.699928 0.827932 0.649724 0.805396 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230148 episodes
GETTING ACTION FROM:
action 1, numVisits=230142, meanQ=4.974611, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0833133 0.596396 0.699928 0.827932 0.649724 0.805396 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=29401, meanQ=8.393313, numObservations: 4
action 3, numVisits=47, meanQ=7.382340, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 288073 episodes
GETTING ACTION FROM:
action 2, numVisits=317205, meanQ=6.167357, numObservations: 4
action 3, numVisits=316, meanQ=5.738134, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0833133 0.596396 0.699928 0.827932 0.649724 0.805396 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 250
Initial state: 0 0.608488 0.885341 0.611391 0.855224 0.811537 0.182184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226831 episodes
GETTING ACTION FROM:
action 1, numVisits=226763, meanQ=4.954574, numObservations: 4
action 3, numVisits=63, meanQ=4.063654, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.608488 0.885341 0.611391 0.855224 0.811537 0.182184 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 251
Initial state: 0 0.588189 0.856831 0.536396 0.875268 0.303416 0.51578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229148 episodes
GETTING ACTION FROM:
action 2, numVisits=229038, meanQ=4.982040, numObservations: 4
action 0, numVisits=75, meanQ=4.176310, numObservations: 1
action -1, numVisits=30, meanQ=3.683722, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.588189 0.856831 0.536396 0.875268 0.303416 0.51578 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 252
Initial state: 0 0.559032 0.894244 0.69879 0.838921 0.0779039 0.642725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155226 episodes
GETTING ACTION FROM:
action 0, numVisits=153787, meanQ=2.980772, numObservations: 1
action -1, numVisits=1387, meanQ=2.689655, numObservations: 1
action 3, numVisits=41, meanQ=1.725124, numObservations: 3
action 2, numVisits=8, meanQ=-0.001250, numObservations: 3
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action: 0
Next state: 0 0.559032 0.894244 0.69879 0.838921 0.0779039 0.642725 w: 1
Observation: 0 0 0.80731 0 0.872942 0 0.587185 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=153777, meanQ=5.012757, numObservations: 5
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 245452 episodes
GETTING ACTION FROM:
action 3, numVisits=399227, meanQ=4.858249, numObservations: 5
action 2, numVisits=5, meanQ=1.396020, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.559032 0.894244 0.69879 0.838921 0.0779039 0.642725 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=49987, meanQ=8.374879, numObservations: 4
action 1, numVisits=8, meanQ=5.748762, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284259 episodes
GETTING ACTION FROM:
action 2, numVisits=334245, meanQ=6.497136, numObservations: 4
action 1, numVisits=9, meanQ=3.887789, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.559032 0.894244 0.69879 0.838921 0.0779039 0.642725 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 253
Initial state: 0 0.649979 0.871932 0.77036 0.485438 0.569934 0.803031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226591 episodes
GETTING ACTION FROM:
action 1, numVisits=217258, meanQ=4.920647, numObservations: 3
action -1, numVisits=9329, meanQ=2.974317, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.649979 0.871932 0.77036 0.485438 0.569934 0.803031 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 254
Initial state: 0 0.353424 0.911834 0.540215 0.897231 0.545379 0.84917 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230870 episodes
GETTING ACTION FROM:
action 1, numVisits=230854, meanQ=4.905988, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=8, meanQ=-0.001250, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.353424 0.911834 0.540215 0.897231 0.545379 0.84917 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16849, meanQ=5.629161, numObservations: 4
action 3, numVisits=8, meanQ=2.986250, numObservations: 3
action 2, numVisits=11, meanQ=2.808182, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 266363 episodes
GETTING ACTION FROM:
action 1, numVisits=283208, meanQ=5.001719, numObservations: 4
action 2, numVisits=11, meanQ=2.808182, numObservations: 3
action 3, numVisits=10, meanQ=2.189000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 0 0.353424 0.911834 0.540215 0.897231 0.545379 0.84917 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=6734, meanQ=6.789936, numObservations: 4
action 3, numVisits=14, meanQ=3.285721, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 290953 episodes
GETTING ACTION FROM:
action 2, numVisits=297687, meanQ=6.173385, numObservations: 4
action 3, numVisits=14, meanQ=3.285721, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.353424 0.911834 0.540215 0.897231 0.545379 0.84917 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 255
Initial state: 0 0.650294 0.888422 0.599057 0.804381 0.350292 0.227324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228875 episodes
GETTING ACTION FROM:
action 3, numVisits=227849, meanQ=4.929339, numObservations: 3
action 1, numVisits=946, meanQ=4.698080, numObservations: 5
action 0, numVisits=76, meanQ=4.121407, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.650294 0.888422 0.599057 0.804381 0.350292 0.227324 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=34743, meanQ=8.280828, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284447 episodes
GETTING ACTION FROM:
action 1, numVisits=319171, meanQ=6.152622, numObservations: 4
action 3, numVisits=21, meanQ=3.851905, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.650294 0.888422 0.599057 0.804381 0.350292 0.227324 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 256
Initial state: 0 0.681907 0.829604 0.053385 0.261212 0.556364 0.85465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229313 episodes
GETTING ACTION FROM:
action 2, numVisits=229307, meanQ=4.997552, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.681907 0.829604 0.053385 0.261212 0.556364 0.85465 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=6079, meanQ=7.749661, numObservations: 4
action 3, numVisits=15, meanQ=4.466687, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282756 episodes
GETTING ACTION FROM:
action 1, numVisits=288821, meanQ=5.752391, numObservations: 4
action 3, numVisits=27, meanQ=4.259270, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.681907 0.829604 0.053385 0.261212 0.556364 0.85465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 257
Initial state: 0 0.554316 0.945935 0.674308 0.859153 0.603719 0.821519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224943 episodes
GETTING ACTION FROM:
action 3, numVisits=221953, meanQ=4.927793, numObservations: 5
action 1, numVisits=2949, meanQ=4.740912, numObservations: 5
action -1, numVisits=38, meanQ=3.764133, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.554316 0.945935 0.674308 0.859153 0.603719 0.821519 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 258
Initial state: 0 0.90072 0.646079 0.616801 0.834854 0.570115 0.807323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227083 episodes
GETTING ACTION FROM:
action 3, numVisits=227023, meanQ=4.979666, numObservations: 5
action 0, numVisits=35, meanQ=3.766174, numObservations: 1
action 2, numVisits=18, meanQ=2.777222, numObservations: 4
action 1, numVisits=5, meanQ=-0.622000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.90072 0.646079 0.616801 0.834854 0.570115 0.807323 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 259
Initial state: 0 0.595812 0.860394 0.295794 0.0795633 0.632978 0.893735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227118 episodes
GETTING ACTION FROM:
action 1, numVisits=226880, meanQ=4.871763, numObservations: 4
action 0, numVisits=118, meanQ=4.231153, numObservations: 1
action -1, numVisits=108, meanQ=4.200198, numObservations: 1
action 3, numVisits=10, meanQ=2.598000, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 0 0.595812 0.860394 0.295794 0.0795633 0.632978 0.893735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16457, meanQ=4.611825, numObservations: 4
action 0, numVisits=59, meanQ=3.759874, numObservations: 1
action -1, numVisits=34, meanQ=3.454702, numObservations: 1
action 3, numVisits=3, meanQ=0.993333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 281491 episodes
GETTING ACTION FROM:
action 2, numVisits=297948, meanQ=5.843730, numObservations: 4
action 0, numVisits=59, meanQ=3.759874, numObservations: 1
action -1, numVisits=34, meanQ=3.454702, numObservations: 1
action 3, numVisits=3, meanQ=0.993333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.595812 0.860394 0.295794 0.0795633 0.632978 0.893735 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=5492, meanQ=8.407369, numObservations: 4
action 1, numVisits=78, meanQ=7.762054, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 292678 episodes
GETTING ACTION FROM:
action 3, numVisits=297831, meanQ=6.249351, numObservations: 4
action 1, numVisits=417, meanQ=5.904677, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.595812 0.860394 0.295794 0.0795633 0.632978 0.893735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 260
Initial state: 0 0.597686 0.896044 0.699233 0.859455 0.066088 0.297433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160620 episodes
GETTING ACTION FROM:
action 0, numVisits=160615, meanQ=5.853931, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.597686 0.896044 0.699233 0.859455 0.066088 0.297433 w: 1
Observation: 0 0 0.97221 0 0.95862 0 0.237224 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=54910, meanQ=7.921483, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 249747 episodes
GETTING ACTION FROM:
action 1, numVisits=304655, meanQ=5.687613, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.597686 0.896044 0.699233 0.859455 0.066088 0.297433 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 261
Initial state: 0 0.588365 0.883781 0.612419 0.883325 0.722087 0.133877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230527 episodes
GETTING ACTION FROM:
action 1, numVisits=230519, meanQ=4.988538, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.588365 0.883781 0.612419 0.883325 0.722087 0.133877 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 262
Initial state: 0 0.510066 0.821862 0.536217 0.88806 0.767529 0.649256 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224190 episodes
GETTING ACTION FROM:
action 3, numVisits=224126, meanQ=4.960784, numObservations: 5
action 1, numVisits=37, meanQ=3.362978, numObservations: 4
action 2, numVisits=23, meanQ=3.090878, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.510066 0.821862 0.536217 0.88806 0.767529 0.649256 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 263
Initial state: 0 0.00367918 0.617203 0.508426 0.886498 0.580168 0.828457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226331 episodes
GETTING ACTION FROM:
action 3, numVisits=226315, meanQ=4.960105, numObservations: 4
action 1, numVisits=11, meanQ=2.633645, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.00367918 0.617203 0.508426 0.886498 0.580168 0.828457 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.579381 0.846826 0.178313 0.643403 0.688877 0.815322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224150 episodes
GETTING ACTION FROM:
action 2, numVisits=224143, meanQ=4.907913, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.579381 0.846826 0.178313 0.643403 0.688877 0.815322 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=21958, meanQ=8.536564, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 289965 episodes
GETTING ACTION FROM:
action 3, numVisits=311914, meanQ=6.063647, numObservations: 3
action 1, numVisits=9, meanQ=3.221111, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.579381 0.846826 0.178313 0.643403 0.688877 0.815322 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 265
Initial state: 0 0.0173729 0.540098 0.599267 0.833071 0.598927 0.860293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228058 episodes
GETTING ACTION FROM:
action 2, numVisits=228019, meanQ=4.924036, numObservations: 4
action 0, numVisits=35, meanQ=3.697289, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0173729 0.540098 0.599267 0.833071 0.598927 0.860293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 266
Initial state: 0 0.632811 0.884916 0.424439 0.302523 0.620671 0.804711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226534 episodes
GETTING ACTION FROM:
action 3, numVisits=226491, meanQ=4.942358, numObservations: 5
action 0, numVisits=39, meanQ=3.808608, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.632811 0.884916 0.424439 0.302523 0.620671 0.804711 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 267
Initial state: 0 0.599517 0.740566 0.544184 0.84333 0.506466 0.82473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226176 episodes
GETTING ACTION FROM:
action 3, numVisits=226069, meanQ=5.104737, numObservations: 5
action 0, numVisits=46, meanQ=4.072170, numObservations: 1
action 2, numVisits=58, meanQ=3.333629, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.599517 0.740566 0.544184 0.84333 0.506466 0.82473 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 268
Initial state: 0 0.684587 0.804979 0.654085 0.839978 0.997684 0.0909501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230965 episodes
GETTING ACTION FROM:
action 3, numVisits=230873, meanQ=4.904998, numObservations: 3
action 0, numVisits=87, meanQ=4.155805, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.684587 0.804979 0.654085 0.839978 0.997684 0.0909501 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 269
Initial state: 0 0.559769 0.857329 0.386795 0.504337 0.5686 0.869629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229917 episodes
GETTING ACTION FROM:
action 1, numVisits=228488, meanQ=5.110476, numObservations: 4
action 2, numVisits=1352, meanQ=4.894436, numObservations: 4
action -1, numVisits=74, meanQ=4.298552, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.559769 0.857329 0.386795 0.504337 0.5686 0.869629 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=15079, meanQ=7.230474, numObservations: 4
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
Sampled 269766 episodes
GETTING ACTION FROM:
action 1, numVisits=284843, meanQ=4.741906, numObservations: 4
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 1
Next state: 1 0.559769 0.857329 0.386795 0.504337 0.5686 0.869629 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 270
Initial state: 0 0.613401 0.865826 0.580972 0.849998 0.690727 0.359756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228879 episodes
GETTING ACTION FROM:
action 1, numVisits=228820, meanQ=5.080658, numObservations: 4
action -1, numVisits=38, meanQ=3.920747, numObservations: 1
action 2, numVisits=16, meanQ=3.249375, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.613401 0.865826 0.580972 0.849998 0.690727 0.359756 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 271
Initial state: 0 0.61689 0.863178 0.239921 0.7395 0.663873 0.86697 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227520 episodes
GETTING ACTION FROM:
action 1, numVisits=227447, meanQ=4.945545, numObservations: 4
action 0, numVisits=42, meanQ=3.854018, numObservations: 1
action -1, numVisits=25, meanQ=3.546506, numObservations: 1
action 2, numVisits=4, meanQ=0.025000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.61689 0.863178 0.239921 0.7395 0.663873 0.86697 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 272
Initial state: 0 0.523504 0.814797 0.876863 0.439622 0.585215 0.813473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221455 episodes
GETTING ACTION FROM:
action 3, numVisits=221448, meanQ=4.892065, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.523504 0.814797 0.876863 0.439622 0.585215 0.813473 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 273
Initial state: 0 0.68147 0.88504 0.478747 0.919263 0.614666 0.813659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231121 episodes
GETTING ACTION FROM:
action 2, numVisits=231050, meanQ=4.870505, numObservations: 3
action 0, numVisits=47, meanQ=3.849558, numObservations: 1
action 1, numVisits=21, meanQ=3.276667, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.68147 0.88504 0.478747 0.919263 0.614666 0.813659 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16834, meanQ=4.567725, numObservations: 3
action 2, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=4, meanQ=-2.997475, numObservations: 2
Sampled 288656 episodes
GETTING ACTION FROM:
action 1, numVisits=305490, meanQ=6.022568, numObservations: 3
action 2, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=4, meanQ=-2.997475, numObservations: 2
action: 1
Next state: 1 0.68147 0.88504 0.478747 0.919263 0.614666 0.813659 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 274
Initial state: 0 0.605627 0.842061 0.540894 0.855144 0.709812 0.127574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231629 episodes
GETTING ACTION FROM:
action 1, numVisits=231577, meanQ=4.965928, numObservations: 3
action -1, numVisits=48, meanQ=3.913742, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.605627 0.842061 0.540894 0.855144 0.709812 0.127574 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 275
Initial state: 0 0.063795 0.103335 0.592982 0.817431 0.658438 0.838858 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227155 episodes
GETTING ACTION FROM:
action 2, numVisits=227119, meanQ=4.989168, numObservations: 5
action 0, numVisits=21, meanQ=3.374945, numObservations: 1
action 3, numVisits=11, meanQ=2.808182, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.063795 0.103335 0.592982 0.817431 0.658438 0.838858 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 276
Initial state: 0 0.685992 0.570575 0.699825 0.898957 0.535577 0.832072 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228202 episodes
GETTING ACTION FROM:
action 1, numVisits=210645, meanQ=5.165950, numObservations: 5
action 2, numVisits=17461, meanQ=4.965752, numObservations: 3
action 0, numVisits=68, meanQ=4.254082, numObservations: 1
action -1, numVisits=21, meanQ=3.570407, numObservations: 1
action 3, numVisits=7, meanQ=2.155714, numObservations: 4
action: 1
Next state: 2 0.685992 0.570575 0.699825 0.898957 0.535577 0.832072 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 277
Initial state: 0 0.595362 0.895097 0.571033 0.880978 0.280675 0.657364 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155578 episodes
GETTING ACTION FROM:
action -1, numVisits=122940, meanQ=2.816927, numObservations: 1
action 0, numVisits=32622, meanQ=2.816560, numObservations: 1
action 2, numVisits=10, meanQ=-0.801990, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action: -1
Next state: 0 0.595362 0.895097 0.571033 0.880978 0.280675 0.657364 w: 1
Observation: 0 0.693053 0 0.63565 0 0.229103 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=122837, meanQ=4.867931, numObservations: 4
action 2, numVisits=60, meanQ=3.781667, numObservations: 3
action 0, numVisits=38, meanQ=3.728285, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 246287 episodes
GETTING ACTION FROM:
action 3, numVisits=369120, meanQ=4.722553, numObservations: 4
action 2, numVisits=60, meanQ=3.781667, numObservations: 3
action 0, numVisits=42, meanQ=3.619665, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.595362 0.895097 0.571033 0.880978 0.280675 0.657364 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=46936, meanQ=8.407929, numObservations: 5
action 2, numVisits=18, meanQ=6.220561, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284085 episodes
GETTING ACTION FROM:
action 1, numVisits=330699, meanQ=6.550509, numObservations: 5
action 2, numVisits=340, meanQ=6.156678, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.595362 0.895097 0.571033 0.880978 0.280675 0.657364 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 278
Initial state: 0 0.915852 0.544421 0.501248 0.807058 0.576726 0.875345 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228862 episodes
GETTING ACTION FROM:
action 2, numVisits=228738, meanQ=5.014243, numObservations: 5
action -1, numVisits=71, meanQ=4.185012, numObservations: 1
action 0, numVisits=51, meanQ=4.032511, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.915852 0.544421 0.501248 0.807058 0.576726 0.875345 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 279
Initial state: 0 0.631835 0.86011 0.556043 0.844984 0.0322113 0.145203 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225042 episodes
GETTING ACTION FROM:
action 3, numVisits=224911, meanQ=4.900297, numObservations: 5
action 2, numVisits=126, meanQ=4.139128, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.631835 0.86011 0.556043 0.844984 0.0322113 0.145203 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5566, meanQ=7.857909, numObservations: 4
action 1, numVisits=21, meanQ=5.856676, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 281013 episodes
GETTING ACTION FROM:
action 2, numVisits=285710, meanQ=6.257167, numObservations: 4
action 1, numVisits=890, meanQ=6.021649, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.631835 0.86011 0.556043 0.844984 0.0322113 0.145203 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 280
Initial state: 0 0.913936 0.494598 0.56642 0.837072 0.696662 0.818918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229369 episodes
GETTING ACTION FROM:
action 1, numVisits=229357, meanQ=4.997318, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.913936 0.494598 0.56642 0.837072 0.696662 0.818918 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 281
Initial state: 0 0.562364 0.863487 0.548598 0.876684 0.243368 0.12101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226985 episodes
GETTING ACTION FROM:
action 1, numVisits=226966, meanQ=5.006375, numObservations: 5
action 3, numVisits=11, meanQ=1.907282, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.562364 0.863487 0.548598 0.876684 0.243368 0.12101 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 282
Initial state: 0 0.493405 0.307045 0.51 0.89211 0.504605 0.837502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227426 episodes
GETTING ACTION FROM:
action 3, numVisits=227419, meanQ=5.093950, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.493405 0.307045 0.51 0.89211 0.504605 0.837502 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 283
Initial state: 0 0.582737 0.878509 0.544228 0.587354 0.657187 0.819458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229953 episodes
GETTING ACTION FROM:
action 1, numVisits=229910, meanQ=4.923349, numObservations: 3
action 0, numVisits=38, meanQ=3.778709, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.582737 0.878509 0.544228 0.587354 0.657187 0.819458 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 284
Initial state: 0 0.356077 0.240497 0.556616 0.871817 0.583603 0.870137 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227183 episodes
GETTING ACTION FROM:
action 1, numVisits=227120, meanQ=4.906486, numObservations: 5
action -1, numVisits=40, meanQ=3.740643, numObservations: 1
action 3, numVisits=20, meanQ=3.095510, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.356077 0.240497 0.556616 0.871817 0.583603 0.870137 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 285
Initial state: 0 0.261291 0.862228 0.609091 0.847092 0.667648 0.833779 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229024 episodes
GETTING ACTION FROM:
action 3, numVisits=228987, meanQ=5.003952, numObservations: 4
action -1, numVisits=25, meanQ=3.514479, numObservations: 1
action 2, numVisits=8, meanQ=1.747513, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.261291 0.862228 0.609091 0.847092 0.667648 0.833779 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 286
Initial state: 0 0.549704 0.876505 0.242526 0.257035 0.6061 0.899639 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228830 episodes
GETTING ACTION FROM:
action 3, numVisits=228787, meanQ=4.955477, numObservations: 4
action 0, numVisits=32, meanQ=3.713864, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.549704 0.876505 0.242526 0.257035 0.6061 0.899639 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 287
Initial state: 0 0.43573 0.974303 0.699334 0.829942 0.505341 0.875433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226432 episodes
GETTING ACTION FROM:
action 1, numVisits=226207, meanQ=4.993216, numObservations: 5
action 0, numVisits=221, meanQ=1.965859, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.43573 0.974303 0.699334 0.829942 0.505341 0.875433 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=4237, meanQ=4.431801, numObservations: 1
action 1, numVisits=9, meanQ=0.997800, numObservations: 2
action 3, numVisits=10, meanQ=0.591010, numObservations: 2
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 290727 episodes
GETTING ACTION FROM:
action 2, numVisits=288416, meanQ=5.695268, numObservations: 3
action -1, numVisits=6553, meanQ=2.679295, numObservations: 1
action 3, numVisits=10, meanQ=0.591010, numObservations: 2
action 1, numVisits=10, meanQ=-0.201980, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.43573 0.974303 0.699334 0.829942 0.505341 0.875433 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 288
Initial state: 0 0.390676 0.754609 0.570435 0.894945 0.678445 0.827705 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228011 episodes
GETTING ACTION FROM:
action 1, numVisits=227947, meanQ=4.955795, numObservations: 4
action -1, numVisits=30, meanQ=3.658705, numObservations: 1
action 0, numVisits=22, meanQ=3.354463, numObservations: 1
action 3, numVisits=11, meanQ=1.180918, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.390676 0.754609 0.570435 0.894945 0.678445 0.827705 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=28857, meanQ=8.398946, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285759 episodes
GETTING ACTION FROM:
action 2, numVisits=314614, meanQ=6.082970, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.390676 0.754609 0.570435 0.894945 0.678445 0.827705 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 289
Initial state: 0 0.558225 0.845891 0.719541 0.737507 0.696266 0.860265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227123 episodes
GETTING ACTION FROM:
action 1, numVisits=227031, meanQ=5.003552, numObservations: 5
action 3, numVisits=82, meanQ=3.723541, numObservations: 4
action 2, numVisits=6, meanQ=1.015000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.558225 0.845891 0.719541 0.737507 0.696266 0.860265 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 290
Initial state: 0 0.503265 0.146652 0.657283 0.814243 0.568133 0.842637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218481 episodes
GETTING ACTION FROM:
action 2, numVisits=218385, meanQ=4.815094, numObservations: 5
action 0, numVisits=72, meanQ=3.997313, numObservations: 1
action 1, numVisits=19, meanQ=2.674216, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.503265 0.146652 0.657283 0.814243 0.568133 0.842637 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 291
Initial state: 0 0.624268 0.810876 0.377139 0.827924 0.523693 0.881432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228964 episodes
GETTING ACTION FROM:
action 3, numVisits=228933, meanQ=4.907026, numObservations: 4
action -1, numVisits=26, meanQ=3.432985, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.624268 0.810876 0.377139 0.827924 0.523693 0.881432 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 292
Initial state: 0 0.553474 0.833421 0.835147 0.455458 0.573672 0.859615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227645 episodes
GETTING ACTION FROM:
action 2, numVisits=227546, meanQ=5.009458, numObservations: 5
action -1, numVisits=49, meanQ=3.971474, numObservations: 1
action 1, numVisits=47, meanQ=3.922130, numObservations: 4
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.553474 0.833421 0.835147 0.455458 0.573672 0.859615 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 293
Initial state: 0 0.581516 0.804213 0.650016 0.827436 0.446313 0.145042 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228650 episodes
GETTING ACTION FROM:
action 3, numVisits=228644, meanQ=5.008303, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.581516 0.804213 0.650016 0.827436 0.446313 0.145042 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=34473, meanQ=8.316433, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 288968 episodes
GETTING ACTION FROM:
action 2, numVisits=323434, meanQ=5.775139, numObservations: 3
action 1, numVisits=7, meanQ=2.427157, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.581516 0.804213 0.650016 0.827436 0.446313 0.145042 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 294
Initial state: 0 0.604929 0.893459 0.381217 0.268755 0.633478 0.844702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229022 episodes
GETTING ACTION FROM:
action 1, numVisits=229016, meanQ=4.899188, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.604929 0.893459 0.381217 0.268755 0.633478 0.844702 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 295
Initial state: 0 0.136779 0.655342 0.616872 0.854988 0.557836 0.890325 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225578 episodes
GETTING ACTION FROM:
action 3, numVisits=225558, meanQ=4.957704, numObservations: 4
action 1, numVisits=15, meanQ=2.606667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.136779 0.655342 0.616872 0.854988 0.557836 0.890325 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 296
Initial state: 0 0.671414 0.86107 0.0473482 0.000223818 0.580332 0.840157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229319 episodes
GETTING ACTION FROM:
action 2, numVisits=229214, meanQ=4.972951, numObservations: 4
action 0, numVisits=46, meanQ=3.907138, numObservations: 1
action 1, numVisits=56, meanQ=3.808218, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.671414 0.86107 0.0473482 0.000223818 0.580332 0.840157 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=35073, meanQ=8.303073, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286909 episodes
GETTING ACTION FROM:
action 3, numVisits=321982, meanQ=6.147401, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.671414 0.86107 0.0473482 0.000223818 0.580332 0.840157 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 297
Initial state: 0 0.672809 0.85803 0.909606 0.308829 0.623271 0.809726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226414 episodes
GETTING ACTION FROM:
action 3, numVisits=226406, meanQ=4.997198, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.672809 0.85803 0.909606 0.308829 0.623271 0.809726 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 298
Initial state: 0 0.648463 0.888646 0.518305 0.831428 0.0273052 0.814538 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224851 episodes
GETTING ACTION FROM:
action 3, numVisits=224840, meanQ=4.963747, numObservations: 5
action 2, numVisits=6, meanQ=1.331683, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.648463 0.888646 0.518305 0.831428 0.0273052 0.814538 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5826, meanQ=7.714199, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 285751 episodes
GETTING ACTION FROM:
action 1, numVisits=291574, meanQ=6.043449, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.648463 0.888646 0.518305 0.831428 0.0273052 0.814538 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 299
Initial state: 0 0.534171 0.843632 0.04559 0.569015 0.546269 0.817834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227483 episodes
GETTING ACTION FROM:
action 1, numVisits=227462, meanQ=4.963130, numObservations: 5
action 3, numVisits=16, meanQ=2.498750, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.534171 0.843632 0.04559 0.569015 0.546269 0.817834 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 300
Initial state: 0 0.990718 0.974241 0.563635 0.803192 0.58429 0.851151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228238 episodes
GETTING ACTION FROM:
action 3, numVisits=228139, meanQ=4.896741, numObservations: 4
action 2, numVisits=46, meanQ=3.604357, numObservations: 3
action 0, numVisits=22, meanQ=3.374138, numObservations: 1
action -1, numVisits=20, meanQ=3.326699, numObservations: 1
action 1, numVisits=11, meanQ=2.453636, numObservations: 3
action: 3
Next state: 1 0.990718 0.974241 0.563635 0.803192 0.58429 0.851151 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 301
Initial state: 0 0.667627 0.801849 0.627897 0.889497 0.554366 0.673795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226197 episodes
GETTING ACTION FROM:
action 1, numVisits=226166, meanQ=4.967735, numObservations: 5
action 2, numVisits=26, meanQ=2.684231, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.667627 0.801849 0.627897 0.889497 0.554366 0.673795 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 302
Initial state: 0 0.672082 0.828217 0.641342 0.858485 0.0637704 0.232883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228896 episodes
GETTING ACTION FROM:
action 1, numVisits=228815, meanQ=4.915935, numObservations: 4
action 0, numVisits=54, meanQ=3.935441, numObservations: 1
action 2, numVisits=21, meanQ=3.285252, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.672082 0.828217 0.641342 0.858485 0.0637704 0.232883 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 303
Initial state: 0 0.521348 0.852778 0.828475 0.0295394 0.679626 0.837649 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226112 episodes
GETTING ACTION FROM:
action 3, numVisits=226105, meanQ=4.917161, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.521348 0.852778 0.828475 0.0295394 0.679626 0.837649 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 304
Initial state: 0 0.573748 0.850617 0.956163 0.705346 0.522303 0.87742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153324 episodes
GETTING ACTION FROM:
action 0, numVisits=153318, meanQ=2.927822, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.573748 0.850617 0.956163 0.705346 0.522303 0.87742 w: 1
Observation: 0 0 0.912468 0 0.609121 0 0.936339 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=153294, meanQ=4.987416, numObservations: 5
action 1, numVisits=18, meanQ=2.443894, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 241140 episodes
GETTING ACTION FROM:
action 2, numVisits=394434, meanQ=4.886507, numObservations: 5
action 1, numVisits=18, meanQ=2.443894, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.573748 0.850617 0.956163 0.705346 0.522303 0.87742 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 305
Initial state: 0 0.524942 0.810237 0.662526 0.852715 0.601675 0.945166 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230098 episodes
GETTING ACTION FROM:
action 1, numVisits=214094, meanQ=4.983061, numObservations: 4
action 3, numVisits=15872, meanQ=4.923190, numObservations: 3
action 2, numVisits=75, meanQ=4.076786, numObservations: 3
action -1, numVisits=55, meanQ=4.038582, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.524942 0.810237 0.662526 0.852715 0.601675 0.945166 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 306
Initial state: 0 0.62711 0.891393 0.679699 0.860309 0.00973214 0.261682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222057 episodes
GETTING ACTION FROM:
action 3, numVisits=222047, meanQ=4.808907, numObservations: 4
action 2, numVisits=5, meanQ=-0.201980, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.62711 0.891393 0.679699 0.860309 0.00973214 0.261682 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 307
Initial state: 0 0.592274 0.893003 0.652187 0.875108 0.769583 0.694617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228718 episodes
GETTING ACTION FROM:
action 3, numVisits=228664, meanQ=4.934228, numObservations: 4
action 0, numVisits=49, meanQ=3.903121, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.592274 0.893003 0.652187 0.875108 0.769583 0.694617 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 308
Initial state: 0 0.63974 0.837028 0.637831 0.807177 0.440642 0.454684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227326 episodes
GETTING ACTION FROM:
action 2, numVisits=227228, meanQ=4.951246, numObservations: 5
action 0, numVisits=93, meanQ=4.233947, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.63974 0.837028 0.637831 0.807177 0.440642 0.454684 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 309
Initial state: 0 0.530328 0.883432 0.134823 0.729676 0.548528 0.811295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222097 episodes
GETTING ACTION FROM:
action 2, numVisits=222090, meanQ=4.805566, numObservations: 3
action 0, numVisits=3, meanQ=-1.673300, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.530328 0.883432 0.134823 0.729676 0.548528 0.811295 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=33753, meanQ=8.302033, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285671 episodes
GETTING ACTION FROM:
action 3, numVisits=319424, meanQ=6.099846, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.530328 0.883432 0.134823 0.729676 0.548528 0.811295 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 310
Initial state: 0 0.531588 0.814594 0.683061 0.884511 0.040524 0.528018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164221 episodes
GETTING ACTION FROM:
action 0, numVisits=156047, meanQ=5.841539, numObservations: 3
action 2, numVisits=8170, meanQ=4.926057, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.531588 0.814594 0.683061 0.884511 0.040524 0.528018 w: 1
Observation: 0 0 0.800856 0 0.955618 0 0.434245 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=51715, meanQ=8.095808, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 248177 episodes
GETTING ACTION FROM:
action 2, numVisits=299852, meanQ=5.552989, numObservations: 5
action -1, numVisits=18, meanQ=3.812072, numObservations: 1
action 0, numVisits=17, meanQ=3.656637, numObservations: 1
action 1, numVisits=9, meanQ=2.342222, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.531588 0.814594 0.683061 0.884511 0.040524 0.528018 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 311
Initial state: 0 0.0182086 0.457653 0.637712 0.807375 0.685626 0.891215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227689 episodes
GETTING ACTION FROM:
action 1, numVisits=227623, meanQ=5.025813, numObservations: 5
action 0, numVisits=53, meanQ=4.049501, numObservations: 1
action 2, numVisits=9, meanQ=2.553344, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0182086 0.457653 0.637712 0.807375 0.685626 0.891215 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=28399, meanQ=8.430626, numObservations: 5
action 2, numVisits=23, meanQ=6.652183, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 281022 episodes
GETTING ACTION FROM:
action 3, numVisits=309401, meanQ=6.236431, numObservations: 5
action 2, numVisits=43, meanQ=5.093030, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0182086 0.457653 0.637712 0.807375 0.685626 0.891215 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 312
Initial state: 0 0.698051 0.866079 0.0939151 0.251196 0.563341 0.869715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228770 episodes
GETTING ACTION FROM:
action 2, numVisits=228709, meanQ=5.005990, numObservations: 5
action -1, numVisits=34, meanQ=3.809585, numObservations: 1
action 0, numVisits=18, meanQ=3.261623, numObservations: 1
action 3, numVisits=8, meanQ=0.748763, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.698051 0.866079 0.0939151 0.251196 0.563341 0.869715 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=22348, meanQ=8.513922, numObservations: 3
action 1, numVisits=20, meanQ=6.299515, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282982 episodes
GETTING ACTION FROM:
action 3, numVisits=305218, meanQ=6.104812, numObservations: 4
action 1, numVisits=132, meanQ=5.454473, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.698051 0.866079 0.0939151 0.251196 0.563341 0.869715 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 313
Initial state: 0 0.994559 0.825646 0.602335 0.828774 0.558514 0.835382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226933 episodes
GETTING ACTION FROM:
action 3, numVisits=226926, meanQ=5.040821, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.994559 0.825646 0.602335 0.828774 0.558514 0.835382 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 314
Initial state: 0 0.469387 0.255087 0.677237 0.838674 0.659337 0.898297 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228776 episodes
GETTING ACTION FROM:
action 1, numVisits=228270, meanQ=4.929562, numObservations: 4
action -1, numVisits=502, meanQ=1.758378, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.469387 0.255087 0.677237 0.838674 0.659337 0.898297 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=34889, meanQ=8.292623, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 285333 episodes
GETTING ACTION FROM:
action 3, numVisits=320220, meanQ=5.695292, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.469387 0.255087 0.677237 0.838674 0.659337 0.898297 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 315
Initial state: 0 0.510994 0.847135 0.574672 0.874283 0.653459 0.98284 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226824 episodes
GETTING ACTION FROM:
action 3, numVisits=226815, meanQ=4.992344, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.510994 0.847135 0.574672 0.874283 0.653459 0.98284 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 316
Initial state: 0 0.583533 0.811717 0.505169 0.807009 0.135167 0.16675 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222079 episodes
GETTING ACTION FROM:
action 1, numVisits=222073, meanQ=4.833752, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.583533 0.811717 0.505169 0.807009 0.135167 0.16675 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 317
Initial state: 0 0.674384 0.858462 0.654543 0.972406 0.645408 0.854588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228561 episodes
GETTING ACTION FROM:
action 2, numVisits=228537, meanQ=4.974340, numObservations: 4
action 3, numVisits=19, meanQ=2.680537, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.674384 0.858462 0.654543 0.972406 0.645408 0.854588 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 318
Initial state: 0 0.257877 0.886963 0.584988 0.86277 0.623561 0.871064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228896 episodes
GETTING ACTION FROM:
action 3, numVisits=228870, meanQ=4.908590, numObservations: 3
action 2, numVisits=21, meanQ=2.705238, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.257877 0.886963 0.584988 0.86277 0.623561 0.871064 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 319
Initial state: 0 0.677691 0.891018 0.605084 0.893521 0.451111 0.0202315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228127 episodes
GETTING ACTION FROM:
action 1, numVisits=228074, meanQ=4.935284, numObservations: 4
action 0, numVisits=34, meanQ=3.713565, numObservations: 1
action 3, numVisits=13, meanQ=2.536923, numObservations: 3
action 2, numVisits=4, meanQ=-2.005000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.677691 0.891018 0.605084 0.893521 0.451111 0.0202315 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 320
Initial state: 0 0.854857 0.367616 0.507055 0.854566 0.560482 0.824753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226033 episodes
GETTING ACTION FROM:
action 2, numVisits=226017, meanQ=5.022011, numObservations: 5
action 1, numVisits=11, meanQ=1.727273, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.854857 0.367616 0.507055 0.854566 0.560482 0.824753 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 321
Initial state: 0 0.506483 0.846199 0.414153 0.655221 0.632214 0.881864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225327 episodes
GETTING ACTION FROM:
action 2, numVisits=225320, meanQ=4.915106, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.506483 0.846199 0.414153 0.655221 0.632214 0.881864 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=34461, meanQ=8.307898, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284944 episodes
GETTING ACTION FROM:
action 1, numVisits=319405, meanQ=6.117705, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.506483 0.846199 0.414153 0.655221 0.632214 0.881864 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 322
Initial state: 0 0.683421 0.867795 0.601685 0.934288 0.672853 0.825924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231107 episodes
GETTING ACTION FROM:
action 1, numVisits=231052, meanQ=4.970138, numObservations: 3
action 0, numVisits=36, meanQ=3.802095, numObservations: 2
action 2, numVisits=13, meanQ=2.998469, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.683421 0.867795 0.601685 0.934288 0.672853 0.825924 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 323
Initial state: 0 0.563071 0.831136 0.671342 0.894983 0.945431 0.989761 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218667 episodes
GETTING ACTION FROM:
action 3, numVisits=218570, meanQ=4.821505, numObservations: 4
action 0, numVisits=33, meanQ=3.596487, numObservations: 1
action 2, numVisits=35, meanQ=3.506294, numObservations: 4
action -1, numVisits=26, meanQ=3.434959, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 3
Next state: 1 0.563071 0.831136 0.671342 0.894983 0.945431 0.989761 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 324
Initial state: 0 0.646093 0.820045 0.882511 0.29616 0.570271 0.807708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224145 episodes
GETTING ACTION FROM:
action 3, numVisits=224061, meanQ=4.894079, numObservations: 5
action -1, numVisits=43, meanQ=3.787289, numObservations: 1
action 0, numVisits=26, meanQ=3.520084, numObservations: 1
action 1, numVisits=9, meanQ=2.333344, numObservations: 3
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action: 3
Next state: 1 0.646093 0.820045 0.882511 0.29616 0.570271 0.807708 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 325
Initial state: 0 0.533357 0.897767 0.0543674 0.8498 0.517206 0.81096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228510 episodes
GETTING ACTION FROM:
action 3, numVisits=228378, meanQ=4.886645, numObservations: 4
action 0, numVisits=118, meanQ=4.242071, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 2
action 1, numVisits=6, meanQ=1.331683, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.533357 0.897767 0.0543674 0.8498 0.517206 0.81096 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 326
Initial state: 0 0.508449 0.830439 0.666514 0.88243 0.933012 0.869641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228805 episodes
GETTING ACTION FROM:
action 2, numVisits=228753, meanQ=4.882070, numObservations: 4
action 0, numVisits=45, meanQ=3.823612, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.508449 0.830439 0.666514 0.88243 0.933012 0.869641 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 327
Initial state: 0 0.54616 0.898341 0.870474 0.887949 0.592274 0.857401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226075 episodes
GETTING ACTION FROM:
action 2, numVisits=225971, meanQ=4.916948, numObservations: 5
action -1, numVisits=93, meanQ=2.631885, numObservations: 1
action 3, numVisits=7, meanQ=1.014286, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.54616 0.898341 0.870474 0.887949 0.592274 0.857401 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 328
Initial state: 0 0.357641 0.782951 0.649336 0.860688 0.691754 0.871181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227367 episodes
GETTING ACTION FROM:
action 2, numVisits=197456, meanQ=4.987324, numObservations: 5
action 3, numVisits=29906, meanQ=4.907769, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.357641 0.782951 0.649336 0.860688 0.691754 0.871181 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 329
Initial state: 0 0.985208 0.639049 0.581769 0.888584 0.548767 0.819897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231974 episodes
GETTING ACTION FROM:
action 2, numVisits=231935, meanQ=4.969600, numObservations: 3
action 0, numVisits=32, meanQ=3.731787, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.985208 0.639049 0.581769 0.888584 0.548767 0.819897 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 330
Initial state: 0 0.568831 0.873825 0.67197 0.0347554 0.633377 0.885129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227018 episodes
GETTING ACTION FROM:
action 1, numVisits=226978, meanQ=4.921807, numObservations: 5
action -1, numVisits=33, meanQ=3.670295, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.568831 0.873825 0.67197 0.0347554 0.633377 0.885129 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 331
Initial state: 0 0.517158 0.897839 0.906686 0.794026 0.53833 0.897365 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228954 episodes
GETTING ACTION FROM:
action 1, numVisits=228871, meanQ=4.942864, numObservations: 4
action -1, numVisits=74, meanQ=4.104113, numObservations: 1
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=4, meanQ=-2.005000, numObservations: 2
action: 1
Next state: 1 0.517158 0.897839 0.906686 0.794026 0.53833 0.897365 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 332
Initial state: 0 0.501245 0.828519 0.686372 0.832791 0.351848 0.967781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227344 episodes
GETTING ACTION FROM:
action 1, numVisits=227287, meanQ=4.985282, numObservations: 4
action 0, numVisits=53, meanQ=3.992240, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.501245 0.828519 0.686372 0.832791 0.351848 0.967781 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 333
Initial state: 0 0.638154 0.897859 0.832758 0.513319 0.587882 0.863965 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227456 episodes
GETTING ACTION FROM:
action 1, numVisits=227398, meanQ=4.893536, numObservations: 4
action -1, numVisits=25, meanQ=3.461260, numObservations: 1
action 2, numVisits=25, meanQ=3.152004, numObservations: 3
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.638154 0.897859 0.832758 0.513319 0.587882 0.863965 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 334
Initial state: 0 0.591256 0.648582 0.61539 0.831274 0.586224 0.863573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228402 episodes
GETTING ACTION FROM:
action 2, numVisits=228289, meanQ=5.025355, numObservations: 5
action 0, numVisits=109, meanQ=4.358338, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.591256 0.648582 0.61539 0.831274 0.586224 0.863573 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 335
Initial state: 0 0.556243 0.86061 0.723342 0.79196 0.554824 0.84877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230461 episodes
GETTING ACTION FROM:
action 3, numVisits=230427, meanQ=4.896683, numObservations: 3
action 2, numVisits=16, meanQ=2.873756, numObservations: 4
action -1, numVisits=12, meanQ=2.564794, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.556243 0.86061 0.723342 0.79196 0.554824 0.84877 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 336
Initial state: 0 0.678739 0.0601288 0.63794 0.886773 0.57744 0.861094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227499 episodes
GETTING ACTION FROM:
action 3, numVisits=227482, meanQ=4.958603, numObservations: 4
action 1, numVisits=12, meanQ=2.333342, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.678739 0.0601288 0.63794 0.886773 0.57744 0.861094 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16590, meanQ=5.657528, numObservations: 4
action 1, numVisits=6, meanQ=2.663350, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284808 episodes
GETTING ACTION FROM:
action 1, numVisits=273215, meanQ=5.912683, numObservations: 4
action 3, numVisits=28186, meanQ=5.238360, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.678739 0.0601288 0.63794 0.886773 0.57744 0.861094 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 337
Initial state: 0 0.668424 0.823099 0.553093 0.987075 0.594288 0.876632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 234327 episodes
GETTING ACTION FROM:
action 2, numVisits=234321, meanQ=5.001949, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.668424 0.823099 0.553093 0.987075 0.594288 0.876632 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 338
Initial state: 0 0.618157 0.415921 0.655944 0.850932 0.682975 0.875958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227463 episodes
GETTING ACTION FROM:
action 3, numVisits=227433, meanQ=4.893009, numObservations: 5
action -1, numVisits=26, meanQ=3.411512, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.618157 0.415921 0.655944 0.850932 0.682975 0.875958 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 339
Initial state: 0 0.57902 0.836422 0.627301 0.822306 0.317647 0.0981492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 121486 episodes
GETTING ACTION FROM:
action 0, numVisits=121452, meanQ=3.753539, numObservations: 1
action 1, numVisits=19, meanQ=2.162647, numObservations: 3
action 2, numVisits=5, meanQ=0.196000, numObservations: 3
action 3, numVisits=8, meanQ=-0.001250, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.57902 0.836422 0.627301 0.822306 0.317647 0.0981492 w: 1
Observation: 0 0 0.933048 0 0.807275 0 0.0365312 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=121439, meanQ=5.871022, numObservations: 3
action 3, numVisits=6, meanQ=0.330033, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 171634 episodes
GETTING ACTION FROM:
action 0, numVisits=293073, meanQ=5.907947, numObservations: 3
action 3, numVisits=6, meanQ=0.330033, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.57902 0.836422 0.627301 0.822306 0.317647 0.0981492 w: 1
Observation: 0 0 0.750383 0 0.847181 0 0.101508 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=113889, meanQ=7.812992, numObservations: 4
action 1, numVisits=26, meanQ=5.999235, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 248527 episodes
GETTING ACTION FROM:
action 2, numVisits=362373, meanQ=6.009808, numObservations: 4
action 1, numVisits=43, meanQ=4.898149, numObservations: 3
action 0, numVisits=26, meanQ=4.474152, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.57902 0.836422 0.627301 0.822306 0.317647 0.0981492 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 340
Initial state: 0 0.576855 0.855825 0.509551 0.843071 0.923892 0.818481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229652 episodes
GETTING ACTION FROM:
action 3, numVisits=229646, meanQ=4.994458, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.576855 0.855825 0.509551 0.843071 0.923892 0.818481 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 341
Initial state: 0 0.594583 0.864598 0.603058 0.836263 0.0697612 0.208708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225799 episodes
GETTING ACTION FROM:
action 1, numVisits=225365, meanQ=4.961018, numObservations: 5
action -1, numVisits=428, meanQ=1.997326, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.594583 0.864598 0.603058 0.836263 0.0697612 0.208708 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 342
Initial state: 0 0.613197 0.0842773 0.58944 0.887939 0.557403 0.870165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228764 episodes
GETTING ACTION FROM:
action 3, numVisits=228650, meanQ=4.976548, numObservations: 4
action -1, numVisits=22, meanQ=3.427941, numObservations: 1
action 1, numVisits=89, meanQ=2.987410, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.613197 0.0842773 0.58944 0.887939 0.557403 0.870165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 343
Initial state: 0 0.0568027 0.437307 0.6735 0.840239 0.688276 0.887862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221276 episodes
GETTING ACTION FROM:
action 1, numVisits=221215, meanQ=4.859538, numObservations: 4
action 0, numVisits=46, meanQ=3.817531, numObservations: 1
action 2, numVisits=12, meanQ=1.997517, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0568027 0.437307 0.6735 0.840239 0.688276 0.887862 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=28494, meanQ=8.377730, numObservations: 4
action 3, numVisits=6, meanQ=3.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287882 episodes
GETTING ACTION FROM:
action 2, numVisits=316301, meanQ=6.129567, numObservations: 4
action 3, numVisits=81, meanQ=5.244321, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.0568027 0.437307 0.6735 0.840239 0.688276 0.887862 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=7489, meanQ=7.650394, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 290523 episodes
GETTING ACTION FROM:
action 2, numVisits=298012, meanQ=6.173787, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0568027 0.437307 0.6735 0.840239 0.688276 0.887862 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 344
Initial state: 0 0.623316 0.825468 0.565782 0.843767 0.0715113 0.148607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220622 episodes
GETTING ACTION FROM:
action 3, numVisits=220563, meanQ=4.982560, numObservations: 4
action 0, numVisits=36, meanQ=3.799395, numObservations: 1
action 2, numVisits=17, meanQ=3.005888, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.623316 0.825468 0.565782 0.843767 0.0715113 0.148607 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=27905, meanQ=8.384139, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286656 episodes
GETTING ACTION FROM:
action 2, numVisits=314560, meanQ=6.195480, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.623316 0.825468 0.565782 0.843767 0.0715113 0.148607 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 345
Initial state: 0 0.531108 0.844756 0.640166 0.891764 0.318739 0.997099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155809 episodes
GETTING ACTION FROM:
action 0, numVisits=155801, meanQ=2.823142, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.531108 0.844756 0.640166 0.891764 0.318739 0.997099 w: 1
Observation: 0 0 0.82969 0 0.978511 0 0.968773 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=153785, meanQ=4.885082, numObservations: 4
action 1, numVisits=1923, meanQ=4.697487, numObservations: 4
action 0, numVisits=41, meanQ=3.806983, numObservations: 1
action 2, numVisits=49, meanQ=3.765112, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 245185 episodes
GETTING ACTION FROM:
action 1, numVisits=219051, meanQ=5.165210, numObservations: 4
action 3, numVisits=181832, meanQ=4.822797, numObservations: 4
action 0, numVisits=51, meanQ=3.852453, numObservations: 1
action 2, numVisits=49, meanQ=3.765112, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.531108 0.844756 0.640166 0.891764 0.318739 0.997099 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 346
Initial state: 0 0.512835 0.876122 0.780171 0.369896 0.629264 0.866717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227642 episodes
GETTING ACTION FROM:
action 3, numVisits=227606, meanQ=4.923571, numObservations: 4
action 2, numVisits=25, meanQ=3.239208, numObservations: 5
action 1, numVisits=7, meanQ=1.570000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.512835 0.876122 0.780171 0.369896 0.629264 0.866717 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 347
Initial state: 0 0.527529 0.810342 0.821482 0.573251 0.539712 0.801612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225521 episodes
GETTING ACTION FROM:
action 1, numVisits=225512, meanQ=4.941396, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.527529 0.810342 0.821482 0.573251 0.539712 0.801612 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 348
Initial state: 0 0.699226 0.826478 0.506838 0.889687 0.913508 0.358009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 232028 episodes
GETTING ACTION FROM:
action 3, numVisits=231996, meanQ=4.985222, numObservations: 3
action 0, numVisits=24, meanQ=3.563662, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.699226 0.826478 0.506838 0.889687 0.913508 0.358009 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 349
Initial state: 0 0.618919 0.8424 0.156507 0.253325 0.602272 0.818865 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227163 episodes
GETTING ACTION FROM:
action 3, numVisits=227097, meanQ=4.882930, numObservations: 4
action 2, numVisits=61, meanQ=2.466725, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.618919 0.8424 0.156507 0.253325 0.602272 0.818865 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 350
Initial state: 0 0.771561 0.421946 0.555073 0.845324 0.672889 0.886039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 232810 episodes
GETTING ACTION FROM:
action 2, numVisits=232800, meanQ=4.978879, numObservations: 3
action 1, numVisits=5, meanQ=-0.597980, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.771561 0.421946 0.555073 0.845324 0.672889 0.886039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 351
Initial state: 0 0.562323 0.895597 0.590821 0.899974 0.182538 0.375074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229306 episodes
GETTING ACTION FROM:
action 2, numVisits=229298, meanQ=5.112093, numObservations: 4
action 3, numVisits=3, meanQ=0.993333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.562323 0.895597 0.590821 0.899974 0.182538 0.375074 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 352
Initial state: 0 0.496496 0.129974 0.512944 0.878444 0.616442 0.885276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229672 episodes
GETTING ACTION FROM:
action 2, numVisits=229662, meanQ=4.925644, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.496496 0.129974 0.512944 0.878444 0.616442 0.885276 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 353
Initial state: 0 0.408351 0.495762 0.57466 0.839735 0.588625 0.897322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223119 episodes
GETTING ACTION FROM:
action 3, numVisits=213711, meanQ=5.023024, numObservations: 5
action 0, numVisits=9402, meanQ=2.977154, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.408351 0.495762 0.57466 0.839735 0.588625 0.897322 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 354
Initial state: 0 0.66538 0.841475 0.85659 0.40901 0.538635 0.806215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230401 episodes
GETTING ACTION FROM:
action 2, numVisits=230305, meanQ=4.983540, numObservations: 4
action -1, numVisits=87, meanQ=4.220725, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.66538 0.841475 0.85659 0.40901 0.538635 0.806215 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 355
Initial state: 0 0.636118 0.803852 0.574734 0.870206 0.306884 0.846848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226665 episodes
GETTING ACTION FROM:
action 3, numVisits=226643, meanQ=4.972958, numObservations: 5
action -1, numVisits=18, meanQ=3.101802, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.636118 0.803852 0.574734 0.870206 0.306884 0.846848 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5528, meanQ=8.001533, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 291235 episodes
GETTING ACTION FROM:
action 1, numVisits=296761, meanQ=5.600692, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.636118 0.803852 0.574734 0.870206 0.306884 0.846848 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 356
Initial state: 0 0.59795 0.866959 0.614695 0.888442 0.625848 0.88686 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230343 episodes
GETTING ACTION FROM:
action 2, numVisits=230277, meanQ=4.999661, numObservations: 4
action 0, numVisits=35, meanQ=3.769094, numObservations: 1
action -1, numVisits=26, meanQ=3.609249, numObservations: 1
action 1, numVisits=4, meanQ=-2.005000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.59795 0.866959 0.614695 0.888442 0.625848 0.88686 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 357
Initial state: 0 0.184094 0.173559 0.570936 0.847848 0.584131 0.832397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226948 episodes
GETTING ACTION FROM:
action 3, numVisits=226880, meanQ=4.994768, numObservations: 5
action 0, numVisits=64, meanQ=4.088469, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.184094 0.173559 0.570936 0.847848 0.584131 0.832397 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 358
Initial state: 0 0.698467 0.881169 0.677031 0.873906 0.204125 0.311594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229579 episodes
GETTING ACTION FROM:
action 2, numVisits=229510, meanQ=4.984822, numObservations: 4
action 0, numVisits=44, meanQ=3.906500, numObservations: 1
action 3, numVisits=22, meanQ=2.453636, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.698467 0.881169 0.677031 0.873906 0.204125 0.311594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 359
Initial state: 0 0.621503 0.853912 0.554126 0.890485 0.659196 0.867769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229309 episodes
GETTING ACTION FROM:
action 1, numVisits=229303, meanQ=4.907772, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.621503 0.853912 0.554126 0.890485 0.659196 0.867769 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 360
Initial state: 0 0.115172 0.343183 0.573147 0.858677 0.63037 0.896216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161908 episodes
GETTING ACTION FROM:
action 0, numVisits=161902, meanQ=5.811279, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.115172 0.343183 0.573147 0.858677 0.63037 0.896216 w: 1
Observation: 0 0 0.425955 0 0.819847 0 0.872929 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=54825, meanQ=8.135258, numObservations: 4
action 3, numVisits=6, meanQ=2.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 251763 episodes
GETTING ACTION FROM:
action 2, numVisits=306586, meanQ=5.778843, numObservations: 4
action 3, numVisits=6, meanQ=2.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.115172 0.343183 0.573147 0.858677 0.63037 0.896216 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 361
Initial state: 0 0.643552 0.874269 0.543643 0.879454 0.899202 0.388446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158246 episodes
GETTING ACTION FROM:
action 0, numVisits=158230, meanQ=2.834739, numObservations: 1
action 1, numVisits=11, meanQ=-0.282718, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.643552 0.874269 0.543643 0.879454 0.899202 0.388446 w: 1
Observation: 0 0 0.904481 0 0.964289 0 0.413959 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=158182, meanQ=4.871044, numObservations: 3
action -1, numVisits=43, meanQ=3.810810, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 250365 episodes
GETTING ACTION FROM:
action 1, numVisits=408545, meanQ=4.846959, numObservations: 3
action -1, numVisits=45, meanQ=3.754609, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.643552 0.874269 0.543643 0.879454 0.899202 0.388446 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 362
Initial state: 0 0.761641 0.805579 0.531059 0.84257 0.514175 0.832408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225333 episodes
GETTING ACTION FROM:
action 2, numVisits=225321, meanQ=5.000046, numObservations: 5
action 1, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.761641 0.805579 0.531059 0.84257 0.514175 0.832408 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 363
Initial state: 0 0.115443 0.0479683 0.64317 0.893205 0.514159 0.824888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223327 episodes
GETTING ACTION FROM:
action 1, numVisits=214606, meanQ=5.019861, numObservations: 4
action -1, numVisits=8717, meanQ=2.949928, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.115443 0.0479683 0.64317 0.893205 0.514159 0.824888 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26822, meanQ=8.414383, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 291276 episodes
GETTING ACTION FROM:
action 2, numVisits=318098, meanQ=6.118598, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.115443 0.0479683 0.64317 0.893205 0.514159 0.824888 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 364
Initial state: 0 0.0685879 0.307693 0.633064 0.817107 0.600674 0.801516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225527 episodes
GETTING ACTION FROM:
action 2, numVisits=224392, meanQ=5.001575, numObservations: 4
action 0, numVisits=1118, meanQ=2.952619, numObservations: 1
action 3, numVisits=14, meanQ=1.572886, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0685879 0.307693 0.633064 0.817107 0.600674 0.801516 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 365
Initial state: 0 0.562798 0.833406 0.887565 0.208706 0.534999 0.829787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229980 episodes
GETTING ACTION FROM:
action 1, numVisits=229906, meanQ=4.981306, numObservations: 3
action 0, numVisits=70, meanQ=4.140661, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.562798 0.833406 0.887565 0.208706 0.534999 0.829787 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 366
Initial state: 0 0.652215 0.271994 0.595265 0.839849 0.596653 0.824844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229343 episodes
GETTING ACTION FROM:
action 3, numVisits=229298, meanQ=4.985745, numObservations: 4
action 0, numVisits=41, meanQ=3.821910, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.652215 0.271994 0.595265 0.839849 0.596653 0.824844 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 367
Initial state: 0 0.519762 0.825064 0.59243 0.882229 0.640548 0.877014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230992 episodes
GETTING ACTION FROM:
action 1, numVisits=230976, meanQ=4.917901, numObservations: 3
action 2, numVisits=10, meanQ=-0.201000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.519762 0.825064 0.59243 0.882229 0.640548 0.877014 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 368
Initial state: 0 0.624192 0.885343 0.0233957 0.738857 0.612908 0.866079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220350 episodes
GETTING ACTION FROM:
action 3, numVisits=218679, meanQ=4.860258, numObservations: 4
action 0, numVisits=1657, meanQ=2.741556, numObservations: 1
action 1, numVisits=10, meanQ=0.603020, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.624192 0.885343 0.0233957 0.738857 0.612908 0.866079 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 369
Initial state: 0 0.621161 0.877099 0.240665 0.177944 0.659022 0.897739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231425 episodes
GETTING ACTION FROM:
action 2, numVisits=231336, meanQ=5.012607, numObservations: 3
action 0, numVisits=47, meanQ=3.979078, numObservations: 1
action 3, numVisits=35, meanQ=3.503143, numObservations: 4
action 1, numVisits=5, meanQ=-0.201980, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.621161 0.877099 0.240665 0.177944 0.659022 0.897739 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=34197, meanQ=8.343768, numObservations: 4
action 1, numVisits=550, meanQ=8.096331, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 280142 episodes
GETTING ACTION FROM:
action 3, numVisits=307818, meanQ=6.175722, numObservations: 4
action 1, numVisits=7071, meanQ=6.103384, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.621161 0.877099 0.240665 0.177944 0.659022 0.897739 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 370
Initial state: 0 0.808723 0.955718 0.564155 0.804858 0.678354 0.810218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230483 episodes
GETTING ACTION FROM:
action 1, numVisits=230292, meanQ=4.897898, numObservations: 3
action 2, numVisits=159, meanQ=4.016803, numObservations: 4
action 0, numVisits=29, meanQ=3.556313, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.808723 0.955718 0.564155 0.804858 0.678354 0.810218 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 371
Initial state: 0 0.583783 0.811153 0.650264 0.820818 0.861181 0.379605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224812 episodes
GETTING ACTION FROM:
action 3, numVisits=217576, meanQ=4.976051, numObservations: 5
action -1, numVisits=7230, meanQ=2.886033, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.583783 0.811153 0.650264 0.820818 0.861181 0.379605 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 372
Initial state: 0 0.93958 0.977132 0.527441 0.804024 0.614838 0.852927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226600 episodes
GETTING ACTION FROM:
action 3, numVisits=226441, meanQ=4.982294, numObservations: 5
action -1, numVisits=129, meanQ=4.309842, numObservations: 1
action 0, numVisits=16, meanQ=3.163541, numObservations: 1
action 1, numVisits=13, meanQ=2.531546, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.93958 0.977132 0.527441 0.804024 0.614838 0.852927 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 373
Initial state: 0 0.537308 0.849718 0.567015 0.31339 0.688731 0.850364 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227322 episodes
GETTING ACTION FROM:
action 2, numVisits=219341, meanQ=4.916300, numObservations: 4
action -1, numVisits=7968, meanQ=2.917687, numObservations: 1
action 3, numVisits=8, meanQ=-1.000000, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.537308 0.849718 0.567015 0.31339 0.688731 0.850364 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 374
Initial state: 0 0.604457 0.428802 0.619801 0.832097 0.682068 0.852079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229061 episodes
GETTING ACTION FROM:
action 1, numVisits=228564, meanQ=4.960520, numObservations: 4
action 3, numVisits=481, meanQ=4.641108, numObservations: 4
action 2, numVisits=12, meanQ=1.832508, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.604457 0.428802 0.619801 0.832097 0.682068 0.852079 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=35130, meanQ=8.288636, numObservations: 4
action 2, numVisits=33, meanQ=6.936061, numObservations: 2
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 282172 episodes
GETTING ACTION FROM:
action 3, numVisits=317199, meanQ=6.149157, numObservations: 4
action 2, numVisits=134, meanQ=5.504702, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.604457 0.428802 0.619801 0.832097 0.682068 0.852079 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 375
Initial state: 0 0.645805 0.846497 0.511454 0.886159 0.344413 0.960794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229729 episodes
GETTING ACTION FROM:
action 3, numVisits=173137, meanQ=4.982287, numObservations: 3
action 2, numVisits=56586, meanQ=4.978438, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.645805 0.846497 0.511454 0.886159 0.344413 0.960794 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=12600, meanQ=5.537004, numObservations: 4
action 2, numVisits=11, meanQ=1.907282, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 262263 episodes
GETTING ACTION FROM:
action 3, numVisits=274861, meanQ=5.054953, numObservations: 5
action 2, numVisits=11, meanQ=1.907282, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.645805 0.846497 0.511454 0.886159 0.344413 0.960794 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=4704, meanQ=5.761812, numObservations: 4
action 3, numVisits=3, meanQ=-0.329967, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 290357 episodes
GETTING ACTION FROM:
action 1, numVisits=295059, meanQ=5.393151, numObservations: 4
action 3, numVisits=3, meanQ=-0.329967, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.645805 0.846497 0.511454 0.886159 0.344413 0.960794 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=3664, meanQ=7.833109, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 288793 episodes
GETTING ACTION FROM:
action 1, numVisits=292453, meanQ=4.920654, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.645805 0.846497 0.511454 0.886159 0.344413 0.960794 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 376
Initial state: 0 0.465309 0.512955 0.50828 0.836086 0.511762 0.898776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 233106 episodes
GETTING ACTION FROM:
action 1, numVisits=233100, meanQ=4.890983, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.465309 0.512955 0.50828 0.836086 0.511762 0.898776 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=35680, meanQ=8.306996, numObservations: 3
action 3, numVisits=24, meanQ=6.749596, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 291556 episodes
GETTING ACTION FROM:
action 2, numVisits=326926, meanQ=6.194191, numObservations: 3
action 3, numVisits=334, meanQ=5.777277, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.465309 0.512955 0.50828 0.836086 0.511762 0.898776 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 377
Initial state: 0 0.670107 0.819377 0.915133 0.802662 0.660776 0.831194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224399 episodes
GETTING ACTION FROM:
action 1, numVisits=224321, meanQ=4.877877, numObservations: 4
action -1, numVisits=65, meanQ=4.019906, numObservations: 1
action 3, numVisits=10, meanQ=2.598000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.670107 0.819377 0.915133 0.802662 0.660776 0.831194 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 378
Initial state: 0 0.697305 0.828482 0.612659 0.887143 0.316621 0.0902337 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228390 episodes
GETTING ACTION FROM:
action 2, numVisits=228326, meanQ=5.106890, numObservations: 5
action -1, numVisits=60, meanQ=4.204396, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.697305 0.828482 0.612659 0.887143 0.316621 0.0902337 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=15233, meanQ=7.235826, numObservations: 4
action 1, numVisits=4, meanQ=2.497525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 262750 episodes
GETTING ACTION FROM:
action 2, numVisits=277957, meanQ=5.341745, numObservations: 4
action 1, numVisits=28, meanQ=3.924646, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.697305 0.828482 0.612659 0.887143 0.316621 0.0902337 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 379
Initial state: 0 0.574562 0.852848 0.526429 0.214192 0.638622 0.807329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229821 episodes
GETTING ACTION FROM:
action 1, numVisits=229717, meanQ=5.112737, numObservations: 4
action -1, numVisits=62, meanQ=4.230774, numObservations: 1
action 0, numVisits=21, meanQ=3.525305, numObservations: 1
action 2, numVisits=20, meanQ=3.399010, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.574562 0.852848 0.526429 0.214192 0.638622 0.807329 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 380
Initial state: 0 0.52374 0.809825 0.582477 0.854038 0.544301 0.828776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227182 episodes
GETTING ACTION FROM:
action 3, numVisits=224125, meanQ=4.993622, numObservations: 4
action -1, numVisits=2655, meanQ=2.896492, numObservations: 1
action 0, numVisits=396, meanQ=2.721673, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.52374 0.809825 0.582477 0.854038 0.544301 0.828776 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 381
Initial state: 0 0.614148 0.844718 0.605486 0.806915 0.541037 0.695311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228158 episodes
GETTING ACTION FROM:
action 1, numVisits=228069, meanQ=5.099451, numObservations: 5
action -1, numVisits=47, meanQ=4.085519, numObservations: 1
action 0, numVisits=35, meanQ=3.907246, numObservations: 1
action 2, numVisits=5, meanQ=1.396020, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.614148 0.844718 0.605486 0.806915 0.541037 0.695311 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 382
Initial state: 0 0.586223 0.830912 0.119402 0.653249 0.604026 0.898281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226472 episodes
GETTING ACTION FROM:
action 1, numVisits=226466, meanQ=4.878277, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.586223 0.830912 0.119402 0.653249 0.604026 0.898281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16698, meanQ=4.684961, numObservations: 3
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 284616 episodes
GETTING ACTION FROM:
action 3, numVisits=301314, meanQ=6.050488, numObservations: 3
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.586223 0.830912 0.119402 0.653249 0.604026 0.898281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 383
Initial state: 0 0.156771 0.899266 0.558241 0.876769 0.584653 0.877232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228163 episodes
GETTING ACTION FROM:
action 3, numVisits=228041, meanQ=4.900298, numObservations: 4
action 0, numVisits=75, meanQ=4.085641, numObservations: 1
action -1, numVisits=43, meanQ=3.829688, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 1 0.156771 0.899266 0.558241 0.876769 0.584653 0.877232 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 384
Initial state: 0 0.665582 0.872227 0.521204 0.815739 0.148352 0.505453 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227608 episodes
GETTING ACTION FROM:
action 1, numVisits=227573, meanQ=4.886449, numObservations: 4
action 2, numVisits=22, meanQ=2.726368, numObservations: 4
action 3, numVisits=9, meanQ=2.098900, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.665582 0.872227 0.521204 0.815739 0.148352 0.505453 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 385
Initial state: 0 0.631779 0.810392 0.737385 0.898523 0.606539 0.823756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225612 episodes
GETTING ACTION FROM:
action 3, numVisits=225604, meanQ=4.943915, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=3, meanQ=-2.966667, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.631779 0.810392 0.737385 0.898523 0.606539 0.823756 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 386
Initial state: 0 0.511368 0.860335 0.945198 0.41454 0.619775 0.884765 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228962 episodes
GETTING ACTION FROM:
action 1, numVisits=228951, meanQ=4.932970, numObservations: 4
action 2, numVisits=6, meanQ=1.001683, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.511368 0.860335 0.945198 0.41454 0.619775 0.884765 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 387
Initial state: 0 0.980126 0.56851 0.515837 0.807373 0.630498 0.870116 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231097 episodes
GETTING ACTION FROM:
action 1, numVisits=230144, meanQ=4.920882, numObservations: 3
action 3, numVisits=948, meanQ=4.695552, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.980126 0.56851 0.515837 0.807373 0.630498 0.870116 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1963, meanQ=6.162471, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 266516 episodes
GETTING ACTION FROM:
action 1, numVisits=268477, meanQ=4.831409, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.980126 0.56851 0.515837 0.807373 0.630498 0.870116 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 388
Initial state: 0 0.600064 0.859008 0.599256 0.844334 0.690691 0.882978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226877 episodes
GETTING ACTION FROM:
action 1, numVisits=222184, meanQ=4.925716, numObservations: 4
action 0, numVisits=4689, meanQ=3.027070, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.600064 0.859008 0.599256 0.844334 0.690691 0.882978 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 389
Initial state: 0 0.435336 0.0856445 0.562991 0.857235 0.679748 0.856308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230812 episodes
GETTING ACTION FROM:
action 3, numVisits=230667, meanQ=4.907352, numObservations: 3
action -1, numVisits=47, meanQ=3.893828, numObservations: 1
action 0, numVisits=46, meanQ=3.867878, numObservations: 1
action 2, numVisits=48, meanQ=3.609385, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action: 3
Next state: 0 0.435336 0.0856445 0.562991 0.857235 0.679748 0.856308 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=34896, meanQ=8.249819, numObservations: 4
action 1, numVisits=123, meanQ=7.662278, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284841 episodes
GETTING ACTION FROM:
action 2, numVisits=318699, meanQ=6.237153, numObservations: 4
action 1, numVisits=1161, meanQ=6.027195, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.435336 0.0856445 0.562991 0.857235 0.679748 0.856308 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 390
Initial state: 0 0.694136 0.805004 0.630622 0.508611 0.619583 0.863449 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222122 episodes
GETTING ACTION FROM:
action 3, numVisits=213806, meanQ=5.081594, numObservations: 5
action 0, numVisits=8310, meanQ=2.932762, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.694136 0.805004 0.630622 0.508611 0.619583 0.863449 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 391
Initial state: 0 0.691597 0.816989 0.648826 0.870607 0.737358 0.375104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226287 episodes
GETTING ACTION FROM:
action 2, numVisits=226280, meanQ=4.948334, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.691597 0.816989 0.648826 0.870607 0.737358 0.375104 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 392
Initial state: 0 0.541397 0.875841 0.629072 0.827987 0.464697 0.726233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218907 episodes
GETTING ACTION FROM:
action 1, numVisits=218898, meanQ=4.790398, numObservations: 5
action 3, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.541397 0.875841 0.629072 0.827987 0.464697 0.726233 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 393
Initial state: 0 0.175867 0.369827 0.526002 0.866992 0.589452 0.861292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159946 episodes
GETTING ACTION FROM:
action 0, numVisits=159856, meanQ=5.848408, numObservations: 3
action -1, numVisits=87, meanQ=2.781580, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.175867 0.369827 0.526002 0.866992 0.589452 0.861292 w: 1
Observation: 0 0 0.418413 0 0.789059 0 0.788387 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=50806, meanQ=8.068518, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 244225 episodes
GETTING ACTION FROM:
action 2, numVisits=294968, meanQ=5.472874, numObservations: 5
action 0, numVisits=40, meanQ=4.328894, numObservations: 1
action -1, numVisits=25, meanQ=3.994496, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.175867 0.369827 0.526002 0.866992 0.589452 0.861292 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 394
Initial state: 0 0.84241 0.454932 0.58701 0.847729 0.692701 0.859465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156323 episodes
GETTING ACTION FROM:
action -1, numVisits=122938, meanQ=2.816906, numObservations: 1
action 0, numVisits=33379, meanQ=2.816694, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.84241 0.454932 0.58701 0.847729 0.692701 0.859465 w: 1
Observation: 0 0.77892 0 0.592407 0 0.751303 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=122927, meanQ=4.898968, numObservations: 5
action 3, numVisits=5, meanQ=0.196000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 244482 episodes
GETTING ACTION FROM:
action 2, numVisits=367409, meanQ=5.020146, numObservations: 5
action 3, numVisits=5, meanQ=0.196000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.84241 0.454932 0.58701 0.847729 0.692701 0.859465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 395
Initial state: 0 0.535757 0.836946 0.665317 0.866686 0.0301718 0.254508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227908 episodes
GETTING ACTION FROM:
action 3, numVisits=226368, meanQ=5.019379, numObservations: 4
action -1, numVisits=1536, meanQ=2.693367, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.535757 0.836946 0.665317 0.866686 0.0301718 0.254508 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=34642, meanQ=8.311150, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 288516 episodes
GETTING ACTION FROM:
action 2, numVisits=323156, meanQ=6.134948, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.535757 0.836946 0.665317 0.866686 0.0301718 0.254508 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 396
Initial state: 0 0.502967 0.825328 0.683524 0.814187 0.69961 0.885184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228569 episodes
GETTING ACTION FROM:
action 3, numVisits=228559, meanQ=4.898125, numObservations: 4
action 1, numVisits=3, meanQ=-0.329967, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.502967 0.825328 0.683524 0.814187 0.69961 0.885184 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 397
Initial state: 0 0.357567 0.544312 0.576559 0.827049 0.582765 0.840303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229699 episodes
GETTING ACTION FROM:
action 1, numVisits=229690, meanQ=4.946578, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.357567 0.544312 0.576559 0.827049 0.582765 0.840303 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=29147, meanQ=8.343543, numObservations: 3
action 3, numVisits=7, meanQ=5.568571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287693 episodes
GETTING ACTION FROM:
action 2, numVisits=316839, meanQ=6.326413, numObservations: 3
action 3, numVisits=8, meanQ=3.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.357567 0.544312 0.576559 0.827049 0.582765 0.840303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 398
Initial state: 0 0.558293 0.879976 0.0835616 0.224964 0.615502 0.84988 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228121 episodes
GETTING ACTION FROM:
action 3, numVisits=228115, meanQ=4.957266, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.558293 0.879976 0.0835616 0.224964 0.615502 0.84988 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 399
Initial state: 0 0.640019 0.882195 0.241742 0.0339646 0.610774 0.802984 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230064 episodes
GETTING ACTION FROM:
action 1, numVisits=230057, meanQ=4.922560, numObservations: 4
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.640019 0.882195 0.241742 0.0339646 0.610774 0.802984 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 400
Initial state: 0 0.629892 0.840859 0.112562 0.853328 0.67538 0.839754 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228476 episodes
GETTING ACTION FROM:
action 1, numVisits=228426, meanQ=4.917912, numObservations: 4
action -1, numVisits=30, meanQ=3.633948, numObservations: 1
action 3, numVisits=17, meanQ=2.763547, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.629892 0.840859 0.112562 0.853328 0.67538 0.839754 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 401
Initial state: 0 0.445465 0.326483 0.687865 0.892798 0.637956 0.849414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225888 episodes
GETTING ACTION FROM:
action 2, numVisits=225684, meanQ=4.911287, numObservations: 5
action 0, numVisits=199, meanQ=4.417300, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.445465 0.326483 0.687865 0.892798 0.637956 0.849414 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 402
Initial state: 0 0.259213 0.473944 0.541656 0.880701 0.637197 0.878525 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223284 episodes
GETTING ACTION FROM:
action 3, numVisits=223263, meanQ=4.936139, numObservations: 5
action -1, numVisits=17, meanQ=3.205889, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.259213 0.473944 0.541656 0.880701 0.637197 0.878525 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 403
Initial state: 0 0.578315 0.813649 0.604785 0.816661 0.837107 0.971343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226949 episodes
GETTING ACTION FROM:
action 3, numVisits=226908, meanQ=5.151080, numObservations: 5
action 0, numVisits=37, meanQ=3.993467, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.578315 0.813649 0.604785 0.816661 0.837107 0.971343 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 404
Initial state: 0 0.617878 0.815654 0.630556 0.826373 0.31769 0.642601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218835 episodes
GETTING ACTION FROM:
action 1, numVisits=218829, meanQ=4.967899, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.617878 0.815654 0.630556 0.826373 0.31769 0.642601 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 405
Initial state: 0 0.180195 0.864747 0.530701 0.891698 0.554045 0.802051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230259 episodes
GETTING ACTION FROM:
action 2, numVisits=230193, meanQ=4.947083, numObservations: 4
action -1, numVisits=56, meanQ=3.803812, numObservations: 1
action 3, numVisits=5, meanQ=0.196000, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.180195 0.864747 0.530701 0.891698 0.554045 0.802051 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 406
Initial state: 0 0.417676 0.473787 0.55283 0.845885 0.593265 0.813279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228954 episodes
GETTING ACTION FROM:
action 2, numVisits=228883, meanQ=5.133664, numObservations: 5
action 0, numVisits=67, meanQ=4.278914, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.417676 0.473787 0.55283 0.845885 0.593265 0.813279 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 407
Initial state: 0 0.705394 0.204094 0.54883 0.855901 0.636188 0.814455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 182755 episodes
GETTING ACTION FROM:
action 0, numVisits=110991, meanQ=5.819617, numObservations: 3
action 3, numVisits=71710, meanQ=4.994227, numObservations: 4
action 1, numVisits=51, meanQ=3.969224, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.705394 0.204094 0.54883 0.855901 0.636188 0.814455 w: 1
Observation: 0 0 0.223053 0 0.764743 0 0.783352 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=36833, meanQ=7.943892, numObservations: 3
action 2, numVisits=18, meanQ=4.332222, numObservations: 3
action 1, numVisits=11, meanQ=3.156364, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 245658 episodes
GETTING ACTION FROM:
action 3, numVisits=282425, meanQ=5.208014, numObservations: 3
action 0, numVisits=44, meanQ=4.140406, numObservations: 1
action 2, numVisits=32, meanQ=3.812194, numObservations: 5
action 1, numVisits=19, meanQ=3.501579, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.705394 0.204094 0.54883 0.855901 0.636188 0.814455 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 408
Initial state: 0 0.671315 0.824496 0.553186 0.856625 0.262171 0.589376 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157082 episodes
GETTING ACTION FROM:
action -1, numVisits=157051, meanQ=2.829755, numObservations: 1
action 3, numVisits=20, meanQ=-0.197990, numObservations: 4
action 1, numVisits=5, meanQ=-1.402000, numObservations: 2
action 2, numVisits=4, meanQ=-2.005000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: -1
Next state: 0 0.671315 0.824496 0.553186 0.856625 0.262171 0.589376 w: 1
Observation: 0 0.60489 0 0.598142 0 0.248065 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=156869, meanQ=4.886278, numObservations: 4
action 0, numVisits=88, meanQ=4.161630, numObservations: 1
action 2, numVisits=52, meanQ=3.690008, numObservations: 4
action 3, numVisits=39, meanQ=3.453851, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 248662 episodes
GETTING ACTION FROM:
action 1, numVisits=405528, meanQ=4.896180, numObservations: 4
action 0, numVisits=91, meanQ=4.143436, numObservations: 1
action 2, numVisits=52, meanQ=3.690008, numObservations: 4
action 3, numVisits=39, meanQ=3.453851, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.671315 0.824496 0.553186 0.856625 0.262171 0.589376 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 409
Initial state: 0 0.524908 0.824466 0.594219 0.873565 0.541029 0.87733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228214 episodes
GETTING ACTION FROM:
action 3, numVisits=228205, meanQ=5.009980, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.524908 0.824466 0.594219 0.873565 0.541029 0.87733 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 410
Initial state: 0 0.540498 0.811502 0.0940754 0.763956 0.673928 0.893877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226137 episodes
GETTING ACTION FROM:
action 3, numVisits=226131, meanQ=5.121498, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.540498 0.811502 0.0940754 0.763956 0.673928 0.893877 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 411
Initial state: 0 0.620857 0.894137 0.181588 0.0771775 0.546431 0.868262 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228081 episodes
GETTING ACTION FROM:
action 1, numVisits=227878, meanQ=5.099599, numObservations: 5
action 3, numVisits=198, meanQ=4.594820, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.620857 0.894137 0.181588 0.0771775 0.546431 0.868262 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 412
Initial state: 0 0.35399 0.258924 0.567385 0.868994 0.554282 0.835149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230601 episodes
GETTING ACTION FROM:
action 1, numVisits=230521, meanQ=4.871528, numObservations: 3
action -1, numVisits=44, meanQ=3.818479, numObservations: 1
action 3, numVisits=21, meanQ=2.713343, numObservations: 3
action 2, numVisits=13, meanQ=2.536923, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.35399 0.258924 0.567385 0.868994 0.554282 0.835149 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=35180, meanQ=8.314449, numObservations: 5
action 3, numVisits=46, meanQ=7.263485, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 284384 episodes
GETTING ACTION FROM:
action 2, numVisits=315569, meanQ=6.050222, numObservations: 5
action 3, numVisits=4039, meanQ=5.949373, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.35399 0.258924 0.567385 0.868994 0.554282 0.835149 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 413
Initial state: 0 0.578735 0.843467 0.592885 0.857265 0.649148 0.0879084 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229407 episodes
GETTING ACTION FROM:
action 2, numVisits=229365, meanQ=4.897333, numObservations: 4
action -1, numVisits=34, meanQ=3.681265, numObservations: 1
action 1, numVisits=5, meanQ=1.396020, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.578735 0.843467 0.592885 0.857265 0.649148 0.0879084 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 414
Initial state: 0 0.646263 0.765949 0.510018 0.889612 0.535664 0.873594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223442 episodes
GETTING ACTION FROM:
action 2, numVisits=223361, meanQ=4.794430, numObservations: 3
action 0, numVisits=74, meanQ=3.972042, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.646263 0.765949 0.510018 0.889612 0.535664 0.873594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 415
Initial state: 0 0.592846 0.851848 0.505376 0.893227 0.172553 0.927264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230287 episodes
GETTING ACTION FROM:
action 2, numVisits=230281, meanQ=4.988914, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.592846 0.851848 0.505376 0.893227 0.172553 0.927264 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 416
Initial state: 0 0.528713 0.828349 0.533241 0.872128 0.105943 0.720148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229048 episodes
GETTING ACTION FROM:
action 1, numVisits=228974, meanQ=4.914828, numObservations: 4
action 3, numVisits=69, meanQ=3.975077, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.528713 0.828349 0.533241 0.872128 0.105943 0.720148 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 417
Initial state: 0 0.629185 0.495784 0.531756 0.871733 0.541031 0.898446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227045 episodes
GETTING ACTION FROM:
action 3, numVisits=227037, meanQ=4.980850, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.629185 0.495784 0.531756 0.871733 0.541031 0.898446 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 418
Initial state: 0 0.526117 0.893662 0.582681 0.899318 0.614915 0.440693 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229362 episodes
GETTING ACTION FROM:
action 2, numVisits=229283, meanQ=4.943451, numObservations: 4
action 1, numVisits=62, meanQ=3.891290, numObservations: 3
action 3, numVisits=13, meanQ=2.846162, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.526117 0.893662 0.582681 0.899318 0.614915 0.440693 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 419
Initial state: 0 0.539904 0.868033 0.617717 0.817883 0.454115 0.544546 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224612 episodes
GETTING ACTION FROM:
action 2, numVisits=26397, meanQ=4.971777, numObservations: 5
action 1, numVisits=198158, meanQ=4.894955, numObservations: 5
action 3, numVisits=37, meanQ=3.540286, numObservations: 4
action -1, numVisits=18, meanQ=3.258703, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.539904 0.868033 0.617717 0.817883 0.454115 0.544546 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1894, meanQ=5.742674, numObservations: 3
action 1, numVisits=60, meanQ=3.910500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
Sampled 285142 episodes
GETTING ACTION FROM:
action 1, numVisits=256229, meanQ=5.953211, numObservations: 4
action 2, numVisits=30865, meanQ=4.703791, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action: 1
Next state: 1 0.539904 0.868033 0.617717 0.817883 0.454115 0.544546 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 420
Initial state: 0 0.616214 0.885803 0.166902 0.859294 0.606815 0.827796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222503 episodes
GETTING ACTION FROM:
action 2, numVisits=222485, meanQ=4.818247, numObservations: 3
action 3, numVisits=12, meanQ=2.332525, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.616214 0.885803 0.166902 0.859294 0.606815 0.827796 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 421
Initial state: 0 0.971581 0.814116 0.698822 0.888023 0.500111 0.883341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153600 episodes
GETTING ACTION FROM:
action 0, numVisits=153581, meanQ=2.860104, numObservations: 1
action 2, numVisits=7, meanQ=-0.429986, numObservations: 3
action 3, numVisits=7, meanQ=-1.287143, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.971581 0.814116 0.698822 0.888023 0.500111 0.883341 w: 1
Observation: 0 0 0.90648 0 0.868163 0 0.970709 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=153358, meanQ=4.940103, numObservations: 4
action 0, numVisits=176, meanQ=4.398544, numObservations: 1
action 3, numVisits=43, meanQ=3.589767, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 236346 episodes
GETTING ACTION FROM:
action 1, numVisits=389704, meanQ=5.053428, numObservations: 4
action 0, numVisits=176, meanQ=4.398544, numObservations: 1
action 3, numVisits=43, meanQ=3.589767, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.971581 0.814116 0.698822 0.888023 0.500111 0.883341 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 422
Initial state: 0 0.619152 0.885938 0.263571 0.268279 0.591519 0.812465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226103 episodes
GETTING ACTION FROM:
action 3, numVisits=226096, meanQ=5.088139, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.619152 0.885938 0.263571 0.268279 0.591519 0.812465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 423
Initial state: 0 0.596335 0.882305 0.341439 0.561095 0.578141 0.854351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230171 episodes
GETTING ACTION FROM:
action 2, numVisits=230128, meanQ=4.972932, numObservations: 4
action -1, numVisits=31, meanQ=3.643990, numObservations: 1
action 3, numVisits=9, meanQ=2.553344, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.596335 0.882305 0.341439 0.561095 0.578141 0.854351 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 424
Initial state: 0 0.290362 0.386949 0.580008 0.804898 0.625986 0.879434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226418 episodes
GETTING ACTION FROM:
action 2, numVisits=226411, meanQ=4.987273, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.290362 0.386949 0.580008 0.804898 0.625986 0.879434 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 425
Initial state: 0 0.680675 0.817385 0.939216 0.500658 0.621668 0.871902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226603 episodes
GETTING ACTION FROM:
action 1, numVisits=226514, meanQ=4.934232, numObservations: 5
action 0, numVisits=57, meanQ=4.013762, numObservations: 1
action -1, numVisits=30, meanQ=3.618895, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.680675 0.817385 0.939216 0.500658 0.621668 0.871902 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 426
Initial state: 0 0.437462 0.902583 0.681982 0.888085 0.638664 0.800897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231724 episodes
GETTING ACTION FROM:
action 1, numVisits=231690, meanQ=4.910628, numObservations: 3
action -1, numVisits=27, meanQ=3.463664, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.437462 0.902583 0.681982 0.888085 0.638664 0.800897 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16779, meanQ=4.590657, numObservations: 5
action -1, numVisits=24, meanQ=3.048054, numObservations: 1
action 3, numVisits=17, meanQ=2.763547, numObservations: 4
action 1, numVisits=3, meanQ=0.330033, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 285545 episodes
GETTING ACTION FROM:
action 2, numVisits=302324, meanQ=5.660664, numObservations: 5
action -1, numVisits=24, meanQ=3.048054, numObservations: 1
action 3, numVisits=17, meanQ=2.763547, numObservations: 4
action 1, numVisits=3, meanQ=0.330033, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.437462 0.902583 0.681982 0.888085 0.638664 0.800897 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 427
Initial state: 0 0.59988 0.898589 0.589703 0.727727 0.581262 0.888588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225785 episodes
GETTING ACTION FROM:
action 3, numVisits=219909, meanQ=4.899519, numObservations: 4
action 0, numVisits=5824, meanQ=2.804752, numObservations: 1
action -1, numVisits=46, meanQ=2.004308, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.59988 0.898589 0.589703 0.727727 0.581262 0.888588 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 428
Initial state: 0 0.488936 0.0918596 0.563998 0.886045 0.67908 0.835223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227962 episodes
GETTING ACTION FROM:
action 3, numVisits=227956, meanQ=5.004660, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.488936 0.0918596 0.563998 0.886045 0.67908 0.835223 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 429
Initial state: 0 0.614733 0.866359 0.644178 0.297642 0.668357 0.848211 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223391 episodes
GETTING ACTION FROM:
action 2, numVisits=211388, meanQ=4.936876, numObservations: 5
action -1, numVisits=11999, meanQ=3.063628, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.614733 0.866359 0.644178 0.297642 0.668357 0.848211 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 430
Initial state: 0 0.511355 0.80581 0.685563 0.868465 0.821988 0.368776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225284 episodes
GETTING ACTION FROM:
action 2, numVisits=225254, meanQ=4.913421, numObservations: 4
action 3, numVisits=25, meanQ=3.159608, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.511355 0.80581 0.685563 0.868465 0.821988 0.368776 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 431
Initial state: 0 0.640246 0.830217 0.96731 0.853243 0.686944 0.899835 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219978 episodes
GETTING ACTION FROM:
action 2, numVisits=219951, meanQ=4.848283, numObservations: 4
action 1, numVisits=22, meanQ=2.999105, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.640246 0.830217 0.96731 0.853243 0.686944 0.899835 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 432
Initial state: 0 0.669746 0.853264 0.614507 0.534632 0.631268 0.828193 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230043 episodes
GETTING ACTION FROM:
action 1, numVisits=229982, meanQ=5.021739, numObservations: 4
action -1, numVisits=41, meanQ=3.904050, numObservations: 1
action 2, numVisits=16, meanQ=2.748775, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.669746 0.853264 0.614507 0.534632 0.631268 0.828193 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 433
Initial state: 0 0.23365 0.833282 0.51466 0.81861 0.545729 0.867625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228105 episodes
GETTING ACTION FROM:
action 3, numVisits=228099, meanQ=4.947308, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.23365 0.833282 0.51466 0.81861 0.545729 0.867625 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 434
Initial state: 0 0.47268 0.670764 0.535201 0.805659 0.651543 0.832974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227417 episodes
GETTING ACTION FROM:
action 1, numVisits=223276, meanQ=5.003970, numObservations: 5
action 3, numVisits=3432, meanQ=4.839915, numObservations: 4
action 2, numVisits=638, meanQ=4.705325, numObservations: 5
action 0, numVisits=51, meanQ=4.025125, numObservations: 1
action -1, numVisits=20, meanQ=3.427765, numObservations: 1
action: 1
Next state: 0 0.47268 0.670764 0.535201 0.805659 0.651543 0.832974 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=28258, meanQ=8.381680, numObservations: 3
action 3, numVisits=14, meanQ=5.572150, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 291532 episodes
GETTING ACTION FROM:
action 2, numVisits=319615, meanQ=6.132457, numObservations: 3
action 3, numVisits=189, meanQ=5.612381, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.47268 0.670764 0.535201 0.805659 0.651543 0.832974 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 435
Initial state: 0 0.591475 0.841849 0.595994 0.873163 0.630397 0.817772 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228283 episodes
GETTING ACTION FROM:
action 2, numVisits=228269, meanQ=4.897176, numObservations: 4
action 1, numVisits=9, meanQ=1.644456, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.591475 0.841849 0.595994 0.873163 0.630397 0.817772 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 436
Initial state: 0 0.00159771 0.174924 0.635009 0.894648 0.551393 0.802012 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229468 episodes
GETTING ACTION FROM:
action 3, numVisits=229460, meanQ=4.958631, numObservations: 3
action 2, numVisits=3, meanQ=0.330033, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.00159771 0.174924 0.635009 0.894648 0.551393 0.802012 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 437
Initial state: 0 0.408486 0.661094 0.658291 0.824906 0.523726 0.841786 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229469 episodes
GETTING ACTION FROM:
action 1, numVisits=229463, meanQ=4.890350, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.408486 0.661094 0.658291 0.824906 0.523726 0.841786 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 438
Initial state: 0 0.566142 0.893876 0.814814 0.142612 0.517268 0.8771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227874 episodes
GETTING ACTION FROM:
action 1, numVisits=227868, meanQ=4.875180, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.566142 0.893876 0.814814 0.142612 0.517268 0.8771 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 439
Initial state: 0 0.557836 0.831992 0.503416 0.801679 0.402242 0.0739642 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227177 episodes
GETTING ACTION FROM:
action 3, numVisits=227091, meanQ=4.903547, numObservations: 5
action -1, numVisits=73, meanQ=4.090259, numObservations: 1
action 1, numVisits=10, meanQ=0.981000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.557836 0.831992 0.503416 0.801679 0.402242 0.0739642 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=15322, meanQ=8.528176, numObservations: 3
action 1, numVisits=6885, meanQ=8.500438, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286429 episodes
GETTING ACTION FROM:
action 2, numVisits=216643, meanQ=6.058709, numObservations: 4
action 1, numVisits=91991, meanQ=6.052418, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.557836 0.831992 0.503416 0.801679 0.402242 0.0739642 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 440
Initial state: 0 0.678223 0.860856 0.732017 0.863427 0.64571 0.881539 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226799 episodes
GETTING ACTION FROM:
action 3, numVisits=226789, meanQ=4.964694, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.678223 0.860856 0.732017 0.863427 0.64571 0.881539 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16553, meanQ=5.346498, numObservations: 4
action 1, numVisits=5, meanQ=1.780000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
Sampled 262620 episodes
GETTING ACTION FROM:
action 3, numVisits=279171, meanQ=5.224876, numObservations: 4
action 1, numVisits=5, meanQ=1.780000, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.678223 0.860856 0.732017 0.863427 0.64571 0.881539 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 441
Initial state: 0 0.520302 0.859943 0.885659 0.833503 0.656009 0.830004 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224060 episodes
GETTING ACTION FROM:
action 3, numVisits=224048, meanQ=4.837099, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.520302 0.859943 0.885659 0.833503 0.656009 0.830004 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 442
Initial state: 0 0.630693 0.961869 0.668722 0.883995 0.500932 0.821902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226607 episodes
GETTING ACTION FROM:
action 2, numVisits=226589, meanQ=4.911268, numObservations: 5
action 0, numVisits=14, meanQ=3.029495, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.630693 0.961869 0.668722 0.883995 0.500932 0.821902 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16625, meanQ=4.653766, numObservations: 5
action 1, numVisits=18, meanQ=2.337778, numObservations: 4
action 0, numVisits=10, meanQ=2.091670, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 280377 episodes
GETTING ACTION FROM:
action 3, numVisits=297002, meanQ=5.668074, numObservations: 5
action 1, numVisits=18, meanQ=2.337778, numObservations: 4
action 0, numVisits=10, meanQ=2.091670, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.630693 0.961869 0.668722 0.883995 0.500932 0.821902 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 443
Initial state: 0 0.871558 0.420526 0.6802 0.896398 0.654169 0.84859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229648 episodes
GETTING ACTION FROM:
action 3, numVisits=229642, meanQ=5.003067, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.871558 0.420526 0.6802 0.896398 0.654169 0.84859 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 444
Initial state: 0 0.598229 0.852126 0.145813 0.532107 0.559616 0.895903 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229073 episodes
GETTING ACTION FROM:
action 2, numVisits=229024, meanQ=4.897478, numObservations: 4
action -1, numVisits=30, meanQ=3.624792, numObservations: 1
action 0, numVisits=17, meanQ=3.104275, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.598229 0.852126 0.145813 0.532107 0.559616 0.895903 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=34767, meanQ=8.141891, numObservations: 4
action 1, numVisits=14, meanQ=6.284293, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 278351 episodes
GETTING ACTION FROM:
action 3, numVisits=313100, meanQ=6.198108, numObservations: 4
action 1, numVisits=32, meanQ=4.874381, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.598229 0.852126 0.145813 0.532107 0.559616 0.895903 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 445
Initial state: 0 0.638223 0.846603 0.965477 0.873584 0.583218 0.828395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227389 episodes
GETTING ACTION FROM:
action 1, numVisits=227344, meanQ=4.898173, numObservations: 4
action 0, numVisits=39, meanQ=3.754276, numObservations: 1
action 3, numVisits=3, meanQ=-0.329967, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.638223 0.846603 0.965477 0.873584 0.583218 0.828395 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=34604, meanQ=8.277955, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 281862 episodes
GETTING ACTION FROM:
action 2, numVisits=316466, meanQ=6.185220, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.638223 0.846603 0.965477 0.873584 0.583218 0.828395 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 446
Initial state: 0 0.335912 0.490717 0.564551 0.817781 0.567574 0.804226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225210 episodes
GETTING ACTION FROM:
action 1, numVisits=225168, meanQ=4.913225, numObservations: 5
action -1, numVisits=27, meanQ=3.557028, numObservations: 1
action 0, numVisits=13, meanQ=2.784054, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.335912 0.490717 0.564551 0.817781 0.567574 0.804226 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=14733, meanQ=8.395330, numObservations: 3
action 3, numVisits=14039, meanQ=8.381202, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287587 episodes
GETTING ACTION FROM:
action 2, numVisits=183978, meanQ=6.063167, numObservations: 3
action 3, numVisits=132379, meanQ=6.059647, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.335912 0.490717 0.564551 0.817781 0.567574 0.804226 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 447
Initial state: 0 0.500538 0.814701 0.562973 0.829391 0.799391 0.377588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 152672 episodes
GETTING ACTION FROM:
action 0, numVisits=152663, meanQ=2.740353, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.500538 0.814701 0.562973 0.829391 0.799391 0.377588 w: 1
Observation: 0 0 0.879106 0 0.762167 0 0.278284 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=152641, meanQ=4.831732, numObservations: 5
action 2, numVisits=14, meanQ=1.998579, numObservations: 3
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 240635 episodes
GETTING ACTION FROM:
action 1, numVisits=393276, meanQ=4.676251, numObservations: 5
action 2, numVisits=14, meanQ=1.998579, numObservations: 3
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.500538 0.814701 0.562973 0.829391 0.799391 0.377588 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 448
Initial state: 0 0.611485 0.836516 0.648448 0.806139 0.0732198 0.0856589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227134 episodes
GETTING ACTION FROM:
action 1, numVisits=227113, meanQ=5.114747, numObservations: 5
action 0, numVisits=17, meanQ=3.387965, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.611485 0.836516 0.648448 0.806139 0.0732198 0.0856589 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 449
Initial state: 0 0.910078 0.101764 0.677081 0.840222 0.500313 0.806335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155669 episodes
GETTING ACTION FROM:
action 0, numVisits=155639, meanQ=2.931922, numObservations: 2
action 1, numVisits=20, meanQ=1.300010, numObservations: 2
action 2, numVisits=5, meanQ=-1.402000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 1
action: 0
Next state: 0 0.910078 0.101764 0.677081 0.840222 0.500313 0.806335 w: 1
Observation: 0 0 0.0605566 0 0.801063 0 0.862121 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=110322, meanQ=3.656787, numObservations: 4
action 3, numVisits=16, meanQ=0.749381, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
Sampled 249452 episodes
GETTING ACTION FROM:
action 2, numVisits=359774, meanQ=4.514699, numObservations: 4
action 3, numVisits=16, meanQ=0.749381, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 2
Next state: 1 0.910078 0.101764 0.677081 0.840222 0.500313 0.806335 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 450
Initial state: 0 0.579327 0.893411 0.585658 0.839868 0.346042 0.194801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230343 episodes
GETTING ACTION FROM:
action 1, numVisits=230301, meanQ=4.897459, numObservations: 3
action 0, numVisits=34, meanQ=3.695059, numObservations: 1
action 3, numVisits=5, meanQ=0.998040, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.579327 0.893411 0.585658 0.839868 0.346042 0.194801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 451
Initial state: 0 0.509147 0.851272 0.638562 0.33302 0.504072 0.823538 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228446 episodes
GETTING ACTION FROM:
action 2, numVisits=228300, meanQ=4.974643, numObservations: 5
action -1, numVisits=140, meanQ=4.370234, numObservations: 1
action 1, numVisits=3, meanQ=-0.329967, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.509147 0.851272 0.638562 0.33302 0.504072 0.823538 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 452
Initial state: 0 0.898146 0.648275 0.663364 0.835338 0.693159 0.851913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227840 episodes
GETTING ACTION FROM:
action 1, numVisits=227772, meanQ=4.902641, numObservations: 4
action -1, numVisits=29, meanQ=3.514816, numObservations: 1
action 3, numVisits=35, meanQ=2.940297, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.898146 0.648275 0.663364 0.835338 0.693159 0.851913 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 453
Initial state: 0 0.649043 0.802512 0.691933 0.866122 0.531061 0.887753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157657 episodes
GETTING ACTION FROM:
action 0, numVisits=157648, meanQ=2.880523, numObservations: 1
action 3, numVisits=5, meanQ=-0.622000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.649043 0.802512 0.691933 0.866122 0.531061 0.887753 w: 1
Observation: 0 0 0.873027 0 0.931539 0 0.825606 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=157502, meanQ=4.910277, numObservations: 3
action 0, numVisits=106, meanQ=4.252324, numObservations: 1
action -1, numVisits=27, meanQ=3.528696, numObservations: 1
action 1, numVisits=11, meanQ=2.453636, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 249198 episodes
GETTING ACTION FROM:
action 2, numVisits=406694, meanQ=4.864734, numObservations: 3
action 0, numVisits=111, meanQ=4.191030, numObservations: 1
action -1, numVisits=28, meanQ=3.477160, numObservations: 1
action 1, numVisits=11, meanQ=2.453636, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.649043 0.802512 0.691933 0.866122 0.531061 0.887753 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 454
Initial state: 0 0.642359 0.826338 0.667236 0.83863 0.324976 0.165023 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219048 episodes
GETTING ACTION FROM:
action 3, numVisits=219016, meanQ=4.806424, numObservations: 5
action 0, numVisits=17, meanQ=3.101538, numObservations: 1
action 2, numVisits=7, meanQ=2.144300, numObservations: 3
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.642359 0.826338 0.667236 0.83863 0.324976 0.165023 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=26491, meanQ=8.376196, numObservations: 4
action 2, numVisits=1548, meanQ=8.206210, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284500 episodes
GETTING ACTION FROM:
action 1, numVisits=287142, meanQ=6.101461, numObservations: 4
action 2, numVisits=25397, meanQ=6.069314, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.642359 0.826338 0.667236 0.83863 0.324976 0.165023 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 455
Initial state: 0 0.831134 0.520088 0.690395 0.813489 0.635089 0.890215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215076 episodes
GETTING ACTION FROM:
action 3, numVisits=214986, meanQ=4.693470, numObservations: 5
action -1, numVisits=55, meanQ=3.751582, numObservations: 1
action 0, numVisits=20, meanQ=2.971586, numObservations: 1
action 1, numVisits=14, meanQ=1.862857, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.831134 0.520088 0.690395 0.813489 0.635089 0.890215 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 456
Initial state: 0 0.570868 0.802571 0.346585 0.683579 0.601541 0.882665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229250 episodes
GETTING ACTION FROM:
action 3, numVisits=224074, meanQ=5.098193, numObservations: 4
action 2, numVisits=5135, meanQ=4.960943, numObservations: 4
action 1, numVisits=37, meanQ=3.913792, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.570868 0.802571 0.346585 0.683579 0.601541 0.882665 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=14605, meanQ=7.234507, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 270347 episodes
GETTING ACTION FROM:
action 3, numVisits=284950, meanQ=4.862755, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.570868 0.802571 0.346585 0.683579 0.601541 0.882665 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 457
Initial state: 0 0.665391 0.837056 0.2716 0.202585 0.562136 0.882072 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227631 episodes
GETTING ACTION FROM:
action 3, numVisits=227623, meanQ=4.944342, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.665391 0.837056 0.2716 0.202585 0.562136 0.882072 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 458
Initial state: 0 0.59757 0.892089 0.55576 0.810094 0.190609 0.28129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227315 episodes
GETTING ACTION FROM:
action 3, numVisits=227306, meanQ=4.958356, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=4, meanQ=-2.005000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.59757 0.892089 0.55576 0.810094 0.190609 0.28129 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=22267, meanQ=8.536735, numObservations: 3
action 1, numVisits=94, meanQ=7.887769, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 289952 episodes
GETTING ACTION FROM:
action 2, numVisits=311952, meanQ=6.290367, numObservations: 3
action 1, numVisits=361, meanQ=5.915432, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.59757 0.892089 0.55576 0.810094 0.190609 0.28129 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 459
Initial state: 0 0.676155 0.854709 0.633197 0.81433 0.103836 0.0715492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228342 episodes
GETTING ACTION FROM:
action 2, numVisits=227980, meanQ=4.995235, numObservations: 5
action 1, numVisits=199, meanQ=4.483813, numObservations: 3
action -1, numVisits=134, meanQ=4.401030, numObservations: 1
action 0, numVisits=28, meanQ=3.654018, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.676155 0.854709 0.633197 0.81433 0.103836 0.0715492 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 460
Initial state: 0 0.636952 0.954758 0.626232 0.866049 0.695539 0.880026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226516 episodes
GETTING ACTION FROM:
action 2, numVisits=226510, meanQ=5.113689, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.636952 0.954758 0.626232 0.866049 0.695539 0.880026 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 461
Initial state: 0 0.595766 0.883042 0.618005 0.891641 0.334001 0.697842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226200 episodes
GETTING ACTION FROM:
action 3, numVisits=226151, meanQ=4.917782, numObservations: 5
action 0, numVisits=37, meanQ=3.751296, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.595766 0.883042 0.618005 0.891641 0.334001 0.697842 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=22169, meanQ=8.533324, numObservations: 3
action 2, numVisits=9, meanQ=6.110011, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282985 episodes
GETTING ACTION FROM:
action 2, numVisits=179366, meanQ=6.200931, numObservations: 5
action 1, numVisits=125797, meanQ=6.183348, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.595766 0.883042 0.618005 0.891641 0.334001 0.697842 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 462
Initial state: 0 0.140051 0.292444 0.565476 0.855181 0.690944 0.89199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229343 episodes
GETTING ACTION FROM:
action 2, numVisits=229311, meanQ=5.005952, numObservations: 4
action 0, numVisits=28, meanQ=3.690138, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.140051 0.292444 0.565476 0.855181 0.690944 0.89199 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 463
Initial state: 0 0.536568 0.813197 0.233685 0.94636 0.517184 0.812801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227907 episodes
GETTING ACTION FROM:
action 3, numVisits=227874, meanQ=4.940902, numObservations: 4
action 0, numVisits=28, meanQ=3.427909, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.536568 0.813197 0.233685 0.94636 0.517184 0.812801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 464
Initial state: 0 0.576066 0.875538 0.649017 0.892661 0.139727 0.49981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228972 episodes
GETTING ACTION FROM:
action 1, numVisits=228894, meanQ=4.895029, numObservations: 4
action -1, numVisits=44, meanQ=3.844262, numObservations: 1
action 3, numVisits=31, meanQ=3.374526, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.576066 0.875538 0.649017 0.892661 0.139727 0.49981 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 465
Initial state: 0 0.0365707 0.538827 0.693962 0.858619 0.629851 0.813801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156969 episodes
GETTING ACTION FROM:
action 0, numVisits=154066, meanQ=2.902785, numObservations: 1
action -1, numVisits=2875, meanQ=2.791388, numObservations: 1
action 3, numVisits=26, meanQ=1.373854, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0365707 0.538827 0.693962 0.858619 0.629851 0.813801 w: 1
Observation: 0 0 0.49606 0 0.89636 0 0.717982 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=154007, meanQ=4.939930, numObservations: 4
action -1, numVisits=41, meanQ=3.872098, numObservations: 1
action 3, numVisits=14, meanQ=2.856436, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 246581 episodes
GETTING ACTION FROM:
action 2, numVisits=400584, meanQ=4.914225, numObservations: 4
action -1, numVisits=45, meanQ=3.834009, numObservations: 1
action 3, numVisits=14, meanQ=2.856436, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0365707 0.538827 0.693962 0.858619 0.629851 0.813801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 466
Initial state: 0 0.621607 0.837829 0.582165 0.849155 0.26926 0.373722 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229724 episodes
GETTING ACTION FROM:
action 2, numVisits=229683, meanQ=5.023218, numObservations: 4
action 0, numVisits=36, meanQ=3.845735, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.621607 0.837829 0.582165 0.849155 0.26926 0.373722 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 467
Initial state: 0 0.521016 0.881574 0.677738 0.833769 0.582824 0.27697 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229179 episodes
GETTING ACTION FROM:
action 3, numVisits=229070, meanQ=5.122209, numObservations: 4
action -1, numVisits=45, meanQ=4.069637, numObservations: 1
action 1, numVisits=32, meanQ=3.811884, numObservations: 3
action 0, numVisits=25, meanQ=3.705805, numObservations: 1
action 2, numVisits=7, meanQ=2.427157, numObservations: 3
action: 3
Next state: 2 0.521016 0.881574 0.677738 0.833769 0.582824 0.27697 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 468
Initial state: 0 0.613672 0.870637 0.783231 0.523132 0.63949 0.834321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226896 episodes
GETTING ACTION FROM:
action 2, numVisits=226838, meanQ=4.990267, numObservations: 5
action 0, numVisits=54, meanQ=4.037267, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.613672 0.870637 0.783231 0.523132 0.63949 0.834321 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 469
Initial state: 0 0.619415 0.887562 0.523976 0.839801 0.619523 0.914837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157391 episodes
GETTING ACTION FROM:
action -1, numVisits=157383, meanQ=2.872530, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.619415 0.887562 0.523976 0.839801 0.619523 0.914837 w: 1
Observation: 0 0.636116 0 0.469094 0 0.647981 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=157262, meanQ=4.916123, numObservations: 4
action 1, numVisits=105, meanQ=4.214373, numObservations: 4
action 2, numVisits=11, meanQ=2.088182, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 247788 episodes
GETTING ACTION FROM:
action 3, numVisits=405045, meanQ=4.785998, numObservations: 4
action 1, numVisits=110, meanQ=4.109375, numObservations: 4
action 2, numVisits=11, meanQ=2.088182, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.619415 0.887562 0.523976 0.839801 0.619523 0.914837 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 470
Initial state: 0 0.542616 0.83133 0.154542 0.99657 0.508512 0.898853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227318 episodes
GETTING ACTION FROM:
action 1, numVisits=227285, meanQ=4.868874, numObservations: 4
action -1, numVisits=24, meanQ=3.433795, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.542616 0.83133 0.154542 0.99657 0.508512 0.898853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 471
Initial state: 0 0.500829 0.962454 0.698345 0.870558 0.537409 0.872486 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229110 episodes
GETTING ACTION FROM:
action 2, numVisits=229099, meanQ=5.157710, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=4, meanQ=-4.002500, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.500829 0.962454 0.698345 0.870558 0.537409 0.872486 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 472
Initial state: 0 0.677653 0.812985 0.540958 0.880772 0.687905 0.508003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227387 episodes
GETTING ACTION FROM:
action 2, numVisits=224807, meanQ=5.129853, numObservations: 5
action 1, numVisits=2574, meanQ=4.984059, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.677653 0.812985 0.540958 0.880772 0.687905 0.508003 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 473
Initial state: 0 0.492309 0.64342 0.581201 0.890848 0.628198 0.888705 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228890 episodes
GETTING ACTION FROM:
action 3, numVisits=228876, meanQ=4.920560, numObservations: 4
action -1, numVisits=10, meanQ=2.091670, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.492309 0.64342 0.581201 0.890848 0.628198 0.888705 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 474
Initial state: 0 0.585416 0.80028 0.620407 0.888322 0.188041 0.572029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227807 episodes
GETTING ACTION FROM:
action 3, numVisits=227736, meanQ=4.930495, numObservations: 4
action 0, numVisits=41, meanQ=3.831442, numObservations: 1
action 1, numVisits=21, meanQ=2.695714, numObservations: 4
action 2, numVisits=7, meanQ=0.428571, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.585416 0.80028 0.620407 0.888322 0.188041 0.572029 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31993, meanQ=8.345374, numObservations: 4
action 2, numVisits=2579, meanQ=8.253635, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 283983 episodes
GETTING ACTION FROM:
action 1, numVisits=214157, meanQ=6.084524, numObservations: 4
action 2, numVisits=104396, meanQ=6.079572, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.585416 0.80028 0.620407 0.888322 0.188041 0.572029 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 475
Initial state: 0 0.669473 0.858543 0.228442 0.0268485 0.638669 0.839081 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225587 episodes
GETTING ACTION FROM:
action 3, numVisits=225581, meanQ=4.995810, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.669473 0.858543 0.228442 0.0268485 0.638669 0.839081 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16451, meanQ=5.627534, numObservations: 4
action 2, numVisits=6, meanQ=2.331700, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 267208 episodes
GETTING ACTION FROM:
action 2, numVisits=83867, meanQ=5.657720, numObservations: 5
action 3, numVisits=199796, meanQ=5.136761, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.669473 0.858543 0.228442 0.0268485 0.638669 0.839081 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=876, meanQ=8.328848, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 294660 episodes
GETTING ACTION FROM:
action 1, numVisits=295535, meanQ=6.082578, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.669473 0.858543 0.228442 0.0268485 0.638669 0.839081 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 476
Initial state: 0 0.550389 0.891603 0.640531 0.870904 0.529775 0.0440725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230532 episodes
GETTING ACTION FROM:
action 3, numVisits=230526, meanQ=4.959846, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.550389 0.891603 0.640531 0.870904 0.529775 0.0440725 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 477
Initial state: 0 0.654417 0.861782 0.644838 0.893472 0.580218 0.946589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221550 episodes
GETTING ACTION FROM:
action 1, numVisits=221521, meanQ=4.866287, numObservations: 5
action 3, numVisits=21, meanQ=3.190495, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.654417 0.861782 0.644838 0.893472 0.580218 0.946589 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.608053 0.817965 0.522177 0.883703 0.350514 0.972425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220364 episodes
GETTING ACTION FROM:
action 3, numVisits=220245, meanQ=4.802134, numObservations: 4
action -1, numVisits=111, meanQ=4.146370, numObservations: 1
action 2, numVisits=5, meanQ=-0.201980, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.608053 0.817965 0.522177 0.883703 0.350514 0.972425 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 479
Initial state: 0 0.505795 0.873392 0.500232 0.813921 0.772255 0.928888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219928 episodes
GETTING ACTION FROM:
action 1, numVisits=219922, meanQ=4.836548, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.505795 0.873392 0.500232 0.813921 0.772255 0.928888 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 480
Initial state: 0 0.94155 0.267548 0.570581 0.863306 0.695576 0.808406 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 151610 episodes
GETTING ACTION FROM:
action -1, numVisits=120841, meanQ=2.900803, numObservations: 1
action 0, numVisits=30758, meanQ=2.881286, numObservations: 1
action 1, numVisits=9, meanQ=0.557800, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.94155 0.267548 0.570581 0.863306 0.695576 0.808406 w: 1
Observation: 0 0.864463 0 0.66836 0 0.718012 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=120828, meanQ=4.947612, numObservations: 3
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 245447 episodes
GETTING ACTION FROM:
action 3, numVisits=366275, meanQ=4.800246, numObservations: 3
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.94155 0.267548 0.570581 0.863306 0.695576 0.808406 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 481
Initial state: 0 0.511372 0.816092 0.569996 0.871811 0.000713659 0.13105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229006 episodes
GETTING ACTION FROM:
action 2, numVisits=228925, meanQ=4.973690, numObservations: 4
action 0, numVisits=52, meanQ=3.992523, numObservations: 1
action 1, numVisits=26, meanQ=3.534235, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.511372 0.816092 0.569996 0.871811 0.000713659 0.13105 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 482
Initial state: 0 0.675378 0.875399 0.586969 0.820952 0.0788635 0.250502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154152 episodes
GETTING ACTION FROM:
action 0, numVisits=154134, meanQ=2.872698, numObservations: 1
action 1, numVisits=12, meanQ=-0.834992, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.675378 0.875399 0.586969 0.820952 0.0788635 0.250502 w: 1
Observation: 0 0 0.864378 0 0.780087 0 0.162711 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=154085, meanQ=4.962245, numObservations: 4
action 3, numVisits=42, meanQ=3.748100, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 246185 episodes
GETTING ACTION FROM:
action 2, numVisits=400270, meanQ=4.998342, numObservations: 4
action 3, numVisits=42, meanQ=3.748100, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.675378 0.875399 0.586969 0.820952 0.0788635 0.250502 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=29661, meanQ=5.398780, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 264088 episodes
GETTING ACTION FROM:
action 2, numVisits=293747, meanQ=5.091957, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.675378 0.875399 0.586969 0.820952 0.0788635 0.250502 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 0, numVisits=7824, meanQ=4.351675, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 268229 episodes
GETTING ACTION FROM:
action 2, numVisits=257663, meanQ=5.120299, numObservations: 5
action 0, numVisits=18386, meanQ=1.093895, numObservations: 1
action -1, numVisits=4, meanQ=-2.002475, numObservations: 1
action 3, numVisits=5, meanQ=-3.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.675378 0.875399 0.586969 0.820952 0.0788635 0.250502 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -1.14771
Run # 483
Initial state: 0 0.673891 0.49321 0.653475 0.882469 0.653735 0.817074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222414 episodes
GETTING ACTION FROM:
action 3, numVisits=218820, meanQ=4.904072, numObservations: 5
action -1, numVisits=3358, meanQ=2.947735, numObservations: 1
action 0, numVisits=225, meanQ=2.662336, numObservations: 1
action 1, numVisits=10, meanQ=0.598000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.673891 0.49321 0.653475 0.882469 0.653735 0.817074 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 484
Initial state: 0 0.218177 0.710331 0.624369 0.891367 0.599355 0.807063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223312 episodes
GETTING ACTION FROM:
action 3, numVisits=223269, meanQ=4.811359, numObservations: 3
action -1, numVisits=24, meanQ=3.373951, numObservations: 1
action 0, numVisits=17, meanQ=2.969489, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.218177 0.710331 0.624369 0.891367 0.599355 0.807063 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 485
Initial state: 0 0.616829 0.770638 0.553547 0.801088 0.627637 0.856024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224214 episodes
GETTING ACTION FROM:
action 1, numVisits=224192, meanQ=4.879938, numObservations: 5
action 3, numVisits=16, meanQ=1.999381, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.616829 0.770638 0.553547 0.801088 0.627637 0.856024 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12226, meanQ=7.901500, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 281860 episodes
GETTING ACTION FROM:
action 2, numVisits=294079, meanQ=5.616340, numObservations: 5
action 1, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.616829 0.770638 0.553547 0.801088 0.627637 0.856024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 486
Initial state: 0 0.591205 0.818521 0.670106 0.84376 0.248333 0.82722 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229341 episodes
GETTING ACTION FROM:
action 1, numVisits=229335, meanQ=5.000235, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.591205 0.818521 0.670106 0.84376 0.248333 0.82722 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 487
Initial state: 0 0.00647585 0.0290913 0.511883 0.845866 0.663414 0.892045 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226573 episodes
GETTING ACTION FROM:
action 3, numVisits=226567, meanQ=4.977579, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.00647585 0.0290913 0.511883 0.845866 0.663414 0.892045 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 488
Initial state: 0 0.686504 0.858967 0.548544 0.855795 0.36969 0.830997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221758 episodes
GETTING ACTION FROM:
action 3, numVisits=212319, meanQ=4.910642, numObservations: 4
action -1, numVisits=9434, meanQ=2.978338, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.686504 0.858967 0.548544 0.855795 0.36969 0.830997 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 489
Initial state: 0 0.550403 0.861103 0.674564 0.816592 0.338535 0.768964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226996 episodes
GETTING ACTION FROM:
action 1, numVisits=226989, meanQ=4.917416, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.550403 0.861103 0.674564 0.816592 0.338535 0.768964 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 490
Initial state: 0 0.676739 0.888515 0.447 0.0159054 0.647261 0.861282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231163 episodes
GETTING ACTION FROM:
action 3, numVisits=231157, meanQ=4.902728, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.676739 0.888515 0.447 0.0159054 0.647261 0.861282 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16481, meanQ=4.680625, numObservations: 5
action 1, numVisits=388, meanQ=4.376306, numObservations: 4
action -1, numVisits=57, meanQ=3.878650, numObservations: 1
action 3, numVisits=8, meanQ=2.498750, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 282664 episodes
GETTING ACTION FROM:
action 2, numVisits=299145, meanQ=5.739878, numObservations: 5
action 1, numVisits=388, meanQ=4.376306, numObservations: 4
action -1, numVisits=57, meanQ=3.878650, numObservations: 1
action 3, numVisits=8, meanQ=2.498750, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.676739 0.888515 0.447 0.0159054 0.647261 0.861282 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=4094, meanQ=8.504056, numObservations: 3
action 1, numVisits=96, meanQ=7.979246, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 292174 episodes
GETTING ACTION FROM:
action 1, numVisits=254297, meanQ=6.271264, numObservations: 4
action 3, numVisits=42067, meanQ=6.229679, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.676739 0.888515 0.447 0.0159054 0.647261 0.861282 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 491
Initial state: 0 0.592933 0.880357 0.126107 0.215548 0.546112 0.889824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227794 episodes
GETTING ACTION FROM:
action 1, numVisits=227741, meanQ=4.976668, numObservations: 5
action 0, numVisits=49, meanQ=3.949090, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.592933 0.880357 0.126107 0.215548 0.546112 0.889824 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 492
Initial state: 0 0.558613 0.954657 0.597154 0.807984 0.645074 0.85106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230302 episodes
GETTING ACTION FROM:
action 2, numVisits=230295, meanQ=4.897887, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.558613 0.954657 0.597154 0.807984 0.645074 0.85106 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 493
Initial state: 0 0.693362 0.438218 0.690793 0.839223 0.673175 0.853622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155285 episodes
GETTING ACTION FROM:
action -1, numVisits=92311, meanQ=2.875314, numObservations: 1
action 0, numVisits=62959, meanQ=2.860593, numObservations: 1
action 1, numVisits=8, meanQ=0.237512, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=4, meanQ=-2.005000, numObservations: 3
action: -1
Next state: 0 0.693362 0.438218 0.690793 0.839223 0.673175 0.853622 w: 1
Observation: 0 0.686524 0 0.670193 0 0.604304 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=92276, meanQ=4.956687, numObservations: 4
action 1, numVisits=29, meanQ=3.055517, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 248512 episodes
GETTING ACTION FROM:
action 2, numVisits=340788, meanQ=4.972901, numObservations: 4
action 1, numVisits=29, meanQ=3.055517, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.693362 0.438218 0.690793 0.839223 0.673175 0.853622 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 494
Initial state: 0 0.0511561 0.609768 0.69474 0.872133 0.548662 0.828078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228492 episodes
GETTING ACTION FROM:
action 1, numVisits=228450, meanQ=4.900010, numObservations: 4
action 0, numVisits=30, meanQ=3.620204, numObservations: 1
action -1, numVisits=10, meanQ=1.959010, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0511561 0.609768 0.69474 0.872133 0.548662 0.828078 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=28809, meanQ=8.362326, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286926 episodes
GETTING ACTION FROM:
action 2, numVisits=315735, meanQ=6.189198, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0511561 0.609768 0.69474 0.872133 0.548662 0.828078 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 495
Initial state: 0 0.365433 0.700371 0.547794 0.828801 0.698696 0.87149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230191 episodes
GETTING ACTION FROM:
action 1, numVisits=230051, meanQ=5.020912, numObservations: 4
action -1, numVisits=76, meanQ=4.212864, numObservations: 1
action 0, numVisits=22, meanQ=3.444736, numObservations: 1
action 2, numVisits=39, meanQ=3.242315, numObservations: 4
action 3, numVisits=3, meanQ=-0.329967, numObservations: 2
action: 1
Next state: 2 0.365433 0.700371 0.547794 0.828801 0.698696 0.87149 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 496
Initial state: 0 0.633869 0.611846 0.642518 0.889102 0.631536 0.843116 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221900 episodes
GETTING ACTION FROM:
action 3, numVisits=221864, meanQ=4.978727, numObservations: 4
action 0, numVisits=32, meanQ=3.728840, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.633869 0.611846 0.642518 0.889102 0.631536 0.843116 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 497
Initial state: 0 0.556969 0.81024 0.621641 0.870293 0.290647 0.287409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231703 episodes
GETTING ACTION FROM:
action 1, numVisits=231679, meanQ=4.968668, numObservations: 3
action 2, numVisits=17, meanQ=2.411176, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.556969 0.81024 0.621641 0.870293 0.290647 0.287409 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=17057, meanQ=5.541186, numObservations: 3
action 3, numVisits=282, meanQ=4.696836, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 276875 episodes
GETTING ACTION FROM:
action 3, numVisits=181489, meanQ=5.816055, numObservations: 4
action 1, numVisits=112723, meanQ=5.014706, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.556969 0.81024 0.621641 0.870293 0.290647 0.287409 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=1791, meanQ=8.262373, numObservations: 4
action 1, numVisits=1343, meanQ=7.748299, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 289201 episodes
GETTING ACTION FROM:
action 1, numVisits=186273, meanQ=5.796585, numObservations: 5
action 2, numVisits=106060, meanQ=5.787876, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.556969 0.81024 0.621641 0.870293 0.290647 0.287409 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 498
Initial state: 0 0.632227 0.833279 0.597442 0.860312 0.00486823 0.308489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231965 episodes
GETTING ACTION FROM:
action 1, numVisits=231959, meanQ=4.986531, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.632227 0.833279 0.597442 0.860312 0.00486823 0.308489 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 499
Initial state: 0 0.646939 0.889728 0.564602 0.882816 0.437718 0.939409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218975 episodes
GETTING ACTION FROM:
action 2, numVisits=218936, meanQ=4.696163, numObservations: 4
action -1, numVisits=34, meanQ=1.830946, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.646939 0.889728 0.564602 0.882816 0.437718 0.939409 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 500
Initial state: 0 0.583194 0.813465 0.941564 0.391464 0.603854 0.886382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228308 episodes
GETTING ACTION FROM:
action 3, numVisits=195352, meanQ=4.913632, numObservations: 4
action 1, numVisits=32802, meanQ=4.872242, numObservations: 4
action -1, numVisits=114, meanQ=4.262008, numObservations: 1
action 0, numVisits=39, meanQ=3.775166, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.583194 0.813465 0.941564 0.391464 0.603854 0.886382 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
