Run # 1
Initial state: 0 0.514789 0.819348 0.0938829 0.513059 0.674451 0.849372 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1051662 episodes
GETTING ACTION FROM:
action 3, numVisits=1051654, meanQ=4.895061, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.514789 0.819348 0.0938829 0.513059 0.674451 0.849372 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.452327 0.893501 0.644924 0.80185 0.537155 0.880197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1064816 episodes
GETTING ACTION FROM:
action 3, numVisits=912030, meanQ=4.913687, numObservations: 4
action -1, numVisits=152709, meanQ=2.936602, numObservations: 1
action 0, numVisits=73, meanQ=2.133957, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 3
Next state: 1 0.452327 0.893501 0.644924 0.80185 0.537155 0.880197 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 3
Initial state: 0 0.846025 0.171186 0.532655 0.889904 0.689964 0.805048 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134691 episodes
GETTING ACTION FROM:
action 1, numVisits=1134685, meanQ=4.919435, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.846025 0.171186 0.532655 0.889904 0.689964 0.805048 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.685674 0.820891 0.661202 0.835611 0.363069 0.555705 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1152199 episodes
GETTING ACTION FROM:
action 3, numVisits=1152048, meanQ=4.920541, numObservations: 3
action 0, numVisits=113, meanQ=4.085135, numObservations: 1
action 2, numVisits=24, meanQ=2.500429, numObservations: 3
action 1, numVisits=12, meanQ=1.997517, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.685674 0.820891 0.661202 0.835611 0.363069 0.555705 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=175969, meanQ=8.306958, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1452445 episodes
GETTING ACTION FROM:
action 2, numVisits=1628412, meanQ=6.060698, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.685674 0.820891 0.661202 0.835611 0.363069 0.555705 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 5
Initial state: 0 0.328295 0.0891959 0.553926 0.852466 0.603178 0.809682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130856 episodes
GETTING ACTION FROM:
action 3, numVisits=1130832, meanQ=4.927573, numObservations: 5
action -1, numVisits=16, meanQ=2.760749, numObservations: 1
action 1, numVisits=4, meanQ=0.025000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.328295 0.0891959 0.553926 0.852466 0.603178 0.809682 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 6
Initial state: 0 0.232609 0.367835 0.652612 0.898143 0.557604 0.892964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104973 episodes
GETTING ACTION FROM:
action 2, numVisits=1104951, meanQ=4.839381, numObservations: 4
action 3, numVisits=16, meanQ=1.248750, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.232609 0.367835 0.652612 0.898143 0.557604 0.892964 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 7
Initial state: 0 0.658134 0.850801 0.572035 0.816207 0.450558 0.534168 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1141854 episodes
GETTING ACTION FROM:
action 3, numVisits=1141734, meanQ=4.996719, numObservations: 4
action -1, numVisits=102, meanQ=4.261803, numObservations: 1
action 2, numVisits=15, meanQ=2.598000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.658134 0.850801 0.572035 0.816207 0.450558 0.534168 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=145015, meanQ=8.393381, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1409001 episodes
GETTING ACTION FROM:
action 2, numVisits=1554014, meanQ=6.192844, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.658134 0.850801 0.572035 0.816207 0.450558 0.534168 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 8
Initial state: 0 0.576864 0.890547 0.637137 0.848009 0.168351 0.779193 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138767 episodes
GETTING ACTION FROM:
action 1, numVisits=1138719, meanQ=4.906725, numObservations: 4
action 0, numVisits=39, meanQ=3.664332, numObservations: 1
action 2, numVisits=6, meanQ=-0.350000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.576864 0.890547 0.637137 0.848009 0.168351 0.779193 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 9
Initial state: 0 0.647886 0.899662 0.595723 0.61045 0.626092 0.810552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116919 episodes
GETTING ACTION FROM:
action 2, numVisits=1116847, meanQ=4.963678, numObservations: 5
action 0, numVisits=57, meanQ=3.940695, numObservations: 1
action 1, numVisits=12, meanQ=1.998333, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.647886 0.899662 0.595723 0.61045 0.626092 0.810552 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 10
Initial state: 0 0.615179 0.855534 0.462897 0.618847 0.5151 0.831428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107660 episodes
GETTING ACTION FROM:
action 3, numVisits=1107624, meanQ=5.037383, numObservations: 5
action 1, numVisits=31, meanQ=3.445165, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.615179 0.855534 0.462897 0.618847 0.5151 0.831428 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=61559, meanQ=5.907201, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1310650 episodes
GETTING ACTION FROM:
action 3, numVisits=1276563, meanQ=4.824775, numObservations: 4
action 0, numVisits=95647, meanQ=3.741103, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.615179 0.855534 0.462897 0.618847 0.5151 0.831428 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 11
Initial state: 0 0.953157 0.895745 0.696561 0.812592 0.586146 0.831333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1150122 episodes
GETTING ACTION FROM:
action 3, numVisits=1150081, meanQ=4.953979, numObservations: 3
action 0, numVisits=35, meanQ=3.678562, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.953157 0.895745 0.696561 0.812592 0.586146 0.831333 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 12
Initial state: 0 0.502848 0.816174 0.599633 0.0763964 0.500161 0.860775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 785419 episodes
GETTING ACTION FROM:
action -1, numVisits=785408, meanQ=2.889092, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=3, meanQ=-2.966667, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.502848 0.816174 0.599633 0.0763964 0.500161 0.860775 w: 1
Observation: 0 0.491835 0 0.526435 0 0.437945 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=360296, meanQ=4.939618, numObservations: 3
action 1, numVisits=425074, meanQ=4.908390, numObservations: 3
action -1, numVisits=33, meanQ=3.653711, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1252679 episodes
GETTING ACTION FROM:
action 2, numVisits=1612974, meanQ=4.962700, numObservations: 3
action 1, numVisits=425074, meanQ=4.908390, numObservations: 3
action -1, numVisits=34, meanQ=3.641026, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.502848 0.816174 0.599633 0.0763964 0.500161 0.860775 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 13
Initial state: 0 0.605452 0.873857 0.357242 0.36454 0.509178 0.81984 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 809250 episodes
GETTING ACTION FROM:
action 0, numVisits=802440, meanQ=5.693959, numObservations: 2
action 1, numVisits=6780, meanQ=4.859568, numObservations: 3
action 2, numVisits=27, meanQ=2.924822, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.605452 0.873857 0.357242 0.36454 0.509178 0.81984 w: 1
Observation: 0 0 0.957324 0 0.345829 0 0.875803 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=425847, meanQ=7.594286, numObservations: 4
action 2, numVisits=12, meanQ=2.983333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1186093 episodes
GETTING ACTION FROM:
action 3, numVisits=1611921, meanQ=5.553023, numObservations: 4
action 0, numVisits=19, meanQ=3.657509, numObservations: 1
action 2, numVisits=12, meanQ=2.983333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.605452 0.873857 0.357242 0.36454 0.509178 0.81984 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 14
Initial state: 0 0.646365 0.860715 0.528664 0.801128 0.260146 0.585234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1149337 episodes
GETTING ACTION FROM:
action 2, numVisits=1149311, meanQ=5.013274, numObservations: 4
action 1, numVisits=20, meanQ=3.098515, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.646365 0.860715 0.528664 0.801128 0.260146 0.585234 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 15
Initial state: 0 0.354669 0.542913 0.624082 0.801202 0.655119 0.835624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1140145 episodes
GETTING ACTION FROM:
action 1, numVisits=1132647, meanQ=4.991707, numObservations: 4
action -1, numVisits=7492, meanQ=2.895054, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.354669 0.542913 0.624082 0.801202 0.655119 0.835624 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=143186, meanQ=8.387250, numObservations: 4
action 2, numVisits=6, meanQ=3.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1429823 episodes
GETTING ACTION FROM:
action 3, numVisits=1573001, meanQ=6.289029, numObservations: 4
action 2, numVisits=12, meanQ=2.999167, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.354669 0.542913 0.624082 0.801202 0.655119 0.835624 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 16
Initial state: 0 0.528537 0.861193 0.924079 0.443373 0.693701 0.831474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137967 episodes
GETTING ACTION FROM:
action 1, numVisits=1137426, meanQ=4.993458, numObservations: 4
action 3, numVisits=494, meanQ=4.592148, numObservations: 5
action 0, numVisits=31, meanQ=3.642367, numObservations: 1
action 2, numVisits=14, meanQ=2.427857, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.528537 0.861193 0.924079 0.443373 0.693701 0.831474 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 17
Initial state: 0 0.691192 0.846536 0.117371 0.757429 0.662227 0.87263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1143564 episodes
GETTING ACTION FROM:
action 3, numVisits=1143557, meanQ=4.913646, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.691192 0.846536 0.117371 0.757429 0.662227 0.87263 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 18
Initial state: 0 0.67147 0.877812 0.625497 0.893884 0.671941 0.298497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1143338 episodes
GETTING ACTION FROM:
action 3, numVisits=1143185, meanQ=4.994095, numObservations: 4
action 0, numVisits=97, meanQ=4.223893, numObservations: 1
action 2, numVisits=25, meanQ=3.479204, numObservations: 3
action -1, numVisits=17, meanQ=3.121663, numObservations: 1
action 1, numVisits=14, meanQ=2.715007, numObservations: 4
action: 3
Next state: 2 0.67147 0.877812 0.625497 0.893884 0.671941 0.298497 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 19
Initial state: 0 0.243353 0.98164 0.6462 0.896785 0.50164 0.857727 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132887 episodes
GETTING ACTION FROM:
action 1, numVisits=1125539, meanQ=4.985707, numObservations: 5
action 0, numVisits=7337, meanQ=2.887657, numObservations: 1
action 3, numVisits=8, meanQ=0.748763, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.243353 0.98164 0.6462 0.896785 0.50164 0.857727 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=74048, meanQ=5.687062, numObservations: 3
action 3, numVisits=8695, meanQ=4.724604, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1347344 episodes
GETTING ACTION FROM:
action 1, numVisits=1421392, meanQ=5.025785, numObservations: 4
action 3, numVisits=8695, meanQ=4.724604, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.243353 0.98164 0.6462 0.896785 0.50164 0.857727 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 20
Initial state: 0 0.803792 0.272588 0.602501 0.812492 0.632781 0.848415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105718 episodes
GETTING ACTION FROM:
action 3, numVisits=1105712, meanQ=4.981577, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.803792 0.272588 0.602501 0.812492 0.632781 0.848415 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 21
Initial state: 0 0.186902 0.763258 0.642924 0.830326 0.511578 0.826906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100311 episodes
GETTING ACTION FROM:
action 1, numVisits=1100218, meanQ=4.885390, numObservations: 4
action -1, numVisits=72, meanQ=3.988463, numObservations: 1
action 3, numVisits=12, meanQ=1.316667, numObservations: 3
action 2, numVisits=7, meanQ=0.985714, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.186902 0.763258 0.642924 0.830326 0.511578 0.826906 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=167796, meanQ=8.283822, numObservations: 5
action 2, numVisits=261, meanQ=7.863185, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1417802 episodes
GETTING ACTION FROM:
action 2, numVisits=408669, meanQ=6.100604, numObservations: 3
action 3, numVisits=1177188, meanQ=6.078905, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.186902 0.763258 0.642924 0.830326 0.511578 0.826906 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 22
Initial state: 0 0.625808 0.823635 0.0968551 0.995839 0.551113 0.835686 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1148136 episodes
GETTING ACTION FROM:
action 2, numVisits=1148044, meanQ=4.962968, numObservations: 4
action -1, numVisits=87, meanQ=4.163575, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.625808 0.823635 0.0968551 0.995839 0.551113 0.835686 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=10049, meanQ=3.931255, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
Sampled 1431678 episodes
GETTING ACTION FROM:
action 3, numVisits=1429405, meanQ=6.071014, numObservations: 4
action -1, numVisits=12320, meanQ=3.072625, numObservations: 1
action 2, numVisits=4, meanQ=-0.504975, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 3
Next state: 1 0.625808 0.823635 0.0968551 0.995839 0.551113 0.835686 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 23
Initial state: 0 0.553892 0.297557 0.689607 0.840307 0.579095 0.841537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139213 episodes
GETTING ACTION FROM:
action 2, numVisits=1138957, meanQ=4.996042, numObservations: 4
action 0, numVisits=104, meanQ=4.269586, numObservations: 1
action -1, numVisits=105, meanQ=4.268665, numObservations: 1
action 3, numVisits=42, meanQ=3.612624, numObservations: 3
action 1, numVisits=5, meanQ=0.196000, numObservations: 2
action: 2
Next state: 1 0.553892 0.297557 0.689607 0.840307 0.579095 0.841537 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 24
Initial state: 0 0.877919 0.924193 0.512368 0.820911 0.60065 0.865577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138553 episodes
GETTING ACTION FROM:
action 2, numVisits=1138537, meanQ=4.976850, numObservations: 4
action 1, numVisits=10, meanQ=-0.801990, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.877919 0.924193 0.512368 0.820911 0.60065 0.865577 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 25
Initial state: 0 0.511566 0.825372 0.656938 0.883944 0.812439 0.905439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104310 episodes
GETTING ACTION FROM:
action 1, numVisits=1104301, meanQ=4.896323, numObservations: 5
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.511566 0.825372 0.656938 0.883944 0.812439 0.905439 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=68894, meanQ=3.819324, numObservations: 1
action 0, numVisits=808, meanQ=1.475871, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=5, meanQ=-1.402000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1324323 episodes
GETTING ACTION FROM:
action 1, numVisits=1262440, meanQ=5.331052, numObservations: 5
action -1, numVisits=130768, meanQ=1.649831, numObservations: 1
action 0, numVisits=821, meanQ=1.429132, numObservations: 1
action 2, numVisits=5, meanQ=-1.402000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.511566 0.825372 0.656938 0.883944 0.812439 0.905439 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 26
Initial state: 0 0.521716 0.828113 0.511947 0.818654 0.784064 0.654962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1136685 episodes
GETTING ACTION FROM:
action 1, numVisits=1136662, meanQ=4.904294, numObservations: 4
action 3, numVisits=18, meanQ=1.665567, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.521716 0.828113 0.511947 0.818654 0.784064 0.654962 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 27
Initial state: 0 0.683222 0.485941 0.50702 0.859464 0.686781 0.804165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 780560 episodes
GETTING ACTION FROM:
action -1, numVisits=780542, meanQ=2.916676, numObservations: 1
action 1, numVisits=11, meanQ=0.634564, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.683222 0.485941 0.50702 0.859464 0.686781 0.804165 w: 1
Observation: 0 0.672101 0 0.54701 0 0.762892 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=780532, meanQ=4.967092, numObservations: 4
action 1, numVisits=4, meanQ=-0.504975, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1234429 episodes
GETTING ACTION FROM:
action 2, numVisits=2014961, meanQ=5.061135, numObservations: 4
action 1, numVisits=4, meanQ=-0.504975, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.683222 0.485941 0.50702 0.859464 0.686781 0.804165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 28
Initial state: 0 0.508304 0.835054 0.921937 0.893158 0.512862 0.822213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1141078 episodes
GETTING ACTION FROM:
action 2, numVisits=1141048, meanQ=4.983603, numObservations: 4
action 0, numVisits=22, meanQ=3.276905, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.508304 0.835054 0.921937 0.893158 0.512862 0.822213 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 29
Initial state: 0 0.238107 0.408631 0.611374 0.852224 0.563796 0.885705 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146972 episodes
GETTING ACTION FROM:
action 3, numVisits=1146887, meanQ=4.925244, numObservations: 3
action -1, numVisits=63, meanQ=3.924326, numObservations: 1
action 0, numVisits=10, meanQ=2.485195, numObservations: 1
action 2, numVisits=11, meanQ=2.453636, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.238107 0.408631 0.611374 0.852224 0.563796 0.885705 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 30
Initial state: 0 0.795478 0.839567 0.631565 0.805596 0.537482 0.806629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1149027 episodes
GETTING ACTION FROM:
action 2, numVisits=1148745, meanQ=4.971206, numObservations: 3
action 1, numVisits=248, meanQ=4.480010, numObservations: 5
action 3, numVisits=30, meanQ=3.511333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.795478 0.839567 0.631565 0.805596 0.537482 0.806629 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 31
Initial state: 0 0.441275 0.321628 0.612423 0.873192 0.554522 0.838253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1141676 episodes
GETTING ACTION FROM:
action 2, numVisits=1141531, meanQ=4.917715, numObservations: 4
action -1, numVisits=76, meanQ=4.066185, numObservations: 1
action 0, numVisits=54, meanQ=3.904780, numObservations: 1
action 1, numVisits=11, meanQ=1.907282, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action: 2
Next state: 1 0.441275 0.321628 0.612423 0.873192 0.554522 0.838253 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 32
Initial state: 0 0.660329 0.807585 0.652665 0.861655 0.439444 0.395993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137351 episodes
GETTING ACTION FROM:
action 1, numVisits=1137342, meanQ=4.918496, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.660329 0.807585 0.652665 0.861655 0.439444 0.395993 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9783, meanQ=6.191239, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1333114 episodes
GETTING ACTION FROM:
action 1, numVisits=1342893, meanQ=4.828427, numObservations: 4
action 0, numVisits=4, meanQ=0.475000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.660329 0.807585 0.652665 0.861655 0.439444 0.395993 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 33
Initial state: 0 0.0519481 0.211379 0.672367 0.836359 0.671746 0.800148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1123271 episodes
GETTING ACTION FROM:
action 2, numVisits=1123158, meanQ=5.100764, numObservations: 5
action 0, numVisits=97, meanQ=4.339685, numObservations: 1
action 1, numVisits=13, meanQ=2.536923, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.0519481 0.211379 0.672367 0.836359 0.671746 0.800148 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=73712, meanQ=7.236907, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1329185 episodes
GETTING ACTION FROM:
action 2, numVisits=1402892, meanQ=5.494319, numObservations: 4
action 0, numVisits=5, meanQ=1.762000, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0519481 0.211379 0.672367 0.836359 0.671746 0.800148 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 34
Initial state: 0 0.525668 0.848521 0.705184 0.748166 0.67428 0.804832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137706 episodes
GETTING ACTION FROM:
action 1, numVisits=1137594, meanQ=4.900852, numObservations: 4
action -1, numVisits=107, meanQ=4.170208, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.525668 0.848521 0.705184 0.748166 0.67428 0.804832 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 35
Initial state: 0 0.784041 0.630889 0.663655 0.818217 0.527798 0.873736 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1144864 episodes
GETTING ACTION FROM:
action 1, numVisits=1144838, meanQ=4.977551, numObservations: 4
action 3, numVisits=19, meanQ=0.262637, numObservations: 4
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.784041 0.630889 0.663655 0.818217 0.527798 0.873736 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 36
Initial state: 0 0.00244563 0.834136 0.638557 0.842749 0.63199 0.871931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129332 episodes
GETTING ACTION FROM:
action 3, numVisits=1129323, meanQ=5.107298, numObservations: 5
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.00244563 0.834136 0.638557 0.842749 0.63199 0.871931 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 37
Initial state: 0 0.06535 0.662392 0.532557 0.855688 0.617067 0.809439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106931 episodes
GETTING ACTION FROM:
action 1, numVisits=1106751, meanQ=4.831318, numObservations: 4
action -1, numVisits=117, meanQ=4.139684, numObservations: 1
action 0, numVisits=58, meanQ=3.829121, numObservations: 1
action 3, numVisits=4, meanQ=-2.005000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.06535 0.662392 0.532557 0.855688 0.617067 0.809439 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=140591, meanQ=8.392951, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1450187 episodes
GETTING ACTION FROM:
action 2, numVisits=1590776, meanQ=5.917997, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.06535 0.662392 0.532557 0.855688 0.617067 0.809439 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 38
Initial state: 0 0.910638 0.722592 0.655464 0.891395 0.699804 0.876602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133736 episodes
GETTING ACTION FROM:
action 3, numVisits=1133653, meanQ=4.925006, numObservations: 4
action 0, numVisits=74, meanQ=4.040773, numObservations: 1
action 1, numVisits=6, meanQ=1.331683, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.910638 0.722592 0.655464 0.891395 0.699804 0.876602 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 39
Initial state: 0 0.0660893 0.918618 0.509169 0.806721 0.642336 0.868371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1155981 episodes
GETTING ACTION FROM:
action 1, numVisits=1155820, meanQ=5.015272, numObservations: 4
action -1, numVisits=90, meanQ=4.225193, numObservations: 1
action 2, numVisits=68, meanQ=4.076032, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.0660893 0.918618 0.509169 0.806721 0.642336 0.868371 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 40
Initial state: 0 0.500466 0.861639 0.663008 0.884599 0.672219 0.808878 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 757896 episodes
GETTING ACTION FROM:
action -1, numVisits=757889, meanQ=2.819631, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.500466 0.861639 0.663008 0.884599 0.672219 0.808878 w: 1
Observation: 0 0.433598 0 0.67137 0 0.701008 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=757861, meanQ=4.869470, numObservations: 3
action 3, numVisits=16, meanQ=2.362506, numObservations: 4
action 1, numVisits=7, meanQ=0.985714, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1200575 episodes
GETTING ACTION FROM:
action 2, numVisits=1958436, meanQ=4.753831, numObservations: 3
action 3, numVisits=16, meanQ=2.362506, numObservations: 4
action 1, numVisits=7, meanQ=0.985714, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.500466 0.861639 0.663008 0.884599 0.672219 0.808878 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 41
Initial state: 0 0.679552 0.819446 0.656886 0.847393 0.846908 0.858859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133944 episodes
GETTING ACTION FROM:
action 3, numVisits=1133931, meanQ=4.962778, numObservations: 4
action 2, numVisits=8, meanQ=1.500000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.679552 0.819446 0.656886 0.847393 0.846908 0.858859 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 42
Initial state: 0 0.286083 0.0795037 0.59053 0.815338 0.580543 0.800088 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138072 episodes
GETTING ACTION FROM:
action 3, numVisits=1137957, meanQ=4.925035, numObservations: 4
action -1, numVisits=97, meanQ=4.168167, numObservations: 1
action 1, numVisits=15, meanQ=2.733347, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.286083 0.0795037 0.59053 0.815338 0.580543 0.800088 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 43
Initial state: 0 0.561821 0.89041 0.209218 0.237434 0.534405 0.846265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146454 episodes
GETTING ACTION FROM:
action 2, numVisits=1140052, meanQ=5.022893, numObservations: 4
action 0, numVisits=6392, meanQ=2.836809, numObservations: 1
action 3, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 2
Next state: 0 0.561821 0.89041 0.209218 0.237434 0.534405 0.846265 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=174270, meanQ=8.292777, numObservations: 4
action 3, numVisits=16, meanQ=6.375637, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1422860 episodes
GETTING ACTION FROM:
action 1, numVisits=1596873, meanQ=6.380049, numObservations: 4
action 3, numVisits=271, meanQ=5.876532, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.561821 0.89041 0.209218 0.237434 0.534405 0.846265 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 44
Initial state: 0 0.558591 0.811766 0.688857 0.808461 0.842487 0.82264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134664 episodes
GETTING ACTION FROM:
action 1, numVisits=1121875, meanQ=4.907310, numObservations: 4
action -1, numVisits=12783, meanQ=2.788145, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 1
Next state: 1 0.558591 0.811766 0.688857 0.808461 0.842487 0.82264 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 45
Initial state: 0 0.339971 0.628199 0.687462 0.878052 0.689679 0.81046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1135177 episodes
GETTING ACTION FROM:
action 2, numVisits=1135161, meanQ=4.985127, numObservations: 5
action 1, numVisits=10, meanQ=-1.402000, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.339971 0.628199 0.687462 0.878052 0.689679 0.81046 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 46
Initial state: 0 0.351201 0.688822 0.657129 0.859013 0.513372 0.828276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142019 episodes
GETTING ACTION FROM:
action 1, numVisits=1141895, meanQ=4.914283, numObservations: 4
action -1, numVisits=77, meanQ=4.063460, numObservations: 1
action 0, numVisits=43, meanQ=3.780846, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.351201 0.688822 0.657129 0.859013 0.513372 0.828276 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=111546, meanQ=8.533911, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1433830 episodes
GETTING ACTION FROM:
action 3, numVisits=1545351, meanQ=6.050666, numObservations: 3
action 2, numVisits=25, meanQ=4.039200, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.351201 0.688822 0.657129 0.859013 0.513372 0.828276 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=33904, meanQ=7.760155, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1459077 episodes
GETTING ACTION FROM:
action 3, numVisits=1492979, meanQ=6.056709, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.351201 0.688822 0.657129 0.859013 0.513372 0.828276 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 47
Initial state: 0 0.629324 0.807275 0.550994 0.871554 0.832223 0.29413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 770448 episodes
GETTING ACTION FROM:
action 0, numVisits=770402, meanQ=2.939121, numObservations: 1
action 3, numVisits=41, meanQ=1.724644, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.629324 0.807275 0.550994 0.871554 0.832223 0.29413 w: 1
Observation: 0 0 0.716024 0 0.841144 0 0.243767 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=770390, meanQ=4.990290, numObservations: 5
action 2, numVisits=6, meanQ=1.663333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1224870 episodes
GETTING ACTION FROM:
action 3, numVisits=1995260, meanQ=5.074787, numObservations: 5
action 2, numVisits=6, meanQ=1.663333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.629324 0.807275 0.550994 0.871554 0.832223 0.29413 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 48
Initial state: 0 0.649059 0.840687 0.847477 0.338836 0.622951 0.821951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1158293 episodes
GETTING ACTION FROM:
action 2, numVisits=1158164, meanQ=4.915623, numObservations: 3
action -1, numVisits=124, meanQ=4.248739, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.649059 0.840687 0.847477 0.338836 0.622951 0.821951 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 49
Initial state: 0 0.521348 0.8962 0.620245 0.826005 0.553869 0.795632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128472 episodes
GETTING ACTION FROM:
action 2, numVisits=1128372, meanQ=4.980538, numObservations: 5
action 0, numVisits=64, meanQ=4.029891, numObservations: 1
action -1, numVisits=18, meanQ=3.082944, numObservations: 1
action 3, numVisits=17, meanQ=2.407065, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.521348 0.8962 0.620245 0.826005 0.553869 0.795632 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=82595, meanQ=5.505025, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1262538 episodes
GETTING ACTION FROM:
action 2, numVisits=1345133, meanQ=4.758989, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.521348 0.8962 0.620245 0.826005 0.553869 0.795632 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 50
Initial state: 0 0.576674 0.822842 0.510802 0.430369 0.597377 0.847515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111096 episodes
GETTING ACTION FROM:
action 3, numVisits=1111006, meanQ=4.785011, numObservations: 4
action -1, numVisits=86, meanQ=3.902290, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.576674 0.822842 0.510802 0.430369 0.597377 0.847515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=81896, meanQ=4.665515, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1424504 episodes
GETTING ACTION FROM:
action 1, numVisits=1506400, meanQ=5.850932, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.576674 0.822842 0.510802 0.430369 0.597377 0.847515 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 51
Initial state: 0 0.579456 0.834426 0.566587 0.833554 0.788598 0.945208 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124099 episodes
GETTING ACTION FROM:
action 1, numVisits=1124022, meanQ=4.909426, numObservations: 5
action 3, numVisits=54, meanQ=3.741119, numObservations: 5
action 2, numVisits=19, meanQ=2.980005, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.579456 0.834426 0.566587 0.833554 0.788598 0.945208 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 52
Initial state: 0 0.393902 0.806995 0.684768 0.878153 0.592904 0.822529 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117229 episodes
GETTING ACTION FROM:
action 1, numVisits=1117183, meanQ=4.845612, numObservations: 4
action 0, numVisits=33, meanQ=3.533716, numObservations: 1
action 3, numVisits=8, meanQ=0.965000, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.393902 0.806995 0.684768 0.878153 0.592904 0.822529 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 53
Initial state: 0 0.61141 0.855554 0.150939 0.514935 0.643284 0.829146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1122812 episodes
GETTING ACTION FROM:
action 2, numVisits=1122732, meanQ=4.959924, numObservations: 5
action -1, numVisits=74, meanQ=4.088479, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.61141 0.855554 0.150939 0.514935 0.643284 0.829146 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=59212, meanQ=8.540878, numObservations: 3
action 3, numVisits=49998, meanQ=8.535794, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1430551 episodes
GETTING ACTION FROM:
action 1, numVisits=1236301, meanQ=6.152082, numObservations: 4
action 3, numVisits=303458, meanQ=6.144991, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.61141 0.855554 0.150939 0.514935 0.643284 0.829146 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 54
Initial state: 0 0.264678 0.0516875 0.658312 0.856934 0.549436 0.858801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142968 episodes
GETTING ACTION FROM:
action 3, numVisits=1142958, meanQ=4.978506, numObservations: 3
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.264678 0.0516875 0.658312 0.856934 0.549436 0.858801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 55
Initial state: 0 0.766757 0.387124 0.667087 0.808221 0.695362 0.871016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139924 episodes
GETTING ACTION FROM:
action 3, numVisits=1131731, meanQ=4.945701, numObservations: 4
action 0, numVisits=8173, meanQ=2.927305, numObservations: 1
action 2, numVisits=17, meanQ=1.000612, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.766757 0.387124 0.667087 0.808221 0.695362 0.871016 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 56
Initial state: 0 0.56498 0.839642 0.720379 0.126973 0.581467 0.845942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 774830 episodes
GETTING ACTION FROM:
action -1, numVisits=774822, meanQ=2.846996, numObservations: 1
action 1, numVisits=4, meanQ=-2.502475, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.56498 0.839642 0.720379 0.126973 0.581467 0.845942 w: 1
Observation: 0 0.644582 0 0.796728 0 0.498578 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=774773, meanQ=4.895219, numObservations: 5
action 0, numVisits=44, meanQ=3.779705, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1228419 episodes
GETTING ACTION FROM:
action 1, numVisits=2003192, meanQ=5.037826, numObservations: 5
action 0, numVisits=44, meanQ=3.779705, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.56498 0.839642 0.720379 0.126973 0.581467 0.845942 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 57
Initial state: 0 0.607165 0.828543 0.90735 0.551164 0.538286 0.832621 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099096 episodes
GETTING ACTION FROM:
action 1, numVisits=1098712, meanQ=4.953579, numObservations: 4
action 0, numVisits=380, meanQ=1.618102, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.607165 0.828543 0.90735 0.551164 0.538286 0.832621 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 58
Initial state: 0 0.603416 0.87537 0.00578299 0.480264 0.647913 0.817277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130988 episodes
GETTING ACTION FROM:
action 1, numVisits=1124437, meanQ=4.945513, numObservations: 4
action -1, numVisits=6501, meanQ=3.118750, numObservations: 1
action 3, numVisits=46, meanQ=2.210918, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.603416 0.87537 0.00578299 0.480264 0.647913 0.817277 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 59
Initial state: 0 0.540066 0.860947 0.652009 0.8313 0.144871 0.602334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130285 episodes
GETTING ACTION FROM:
action 2, numVisits=1124040, meanQ=4.992893, numObservations: 4
action -1, numVisits=4919, meanQ=2.818014, numObservations: 1
action 0, numVisits=1320, meanQ=2.739515, numObservations: 1
action 1, numVisits=5, meanQ=0.196000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.540066 0.860947 0.652009 0.8313 0.144871 0.602334 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 60
Initial state: 0 0.508713 0.887696 0.638997 0.823944 0.1955 0.163119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109009 episodes
GETTING ACTION FROM:
action 1, numVisits=1108927, meanQ=4.834408, numObservations: 4
action 0, numVisits=62, meanQ=3.863358, numObservations: 1
action 3, numVisits=17, meanQ=2.881176, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.508713 0.887696 0.638997 0.823944 0.1955 0.163119 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 61
Initial state: 0 0.697411 0.862066 0.677835 0.821253 0.177825 0.276883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133410 episodes
GETTING ACTION FROM:
action 1, numVisits=1133403, meanQ=4.981251, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.697411 0.862066 0.677835 0.821253 0.177825 0.276883 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 62
Initial state: 0 0.548837 0.878023 0.667356 0.831963 0.712716 0.97304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1135368 episodes
GETTING ACTION FROM:
action 3, numVisits=1135280, meanQ=4.901477, numObservations: 4
action 0, numVisits=45, meanQ=3.783730, numObservations: 3
action 2, numVisits=26, meanQ=3.300773, numObservations: 2
action -1, numVisits=16, meanQ=2.987720, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.548837 0.878023 0.667356 0.831963 0.712716 0.97304 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 63
Initial state: 0 0.530868 0.885455 0.635139 0.802559 0.332638 0.850675 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1143417 episodes
GETTING ACTION FROM:
action 2, numVisits=1143406, meanQ=4.893101, numObservations: 4
action 3, numVisits=6, meanQ=-0.316667, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.530868 0.885455 0.635139 0.802559 0.332638 0.850675 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 64
Initial state: 0 0.295919 0.692616 0.623596 0.830718 0.553075 0.837351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124753 episodes
GETTING ACTION FROM:
action 2, numVisits=1124603, meanQ=4.965380, numObservations: 5
action 0, numVisits=92, meanQ=4.187683, numObservations: 1
action -1, numVisits=48, meanQ=3.893016, numObservations: 1
action 3, numVisits=7, meanQ=0.428571, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 2
Next state: 1 0.295919 0.692616 0.623596 0.830718 0.553075 0.837351 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 65
Initial state: 0 0.146407 0.886008 0.609503 0.807782 0.678958 0.806542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1073747 episodes
GETTING ACTION FROM:
action 3, numVisits=1073724, meanQ=4.622279, numObservations: 4
action 1, numVisits=18, meanQ=2.777222, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.146407 0.886008 0.609503 0.807782 0.678958 0.806542 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 66
Initial state: 0 0.643507 0.858526 0.0188866 0.450256 0.629641 0.838715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128409 episodes
GETTING ACTION FROM:
action 1, numVisits=1128313, meanQ=4.989088, numObservations: 5
action 0, numVisits=64, meanQ=4.052166, numObservations: 1
action -1, numVisits=21, meanQ=3.257694, numObservations: 1
action 2, numVisits=10, meanQ=1.997010, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.643507 0.858526 0.0188866 0.450256 0.629641 0.838715 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=59309, meanQ=7.849124, numObservations: 5
action 3, numVisits=3376, meanQ=7.738160, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1433404 episodes
GETTING ACTION FROM:
action 3, numVisits=1254797, meanQ=6.210219, numObservations: 3
action 2, numVisits=241290, meanQ=6.200818, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.643507 0.858526 0.0188866 0.450256 0.629641 0.838715 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 67
Initial state: 0 0.525112 0.816399 0.527678 0.812169 0.754243 0.842851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129233 episodes
GETTING ACTION FROM:
action 2, numVisits=1129189, meanQ=4.905160, numObservations: 5
action -1, numVisits=23, meanQ=3.319541, numObservations: 1
action 0, numVisits=19, meanQ=3.152730, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.525112 0.816399 0.527678 0.812169 0.754243 0.842851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 68
Initial state: 0 0.699312 0.855049 0.580623 0.823072 0.188598 0.78767 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133436 episodes
GETTING ACTION FROM:
action 1, numVisits=1132876, meanQ=4.924116, numObservations: 5
action 0, numVisits=556, meanQ=1.807428, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.699312 0.855049 0.580623 0.823072 0.188598 0.78767 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 69
Initial state: 0 0.553433 0.839224 0.557874 0.878127 0.0184737 0.498896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137231 episodes
GETTING ACTION FROM:
action 1, numVisits=1137176, meanQ=4.991316, numObservations: 5
action -1, numVisits=18, meanQ=3.198308, numObservations: 1
action 3, numVisits=24, meanQ=2.915846, numObservations: 3
action 2, numVisits=11, meanQ=2.453645, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.553433 0.839224 0.557874 0.878127 0.0184737 0.498896 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 70
Initial state: 0 0.244679 0.863439 0.672155 0.851593 0.665761 0.885255 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1157466 episodes
GETTING ACTION FROM:
action 1, numVisits=1157455, meanQ=4.995549, numObservations: 3
action 3, numVisits=6, meanQ=1.663333, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.244679 0.863439 0.672155 0.851593 0.665761 0.885255 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=177592, meanQ=8.295367, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1452651 episodes
GETTING ACTION FROM:
action 2, numVisits=1630240, meanQ=6.223155, numObservations: 3
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.244679 0.863439 0.672155 0.851593 0.665761 0.885255 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 71
Initial state: 0 0.644826 0.861047 0.568219 0.894766 0.924504 0.849165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146982 episodes
GETTING ACTION FROM:
action 2, numVisits=1146975, meanQ=4.899792, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.644826 0.861047 0.568219 0.894766 0.924504 0.849165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 72
Initial state: 0 0.590566 0.853165 0.650039 0.37306 0.690969 0.81084 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107403 episodes
GETTING ACTION FROM:
action 1, numVisits=1107396, meanQ=4.975378, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.590566 0.853165 0.650039 0.37306 0.690969 0.81084 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 73
Initial state: 0 0.770084 0.131029 0.597234 0.844473 0.522354 0.846859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1123159 episodes
GETTING ACTION FROM:
action 3, numVisits=1123071, meanQ=4.898259, numObservations: 5
action 0, numVisits=45, meanQ=3.788890, numObservations: 1
action -1, numVisits=29, meanQ=3.476025, numObservations: 1
action 1, numVisits=12, meanQ=2.657517, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 1 0.770084 0.131029 0.597234 0.844473 0.522354 0.846859 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 74
Initial state: 0 0.68067 0.800939 0.984559 0.66142 0.62529 0.864829 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132541 episodes
GETTING ACTION FROM:
action 2, numVisits=1132533, meanQ=4.986026, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.68067 0.800939 0.984559 0.66142 0.62529 0.864829 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 75
Initial state: 0 0.541269 0.827572 0.589466 0.845872 0.531657 0.348124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1140432 episodes
GETTING ACTION FROM:
action 3, numVisits=1140330, meanQ=4.971238, numObservations: 4
action -1, numVisits=98, meanQ=4.212301, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.541269 0.827572 0.589466 0.845872 0.531657 0.348124 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=62776, meanQ=7.870112, numObservations: 3
action 2, numVisits=6, meanQ=4.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1453082 episodes
GETTING ACTION FROM:
action 1, numVisits=1515855, meanQ=5.944532, numObservations: 3
action 2, numVisits=7, meanQ=2.711429, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.541269 0.827572 0.589466 0.845872 0.531657 0.348124 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 76
Initial state: 0 0.539642 0.735036 0.662973 0.854189 0.530853 0.881887 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145289 episodes
GETTING ACTION FROM:
action 2, numVisits=1145214, meanQ=5.138144, numObservations: 4
action -1, numVisits=37, meanQ=3.897813, numObservations: 1
action 0, numVisits=32, meanQ=3.769078, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action: 2
Next state: 1 0.539642 0.735036 0.662973 0.854189 0.530853 0.881887 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 77
Initial state: 0 0.675328 0.810149 0.88339 0.257384 0.659612 0.873146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133448 episodes
GETTING ACTION FROM:
action 1, numVisits=1133442, meanQ=4.918487, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.675328 0.810149 0.88339 0.257384 0.659612 0.873146 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 78
Initial state: 0 0.527217 0.833953 0.547332 0.832122 0.970713 0.569553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1077240 episodes
GETTING ACTION FROM:
action 1, numVisits=956088, meanQ=4.954453, numObservations: 5
action 0, numVisits=121139, meanQ=2.939714, numObservations: 1
action 2, numVisits=8, meanQ=0.501263, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=3, meanQ=-3.033333, numObservations: 2
action: 1
Next state: 1 0.527217 0.833953 0.547332 0.832122 0.970713 0.569553 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 79
Initial state: 0 0.697397 0.819843 0.505544 0.887082 0.887527 0.231012 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1141002 episodes
GETTING ACTION FROM:
action 3, numVisits=1140926, meanQ=4.894977, numObservations: 4
action -1, numVisits=51, meanQ=3.844445, numObservations: 1
action 1, numVisits=22, meanQ=3.164555, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.697397 0.819843 0.505544 0.887082 0.887527 0.231012 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 80
Initial state: 0 0.623847 0.839131 0.338831 0.0427136 0.607137 0.843969 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137695 episodes
GETTING ACTION FROM:
action 1, numVisits=1137661, meanQ=4.942913, numObservations: 4
action -1, numVisits=16, meanQ=2.977991, numObservations: 1
action 2, numVisits=15, meanQ=2.866000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.623847 0.839131 0.338831 0.0427136 0.607137 0.843969 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=67282, meanQ=5.581419, numObservations: 4
action 0, numVisits=15227, meanQ=3.154416, numObservations: 1
action -1, numVisits=368, meanQ=2.855661, numObservations: 1
action 3, numVisits=13, meanQ=0.845392, numObservations: 3
action 2, numVisits=5, meanQ=-0.201980, numObservations: 3
Sampled 1332971 episodes
GETTING ACTION FROM:
action 1, numVisits=1400253, meanQ=5.033070, numObservations: 4
action 0, numVisits=15227, meanQ=3.154416, numObservations: 1
action -1, numVisits=368, meanQ=2.855661, numObservations: 1
action 3, numVisits=13, meanQ=0.845392, numObservations: 3
action 2, numVisits=5, meanQ=-0.201980, numObservations: 3
action: 1
Next state: 1 0.623847 0.839131 0.338831 0.0427136 0.607137 0.843969 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 81
Initial state: 0 0.615807 0.80872 0.675875 0.737592 0.592668 0.86194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 780010 episodes
GETTING ACTION FROM:
action -1, numVisits=779986, meanQ=2.954777, numObservations: 1
action 1, numVisits=13, meanQ=0.845392, numObservations: 3
action 3, numVisits=6, meanQ=-1.000000, numObservations: 3
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action: -1
Next state: 0 0.615807 0.80872 0.675875 0.737592 0.592668 0.86194 w: 1
Observation: 0 0.682311 0 0.700468 0 0.541695 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=779901, meanQ=5.009627, numObservations: 4
action -1, numVisits=38, meanQ=3.757747, numObservations: 1
action 0, numVisits=37, meanQ=3.719398, numObservations: 1
action 1, numVisits=6, meanQ=1.001683, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
Sampled 1254183 episodes
GETTING ACTION FROM:
action 2, numVisits=2034081, meanQ=4.897766, numObservations: 4
action -1, numVisits=40, meanQ=3.668340, numObservations: 1
action 0, numVisits=38, meanQ=3.627120, numObservations: 1
action 1, numVisits=6, meanQ=1.001683, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 2
Next state: 2 0.615807 0.80872 0.675875 0.737592 0.592668 0.86194 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 82
Initial state: 0 0.506486 0.840222 0.651616 0.808283 0.437531 0.637714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129165 episodes
GETTING ACTION FROM:
action 1, numVisits=1128999, meanQ=4.971044, numObservations: 5
action 0, numVisits=73, meanQ=4.078992, numObservations: 1
action -1, numVisits=64, meanQ=4.018166, numObservations: 1
action 2, numVisits=22, meanQ=3.089550, numObservations: 5
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action: 1
Next state: 1 0.506486 0.840222 0.651616 0.808283 0.437531 0.637714 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 83
Initial state: 0 0.519001 0.899759 0.329528 0.784863 0.545021 0.866604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129562 episodes
GETTING ACTION FROM:
action 3, numVisits=1129492, meanQ=4.999785, numObservations: 5
action 2, numVisits=26, meanQ=3.303085, numObservations: 5
action 1, numVisits=24, meanQ=3.166263, numObservations: 3
action -1, numVisits=18, meanQ=2.986132, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.519001 0.899759 0.329528 0.784863 0.545021 0.866604 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 84
Initial state: 0 0.557114 0.843212 0.521712 0.830116 0.814349 0.829695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1143568 episodes
GETTING ACTION FROM:
action 1, numVisits=1141793, meanQ=4.971712, numObservations: 4
action 3, numVisits=1708, meanQ=4.721477, numObservations: 4
action 0, numVisits=33, meanQ=3.658170, numObservations: 1
action -1, numVisits=24, meanQ=3.402516, numObservations: 1
action 2, numVisits=10, meanQ=2.598000, numObservations: 3
action: 1
Next state: 1 0.557114 0.843212 0.521712 0.830116 0.814349 0.829695 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 85
Initial state: 0 0.660095 0.812425 0.515799 0.897764 0.525568 0.209343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145154 episodes
GETTING ACTION FROM:
action 1, numVisits=1144604, meanQ=5.003860, numObservations: 4
action 0, numVisits=538, meanQ=2.599313, numObservations: 1
action 3, numVisits=9, meanQ=0.111122, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.660095 0.812425 0.515799 0.897764 0.525568 0.209343 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=174840, meanQ=8.304116, numObservations: 5
action 2, numVisits=469, meanQ=7.983881, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1399654 episodes
GETTING ACTION FROM:
action 3, numVisits=1570497, meanQ=5.987029, numObservations: 5
action 2, numVisits=4464, meanQ=5.878457, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.660095 0.812425 0.515799 0.897764 0.525568 0.209343 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 86
Initial state: 0 0.657811 0.846952 0.635403 0.881795 0.360902 0.276994 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1153534 episodes
GETTING ACTION FROM:
action 3, numVisits=1153516, meanQ=4.971270, numObservations: 3
action 1, numVisits=13, meanQ=2.383854, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.657811 0.846952 0.635403 0.881795 0.360902 0.276994 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 87
Initial state: 0 0.0991427 0.237606 0.513238 0.897259 0.540433 0.889093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145502 episodes
GETTING ACTION FROM:
action 3, numVisits=1145436, meanQ=4.986363, numObservations: 4
action -1, numVisits=36, meanQ=3.735356, numObservations: 1
action 0, numVisits=19, meanQ=3.236851, numObservations: 1
action 1, numVisits=10, meanQ=2.399010, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.0991427 0.237606 0.513238 0.897259 0.540433 0.889093 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=83264, meanQ=5.620861, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1330919 episodes
GETTING ACTION FROM:
action 3, numVisits=1414183, meanQ=5.164826, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.0991427 0.237606 0.513238 0.897259 0.540433 0.889093 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=30529, meanQ=6.201565, numObservations: 4
action 2, numVisits=25, meanQ=3.860400, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1452542 episodes
GETTING ACTION FROM:
action 1, numVisits=1483069, meanQ=6.023199, numObservations: 4
action 2, numVisits=25, meanQ=3.860400, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.0991427 0.237606 0.513238 0.897259 0.540433 0.889093 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 88
Initial state: 0 0.526487 0.830828 0.650412 0.873098 0.36215 0.710817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1135463 episodes
GETTING ACTION FROM:
action 1, numVisits=1135417, meanQ=4.918820, numObservations: 4
action -1, numVisits=41, meanQ=3.750042, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.526487 0.830828 0.650412 0.873098 0.36215 0.710817 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 89
Initial state: 0 0.476936 0.513132 0.641191 0.866032 0.551858 0.850788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132989 episodes
GETTING ACTION FROM:
action 2, numVisits=1124366, meanQ=4.987019, numObservations: 4
action 0, numVisits=8563, meanQ=2.945645, numObservations: 1
action -1, numVisits=43, meanQ=1.789936, numObservations: 1
action 1, numVisits=14, meanQ=0.990714, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 2
Next state: 1 0.476936 0.513132 0.641191 0.866032 0.551858 0.850788 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 90
Initial state: 0 0.697189 0.851305 0.5327 0.884149 0.976706 0.418847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132520 episodes
GETTING ACTION FROM:
action 2, numVisits=1132405, meanQ=4.983850, numObservations: 5
action 0, numVisits=111, meanQ=4.270161, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.697189 0.851305 0.5327 0.884149 0.976706 0.418847 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 91
Initial state: 0 0.145887 0.111148 0.648234 0.876737 0.510195 0.86213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130850 episodes
GETTING ACTION FROM:
action 1, numVisits=1130840, meanQ=4.900868, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.145887 0.111148 0.648234 0.876737 0.510195 0.86213 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 92
Initial state: 0 0.541892 0.865306 0.508661 0.852564 0.702042 0.0430965 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145633 episodes
GETTING ACTION FROM:
action 2, numVisits=1145529, meanQ=4.979732, numObservations: 4
action -1, numVisits=52, meanQ=3.926406, numObservations: 1
action 3, numVisits=43, meanQ=3.741165, numObservations: 4
action 1, numVisits=7, meanQ=2.127143, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.541892 0.865306 0.508661 0.852564 0.702042 0.0430965 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 93
Initial state: 0 0.523524 0.808207 0.0549258 0.277591 0.673844 0.895775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1135242 episodes
GETTING ACTION FROM:
action 1, numVisits=1135235, meanQ=4.893637, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.523524 0.808207 0.0549258 0.277591 0.673844 0.895775 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 94
Initial state: 0 0.961933 0.0198097 0.527033 0.858313 0.579709 0.899388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125163 episodes
GETTING ACTION FROM:
action 3, numVisits=1124684, meanQ=4.902037, numObservations: 5
action 2, numVisits=194, meanQ=4.343504, numObservations: 3
action 0, numVisits=166, meanQ=4.326403, numObservations: 1
action -1, numVisits=118, meanQ=4.206678, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.961933 0.0198097 0.527033 0.858313 0.579709 0.899388 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 95
Initial state: 0 0.511541 0.86584 0.119047 0.965728 0.615234 0.833026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099239 episodes
GETTING ACTION FROM:
action 3, numVisits=1099220, meanQ=4.764638, numObservations: 4
action 1, numVisits=14, meanQ=0.998586, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.511541 0.86584 0.119047 0.965728 0.615234 0.833026 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 96
Initial state: 0 0.688828 0.8428 0.457425 0.993581 0.643808 0.82589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1143950 episodes
GETTING ACTION FROM:
action 2, numVisits=1132391, meanQ=5.105872, numObservations: 4
action -1, numVisits=11554, meanQ=3.050345, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.688828 0.8428 0.457425 0.993581 0.643808 0.82589 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 97
Initial state: 0 0.62536 0.040037 0.690346 0.808682 0.62619 0.895819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1147289 episodes
GETTING ACTION FROM:
action 1, numVisits=1147246, meanQ=4.983458, numObservations: 4
action -1, numVisits=33, meanQ=3.682626, numObservations: 1
action 3, numVisits=7, meanQ=0.985714, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.62536 0.040037 0.690346 0.808682 0.62619 0.895819 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 98
Initial state: 0 0.222184 0.234473 0.554406 0.842832 0.683044 0.898848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146687 episodes
GETTING ACTION FROM:
action 2, numVisits=1146648, meanQ=4.907716, numObservations: 4
action -1, numVisits=35, meanQ=3.630789, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.222184 0.234473 0.554406 0.842832 0.683044 0.898848 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 99
Initial state: 0 0.536364 0.851498 0.634478 0.88533 0.396886 0.238733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090095 episodes
GETTING ACTION FROM:
action 3, numVisits=1090078, meanQ=4.825835, numObservations: 4
action 2, numVisits=12, meanQ=2.498342, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.536364 0.851498 0.634478 0.88533 0.396886 0.238733 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=163590, meanQ=8.264743, numObservations: 5
action 2, numVisits=2883, meanQ=8.149565, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1406124 episodes
GETTING ACTION FROM:
action 1, numVisits=1550616, meanQ=6.097307, numObservations: 5
action 2, numVisits=21979, meanQ=6.052325, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.536364 0.851498 0.634478 0.88533 0.396886 0.238733 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 100
Initial state: 0 0.609805 0.890095 0.206465 0.40666 0.654326 0.805629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127631 episodes
GETTING ACTION FROM:
action 1, numVisits=1119163, meanQ=4.923567, numObservations: 5
action 0, numVisits=8458, meanQ=2.939268, numObservations: 1
action 3, numVisits=5, meanQ=-1.402000, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.609805 0.890095 0.206465 0.40666 0.654326 0.805629 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 101
Initial state: 0 0.519708 0.815922 0.587819 0.860434 0.433565 0.325816 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130657 episodes
GETTING ACTION FROM:
action 1, numVisits=1130650, meanQ=4.927641, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.519708 0.815922 0.587819 0.860434 0.433565 0.325816 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 102
Initial state: 0 0.514376 0.89286 0.942131 0.0836203 0.655683 0.874615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146132 episodes
GETTING ACTION FROM:
action 3, numVisits=1145969, meanQ=4.903807, numObservations: 3
action 0, numVisits=91, meanQ=4.123848, numObservations: 1
action -1, numVisits=66, meanQ=3.987759, numObservations: 1
action 1, numVisits=4, meanQ=0.025000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 1 0.514376 0.89286 0.942131 0.0836203 0.655683 0.874615 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 103
Initial state: 0 0.594088 0.849782 0.192807 0.80865 0.610795 0.808604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1150076 episodes
GETTING ACTION FROM:
action 3, numVisits=1122378, meanQ=4.965171, numObservations: 3
action 1, numVisits=27693, meanQ=4.822694, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.594088 0.849782 0.192807 0.80865 0.610795 0.808604 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 104
Initial state: 0 0.670481 0.867849 0.878692 0.614973 0.577723 0.888901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137348 episodes
GETTING ACTION FROM:
action 2, numVisits=1137332, meanQ=4.991769, numObservations: 4
action 1, numVisits=10, meanQ=1.198010, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.670481 0.867849 0.878692 0.614973 0.577723 0.888901 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 105
Initial state: 0 0.519273 0.0503849 0.680017 0.828339 0.652113 0.811723 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1141436 episodes
GETTING ACTION FROM:
action 3, numVisits=1141366, meanQ=4.966380, numObservations: 4
action 0, numVisits=63, meanQ=4.023744, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.519273 0.0503849 0.680017 0.828339 0.652113 0.811723 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 106
Initial state: 0 0.503005 0.807256 0.792263 0.525896 0.565201 0.818455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103620 episodes
GETTING ACTION FROM:
action 2, numVisits=1103387, meanQ=4.812946, numObservations: 4
action 0, numVisits=229, meanQ=4.151375, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.503005 0.807256 0.792263 0.525896 0.565201 0.818455 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 107
Initial state: 0 0.54907 0.819028 0.640423 0.85622 0.0850355 0.97587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127930 episodes
GETTING ACTION FROM:
action 3, numVisits=1127912, meanQ=4.959995, numObservations: 4
action 2, numVisits=6, meanQ=1.663333, numObservations: 4
action 1, numVisits=8, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.54907 0.819028 0.640423 0.85622 0.0850355 0.97587 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 108
Initial state: 0 0.663381 0.83278 0.63916 0.803389 0.559799 0.634679 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1147727 episodes
GETTING ACTION FROM:
action 3, numVisits=1147692, meanQ=5.022940, numObservations: 4
action 0, numVisits=31, meanQ=3.647332, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.663381 0.83278 0.63916 0.803389 0.559799 0.634679 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 109
Initial state: 0 0.251435 0.00241674 0.542258 0.838979 0.675392 0.826239 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139996 episodes
GETTING ACTION FROM:
action 2, numVisits=1138981, meanQ=4.997777, numObservations: 4
action 1, numVisits=898, meanQ=4.749452, numObservations: 4
action -1, numVisits=114, meanQ=4.295360, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.251435 0.00241674 0.542258 0.838979 0.675392 0.826239 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 110
Initial state: 0 0.769161 0.278536 0.663894 0.81954 0.564491 0.831068 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130775 episodes
GETTING ACTION FROM:
action 2, numVisits=1130769, meanQ=4.990642, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.769161 0.278536 0.663894 0.81954 0.564491 0.831068 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 111
Initial state: 0 0.59867 0.838461 0.997103 0.202588 0.513084 0.85478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1144413 episodes
GETTING ACTION FROM:
action 2, numVisits=1144287, meanQ=4.907177, numObservations: 4
action -1, numVisits=78, meanQ=4.044296, numObservations: 1
action 0, numVisits=46, meanQ=3.775869, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.59867 0.838461 0.997103 0.202588 0.513084 0.85478 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=83167, meanQ=4.678436, numObservations: 5
action -1, numVisits=42, meanQ=3.641417, numObservations: 1
action 2, numVisits=42, meanQ=3.520243, numObservations: 3
action 0, numVisits=17, meanQ=3.023710, numObservations: 1
action 1, numVisits=11, meanQ=1.907282, numObservations: 2
Sampled 1406804 episodes
GETTING ACTION FROM:
action 3, numVisits=1489971, meanQ=5.962396, numObservations: 5
action -1, numVisits=42, meanQ=3.641417, numObservations: 1
action 2, numVisits=42, meanQ=3.520243, numObservations: 3
action 0, numVisits=17, meanQ=3.023710, numObservations: 1
action 1, numVisits=11, meanQ=1.907282, numObservations: 2
action: 3
Next state: 0 0.59867 0.838461 0.997103 0.202588 0.513084 0.85478 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=32005, meanQ=6.700436, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1471754 episodes
GETTING ACTION FROM:
action 3, numVisits=1503757, meanQ=5.692206, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.59867 0.838461 0.997103 0.202588 0.513084 0.85478 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 112
Initial state: 0 0.0727706 0.289864 0.503443 0.800923 0.685981 0.812719 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132138 episodes
GETTING ACTION FROM:
action 2, numVisits=1132131, meanQ=4.961750, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0727706 0.289864 0.503443 0.800923 0.685981 0.812719 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 113
Initial state: 0 0.631967 0.893728 0.586285 0.882353 0.906603 0.742286 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146390 episodes
GETTING ACTION FROM:
action 3, numVisits=1146208, meanQ=4.900195, numObservations: 3
action -1, numVisits=128, meanQ=4.049385, numObservations: 1
action 0, numVisits=36, meanQ=3.577859, numObservations: 1
action 1, numVisits=17, meanQ=2.763547, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.631967 0.893728 0.586285 0.882353 0.906603 0.742286 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 114
Initial state: 0 0.128627 0.102043 0.611751 0.890027 0.654967 0.874868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130016 episodes
GETTING ACTION FROM:
action 3, numVisits=1125980, meanQ=4.968001, numObservations: 5
action 1, numVisits=4013, meanQ=4.814037, numObservations: 5
action -1, numVisits=20, meanQ=3.240599, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.128627 0.102043 0.611751 0.890027 0.654967 0.874868 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 115
Initial state: 0 0.440242 0.648979 0.588056 0.854221 0.671766 0.883477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1135765 episodes
GETTING ACTION FROM:
action 3, numVisits=1135753, meanQ=5.124112, numObservations: 4
action 1, numVisits=7, meanQ=-0.701429, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.440242 0.648979 0.588056 0.854221 0.671766 0.883477 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 116
Initial state: 0 0.500385 0.855308 0.570656 0.892646 0.7208 0.75852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127910 episodes
GETTING ACTION FROM:
action 1, numVisits=1121185, meanQ=4.988392, numObservations: 5
action 2, numVisits=6693, meanQ=4.889256, numObservations: 4
action 0, numVisits=26, meanQ=3.525797, numObservations: 1
action 3, numVisits=4, meanQ=-0.504975, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.500385 0.855308 0.570656 0.892646 0.7208 0.75852 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=81077, meanQ=5.549208, numObservations: 4
action 2, numVisits=742, meanQ=4.377177, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 1354413 episodes
GETTING ACTION FROM:
action 1, numVisits=1435490, meanQ=5.116989, numObservations: 4
action 2, numVisits=742, meanQ=4.377177, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.500385 0.855308 0.570656 0.892646 0.7208 0.75852 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 117
Initial state: 0 0.590852 0.806493 0.856479 0.411959 0.624129 0.839836 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129357 episodes
GETTING ACTION FROM:
action 3, numVisits=1118562, meanQ=4.975945, numObservations: 4
action -1, numVisits=10089, meanQ=3.024206, numObservations: 1
action 0, numVisits=699, meanQ=2.854325, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 3
Next state: 1 0.590852 0.806493 0.856479 0.411959 0.624129 0.839836 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 118
Initial state: 0 0.847871 0.925504 0.615082 0.867237 0.58094 0.861137 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1126345 episodes
GETTING ACTION FROM:
action 3, numVisits=1126273, meanQ=4.904424, numObservations: 5
action 0, numVisits=68, meanQ=3.989830, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.847871 0.925504 0.615082 0.867237 0.58094 0.861137 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 119
Initial state: 0 0.576237 0.89928 0.472493 0.774631 0.582053 0.895064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1143628 episodes
GETTING ACTION FROM:
action 1, numVisits=1143528, meanQ=4.994587, numObservations: 4
action 2, numVisits=93, meanQ=3.955175, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.576237 0.89928 0.472493 0.774631 0.582053 0.895064 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 120
Initial state: 0 0.56233 0.877194 0.534847 0.84872 0.50351 0.659539 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 776157 episodes
GETTING ACTION FROM:
action 0, numVisits=775331, meanQ=2.898127, numObservations: 1
action -1, numVisits=821, meanQ=1.479044, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.56233 0.877194 0.534847 0.84872 0.50351 0.659539 w: 1
Observation: 0 0 0.91828 0 0.893367 0 0.640524 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=775232, meanQ=4.961946, numObservations: 4
action 0, numVisits=83, meanQ=4.145738, numObservations: 1
action 1, numVisits=8, meanQ=1.996250, numObservations: 3
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1241623 episodes
GETTING ACTION FROM:
action 3, numVisits=2016849, meanQ=4.890778, numObservations: 4
action 0, numVisits=89, meanQ=4.083521, numObservations: 1
action 1, numVisits=8, meanQ=1.996250, numObservations: 3
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.56233 0.877194 0.534847 0.84872 0.50351 0.659539 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 121
Initial state: 0 0.576234 0.87115 0.615678 0.851179 0.768902 0.397958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120851 episodes
GETTING ACTION FROM:
action 3, numVisits=1120819, meanQ=4.980774, numObservations: 5
action 1, numVisits=27, meanQ=3.218159, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.576234 0.87115 0.615678 0.851179 0.768902 0.397958 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 122
Initial state: 0 0.660507 0.889603 0.521984 0.865887 0.409031 0.784601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1143623 episodes
GETTING ACTION FROM:
action 2, numVisits=1143617, meanQ=4.987307, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.660507 0.889603 0.521984 0.865887 0.409031 0.784601 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 123
Initial state: 0 0.643703 0.37858 0.603044 0.823432 0.693101 0.887226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1144139 episodes
GETTING ACTION FROM:
action 1, numVisits=1144030, meanQ=4.985725, numObservations: 4
action 0, numVisits=55, meanQ=3.971015, numObservations: 1
action -1, numVisits=52, meanQ=3.941444, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.643703 0.37858 0.603044 0.823432 0.693101 0.887226 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=62987, meanQ=7.787175, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1435686 episodes
GETTING ACTION FROM:
action 3, numVisits=1498671, meanQ=5.795360, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.643703 0.37858 0.603044 0.823432 0.693101 0.887226 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 124
Initial state: 0 0.792423 0.672727 0.627308 0.87066 0.57904 0.801701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131175 episodes
GETTING ACTION FROM:
action 2, numVisits=1131164, meanQ=4.904826, numObservations: 5
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.792423 0.672727 0.627308 0.87066 0.57904 0.801701 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 125
Initial state: 0 0.678949 0.803325 0.565321 0.674178 0.539722 0.821032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133986 episodes
GETTING ACTION FROM:
action 3, numVisits=1133886, meanQ=4.974940, numObservations: 4
action -1, numVisits=59, meanQ=3.997922, numObservations: 1
action 1, numVisits=35, meanQ=3.511443, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.678949 0.803325 0.565321 0.674178 0.539722 0.821032 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=83206, meanQ=5.611684, numObservations: 4
action 0, numVisits=35, meanQ=4.466159, numObservations: 1
action 1, numVisits=8, meanQ=3.011250, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1419220 episodes
GETTING ACTION FROM:
action 1, numVisits=1304210, meanQ=5.775225, numObservations: 4
action 3, numVisits=198220, meanQ=5.010893, numObservations: 4
action 0, numVisits=39, meanQ=3.802964, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.678949 0.803325 0.565321 0.674178 0.539722 0.821032 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 126
Initial state: 0 0.50251 0.81109 0.617825 0.841782 0.52775 0.837494 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131193 episodes
GETTING ACTION FROM:
action 3, numVisits=1131170, meanQ=4.974009, numObservations: 4
action 2, numVisits=18, meanQ=2.993889, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.50251 0.81109 0.617825 0.841782 0.52775 0.837494 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=62192, meanQ=7.757102, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1432529 episodes
GETTING ACTION FROM:
action 2, numVisits=1022972, meanQ=6.163376, numObservations: 4
action 1, numVisits=471749, meanQ=5.820307, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.50251 0.81109 0.617825 0.841782 0.52775 0.837494 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 127
Initial state: 0 0.569911 0.864753 0.394283 0.988248 0.630973 0.889714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 773697 episodes
GETTING ACTION FROM:
action -1, numVisits=563607, meanQ=2.894339, numObservations: 1
action 0, numVisits=210069, meanQ=2.888081, numObservations: 1
action 1, numVisits=12, meanQ=0.666675, numObservations: 2
action 3, numVisits=7, meanQ=-0.145714, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action: -1
Next state: 0 0.569911 0.864753 0.394283 0.988248 0.630973 0.889714 w: 1
Observation: 0 0.576308 0 0.386299 0 0.563059 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=563591, meanQ=4.939917, numObservations: 5
action 3, numVisits=9, meanQ=2.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1219300 episodes
GETTING ACTION FROM:
action 2, numVisits=1782884, meanQ=4.824451, numObservations: 5
action 3, numVisits=16, meanQ=2.374381, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.569911 0.864753 0.394283 0.988248 0.630973 0.889714 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=135361, meanQ=5.397163, numObservations: 4
action -1, numVisits=29, meanQ=4.076879, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1303511 episodes
GETTING ACTION FROM:
action 2, numVisits=1438868, meanQ=4.892377, numObservations: 5
action -1, numVisits=33, meanQ=3.468436, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.569911 0.864753 0.394283 0.988248 0.630973 0.889714 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=47198, meanQ=6.755095, numObservations: 4
action 2, numVisits=4, meanQ=2.497525, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1443049 episodes
GETTING ACTION FROM:
action 3, numVisits=1490233, meanQ=5.794759, numObservations: 4
action 2, numVisits=16, meanQ=3.624381, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.569911 0.864753 0.394283 0.988248 0.630973 0.889714 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -1.14771
Run # 128
Initial state: 0 0.537964 0.458637 0.623735 0.807995 0.655248 0.841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106180 episodes
GETTING ACTION FROM:
action 1, numVisits=1106117, meanQ=4.767923, numObservations: 4
action 0, numVisits=37, meanQ=3.547924, numObservations: 1
action 3, numVisits=23, meanQ=2.903930, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.537964 0.458637 0.623735 0.807995 0.655248 0.841 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 129
Initial state: 0 0.50238 0.801021 0.673404 0.857288 0.0630671 0.526046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128131 episodes
GETTING ACTION FROM:
action 1, numVisits=1118928, meanQ=4.930459, numObservations: 5
action -1, numVisits=9199, meanQ=2.969299, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.50238 0.801021 0.673404 0.857288 0.0630671 0.526046 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 130
Initial state: 0 0.604213 0.866993 0.579094 0.894924 0.455041 0.64235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1151639 episodes
GETTING ACTION FROM:
action 1, numVisits=1151633, meanQ=4.919516, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.604213 0.866993 0.579094 0.894924 0.455041 0.64235 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 131
Initial state: 0 0.573132 0.825879 0.0771401 0.975819 0.577882 0.800993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138342 episodes
GETTING ACTION FROM:
action 2, numVisits=1138330, meanQ=4.918988, numObservations: 4
action 3, numVisits=7, meanQ=-0.145714, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.573132 0.825879 0.0771401 0.975819 0.577882 0.800993 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=173570, meanQ=8.282588, numObservations: 4
action 3, numVisits=36, meanQ=6.944450, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1429201 episodes
GETTING ACTION FROM:
action 1, numVisits=1597856, meanQ=5.960626, numObservations: 4
action 3, numVisits=4949, meanQ=5.858718, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.573132 0.825879 0.0771401 0.975819 0.577882 0.800993 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=4672, meanQ=7.285040, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1483888 episodes
GETTING ACTION FROM:
action 3, numVisits=1488558, meanQ=6.092407, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.573132 0.825879 0.0771401 0.975819 0.577882 0.800993 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 132
Initial state: 0 0.656399 0.898008 0.603733 0.861724 0.0411783 0.034867 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139755 episodes
GETTING ACTION FROM:
action 1, numVisits=1139698, meanQ=5.155154, numObservations: 5
action -1, numVisits=50, meanQ=4.080478, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.656399 0.898008 0.603733 0.861724 0.0411783 0.034867 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 133
Initial state: 0 0.588061 0.874437 0.355881 0.427691 0.671825 0.863836 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1143149 episodes
GETTING ACTION FROM:
action 2, numVisits=1143086, meanQ=4.966422, numObservations: 4
action 0, numVisits=53, meanQ=3.903300, numObservations: 1
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.588061 0.874437 0.355881 0.427691 0.671825 0.863836 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=174500, meanQ=8.292181, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1454501 episodes
GETTING ACTION FROM:
action 3, numVisits=1628984, meanQ=6.048358, numObservations: 3
action 1, numVisits=17, meanQ=4.057647, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.588061 0.874437 0.355881 0.427691 0.671825 0.863836 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=37502, meanQ=7.821227, numObservations: 3
action 1, numVisits=193, meanQ=7.332590, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1473923 episodes
GETTING ACTION FROM:
action 1, numVisits=1195570, meanQ=5.973608, numObservations: 4
action 3, numVisits=316046, meanQ=5.925975, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.588061 0.874437 0.355881 0.427691 0.671825 0.863836 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 134
Initial state: 0 0.652762 0.85842 0.593052 0.844835 0.797009 0.72121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138038 episodes
GETTING ACTION FROM:
action 1, numVisits=1137965, meanQ=4.896153, numObservations: 4
action -1, numVisits=41, meanQ=3.707159, numObservations: 1
action 2, numVisits=29, meanQ=3.485517, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.652762 0.85842 0.593052 0.844835 0.797009 0.72121 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 135
Initial state: 0 0.577158 0.802494 0.595028 0.895858 0.0987905 0.503134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 777612 episodes
GETTING ACTION FROM:
action 0, numVisits=777581, meanQ=2.957133, numObservations: 1
action 1, numVisits=19, meanQ=0.999474, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action 3, numVisits=5, meanQ=-1.005980, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action: 0
Next state: 0 0.577158 0.802494 0.595028 0.895858 0.0987905 0.503134 w: 1
Observation: 0 0 0.718264 0 0.838343 0 0.541494 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=777515, meanQ=4.998566, numObservations: 4
action 2, numVisits=46, meanQ=3.684133, numObservations: 4
action 1, numVisits=15, meanQ=2.866000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1240369 episodes
GETTING ACTION FROM:
action 3, numVisits=2017884, meanQ=5.041433, numObservations: 4
action 2, numVisits=46, meanQ=3.684133, numObservations: 4
action 1, numVisits=15, meanQ=2.866000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.577158 0.802494 0.595028 0.895858 0.0987905 0.503134 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=312733, meanQ=8.323546, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1430588 episodes
GETTING ACTION FROM:
action 1, numVisits=1743319, meanQ=6.215709, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.577158 0.802494 0.595028 0.895858 0.0987905 0.503134 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 136
Initial state: 0 0.635046 0.842716 0.621972 0.521654 0.529655 0.880275 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131068 episodes
GETTING ACTION FROM:
action 1, numVisits=1131062, meanQ=5.119176, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.635046 0.842716 0.621972 0.521654 0.529655 0.880275 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 137
Initial state: 0 0.545956 0.834171 0.537248 0.878922 0.406205 0.757576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 803562 episodes
GETTING ACTION FROM:
action 0, numVisits=803555, meanQ=5.516558, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.545956 0.834171 0.537248 0.878922 0.406205 0.757576 w: 1
Observation: 0 0 0.89983 0 0.891471 0 0.792681 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=609010, meanQ=7.348134, numObservations: 4
action 1, numVisits=2116, meanQ=4.028722, numObservations: 5
action 2, numVisits=25, meanQ=2.919608, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 1227056 episodes
GETTING ACTION FROM:
action 3, numVisits=1836066, meanQ=5.764411, numObservations: 4
action 1, numVisits=2116, meanQ=4.028722, numObservations: 5
action 2, numVisits=25, meanQ=2.919608, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.545956 0.834171 0.537248 0.878922 0.406205 0.757576 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=229964, meanQ=8.220778, numObservations: 4
action 1, numVisits=4, meanQ=4.000000, numObservations: 1
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1430114 episodes
GETTING ACTION FROM:
action 2, numVisits=1660060, meanQ=6.089654, numObservations: 4
action 1, numVisits=14, meanQ=3.285714, numObservations: 2
action 3, numVisits=5, meanQ=2.598000, numObservations: 2
action 0, numVisits=5, meanQ=1.762000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 0 0.545956 0.834171 0.537248 0.878922 0.406205 0.757576 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=5438, meanQ=7.838182, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1476721 episodes
GETTING ACTION FROM:
action 2, numVisits=1482157, meanQ=5.495293, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.545956 0.834171 0.537248 0.878922 0.406205 0.757576 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -1.14771
Run # 138
Initial state: 0 0.527066 0.80979 0.605312 0.527553 0.695416 0.837374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133488 episodes
GETTING ACTION FROM:
action 2, numVisits=1129868, meanQ=4.996019, numObservations: 5
action 3, numVisits=3591, meanQ=4.841614, numObservations: 4
action 0, numVisits=21, meanQ=3.333878, numObservations: 1
action 1, numVisits=6, meanQ=1.015000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.527066 0.80979 0.605312 0.527553 0.695416 0.837374 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 139
Initial state: 0 0.691398 0.802351 0.672812 0.48882 0.685289 0.883491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133582 episodes
GETTING ACTION FROM:
action 2, numVisits=1133569, meanQ=4.929691, numObservations: 5
action 1, numVisits=8, meanQ=-1.001225, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.691398 0.802351 0.672812 0.48882 0.685289 0.883491 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 140
Initial state: 0 0.305727 0.704824 0.662481 0.807993 0.533384 0.813799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128280 episodes
GETTING ACTION FROM:
action 3, numVisits=1128211, meanQ=4.972892, numObservations: 5
action -1, numVisits=34, meanQ=3.684933, numObservations: 1
action 0, numVisits=31, meanQ=3.555220, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.305727 0.704824 0.662481 0.807993 0.533384 0.813799 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 141
Initial state: 0 0.702896 0.708319 0.613188 0.807524 0.674527 0.874689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1152109 episodes
GETTING ACTION FROM:
action 3, numVisits=1152034, meanQ=4.975235, numObservations: 3
action 0, numVisits=67, meanQ=4.061970, numObservations: 1
action 2, numVisits=4, meanQ=-0.007500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.702896 0.708319 0.613188 0.807524 0.674527 0.874689 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 142
Initial state: 0 0.667721 0.810602 0.985534 0.719065 0.547345 0.831214 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145847 episodes
GETTING ACTION FROM:
action 1, numVisits=1145823, meanQ=4.997677, numObservations: 4
action 2, numVisits=19, meanQ=3.101058, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.667721 0.810602 0.985534 0.719065 0.547345 0.831214 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=82908, meanQ=5.615621, numObservations: 4
action 3, numVisits=75, meanQ=3.970801, numObservations: 4
action 0, numVisits=17, meanQ=3.861285, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1358615 episodes
GETTING ACTION FROM:
action 3, numVisits=695380, meanQ=5.584120, numObservations: 5
action 1, numVisits=746215, meanQ=4.811530, numObservations: 5
action 0, numVisits=20, meanQ=2.982092, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.667721 0.810602 0.985534 0.719065 0.547345 0.831214 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 143
Initial state: 0 0.623649 0.889856 0.54836 0.944705 0.605013 0.80416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1085131 episodes
GETTING ACTION FROM:
action 2, numVisits=1085125, meanQ=4.779445, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.623649 0.889856 0.54836 0.944705 0.605013 0.80416 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 144
Initial state: 0 0.264465 0.625693 0.525356 0.801689 0.608891 0.845211 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142127 episodes
GETTING ACTION FROM:
action 2, numVisits=1141632, meanQ=4.979668, numObservations: 4
action 3, numVisits=222, meanQ=4.435549, numObservations: 4
action 1, numVisits=210, meanQ=4.420679, numObservations: 4
action 0, numVisits=61, meanQ=4.011945, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.264465 0.625693 0.525356 0.801689 0.608891 0.845211 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 145
Initial state: 0 0.641198 0.818196 0.21541 0.307506 0.608244 0.854195 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1143242 episodes
GETTING ACTION FROM:
action 1, numVisits=1143236, meanQ=4.913356, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.641198 0.818196 0.21541 0.307506 0.608244 0.854195 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 146
Initial state: 0 0.58918 0.462188 0.57196 0.89837 0.676892 0.877394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1144307 episodes
GETTING ACTION FROM:
action 2, numVisits=1144274, meanQ=4.994682, numObservations: 4
action 3, numVisits=21, meanQ=1.946676, numObservations: 4
action 1, numVisits=8, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.58918 0.462188 0.57196 0.89837 0.676892 0.877394 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 147
Initial state: 0 0.683781 0.862042 0.14782 0.632363 0.68383 0.878561 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1149277 episodes
GETTING ACTION FROM:
action 3, numVisits=1149260, meanQ=4.988590, numObservations: 3
action 2, numVisits=12, meanQ=1.998333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.683781 0.862042 0.14782 0.632363 0.68383 0.878561 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 148
Initial state: 0 0.662423 0.861915 0.367204 0.737008 0.574578 0.838828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120995 episodes
GETTING ACTION FROM:
action 2, numVisits=1120977, meanQ=4.939124, numObservations: 3
action -1, numVisits=14, meanQ=2.842695, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.662423 0.861915 0.367204 0.737008 0.574578 0.838828 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=172037, meanQ=8.291767, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1426566 episodes
GETTING ACTION FROM:
action 3, numVisits=1598601, meanQ=6.048421, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.662423 0.861915 0.367204 0.737008 0.574578 0.838828 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 149
Initial state: 0 0.610475 0.8495 0.918394 0.0883711 0.672257 0.894544 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129159 episodes
GETTING ACTION FROM:
action 1, numVisits=1129120, meanQ=4.924290, numObservations: 5
action -1, numVisits=19, meanQ=3.101005, numObservations: 1
action 2, numVisits=10, meanQ=1.997010, numObservations: 4
action 3, numVisits=8, meanQ=1.996250, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.610475 0.8495 0.918394 0.0883711 0.672257 0.894544 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 150
Initial state: 0 0.685227 0.893109 0.842389 0.0581133 0.664687 0.837717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133194 episodes
GETTING ACTION FROM:
action 2, numVisits=1133184, meanQ=4.994861, numObservations: 5
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.685227 0.893109 0.842389 0.0581133 0.664687 0.837717 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=83016, meanQ=5.736335, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1342548 episodes
GETTING ACTION FROM:
action 2, numVisits=1425559, meanQ=5.151649, numObservations: 4
action 0, numVisits=5, meanQ=1.762000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.685227 0.893109 0.842389 0.0581133 0.664687 0.837717 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 151
Initial state: 0 0.587789 0.882611 0.337508 0.208151 0.60828 0.886632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1119122 episodes
GETTING ACTION FROM:
action 3, numVisits=1117661, meanQ=4.957361, numObservations: 5
action 1, numVisits=1456, meanQ=4.764820, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.587789 0.882611 0.337508 0.208151 0.60828 0.886632 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 152
Initial state: 0 0.660895 0.883229 0.206309 0.628858 0.69782 0.895664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1123126 episodes
GETTING ACTION FROM:
action 2, numVisits=1123016, meanQ=4.918311, numObservations: 5
action 1, numVisits=87, meanQ=4.070348, numObservations: 4
action -1, numVisits=20, meanQ=3.192481, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.660895 0.883229 0.206309 0.628858 0.69782 0.895664 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=62028, meanQ=7.847036, numObservations: 4
action 3, numVisits=7, meanQ=4.427143, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1429690 episodes
GETTING ACTION FROM:
action 1, numVisits=1491714, meanQ=5.835687, numObservations: 4
action 3, numVisits=8, meanQ=2.498750, numObservations: 3
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.660895 0.883229 0.206309 0.628858 0.69782 0.895664 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 153
Initial state: 0 0.809715 0.310486 0.602547 0.853129 0.630594 0.886691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1148241 episodes
GETTING ACTION FROM:
action 1, numVisits=1148235, meanQ=4.991786, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.809715 0.310486 0.602547 0.853129 0.630594 0.886691 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 154
Initial state: 0 0.600529 0.851539 0.628374 0.836035 0.50248 0.902747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1141668 episodes
GETTING ACTION FROM:
action 3, numVisits=1141626, meanQ=4.932248, numObservations: 4
action -1, numVisits=35, meanQ=3.650062, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.600529 0.851539 0.628374 0.836035 0.50248 0.902747 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 155
Initial state: 0 0.541843 0.886838 0.452786 0.0210719 0.543654 0.899153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1140161 episodes
GETTING ACTION FROM:
action 3, numVisits=1140110, meanQ=4.964148, numObservations: 4
action -1, numVisits=46, meanQ=3.835967, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.541843 0.886838 0.452786 0.0210719 0.543654 0.899153 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 156
Initial state: 0 0.685065 0.808193 0.600469 0.893163 0.660904 0.805299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124801 episodes
GETTING ACTION FROM:
action 3, numVisits=1124252, meanQ=4.976719, numObservations: 5
action 1, numVisits=270, meanQ=4.520217, numObservations: 4
action 2, numVisits=249, meanQ=4.505332, numObservations: 3
action 0, numVisits=28, meanQ=3.502127, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.685065 0.808193 0.600469 0.893163 0.660904 0.805299 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 157
Initial state: 0 0.577089 0.827339 0.0758698 0.645802 0.672328 0.874054 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097416 episodes
GETTING ACTION FROM:
action 2, numVisits=1096084, meanQ=4.806178, numObservations: 4
action 1, numVisits=1273, meanQ=4.592839, numObservations: 5
action 0, numVisits=56, meanQ=3.813777, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.577089 0.827339 0.0758698 0.645802 0.672328 0.874054 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=150815, meanQ=8.296384, numObservations: 4
action 3, numVisits=16913, meanQ=8.114356, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1423730 episodes
GETTING ACTION FROM:
action 1, numVisits=1416565, meanQ=5.970492, numObservations: 4
action 3, numVisits=174891, meanQ=5.958725, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.577089 0.827339 0.0758698 0.645802 0.672328 0.874054 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 158
Initial state: 0 0.292604 0.941118 0.504074 0.824468 0.513066 0.80812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1135991 episodes
GETTING ACTION FROM:
action 2, numVisits=1120145, meanQ=4.911671, numObservations: 4
action 0, numVisits=15709, meanQ=2.800311, numObservations: 1
action -1, numVisits=134, meanQ=2.310335, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.292604 0.941118 0.504074 0.824468 0.513066 0.80812 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 159
Initial state: 0 0.441392 0.914966 0.592865 0.83685 0.649621 0.825108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109498 episodes
GETTING ACTION FROM:
action 3, numVisits=1109492, meanQ=4.882133, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.441392 0.914966 0.592865 0.83685 0.649621 0.825108 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 160
Initial state: 0 0.460933 0.876419 0.537355 0.839573 0.518081 0.839238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1140478 episodes
GETTING ACTION FROM:
action 1, numVisits=1140395, meanQ=4.971628, numObservations: 4
action 0, numVisits=76, meanQ=4.117424, numObservations: 1
action 3, numVisits=4, meanQ=-0.504975, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.460933 0.876419 0.537355 0.839573 0.518081 0.839238 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 161
Initial state: 0 0.558642 0.81109 0.572631 0.517626 0.620625 0.87071 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146690 episodes
GETTING ACTION FROM:
action 1, numVisits=1146591, meanQ=4.980117, numObservations: 3
action 0, numVisits=55, meanQ=3.971490, numObservations: 1
action -1, numVisits=41, meanQ=3.785976, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.558642 0.81109 0.572631 0.517626 0.620625 0.87071 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 162
Initial state: 0 0.726671 0.742261 0.502955 0.83615 0.598821 0.843026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125634 episodes
GETTING ACTION FROM:
action 3, numVisits=1125583, meanQ=4.923113, numObservations: 5
action 0, numVisits=47, meanQ=3.794314, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.726671 0.742261 0.502955 0.83615 0.598821 0.843026 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 163
Initial state: 0 0.678313 0.806533 0.524578 0.88491 0.499243 0.773681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 779742 episodes
GETTING ACTION FROM:
action 0, numVisits=779730, meanQ=2.924905, numObservations: 1
action -1, numVisits=4, meanQ=-2.502425, numObservations: 1
action 1, numVisits=5, meanQ=-2.603980, numObservations: 3
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.678313 0.806533 0.524578 0.88491 0.499243 0.773681 w: 1
Observation: 0 0 0.746593 0 0.890295 0 0.862165 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=774568, meanQ=4.996309, numObservations: 4
action 0, numVisits=5152, meanQ=2.729839, numObservations: 1
action 3, numVisits=5, meanQ=-0.201980, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1240131 episodes
GETTING ACTION FROM:
action 1, numVisits=2014699, meanQ=5.004002, numObservations: 4
action 0, numVisits=5152, meanQ=2.729839, numObservations: 1
action 3, numVisits=5, meanQ=-0.201980, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.678313 0.806533 0.524578 0.88491 0.499243 0.773681 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 164
Initial state: 0 0.663793 0.853223 0.00849849 0.250292 0.666375 0.870975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139698 episodes
GETTING ACTION FROM:
action 1, numVisits=1139686, meanQ=4.898821, numObservations: 4
action 3, numVisits=7, meanQ=0.428586, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.663793 0.853223 0.00849849 0.250292 0.666375 0.870975 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9706, meanQ=6.001974, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1346235 episodes
GETTING ACTION FROM:
action 1, numVisits=1355939, meanQ=4.892917, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.663793 0.853223 0.00849849 0.250292 0.666375 0.870975 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 165
Initial state: 0 0.579632 0.892927 0.528487 0.827546 0.0737146 0.0601044 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1126366 episodes
GETTING ACTION FROM:
action 1, numVisits=1126250, meanQ=4.913547, numObservations: 5
action -1, numVisits=111, meanQ=4.209363, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.579632 0.892927 0.528487 0.827546 0.0737146 0.0601044 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 166
Initial state: 0 0.646338 0.889721 0.970658 0.434439 0.600796 0.811607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142041 episodes
GETTING ACTION FROM:
action 2, numVisits=1142024, meanQ=4.990968, numObservations: 4
action 3, numVisits=11, meanQ=2.453636, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.646338 0.889721 0.970658 0.434439 0.600796 0.811607 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 167
Initial state: 0 0.533381 0.823652 0.633647 0.879295 0.40456 0.159536 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137072 episodes
GETTING ACTION FROM:
action 2, numVisits=1137014, meanQ=4.912080, numObservations: 5
action -1, numVisits=54, meanQ=3.859762, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.533381 0.823652 0.633647 0.879295 0.40456 0.159536 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 168
Initial state: 0 0.681328 0.831736 0.686409 0.888401 0.0722661 0.907879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129737 episodes
GETTING ACTION FROM:
action 3, numVisits=1128125, meanQ=4.973851, numObservations: 5
action -1, numVisits=789, meanQ=3.228602, numObservations: 1
action 0, numVisits=788, meanQ=3.228181, numObservations: 1
action 2, numVisits=30, meanQ=2.060677, numObservations: 4
action 1, numVisits=5, meanQ=-2.180000, numObservations: 1
action: 3
Next state: 0 0.681328 0.831736 0.686409 0.888401 0.0722661 0.907879 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=82174, meanQ=5.621600, numObservations: 3
action 0, numVisits=31, meanQ=4.413075, numObservations: 1
action 2, numVisits=14, meanQ=1.998579, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1345847 episodes
GETTING ACTION FROM:
action 3, numVisits=1428018, meanQ=5.204323, numObservations: 3
action 0, numVisits=34, meanQ=3.847215, numObservations: 1
action 2, numVisits=14, meanQ=1.998579, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.681328 0.831736 0.686409 0.888401 0.0722661 0.907879 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 169
Initial state: 0 0.632927 0.881329 0.504922 0.805766 0.511114 0.430795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1144682 episodes
GETTING ACTION FROM:
action 1, numVisits=1144676, meanQ=4.972875, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.632927 0.881329 0.504922 0.805766 0.511114 0.430795 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 170
Initial state: 0 0.684153 0.898761 0.524498 0.879265 0.345081 0.592778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138589 episodes
GETTING ACTION FROM:
action 3, numVisits=1138580, meanQ=4.925591, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.684153 0.898761 0.524498 0.879265 0.345081 0.592778 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=62719, meanQ=8.291427, numObservations: 4
action 1, numVisits=111774, meanQ=8.275934, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1423744 episodes
GETTING ACTION FROM:
action 1, numVisits=1245985, meanQ=6.379747, numObservations: 4
action 2, numVisits=352243, meanQ=6.373741, numObservations: 4
action 0, numVisits=6, meanQ=2.620000, numObservations: 1
action -1, numVisits=5, meanQ=1.762000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.684153 0.898761 0.524498 0.879265 0.345081 0.592778 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 171
Initial state: 0 0.6074 0.863476 0.549589 0.899703 0.963526 0.520588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1150395 episodes
GETTING ACTION FROM:
action 3, numVisits=1150288, meanQ=4.919738, numObservations: 3
action 0, numVisits=57, meanQ=3.915058, numObservations: 1
action -1, numVisits=41, meanQ=3.716065, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action: 3
Next state: 2 0.6074 0.863476 0.549589 0.899703 0.963526 0.520588 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 172
Initial state: 0 0.895018 0.213581 0.583328 0.885694 0.68551 0.813252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125341 episodes
GETTING ACTION FROM:
action 2, numVisits=1125261, meanQ=4.985683, numObservations: 5
action 0, numVisits=66, meanQ=4.058585, numObservations: 1
action 1, numVisits=11, meanQ=1.361818, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.895018 0.213581 0.583328 0.885694 0.68551 0.813252 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 173
Initial state: 0 0.588483 0.890761 0.60126 0.40825 0.528473 0.841405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1123602 episodes
GETTING ACTION FROM:
action 3, numVisits=1116349, meanQ=4.914256, numObservations: 5
action -1, numVisits=7237, meanQ=2.882552, numObservations: 1
action 2, numVisits=8, meanQ=0.748763, numObservations: 5
action 1, numVisits=6, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.588483 0.890761 0.60126 0.40825 0.528473 0.841405 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 174
Initial state: 0 0.60403 0.841911 0.854409 0.0197704 0.659166 0.896971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1143693 episodes
GETTING ACTION FROM:
action 1, numVisits=1140722, meanQ=4.963873, numObservations: 4
action 0, numVisits=2948, meanQ=2.782378, numObservations: 1
action 3, numVisits=20, meanQ=1.594500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.60403 0.841911 0.854409 0.0197704 0.659166 0.896971 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 175
Initial state: 0 0.645835 0.856149 0.592594 0.827312 0.495247 0.0186608 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134600 episodes
GETTING ACTION FROM:
action 2, numVisits=1134552, meanQ=4.921135, numObservations: 5
action -1, numVisits=43, meanQ=3.782491, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.645835 0.856149 0.592594 0.827312 0.495247 0.0186608 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 176
Initial state: 0 0.233595 0.792699 0.601329 0.878296 0.536809 0.888967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 806449 episodes
GETTING ACTION FROM:
action 0, numVisits=806444, meanQ=5.676319, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.233595 0.792699 0.601329 0.878296 0.536809 0.888967 w: 1
Observation: 0 0 0.725153 0 0.788167 0 0.956511 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=577049, meanQ=7.540513, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1234241 episodes
GETTING ACTION FROM:
action 1, numVisits=1811248, meanQ=5.928430, numObservations: 4
action 0, numVisits=42, meanQ=4.739017, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.233595 0.792699 0.601329 0.878296 0.536809 0.888967 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 177
Initial state: 0 0.662597 0.835753 0.600199 0.822497 0.970113 0.395734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 808047 episodes
GETTING ACTION FROM:
action 0, numVisits=807801, meanQ=5.501888, numObservations: 2
action -1, numVisits=241, meanQ=3.381502, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.662597 0.835753 0.600199 0.822497 0.970113 0.395734 w: 1
Observation: 0 0 0.933478 0 0.884581 0 0.441642 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=214790, meanQ=7.820174, numObservations: 4
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1245735 episodes
GETTING ACTION FROM:
action 2, numVisits=1460523, meanQ=5.618014, numObservations: 4
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.662597 0.835753 0.600199 0.822497 0.970113 0.395734 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 178
Initial state: 0 0.0727131 0.528372 0.559816 0.849705 0.659488 0.887848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1042378 episodes
GETTING ACTION FROM:
action 2, numVisits=1042368, meanQ=4.568774, numObservations: 5
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0727131 0.528372 0.559816 0.849705 0.659488 0.887848 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 179
Initial state: 0 0.530088 0.846288 0.65867 0.885931 0.490039 0.0483758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125917 episodes
GETTING ACTION FROM:
action 2, numVisits=1125887, meanQ=4.894928, numObservations: 5
action 3, numVisits=15, meanQ=2.465340, numObservations: 3
action 1, numVisits=11, meanQ=1.907282, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.530088 0.846288 0.65867 0.885931 0.490039 0.0483758 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 180
Initial state: 0 0.19406 0.438078 0.570252 0.873876 0.518722 0.866356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127264 episodes
GETTING ACTION FROM:
action 1, numVisits=1127258, meanQ=4.899850, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.19406 0.438078 0.570252 0.873876 0.518722 0.866356 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=110399, meanQ=8.533801, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1403221 episodes
GETTING ACTION FROM:
action 3, numVisits=1513617, meanQ=5.860803, numObservations: 5
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.19406 0.438078 0.570252 0.873876 0.518722 0.866356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 181
Initial state: 0 0.620283 0.823229 0.499106 0.145292 0.57104 0.84709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146154 episodes
GETTING ACTION FROM:
action 2, numVisits=1146118, meanQ=4.963165, numObservations: 4
action -1, numVisits=32, meanQ=3.627573, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.620283 0.823229 0.499106 0.145292 0.57104 0.84709 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 182
Initial state: 0 0.661424 0.817753 0.555456 0.822265 0.72483 0.866419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134742 episodes
GETTING ACTION FROM:
action 1, numVisits=1134728, meanQ=4.983343, numObservations: 5
action 2, numVisits=9, meanQ=2.333333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.661424 0.817753 0.555456 0.822265 0.72483 0.866419 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.294163 0.533493 0.527192 0.874246 0.646664 0.884728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124359 episodes
GETTING ACTION FROM:
action 2, numVisits=1124220, meanQ=4.900461, numObservations: 5
action 0, numVisits=104, meanQ=4.167275, numObservations: 1
action 1, numVisits=23, meanQ=2.730000, numObservations: 3
action 3, numVisits=10, meanQ=2.201010, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.294163 0.533493 0.527192 0.874246 0.646664 0.884728 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 184
Initial state: 0 0.556551 0.894223 0.60338 0.852249 0.627474 0.817489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137538 episodes
GETTING ACTION FROM:
action 3, numVisits=1137501, meanQ=4.901658, numObservations: 4
action -1, numVisits=33, meanQ=3.589563, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.556551 0.894223 0.60338 0.852249 0.627474 0.817489 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 185
Initial state: 0 0.680152 0.839329 0.586418 0.820813 0.543959 0.899938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1126601 episodes
GETTING ACTION FROM:
action 1, numVisits=1126588, meanQ=4.909859, numObservations: 5
action 3, numVisits=8, meanQ=1.987500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.680152 0.839329 0.586418 0.820813 0.543959 0.899938 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 186
Initial state: 0 0.662579 0.991427 0.645879 0.855231 0.677725 0.890834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134348 episodes
GETTING ACTION FROM:
action 2, numVisits=1134329, meanQ=4.979013, numObservations: 4
action 3, numVisits=13, meanQ=1.922315, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.662579 0.991427 0.645879 0.855231 0.677725 0.890834 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 187
Initial state: 0 0.588231 0.835945 0.612308 0.837381 0.823935 0.148228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128920 episodes
GETTING ACTION FROM:
action 2, numVisits=1128858, meanQ=4.980200, numObservations: 5
action 0, numVisits=58, meanQ=3.934475, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.588231 0.835945 0.612308 0.837381 0.823935 0.148228 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 188
Initial state: 0 0.552189 0.157493 0.609579 0.831331 0.669907 0.849869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142291 episodes
GETTING ACTION FROM:
action 3, numVisits=1142285, meanQ=4.970520, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.552189 0.157493 0.609579 0.831331 0.669907 0.849869 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=83673, meanQ=5.739263, numObservations: 4
action 2, numVisits=8, meanQ=1.500013, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1311029 episodes
GETTING ACTION FROM:
action 3, numVisits=1394698, meanQ=5.254488, numObservations: 5
action 2, numVisits=8, meanQ=1.500013, numObservations: 2
action 0, numVisits=4, meanQ=0.475000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.552189 0.157493 0.609579 0.831331 0.669907 0.849869 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 189
Initial state: 0 0.653373 0.849613 0.631372 0.816937 0.463942 0.627433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1150624 episodes
GETTING ACTION FROM:
action 2, numVisits=1141480, meanQ=4.984554, numObservations: 4
action 0, numVisits=9139, meanQ=2.966944, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.653373 0.849613 0.631372 0.816937 0.463942 0.627433 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 190
Initial state: 0 0.551909 0.895405 0.686124 0.862711 0.574187 0.313859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131220 episodes
GETTING ACTION FROM:
action 3, numVisits=1131207, meanQ=4.981879, numObservations: 5
action 1, numVisits=8, meanQ=1.485000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.551909 0.895405 0.686124 0.862711 0.574187 0.313859 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 191
Initial state: 0 0.688594 0.822496 0.765783 0.365954 0.656071 0.876718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1148172 episodes
GETTING ACTION FROM:
action 1, numVisits=1148161, meanQ=4.989186, numObservations: 4
action 3, numVisits=6, meanQ=1.331683, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.688594 0.822496 0.765783 0.365954 0.656071 0.876718 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 192
Initial state: 0 0.656865 0.819098 0.424924 0.683335 0.501659 0.830131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116771 episodes
GETTING ACTION FROM:
action 3, numVisits=1116764, meanQ=4.904169, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.656865 0.819098 0.424924 0.683335 0.501659 0.830131 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 193
Initial state: 0 0.468028 0.458786 0.545975 0.878373 0.642104 0.818239 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146016 episodes
GETTING ACTION FROM:
action 1, numVisits=1146008, meanQ=5.032513, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.468028 0.458786 0.545975 0.878373 0.642104 0.818239 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=174854, meanQ=8.302952, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1418391 episodes
GETTING ACTION FROM:
action 3, numVisits=1593243, meanQ=6.098500, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.468028 0.458786 0.545975 0.878373 0.642104 0.818239 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 194
Initial state: 0 0.541377 0.817894 0.796133 0.96344 0.611566 0.870866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131744 episodes
GETTING ACTION FROM:
action 2, numVisits=1131738, meanQ=4.995172, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.541377 0.817894 0.796133 0.96344 0.611566 0.870866 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 195
Initial state: 0 0.61634 0.812693 0.613166 0.870041 0.614623 0.165164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1157698 episodes
GETTING ACTION FROM:
action 2, numVisits=1157660, meanQ=4.981962, numObservations: 3
action -1, numVisits=33, meanQ=3.674904, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.61634 0.812693 0.613166 0.870041 0.614623 0.165164 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 196
Initial state: 0 0.639676 0.874942 0.0237817 0.205368 0.553477 0.884805 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1118882 episodes
GETTING ACTION FROM:
action 1, numVisits=1118781, meanQ=4.925524, numObservations: 5
action 2, numVisits=93, meanQ=3.023372, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.639676 0.874942 0.0237817 0.205368 0.553477 0.884805 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=81382, meanQ=4.548524, numObservations: 5
action 2, numVisits=12, meanQ=2.157508, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1383186 episodes
GETTING ACTION FROM:
action 3, numVisits=1464568, meanQ=5.745778, numObservations: 5
action 2, numVisits=12, meanQ=2.157508, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.639676 0.874942 0.0237817 0.205368 0.553477 0.884805 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 197
Initial state: 0 0.670372 0.842864 0.516964 0.830522 0.633591 0.977344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132121 episodes
GETTING ACTION FROM:
action 3, numVisits=1132080, meanQ=4.997729, numObservations: 5
action 1, numVisits=33, meanQ=3.653642, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.670372 0.842864 0.516964 0.830522 0.633591 0.977344 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 198
Initial state: 0 0.768393 0.388216 0.65599 0.864769 0.624601 0.882869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115970 episodes
GETTING ACTION FROM:
action 3, numVisits=1115962, meanQ=4.839674, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.768393 0.388216 0.65599 0.864769 0.624601 0.882869 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 199
Initial state: 0 0.646556 0.894947 0.0188406 0.0445024 0.643964 0.868529 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134409 episodes
GETTING ACTION FROM:
action 3, numVisits=1134316, meanQ=4.901898, numObservations: 4
action 0, numVisits=45, meanQ=3.785025, numObservations: 1
action -1, numVisits=40, meanQ=3.727853, numObservations: 1
action 2, numVisits=6, meanQ=1.331683, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 1 0.646556 0.894947 0.0188406 0.0445024 0.643964 0.868529 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 200
Initial state: 0 0.609847 0.866963 0.573613 0.889179 0.018772 0.504504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146035 episodes
GETTING ACTION FROM:
action 1, numVisits=1146014, meanQ=5.007633, numObservations: 4
action -1, numVisits=17, meanQ=3.081654, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.609847 0.866963 0.573613 0.889179 0.018772 0.504504 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 201
Initial state: 0 0.601002 0.871737 0.808421 0.999501 0.624828 0.870302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137682 episodes
GETTING ACTION FROM:
action 1, numVisits=1125608, meanQ=4.985094, numObservations: 4
action 0, numVisits=12066, meanQ=3.065692, numObservations: 1
action 2, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.601002 0.871737 0.808421 0.999501 0.624828 0.870302 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 202
Initial state: 0 0.507139 0.412996 0.502838 0.817881 0.508768 0.859264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1147423 episodes
GETTING ACTION FROM:
action 1, numVisits=1147255, meanQ=4.905612, numObservations: 3
action 2, numVisits=144, meanQ=4.269035, numObservations: 4
action 0, numVisits=20, meanQ=3.113927, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.507139 0.412996 0.502838 0.817881 0.508768 0.859264 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=175691, meanQ=8.284766, numObservations: 5
action 2, numVisits=16, meanQ=6.124381, numObservations: 1
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1397204 episodes
GETTING ACTION FROM:
action 3, numVisits=1572858, meanQ=6.183036, numObservations: 5
action 1, numVisits=33, meanQ=4.870000, numObservations: 3
action 2, numVisits=20, meanQ=4.099005, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.507139 0.412996 0.502838 0.817881 0.508768 0.859264 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 203
Initial state: 0 0.580767 0.816987 0.942013 0.701586 0.597374 0.809388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 778466 episodes
GETTING ACTION FROM:
action 0, numVisits=776637, meanQ=2.976465, numObservations: 1
action -1, numVisits=1811, meanQ=2.766512, numObservations: 1
action 1, numVisits=10, meanQ=0.598000, numObservations: 2
action 2, numVisits=6, meanQ=-1.670000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 0
Next state: 0 0.580767 0.816987 0.942013 0.701586 0.597374 0.809388 w: 1
Observation: 0 0 0.72476 0 0.685922 0 0.762708 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=776535, meanQ=5.028963, numObservations: 5
action 0, numVisits=68, meanQ=4.133176, numObservations: 1
action -1, numVisits=28, meanQ=3.601561, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1228888 episodes
GETTING ACTION FROM:
action 2, numVisits=2005423, meanQ=5.052303, numObservations: 5
action 0, numVisits=68, meanQ=4.133176, numObservations: 1
action -1, numVisits=28, meanQ=3.601561, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.580767 0.816987 0.942013 0.701586 0.597374 0.809388 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 204
Initial state: 0 0.616717 0.848275 0.612158 0.857015 0.494297 0.684978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125171 episodes
GETTING ACTION FROM:
action 1, numVisits=1118005, meanQ=4.979272, numObservations: 5
action -1, numVisits=7157, meanQ=2.878443, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.616717 0.848275 0.612158 0.857015 0.494297 0.684978 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 205
Initial state: 0 0.526466 0.807991 0.586471 0.81896 0.600939 0.0171452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129439 episodes
GETTING ACTION FROM:
action 1, numVisits=1129396, meanQ=4.967748, numObservations: 5
action 0, numVisits=39, meanQ=3.761952, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.526466 0.807991 0.586471 0.81896 0.600939 0.0171452 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 206
Initial state: 0 0.58701 0.83277 0.533564 0.817734 0.052205 0.423694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138019 episodes
GETTING ACTION FROM:
action 1, numVisits=1137866, meanQ=5.004887, numObservations: 5
action -1, numVisits=119, meanQ=4.317615, numObservations: 1
action 3, numVisits=25, meanQ=3.235616, numObservations: 4
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.58701 0.83277 0.533564 0.817734 0.052205 0.423694 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 207
Initial state: 0 0.547952 0.824689 0.583951 0.88007 0.585445 0.387046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108377 episodes
GETTING ACTION FROM:
action 1, numVisits=1102165, meanQ=4.983274, numObservations: 4
action 0, numVisits=6201, meanQ=2.825705, numObservations: 1
action 3, numVisits=8, meanQ=-0.249975, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.547952 0.824689 0.583951 0.88007 0.585445 0.387046 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 208
Initial state: 0 0.458256 0.225696 0.518214 0.826329 0.681985 0.883654 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1149995 episodes
GETTING ACTION FROM:
action 2, numVisits=1119664, meanQ=4.921785, numObservations: 3
action 1, numVisits=29081, meanQ=4.817058, numObservations: 5
action 3, numVisits=1246, meanQ=4.706058, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.458256 0.225696 0.518214 0.826329 0.681985 0.883654 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=9725, meanQ=6.105226, numObservations: 3
action 3, numVisits=9, meanQ=2.553344, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1338143 episodes
GETTING ACTION FROM:
action 2, numVisits=1347864, meanQ=5.071838, numObservations: 4
action 3, numVisits=9, meanQ=2.553344, numObservations: 3
action -1, numVisits=4, meanQ=0.475000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.458256 0.225696 0.518214 0.826329 0.681985 0.883654 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 209
Initial state: 0 0.61688 0.81908 0.591397 0.831012 0.986447 0.228833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1136346 episodes
GETTING ACTION FROM:
action 2, numVisits=1136323, meanQ=4.982691, numObservations: 5
action -1, numVisits=19, meanQ=3.232949, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.61688 0.81908 0.591397 0.831012 0.986447 0.228833 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=83641, meanQ=5.559165, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1344537 episodes
GETTING ACTION FROM:
action 2, numVisits=1428178, meanQ=4.956691, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.61688 0.81908 0.591397 0.831012 0.986447 0.228833 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 210
Initial state: 0 0.57635 0.844052 0.0756907 0.028642 0.5348 0.852853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1143690 episodes
GETTING ACTION FROM:
action 1, numVisits=1143503, meanQ=5.117899, numObservations: 4
action 3, numVisits=179, meanQ=4.505818, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=4, meanQ=-2.005000, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.57635 0.844052 0.0756907 0.028642 0.5348 0.852853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 211
Initial state: 0 0.585407 0.828186 0.0738614 0.953203 0.541567 0.840683 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1144312 episodes
GETTING ACTION FROM:
action 3, numVisits=1144305, meanQ=4.979367, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.585407 0.828186 0.0738614 0.953203 0.541567 0.840683 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 212
Initial state: 0 0.359253 0.453287 0.609464 0.848257 0.685894 0.877012 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1141331 episodes
GETTING ACTION FROM:
action 1, numVisits=1141286, meanQ=5.120572, numObservations: 4
action -1, numVisits=25, meanQ=3.583562, numObservations: 1
action 3, numVisits=17, meanQ=2.652353, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.359253 0.453287 0.609464 0.848257 0.685894 0.877012 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=111395, meanQ=8.542854, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1435817 episodes
GETTING ACTION FROM:
action 2, numVisits=1547208, meanQ=6.119903, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 3, numVisits=3, meanQ=-0.329967, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.359253 0.453287 0.609464 0.848257 0.685894 0.877012 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 213
Initial state: 0 0.52398 0.814722 0.600442 0.875505 0.663448 0.285853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125816 episodes
GETTING ACTION FROM:
action 1, numVisits=1125411, meanQ=4.982400, numObservations: 5
action 2, numVisits=400, meanQ=4.607739, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.52398 0.814722 0.600442 0.875505 0.663448 0.285853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 214
Initial state: 0 0.516733 0.844867 0.644694 0.817579 0.221619 0.894327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095540 episodes
GETTING ACTION FROM:
action 1, numVisits=1095524, meanQ=4.841016, numObservations: 5
action 3, numVisits=9, meanQ=-0.556656, numObservations: 4
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.516733 0.844867 0.644694 0.817579 0.221619 0.894327 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 215
Initial state: 0 0.402088 0.646795 0.565851 0.836089 0.569846 0.856538 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127286 episodes
GETTING ACTION FROM:
action 1, numVisits=1127261, meanQ=4.963557, numObservations: 5
action -1, numVisits=20, meanQ=3.169187, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.402088 0.646795 0.565851 0.836089 0.569846 0.856538 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=142925, meanQ=8.392507, numObservations: 4
action 2, numVisits=8, meanQ=4.247513, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1427358 episodes
GETTING ACTION FROM:
action 3, numVisits=1570272, meanQ=5.889445, numObservations: 4
action 2, numVisits=17, meanQ=3.234124, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.402088 0.646795 0.565851 0.836089 0.569846 0.856538 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=34954, meanQ=7.567508, numObservations: 4
action 3, numVisits=2251, meanQ=7.474234, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1476028 episodes
GETTING ACTION FROM:
action 2, numVisits=1505865, meanQ=6.056764, numObservations: 4
action 3, numVisits=7366, meanQ=5.974017, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.402088 0.646795 0.565851 0.836089 0.569846 0.856538 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 216
Initial state: 0 0.506352 0.815606 0.642213 0.854623 0.134127 0.591476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130115 episodes
GETTING ACTION FROM:
action 3, numVisits=1130025, meanQ=4.985122, numObservations: 5
action 0, numVisits=58, meanQ=3.985138, numObservations: 1
action -1, numVisits=30, meanQ=3.603032, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.506352 0.815606 0.642213 0.854623 0.134127 0.591476 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=143038, meanQ=8.378058, numObservations: 4
action 2, numVisits=16, meanQ=5.737500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1430134 episodes
GETTING ACTION FROM:
action 1, numVisits=1573027, meanQ=5.880000, numObservations: 4
action 2, numVisits=159, meanQ=5.199435, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.506352 0.815606 0.642213 0.854623 0.134127 0.591476 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 217
Initial state: 0 0.599665 0.807215 0.556296 0.855284 0.991958 0.259065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146658 episodes
GETTING ACTION FROM:
action 2, numVisits=982462, meanQ=4.968971, numObservations: 4
action 1, numVisits=164112, meanQ=4.896778, numObservations: 4
action -1, numVisits=81, meanQ=4.134970, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.599665 0.807215 0.556296 0.855284 0.991958 0.259065 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 218
Initial state: 0 0.413272 0.466048 0.601243 0.861368 0.621309 0.886843 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138225 episodes
GETTING ACTION FROM:
action 1, numVisits=1138063, meanQ=4.946185, numObservations: 4
action 0, numVisits=153, meanQ=4.335406, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.413272 0.466048 0.601243 0.861368 0.621309 0.886843 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 219
Initial state: 0 0.583936 0.886862 0.590663 0.824761 0.265089 0.874136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120213 episodes
GETTING ACTION FROM:
action 2, numVisits=1120205, meanQ=4.924437, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.583936 0.886862 0.590663 0.824761 0.265089 0.874136 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 220
Initial state: 0 0.514565 0.804116 0.122331 0.640407 0.551491 0.815482 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125767 episodes
GETTING ACTION FROM:
action 2, numVisits=1125753, meanQ=4.909404, numObservations: 5
action 1, numVisits=9, meanQ=0.998889, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.514565 0.804116 0.122331 0.640407 0.551491 0.815482 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=29474, meanQ=7.840154, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1429233 episodes
GETTING ACTION FROM:
action 3, numVisits=1458688, meanQ=5.594637, numObservations: 4
action 1, numVisits=19, meanQ=3.525263, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.514565 0.804116 0.122331 0.640407 0.551491 0.815482 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=28229, meanQ=6.923069, numObservations: 5
action 3, numVisits=15, meanQ=5.260000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1451983 episodes
GETTING ACTION FROM:
action 1, numVisits=1480110, meanQ=5.861804, numObservations: 5
action 3, numVisits=115, meanQ=5.138349, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.514565 0.804116 0.122331 0.640407 0.551491 0.815482 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 221
Initial state: 0 0.346734 0.377699 0.655745 0.878515 0.682486 0.861078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124183 episodes
GETTING ACTION FROM:
action 3, numVisits=1124065, meanQ=4.970523, numObservations: 5
action 0, numVisits=82, meanQ=4.144212, numObservations: 1
action -1, numVisits=30, meanQ=3.501456, numObservations: 1
action 1, numVisits=5, meanQ=0.196000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.346734 0.377699 0.655745 0.878515 0.682486 0.861078 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 222
Initial state: 0 0.110586 0.577232 0.613235 0.849337 0.663005 0.877021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130564 episodes
GETTING ACTION FROM:
action 3, numVisits=1130420, meanQ=4.972635, numObservations: 5
action -1, numVisits=110, meanQ=4.264050, numObservations: 1
action 0, numVisits=28, meanQ=3.549083, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.110586 0.577232 0.613235 0.849337 0.663005 0.877021 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 223
Initial state: 0 0.833458 0.319409 0.532488 0.807251 0.690775 0.813641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124683 episodes
GETTING ACTION FROM:
action 3, numVisits=1124662, meanQ=4.982919, numObservations: 5
action 2, numVisits=16, meanQ=2.630631, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.833458 0.319409 0.532488 0.807251 0.690775 0.813641 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=79502, meanQ=5.505911, numObservations: 4
action -1, numVisits=1856, meanQ=2.365761, numObservations: 1
action 0, numVisits=79, meanQ=1.792390, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
Sampled 1328817 episodes
GETTING ACTION FROM:
action 3, numVisits=1408319, meanQ=5.068279, numObservations: 4
action -1, numVisits=1856, meanQ=2.365761, numObservations: 1
action 0, numVisits=79, meanQ=1.792390, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 1 0.833458 0.319409 0.532488 0.807251 0.690775 0.813641 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 224
Initial state: 0 0.330836 0.0114305 0.611537 0.801063 0.532823 0.876026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139922 episodes
GETTING ACTION FROM:
action 1, numVisits=1132565, meanQ=4.989248, numObservations: 4
action -1, numVisits=7353, meanQ=2.888149, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.330836 0.0114305 0.611537 0.801063 0.532823 0.876026 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=143674, meanQ=8.391984, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1428402 episodes
GETTING ACTION FROM:
action 2, numVisits=1572071, meanQ=5.846587, numObservations: 4
action 0, numVisits=5, meanQ=1.762000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.330836 0.0114305 0.611537 0.801063 0.532823 0.876026 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 225
Initial state: 0 0.689586 0.840577 0.547582 0.880034 0.780379 0.802205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134036 episodes
GETTING ACTION FROM:
action 3, numVisits=1133917, meanQ=4.995067, numObservations: 4
action -1, numVisits=111, meanQ=4.287480, numObservations: 1
action 1, numVisits=4, meanQ=-0.999975, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.689586 0.840577 0.547582 0.880034 0.780379 0.802205 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 226
Initial state: 0 0.625041 0.811365 0.696094 0.838872 0.241518 0.967602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127275 episodes
GETTING ACTION FROM:
action 3, numVisits=1127221, meanQ=4.958133, numObservations: 4
action -1, numVisits=50, meanQ=3.898803, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.625041 0.811365 0.696094 0.838872 0.241518 0.967602 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=82650, meanQ=5.335514, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1307030 episodes
GETTING ACTION FROM:
action 3, numVisits=1389680, meanQ=4.791904, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.625041 0.811365 0.696094 0.838872 0.241518 0.967602 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=29798, meanQ=4.116229, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1454622 episodes
GETTING ACTION FROM:
action 2, numVisits=1430850, meanQ=6.302702, numObservations: 4
action -1, numVisits=53570, meanQ=1.857456, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.625041 0.811365 0.696094 0.838872 0.241518 0.967602 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=3985, meanQ=8.219557, numObservations: 5
action 3, numVisits=27, meanQ=4.669259, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1454851 episodes
GETTING ACTION FROM:
action 1, numVisits=1458751, meanQ=5.761833, numObservations: 5
action 3, numVisits=110, meanQ=4.990727, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.625041 0.811365 0.696094 0.838872 0.241518 0.967602 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 227
Initial state: 0 0.652827 0.81827 0.554082 0.843644 0.506651 0.462799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128851 episodes
GETTING ACTION FROM:
action 2, numVisits=1128808, meanQ=5.008103, numObservations: 5
action 0, numVisits=39, meanQ=3.782249, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.652827 0.81827 0.554082 0.843644 0.506651 0.462799 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 228
Initial state: 0 0.623257 0.824902 0.655409 0.873691 0.500767 0.741592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 779090 episodes
GETTING ACTION FROM:
action -1, numVisits=779084, meanQ=2.926393, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.623257 0.824902 0.655409 0.873691 0.500767 0.741592 w: 1
Observation: 0 0.639237 0 0.603806 0 0.508679 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=779026, meanQ=4.978448, numObservations: 5
action -1, numVisits=53, meanQ=3.971811, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1230448 episodes
GETTING ACTION FROM:
action 3, numVisits=2009470, meanQ=4.833700, numObservations: 5
action -1, numVisits=57, meanQ=3.774841, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.623257 0.824902 0.655409 0.873691 0.500767 0.741592 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=111351, meanQ=7.919796, numObservations: 4
action 1, numVisits=7, meanQ=4.427143, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1436512 episodes
GETTING ACTION FROM:
action 2, numVisits=1547860, meanQ=6.160112, numObservations: 4
action 1, numVisits=8, meanQ=2.498750, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.623257 0.824902 0.655409 0.873691 0.500767 0.741592 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 229
Initial state: 0 0.159176 0.00526801 0.664321 0.879588 0.536018 0.833679 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133240 episodes
GETTING ACTION FROM:
action 2, numVisits=1133181, meanQ=4.993334, numObservations: 5
action 3, numVisits=54, meanQ=3.242039, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.159176 0.00526801 0.664321 0.879588 0.536018 0.833679 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 230
Initial state: 0 0.32079 0.279852 0.639824 0.89438 0.523266 0.833193 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1150055 episodes
GETTING ACTION FROM:
action 2, numVisits=1150040, meanQ=4.964451, numObservations: 3
action 1, numVisits=10, meanQ=2.201010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.32079 0.279852 0.639824 0.89438 0.523266 0.833193 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 231
Initial state: 0 0.603223 0.871943 0.623819 0.855843 0.971358 0.292831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133069 episodes
GETTING ACTION FROM:
action 1, numVisits=1132888, meanQ=4.972410, numObservations: 4
action 0, numVisits=138, meanQ=4.140549, numObservations: 1
action -1, numVisits=36, meanQ=3.664680, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.603223 0.871943 0.623819 0.855843 0.971358 0.292831 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 232
Initial state: 0 0.580209 0.89986 0.329106 0.636737 0.58514 0.857945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1141405 episodes
GETTING ACTION FROM:
action 2, numVisits=1141329, meanQ=5.101075, numObservations: 4
action -1, numVisits=47, meanQ=4.015629, numObservations: 1
action 0, numVisits=24, meanQ=3.575844, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.580209 0.89986 0.329106 0.636737 0.58514 0.857945 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=111515, meanQ=8.541737, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1434407 episodes
GETTING ACTION FROM:
action 1, numVisits=1545920, meanQ=6.257487, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.580209 0.89986 0.329106 0.636737 0.58514 0.857945 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 233
Initial state: 0 0.596348 0.837034 0.296629 0.619021 0.636213 0.822331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138872 episodes
GETTING ACTION FROM:
action 2, numVisits=1135382, meanQ=4.978440, numObservations: 5
action 0, numVisits=3374, meanQ=2.603969, numObservations: 1
action -1, numVisits=112, meanQ=2.162446, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.596348 0.837034 0.296629 0.619021 0.636213 0.822331 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=143485, meanQ=8.396078, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1443953 episodes
GETTING ACTION FROM:
action 3, numVisits=1587436, meanQ=6.152083, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.596348 0.837034 0.296629 0.619021 0.636213 0.822331 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=23465, meanQ=8.235817, numObservations: 5
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1448529 episodes
GETTING ACTION FROM:
action 1, numVisits=1471870, meanQ=5.786852, numObservations: 5
action 2, numVisits=122, meanQ=5.014755, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.596348 0.837034 0.296629 0.619021 0.636213 0.822331 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 234
Initial state: 0 0.594819 0.808016 0.320114 0.746992 0.647524 0.825859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142528 episodes
GETTING ACTION FROM:
action 3, numVisits=1142367, meanQ=4.897608, numObservations: 3
action 0, numVisits=129, meanQ=4.234271, numObservations: 1
action -1, numVisits=21, meanQ=3.260921, numObservations: 1
action 2, numVisits=10, meanQ=2.399010, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.594819 0.808016 0.320114 0.746992 0.647524 0.825859 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 235
Initial state: 0 0.558018 0.877269 0.691638 0.879742 0.562703 0.980927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130022 episodes
GETTING ACTION FROM:
action 3, numVisits=1130013, meanQ=4.920862, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.558018 0.877269 0.691638 0.879742 0.562703 0.980927 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 236
Initial state: 0 0.505549 0.630345 0.56063 0.824746 0.66981 0.874203 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133240 episodes
GETTING ACTION FROM:
action 2, numVisits=1133204, meanQ=4.990161, numObservations: 4
action 3, numVisits=27, meanQ=3.147411, numObservations: 4
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.505549 0.630345 0.56063 0.824746 0.66981 0.874203 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 237
Initial state: 0 0.615852 0.810214 0.649098 0.834093 0.679272 0.117217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145341 episodes
GETTING ACTION FROM:
action 3, numVisits=1145230, meanQ=4.984391, numObservations: 4
action -1, numVisits=102, meanQ=4.239150, numObservations: 1
action 1, numVisits=6, meanQ=1.331683, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.615852 0.810214 0.649098 0.834093 0.679272 0.117217 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=62875, meanQ=7.849305, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1431378 episodes
GETTING ACTION FROM:
action 2, numVisits=1494251, meanQ=5.953141, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.615852 0.810214 0.649098 0.834093 0.679272 0.117217 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 238
Initial state: 0 0.657581 0.20946 0.585049 0.857056 0.52364 0.888688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1147919 episodes
GETTING ACTION FROM:
action 2, numVisits=1145099, meanQ=4.904563, numObservations: 4
action 1, numVisits=2763, meanQ=4.761740, numObservations: 4
action -1, numVisits=54, meanQ=3.885742, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.657581 0.20946 0.585049 0.857056 0.52364 0.888688 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 239
Initial state: 0 0.415293 0.0963117 0.563431 0.857788 0.638825 0.881981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129206 episodes
GETTING ACTION FROM:
action 3, numVisits=1127444, meanQ=4.977604, numObservations: 4
action 2, numVisits=1748, meanQ=4.791221, numObservations: 4
action 1, numVisits=10, meanQ=1.799000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.415293 0.0963117 0.563431 0.857788 0.638825 0.881981 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 240
Initial state: 0 0.614208 0.85892 0.584583 0.260388 0.643405 0.846385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132923 episodes
GETTING ACTION FROM:
action 3, numVisits=1132917, meanQ=4.973446, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.614208 0.85892 0.584583 0.260388 0.643405 0.846385 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 241
Initial state: 0 0.525538 0.836681 0.186386 0.21685 0.631772 0.842731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113743 episodes
GETTING ACTION FROM:
action 1, numVisits=1113737, meanQ=4.766762, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.525538 0.836681 0.186386 0.21685 0.631772 0.842731 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 242
Initial state: 0 0.0669212 0.677918 0.538294 0.81023 0.575387 0.873061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146447 episodes
GETTING ACTION FROM:
action 3, numVisits=1146301, meanQ=4.889093, numObservations: 3
action -1, numVisits=86, meanQ=4.083811, numObservations: 1
action 1, numVisits=57, meanQ=3.838604, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0669212 0.677918 0.538294 0.81023 0.575387 0.873061 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 243
Initial state: 0 0.678121 0.801727 0.604181 0.81914 0.0781034 0.724302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1136713 episodes
GETTING ACTION FROM:
action 1, numVisits=1136691, meanQ=4.929263, numObservations: 4
action 3, numVisits=14, meanQ=2.150000, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.678121 0.801727 0.604181 0.81914 0.0781034 0.724302 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 244
Initial state: 0 0.536975 0.893933 0.0106381 0.662398 0.537748 0.828934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129426 episodes
GETTING ACTION FROM:
action 2, numVisits=1129382, meanQ=4.988941, numObservations: 5
action 0, numVisits=35, meanQ=3.668732, numObservations: 1
action 3, numVisits=6, meanQ=1.331683, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.536975 0.893933 0.0106381 0.662398 0.537748 0.828934 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=142754, meanQ=8.397498, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1413304 episodes
GETTING ACTION FROM:
action 3, numVisits=1556056, meanQ=6.268994, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.536975 0.893933 0.0106381 0.662398 0.537748 0.828934 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 245
Initial state: 0 0.547794 0.860461 0.83114 0.305597 0.648609 0.84208 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134933 episodes
GETTING ACTION FROM:
action 2, numVisits=1130841, meanQ=4.898706, numObservations: 5
action -1, numVisits=4086, meanQ=2.667535, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.547794 0.860461 0.83114 0.305597 0.648609 0.84208 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 246
Initial state: 0 0.245843 0.742831 0.592105 0.888731 0.696919 0.856595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146644 episodes
GETTING ACTION FROM:
action 3, numVisits=1146572, meanQ=4.997142, numObservations: 4
action -1, numVisits=42, meanQ=3.822952, numObservations: 1
action 0, numVisits=25, meanQ=3.425566, numObservations: 1
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 1 0.245843 0.742831 0.592105 0.888731 0.696919 0.856595 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 247
Initial state: 0 0.570904 0.827922 0.674727 0.89091 0.343967 0.615702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1123198 episodes
GETTING ACTION FROM:
action 1, numVisits=1123125, meanQ=4.891827, numObservations: 5
action 0, numVisits=69, meanQ=3.992989, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.570904 0.827922 0.674727 0.89091 0.343967 0.615702 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 248
Initial state: 0 0.648913 0.838007 0.319706 0.107134 0.513505 0.815423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1141758 episodes
GETTING ACTION FROM:
action 2, numVisits=631400, meanQ=4.995688, numObservations: 4
action 3, numVisits=510330, meanQ=4.973197, numObservations: 5
action -1, numVisits=25, meanQ=3.433253, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.648913 0.838007 0.319706 0.107134 0.513505 0.815423 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=97099, meanQ=8.286785, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1452230 episodes
GETTING ACTION FROM:
action 1, numVisits=1549326, meanQ=6.051154, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.648913 0.838007 0.319706 0.107134 0.513505 0.815423 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 249
Initial state: 0 0.584391 0.87899 0.699131 0.84161 0.785721 0.591881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133785 episodes
GETTING ACTION FROM:
action 2, numVisits=1133779, meanQ=4.889687, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.584391 0.87899 0.699131 0.84161 0.785721 0.591881 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 250
Initial state: 0 0.5099 0.179743 0.634772 0.817609 0.698455 0.863859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088108 episodes
GETTING ACTION FROM:
action 3, numVisits=1088062, meanQ=4.846433, numObservations: 5
action 2, numVisits=41, meanQ=1.922449, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.5099 0.179743 0.634772 0.817609 0.698455 0.863859 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 251
Initial state: 0 0.506824 0.885559 0.547571 0.803832 0.27693 0.017244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139785 episodes
GETTING ACTION FROM:
action 3, numVisits=1139779, meanQ=4.981644, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.506824 0.885559 0.547571 0.803832 0.27693 0.017244 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=174368, meanQ=8.295594, numObservations: 3
action 1, numVisits=5, meanQ=3.798020, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1454104 episodes
GETTING ACTION FROM:
action 2, numVisits=1620583, meanQ=5.814249, numObservations: 3
action 1, numVisits=7892, meanQ=5.734317, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.506824 0.885559 0.547571 0.803832 0.27693 0.017244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 252
Initial state: 0 0.512197 0.805668 0.902809 0.587145 0.542003 0.892276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 785031 episodes
GETTING ACTION FROM:
action -1, numVisits=785018, meanQ=2.907593, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=4, meanQ=-2.502475, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: -1
Next state: 0 0.512197 0.805668 0.902809 0.587145 0.542003 0.892276 w: 1
Observation: 0 0.46102 0 0.81704 0 0.546907 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=785007, meanQ=4.975123, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 1242940 episodes
GETTING ACTION FROM:
action 3, numVisits=2027947, meanQ=4.946334, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.512197 0.805668 0.902809 0.587145 0.542003 0.892276 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 253
Initial state: 0 0.695837 0.849243 0.608511 0.889198 0.511779 0.645954 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1149194 episodes
GETTING ACTION FROM:
action 1, numVisits=1149179, meanQ=4.923196, numObservations: 3
action -1, numVisits=11, meanQ=2.590000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.695837 0.849243 0.608511 0.889198 0.511779 0.645954 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 254
Initial state: 0 0.689664 0.830957 0.759007 0.0607323 0.608017 0.894721 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137114 episodes
GETTING ACTION FROM:
action 3, numVisits=1136576, meanQ=4.924009, numObservations: 4
action 1, numVisits=408, meanQ=4.529085, numObservations: 5
action -1, numVisits=78, meanQ=4.073594, numObservations: 1
action 0, numVisits=50, meanQ=3.849006, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 1 0.689664 0.830957 0.759007 0.0607323 0.608017 0.894721 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 255
Initial state: 0 0.688281 0.817844 0.560494 0.878689 0.0526591 0.0540141 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131719 episodes
GETTING ACTION FROM:
action 1, numVisits=1131712, meanQ=4.975783, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.688281 0.817844 0.560494 0.878689 0.0526591 0.0540141 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=82396, meanQ=5.620132, numObservations: 3
action -1, numVisits=89, meanQ=4.924964, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1352469 episodes
GETTING ACTION FROM:
action 1, numVisits=1434854, meanQ=5.053373, numObservations: 3
action -1, numVisits=100, meanQ=4.289397, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.688281 0.817844 0.560494 0.878689 0.0526591 0.0540141 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=5461, meanQ=6.775135, numObservations: 4
action 3, numVisits=24031, meanQ=6.217263, numObservations: 3
action 1, numVisits=4, meanQ=2.497525, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1464499 episodes
GETTING ACTION FROM:
action 3, numVisits=1420866, meanQ=5.949674, numObservations: 3
action 2, numVisits=73122, meanQ=5.924966, numObservations: 4
action 1, numVisits=5, meanQ=1.396020, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 0 0.688281 0.817844 0.560494 0.878689 0.0526591 0.0540141 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=4932, meanQ=8.295975, numObservations: 3
action 1, numVisits=34, meanQ=7.116771, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1472568 episodes
GETTING ACTION FROM:
action 1, numVisits=1442025, meanQ=6.043202, numObservations: 4
action 2, numVisits=35507, meanQ=5.990011, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.688281 0.817844 0.560494 0.878689 0.0526591 0.0540141 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 256
Initial state: 0 0.522968 0.857341 0.626404 0.240284 0.569891 0.818048 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1144370 episodes
GETTING ACTION FROM:
action 2, numVisits=1144329, meanQ=4.991170, numObservations: 4
action 0, numVisits=36, meanQ=3.683717, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.522968 0.857341 0.626404 0.240284 0.569891 0.818048 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 257
Initial state: 0 0.644871 0.804552 0.610726 0.84354 0.4533 0.782975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127107 episodes
GETTING ACTION FROM:
action 3, numVisits=1121121, meanQ=4.905131, numObservations: 5
action 0, numVisits=5981, meanQ=2.811927, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.644871 0.804552 0.610726 0.84354 0.4533 0.782975 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=141646, meanQ=8.395141, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1456684 episodes
GETTING ACTION FROM:
action 2, numVisits=1598328, meanQ=5.868578, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.644871 0.804552 0.610726 0.84354 0.4533 0.782975 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 258
Initial state: 0 0.553274 0.895575 0.0217633 0.867178 0.553688 0.898386 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1140441 episodes
GETTING ACTION FROM:
action 3, numVisits=1140431, meanQ=4.975263, numObservations: 4
action 1, numVisits=5, meanQ=-1.402000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.553274 0.895575 0.0217633 0.867178 0.553688 0.898386 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 259
Initial state: 0 0.573801 0.851597 0.469398 0.18806 0.54793 0.813879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1144880 episodes
GETTING ACTION FROM:
action 1, numVisits=1144874, meanQ=4.957791, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.573801 0.851597 0.469398 0.18806 0.54793 0.813879 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 260
Initial state: 0 0.962607 0.0486022 0.541653 0.834237 0.570213 0.891444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142246 episodes
GETTING ACTION FROM:
action 2, numVisits=1142217, meanQ=4.976173, numObservations: 4
action 1, numVisits=24, meanQ=2.999167, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.962607 0.0486022 0.541653 0.834237 0.570213 0.891444 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 261
Initial state: 0 0.322591 0.158198 0.614937 0.814632 0.501301 0.831928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109046 episodes
GETTING ACTION FROM:
action 1, numVisits=1108929, meanQ=4.975651, numObservations: 4
action -1, numVisits=113, meanQ=1.677685, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.322591 0.158198 0.614937 0.814632 0.501301 0.831928 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=108099, meanQ=8.540267, numObservations: 3
action 2, numVisits=11, meanQ=5.724545, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1436902 episodes
GETTING ACTION FROM:
action 2, numVisits=928440, meanQ=6.161880, numObservations: 3
action 3, numVisits=616567, meanQ=6.143422, numObservations: 5
action -1, numVisits=5, meanQ=1.762000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.322591 0.158198 0.614937 0.814632 0.501301 0.831928 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 262
Initial state: 0 0.596998 0.81104 0.915625 0.0487208 0.677743 0.804655 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105599 episodes
GETTING ACTION FROM:
action 2, numVisits=1105592, meanQ=4.821739, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.596998 0.81104 0.915625 0.0487208 0.677743 0.804655 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 263
Initial state: 0 0.641078 0.891881 0.693488 0.898075 0.354069 0.735211 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1073814 episodes
GETTING ACTION FROM:
action 3, numVisits=1073789, meanQ=4.700059, numObservations: 5
action 2, numVisits=20, meanQ=1.300010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.641078 0.891881 0.693488 0.898075 0.354069 0.735211 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=58893, meanQ=7.825114, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1437100 episodes
GETTING ACTION FROM:
action 2, numVisits=1495991, meanQ=6.090415, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.641078 0.891881 0.693488 0.898075 0.354069 0.735211 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 264
Initial state: 0 0.552077 0.89713 0.843336 0.103912 0.548639 0.803898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1155223 episodes
GETTING ACTION FROM:
action 1, numVisits=1155066, meanQ=4.986142, numObservations: 3
action -1, numVisits=74, meanQ=4.122194, numObservations: 1
action 3, numVisits=50, meanQ=3.795808, numObservations: 4
action 0, numVisits=32, meanQ=3.620499, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.552077 0.89713 0.843336 0.103912 0.548639 0.803898 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 265
Initial state: 0 0.673315 0.862828 0.62764 0.888621 0.5439 0.826655 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128382 episodes
GETTING ACTION FROM:
action 1, numVisits=1128375, meanQ=4.907544, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.673315 0.862828 0.62764 0.888621 0.5439 0.826655 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 266
Initial state: 0 0.8153 0.785438 0.698692 0.824492 0.652104 0.87796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142020 episodes
GETTING ACTION FROM:
action 2, numVisits=1135019, meanQ=4.973435, numObservations: 4
action -1, numVisits=6996, meanQ=2.869888, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.8153 0.785438 0.698692 0.824492 0.652104 0.87796 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 267
Initial state: 0 0.365843 0.548031 0.546789 0.828583 0.600233 0.802274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138410 episodes
GETTING ACTION FROM:
action 2, numVisits=1138399, meanQ=4.976154, numObservations: 4
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.365843 0.548031 0.546789 0.828583 0.600233 0.802274 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 268
Initial state: 0 0.499171 0.491406 0.515742 0.803048 0.660439 0.892408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1149141 episodes
GETTING ACTION FROM:
action 1, numVisits=1149134, meanQ=4.986490, numObservations: 3
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.499171 0.491406 0.515742 0.803048 0.660439 0.892408 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=171642, meanQ=8.294171, numObservations: 4
action 3, numVisits=4446, meanQ=8.205785, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1438581 episodes
GETTING ACTION FROM:
action 2, numVisits=1594589, meanQ=6.283096, numObservations: 4
action 3, numVisits=20078, meanQ=6.235320, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.499171 0.491406 0.515742 0.803048 0.660439 0.892408 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 269
Initial state: 0 0.230988 0.354586 0.671467 0.870932 0.637076 0.833731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146995 episodes
GETTING ACTION FROM:
action 1, numVisits=1146971, meanQ=4.994513, numObservations: 4
action 3, numVisits=19, meanQ=3.104221, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.230988 0.354586 0.671467 0.870932 0.637076 0.833731 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=145367, meanQ=8.387304, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1430047 episodes
GETTING ACTION FROM:
action 3, numVisits=1575412, meanQ=6.005627, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.230988 0.354586 0.671467 0.870932 0.637076 0.833731 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 270
Initial state: 0 0.614113 0.881332 0.53054 0.822033 0.141888 0.724713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1144745 episodes
GETTING ACTION FROM:
action 2, numVisits=1144739, meanQ=4.968469, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.614113 0.881332 0.53054 0.822033 0.141888 0.724713 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=83311, meanQ=5.577396, numObservations: 3
action -1, numVisits=31, meanQ=4.380084, numObservations: 1
action 3, numVisits=9, meanQ=2.553344, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1343882 episodes
GETTING ACTION FROM:
action 2, numVisits=1427185, meanQ=5.002298, numObservations: 3
action -1, numVisits=37, meanQ=3.619894, numObservations: 1
action 3, numVisits=11, meanQ=1.907282, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.614113 0.881332 0.53054 0.822033 0.141888 0.724713 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 271
Initial state: 0 0.604294 0.872495 0.181707 0.276749 0.690299 0.801153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138581 episodes
GETTING ACTION FROM:
action 3, numVisits=1138246, meanQ=4.987226, numObservations: 4
action -1, numVisits=331, meanQ=2.126640, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.604294 0.872495 0.181707 0.276749 0.690299 0.801153 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 272
Initial state: 0 0.13174 0.257134 0.565223 0.893191 0.641027 0.82328 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131083 episodes
GETTING ACTION FROM:
action 2, numVisits=1131004, meanQ=4.990365, numObservations: 5
action 0, numVisits=72, meanQ=4.115035, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.13174 0.257134 0.565223 0.893191 0.641027 0.82328 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 273
Initial state: 0 0.665897 0.412565 0.567321 0.800082 0.680629 0.806532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117483 episodes
GETTING ACTION FROM:
action 2, numVisits=1117400, meanQ=4.859935, numObservations: 5
action 0, numVisits=45, meanQ=3.717218, numObservations: 1
action 3, numVisits=17, meanQ=2.993535, numObservations: 4
action 1, numVisits=19, meanQ=2.895800, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.665897 0.412565 0.567321 0.800082 0.680629 0.806532 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 274
Initial state: 0 0.567215 0.81586 0.686001 0.839938 0.576868 0.840993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1156569 episodes
GETTING ACTION FROM:
action 1, numVisits=1156514, meanQ=4.917639, numObservations: 3
action -1, numVisits=48, meanQ=3.812569, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.567215 0.81586 0.686001 0.839938 0.576868 0.840993 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 275
Initial state: 0 0.733636 0.0624534 0.653846 0.86788 0.604572 0.881804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131105 episodes
GETTING ACTION FROM:
action 1, numVisits=1131096, meanQ=4.986797, numObservations: 5
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.733636 0.0624534 0.653846 0.86788 0.604572 0.881804 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 276
Initial state: 0 0.595614 0.876312 0.650614 0.888068 0.866324 0.390913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 798191 episodes
GETTING ACTION FROM:
action 0, numVisits=798180, meanQ=5.884025, numObservations: 3
action 3, numVisits=7, meanQ=0.144314, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.595614 0.876312 0.650614 0.888068 0.866324 0.390913 w: 1
Observation: 0 0 0.822244 0 0.947171 0 0.447352 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=299288, meanQ=7.817927, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1238709 episodes
GETTING ACTION FROM:
action 2, numVisits=1537983, meanQ=5.560158, numObservations: 5
action 0, numVisits=14, meanQ=3.410204, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.595614 0.876312 0.650614 0.888068 0.866324 0.390913 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 277
Initial state: 0 0.757515 0.940256 0.673383 0.850229 0.582065 0.837274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138986 episodes
GETTING ACTION FROM:
action 2, numVisits=1138945, meanQ=4.996120, numObservations: 4
action 0, numVisits=19, meanQ=3.149633, numObservations: 1
action 3, numVisits=14, meanQ=2.122150, numObservations: 4
action 1, numVisits=6, meanQ=1.331683, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.757515 0.940256 0.673383 0.850229 0.582065 0.837274 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.564052 0.814472 0.137515 0.56547 0.50775 0.834705 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1143863 episodes
GETTING ACTION FROM:
action 2, numVisits=1131665, meanQ=4.922533, numObservations: 3
action 0, numVisits=12191, meanQ=3.069278, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.564052 0.814472 0.137515 0.56547 0.50775 0.834705 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=173380, meanQ=8.251303, numObservations: 4
action 3, numVisits=4, meanQ=4.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1419476 episodes
GETTING ACTION FROM:
action 1, numVisits=1592825, meanQ=6.255451, numObservations: 4
action 3, numVisits=33, meanQ=4.757576, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.564052 0.814472 0.137515 0.56547 0.50775 0.834705 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 279
Initial state: 0 0.329265 0.24994 0.53381 0.876931 0.504366 0.821467 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1155038 episodes
GETTING ACTION FROM:
action 2, numVisits=1155027, meanQ=5.019630, numObservations: 4
action 1, numVisits=6, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.329265 0.24994 0.53381 0.876931 0.504366 0.821467 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 280
Initial state: 0 0.670851 0.882787 0.641864 0.880819 0.175149 0.762547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1157428 episodes
GETTING ACTION FROM:
action 1, numVisits=1157421, meanQ=4.896503, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.670851 0.882787 0.641864 0.880819 0.175149 0.762547 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 281
Initial state: 0 0.600661 0.835736 0.6596 0.886017 0.991568 0.604238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138664 episodes
GETTING ACTION FROM:
action 3, numVisits=1138655, meanQ=4.980751, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.600661 0.835736 0.6596 0.886017 0.991568 0.604238 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 282
Initial state: 0 0.655536 0.81901 0.689827 0.822892 0.270623 0.0182805 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131973 episodes
GETTING ACTION FROM:
action 1, numVisits=1104074, meanQ=4.976580, numObservations: 5
action 3, numVisits=27889, meanQ=4.915924, numObservations: 4
action 2, numVisits=6, meanQ=1.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.655536 0.81901 0.689827 0.822892 0.270623 0.0182805 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 283
Initial state: 0 0.792771 0.761018 0.568049 0.856804 0.69344 0.820457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130260 episodes
GETTING ACTION FROM:
action 3, numVisits=1130233, meanQ=5.005294, numObservations: 5
action -1, numVisits=14, meanQ=2.825401, numObservations: 1
action 2, numVisits=5, meanQ=1.396020, numObservations: 2
action 1, numVisits=6, meanQ=0.331667, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.792771 0.761018 0.568049 0.856804 0.69344 0.820457 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 284
Initial state: 0 0.661522 0.875933 0.732554 0.106048 0.58698 0.876496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093971 episodes
GETTING ACTION FROM:
action 2, numVisits=1093890, meanQ=4.830533, numObservations: 5
action 0, numVisits=49, meanQ=3.754797, numObservations: 1
action 1, numVisits=20, meanQ=2.699505, numObservations: 3
action 3, numVisits=10, meanQ=2.399010, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.661522 0.875933 0.732554 0.106048 0.58698 0.876496 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 285
Initial state: 0 0.650289 0.813695 0.255859 0.517492 0.627497 0.887233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1119977 episodes
GETTING ACTION FROM:
action 2, numVisits=1119959, meanQ=4.982959, numObservations: 5
action 3, numVisits=13, meanQ=1.460008, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.650289 0.813695 0.255859 0.517492 0.627497 0.887233 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=141967, meanQ=8.383465, numObservations: 4
action 3, numVisits=142, meanQ=7.820564, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1422629 episodes
GETTING ACTION FROM:
action 1, numVisits=1560736, meanQ=5.906950, numObservations: 4
action 3, numVisits=3999, meanQ=5.793243, numObservations: 5
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.650289 0.813695 0.255859 0.517492 0.627497 0.887233 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 286
Initial state: 0 0.554875 0.829223 0.874628 0.119441 0.654088 0.828283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1136651 episodes
GETTING ACTION FROM:
action 3, numVisits=1136577, meanQ=4.916278, numObservations: 4
action 0, numVisits=68, meanQ=4.009077, numObservations: 1
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.554875 0.829223 0.874628 0.119441 0.654088 0.828283 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 287
Initial state: 0 0.633526 0.810017 0.63484 0.809714 0.217555 0.209732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1122364 episodes
GETTING ACTION FROM:
action 3, numVisits=1122358, meanQ=4.916251, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.633526 0.810017 0.63484 0.809714 0.217555 0.209732 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=61757, meanQ=7.848723, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1430019 episodes
GETTING ACTION FROM:
action 2, numVisits=1491774, meanQ=5.746587, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.633526 0.810017 0.63484 0.809714 0.217555 0.209732 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 288
Initial state: 0 0.118339 0.120969 0.610453 0.898169 0.657337 0.894347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 773811 episodes
GETTING ACTION FROM:
action 0, numVisits=773803, meanQ=2.904506, numObservations: 1
action -1, numVisits=3, meanQ=-3.656600, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.118339 0.120969 0.610453 0.898169 0.657337 0.894347 w: 1
Observation: 0 0 0.201587 0 0.865353 0 0.93942 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=766535, meanQ=4.970143, numObservations: 5
action 0, numVisits=7260, meanQ=2.883599, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1244513 episodes
GETTING ACTION FROM:
action 1, numVisits=2011048, meanQ=5.101447, numObservations: 5
action 0, numVisits=7260, meanQ=2.883599, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.118339 0.120969 0.610453 0.898169 0.657337 0.894347 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=198146, meanQ=8.391485, numObservations: 4
action 3, numVisits=48480, meanQ=8.375200, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1432963 episodes
GETTING ACTION FROM:
action 2, numVisits=1224397, meanQ=6.204368, numObservations: 4
action 3, numVisits=455189, meanQ=6.200083, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.118339 0.120969 0.610453 0.898169 0.657337 0.894347 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 289
Initial state: 0 0.606515 0.0902822 0.546841 0.848004 0.53186 0.854224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1140686 episodes
GETTING ACTION FROM:
action 3, numVisits=1140620, meanQ=4.973876, numObservations: 4
action 0, numVisits=35, meanQ=3.691080, numObservations: 1
action -1, numVisits=29, meanQ=3.574644, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.606515 0.0902822 0.546841 0.848004 0.53186 0.854224 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=83403, meanQ=5.612386, numObservations: 3
action 2, numVisits=48, meanQ=3.776252, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1335916 episodes
GETTING ACTION FROM:
action 3, numVisits=1419319, meanQ=4.937792, numObservations: 4
action 2, numVisits=48, meanQ=3.776252, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.606515 0.0902822 0.546841 0.848004 0.53186 0.854224 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 290
Initial state: 0 0.474959 0.909677 0.627559 0.838949 0.567615 0.815056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1121643 episodes
GETTING ACTION FROM:
action 3, numVisits=1121632, meanQ=4.997291, numObservations: 5
action 2, numVisits=6, meanQ=1.331683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.474959 0.909677 0.627559 0.838949 0.567615 0.815056 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 291
Initial state: 0 0.0825447 0.269421 0.650306 0.88841 0.633475 0.836549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 782688 episodes
GETTING ACTION FROM:
action -1, numVisits=782659, meanQ=2.841708, numObservations: 1
action 1, numVisits=17, meanQ=0.880606, numObservations: 4
action 2, numVisits=8, meanQ=0.237513, numObservations: 4
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action: -1
Next state: 0 0.0825447 0.269421 0.650306 0.88841 0.633475 0.836549 w: 1
Observation: 0 0.0741395 0 0.65062 0 0.697069 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=782631, meanQ=4.899695, numObservations: 4
action -1, numVisits=22, meanQ=3.290778, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1236937 episodes
GETTING ACTION FROM:
action 3, numVisits=2019567, meanQ=4.823320, numObservations: 4
action -1, numVisits=23, meanQ=3.220006, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0825447 0.269421 0.650306 0.88841 0.633475 0.836549 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 292
Initial state: 0 0.577504 0.810477 0.562581 0.706497 0.574048 0.850753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1147885 episodes
GETTING ACTION FROM:
action 2, numVisits=1138578, meanQ=5.008025, numObservations: 3
action 1, numVisits=9245, meanQ=4.933975, numObservations: 3
action 0, numVisits=59, meanQ=4.026373, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.577504 0.810477 0.562581 0.706497 0.574048 0.850753 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 293
Initial state: 0 0.58943 0.864831 0.542729 0.86642 0.931521 0.493034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1119493 episodes
GETTING ACTION FROM:
action 3, numVisits=1119451, meanQ=4.915654, numObservations: 5
action 1, numVisits=32, meanQ=3.360634, numObservations: 3
action 2, numVisits=6, meanQ=1.651683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.58943 0.864831 0.542729 0.86642 0.931521 0.493034 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=9234, meanQ=4.446749, numObservations: 5
action -1, numVisits=27, meanQ=3.210973, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1403054 episodes
GETTING ACTION FROM:
action 1, numVisits=1412288, meanQ=5.897481, numObservations: 5
action -1, numVisits=27, meanQ=3.210973, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.58943 0.864831 0.542729 0.86642 0.931521 0.493034 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 294
Initial state: 0 0.533725 0.893503 0.457215 0.871799 0.521897 0.864728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142206 episodes
GETTING ACTION FROM:
action 2, numVisits=1142200, meanQ=4.981663, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.533725 0.893503 0.457215 0.871799 0.521897 0.864728 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=63505, meanQ=7.835961, numObservations: 4
action 1, numVisits=24, meanQ=5.999175, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1434381 episodes
GETTING ACTION FROM:
action 3, numVisits=1497593, meanQ=5.672694, numObservations: 4
action 1, numVisits=315, meanQ=5.205208, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.533725 0.893503 0.457215 0.871799 0.521897 0.864728 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 295
Initial state: 0 0.544942 0.860849 0.627073 0.845999 0.742344 0.375968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129740 episodes
GETTING ACTION FROM:
action 1, numVisits=1129670, meanQ=5.116977, numObservations: 5
action 0, numVisits=63, meanQ=4.169821, numObservations: 1
action 2, numVisits=4, meanQ=-0.007500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.544942 0.860849 0.627073 0.845999 0.742344 0.375968 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 296
Initial state: 0 0.555129 0.852737 0.658462 0.806963 0.42652 0.692155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1149708 episodes
GETTING ACTION FROM:
action 2, numVisits=1145567, meanQ=4.987607, numObservations: 3
action -1, numVisits=4136, meanQ=2.991692, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.555129 0.852737 0.658462 0.806963 0.42652 0.692155 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 297
Initial state: 0 0.577645 0.890714 0.620762 0.834135 0.540687 0.250474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1149381 episodes
GETTING ACTION FROM:
action 1, numVisits=1149237, meanQ=4.985927, numObservations: 4
action -1, numVisits=138, meanQ=4.346463, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.577645 0.890714 0.620762 0.834135 0.540687 0.250474 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 298
Initial state: 0 0.606779 0.413557 0.566978 0.89321 0.614627 0.859015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127703 episodes
GETTING ACTION FROM:
action 1, numVisits=1127177, meanQ=4.906299, numObservations: 5
action 3, numVisits=521, meanQ=4.572516, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.606779 0.413557 0.566978 0.89321 0.614627 0.859015 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 299
Initial state: 0 0.687389 0.894906 0.622308 0.500264 0.521438 0.809838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1156680 episodes
GETTING ACTION FROM:
action 1, numVisits=1156481, meanQ=4.973681, numObservations: 3
action -1, numVisits=194, meanQ=4.441485, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.687389 0.894906 0.622308 0.500264 0.521438 0.809838 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 300
Initial state: 0 0.657661 0.865441 0.515846 0.241901 0.686391 0.835695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129485 episodes
GETTING ACTION FROM:
action 1, numVisits=1129468, meanQ=4.979784, numObservations: 5
action 2, numVisits=12, meanQ=2.498342, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.657661 0.865441 0.515846 0.241901 0.686391 0.835695 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 301
Initial state: 0 0.0461013 0.111134 0.548108 0.8204 0.653785 0.807609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127798 episodes
GETTING ACTION FROM:
action 1, numVisits=1127704, meanQ=4.916679, numObservations: 5
action 0, numVisits=89, meanQ=4.130825, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0461013 0.111134 0.548108 0.8204 0.653785 0.807609 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=109354, meanQ=8.530988, numObservations: 3
action 2, numVisits=1187, meanQ=8.353658, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1402950 episodes
GETTING ACTION FROM:
action 3, numVisits=1505604, meanQ=6.327048, numObservations: 5
action 2, numVisits=7884, meanQ=6.247337, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0461013 0.111134 0.548108 0.8204 0.653785 0.807609 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 302
Initial state: 0 0.613545 0.851088 0.136779 0.814846 0.535305 0.84007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125891 episodes
GETTING ACTION FROM:
action 1, numVisits=1125810, meanQ=4.965989, numObservations: 5
action 0, numVisits=75, meanQ=4.100604, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.613545 0.851088 0.136779 0.814846 0.535305 0.84007 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 303
Initial state: 0 0.245975 0.282659 0.594884 0.838665 0.694565 0.880925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1140071 episodes
GETTING ACTION FROM:
action 2, numVisits=1139907, meanQ=4.990367, numObservations: 4
action 0, numVisits=139, meanQ=4.233830, numObservations: 1
action 1, numVisits=21, meanQ=1.843338, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.245975 0.282659 0.594884 0.838665 0.694565 0.880925 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 304
Initial state: 0 0.546014 0.807492 0.774177 0.0740305 0.506692 0.875054 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 786217 episodes
GETTING ACTION FROM:
action -1, numVisits=786201, meanQ=2.856264, numObservations: 1
action 1, numVisits=7, meanQ=-0.429986, numObservations: 1
action 3, numVisits=6, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.546014 0.807492 0.774177 0.0740305 0.506692 0.875054 w: 1
Observation: 0 0.642532 0 0.686941 0 0.47165 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=786169, meanQ=4.904058, numObservations: 4
action 1, numVisits=15, meanQ=2.866000, numObservations: 3
action 2, numVisits=12, meanQ=1.998333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1243027 episodes
GETTING ACTION FROM:
action 3, numVisits=2029196, meanQ=4.920059, numObservations: 4
action 1, numVisits=15, meanQ=2.866000, numObservations: 3
action 2, numVisits=12, meanQ=1.998333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.546014 0.807492 0.774177 0.0740305 0.506692 0.875054 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 305
Initial state: 0 0.646431 0.804108 0.541934 0.868166 0.667636 0.0618842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102753 episodes
GETTING ACTION FROM:
action 2, numVisits=1102713, meanQ=4.991403, numObservations: 5
action 0, numVisits=29, meanQ=3.601498, numObservations: 1
action 1, numVisits=8, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.646431 0.804108 0.541934 0.868166 0.667636 0.0618842 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=71919, meanQ=7.256876, numObservations: 4
action 1, numVisits=5, meanQ=2.598000, numObservations: 2
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1324421 episodes
GETTING ACTION FROM:
action 2, numVisits=1396332, meanQ=5.144122, numObservations: 4
action 1, numVisits=11, meanQ=2.453636, numObservations: 4
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.646431 0.804108 0.541934 0.868166 0.667636 0.0618842 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 306
Initial state: 0 0.691158 0.899992 0.574559 0.800335 0.740014 0.284444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1144203 episodes
GETTING ACTION FROM:
action 1, numVisits=1144195, meanQ=4.936981, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.691158 0.899992 0.574559 0.800335 0.740014 0.284444 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 307
Initial state: 0 0.691778 0.858978 0.582344 0.814973 0.10787 0.110945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100521 episodes
GETTING ACTION FROM:
action 1, numVisits=1100468, meanQ=4.835984, numObservations: 5
action -1, numVisits=35, meanQ=3.559742, numObservations: 1
action 3, numVisits=14, meanQ=2.569293, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.691778 0.858978 0.582344 0.814973 0.10787 0.110945 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 308
Initial state: 0 0.6179 0.817026 0.663486 0.844719 0.165848 0.178528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1136037 episodes
GETTING ACTION FROM:
action 1, numVisits=1135892, meanQ=4.952055, numObservations: 4
action -1, numVisits=141, meanQ=1.538852, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.6179 0.817026 0.663486 0.844719 0.165848 0.178528 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 309
Initial state: 0 0.568683 0.889193 0.277598 0.706223 0.568008 0.873411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1150566 episodes
GETTING ACTION FROM:
action 2, numVisits=1150541, meanQ=4.904694, numObservations: 4
action -1, numVisits=21, meanQ=3.261356, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.568683 0.889193 0.277598 0.706223 0.568008 0.873411 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=175594, meanQ=8.304326, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1435084 episodes
GETTING ACTION FROM:
action 3, numVisits=1610676, meanQ=6.075086, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.568683 0.889193 0.277598 0.706223 0.568008 0.873411 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 310
Initial state: 0 0.497391 0.210393 0.66639 0.881995 0.658936 0.897375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106190 episodes
GETTING ACTION FROM:
action 3, numVisits=1106052, meanQ=4.816310, numObservations: 4
action -1, numVisits=63, meanQ=3.874348, numObservations: 1
action 0, numVisits=46, meanQ=3.714958, numObservations: 1
action 1, numVisits=28, meanQ=3.281429, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.497391 0.210393 0.66639 0.881995 0.658936 0.897375 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 311
Initial state: 0 0.543641 0.889297 0.595807 0.846418 0.8464 0.774388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146251 episodes
GETTING ACTION FROM:
action 3, numVisits=1146240, meanQ=4.945674, numObservations: 3
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.543641 0.889297 0.595807 0.846418 0.8464 0.774388 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 312
Initial state: 0 0.190539 0.074405 0.589471 0.873768 0.553825 0.829889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142846 episodes
GETTING ACTION FROM:
action 1, numVisits=1142731, meanQ=4.976958, numObservations: 4
action 3, numVisits=110, meanQ=4.245959, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.190539 0.074405 0.589471 0.873768 0.553825 0.829889 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=175093, meanQ=8.262056, numObservations: 4
action 3, numVisits=3, meanQ=2.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1423075 episodes
GETTING ACTION FROM:
action 2, numVisits=1598160, meanQ=5.995781, numObservations: 4
action 3, numVisits=9, meanQ=2.333333, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.190539 0.074405 0.589471 0.873768 0.553825 0.829889 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 313
Initial state: 0 0.627453 0.816108 0.643211 0.871195 0.021178 0.545848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142148 episodes
GETTING ACTION FROM:
action 2, numVisits=1142098, meanQ=4.930258, numObservations: 4
action 1, numVisits=45, meanQ=3.605558, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.627453 0.816108 0.643211 0.871195 0.021178 0.545848 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=83312, meanQ=4.701631, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1407834 episodes
GETTING ACTION FROM:
action 1, numVisits=1491146, meanQ=5.647898, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.627453 0.816108 0.643211 0.871195 0.021178 0.545848 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 314
Initial state: 0 0.605467 0.854265 0.546584 0.888052 0.552164 0.474885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1122812 episodes
GETTING ACTION FROM:
action 1, numVisits=1122759, meanQ=4.904092, numObservations: 5
action 2, numVisits=25, meanQ=3.152004, numObservations: 3
action 3, numVisits=24, meanQ=3.078754, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.605467 0.854265 0.546584 0.888052 0.552164 0.474885 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 315
Initial state: 0 0.162237 0.761796 0.649515 0.819449 0.683247 0.880385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127592 episodes
GETTING ACTION FROM:
action 3, numVisits=1127582, meanQ=5.160442, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.162237 0.761796 0.649515 0.819449 0.683247 0.880385 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 316
Initial state: 0 0.59386 0.890398 0.668634 0.374364 0.674434 0.810127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137248 episodes
GETTING ACTION FROM:
action 3, numVisits=1137241, meanQ=4.980174, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.59386 0.890398 0.668634 0.374364 0.674434 0.810127 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 317
Initial state: 0 0.894701 0.817912 0.574783 0.882174 0.503435 0.822741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128095 episodes
GETTING ACTION FROM:
action 3, numVisits=1128086, meanQ=4.987371, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.894701 0.817912 0.574783 0.882174 0.503435 0.822741 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 318
Initial state: 0 0.58623 0.804857 0.267933 0.867266 0.605292 0.828582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128795 episodes
GETTING ACTION FROM:
action 3, numVisits=1128752, meanQ=4.989460, numObservations: 5
action -1, numVisits=38, meanQ=3.774387, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.58623 0.804857 0.267933 0.867266 0.605292 0.828582 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 319
Initial state: 0 0.635443 0.890628 0.654998 0.833882 0.676915 0.329382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129186 episodes
GETTING ACTION FROM:
action 3, numVisits=1129013, meanQ=4.986291, numObservations: 5
action 0, numVisits=145, meanQ=4.362761, numObservations: 1
action 2, numVisits=25, meanQ=2.998804, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.635443 0.890628 0.654998 0.833882 0.676915 0.329382 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 320
Initial state: 0 0.102412 0.125142 0.512532 0.846151 0.52978 0.812067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132787 episodes
GETTING ACTION FROM:
action 3, numVisits=1132781, meanQ=4.943608, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.102412 0.125142 0.512532 0.846151 0.52978 0.812067 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 321
Initial state: 0 0.538779 0.897333 0.620147 0.901768 0.633266 0.86735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132610 episodes
GETTING ACTION FROM:
action 3, numVisits=1128356, meanQ=4.979325, numObservations: 5
action 1, numVisits=4153, meanQ=4.870134, numObservations: 4
action 2, numVisits=97, meanQ=4.202203, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.538779 0.897333 0.620147 0.901768 0.633266 0.86735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 322
Initial state: 0 0.63271 0.865327 0.620786 0.0894119 0.671858 0.873611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1126184 episodes
GETTING ACTION FROM:
action 3, numVisits=1111658, meanQ=5.023781, numObservations: 5
action 0, numVisits=14522, meanQ=3.111422, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.63271 0.865327 0.620786 0.0894119 0.671858 0.873611 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 323
Initial state: 0 0.136338 0.97639 0.567891 0.827048 0.695391 0.81025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139212 episodes
GETTING ACTION FROM:
action 3, numVisits=1139094, meanQ=4.965282, numObservations: 4
action 0, numVisits=106, meanQ=4.246239, numObservations: 1
action 2, numVisits=7, meanQ=0.428571, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.136338 0.97639 0.567891 0.827048 0.695391 0.81025 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 324
Initial state: 0 0.645531 0.897321 0.558693 0.81969 0.807016 0.925512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146816 episodes
GETTING ACTION FROM:
action 2, numVisits=1146784, meanQ=4.988294, numObservations: 4
action 3, numVisits=26, meanQ=3.376927, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.645531 0.897321 0.558693 0.81969 0.807016 0.925512 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 325
Initial state: 0 0.531121 0.815788 0.927603 0.531429 0.544885 0.857562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1151126 episodes
GETTING ACTION FROM:
action 2, numVisits=1151112, meanQ=4.977289, numObservations: 4
action 1, numVisits=9, meanQ=0.111111, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.531121 0.815788 0.927603 0.531429 0.544885 0.857562 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 326
Initial state: 0 0.506908 0.893821 0.479666 0.583253 0.550237 0.898533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098841 episodes
GETTING ACTION FROM:
action 1, numVisits=1087905, meanQ=4.813241, numObservations: 4
action -1, numVisits=10932, meanQ=3.030799, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.506908 0.893821 0.479666 0.583253 0.550237 0.898533 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 327
Initial state: 0 0.584454 0.894548 0.521546 0.842421 0.337454 0.262947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1127668 episodes
GETTING ACTION FROM:
action 2, numVisits=1127617, meanQ=4.971784, numObservations: 5
action 0, numVisits=46, meanQ=3.857069, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.584454 0.894548 0.521546 0.842421 0.337454 0.262947 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=82361, meanQ=5.340564, numObservations: 3
action 1, numVisits=13, meanQ=3.307708, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1338301 episodes
GETTING ACTION FROM:
action 2, numVisits=1420660, meanQ=5.123355, numObservations: 3
action 1, numVisits=15, meanQ=2.733347, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.584454 0.894548 0.521546 0.842421 0.337454 0.262947 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 328
Initial state: 0 0.624019 0.861147 0.594196 0.860643 0.594262 0.315009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128855 episodes
GETTING ACTION FROM:
action 3, numVisits=1100606, meanQ=4.903591, numObservations: 3
action 0, numVisits=28237, meanQ=2.898516, numObservations: 1
action 1, numVisits=7, meanQ=0.411429, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action: 3
Next state: 0 0.624019 0.861147 0.594196 0.860643 0.594262 0.315009 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=168110, meanQ=8.302057, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1431244 episodes
GETTING ACTION FROM:
action 2, numVisits=1599352, meanQ=6.199670, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.624019 0.861147 0.594196 0.860643 0.594262 0.315009 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 329
Initial state: 0 0.516202 0.875183 0.638589 0.863876 0.342701 0.902493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145065 episodes
GETTING ACTION FROM:
action 2, numVisits=1145059, meanQ=4.915131, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.516202 0.875183 0.638589 0.863876 0.342701 0.902493 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 330
Initial state: 0 0.645629 0.882137 0.757358 0.40313 0.540903 0.86604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1148072 episodes
GETTING ACTION FROM:
action 3, numVisits=1148066, meanQ=4.913174, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.645629 0.882137 0.757358 0.40313 0.540903 0.86604 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 331
Initial state: 0 0.048343 0.57634 0.634587 0.805983 0.688419 0.896378 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131816 episodes
GETTING ACTION FROM:
action 2, numVisits=1131810, meanQ=4.973727, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.048343 0.57634 0.634587 0.805983 0.688419 0.896378 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 332
Initial state: 0 0.756258 0.115911 0.647681 0.879513 0.66696 0.840155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1155353 episodes
GETTING ACTION FROM:
action 3, numVisits=1155342, meanQ=4.977433, numObservations: 3
action 1, numVisits=6, meanQ=1.331683, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.756258 0.115911 0.647681 0.879513 0.66696 0.840155 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 333
Initial state: 0 0.18703 0.502439 0.554322 0.835036 0.65715 0.80477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132088 episodes
GETTING ACTION FROM:
action 3, numVisits=1116732, meanQ=5.112870, numObservations: 4
action 0, numVisits=15351, meanQ=3.149224, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.18703 0.502439 0.554322 0.835036 0.65715 0.80477 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 334
Initial state: 0 0.627108 0.808065 0.544927 0.830504 0.0937893 0.0261567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125270 episodes
GETTING ACTION FROM:
action 1, numVisits=1116276, meanQ=4.991508, numObservations: 5
action -1, numVisits=4935, meanQ=2.938786, numObservations: 1
action 0, numVisits=4057, meanQ=2.929958, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.627108 0.808065 0.544927 0.830504 0.0937893 0.0261567 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 335
Initial state: 0 0.556513 0.82621 0.611044 0.82122 0.0980889 0.30853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129553 episodes
GETTING ACTION FROM:
action 2, numVisits=1129389, meanQ=4.986890, numObservations: 5
action 0, numVisits=160, meanQ=4.398544, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.556513 0.82621 0.611044 0.82122 0.0980889 0.30853 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 336
Initial state: 0 0.579622 0.846255 0.967184 0.790677 0.520657 0.805064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091804 episodes
GETTING ACTION FROM:
action 2, numVisits=1091771, meanQ=4.818115, numObservations: 5
action 3, numVisits=28, meanQ=3.274643, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.579622 0.846255 0.967184 0.790677 0.520657 0.805064 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 337
Initial state: 0 0.563049 0.86585 0.697343 0.830724 0.257269 0.200281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109599 episodes
GETTING ACTION FROM:
action 3, numVisits=1109520, meanQ=4.850338, numObservations: 4
action -1, numVisits=54, meanQ=3.822266, numObservations: 1
action 0, numVisits=22, meanQ=3.256898, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.563049 0.86585 0.697343 0.830724 0.257269 0.200281 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=140535, meanQ=8.391303, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1423044 episodes
GETTING ACTION FROM:
action 1, numVisits=1563484, meanQ=6.212535, numObservations: 4
action 2, numVisits=94, meanQ=5.319044, numObservations: 5
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.563049 0.86585 0.697343 0.830724 0.257269 0.200281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 338
Initial state: 0 0.685719 0.298314 0.515535 0.859084 0.502006 0.807075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133657 episodes
GETTING ACTION FROM:
action 2, numVisits=1133613, meanQ=4.986028, numObservations: 5
action -1, numVisits=39, meanQ=3.762547, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.685719 0.298314 0.515535 0.859084 0.502006 0.807075 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 339
Initial state: 0 0.56974 0.886763 0.570304 0.845596 0.656836 0.19569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139961 episodes
GETTING ACTION FROM:
action 1, numVisits=1139880, meanQ=4.977904, numObservations: 4
action -1, numVisits=56, meanQ=3.970027, numObservations: 1
action 3, numVisits=18, meanQ=2.553889, numObservations: 3
action 2, numVisits=5, meanQ=0.196000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.56974 0.886763 0.570304 0.845596 0.656836 0.19569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 340
Initial state: 0 0.682029 0.68645 0.659307 0.865582 0.648298 0.835123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134478 episodes
GETTING ACTION FROM:
action 2, numVisits=1134470, meanQ=4.955846, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.682029 0.68645 0.659307 0.865582 0.648298 0.835123 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 341
Initial state: 0 0.618296 0.82192 0.667222 0.845084 0.344536 0.149545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133825 episodes
GETTING ACTION FROM:
action 1, numVisits=1133738, meanQ=4.986603, numObservations: 5
action -1, numVisits=81, meanQ=4.161655, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.618296 0.82192 0.667222 0.845084 0.344536 0.149545 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=82884, meanQ=5.608985, numObservations: 4
action 0, numVisits=99, meanQ=4.949916, numObservations: 1
action -1, numVisits=62, meanQ=4.764212, numObservations: 1
action 3, numVisits=9, meanQ=2.333344, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
Sampled 1359184 episodes
GETTING ACTION FROM:
action 3, numVisits=523770, meanQ=5.779031, numObservations: 5
action 1, numVisits=918276, meanQ=4.795918, numObservations: 5
action 0, numVisits=116, meanQ=4.110584, numObservations: 1
action -1, numVisits=76, meanQ=3.916335, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 0 0.618296 0.82192 0.667222 0.845084 0.344536 0.149545 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=4330, meanQ=8.488694, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1475608 episodes
GETTING ACTION FROM:
action 2, numVisits=1479933, meanQ=5.965771, numObservations: 4
action 1, numVisits=5, meanQ=0.196000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.618296 0.82192 0.667222 0.845084 0.344536 0.149545 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 342
Initial state: 0 0.595439 0.820083 0.19262 0.248572 0.603018 0.823572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137865 episodes
GETTING ACTION FROM:
action 3, numVisits=1137790, meanQ=4.989827, numObservations: 4
action 0, numVisits=71, meanQ=4.102126, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.595439 0.820083 0.19262 0.248572 0.603018 0.823572 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 343
Initial state: 0 0.56032 0.851762 0.596191 0.898883 0.663385 0.820403 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145470 episodes
GETTING ACTION FROM:
action 3, numVisits=1145297, meanQ=4.997816, numObservations: 4
action -1, numVisits=91, meanQ=4.202477, numObservations: 1
action 2, numVisits=72, meanQ=4.093058, numObservations: 5
action 1, numVisits=8, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.56032 0.851762 0.596191 0.898883 0.663385 0.820403 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 344
Initial state: 0 0.595914 0.883452 0.583523 0.859802 0.191643 0.810233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1141545 episodes
GETTING ACTION FROM:
action 1, numVisits=1141538, meanQ=4.964719, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.595914 0.883452 0.583523 0.859802 0.191643 0.810233 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=83161, meanQ=5.614218, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1345466 episodes
GETTING ACTION FROM:
action 1, numVisits=1428627, meanQ=5.253346, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.595914 0.883452 0.583523 0.859802 0.191643 0.810233 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 345
Initial state: 0 0.508537 0.867297 0.269761 0.939763 0.681803 0.834898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125296 episodes
GETTING ACTION FROM:
action 1, numVisits=1125189, meanQ=4.909097, numObservations: 4
action 2, numVisits=66, meanQ=3.926821, numObservations: 3
action 0, numVisits=36, meanQ=3.630986, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.508537 0.867297 0.269761 0.939763 0.681803 0.834898 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 346
Initial state: 0 0.649286 0.892288 0.0751792 0.53066 0.539405 0.879113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106354 episodes
GETTING ACTION FROM:
action 2, numVisits=1106309, meanQ=4.830332, numObservations: 4
action -1, numVisits=29, meanQ=3.417512, numObservations: 1
action 0, numVisits=13, meanQ=2.636140, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.649286 0.892288 0.0751792 0.53066 0.539405 0.879113 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=108392, meanQ=8.542831, numObservations: 3
action 1, numVisits=30, meanQ=7.200007, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1407661 episodes
GETTING ACTION FROM:
action 3, numVisits=1515572, meanQ=6.034351, numObservations: 5
action 1, numVisits=509, meanQ=5.683676, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.649286 0.892288 0.0751792 0.53066 0.539405 0.879113 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 347
Initial state: 0 0.332677 0.0818735 0.54555 0.862226 0.601134 0.871956 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139269 episodes
GETTING ACTION FROM:
action 3, numVisits=1139211, meanQ=4.922017, numObservations: 4
action 0, numVisits=47, meanQ=3.838870, numObservations: 1
action 2, numVisits=5, meanQ=1.396020, numObservations: 2
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.332677 0.0818735 0.54555 0.862226 0.601134 0.871956 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=144605, meanQ=8.395356, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1437347 episodes
GETTING ACTION FROM:
action 1, numVisits=1581950, meanQ=5.864738, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.332677 0.0818735 0.54555 0.862226 0.601134 0.871956 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=19840, meanQ=8.300293, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1453941 episodes
GETTING ACTION FROM:
action 2, numVisits=1473779, meanQ=6.342512, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.332677 0.0818735 0.54555 0.862226 0.601134 0.871956 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 348
Initial state: 0 0.605636 0.814662 0.663395 0.462802 0.626203 0.839783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124383 episodes
GETTING ACTION FROM:
action 2, numVisits=1123993, meanQ=4.883709, numObservations: 3
action 1, numVisits=339, meanQ=4.458126, numObservations: 4
action 3, numVisits=29, meanQ=3.469317, numObservations: 3
action 0, numVisits=20, meanQ=3.165914, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.605636 0.814662 0.663395 0.462802 0.626203 0.839783 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=154526, meanQ=8.315922, numObservations: 5
action 3, numVisits=17184, meanQ=8.212270, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1416672 episodes
GETTING ACTION FROM:
action 1, numVisits=1509403, meanQ=6.201101, numObservations: 5
action 3, numVisits=78977, meanQ=6.180212, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.605636 0.814662 0.663395 0.462802 0.626203 0.839783 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 349
Initial state: 0 0.69166 0.848792 0.638006 0.871558 0.13825 0.887071 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128320 episodes
GETTING ACTION FROM:
action 3, numVisits=1123181, meanQ=4.911608, numObservations: 5
action 0, numVisits=5127, meanQ=3.052077, numObservations: 1
action 2, numVisits=7, meanQ=-0.145714, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 3
Next state: 2 0.69166 0.848792 0.638006 0.871558 0.13825 0.887071 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 350
Initial state: 0 0.681229 0.881523 0.530781 0.86544 0.31916 0.77426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1155666 episodes
GETTING ACTION FROM:
action 1, numVisits=1155607, meanQ=5.003031, numObservations: 3
action 3, numVisits=54, meanQ=3.843335, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.681229 0.881523 0.530781 0.86544 0.31916 0.77426 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 351
Initial state: 0 0.583579 0.815707 0.22618 0.168985 0.552485 0.890235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129180 episodes
GETTING ACTION FROM:
action 3, numVisits=1129173, meanQ=4.878705, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.583579 0.815707 0.22618 0.168985 0.552485 0.890235 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=40654, meanQ=4.645133, numObservations: 3
action 0, numVisits=41987, meanQ=3.582677, numObservations: 1
action -1, numVisits=73, meanQ=2.665660, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1431859 episodes
GETTING ACTION FROM:
action 2, numVisits=1472513, meanQ=5.589107, numObservations: 3
action 0, numVisits=41987, meanQ=3.582677, numObservations: 1
action -1, numVisits=73, meanQ=2.665660, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.583579 0.815707 0.22618 0.168985 0.552485 0.890235 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 352
Initial state: 0 0.607202 0.838958 0.655052 0.81072 0.523405 0.268034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 780495 episodes
GETTING ACTION FROM:
action -1, numVisits=780488, meanQ=2.884407, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.607202 0.838958 0.655052 0.81072 0.523405 0.268034 w: 1
Observation: 0 0.687293 0 0.709559 0 0.613717 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=780478, meanQ=4.920837, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1238346 episodes
GETTING ACTION FROM:
action 3, numVisits=2018824, meanQ=4.808299, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.607202 0.838958 0.655052 0.81072 0.523405 0.268034 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 353
Initial state: 0 0.522397 0.882467 0.00793279 0.0406512 0.599903 0.877921 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 782147 episodes
GETTING ACTION FROM:
action 0, numVisits=782134, meanQ=2.937335, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action: 0
Next state: 0 0.522397 0.882467 0.00793279 0.0406512 0.599903 0.877921 w: 1
Observation: 0 0 0.840702 0 0 0 0.94407 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=782040, meanQ=4.991526, numObservations: 4
action 0, numVisits=34, meanQ=3.722793, numObservations: 1
action 3, numVisits=32, meanQ=3.624381, numObservations: 3
action 2, numVisits=25, meanQ=3.395200, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1230364 episodes
GETTING ACTION FROM:
action 1, numVisits=2012404, meanQ=5.072680, numObservations: 4
action 0, numVisits=34, meanQ=3.722793, numObservations: 1
action 3, numVisits=32, meanQ=3.624381, numObservations: 3
action 2, numVisits=25, meanQ=3.395200, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.522397 0.882467 0.00793279 0.0406512 0.599903 0.877921 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 354
Initial state: 0 0.866564 0.320526 0.512142 0.874656 0.553165 0.839713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1065446 episodes
GETTING ACTION FROM:
action 2, numVisits=873605, meanQ=5.006308, numObservations: 3
action -1, numVisits=183948, meanQ=2.951216, numObservations: 1
action 0, numVisits=7889, meanQ=2.888942, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.866564 0.320526 0.512142 0.874656 0.553165 0.839713 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=64262, meanQ=5.651025, numObservations: 3
action 3, numVisits=5, meanQ=1.820000, numObservations: 2
action 1, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1421669 episodes
GETTING ACTION FROM:
action 1, numVisits=1339580, meanQ=5.962641, numObservations: 4
action 2, numVisits=146347, meanQ=4.957501, numObservations: 4
action 0, numVisits=7, meanQ=1.960000, numObservations: 1
action 3, numVisits=5, meanQ=1.820000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 2 0.866564 0.320526 0.512142 0.874656 0.553165 0.839713 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 355
Initial state: 0 0.686964 0.594027 0.615724 0.865836 0.548418 0.803886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093928 episodes
GETTING ACTION FROM:
action 2, numVisits=1093878, meanQ=4.817849, numObservations: 5
action 0, numVisits=40, meanQ=3.640662, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.686964 0.594027 0.615724 0.865836 0.548418 0.803886 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 356
Initial state: 0 0.606376 0.847517 0.257948 0.897997 0.69864 0.892458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1135682 episodes
GETTING ACTION FROM:
action 1, numVisits=1135675, meanQ=4.917929, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.606376 0.847517 0.257948 0.897997 0.69864 0.892458 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 357
Initial state: 0 0.640431 0.860797 0.652525 0.896305 0.530765 0.590343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1144613 episodes
GETTING ACTION FROM:
action 2, numVisits=1144606, meanQ=4.979772, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.640431 0.860797 0.652525 0.896305 0.530765 0.590343 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 358
Initial state: 0 0.524408 0.873831 0.504314 0.84599 0.682267 0.945016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132323 episodes
GETTING ACTION FROM:
action 3, numVisits=1132093, meanQ=4.970119, numObservations: 4
action 0, numVisits=214, meanQ=4.464832, numObservations: 1
action 1, numVisits=12, meanQ=1.667508, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.524408 0.873831 0.504314 0.84599 0.682267 0.945016 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 359
Initial state: 0 0.613883 0.837184 0.789602 0.0178282 0.661621 0.856126 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1118077 episodes
GETTING ACTION FROM:
action 3, numVisits=1118070, meanQ=4.932888, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.613883 0.837184 0.789602 0.0178282 0.661621 0.856126 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 360
Initial state: 0 0.553755 0.886018 0.543309 0.896168 0.994517 0.425933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1148628 episodes
GETTING ACTION FROM:
action 3, numVisits=1148536, meanQ=4.994184, numObservations: 3
action -1, numVisits=67, meanQ=4.076460, numObservations: 1
action 1, numVisits=22, meanQ=3.350464, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.553755 0.886018 0.543309 0.896168 0.994517 0.425933 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 361
Initial state: 0 0.549596 0.857927 0.529753 0.830735 0.585312 0.914817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137301 episodes
GETTING ACTION FROM:
action 2, numVisits=1137171, meanQ=5.152180, numObservations: 5
action 0, numVisits=40, meanQ=3.943286, numObservations: 1
action 3, numVisits=82, meanQ=3.936465, numObservations: 4
action 1, numVisits=6, meanQ=1.663333, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.549596 0.857927 0.529753 0.830735 0.585312 0.914817 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 362
Initial state: 0 0.35894 0.858611 0.537317 0.816429 0.509386 0.873755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109633 episodes
GETTING ACTION FROM:
action 1, numVisits=1109246, meanQ=4.831598, numObservations: 4
action 3, numVisits=382, meanQ=4.445581, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.35894 0.858611 0.537317 0.816429 0.509386 0.873755 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=28470, meanQ=7.810339, numObservations: 4
action 3, numVisits=4, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1428480 episodes
GETTING ACTION FROM:
action 2, numVisits=1456947, meanQ=5.634340, numObservations: 4
action 3, numVisits=5, meanQ=1.794000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.35894 0.858611 0.537317 0.816429 0.509386 0.873755 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 363
Initial state: 0 0.565547 0.894707 0.860897 0.303469 0.553082 0.812435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137867 episodes
GETTING ACTION FROM:
action 2, numVisits=1137759, meanQ=5.016422, numObservations: 5
action -1, numVisits=28, meanQ=3.587017, numObservations: 1
action 0, numVisits=33, meanQ=3.572792, numObservations: 2
action 3, numVisits=43, meanQ=3.447914, numObservations: 3
action 1, numVisits=4, meanQ=-2.005000, numObservations: 2
action: 2
Next state: 2 0.565547 0.894707 0.860897 0.303469 0.553082 0.812435 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 364
Initial state: 0 0.551471 0.836511 0.722521 0.139056 0.516757 0.897351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1140313 episodes
GETTING ACTION FROM:
action 1, numVisits=1140201, meanQ=5.143551, numObservations: 5
action -1, numVisits=107, meanQ=4.426727, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.551471 0.836511 0.722521 0.139056 0.516757 0.897351 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 365
Initial state: 0 0.561999 0.817452 0.561428 0.608739 0.547295 0.895884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137292 episodes
GETTING ACTION FROM:
action 3, numVisits=1137286, meanQ=4.898783, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.561999 0.817452 0.561428 0.608739 0.547295 0.895884 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 366
Initial state: 0 0.606485 0.413458 0.551837 0.89168 0.695322 0.890313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100317 episodes
GETTING ACTION FROM:
action 3, numVisits=1100264, meanQ=4.822858, numObservations: 4
action 0, numVisits=46, meanQ=3.715886, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.606485 0.413458 0.551837 0.89168 0.695322 0.890313 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=80542, meanQ=3.529752, numObservations: 1
action 1, numVisits=5, meanQ=-1.402000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1420952 episodes
GETTING ACTION FROM:
action 1, numVisits=1355425, meanQ=6.064786, numObservations: 4
action -1, numVisits=146072, meanQ=1.664348, numObservations: 1
action 0, numVisits=4, meanQ=-2.252450, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.606485 0.413458 0.551837 0.89168 0.695322 0.890313 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 367
Initial state: 0 0.595396 0.888016 0.546781 0.814416 0.260266 0.426667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145730 episodes
GETTING ACTION FROM:
action 2, numVisits=1145614, meanQ=4.993468, numObservations: 4
action -1, numVisits=69, meanQ=4.091451, numObservations: 1
action 0, numVisits=45, meanQ=3.879393, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.595396 0.888016 0.546781 0.814416 0.260266 0.426667 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 368
Initial state: 0 0.584188 0.803209 0.601014 0.439437 0.649919 0.886821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 778904 episodes
GETTING ACTION FROM:
action 0, numVisits=778899, meanQ=2.851288, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.584188 0.803209 0.601014 0.439437 0.649919 0.886821 w: 1
Observation: 0 0 0.753129 0 0.437814 0 0.863638 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=778795, meanQ=4.895609, numObservations: 4
action -1, numVisits=56, meanQ=3.885491, numObservations: 1
action 1, numVisits=44, meanQ=2.222730, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1236193 episodes
GETTING ACTION FROM:
action 2, numVisits=2014988, meanQ=4.982757, numObservations: 4
action -1, numVisits=56, meanQ=3.885491, numObservations: 1
action 1, numVisits=44, meanQ=2.222730, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.584188 0.803209 0.601014 0.439437 0.649919 0.886821 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 369
Initial state: 0 0.560119 0.840896 0.579364 0.315589 0.656664 0.875449 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1136758 episodes
GETTING ACTION FROM:
action 1, numVisits=1136621, meanQ=4.937224, numObservations: 4
action 0, numVisits=131, meanQ=4.287697, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.560119 0.840896 0.579364 0.315589 0.656664 0.875449 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 370
Initial state: 0 0.586922 0.858637 0.538931 0.876539 0.0384203 0.286328 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1162923 episodes
GETTING ACTION FROM:
action 2, numVisits=1162865, meanQ=4.972273, numObservations: 3
action -1, numVisits=53, meanQ=3.951418, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.586922 0.858637 0.538931 0.876539 0.0384203 0.286328 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 371
Initial state: 0 0.611863 0.801353 0.70984 0.991553 0.531357 0.870899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145802 episodes
GETTING ACTION FROM:
action 2, numVisits=1145793, meanQ=4.993604, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=4, meanQ=-4.002500, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.611863 0.801353 0.70984 0.991553 0.531357 0.870899 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 372
Initial state: 0 0.807587 0.642477 0.688181 0.828989 0.603403 0.84307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104899 episodes
GETTING ACTION FROM:
action 3, numVisits=1104840, meanQ=4.895021, numObservations: 5
action -1, numVisits=55, meanQ=3.887429, numObservations: 1
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.807587 0.642477 0.688181 0.828989 0.603403 0.84307 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 373
Initial state: 0 0.671953 0.864198 0.323812 0.0614694 0.632664 0.894876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 782664 episodes
GETTING ACTION FROM:
action -1, numVisits=782617, meanQ=2.946313, numObservations: 1
action 0, numVisits=31, meanQ=1.613834, numObservations: 1
action 3, numVisits=12, meanQ=0.490842, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.671953 0.864198 0.323812 0.0614694 0.632664 0.894876 w: 1
Observation: 0 0.613239 0 0.247107 0 0.672107 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=782586, meanQ=4.997786, numObservations: 4
action 0, numVisits=26, meanQ=3.474105, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1240699 episodes
GETTING ACTION FROM:
action 1, numVisits=2023283, meanQ=4.854410, numObservations: 4
action 0, numVisits=28, meanQ=3.353595, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.671953 0.864198 0.323812 0.0614694 0.632664 0.894876 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 374
Initial state: 0 0.505203 0.115441 0.63342 0.856348 0.514271 0.829607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1153005 episodes
GETTING ACTION FROM:
action 3, numVisits=1152999, meanQ=4.985940, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.505203 0.115441 0.63342 0.856348 0.514271 0.829607 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 375
Initial state: 0 0.575217 0.820346 0.753179 0.962535 0.655684 0.830002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1123948 episodes
GETTING ACTION FROM:
action 3, numVisits=1123451, meanQ=4.984620, numObservations: 5
action 2, numVisits=485, meanQ=4.619986, numObservations: 5
action 1, numVisits=8, meanQ=1.498775, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.575217 0.820346 0.753179 0.962535 0.655684 0.830002 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 376
Initial state: 0 0.598368 0.838757 0.591537 0.822826 0.534497 0.877615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133244 episodes
GETTING ACTION FROM:
action 2, numVisits=1133144, meanQ=4.913404, numObservations: 4
action 0, numVisits=66, meanQ=3.990294, numObservations: 1
action 3, numVisits=31, meanQ=3.439032, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.598368 0.838757 0.591537 0.822826 0.534497 0.877615 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 377
Initial state: 0 0.639551 0.81646 0.574908 0.803631 0.313088 0.455969 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124837 episodes
GETTING ACTION FROM:
action 1, numVisits=1124831, meanQ=4.927386, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.639551 0.81646 0.574908 0.803631 0.313088 0.455969 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 378
Initial state: 0 0.518435 0.892179 0.906919 0.747876 0.605442 0.852103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132307 episodes
GETTING ACTION FROM:
action 2, numVisits=1132301, meanQ=5.102263, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.518435 0.892179 0.906919 0.747876 0.605442 0.852103 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 379
Initial state: 0 0.552222 0.881783 0.37581 0.782646 0.555694 0.854204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107599 episodes
GETTING ACTION FROM:
action 1, numVisits=1107588, meanQ=4.813928, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=4, meanQ=-4.975000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.552222 0.881783 0.37581 0.782646 0.555694 0.854204 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 380
Initial state: 0 0.291424 0.84018 0.550909 0.850194 0.588062 0.864334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139567 episodes
GETTING ACTION FROM:
action 3, numVisits=1139561, meanQ=4.911784, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.291424 0.84018 0.550909 0.850194 0.588062 0.864334 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=83253, meanQ=4.608653, numObservations: 5
action 0, numVisits=14, meanQ=2.589824, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1410846 episodes
GETTING ACTION FROM:
action 1, numVisits=1494099, meanQ=5.721292, numObservations: 5
action 0, numVisits=14, meanQ=2.589824, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.291424 0.84018 0.550909 0.850194 0.588062 0.864334 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=6980, meanQ=7.345857, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1446694 episodes
GETTING ACTION FROM:
action 3, numVisits=1453672, meanQ=5.580295, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.291424 0.84018 0.550909 0.850194 0.588062 0.864334 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 381
Initial state: 0 0.621355 0.85714 0.56951 0.660796 0.584462 0.858484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139740 episodes
GETTING ACTION FROM:
action 3, numVisits=1139734, meanQ=4.917617, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.621355 0.85714 0.56951 0.660796 0.584462 0.858484 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 382
Initial state: 0 0.624212 0.862631 0.529211 0.830651 0.225786 0.936796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128370 episodes
GETTING ACTION FROM:
action 1, numVisits=1128280, meanQ=4.965742, numObservations: 5
action -1, numVisits=85, meanQ=4.160069, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.624212 0.862631 0.529211 0.830651 0.225786 0.936796 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 383
Initial state: 0 0.591448 0.867672 0.645233 0.811096 0.68301 0.10493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139590 episodes
GETTING ACTION FROM:
action 1, numVisits=1138734, meanQ=4.901546, numObservations: 4
action 3, numVisits=851, meanQ=4.631486, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.591448 0.867672 0.645233 0.811096 0.68301 0.10493 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 384
Initial state: 0 0.260616 0.0939143 0.511695 0.828562 0.55732 0.851643 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117445 episodes
GETTING ACTION FROM:
action 1, numVisits=1117436, meanQ=4.872912, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.260616 0.0939143 0.511695 0.828562 0.55732 0.851643 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=141330, meanQ=8.393160, numObservations: 4
action 2, numVisits=5, meanQ=4.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1419984 episodes
GETTING ACTION FROM:
action 3, numVisits=1561309, meanQ=6.003073, numObservations: 4
action 2, numVisits=7, meanQ=2.711429, numObservations: 2
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.260616 0.0939143 0.511695 0.828562 0.55732 0.851643 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 385
Initial state: 0 0.525016 0.883457 0.532791 0.867527 0.149823 0.157165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137563 episodes
GETTING ACTION FROM:
action 3, numVisits=1137405, meanQ=5.001220, numObservations: 4
action 0, numVisits=132, meanQ=4.354100, numObservations: 1
action -1, numVisits=15, meanQ=2.947157, numObservations: 1
action 1, numVisits=10, meanQ=2.196000, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.525016 0.883457 0.532791 0.867527 0.149823 0.157165 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=144478, meanQ=8.401235, numObservations: 4
action 2, numVisits=6, meanQ=4.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1423218 episodes
GETTING ACTION FROM:
action 1, numVisits=1567655, meanQ=6.383208, numObservations: 4
action 2, numVisits=45, meanQ=5.177558, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.525016 0.883457 0.532791 0.867527 0.149823 0.157165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 386
Initial state: 0 0.275726 0.917602 0.655177 0.886009 0.589957 0.802429 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139960 episodes
GETTING ACTION FROM:
action 2, numVisits=1139951, meanQ=4.965749, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.275726 0.917602 0.655177 0.886009 0.589957 0.802429 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 387
Initial state: 0 0.634218 0.812292 0.70167 0.317181 0.551 0.846116 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137761 episodes
GETTING ACTION FROM:
action 3, numVisits=1137604, meanQ=4.926336, numObservations: 4
action 0, numVisits=141, meanQ=4.301407, numObservations: 1
action 2, numVisits=13, meanQ=2.069238, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.634218 0.812292 0.70167 0.317181 0.551 0.846116 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9682, meanQ=5.972901, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1338337 episodes
GETTING ACTION FROM:
action 3, numVisits=1348017, meanQ=4.937240, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.634218 0.812292 0.70167 0.317181 0.551 0.846116 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=22868, meanQ=6.412123, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1431753 episodes
GETTING ACTION FROM:
action 2, numVisits=1454619, meanQ=5.663323, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.634218 0.812292 0.70167 0.317181 0.551 0.846116 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 388
Initial state: 0 0.73696 0.503335 0.699848 0.857894 0.66535 0.879693 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1149282 episodes
GETTING ACTION FROM:
action 2, numVisits=1149218, meanQ=5.107055, numObservations: 4
action -1, numVisits=49, meanQ=4.017430, numObservations: 1
action 0, numVisits=10, meanQ=2.488000, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.73696 0.503335 0.699848 0.857894 0.66535 0.879693 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 389
Initial state: 0 0.596637 0.878745 0.607304 0.875902 0.0193569 0.486307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1141233 episodes
GETTING ACTION FROM:
action 1, numVisits=1141227, meanQ=4.991891, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.596637 0.878745 0.607304 0.875902 0.0193569 0.486307 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 390
Initial state: 0 0.580153 0.802473 0.668289 0.826738 0.769396 0.841402 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131638 episodes
GETTING ACTION FROM:
action 3, numVisits=1107721, meanQ=5.132289, numObservations: 4
action -1, numVisits=15578, meanQ=2.960202, numObservations: 1
action 0, numVisits=8321, meanQ=2.941465, numObservations: 1
action 2, numVisits=13, meanQ=0.699231, numObservations: 3
action 1, numVisits=5, meanQ=-1.402000, numObservations: 2
action: 3
Next state: 1 0.580153 0.802473 0.668289 0.826738 0.769396 0.841402 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 391
Initial state: 0 0.582464 0.66405 0.600039 0.817146 0.521932 0.805682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131565 episodes
GETTING ACTION FROM:
action 1, numVisits=1131550, meanQ=4.952956, numObservations: 5
action 3, numVisits=10, meanQ=2.398030, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.582464 0.66405 0.600039 0.817146 0.521932 0.805682 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=62734, meanQ=7.762099, numObservations: 4
action 3, numVisits=54, meanQ=6.809631, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1428789 episodes
GETTING ACTION FROM:
action 2, numVisits=1491361, meanQ=5.896095, numObservations: 4
action 3, numVisits=214, meanQ=5.381402, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.582464 0.66405 0.600039 0.817146 0.521932 0.805682 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 392
Initial state: 0 0.793607 0.910712 0.628882 0.887305 0.641626 0.883434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1153024 episodes
GETTING ACTION FROM:
action 2, numVisits=1153014, meanQ=4.995334, numObservations: 3
action 1, numVisits=5, meanQ=0.196000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.793607 0.910712 0.628882 0.887305 0.641626 0.883434 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=84673, meanQ=5.603135, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1333978 episodes
GETTING ACTION FROM:
action 2, numVisits=1418651, meanQ=5.063682, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.793607 0.910712 0.628882 0.887305 0.641626 0.883434 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 393
Initial state: 0 0.689235 0.820373 0.0971473 0.640957 0.674722 0.832046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132243 episodes
GETTING ACTION FROM:
action 3, numVisits=1132207, meanQ=4.988057, numObservations: 4
action 2, numVisits=21, meanQ=2.713343, numObservations: 3
action -1, numVisits=11, meanQ=2.136700, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.689235 0.820373 0.0971473 0.640957 0.674722 0.832046 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 394
Initial state: 0 0.666122 0.892788 0.0022794 0.368356 0.685447 0.877054 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101492 episodes
GETTING ACTION FROM:
action 1, numVisits=1089600, meanQ=4.840748, numObservations: 4
action -1, numVisits=11880, meanQ=3.060342, numObservations: 1
action 3, numVisits=9, meanQ=0.331122, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.666122 0.892788 0.0022794 0.368356 0.685447 0.877054 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=79664, meanQ=3.554889, numObservations: 1
action 3, numVisits=9, meanQ=0.998889, numObservations: 2
action 2, numVisits=3, meanQ=-0.329967, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1428494 episodes
GETTING ACTION FROM:
action 2, numVisits=1427955, meanQ=6.031618, numObservations: 4
action 0, numVisits=80206, meanQ=3.526598, numObservations: 1
action 3, numVisits=9, meanQ=0.998889, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.666122 0.892788 0.0022794 0.368356 0.685447 0.877054 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 395
Initial state: 0 0.803354 0.528104 0.589682 0.871799 0.578021 0.824338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 778933 episodes
GETTING ACTION FROM:
action 0, numVisits=778919, meanQ=2.864702, numObservations: 1
action 2, numVisits=8, meanQ=-2.501250, numObservations: 2
action -1, numVisits=3, meanQ=-2.996600, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.803354 0.528104 0.589682 0.871799 0.578021 0.824338 w: 1
Observation: 0 0 0.592145 0 0.795232 0 0.796238 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=778293, meanQ=4.894369, numObservations: 4
action 0, numVisits=618, meanQ=1.860668, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=4, meanQ=-2.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1252994 episodes
GETTING ACTION FROM:
action 3, numVisits=2031287, meanQ=4.832951, numObservations: 4
action 0, numVisits=618, meanQ=1.860668, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=4, meanQ=-2.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.803354 0.528104 0.589682 0.871799 0.578021 0.824338 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 396
Initial state: 0 0.643312 0.886783 0.582286 0.0458282 0.676849 0.882945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104734 episodes
GETTING ACTION FROM:
action 1, numVisits=1104507, meanQ=4.843571, numObservations: 4
action 0, numVisits=132, meanQ=4.198865, numObservations: 1
action -1, numVisits=76, meanQ=3.993271, numObservations: 1
action 3, numVisits=13, meanQ=2.369238, numObservations: 2
action 2, numVisits=6, meanQ=1.663333, numObservations: 2
action: 1
Next state: 1 0.643312 0.886783 0.582286 0.0458282 0.676849 0.882945 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 397
Initial state: 0 0.680337 0.896814 0.592432 0.833222 0.872117 0.393051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129049 episodes
GETTING ACTION FROM:
action 1, numVisits=1129040, meanQ=4.995261, numObservations: 5
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.680337 0.896814 0.592432 0.833222 0.872117 0.393051 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 398
Initial state: 0 0.681581 0.818523 0.697504 0.848278 0.69944 0.870976 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128641 episodes
GETTING ACTION FROM:
action 2, numVisits=1128635, meanQ=4.926693, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.681581 0.818523 0.697504 0.848278 0.69944 0.870976 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 399
Initial state: 0 0.540417 0.870046 0.13217 0.321088 0.54257 0.868137 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132932 episodes
GETTING ACTION FROM:
action 3, numVisits=1132923, meanQ=4.898027, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.540417 0.870046 0.13217 0.321088 0.54257 0.868137 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=82779, meanQ=4.647756, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1425735 episodes
GETTING ACTION FROM:
action 1, numVisits=1508514, meanQ=5.747935, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.540417 0.870046 0.13217 0.321088 0.54257 0.868137 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 400
Initial state: 0 0.561597 0.82602 0.555843 0.801836 0.0192262 0.597725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1121401 episodes
GETTING ACTION FROM:
action 3, numVisits=1121339, meanQ=4.981936, numObservations: 5
action 0, numVisits=36, meanQ=3.700723, numObservations: 1
action -1, numVisits=21, meanQ=3.338922, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.561597 0.82602 0.555843 0.801836 0.0192262 0.597725 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=29251, meanQ=7.758757, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1426420 episodes
GETTING ACTION FROM:
action 1, numVisits=1455666, meanQ=5.791997, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.561597 0.82602 0.555843 0.801836 0.0192262 0.597725 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 401
Initial state: 0 0.640744 0.895804 0.645177 0.846254 0.0417755 0.438257 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1121753 episodes
GETTING ACTION FROM:
action 3, numVisits=1121744, meanQ=4.920255, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.640744 0.895804 0.645177 0.846254 0.0417755 0.438257 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=142024, meanQ=8.399442, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1423784 episodes
GETTING ACTION FROM:
action 1, numVisits=1565806, meanQ=5.947799, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.640744 0.895804 0.645177 0.846254 0.0417755 0.438257 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 402
Initial state: 0 0.582724 0.823618 0.537809 0.872704 0.489388 0.662431 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129688 episodes
GETTING ACTION FROM:
action 1, numVisits=1114513, meanQ=4.904187, numObservations: 4
action -1, numVisits=15169, meanQ=3.145233, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.582724 0.823618 0.537809 0.872704 0.489388 0.662431 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 403
Initial state: 0 0.535985 0.454342 0.612035 0.808898 0.59958 0.880553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1155390 episodes
GETTING ACTION FROM:
action 3, numVisits=1155356, meanQ=4.915375, numObservations: 3
action -1, numVisits=23, meanQ=3.225358, numObservations: 1
action 1, numVisits=8, meanQ=1.500000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.535985 0.454342 0.612035 0.808898 0.59958 0.880553 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 404
Initial state: 0 0.595842 0.835367 0.606097 0.883509 0.325958 0.801751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131791 episodes
GETTING ACTION FROM:
action 3, numVisits=1131718, meanQ=4.993616, numObservations: 5
action 0, numVisits=50, meanQ=3.930363, numObservations: 1
action -1, numVisits=21, meanQ=3.358772, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.595842 0.835367 0.606097 0.883509 0.325958 0.801751 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=62219, meanQ=7.864334, numObservations: 4
action 1, numVisits=52, meanQ=6.760000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1434027 episodes
GETTING ACTION FROM:
action 2, numVisits=1495752, meanQ=6.134783, numObservations: 4
action 1, numVisits=544, meanQ=5.815008, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.595842 0.835367 0.606097 0.883509 0.325958 0.801751 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 405
Initial state: 0 0.134907 0.735183 0.534937 0.880549 0.504495 0.825004 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1147036 episodes
GETTING ACTION FROM:
action 1, numVisits=1146961, meanQ=4.969460, numObservations: 4
action -1, numVisits=64, meanQ=4.033572, numObservations: 1
action 3, numVisits=8, meanQ=1.747513, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.134907 0.735183 0.534937 0.880549 0.504495 0.825004 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=175943, meanQ=8.297380, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1434867 episodes
GETTING ACTION FROM:
action 2, numVisits=1610806, meanQ=6.478662, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.134907 0.735183 0.534937 0.880549 0.504495 0.825004 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 406
Initial state: 0 0.658061 0.89431 0.938756 0.850939 0.52762 0.803695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1157098 episodes
GETTING ACTION FROM:
action 2, numVisits=1157002, meanQ=4.996405, numObservations: 3
action -1, numVisits=54, meanQ=3.959793, numObservations: 1
action 0, numVisits=33, meanQ=3.628174, numObservations: 1
action 3, numVisits=8, meanQ=0.997500, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.658061 0.89431 0.938756 0.850939 0.52762 0.803695 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 407
Initial state: 0 0.247895 0.860326 0.554695 0.839101 0.514659 0.886643 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 772906 episodes
GETTING ACTION FROM:
action -1, numVisits=772884, meanQ=2.832766, numObservations: 1
action 3, numVisits=7, meanQ=-0.145714, numObservations: 3
action 2, numVisits=7, meanQ=-0.145714, numObservations: 3
action 1, numVisits=6, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: -1
Next state: 0 0.247895 0.860326 0.554695 0.839101 0.514659 0.886643 w: 1
Observation: 0 0.222558 0 0.652491 0 0.506114 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=772877, meanQ=4.886833, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1218307 episodes
GETTING ACTION FROM:
action 3, numVisits=1991184, meanQ=4.950037, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.247895 0.860326 0.554695 0.839101 0.514659 0.886643 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 408
Initial state: 0 0.555652 0.895044 0.263131 0.096021 0.56274 0.86328 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128923 episodes
GETTING ACTION FROM:
action 3, numVisits=1128867, meanQ=4.989827, numObservations: 5
action 0, numVisits=50, meanQ=3.883881, numObservations: 1
action 1, numVisits=3, meanQ=0.330033, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.555652 0.895044 0.263131 0.096021 0.56274 0.86328 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 409
Initial state: 0 0.0588366 0.242225 0.610964 0.878541 0.522986 0.842958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142985 episodes
GETTING ACTION FROM:
action 2, numVisits=1142769, meanQ=4.918590, numObservations: 4
action 0, numVisits=125, meanQ=4.249340, numObservations: 1
action 3, numVisits=58, meanQ=3.855871, numObservations: 4
action -1, numVisits=32, meanQ=3.597281, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0588366 0.242225 0.610964 0.878541 0.522986 0.842958 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 410
Initial state: 0 0.122094 0.404771 0.691987 0.889285 0.600978 0.886376 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1143971 episodes
GETTING ACTION FROM:
action 1, numVisits=1143964, meanQ=4.974402, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.122094 0.404771 0.691987 0.889285 0.600978 0.886376 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=145236, meanQ=8.398759, numObservations: 3
action 2, numVisits=7, meanQ=5.568571, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1449006 episodes
GETTING ACTION FROM:
action 3, numVisits=1594220, meanQ=5.876654, numObservations: 3
action 2, numVisits=25, meanQ=4.039200, numObservations: 3
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.122094 0.404771 0.691987 0.889285 0.600978 0.886376 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 411
Initial state: 0 0.633629 0.868255 0.525082 0.808117 0.104104 0.0206711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1132577 episodes
GETTING ACTION FROM:
action 1, numVisits=1132480, meanQ=4.994711, numObservations: 5
action -1, numVisits=57, meanQ=3.978120, numObservations: 1
action 0, numVisits=27, meanQ=3.511286, numObservations: 1
action 3, numVisits=12, meanQ=2.658333, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.633629 0.868255 0.525082 0.808117 0.104104 0.0206711 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 412
Initial state: 0 0.579871 0.855443 0.83575 0.514383 0.500188 0.871118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1135233 episodes
GETTING ACTION FROM:
action 3, numVisits=1135092, meanQ=4.963940, numObservations: 3
action 0, numVisits=64, meanQ=4.036493, numObservations: 1
action 1, numVisits=52, meanQ=3.761100, numObservations: 3
action -1, numVisits=15, meanQ=2.966291, numObservations: 1
action 2, numVisits=10, meanQ=2.598000, numObservations: 3
action: 3
Next state: 1 0.579871 0.855443 0.83575 0.514383 0.500188 0.871118 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 413
Initial state: 0 0.507599 0.426392 0.685659 0.856208 0.552691 0.893748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134886 episodes
GETTING ACTION FROM:
action 1, numVisits=1134831, meanQ=4.968252, numObservations: 4
action 0, numVisits=39, meanQ=3.746651, numObservations: 1
action 2, numVisits=13, meanQ=2.536923, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.507599 0.426392 0.685659 0.856208 0.552691 0.893748 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 414
Initial state: 0 0.562871 0.749041 0.658861 0.877088 0.525884 0.803746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117856 episodes
GETTING ACTION FROM:
action 3, numVisits=1117846, meanQ=5.004131, numObservations: 5
action 2, numVisits=5, meanQ=1.000020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.562871 0.749041 0.658861 0.877088 0.525884 0.803746 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 415
Initial state: 0 0.119262 0.21586 0.665838 0.841028 0.567008 0.821562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1118719 episodes
GETTING ACTION FROM:
action 2, numVisits=1118697, meanQ=4.900168, numObservations: 5
action 1, numVisits=9, meanQ=1.886667, numObservations: 4
action 3, numVisits=9, meanQ=1.886667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.119262 0.21586 0.665838 0.841028 0.567008 0.821562 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 416
Initial state: 0 0.647136 0.860124 0.512646 0.812633 0.324267 0.244874 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131166 episodes
GETTING ACTION FROM:
action 2, numVisits=1131076, meanQ=5.119154, numObservations: 5
action -1, numVisits=86, meanQ=4.292771, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.647136 0.860124 0.512646 0.812633 0.324267 0.244874 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 417
Initial state: 0 0.580839 0.89126 0.574839 0.872711 0.651254 0.0571086 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124647 episodes
GETTING ACTION FROM:
action 2, numVisits=1124551, meanQ=5.115960, numObservations: 5
action 0, numVisits=33, meanQ=3.770173, numObservations: 1
action 1, numVisits=59, meanQ=3.502212, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.580839 0.89126 0.574839 0.872711 0.651254 0.0571086 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=74018, meanQ=7.305624, numObservations: 3
action 3, numVisits=7, meanQ=4.427143, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1385340 episodes
GETTING ACTION FROM:
action 3, numVisits=1166559, meanQ=5.832927, numObservations: 4
action 2, numVisits=292804, meanQ=5.685884, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.580839 0.89126 0.574839 0.872711 0.651254 0.0571086 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 418
Initial state: 0 0.460809 0.718605 0.652519 0.897156 0.617751 0.884756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129941 episodes
GETTING ACTION FROM:
action 1, numVisits=1129895, meanQ=4.911134, numObservations: 5
action -1, numVisits=37, meanQ=3.597095, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.460809 0.718605 0.652519 0.897156 0.617751 0.884756 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 419
Initial state: 0 0.689618 0.251614 0.584764 0.855793 0.541481 0.868503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1144631 episodes
GETTING ACTION FROM:
action 1, numVisits=1144553, meanQ=4.942880, numObservations: 4
action 2, numVisits=72, meanQ=2.914039, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.689618 0.251614 0.584764 0.855793 0.541481 0.868503 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 420
Initial state: 0 0.97558 0.889177 0.666782 0.85386 0.614584 0.860706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131165 episodes
GETTING ACTION FROM:
action 1, numVisits=1131159, meanQ=4.920475, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.97558 0.889177 0.666782 0.85386 0.614584 0.860706 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 421
Initial state: 0 0.420346 0.448829 0.669154 0.896979 0.560013 0.892247 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1143546 episodes
GETTING ACTION FROM:
action 3, numVisits=1143407, meanQ=4.984026, numObservations: 4
action -1, numVisits=131, meanQ=4.337804, numObservations: 1
action 1, numVisits=5, meanQ=0.602040, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.420346 0.448829 0.669154 0.896979 0.560013 0.892247 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=83392, meanQ=5.593056, numObservations: 4
action 1, numVisits=9, meanQ=3.221111, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 1424932 episodes
GETTING ACTION FROM:
action 1, numVisits=1401664, meanQ=5.814659, numObservations: 4
action 3, numVisits=106669, meanQ=5.468608, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.420346 0.448829 0.669154 0.896979 0.560013 0.892247 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=18713, meanQ=7.992403, numObservations: 4
action 2, numVisits=42, meanQ=6.997390, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1448100 episodes
GETTING ACTION FROM:
action 3, numVisits=1465889, meanQ=5.549256, numObservations: 4
action 2, numVisits=964, meanQ=5.302324, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.420346 0.448829 0.669154 0.896979 0.560013 0.892247 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 422
Initial state: 0 0.529774 0.803898 0.0371321 0.309244 0.608189 0.873403 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1135487 episodes
GETTING ACTION FROM:
action 1, numVisits=1135465, meanQ=4.920805, numObservations: 4
action 0, numVisits=11, meanQ=2.407300, numObservations: 2
action 2, numVisits=8, meanQ=1.996250, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.529774 0.803898 0.0371321 0.309244 0.608189 0.873403 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 423
Initial state: 0 0.650213 0.854128 0.581705 0.830899 0.316384 0.824694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139532 episodes
GETTING ACTION FROM:
action 2, numVisits=1139410, meanQ=4.913522, numObservations: 4
action 0, numVisits=118, meanQ=4.232316, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.650213 0.854128 0.581705 0.830899 0.316384 0.824694 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 424
Initial state: 0 0.557177 0.804779 0.536824 0.859084 0.193199 0.787521 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105662 episodes
GETTING ACTION FROM:
action 2, numVisits=1105623, meanQ=4.855657, numObservations: 4
action 0, numVisits=35, meanQ=3.551374, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.557177 0.804779 0.536824 0.859084 0.193199 0.787521 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 425
Initial state: 0 0.592039 0.83168 0.582163 0.826941 0.906744 0.263946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1126775 episodes
GETTING ACTION FROM:
action 3, numVisits=1126675, meanQ=4.930375, numObservations: 5
action -1, numVisits=54, meanQ=3.919659, numObservations: 1
action 0, numVisits=41, meanQ=3.752253, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.592039 0.83168 0.582163 0.826941 0.906744 0.263946 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 426
Initial state: 0 0.513616 0.816469 0.222629 0.552473 0.632438 0.802313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095091 episodes
GETTING ACTION FROM:
action 2, numVisits=1094922, meanQ=4.834228, numObservations: 5
action -1, numVisits=129, meanQ=4.180271, numObservations: 1
action 0, numVisits=26, meanQ=3.341564, numObservations: 1
action 1, numVisits=12, meanQ=2.163342, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 2 0.513616 0.816469 0.222629 0.552473 0.632438 0.802313 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 427
Initial state: 0 0.571148 0.879361 0.538664 0.867985 0.982418 0.484079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099205 episodes
GETTING ACTION FROM:
action 3, numVisits=1099120, meanQ=4.809751, numObservations: 4
action 0, numVisits=49, meanQ=3.730860, numObservations: 1
action -1, numVisits=29, meanQ=3.414530, numObservations: 1
action 1, numVisits=6, meanQ=1.663333, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.571148 0.879361 0.538664 0.867985 0.982418 0.484079 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 428
Initial state: 0 0.384968 0.759198 0.521117 0.886743 0.526774 0.885664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128517 episodes
GETTING ACTION FROM:
action 3, numVisits=1128511, meanQ=4.920002, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.384968 0.759198 0.521117 0.886743 0.526774 0.885664 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5037, meanQ=7.247921, numObservations: 3
action 1, numVisits=19, meanQ=3.741053, numObservations: 5
action 2, numVisits=4, meanQ=2.497525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1408239 episodes
GETTING ACTION FROM:
action 1, numVisits=1366523, meanQ=6.116344, numObservations: 5
action 3, numVisits=46737, meanQ=5.049568, numObservations: 4
action 2, numVisits=37, meanQ=3.594330, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 0 0.384968 0.759198 0.521117 0.886743 0.526774 0.885664 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=15847, meanQ=8.520355, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1461617 episodes
GETTING ACTION FROM:
action 2, numVisits=1477462, meanQ=5.963780, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.384968 0.759198 0.521117 0.886743 0.526774 0.885664 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 429
Initial state: 0 0.65137 0.859115 0.689378 0.803307 0.80606 0.657577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 782819 episodes
GETTING ACTION FROM:
action 0, numVisits=782809, meanQ=2.945994, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.65137 0.859115 0.689378 0.803307 0.80606 0.657577 w: 1
Observation: 0 0 0.891607 0 0.8264 0 0.689944 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=782773, meanQ=4.996481, numObservations: 4
action -1, numVisits=25, meanQ=3.478909, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=4, meanQ=-0.007500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1245003 episodes
GETTING ACTION FROM:
action 2, numVisits=2027776, meanQ=5.023001, numObservations: 4
action -1, numVisits=25, meanQ=3.478909, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=4, meanQ=-0.007500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.65137 0.859115 0.689378 0.803307 0.80606 0.657577 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 430
Initial state: 0 0.521796 0.876 0.340283 0.293602 0.669556 0.879549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110906 episodes
GETTING ACTION FROM:
action 2, numVisits=1110900, meanQ=4.895187, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.521796 0.876 0.340283 0.293602 0.669556 0.879549 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=169973, meanQ=8.291743, numObservations: 4
action 3, numVisits=25, meanQ=6.595200, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1428384 episodes
GETTING ACTION FROM:
action 1, numVisits=1598187, meanQ=6.122346, numObservations: 4
action 3, numVisits=191, meanQ=5.562881, numObservations: 5
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.521796 0.876 0.340283 0.293602 0.669556 0.879549 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 431
Initial state: 0 0.187465 0.349118 0.691339 0.877739 0.555311 0.82368 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128436 episodes
GETTING ACTION FROM:
action 3, numVisits=1128385, meanQ=5.101705, numObservations: 5
action -1, numVisits=47, meanQ=3.980966, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.187465 0.349118 0.691339 0.877739 0.555311 0.82368 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 432
Initial state: 0 0.21992 0.884021 0.606283 0.888054 0.593359 0.808303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1150251 episodes
GETTING ACTION FROM:
action 3, numVisits=1150141, meanQ=5.018906, numObservations: 4
action 1, numVisits=105, meanQ=4.161812, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.21992 0.884021 0.606283 0.888054 0.593359 0.808303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 433
Initial state: 0 0.632167 0.889644 0.751355 0.701289 0.584581 0.806937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128770 episodes
GETTING ACTION FROM:
action 2, numVisits=1128662, meanQ=4.977563, numObservations: 5
action 1, numVisits=87, meanQ=4.066084, numObservations: 4
action 3, numVisits=17, meanQ=2.881176, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.632167 0.889644 0.751355 0.701289 0.584581 0.806937 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 434
Initial state: 0 0.692103 0.876645 0.679807 0.811398 0.229723 0.631117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139141 episodes
GETTING ACTION FROM:
action 3, numVisits=1138350, meanQ=4.955953, numObservations: 3
action 2, numVisits=549, meanQ=4.625203, numObservations: 4
action 1, numVisits=191, meanQ=4.416233, numObservations: 4
action 0, numVisits=49, meanQ=3.876148, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.692103 0.876645 0.679807 0.811398 0.229723 0.631117 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 435
Initial state: 0 0.0177264 0.15883 0.632309 0.809756 0.608284 0.809391 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1126830 episodes
GETTING ACTION FROM:
action 3, numVisits=1126806, meanQ=4.910126, numObservations: 5
action 0, numVisits=17, meanQ=2.812305, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.0177264 0.15883 0.632309 0.809756 0.608284 0.809391 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=9622, meanQ=6.026729, numObservations: 3
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1317601 episodes
GETTING ACTION FROM:
action 3, numVisits=1327221, meanQ=5.039632, numObservations: 5
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0177264 0.15883 0.632309 0.809756 0.608284 0.809391 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 436
Initial state: 0 0.537035 0.307527 0.538385 0.846795 0.614334 0.835035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139446 episodes
GETTING ACTION FROM:
action 1, numVisits=1139434, meanQ=4.985466, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.537035 0.307527 0.538385 0.846795 0.614334 0.835035 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 437
Initial state: 0 0.529181 0.85511 0.659071 0.81165 0.625071 0.0789809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1146650 episodes
GETTING ACTION FROM:
action 3, numVisits=1145208, meanQ=5.024335, numObservations: 4
action 0, numVisits=1436, meanQ=2.604713, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.529181 0.85511 0.659071 0.81165 0.625071 0.0789809 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 438
Initial state: 0 0.633026 0.841014 0.524614 0.862589 0.650894 0.16147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142831 episodes
GETTING ACTION FROM:
action 2, numVisits=1142794, meanQ=5.116289, numObservations: 4
action -1, numVisits=31, meanQ=3.730497, numObservations: 1
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.633026 0.841014 0.524614 0.862589 0.650894 0.16147 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=71841, meanQ=7.907796, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1424385 episodes
GETTING ACTION FROM:
action 3, numVisits=1496224, meanQ=6.150735, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.633026 0.841014 0.524614 0.862589 0.650894 0.16147 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 439
Initial state: 0 0.513138 0.805886 0.531636 0.802709 0.688944 0.576081 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145793 episodes
GETTING ACTION FROM:
action 1, numVisits=1145103, meanQ=4.911948, numObservations: 3
action 3, numVisits=627, meanQ=4.517253, numObservations: 5
action 2, numVisits=59, meanQ=3.870851, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.513138 0.805886 0.531636 0.802709 0.688944 0.576081 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 440
Initial state: 0 0.606026 0.878217 0.554708 0.833952 0.26476 0.0685169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1148785 episodes
GETTING ACTION FROM:
action 2, numVisits=1148779, meanQ=4.883020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.606026 0.878217 0.554708 0.833952 0.26476 0.0685169 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 441
Initial state: 0 0.623565 0.845605 0.00362133 0.546245 0.585362 0.893712 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1153124 episodes
GETTING ACTION FROM:
action 1, numVisits=1153045, meanQ=4.973053, numObservations: 3
action 0, numVisits=72, meanQ=4.088899, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.623565 0.845605 0.00362133 0.546245 0.585362 0.893712 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 442
Initial state: 0 0.539669 0.823927 0.466259 0.75367 0.62815 0.849419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105059 episodes
GETTING ACTION FROM:
action 1, numVisits=1105015, meanQ=4.822172, numObservations: 4
action -1, numVisits=37, meanQ=3.600286, numObservations: 1
action 3, numVisits=4, meanQ=-2.005000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.539669 0.823927 0.466259 0.75367 0.62815 0.849419 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 443
Initial state: 0 0.645577 0.715564 0.619374 0.810551 0.547191 0.897581 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 804806 episodes
GETTING ACTION FROM:
action 0, numVisits=804705, meanQ=5.851322, numObservations: 3
action -1, numVisits=87, meanQ=2.828448, numObservations: 1
action 3, numVisits=12, meanQ=1.165042, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.645577 0.715564 0.619374 0.810551 0.547191 0.897581 w: 1
Observation: 0 0 0.800417 0 0.854109 0 0.847981 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=289910, meanQ=7.723873, numObservations: 4
action 1, numVisits=3, meanQ=3.633333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1240219 episodes
GETTING ACTION FROM:
action 2, numVisits=1530116, meanQ=5.743186, numObservations: 4
action 1, numVisits=14, meanQ=3.272143, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.645577 0.715564 0.619374 0.810551 0.547191 0.897581 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 444
Initial state: 0 0.633153 0.836451 0.67316 0.846543 0.52892 0.730545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145335 episodes
GETTING ACTION FROM:
action 3, numVisits=1145329, meanQ=4.980631, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.633153 0.836451 0.67316 0.846543 0.52892 0.730545 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 445
Initial state: 0 0.457474 0.198949 0.525567 0.806046 0.572529 0.878586 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139928 episodes
GETTING ACTION FROM:
action 1, numVisits=1131922, meanQ=5.027100, numObservations: 4
action -1, numVisits=7991, meanQ=2.918907, numObservations: 1
action 3, numVisits=7, meanQ=0.428586, numObservations: 3
action 2, numVisits=6, meanQ=0.331667, numObservations: 4
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.457474 0.198949 0.525567 0.806046 0.572529 0.878586 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=173121, meanQ=8.296019, numObservations: 5
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1400849 episodes
GETTING ACTION FROM:
action 3, numVisits=1573956, meanQ=6.040749, numObservations: 5
action 2, numVisits=14, meanQ=3.856429, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.457474 0.198949 0.525567 0.806046 0.572529 0.878586 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 446
Initial state: 0 0.548388 0.806828 0.0416992 0.814763 0.585422 0.809441 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131033 episodes
GETTING ACTION FROM:
action 2, numVisits=1131026, meanQ=4.960829, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.548388 0.806828 0.0416992 0.814763 0.585422 0.809441 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 447
Initial state: 0 0.576879 0.890341 0.512181 0.834547 0.703669 0.983809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1131146 episodes
GETTING ACTION FROM:
action 2, numVisits=1131074, meanQ=4.991652, numObservations: 5
action 3, numVisits=44, meanQ=3.482957, numObservations: 4
action 1, numVisits=24, meanQ=3.166671, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.576879 0.890341 0.512181 0.834547 0.703669 0.983809 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 448
Initial state: 0 0.692948 0.572192 0.612059 0.872709 0.662985 0.83124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1138378 episodes
GETTING ACTION FROM:
action 1, numVisits=1138261, meanQ=4.899252, numObservations: 4
action -1, numVisits=113, meanQ=4.190560, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.692948 0.572192 0.612059 0.872709 0.662985 0.83124 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 449
Initial state: 0 0.912316 0.481005 0.66018 0.815386 0.502719 0.886905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1119257 episodes
GETTING ACTION FROM:
action 2, numVisits=1119247, meanQ=4.851137, numObservations: 5
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.912316 0.481005 0.66018 0.815386 0.502719 0.886905 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=70244, meanQ=3.982657, numObservations: 4
action 1, numVisits=182, meanQ=3.455543, numObservations: 4
action 0, numVisits=82, meanQ=3.255333, numObservations: 1
action 2, numVisits=8, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1417590 episodes
GETTING ACTION FROM:
action 3, numVisits=1487834, meanQ=5.805926, numObservations: 4
action 1, numVisits=182, meanQ=3.455543, numObservations: 4
action 0, numVisits=82, meanQ=3.255333, numObservations: 1
action 2, numVisits=8, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.912316 0.481005 0.66018 0.815386 0.502719 0.886905 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 450
Initial state: 0 0.683751 0.833599 0.537826 0.867309 0.593552 0.879188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1149142 episodes
GETTING ACTION FROM:
action 2, numVisits=1149136, meanQ=5.000908, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.683751 0.833599 0.537826 0.867309 0.593552 0.879188 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 451
Initial state: 0 0.472586 0.390818 0.677744 0.839437 0.53764 0.893676 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1144673 episodes
GETTING ACTION FROM:
action 1, numVisits=1144667, meanQ=4.982734, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.472586 0.390818 0.677744 0.839437 0.53764 0.893676 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=111482, meanQ=8.538698, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1453458 episodes
GETTING ACTION FROM:
action 2, numVisits=1564937, meanQ=5.916969, numObservations: 3
action 3, numVisits=3, meanQ=0.330033, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.472586 0.390818 0.677744 0.839437 0.53764 0.893676 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 452
Initial state: 0 0.893511 0.606919 0.542915 0.833937 0.657459 0.856083 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145804 episodes
GETTING ACTION FROM:
action 2, numVisits=1145727, meanQ=4.952020, numObservations: 3
action 0, numVisits=44, meanQ=3.792112, numObservations: 1
action 3, numVisits=27, meanQ=3.148907, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.893511 0.606919 0.542915 0.833937 0.657459 0.856083 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 453
Initial state: 0 0.697189 0.89111 0.640354 0.647264 0.612105 0.829367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095269 episodes
GETTING ACTION FROM:
action 1, numVisits=1095262, meanQ=4.826350, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.697189 0.89111 0.640354 0.647264 0.612105 0.829367 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 454
Initial state: 0 0.629757 0.861904 0.338564 0.414695 0.653996 0.807239 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130161 episodes
GETTING ACTION FROM:
action 3, numVisits=1130145, meanQ=4.902537, numObservations: 4
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action 1, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.629757 0.861904 0.338564 0.414695 0.653996 0.807239 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 455
Initial state: 0 0.97985 0.502015 0.518893 0.864207 0.538822 0.81112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134726 episodes
GETTING ACTION FROM:
action 3, numVisits=1134678, meanQ=4.987484, numObservations: 4
action -1, numVisits=41, meanQ=3.800599, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.97985 0.502015 0.518893 0.864207 0.538822 0.81112 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 456
Initial state: 0 0.631481 0.821086 0.561718 0.810485 0.147966 0.790632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 772484 episodes
GETTING ACTION FROM:
action 0, numVisits=768408, meanQ=2.847541, numObservations: 1
action -1, numVisits=4067, meanQ=2.728875, numObservations: 1
action 1, numVisits=6, meanQ=-1.670000, numObservations: 3
action 3, numVisits=2, meanQ=-4.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.631481 0.821086 0.561718 0.810485 0.147966 0.790632 w: 1
Observation: 0 0 0.812517 0 0.802297 0 0.849289 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=768346, meanQ=4.900282, numObservations: 5
action 0, numVisits=57, meanQ=3.914189, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1230207 episodes
GETTING ACTION FROM:
action 2, numVisits=1998553, meanQ=4.940643, numObservations: 5
action 0, numVisits=57, meanQ=3.914189, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.631481 0.821086 0.561718 0.810485 0.147966 0.790632 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 457
Initial state: 0 0.553847 0.832725 0.624793 0.802727 0.420722 0.889901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1150466 episodes
GETTING ACTION FROM:
action 3, numVisits=1150451, meanQ=4.972878, numObservations: 3
action 0, numVisits=10, meanQ=2.488000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.553847 0.832725 0.624793 0.802727 0.420722 0.889901 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=175831, meanQ=8.293925, numObservations: 5
action 1, numVisits=46, meanQ=7.210872, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1410958 episodes
GETTING ACTION FROM:
action 2, numVisits=1586714, meanQ=6.253009, numObservations: 5
action 1, numVisits=119, meanQ=5.465716, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.553847 0.832725 0.624793 0.802727 0.420722 0.889901 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 458
Initial state: 0 0.698691 0.875808 0.955819 0.699891 0.683477 0.88834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142912 episodes
GETTING ACTION FROM:
action 1, numVisits=1142888, meanQ=5.131444, numObservations: 4
action 3, numVisits=11, meanQ=2.808182, numObservations: 2
action 0, numVisits=10, meanQ=2.353030, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.698691 0.875808 0.955819 0.699891 0.683477 0.88834 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 459
Initial state: 0 0.396505 0.074341 0.695934 0.886333 0.634652 0.864938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1122500 episodes
GETTING ACTION FROM:
action 1, numVisits=1122494, meanQ=4.922609, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.396505 0.074341 0.695934 0.886333 0.634652 0.864938 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=142309, meanQ=8.372008, numObservations: 4
action 3, numVisits=25, meanQ=6.919208, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1427389 episodes
GETTING ACTION FROM:
action 2, numVisits=1359841, meanQ=6.114999, numObservations: 4
action 3, numVisits=209880, meanQ=6.104918, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.396505 0.074341 0.695934 0.886333 0.634652 0.864938 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=32554, meanQ=7.658140, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1454588 episodes
GETTING ACTION FROM:
action 2, numVisits=1487139, meanQ=5.285423, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.396505 0.074341 0.695934 0.886333 0.634652 0.864938 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 460
Initial state: 0 0.260545 0.438048 0.63358 0.863713 0.586348 0.880118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133841 episodes
GETTING ACTION FROM:
action 1, numVisits=1133780, meanQ=4.992815, numObservations: 5
action 0, numVisits=32, meanQ=3.662254, numObservations: 1
action 3, numVisits=25, meanQ=3.476408, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.260545 0.438048 0.63358 0.863713 0.586348 0.880118 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=83809, meanQ=8.545762, numObservations: 3
action 3, numVisits=27632, meanQ=8.527519, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1449958 episodes
GETTING ACTION FROM:
action 2, numVisits=1308182, meanQ=6.108562, numObservations: 3
action 3, numVisits=253215, meanQ=6.100058, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.260545 0.438048 0.63358 0.863713 0.586348 0.880118 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 461
Initial state: 0 0.3213 0.35369 0.578343 0.89648 0.58351 0.844006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137345 episodes
GETTING ACTION FROM:
action 1, numVisits=1137289, meanQ=4.982116, numObservations: 4
action 0, numVisits=28, meanQ=3.501798, numObservations: 1
action -1, numVisits=26, meanQ=3.465318, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.3213 0.35369 0.578343 0.89648 0.58351 0.844006 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=111387, meanQ=8.536592, numObservations: 3
action 3, numVisits=18, meanQ=6.777233, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1418752 episodes
GETTING ACTION FROM:
action 3, numVisits=403069, meanQ=6.116156, numObservations: 3
action 2, numVisits=1127086, meanQ=6.045052, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.3213 0.35369 0.578343 0.89648 0.58351 0.844006 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 462
Initial state: 0 0.685733 0.0849549 0.562348 0.834815 0.523559 0.845251 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1152057 episodes
GETTING ACTION FROM:
action 3, numVisits=1152019, meanQ=4.965174, numObservations: 3
action 0, numVisits=26, meanQ=3.482390, numObservations: 1
action 1, numVisits=9, meanQ=1.886667, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.685733 0.0849549 0.562348 0.834815 0.523559 0.845251 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 463
Initial state: 0 0.311947 0.137218 0.662206 0.813522 0.595927 0.8263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1133970 episodes
GETTING ACTION FROM:
action 2, numVisits=1133888, meanQ=4.983915, numObservations: 4
action 0, numVisits=35, meanQ=3.704963, numObservations: 1
action 1, numVisits=34, meanQ=3.699718, numObservations: 3
action 3, numVisits=11, meanQ=2.088182, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.311947 0.137218 0.662206 0.813522 0.595927 0.8263 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 464
Initial state: 0 0.572912 0.849409 0.193514 0.569668 0.522585 0.856873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129942 episodes
GETTING ACTION FROM:
action 3, numVisits=1129828, meanQ=4.919978, numObservations: 5
action -1, numVisits=75, meanQ=4.055768, numObservations: 1
action 1, numVisits=36, meanQ=3.380558, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.572912 0.849409 0.193514 0.569668 0.522585 0.856873 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 465
Initial state: 0 0.657101 0.7405 0.553106 0.892336 0.559512 0.849576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 773880 episodes
GETTING ACTION FROM:
action -1, numVisits=773832, meanQ=2.891868, numObservations: 1
action 1, numVisits=31, meanQ=1.251619, numObservations: 4
action 3, numVisits=11, meanQ=0.454564, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action: -1
Next state: 0 0.657101 0.7405 0.553106 0.892336 0.559512 0.849576 w: 1
Observation: 0 0.589995 0 0.48528 0 0.478385 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=773820, meanQ=4.936216, numObservations: 5
action 2, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1203290 episodes
GETTING ACTION FROM:
action 3, numVisits=1977110, meanQ=4.964986, numObservations: 5
action 2, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.657101 0.7405 0.553106 0.892336 0.559512 0.849576 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 466
Initial state: 0 0.541762 0.873243 0.975319 0.0899296 0.657456 0.807133 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1125138 episodes
GETTING ACTION FROM:
action 1, numVisits=1125086, meanQ=4.914149, numObservations: 5
action 0, numVisits=48, meanQ=3.828794, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.541762 0.873243 0.975319 0.0899296 0.657456 0.807133 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 467
Initial state: 0 0.618243 0.840925 0.545305 0.973686 0.606264 0.870541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1156628 episodes
GETTING ACTION FROM:
action 1, numVisits=1154662, meanQ=4.928755, numObservations: 3
action 0, numVisits=1961, meanQ=2.770304, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.618243 0.840925 0.545305 0.973686 0.606264 0.870541 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 468
Initial state: 0 0.962033 0.933925 0.530203 0.832246 0.662637 0.814628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1139788 episodes
GETTING ACTION FROM:
action 3, numVisits=1139660, meanQ=4.992190, numObservations: 4
action 0, numVisits=123, meanQ=4.318998, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.962033 0.933925 0.530203 0.832246 0.662637 0.814628 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 469
Initial state: 0 0.545802 0.849847 0.597929 0.872894 0.648988 0.624667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1135314 episodes
GETTING ACTION FROM:
action 3, numVisits=1128011, meanQ=4.900175, numObservations: 4
action -1, numVisits=7284, meanQ=2.885351, numObservations: 1
action 1, numVisits=15, meanQ=1.247333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 3
Next state: 0 0.545802 0.849847 0.597929 0.872894 0.648988 0.624667 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=143106, meanQ=8.397400, numObservations: 3
action 2, numVisits=50, meanQ=7.394606, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1431782 episodes
GETTING ACTION FROM:
action 2, numVisits=112397, meanQ=5.950473, numObservations: 5
action 1, numVisits=1462539, meanQ=5.870365, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.545802 0.849847 0.597929 0.872894 0.648988 0.624667 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 470
Initial state: 0 0.665535 0.820804 0.304563 0.743757 0.513228 0.857159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130580 episodes
GETTING ACTION FROM:
action 3, numVisits=1127078, meanQ=4.979241, numObservations: 5
action 0, numVisits=3493, meanQ=2.943258, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.665535 0.820804 0.304563 0.743757 0.513228 0.857159 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 471
Initial state: 0 0.598271 0.85694 0.691061 0.895469 0.400254 0.287131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1150101 episodes
GETTING ACTION FROM:
action 3, numVisits=1150085, meanQ=4.954500, numObservations: 3
action -1, numVisits=12, meanQ=2.565000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.598271 0.85694 0.691061 0.895469 0.400254 0.287131 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=175996, meanQ=8.294134, numObservations: 4
action 2, numVisits=43, meanQ=7.181165, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1433106 episodes
GETTING ACTION FROM:
action 1, numVisits=1609017, meanQ=6.090931, numObservations: 4
action 2, numVisits=125, meanQ=5.397761, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.598271 0.85694 0.691061 0.895469 0.400254 0.287131 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 472
Initial state: 0 0.619642 0.887452 0.428776 0.791787 0.661052 0.806663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142417 episodes
GETTING ACTION FROM:
action 2, numVisits=1141335, meanQ=4.975148, numObservations: 4
action 3, numVisits=1005, meanQ=4.744684, numObservations: 4
action 0, numVisits=55, meanQ=3.960597, numObservations: 1
action -1, numVisits=18, meanQ=3.014316, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 0 0.619642 0.887452 0.428776 0.791787 0.661052 0.806663 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=174398, meanQ=8.285792, numObservations: 4
action 3, numVisits=16, meanQ=6.500006, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1428918 episodes
GETTING ACTION FROM:
action 1, numVisits=1602543, meanQ=6.066340, numObservations: 4
action 3, numVisits=787, meanQ=5.793535, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.619642 0.887452 0.428776 0.791787 0.661052 0.806663 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 473
Initial state: 0 0.652449 0.852272 0.452266 0.200855 0.631026 0.814499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137646 episodes
GETTING ACTION FROM:
action 1, numVisits=1132914, meanQ=4.930756, numObservations: 4
action -1, numVisits=4728, meanQ=2.723395, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.652449 0.852272 0.452266 0.200855 0.631026 0.814499 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 474
Initial state: 0 0.333262 0.292874 0.599585 0.879901 0.623883 0.842824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 777189 episodes
GETTING ACTION FROM:
action -1, numVisits=775269, meanQ=2.925203, numObservations: 1
action 0, numVisits=1912, meanQ=2.765047, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.333262 0.292874 0.599585 0.879901 0.623883 0.842824 w: 1
Observation: 0 0.428327 0 0.662166 0 0.601921 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=772651, meanQ=4.972561, numObservations: 5
action 1, numVisits=2047, meanQ=4.812202, numObservations: 4
action 3, numVisits=524, meanQ=4.650853, numObservations: 4
action -1, numVisits=44, meanQ=3.823916, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1251542 episodes
GETTING ACTION FROM:
action 2, numVisits=2023657, meanQ=4.951596, numObservations: 5
action 1, numVisits=2065, meanQ=4.788638, numObservations: 4
action 3, numVisits=1041, meanQ=4.719780, numObservations: 4
action -1, numVisits=45, meanQ=3.781848, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.333262 0.292874 0.599585 0.879901 0.623883 0.842824 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 475
Initial state: 0 0.627331 0.89342 0.199904 0.0102932 0.630928 0.893087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1140011 episodes
GETTING ACTION FROM:
action 3, numVisits=1139976, meanQ=4.926371, numObservations: 4
action -1, numVisits=26, meanQ=3.407836, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=3, meanQ=0.330033, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.627331 0.89342 0.199904 0.0102932 0.630928 0.893087 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 476
Initial state: 0 0.712265 0.787166 0.516851 0.838684 0.555416 0.809065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1126462 episodes
GETTING ACTION FROM:
action 2, numVisits=1126395, meanQ=4.954517, numObservations: 5
action 3, numVisits=43, meanQ=3.778144, numObservations: 3
action 0, numVisits=21, meanQ=3.247680, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.712265 0.787166 0.516851 0.838684 0.555416 0.809065 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 477
Initial state: 0 0.552015 0.027856 0.569819 0.871649 0.644002 0.879198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1147927 episodes
GETTING ACTION FROM:
action 3, numVisits=1147921, meanQ=4.983482, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.552015 0.027856 0.569819 0.871649 0.644002 0.879198 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.661891 0.826033 0.574314 0.840303 0.377563 0.782295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124915 episodes
GETTING ACTION FROM:
action 3, numVisits=1124909, meanQ=4.991910, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.661891 0.826033 0.574314 0.840303 0.377563 0.782295 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=48920, meanQ=8.536364, numObservations: 3
action 1, numVisits=61561, meanQ=8.535997, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1423116 episodes
GETTING ACTION FROM:
action 1, numVisits=825345, meanQ=6.204639, numObservations: 5
action 2, numVisits=708250, meanQ=6.203910, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.661891 0.826033 0.574314 0.840303 0.377563 0.782295 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 479
Initial state: 0 0.670187 0.886481 0.758947 0.766861 0.590871 0.858921 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1136757 episodes
GETTING ACTION FROM:
action 3, numVisits=1136694, meanQ=4.963189, numObservations: 4
action 0, numVisits=48, meanQ=3.853753, numObservations: 1
action 1, numVisits=12, meanQ=2.163342, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.670187 0.886481 0.758947 0.766861 0.590871 0.858921 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 480
Initial state: 0 0.537615 0.872596 0.546713 0.829677 0.964745 0.22128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 785217 episodes
GETTING ACTION FROM:
action -1, numVisits=784648, meanQ=2.872339, numObservations: 1
action 0, numVisits=557, meanQ=2.566430, numObservations: 1
action 1, numVisits=5, meanQ=-0.597980, numObservations: 3
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action: -1
Next state: 0 0.537615 0.872596 0.546713 0.829677 0.964745 0.22128 w: 1
Observation: 0 0.612566 0 0.524399 0 1 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=784622, meanQ=4.943854, numObservations: 4
action 3, numVisits=20, meanQ=3.089505, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1249149 episodes
GETTING ACTION FROM:
action 2, numVisits=2033771, meanQ=4.929683, numObservations: 4
action 3, numVisits=20, meanQ=3.089505, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.537615 0.872596 0.546713 0.829677 0.964745 0.22128 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 481
Initial state: 0 0.690325 0.800544 0.657395 0.337289 0.55223 0.825714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1129053 episodes
GETTING ACTION FROM:
action 1, numVisits=1129044, meanQ=4.993151, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.690325 0.800544 0.657395 0.337289 0.55223 0.825714 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 482
Initial state: 0 0.0487452 0.155444 0.615247 0.859142 0.679308 0.862684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1155781 episodes
GETTING ACTION FROM:
action 3, numVisits=1155775, meanQ=4.984620, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.0487452 0.155444 0.615247 0.859142 0.679308 0.862684 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=84289, meanQ=5.599698, numObservations: 3
action 0, numVisits=119, meanQ=4.997936, numObservations: 1
action 2, numVisits=27, meanQ=2.335196, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1328424 episodes
GETTING ACTION FROM:
action 3, numVisits=1412706, meanQ=5.274134, numObservations: 3
action 0, numVisits=126, meanQ=4.609162, numObservations: 1
action 2, numVisits=27, meanQ=2.335196, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0487452 0.155444 0.615247 0.859142 0.679308 0.862684 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 483
Initial state: 0 0.646233 0.87954 0.657109 0.86972 0.520459 0.829975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1145366 episodes
GETTING ACTION FROM:
action 2, numVisits=1145327, meanQ=4.907867, numObservations: 4
action -1, numVisits=32, meanQ=3.496257, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.646233 0.87954 0.657109 0.86972 0.520459 0.829975 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 484
Initial state: 0 0.620906 0.941793 0.566354 0.820752 0.548542 0.817353 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 805509 episodes
GETTING ACTION FROM:
action 0, numVisits=798806, meanQ=5.913765, numObservations: 3
action 3, numVisits=6676, meanQ=4.851384, numObservations: 3
action -1, numVisits=25, meanQ=3.689248, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.620906 0.941793 0.566354 0.820752 0.548542 0.817353 w: 1
Observation: 0 0 0.920111 0 0.774948 0 0.897508 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=261534, meanQ=8.029812, numObservations: 5
action 2, numVisits=17, meanQ=5.704118, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1211593 episodes
GETTING ACTION FROM:
action 3, numVisits=1449068, meanQ=5.378809, numObservations: 5
action 2, numVisits=24021, meanQ=5.336353, numObservations: 4
action 0, numVisits=54, meanQ=4.344386, numObservations: 1
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.620906 0.941793 0.566354 0.820752 0.548542 0.817353 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 485
Initial state: 0 0.619464 0.852246 0.616946 0.248424 0.6068 0.859779 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 805210 episodes
GETTING ACTION FROM:
action 0, numVisits=805193, meanQ=5.761318, numObservations: 3
action 2, numVisits=13, meanQ=0.845392, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.619464 0.852246 0.616946 0.248424 0.6068 0.859779 w: 1
Observation: 0 0 0.808945 0 0.175423 0 0.831735 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=356134, meanQ=7.383747, numObservations: 3
action 2, numVisits=8, meanQ=0.997500, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1256359 episodes
GETTING ACTION FROM:
action 1, numVisits=1612491, meanQ=5.492943, numObservations: 3
action 2, numVisits=8, meanQ=0.997500, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.619464 0.852246 0.616946 0.248424 0.6068 0.859779 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 486
Initial state: 0 0.669721 0.86775 0.599856 0.804051 0.392311 0.140428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 780825 episodes
GETTING ACTION FROM:
action -1, numVisits=767887, meanQ=2.904805, numObservations: 1
action 0, numVisits=12900, meanQ=2.843257, numObservations: 1
action 1, numVisits=21, meanQ=1.290005, numObservations: 3
action 3, numVisits=14, meanQ=0.715021, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action: -1
Next state: 0 0.669721 0.86775 0.599856 0.804051 0.392311 0.140428 w: 1
Observation: 0 0.698943 0 0.633578 0 0.42983 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=767776, meanQ=4.969703, numObservations: 4
action 0, numVisits=56, meanQ=3.989553, numObservations: 1
action 2, numVisits=33, meanQ=3.407882, numObservations: 4
action -1, numVisits=20, meanQ=3.072208, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1235104 episodes
GETTING ACTION FROM:
action 3, numVisits=2002879, meanQ=4.979120, numObservations: 4
action 0, numVisits=57, meanQ=3.950557, numObservations: 1
action 2, numVisits=33, meanQ=3.407882, numObservations: 4
action -1, numVisits=20, meanQ=3.072208, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.669721 0.86775 0.599856 0.804051 0.392311 0.140428 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=304362, meanQ=8.303988, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1428161 episodes
GETTING ACTION FROM:
action 1, numVisits=1732520, meanQ=5.784894, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.669721 0.86775 0.599856 0.804051 0.392311 0.140428 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 487
Initial state: 0 0.79825 0.105759 0.580592 0.89716 0.627897 0.873181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1154422 episodes
GETTING ACTION FROM:
action 1, numVisits=1154416, meanQ=4.969853, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.79825 0.105759 0.580592 0.89716 0.627897 0.873181 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=176631, meanQ=8.217913, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1407675 episodes
GETTING ACTION FROM:
action 2, numVisits=1584303, meanQ=6.213112, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.79825 0.105759 0.580592 0.89716 0.627897 0.873181 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 488
Initial state: 0 0.573854 0.895045 0.621617 0.833069 0.733708 0.864623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1130417 episodes
GETTING ACTION FROM:
action 2, numVisits=1130325, meanQ=4.981180, numObservations: 5
action 0, numVisits=87, meanQ=4.173560, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.573854 0.895045 0.621617 0.833069 0.733708 0.864623 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 489
Initial state: 0 0.692531 0.829883 0.630339 0.818955 0.576331 0.217491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1142459 episodes
GETTING ACTION FROM:
action 2, numVisits=1142430, meanQ=4.990168, numObservations: 4
action 0, numVisits=25, meanQ=3.413134, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.692531 0.829883 0.630339 0.818955 0.576331 0.217491 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 490
Initial state: 0 0.382599 0.0581917 0.696272 0.883759 0.609139 0.892547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1128803 episodes
GETTING ACTION FROM:
action 2, numVisits=1128726, meanQ=4.966918, numObservations: 5
action -1, numVisits=49, meanQ=3.860180, numObservations: 1
action 3, numVisits=25, meanQ=3.471604, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.382599 0.0581917 0.696272 0.883759 0.609139 0.892547 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 491
Initial state: 0 0.612656 0.803113 0.410493 0.587769 0.513911 0.893831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134477 episodes
GETTING ACTION FROM:
action 1, numVisits=1134244, meanQ=4.972400, numObservations: 4
action 0, numVisits=200, meanQ=4.449550, numObservations: 1
action -1, numVisits=26, meanQ=3.464728, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.612656 0.803113 0.410493 0.587769 0.513911 0.893831 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 492
Initial state: 0 0.569386 0.857558 0.559159 0.8576 0.454869 0.701559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1135141 episodes
GETTING ACTION FROM:
action 3, numVisits=1135135, meanQ=4.986989, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.569386 0.857558 0.559159 0.8576 0.454869 0.701559 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=173860, meanQ=8.293846, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1423289 episodes
GETTING ACTION FROM:
action 2, numVisits=1597146, meanQ=5.848281, numObservations: 5
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.569386 0.857558 0.559159 0.8576 0.454869 0.701559 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 493
Initial state: 0 0.563081 0.830158 0.699497 0.810144 0.217685 0.304581 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1147317 episodes
GETTING ACTION FROM:
action 1, numVisits=1147230, meanQ=5.003070, numObservations: 4
action 0, numVisits=78, meanQ=4.160321, numObservations: 1
action 2, numVisits=6, meanQ=1.001683, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.563081 0.830158 0.699497 0.810144 0.217685 0.304581 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 494
Initial state: 0 0.503165 0.800651 0.695181 0.817474 0.127101 0.802799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1152859 episodes
GETTING ACTION FROM:
action 3, numVisits=1152853, meanQ=4.919440, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.503165 0.800651 0.695181 0.817474 0.127101 0.802799 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=176737, meanQ=8.282288, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1422092 episodes
GETTING ACTION FROM:
action 2, numVisits=1598720, meanQ=6.622811, numObservations: 4
action 1, numVisits=111, meanQ=5.861532, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.503165 0.800651 0.695181 0.817474 0.127101 0.802799 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 495
Initial state: 0 0.693394 0.88349 0.496293 0.308904 0.619845 0.814459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 780225 episodes
GETTING ACTION FROM:
action -1, numVisits=780216, meanQ=2.924351, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=2, meanQ=-8.950000, numObservations: 1
action: -1
Next state: 0 0.693394 0.88349 0.496293 0.308904 0.619845 0.814459 w: 1
Observation: 0 0.792426 0 0.493909 0 0.584639 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=780186, meanQ=4.975982, numObservations: 4
action 1, numVisits=18, meanQ=1.665567, numObservations: 4
action 2, numVisits=7, meanQ=0.711443, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1219069 episodes
GETTING ACTION FROM:
action 3, numVisits=1999255, meanQ=5.016898, numObservations: 4
action 1, numVisits=18, meanQ=1.665567, numObservations: 4
action 2, numVisits=7, meanQ=0.711443, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.693394 0.88349 0.496293 0.308904 0.619845 0.814459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 496
Initial state: 0 0.017215 0.938344 0.666948 0.842064 0.5291 0.803819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1137468 episodes
GETTING ACTION FROM:
action 1, numVisits=1137448, meanQ=4.898037, numObservations: 4
action 2, numVisits=12, meanQ=1.982500, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.017215 0.938344 0.666948 0.842064 0.5291 0.803819 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 497
Initial state: 0 0.539065 0.805588 0.33324 0.98677 0.595079 0.81124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120364 episodes
GETTING ACTION FROM:
action 3, numVisits=1120345, meanQ=4.952739, numObservations: 5
action 1, numVisits=14, meanQ=2.427857, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.539065 0.805588 0.33324 0.98677 0.595079 0.81124 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 498
Initial state: 0 0.539192 0.819112 0.579741 0.811428 0.142885 0.641202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1134355 episodes
GETTING ACTION FROM:
action 3, numVisits=1133531, meanQ=4.914347, numObservations: 3
action 2, numVisits=814, meanQ=4.635417, numObservations: 5
action 1, numVisits=6, meanQ=0.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.539192 0.819112 0.579741 0.811428 0.142885 0.641202 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=172946, meanQ=8.296983, numObservations: 5
action 2, numVisits=7, meanQ=3.285729, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1416196 episodes
GETTING ACTION FROM:
action 1, numVisits=1589140, meanQ=6.220230, numObservations: 5
action 2, numVisits=7, meanQ=3.285729, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.539192 0.819112 0.579741 0.811428 0.142885 0.641202 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 499
Initial state: 0 0.666652 0.87464 0.410849 0.96182 0.642963 0.860781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1135573 episodes
GETTING ACTION FROM:
action 3, numVisits=1135562, meanQ=4.995039, numObservations: 5
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.666652 0.87464 0.410849 0.96182 0.642963 0.860781 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 500
Initial state: 0 0.225951 0.237691 0.655414 0.815435 0.593704 0.803708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106481 episodes
GETTING ACTION FROM:
action 2, numVisits=1106463, meanQ=4.822186, numObservations: 4
action 3, numVisits=9, meanQ=1.432222, numObservations: 2
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.225951 0.237691 0.655414 0.815435 0.593704 0.803708 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
