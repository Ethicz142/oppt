Run # 1
Initial state: 0 0.672687 0.835311 0.776616 0.276968 0.654209 0.897404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2164485 episodes
GETTING ACTION FROM:
action 1, numVisits=2164165, meanQ=4.978139, numObservations: 3
action 3, numVisits=315, meanQ=4.547391, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.672687 0.835311 0.776616 0.276968 0.654209 0.897404 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.671639 0.869627 0.605263 0.89713 0.979107 0.114122 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254881 episodes
GETTING ACTION FROM:
action 3, numVisits=2254851, meanQ=4.904804, numObservations: 4
action -1, numVisits=24, meanQ=3.319322, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.671639 0.869627 0.605263 0.89713 0.979107 0.114122 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=165544, meanQ=4.688187, numObservations: 5
action -1, numVisits=61, meanQ=3.766643, numObservations: 1
action 2, numVisits=5, meanQ=1.396020, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2775781 episodes
GETTING ACTION FROM:
action 1, numVisits=2941325, meanQ=5.794787, numObservations: 5
action -1, numVisits=61, meanQ=3.766643, numObservations: 1
action 2, numVisits=5, meanQ=1.396020, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.671639 0.869627 0.605263 0.89713 0.979107 0.114122 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 3
Initial state: 0 0.581226 0.871426 0.688606 0.806776 0.466618 0.640987 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2223711 episodes
GETTING ACTION FROM:
action 1, numVisits=2223687, meanQ=4.898982, numObservations: 5
action -1, numVisits=11, meanQ=2.440000, numObservations: 1
action 2, numVisits=10, meanQ=2.201020, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.581226 0.871426 0.688606 0.806776 0.466618 0.640987 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 4
Initial state: 0 0.638675 0.856317 0.513523 0.8601 0.707447 0.434515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2131678 episodes
GETTING ACTION FROM:
action 1, numVisits=2123490, meanQ=4.596422, numObservations: 3
action 0, numVisits=8184, meanQ=2.927149, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.638675 0.856317 0.513523 0.8601 0.707447 0.434515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 5
Initial state: 0 0.614259 0.879163 0.935442 0.877533 0.575496 0.885896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246647 episodes
GETTING ACTION FROM:
action 3, numVisits=2246639, meanQ=4.991148, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.614259 0.879163 0.935442 0.877533 0.575496 0.885896 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 6
Initial state: 0 0.654839 0.893328 0.430569 0.655111 0.652668 0.851127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253846 episodes
GETTING ACTION FROM:
action 1, numVisits=2253815, meanQ=4.909963, numObservations: 4
action -1, numVisits=25, meanQ=3.354583, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.654839 0.893328 0.430569 0.655111 0.652668 0.851127 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 7
Initial state: 0 0.507641 0.801793 0.621993 0.8078 0.395327 0.12368 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2249377 episodes
GETTING ACTION FROM:
action 1, numVisits=2249347, meanQ=4.989998, numObservations: 5
action 2, numVisits=25, meanQ=3.144404, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.507641 0.801793 0.621993 0.8078 0.395327 0.12368 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 8
Initial state: 0 0.693291 0.82523 0.648232 0.824412 0.926178 0.535503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271365 episodes
GETTING ACTION FROM:
action 2, numVisits=2271331, meanQ=4.901437, numObservations: 4
action -1, numVisits=21, meanQ=3.127876, numObservations: 1
action 3, numVisits=9, meanQ=0.998889, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.693291 0.82523 0.648232 0.824412 0.926178 0.535503 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 9
Initial state: 0 0.559757 0.897083 0.668944 0.836179 0.154801 0.92163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2273754 episodes
GETTING ACTION FROM:
action 3, numVisits=2273655, meanQ=4.900053, numObservations: 3
action 0, numVisits=63, meanQ=3.924282, numObservations: 1
action 1, numVisits=30, meanQ=3.394003, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.559757 0.897083 0.668944 0.836179 0.154801 0.92163 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 10
Initial state: 0 0.0429256 0.570453 0.697865 0.82706 0.636943 0.860379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2276937 episodes
GETTING ACTION FROM:
action 2, numVisits=2276886, meanQ=4.910171, numObservations: 4
action -1, numVisits=47, meanQ=3.751512, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.0429256 0.570453 0.697865 0.82706 0.636943 0.860379 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=167005, meanQ=4.692350, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2847294 episodes
GETTING ACTION FROM:
action 3, numVisits=3014299, meanQ=5.915562, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0429256 0.570453 0.697865 0.82706 0.636943 0.860379 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 11
Initial state: 0 0.551859 0.818512 0.657145 0.712568 0.681866 0.860063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2270430 episodes
GETTING ACTION FROM:
action 1, numVisits=2270411, meanQ=4.988824, numObservations: 4
action 2, numVisits=14, meanQ=1.988593, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.551859 0.818512 0.657145 0.712568 0.681866 0.860063 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 12
Initial state: 0 0.335703 0.820544 0.50947 0.812391 0.549081 0.828263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2221833 episodes
GETTING ACTION FROM:
action 1, numVisits=2221827, meanQ=4.828928, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.335703 0.820544 0.50947 0.812391 0.549081 0.828263 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=338091, meanQ=8.318897, numObservations: 3
action 2, numVisits=5, meanQ=4.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2851419 episodes
GETTING ACTION FROM:
action 3, numVisits=3189502, meanQ=6.050676, numObservations: 3
action 2, numVisits=11, meanQ=3.180000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.335703 0.820544 0.50947 0.812391 0.549081 0.828263 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 13
Initial state: 0 0.772811 0.363653 0.616955 0.870488 0.689039 0.828563 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271843 episodes
GETTING ACTION FROM:
action 2, numVisits=2270907, meanQ=5.128778, numObservations: 4
action 1, numVisits=468, meanQ=4.768258, numObservations: 4
action 3, numVisits=418, meanQ=4.748052, numObservations: 3
action -1, numVisits=48, meanQ=4.022555, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.772811 0.363653 0.616955 0.870488 0.689039 0.828563 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 14
Initial state: 0 0.179119 0.0391317 0.638057 0.832707 0.625079 0.806956 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262830 episodes
GETTING ACTION FROM:
action 1, numVisits=2262700, meanQ=4.995208, numObservations: 4
action -1, numVisits=125, meanQ=2.076927, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.179119 0.0391317 0.638057 0.832707 0.625079 0.806956 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=160643, meanQ=8.541144, numObservations: 3
action 2, numVisits=61078, meanQ=8.530132, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2819876 episodes
GETTING ACTION FROM:
action 3, numVisits=2537220, meanQ=6.108496, numObservations: 4
action 2, numVisits=504372, meanQ=6.102426, numObservations: 4
action -1, numVisits=5, meanQ=1.762000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.179119 0.0391317 0.638057 0.832707 0.625079 0.806956 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=40282, meanQ=7.397047, numObservations: 3
action 3, numVisits=18403, meanQ=7.392908, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2971571 episodes
GETTING ACTION FROM:
action 2, numVisits=2968721, meanQ=6.110228, numObservations: 3
action 3, numVisits=61533, meanQ=6.083169, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.179119 0.0391317 0.638057 0.832707 0.625079 0.806956 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 15
Initial state: 0 0.579446 0.879587 0.611566 0.870932 0.961571 0.239566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2256280 episodes
GETTING ACTION FROM:
action 3, numVisits=2247632, meanQ=4.900298, numObservations: 4
action -1, numVisits=8642, meanQ=2.946897, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.579446 0.879587 0.611566 0.870932 0.961571 0.239566 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 16
Initial state: 0 0.322807 0.601368 0.666344 0.834877 0.550417 0.840175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1524687 episodes
GETTING ACTION FROM:
action 0, numVisits=1524675, meanQ=2.931310, numObservations: 1
action 2, numVisits=7, meanQ=-0.145714, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.322807 0.601368 0.666344 0.834877 0.550417 0.840175 w: 1
Observation: 0 0 0.510725 0 0.800201 0 0.886881 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1524613, meanQ=4.985317, numObservations: 5
action 0, numVisits=32, meanQ=3.616634, numObservations: 1
action 2, numVisits=26, meanQ=2.221169, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2418064 episodes
GETTING ACTION FROM:
action 3, numVisits=3942677, meanQ=5.059183, numObservations: 5
action 0, numVisits=32, meanQ=3.616634, numObservations: 1
action 2, numVisits=26, meanQ=2.221169, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.322807 0.601368 0.666344 0.834877 0.550417 0.840175 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 17
Initial state: 0 0.652161 0.815266 0.658718 0.869298 0.467119 0.345511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259059 episodes
GETTING ACTION FROM:
action 1, numVisits=2248611, meanQ=4.916847, numObservations: 4
action 0, numVisits=10442, meanQ=3.014588, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.652161 0.815266 0.658718 0.869298 0.467119 0.345511 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 18
Initial state: 0 0.681177 0.848217 0.650385 0.872215 0.633577 0.393311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2200861 episodes
GETTING ACTION FROM:
action 1, numVisits=2200854, meanQ=4.976481, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.681177 0.848217 0.650385 0.872215 0.633577 0.393311 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 19
Initial state: 0 0.573702 0.880635 0.657337 0.893862 0.654898 0.905798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268124 episodes
GETTING ACTION FROM:
action 3, numVisits=2268048, meanQ=5.003685, numObservations: 4
action 0, numVisits=46, meanQ=3.849325, numObservations: 1
action -1, numVisits=25, meanQ=3.336466, numObservations: 1
action 2, numVisits=4, meanQ=-2.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.573702 0.880635 0.657337 0.893862 0.654898 0.905798 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 20
Initial state: 0 0.610098 0.841999 0.96792 0.840852 0.678288 0.894368 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253168 episodes
GETTING ACTION FROM:
action 2, numVisits=2253097, meanQ=4.987329, numObservations: 5
action -1, numVisits=67, meanQ=4.035345, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.610098 0.841999 0.96792 0.840852 0.678288 0.894368 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 21
Initial state: 0 0.57194 0.897697 0.545614 0.877357 0.591997 0.883031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2249584 episodes
GETTING ACTION FROM:
action 2, numVisits=2249482, meanQ=4.980702, numObservations: 5
action 0, numVisits=58, meanQ=3.953192, numObservations: 1
action -1, numVisits=42, meanQ=3.780045, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.57194 0.897697 0.545614 0.877357 0.591997 0.883031 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 22
Initial state: 0 0.569597 0.890409 0.413689 0.423792 0.546599 0.85134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262656 episodes
GETTING ACTION FROM:
action 1, numVisits=2262650, meanQ=4.976070, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.569597 0.890409 0.413689 0.423792 0.546599 0.85134 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 23
Initial state: 0 0.690708 0.898522 0.533117 0.803231 0.763253 0.201204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263767 episodes
GETTING ACTION FROM:
action 3, numVisits=2263724, meanQ=4.927627, numObservations: 4
action 0, numVisits=39, meanQ=3.659437, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.690708 0.898522 0.533117 0.803231 0.763253 0.201204 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.622729 0.87694 0.561723 0.848531 0.810487 0.503455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2236476 episodes
GETTING ACTION FROM:
action 3, numVisits=2236378, meanQ=4.991593, numObservations: 5
action -1, numVisits=63, meanQ=4.019491, numObservations: 1
action 0, numVisits=33, meanQ=3.642000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.622729 0.87694 0.561723 0.848531 0.810487 0.503455 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 25
Initial state: 0 0.633316 0.820979 0.982946 0.966934 0.67712 0.802268 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2242066 episodes
GETTING ACTION FROM:
action 3, numVisits=2201571, meanQ=4.900991, numObservations: 4
action 0, numVisits=40489, meanQ=2.891757, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.633316 0.820979 0.982946 0.966934 0.67712 0.802268 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 26
Initial state: 0 0.61802 0.87326 0.622028 0.854541 0.865041 0.146003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2228315 episodes
GETTING ACTION FROM:
action 1, numVisits=2228264, meanQ=4.909109, numObservations: 5
action 0, numVisits=47, meanQ=3.782664, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.61802 0.87326 0.622028 0.854541 0.865041 0.146003 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 27
Initial state: 0 0.334952 0.570002 0.633564 0.867482 0.600274 0.879964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2267534 episodes
GETTING ACTION FROM:
action 3, numVisits=2267478, meanQ=4.965052, numObservations: 4
action -1, numVisits=46, meanQ=3.832852, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.334952 0.570002 0.633564 0.867482 0.600274 0.879964 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 28
Initial state: 0 0.946639 0.668673 0.622634 0.878518 0.594088 0.872598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237194 episodes
GETTING ACTION FROM:
action 3, numVisits=2237152, meanQ=4.975038, numObservations: 5
action -1, numVisits=38, meanQ=3.737280, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.946639 0.668673 0.622634 0.878518 0.594088 0.872598 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 29
Initial state: 0 0.937993 0.607302 0.64611 0.877347 0.567027 0.875514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1560839 episodes
GETTING ACTION FROM:
action 0, numVisits=1533740, meanQ=2.946204, numObservations: 1
action -1, numVisits=27092, meanQ=2.906416, numObservations: 1
action 3, numVisits=5, meanQ=-1.402000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.937993 0.607302 0.64611 0.877347 0.567027 0.875514 w: 1
Observation: 0 0 0.507348 0 0.898159 0 0.781197 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1533676, meanQ=4.994867, numObservations: 3
action 0, numVisits=57, meanQ=3.972185, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2462962 episodes
GETTING ACTION FROM:
action 2, numVisits=3996634, meanQ=4.920733, numObservations: 3
action 0, numVisits=61, meanQ=3.903456, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.937993 0.607302 0.64611 0.877347 0.567027 0.875514 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 30
Initial state: 0 0.514059 0.881729 0.662288 0.881765 0.901438 0.764401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2272322 episodes
GETTING ACTION FROM:
action 1, numVisits=2272275, meanQ=4.994479, numObservations: 4
action -1, numVisits=38, meanQ=3.740277, numObservations: 1
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.514059 0.881729 0.662288 0.881765 0.901438 0.764401 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 31
Initial state: 0 0.651678 0.85759 0.667428 0.873432 0.867002 0.381264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259235 episodes
GETTING ACTION FROM:
action 3, numVisits=2259174, meanQ=4.915889, numObservations: 4
action 0, numVisits=57, meanQ=3.902573, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.651678 0.85759 0.667428 0.873432 0.867002 0.381264 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 32
Initial state: 0 0.955903 0.230861 0.602927 0.836285 0.530302 0.862254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2276212 episodes
GETTING ACTION FROM:
action 3, numVisits=2276203, meanQ=4.993111, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.955903 0.230861 0.602927 0.836285 0.530302 0.862254 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 33
Initial state: 0 0.66935 0.838445 0.58356 0.886912 0.958573 0.477487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2260104 episodes
GETTING ACTION FROM:
action 3, numVisits=2257336, meanQ=4.974506, numObservations: 4
action -1, numVisits=2764, meanQ=2.874431, numObservations: 1
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.66935 0.838445 0.58356 0.886912 0.958573 0.477487 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 34
Initial state: 0 0.0244805 0.303217 0.619024 0.816561 0.645301 0.857031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2248263 episodes
GETTING ACTION FROM:
action 1, numVisits=2248177, meanQ=5.001212, numObservations: 5
action -1, numVisits=77, meanQ=4.129614, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0244805 0.303217 0.619024 0.816561 0.645301 0.857031 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=57529, meanQ=7.940057, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2826170 episodes
GETTING ACTION FROM:
action 3, numVisits=2883694, meanQ=6.124122, numObservations: 4
action 1, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0244805 0.303217 0.619024 0.816561 0.645301 0.857031 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 35
Initial state: 0 0.510671 0.874636 0.522916 0.945307 0.564101 0.81415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268200 episodes
GETTING ACTION FROM:
action 2, numVisits=2266695, meanQ=4.994256, numObservations: 4
action -1, numVisits=1495, meanQ=2.688830, numObservations: 1
action 1, numVisits=7, meanQ=-0.429986, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.510671 0.874636 0.522916 0.945307 0.564101 0.81415 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 36
Initial state: 0 0.604577 0.822559 0.617961 0.801387 0.845878 0.102412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264611 episodes
GETTING ACTION FROM:
action 3, numVisits=2264602, meanQ=4.929695, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.604577 0.822559 0.617961 0.801387 0.845878 0.102412 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.634048 0.651772 0.529315 0.863241 0.589683 0.844025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1542479 episodes
GETTING ACTION FROM:
action -1, numVisits=1535226, meanQ=2.935499, numObservations: 1
action 0, numVisits=7241, meanQ=2.852868, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=6, meanQ=-1.670000, numObservations: 2
action: -1
Next state: 0 0.634048 0.651772 0.529315 0.863241 0.589683 0.844025 w: 1
Observation: 0 0.714968 0 0.560874 0 0.538259 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1535180, meanQ=4.983861, numObservations: 5
action 0, numVisits=41, meanQ=3.772626, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2442031 episodes
GETTING ACTION FROM:
action 1, numVisits=3977211, meanQ=5.139923, numObservations: 5
action 0, numVisits=41, meanQ=3.772626, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.634048 0.651772 0.529315 0.863241 0.589683 0.844025 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=469465, meanQ=8.377449, numObservations: 4
action 2, numVisits=18846, meanQ=8.334855, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2823712 episodes
GETTING ACTION FROM:
action 3, numVisits=3154363, meanQ=6.047500, numObservations: 4
action 2, numVisits=157658, meanQ=6.032294, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.634048 0.651772 0.529315 0.863241 0.589683 0.844025 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 38
Initial state: 0 0.697531 0.889282 0.333115 0.069632 0.686162 0.82257 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263586 episodes
GETTING ACTION FROM:
action 1, numVisits=2263208, meanQ=4.992583, numObservations: 4
action 2, numVisits=309, meanQ=4.558206, numObservations: 4
action 3, numVisits=65, meanQ=4.035238, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.697531 0.889282 0.333115 0.069632 0.686162 0.82257 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 39
Initial state: 0 0.56722 0.48647 0.575618 0.886569 0.516117 0.868785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2291923 episodes
GETTING ACTION FROM:
action 1, numVisits=2291914, meanQ=4.966199, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.56722 0.48647 0.575618 0.886569 0.516117 0.868785 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=349992, meanQ=8.325686, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2793575 episodes
GETTING ACTION FROM:
action 3, numVisits=3143565, meanQ=6.148338, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.56722 0.48647 0.575618 0.886569 0.516117 0.868785 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 40
Initial state: 0 0.894156 0.0836372 0.5848 0.874291 0.660941 0.872605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1551689 episodes
GETTING ACTION FROM:
action -1, numVisits=1551681, meanQ=2.824819, numObservations: 1
action 0, numVisits=3, meanQ=-1.673300, numObservations: 2
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.894156 0.0836372 0.5848 0.874291 0.660941 0.872605 w: 1
Observation: 0 0.804883 0 0.607802 0 0.7238 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1551672, meanQ=4.899548, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2459625 episodes
GETTING ACTION FROM:
action 2, numVisits=4011297, meanQ=4.785437, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.894156 0.0836372 0.5848 0.874291 0.660941 0.872605 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 41
Initial state: 0 0.679609 0.854807 0.91345 0.598425 0.667894 0.821176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2245512 episodes
GETTING ACTION FROM:
action 1, numVisits=2245485, meanQ=4.962391, numObservations: 4
action -1, numVisits=18, meanQ=3.134276, numObservations: 1
action 2, numVisits=6, meanQ=1.001683, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.679609 0.854807 0.91345 0.598425 0.667894 0.821176 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 42
Initial state: 0 0.587618 0.872945 0.531641 0.833139 0.87601 0.785161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2287127 episodes
GETTING ACTION FROM:
action 2, numVisits=2287036, meanQ=4.986114, numObservations: 3
action -1, numVisits=81, meanQ=2.662430, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.587618 0.872945 0.531641 0.833139 0.87601 0.785161 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 43
Initial state: 0 0.659616 0.861936 0.598597 0.890851 0.140633 0.296172 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2250739 episodes
GETTING ACTION FROM:
action 1, numVisits=2250724, meanQ=4.920957, numObservations: 5
action 3, numVisits=7, meanQ=1.285743, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.659616 0.861936 0.598597 0.890851 0.140633 0.296172 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 44
Initial state: 0 0.676761 0.886572 0.195011 0.96289 0.659347 0.871449 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258159 episodes
GETTING ACTION FROM:
action 3, numVisits=2258150, meanQ=4.904778, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=4, meanQ=-2.005000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.676761 0.886572 0.195011 0.96289 0.659347 0.871449 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 45
Initial state: 0 0.529906 0.874753 0.315721 0.85278 0.662609 0.894069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2243247 episodes
GETTING ACTION FROM:
action 2, numVisits=2243128, meanQ=4.909095, numObservations: 5
action 0, numVisits=115, meanQ=4.198687, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.529906 0.874753 0.315721 0.85278 0.662609 0.894069 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=141789, meanQ=4.081280, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2772892 episodes
GETTING ACTION FROM:
action 1, numVisits=2914681, meanQ=5.904541, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.529906 0.874753 0.315721 0.85278 0.662609 0.894069 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 46
Initial state: 0 0.574517 0.819297 0.629048 0.879363 0.361376 0.942896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237380 episodes
GETTING ACTION FROM:
action 1, numVisits=2237362, meanQ=4.913140, numObservations: 5
action 3, numVisits=8, meanQ=0.997500, numObservations: 3
action 2, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.574517 0.819297 0.629048 0.879363 0.361376 0.942896 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 47
Initial state: 0 0.652819 0.885303 0.544328 0.804252 0.630072 0.160656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2251125 episodes
GETTING ACTION FROM:
action 1, numVisits=2251091, meanQ=5.119961, numObservations: 5
action -1, numVisits=29, meanQ=3.674669, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.652819 0.885303 0.544328 0.804252 0.630072 0.160656 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=20402, meanQ=6.096844, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2696834 episodes
GETTING ACTION FROM:
action 1, numVisits=2717234, meanQ=5.189136, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.652819 0.885303 0.544328 0.804252 0.630072 0.160656 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 48
Initial state: 0 0.625861 0.861143 0.504417 0.875594 0.17534 0.300512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2203715 episodes
GETTING ACTION FROM:
action 1, numVisits=2203690, meanQ=4.926644, numObservations: 5
action 0, numVisits=21, meanQ=3.215844, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.625861 0.861143 0.504417 0.875594 0.17534 0.300512 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 49
Initial state: 0 0.697519 0.832559 0.643776 0.808216 0.174022 0.564584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2236138 episodes
GETTING ACTION FROM:
action 3, numVisits=2232232, meanQ=5.103577, numObservations: 5
action -1, numVisits=3902, meanQ=2.975036, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.697519 0.832559 0.643776 0.808216 0.174022 0.564584 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=137700, meanQ=7.988803, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2808873 episodes
GETTING ACTION FROM:
action 1, numVisits=2946571, meanQ=5.474560, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.697519 0.832559 0.643776 0.808216 0.174022 0.564584 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 50
Initial state: 0 0.561408 0.591237 0.597856 0.868443 0.546723 0.845644 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2289938 episodes
GETTING ACTION FROM:
action 3, numVisits=2289883, meanQ=4.908959, numObservations: 3
action -1, numVisits=47, meanQ=3.776160, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.561408 0.591237 0.597856 0.868443 0.546723 0.845644 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 51
Initial state: 0 0.535965 0.898049 0.515429 0.851927 0.885874 0.86573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2185783 episodes
GETTING ACTION FROM:
action 3, numVisits=2134803, meanQ=4.823500, numObservations: 4
action 0, numVisits=38632, meanQ=2.999186, numObservations: 1
action -1, numVisits=12329, meanQ=2.973387, numObservations: 1
action 2, numVisits=17, meanQ=1.110594, numObservations: 3
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 3
Next state: 1 0.535965 0.898049 0.515429 0.851927 0.885874 0.86573 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 52
Initial state: 0 0.649166 0.803003 0.620004 0.849095 0.375956 0.529098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2250425 episodes
GETTING ACTION FROM:
action 3, numVisits=2250346, meanQ=4.928915, numObservations: 4
action 0, numVisits=75, meanQ=4.049425, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.649166 0.803003 0.620004 0.849095 0.375956 0.529098 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 53
Initial state: 0 0.96486 0.807516 0.558371 0.81404 0.530022 0.850523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2267090 episodes
GETTING ACTION FROM:
action 1, numVisits=2267078, meanQ=4.926670, numObservations: 4
action 3, numVisits=7, meanQ=1.014286, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.96486 0.807516 0.558371 0.81404 0.530022 0.850523 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 54
Initial state: 0 0.644492 0.834422 0.61808 0.848939 0.864911 0.736306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2270023 episodes
GETTING ACTION FROM:
action 1, numVisits=2270016, meanQ=4.977664, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.644492 0.834422 0.61808 0.848939 0.864911 0.736306 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 55
Initial state: 0 0.686945 0.834858 0.528306 0.878006 0.939155 0.23738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2232886 episodes
GETTING ACTION FROM:
action 3, numVisits=2232825, meanQ=4.990796, numObservations: 5
action 0, numVisits=32, meanQ=3.601709, numObservations: 1
action 1, numVisits=26, meanQ=2.450388, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.686945 0.834858 0.528306 0.878006 0.939155 0.23738 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 56
Initial state: 0 0.592563 0.845243 0.900457 0.941393 0.542561 0.8317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2275452 episodes
GETTING ACTION FROM:
action 1, numVisits=2248327, meanQ=4.980969, numObservations: 3
action -1, numVisits=27118, meanQ=2.927299, numObservations: 1
action 3, numVisits=4, meanQ=-0.504975, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.592563 0.845243 0.900457 0.941393 0.542561 0.8317 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 57
Initial state: 0 0.562303 0.889383 0.956633 0.218718 0.617698 0.830675 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2250283 episodes
GETTING ACTION FROM:
action 3, numVisits=2250173, meanQ=4.969294, numObservations: 4
action 0, numVisits=70, meanQ=4.049119, numObservations: 1
action -1, numVisits=35, meanQ=3.655094, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.562303 0.889383 0.956633 0.218718 0.617698 0.830675 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 58
Initial state: 0 0.592845 0.836839 0.237796 0.804727 0.523909 0.847515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2245791 episodes
GETTING ACTION FROM:
action 1, numVisits=2245678, meanQ=4.961456, numObservations: 5
action -1, numVisits=57, meanQ=3.905654, numObservations: 1
action 0, numVisits=35, meanQ=3.653791, numObservations: 1
action 3, numVisits=20, meanQ=2.795505, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.592845 0.836839 0.237796 0.804727 0.523909 0.847515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 59
Initial state: 0 0.516802 0.887358 0.531931 0.653388 0.65785 0.873462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2282994 episodes
GETTING ACTION FROM:
action 1, numVisits=2282988, meanQ=4.990595, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.516802 0.887358 0.531931 0.653388 0.65785 0.873462 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 60
Initial state: 0 0.44209 0.706134 0.630334 0.82138 0.620578 0.803584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2215935 episodes
GETTING ACTION FROM:
action 2, numVisits=2215892, meanQ=4.887074, numObservations: 5
action -1, numVisits=36, meanQ=3.574043, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.44209 0.706134 0.630334 0.82138 0.620578 0.803584 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 61
Initial state: 0 0.500348 0.809276 0.565579 0.804075 0.0280856 0.0776152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2245118 episodes
GETTING ACTION FROM:
action 2, numVisits=2245112, meanQ=4.928514, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.500348 0.809276 0.565579 0.804075 0.0280856 0.0776152 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 62
Initial state: 0 0.56488 0.899128 0.578581 0.842604 0.152035 0.984647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1578465 episodes
GETTING ACTION FROM:
action 0, numVisits=1556061, meanQ=5.777086, numObservations: 3
action 3, numVisits=22396, meanQ=5.029442, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.56488 0.899128 0.578581 0.842604 0.152035 0.984647 w: 1
Observation: 0 0 0.842504 0 0.823455 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=575913, meanQ=7.565943, numObservations: 4
action 2, numVisits=19, meanQ=4.261584, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2345655 episodes
GETTING ACTION FROM:
action 3, numVisits=2921490, meanQ=5.425963, numObservations: 4
action 2, numVisits=77, meanQ=4.475332, numObservations: 4
action 0, numVisits=20, meanQ=3.584988, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.56488 0.899128 0.578581 0.842604 0.152035 0.984647 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=210178, meanQ=5.485464, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2620283 episodes
GETTING ACTION FROM:
action 3, numVisits=2551251, meanQ=4.847447, numObservations: 4
action -1, numVisits=279211, meanQ=4.058880, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.56488 0.899128 0.578581 0.842604 0.152035 0.984647 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 63
Initial state: 0 0.320945 0.95061 0.643309 0.803033 0.530019 0.874777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2251602 episodes
GETTING ACTION FROM:
action 1, numVisits=2250866, meanQ=4.922064, numObservations: 4
action 3, numVisits=575, meanQ=4.588401, numObservations: 4
action -1, numVisits=92, meanQ=4.120725, numObservations: 1
action 0, numVisits=68, meanQ=3.991647, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.320945 0.95061 0.643309 0.803033 0.530019 0.874777 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=164211, meanQ=4.672751, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2801368 episodes
GETTING ACTION FROM:
action 2, numVisits=2965579, meanQ=5.749127, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.320945 0.95061 0.643309 0.803033 0.530019 0.874777 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 64
Initial state: 0 0.667054 0.898946 0.592116 0.889345 0.957294 0.132104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2275657 episodes
GETTING ACTION FROM:
action 1, numVisits=2270336, meanQ=4.975843, numObservations: 4
action 2, numVisits=5192, meanQ=4.872419, numObservations: 4
action -1, numVisits=122, meanQ=4.287299, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.667054 0.898946 0.592116 0.889345 0.957294 0.132104 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 65
Initial state: 0 0.475852 0.356055 0.536152 0.836127 0.639228 0.873335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2276970 episodes
GETTING ACTION FROM:
action 3, numVisits=2276946, meanQ=4.973194, numObservations: 3
action 2, numVisits=18, meanQ=1.665567, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.475852 0.356055 0.536152 0.836127 0.639228 0.873335 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 66
Initial state: 0 0.567497 0.818217 0.349563 0.629889 0.671736 0.89763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263924 episodes
GETTING ACTION FROM:
action 3, numVisits=2262246, meanQ=4.921559, numObservations: 4
action 1, numVisits=1673, meanQ=4.719420, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.567497 0.818217 0.349563 0.629889 0.671736 0.89763 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 67
Initial state: 0 0.679773 0.805817 0.638754 0.823326 0.354055 0.822413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2283717 episodes
GETTING ACTION FROM:
action 2, numVisits=2283708, meanQ=4.986853, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.679773 0.805817 0.638754 0.823326 0.354055 0.822413 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 68
Initial state: 0 0.643565 0.848532 0.501256 0.88955 0.265176 0.292652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268859 episodes
GETTING ACTION FROM:
action 1, numVisits=2268853, meanQ=4.972247, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.643565 0.848532 0.501256 0.88955 0.265176 0.292652 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 69
Initial state: 0 0.507985 0.898511 0.672629 0.879696 0.574991 0.829103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2272827 episodes
GETTING ACTION FROM:
action 1, numVisits=2272674, meanQ=4.990919, numObservations: 4
action 0, numVisits=92, meanQ=4.183914, numObservations: 1
action -1, numVisits=59, meanQ=3.991528, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.507985 0.898511 0.672629 0.879696 0.574991 0.829103 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 70
Initial state: 0 0.198282 0.237721 0.565221 0.897163 0.647916 0.808103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2240124 episodes
GETTING ACTION FROM:
action 1, numVisits=2240004, meanQ=4.980638, numObservations: 5
action 0, numVisits=76, meanQ=4.104099, numObservations: 1
action -1, numVisits=26, meanQ=3.464006, numObservations: 1
action 2, numVisits=17, meanQ=1.940606, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.198282 0.237721 0.565221 0.897163 0.647916 0.808103 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=273683, meanQ=8.393913, numObservations: 4
action 3, numVisits=10558, meanQ=8.336259, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2846474 episodes
GETTING ACTION FROM:
action 2, numVisits=3057359, meanQ=6.239021, numObservations: 4
action 3, numVisits=73354, meanQ=6.214657, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.198282 0.237721 0.565221 0.897163 0.647916 0.808103 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 71
Initial state: 0 0.656087 0.815363 0.686692 0.233146 0.630475 0.886399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2236216 episodes
GETTING ACTION FROM:
action 1, numVisits=2236134, meanQ=4.929746, numObservations: 5
action 0, numVisits=61, meanQ=3.933075, numObservations: 2
action 3, numVisits=18, meanQ=2.439456, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.656087 0.815363 0.686692 0.233146 0.630475 0.886399 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 72
Initial state: 0 0.713373 0.533726 0.517006 0.800996 0.674819 0.886703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237704 episodes
GETTING ACTION FROM:
action 3, numVisits=2237651, meanQ=4.973224, numObservations: 5
action 0, numVisits=44, meanQ=3.796530, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.713373 0.533726 0.517006 0.800996 0.674819 0.886703 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 73
Initial state: 0 0.59394 0.813214 0.173442 0.366569 0.66868 0.857202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264775 episodes
GETTING ACTION FROM:
action 1, numVisits=2264744, meanQ=4.978283, numObservations: 4
action 0, numVisits=27, meanQ=3.452134, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.59394 0.813214 0.173442 0.366569 0.66868 0.857202 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 74
Initial state: 0 0.51116 0.871601 0.694929 0.838365 0.357703 0.0476064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2199938 episodes
GETTING ACTION FROM:
action 2, numVisits=2197671, meanQ=4.889655, numObservations: 5
action 1, numVisits=2051, meanQ=4.720245, numObservations: 5
action 0, numVisits=111, meanQ=4.167848, numObservations: 1
action -1, numVisits=104, meanQ=4.134683, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.51116 0.871601 0.694929 0.838365 0.357703 0.0476064 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 75
Initial state: 0 0.517899 0.869853 0.671878 0.804781 0.976365 0.00242011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1551585 episodes
GETTING ACTION FROM:
action 0, numVisits=1551573, meanQ=2.897994, numObservations: 1
action 2, numVisits=4, meanQ=-0.999975, numObservations: 3
action 1, numVisits=4, meanQ=-1.002450, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 0
Next state: 0 0.517899 0.869853 0.671878 0.804781 0.976365 0.00242011 w: 1
Observation: 0 0 0.780792 0 0.854527 0 0.0929218 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1200023, meanQ=4.960110, numObservations: 4
action 3, numVisits=351541, meanQ=4.880053, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 2437287 episodes
GETTING ACTION FROM:
action 2, numVisits=3637310, meanQ=4.974932, numObservations: 4
action 3, numVisits=351541, meanQ=4.880053, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.517899 0.869853 0.671878 0.804781 0.976365 0.00242011 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 76
Initial state: 0 0.548538 0.849068 0.61836 0.87881 0.726345 0.45754 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2034871 episodes
GETTING ACTION FROM:
action 3, numVisits=1535996, meanQ=5.012979, numObservations: 5
action -1, numVisits=498868, meanQ=2.844363, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.548538 0.849068 0.61836 0.87881 0.726345 0.45754 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 77
Initial state: 0 0.592675 0.245261 0.655166 0.864123 0.633409 0.8877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2202110 episodes
GETTING ACTION FROM:
action 2, numVisits=2202104, meanQ=4.870325, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.592675 0.245261 0.655166 0.864123 0.633409 0.8877 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 78
Initial state: 0 0.793387 0.251604 0.690648 0.885345 0.560618 0.873428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2289837 episodes
GETTING ACTION FROM:
action 1, numVisits=2289773, meanQ=4.990464, numObservations: 3
action -1, numVisits=59, meanQ=3.994767, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.793387 0.251604 0.690648 0.885345 0.560618 0.873428 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 79
Initial state: 0 0.564269 0.857147 0.542552 0.858301 0.610644 0.719779 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2291603 episodes
GETTING ACTION FROM:
action 3, numVisits=2291432, meanQ=4.987956, numObservations: 3
action -1, numVisits=123, meanQ=4.300161, numObservations: 1
action 0, numVisits=33, meanQ=3.608430, numObservations: 1
action 2, numVisits=13, meanQ=1.921554, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 0 0.564269 0.857147 0.542552 0.858301 0.610644 0.719779 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=298471, meanQ=8.320602, numObservations: 4
action 2, numVisits=50775, meanQ=8.320180, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2834299 episodes
GETTING ACTION FROM:
action 1, numVisits=2772884, meanQ=6.206409, numObservations: 4
action 2, numVisits=410658, meanQ=6.198966, numObservations: 3
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.564269 0.857147 0.542552 0.858301 0.610644 0.719779 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 80
Initial state: 0 0.645705 0.898232 0.89765 0.0701939 0.583926 0.800296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2284969 episodes
GETTING ACTION FROM:
action 3, numVisits=2284861, meanQ=4.996383, numObservations: 3
action 0, numVisits=65, meanQ=4.046447, numObservations: 1
action -1, numVisits=23, meanQ=3.352132, numObservations: 1
action 1, numVisits=19, meanQ=3.095263, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.645705 0.898232 0.89765 0.0701939 0.583926 0.800296 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 81
Initial state: 0 0.3958 0.369786 0.652199 0.842151 0.504086 0.896116 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1558791 episodes
GETTING ACTION FROM:
action 0, numVisits=1556782, meanQ=2.920929, numObservations: 1
action -1, numVisits=2001, meanQ=1.771981, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=4, meanQ=-2.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.3958 0.369786 0.652199 0.842151 0.504086 0.896116 w: 1
Observation: 0 0 0.446098 0 0.803528 0 0.871448 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1556659, meanQ=4.973866, numObservations: 3
action 1, numVisits=117, meanQ=4.269747, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2470099 episodes
GETTING ACTION FROM:
action 1, numVisits=2385245, meanQ=5.016469, numObservations: 4
action 3, numVisits=1641630, meanQ=4.963317, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.3958 0.369786 0.652199 0.842151 0.504086 0.896116 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=288491, meanQ=8.356191, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2795123 episodes
GETTING ACTION FROM:
action 3, numVisits=3083612, meanQ=5.899815, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.3958 0.369786 0.652199 0.842151 0.504086 0.896116 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 82
Initial state: 0 0.386173 0.746573 0.571698 0.836918 0.632426 0.823192 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271770 episodes
GETTING ACTION FROM:
action 2, numVisits=1763391, meanQ=4.936385, numObservations: 4
action 1, numVisits=508307, meanQ=4.919482, numObservations: 4
action -1, numVisits=59, meanQ=3.928543, numObservations: 1
action 3, numVisits=11, meanQ=2.453636, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.386173 0.746573 0.571698 0.836918 0.632426 0.823192 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 83
Initial state: 0 0.855078 0.529415 0.508298 0.868588 0.617063 0.849011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258508 episodes
GETTING ACTION FROM:
action 1, numVisits=2257097, meanQ=4.906508, numObservations: 4
action 0, numVisits=1364, meanQ=3.200041, numObservations: 1
action 2, numVisits=43, meanQ=2.393033, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.855078 0.529415 0.508298 0.868588 0.617063 0.849011 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 84
Initial state: 0 0.519478 0.865031 0.199617 0.200045 0.55467 0.881578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2283316 episodes
GETTING ACTION FROM:
action 1, numVisits=2283220, meanQ=4.921151, numObservations: 3
action 0, numVisits=91, meanQ=4.120742, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.519478 0.865031 0.199617 0.200045 0.55467 0.881578 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 85
Initial state: 0 0.552459 0.810705 0.532301 0.124767 0.528237 0.836751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2135804 episodes
GETTING ACTION FROM:
action 2, numVisits=2135791, meanQ=4.660655, numObservations: 4
action 3, numVisits=6, meanQ=-1.670000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.552459 0.810705 0.532301 0.124767 0.528237 0.836751 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 86
Initial state: 0 0.515577 0.906173 0.68765 0.889397 0.522061 0.857699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2235828 episodes
GETTING ACTION FROM:
action 1, numVisits=2235822, meanQ=4.977025, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.515577 0.906173 0.68765 0.889397 0.522061 0.857699 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 87
Initial state: 0 0.720917 0.196171 0.59125 0.850751 0.578982 0.87986 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2218776 episodes
GETTING ACTION FROM:
action 3, numVisits=2218677, meanQ=4.899212, numObservations: 5
action -1, numVisits=60, meanQ=3.909363, numObservations: 1
action 0, numVisits=37, meanQ=3.592197, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.720917 0.196171 0.59125 0.850751 0.578982 0.87986 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 88
Initial state: 0 0.676003 0.830777 0.614931 0.820101 0.174494 0.0188666 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2282417 episodes
GETTING ACTION FROM:
action 2, numVisits=2282240, meanQ=4.988547, numObservations: 4
action -1, numVisits=173, meanQ=4.407661, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.676003 0.830777 0.614931 0.820101 0.174494 0.0188666 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 89
Initial state: 0 0.60673 0.861863 0.563099 0.854558 0.549645 0.0968055 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2252996 episodes
GETTING ACTION FROM:
action 1, numVisits=2238645, meanQ=4.992160, numObservations: 5
action 3, numVisits=14144, meanQ=4.929261, numObservations: 4
action 2, numVisits=114, meanQ=4.227092, numObservations: 4
action -1, numVisits=55, meanQ=3.940501, numObservations: 1
action 0, numVisits=38, meanQ=3.730632, numObservations: 1
action: 1
Next state: 1 0.60673 0.861863 0.563099 0.854558 0.549645 0.0968055 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 90
Initial state: 0 0.587806 0.824571 0.554632 0.864515 0.331992 0.00108242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2179679 episodes
GETTING ACTION FROM:
action 1, numVisits=2179634, meanQ=4.967616, numObservations: 4
action -1, numVisits=41, meanQ=3.754559, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.587806 0.824571 0.554632 0.864515 0.331992 0.00108242 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 91
Initial state: 0 0.698959 0.302443 0.658226 0.895859 0.67421 0.822798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2257462 episodes
GETTING ACTION FROM:
action 2, numVisits=2257456, meanQ=4.914243, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.698959 0.302443 0.658226 0.895859 0.67421 0.822798 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 92
Initial state: 0 0.648014 0.869371 0.556817 0.861949 0.240684 0.235953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1419658 episodes
GETTING ACTION FROM:
action 0, numVisits=1419641, meanQ=5.091652, numObservations: 3
action 3, numVisits=11, meanQ=1.180927, numObservations: 3
action 1, numVisits=3, meanQ=0.330033, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.648014 0.869371 0.556817 0.861949 0.240684 0.235953 w: 1
Observation: 0 0 0.80706 0 0.85567 0 0.227699 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=521783, meanQ=5.683607, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1612880 episodes
GETTING ACTION FROM:
action -1, numVisits=2134663, meanQ=4.638885, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.648014 0.869371 0.556817 0.861949 0.240684 0.235953 w: 1
Observation: 0 0.685911 0 0.619894 0 0.302308 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=2134600, meanQ=5.800055, numObservations: 5
action 0, numVisits=57, meanQ=4.788769, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2396587 episodes
GETTING ACTION FROM:
action 2, numVisits=4531173, meanQ=5.344624, numObservations: 5
action 0, numVisits=71, meanQ=4.416260, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.648014 0.869371 0.556817 0.861949 0.240684 0.235953 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 93
Initial state: 0 0.523494 0.839007 0.541267 0.856065 0.915564 0.443131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1579998 episodes
GETTING ACTION FROM:
action 0, numVisits=1579989, meanQ=5.698962, numObservations: 3
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.523494 0.839007 0.541267 0.856065 0.915564 0.443131 w: 1
Observation: 0 0 0.782214 0 0.854223 0 0.407257 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=429406, meanQ=8.157611, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2371754 episodes
GETTING ACTION FROM:
action 1, numVisits=2801139, meanQ=5.663999, numObservations: 4
action 0, numVisits=21, meanQ=3.949383, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.523494 0.839007 0.541267 0.856065 0.915564 0.443131 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 94
Initial state: 0 0.569818 0.83819 0.567369 0.892762 0.0342249 0.927927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254886 episodes
GETTING ACTION FROM:
action 3, numVisits=2254809, meanQ=4.990040, numObservations: 4
action 0, numVisits=72, meanQ=4.086141, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.569818 0.83819 0.567369 0.892762 0.0342249 0.927927 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=20426, meanQ=6.149963, numObservations: 3
action 1, numVisits=10, meanQ=3.198010, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2791995 episodes
GETTING ACTION FROM:
action 1, numVisits=2696713, meanQ=5.770962, numObservations: 5
action 3, numVisits=115716, meanQ=5.337434, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.569818 0.83819 0.567369 0.892762 0.0342249 0.927927 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 95
Initial state: 0 0.361262 0.759782 0.661205 0.893789 0.652366 0.843169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246733 episodes
GETTING ACTION FROM:
action 1, numVisits=2246586, meanQ=5.126647, numObservations: 5
action 0, numVisits=79, meanQ=4.262187, numObservations: 1
action -1, numVisits=40, meanQ=3.901055, numObservations: 1
action 2, numVisits=26, meanQ=3.615012, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 2 0.361262 0.759782 0.661205 0.893789 0.652366 0.843169 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 96
Initial state: 0 0.679035 0.860615 0.536932 0.840804 0.859657 0.338371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2281923 episodes
GETTING ACTION FROM:
action 2, numVisits=2281914, meanQ=5.003516, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.679035 0.860615 0.536932 0.840804 0.859657 0.338371 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 97
Initial state: 0 0.524626 0.856585 0.571586 0.895833 0.523523 0.889966 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259976 episodes
GETTING ACTION FROM:
action 2, numVisits=2259861, meanQ=4.889482, numObservations: 3
action 0, numVisits=93, meanQ=4.083242, numObservations: 1
action 3, numVisits=18, meanQ=2.777778, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.524626 0.856585 0.571586 0.895833 0.523523 0.889966 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 98
Initial state: 0 0.613459 0.801599 0.586356 0.84259 0.721045 0.0854712 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253299 episodes
GETTING ACTION FROM:
action 2, numVisits=2253293, meanQ=4.901100, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.613459 0.801599 0.586356 0.84259 0.721045 0.0854712 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 99
Initial state: 0 0.319056 0.180431 0.563007 0.861821 0.642087 0.829434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1563594 episodes
GETTING ACTION FROM:
action -1, numVisits=1563581, meanQ=3.051992, numObservations: 1
action 2, numVisits=7, meanQ=-1.287143, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.319056 0.180431 0.563007 0.861821 0.642087 0.829434 w: 1
Observation: 0 0.336965 0 0.524519 0 0.672515 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1563543, meanQ=5.106166, numObservations: 4
action -1, numVisits=25, meanQ=3.533368, numObservations: 1
action 1, numVisits=9, meanQ=2.553344, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2472015 episodes
GETTING ACTION FROM:
action 3, numVisits=4035556, meanQ=5.099892, numObservations: 4
action -1, numVisits=25, meanQ=3.533368, numObservations: 1
action 1, numVisits=11, meanQ=1.907282, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.319056 0.180431 0.563007 0.861821 0.642087 0.829434 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 100
Initial state: 0 0.543997 0.820076 0.587794 0.861488 0.910092 0.899353 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2224771 episodes
GETTING ACTION FROM:
action 2, numVisits=2224726, meanQ=4.903759, numObservations: 4
action 3, numVisits=30, meanQ=3.387670, numObservations: 4
action 1, numVisits=11, meanQ=2.453636, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.543997 0.820076 0.587794 0.861488 0.910092 0.899353 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 101
Initial state: 0 0.40247 0.158004 0.568309 0.896305 0.695204 0.805446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1546289 episodes
GETTING ACTION FROM:
action -1, numVisits=1428765, meanQ=2.958651, numObservations: 1
action 0, numVisits=117518, meanQ=2.807178, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.40247 0.158004 0.568309 0.896305 0.695204 0.805446 w: 1
Observation: 0 0.447838 0 0.535769 0 0.768903 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1402673, meanQ=5.009711, numObservations: 5
action 3, numVisits=25302, meanQ=4.950208, numObservations: 4
action 2, numVisits=785, meanQ=4.669240, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2458558 episodes
GETTING ACTION FROM:
action 1, numVisits=3861231, meanQ=5.017548, numObservations: 5
action 3, numVisits=25302, meanQ=4.950208, numObservations: 4
action 2, numVisits=785, meanQ=4.669240, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.40247 0.158004 0.568309 0.896305 0.695204 0.805446 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=488343, meanQ=8.357957, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2831620 episodes
GETTING ACTION FROM:
action 2, numVisits=3319961, meanQ=6.159799, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.40247 0.158004 0.568309 0.896305 0.695204 0.805446 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 102
Initial state: 0 0.760751 0.829893 0.587285 0.829459 0.518188 0.820964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2286461 episodes
GETTING ACTION FROM:
action 2, numVisits=2286307, meanQ=4.977555, numObservations: 4
action -1, numVisits=150, meanQ=4.353717, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.760751 0.829893 0.587285 0.829459 0.518188 0.820964 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 103
Initial state: 0 0.841808 0.865321 0.567003 0.839644 0.507266 0.871069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2168328 episodes
GETTING ACTION FROM:
action 3, numVisits=2168265, meanQ=4.836992, numObservations: 5
action 0, numVisits=45, meanQ=3.667441, numObservations: 1
action 1, numVisits=12, meanQ=2.167517, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.841808 0.865321 0.567003 0.839644 0.507266 0.871069 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 104
Initial state: 0 0.637739 0.818122 0.329056 0.908345 0.68541 0.875605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2265630 episodes
GETTING ACTION FROM:
action 1, numVisits=2265616, meanQ=4.987346, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.637739 0.818122 0.329056 0.908345 0.68541 0.875605 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 105
Initial state: 0 0.668145 0.808184 0.569001 0.875297 0.479685 0.323976 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2228200 episodes
GETTING ACTION FROM:
action 1, numVisits=2228194, meanQ=4.908792, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.668145 0.808184 0.569001 0.875297 0.479685 0.323976 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 106
Initial state: 0 0.935303 0.717799 0.605399 0.866833 0.664753 0.801071 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2242665 episodes
GETTING ACTION FROM:
action 2, numVisits=2242647, meanQ=4.919565, numObservations: 4
action 1, numVisits=8, meanQ=1.747513, numObservations: 3
action 3, numVisits=6, meanQ=1.001683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.935303 0.717799 0.605399 0.866833 0.664753 0.801071 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=160829, meanQ=4.634301, numObservations: 4
action -1, numVisits=3938, meanQ=2.653778, numObservations: 1
action 3, numVisits=8, meanQ=-0.752487, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2832603 episodes
GETTING ACTION FROM:
action 1, numVisits=2993432, meanQ=5.811290, numObservations: 4
action -1, numVisits=3938, meanQ=2.653778, numObservations: 1
action 3, numVisits=8, meanQ=-0.752487, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.935303 0.717799 0.605399 0.866833 0.664753 0.801071 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 107
Initial state: 0 0.0757375 0.210234 0.6187 0.85348 0.586415 0.80896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1444576 episodes
GETTING ACTION FROM:
action 0, numVisits=1444571, meanQ=5.225030, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.0757375 0.210234 0.6187 0.85348 0.586415 0.80896 w: 1
Observation: 0 0 0.280729 0 0.948105 0 0.864111 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=473501, meanQ=5.908556, numObservations: 1
action 1, numVisits=8, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1633852 episodes
GETTING ACTION FROM:
action 0, numVisits=2107353, meanQ=4.621955, numObservations: 1
action 1, numVisits=8, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0757375 0.210234 0.6187 0.85348 0.586415 0.80896 w: 1
Observation: 0 0 0.173248 0 0.903779 0 0.760162 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=2107277, meanQ=5.669899, numObservations: 4
action 1, numVisits=70, meanQ=3.436146, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 2404405 episodes
GETTING ACTION FROM:
action 3, numVisits=4511682, meanQ=5.257828, numObservations: 4
action 1, numVisits=70, meanQ=3.436146, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.0757375 0.210234 0.6187 0.85348 0.586415 0.80896 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 108
Initial state: 0 0.568594 0.838193 0.795873 0.828826 0.506775 0.882002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2269823 episodes
GETTING ACTION FROM:
action 1, numVisits=2267638, meanQ=4.915466, numObservations: 4
action -1, numVisits=2181, meanQ=2.802967, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.568594 0.838193 0.795873 0.828826 0.506775 0.882002 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 109
Initial state: 0 0.543672 0.832624 0.558773 0.863612 0.979122 0.947842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1589499 episodes
GETTING ACTION FROM:
action 0, numVisits=1589487, meanQ=5.728663, numObservations: 3
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.543672 0.832624 0.558773 0.863612 0.979122 0.947842 w: 1
Observation: 0 0 0.760117 0 0.77708 0 0.926251 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=611039, meanQ=7.628557, numObservations: 5
action 1, numVisits=9, meanQ=2.553344, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2426813 episodes
GETTING ACTION FROM:
action 3, numVisits=3037841, meanQ=5.543553, numObservations: 5
action 0, numVisits=11, meanQ=2.890000, numObservations: 1
action 1, numVisits=9, meanQ=2.553344, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.543672 0.832624 0.558773 0.863612 0.979122 0.947842 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 110
Initial state: 0 0.639242 0.845425 0.549295 0.804402 0.599184 0.68338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2212355 episodes
GETTING ACTION FROM:
action 1, numVisits=2212299, meanQ=4.980051, numObservations: 4
action -1, numVisits=46, meanQ=3.854988, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.639242 0.845425 0.549295 0.804402 0.599184 0.68338 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 111
Initial state: 0 0.629938 0.894646 0.558969 0.822877 0.619108 0.574273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261979 episodes
GETTING ACTION FROM:
action 1, numVisits=2261837, meanQ=4.919255, numObservations: 3
action 0, numVisits=106, meanQ=4.179508, numObservations: 1
action -1, numVisits=33, meanQ=3.555634, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.629938 0.894646 0.558969 0.822877 0.619108 0.574273 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 112
Initial state: 0 0.545381 0.522293 0.619248 0.875683 0.520098 0.836507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2249189 episodes
GETTING ACTION FROM:
action 3, numVisits=2249174, meanQ=4.911699, numObservations: 4
action 2, numVisits=10, meanQ=1.799000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.545381 0.522293 0.619248 0.875683 0.520098 0.836507 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 113
Initial state: 0 0.693744 0.863128 0.324314 0.509174 0.646086 0.875408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2299812 episodes
GETTING ACTION FROM:
action 2, numVisits=2299788, meanQ=4.977727, numObservations: 3
action 1, numVisits=19, meanQ=2.684216, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.693744 0.863128 0.324314 0.509174 0.646086 0.875408 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=350873, meanQ=8.268079, numObservations: 3
action 3, numVisits=10, meanQ=5.799000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2839952 episodes
GETTING ACTION FROM:
action 1, numVisits=3190813, meanQ=6.169412, numObservations: 3
action 3, numVisits=20, meanQ=4.399500, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.693744 0.863128 0.324314 0.509174 0.646086 0.875408 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 114
Initial state: 0 0.936788 0.419413 0.560447 0.854428 0.545374 0.877189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2286257 episodes
GETTING ACTION FROM:
action 1, numVisits=2282734, meanQ=4.919275, numObservations: 3
action 0, numVisits=3515, meanQ=2.873640, numObservations: 1
action 2, numVisits=5, meanQ=-1.402000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.936788 0.419413 0.560447 0.854428 0.545374 0.877189 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 115
Initial state: 0 0.676614 0.341696 0.63071 0.86187 0.522919 0.817605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1535677 episodes
GETTING ACTION FROM:
action 0, numVisits=1535507, meanQ=2.898231, numObservations: 1
action -1, numVisits=167, meanQ=1.920006, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.676614 0.341696 0.63071 0.86187 0.522919 0.817605 w: 1
Observation: 0 0 0.305588 0 0.855394 0 0.825791 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1535498, meanQ=4.973834, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2430281 episodes
GETTING ACTION FROM:
action 1, numVisits=3965779, meanQ=4.864683, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.676614 0.341696 0.63071 0.86187 0.522919 0.817605 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 116
Initial state: 0 0.945235 0.852193 0.533904 0.897547 0.524694 0.882659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2224953 episodes
GETTING ACTION FROM:
action 2, numVisits=2223848, meanQ=4.982542, numObservations: 5
action 1, numVisits=1083, meanQ=4.729683, numObservations: 5
action 0, numVisits=19, meanQ=3.034849, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.945235 0.852193 0.533904 0.897547 0.524694 0.882659 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 117
Initial state: 0 0.541102 0.804072 0.728135 0.143841 0.571278 0.859227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2244051 episodes
GETTING ACTION FROM:
action 3, numVisits=2243875, meanQ=4.992130, numObservations: 5
action -1, numVisits=121, meanQ=4.296766, numObservations: 1
action 0, numVisits=53, meanQ=3.928195, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.541102 0.804072 0.728135 0.143841 0.571278 0.859227 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 118
Initial state: 0 0.505624 0.812119 0.542509 0.214264 0.575498 0.868839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239923 episodes
GETTING ACTION FROM:
action 2, numVisits=2239821, meanQ=4.918730, numObservations: 5
action 0, numVisits=56, meanQ=3.899317, numObservations: 1
action -1, numVisits=38, meanQ=3.639613, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 0 0.505624 0.812119 0.542509 0.214264 0.575498 0.868839 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=164182, meanQ=4.667350, numObservations: 4
action 2, numVisits=49, meanQ=3.569804, numObservations: 3
action 1, numVisits=11, meanQ=2.453636, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 2798732 episodes
GETTING ACTION FROM:
action 3, numVisits=2962914, meanQ=5.924806, numObservations: 4
action 2, numVisits=49, meanQ=3.569804, numObservations: 3
action 1, numVisits=11, meanQ=2.453636, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.505624 0.812119 0.542509 0.214264 0.575498 0.868839 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 119
Initial state: 0 0.959246 0.977876 0.681929 0.819459 0.626706 0.826161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1553367 episodes
GETTING ACTION FROM:
action -1, numVisits=1553354, meanQ=2.938615, numObservations: 1
action 2, numVisits=6, meanQ=-1.670000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.959246 0.977876 0.681929 0.819459 0.626706 0.826161 w: 1
Observation: 0 1 0 0.602021 0 0.546882 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1553279, meanQ=4.991614, numObservations: 5
action -1, numVisits=70, meanQ=4.064293, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2418950 episodes
GETTING ACTION FROM:
action 3, numVisits=3972224, meanQ=4.874407, numObservations: 5
action -1, numVisits=75, meanQ=3.962206, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.959246 0.977876 0.681929 0.819459 0.626706 0.826161 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 120
Initial state: 0 0.602043 0.898986 0.694766 0.898732 0.275952 0.256237 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2240091 episodes
GETTING ACTION FROM:
action 3, numVisits=2240035, meanQ=4.905028, numObservations: 5
action -1, numVisits=36, meanQ=3.604815, numObservations: 1
action 2, numVisits=12, meanQ=1.343342, numObservations: 2
action 1, numVisits=6, meanQ=1.331683, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.602043 0.898986 0.694766 0.898732 0.275952 0.256237 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=219690, meanQ=8.536858, numObservations: 3
action 2, numVisits=6, meanQ=4.665017, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2870152 episodes
GETTING ACTION FROM:
action 1, numVisits=3089839, meanQ=5.967949, numObservations: 3
action 2, numVisits=7, meanQ=2.427157, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.602043 0.898986 0.694766 0.898732 0.275952 0.256237 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 121
Initial state: 0 0.570249 0.276194 0.51676 0.873515 0.670393 0.876565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1555355 episodes
GETTING ACTION FROM:
action 0, numVisits=1555346, meanQ=2.857869, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.570249 0.276194 0.51676 0.873515 0.670393 0.876565 w: 1
Observation: 0 0 0.316429 0 0.946529 0 0.820022 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1555219, meanQ=4.913482, numObservations: 4
action -1, numVisits=77, meanQ=4.056222, numObservations: 1
action 2, numVisits=29, meanQ=3.134148, numObservations: 3
action 1, numVisits=18, meanQ=3.110017, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2460698 episodes
GETTING ACTION FROM:
action 3, numVisits=4015908, meanQ=4.882588, numObservations: 4
action -1, numVisits=80, meanQ=4.000740, numObservations: 1
action 2, numVisits=29, meanQ=3.134148, numObservations: 3
action 1, numVisits=24, meanQ=2.995433, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.570249 0.276194 0.51676 0.873515 0.670393 0.876565 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 122
Initial state: 0 0.575196 0.840284 0.529341 0.880475 0.341858 0.145749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2238337 episodes
GETTING ACTION FROM:
action 1, numVisits=2238262, meanQ=5.158167, numObservations: 5
action 0, numVisits=68, meanQ=4.229764, numObservations: 1
action 3, numVisits=4, meanQ=0.025000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.575196 0.840284 0.529341 0.880475 0.341858 0.145749 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 123
Initial state: 0 0.102962 0.245463 0.674969 0.833964 0.565031 0.816691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1546878 episodes
GETTING ACTION FROM:
action -1, numVisits=1546850, meanQ=2.936161, numObservations: 1
action 1, numVisits=19, meanQ=1.204747, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action: -1
Next state: 0 0.102962 0.245463 0.674969 0.833964 0.565031 0.816691 w: 1
Observation: 0 0.0300619 0 0.67199 0 0.507611 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1546794, meanQ=4.988079, numObservations: 5
action 0, numVisits=48, meanQ=3.889117, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2407566 episodes
GETTING ACTION FROM:
action 3, numVisits=3954357, meanQ=4.905881, numObservations: 5
action 0, numVisits=51, meanQ=3.776117, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.102962 0.245463 0.674969 0.833964 0.565031 0.816691 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 124
Initial state: 0 0.645799 0.885033 0.738265 0.413865 0.544097 0.82033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2185897 episodes
GETTING ACTION FROM:
action 3, numVisits=2185806, meanQ=4.982332, numObservations: 4
action 0, numVisits=86, meanQ=4.115802, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.645799 0.885033 0.738265 0.413865 0.544097 0.82033 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 125
Initial state: 0 0.898967 0.804558 0.631123 0.834197 0.608114 0.841596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2234480 episodes
GETTING ACTION FROM:
action 3, numVisits=2234195, meanQ=4.877655, numObservations: 4
action 2, numVisits=263, meanQ=4.366118, numObservations: 5
action -1, numVisits=18, meanQ=2.994087, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.898967 0.804558 0.631123 0.834197 0.608114 0.841596 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 126
Initial state: 0 0.705115 0.54441 0.504359 0.841278 0.503545 0.860768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2296214 episodes
GETTING ACTION FROM:
action 1, numVisits=2296208, meanQ=4.978220, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.705115 0.54441 0.504359 0.841278 0.503545 0.860768 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 127
Initial state: 0 0.533874 0.816336 0.576623 0.841816 0.613307 0.642763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2257841 episodes
GETTING ACTION FROM:
action 3, numVisits=2257835, meanQ=5.110293, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.533874 0.816336 0.576623 0.841816 0.613307 0.642763 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=138647, meanQ=8.012237, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2846524 episodes
GETTING ACTION FROM:
action 1, numVisits=2985168, meanQ=5.898490, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.533874 0.816336 0.576623 0.841816 0.613307 0.642763 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=59934, meanQ=7.564277, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2924989 episodes
GETTING ACTION FROM:
action 1, numVisits=2984921, meanQ=5.465506, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.533874 0.816336 0.576623 0.841816 0.613307 0.642763 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 128
Initial state: 0 0.0229609 0.592254 0.613191 0.802173 0.525501 0.858986 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1598194 episodes
GETTING ACTION FROM:
action 0, numVisits=1585414, meanQ=5.872792, numObservations: 3
action 3, numVisits=12759, meanQ=5.085396, numObservations: 4
action 1, numVisits=18, meanQ=2.990006, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0229609 0.592254 0.613191 0.802173 0.525501 0.858986 w: 1
Observation: 0 0 0.565189 0 0.796254 0 0.812537 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=594167, meanQ=7.699286, numObservations: 5
action 1, numVisits=62, meanQ=5.209356, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2414591 episodes
GETTING ACTION FROM:
action 3, numVisits=3006442, meanQ=5.283820, numObservations: 5
action 1, numVisits=2366, meanQ=5.127278, numObservations: 4
action -1, numVisits=12, meanQ=2.619044, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0229609 0.592254 0.613191 0.802173 0.525501 0.858986 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 129
Initial state: 0 0.687035 0.418625 0.666994 0.881675 0.598688 0.806342 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2217502 episodes
GETTING ACTION FROM:
action 2, numVisits=2217458, meanQ=4.991868, numObservations: 5
action 3, numVisits=39, meanQ=3.501036, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.687035 0.418625 0.666994 0.881675 0.598688 0.806342 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 130
Initial state: 0 0.569467 0.837706 0.696842 0.892223 0.187029 0.50175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2219545 episodes
GETTING ACTION FROM:
action 3, numVisits=2219538, meanQ=4.979838, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.569467 0.837706 0.696842 0.892223 0.187029 0.50175 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=338356, meanQ=8.323645, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2808765 episodes
GETTING ACTION FROM:
action 1, numVisits=3147121, meanQ=6.210070, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.569467 0.837706 0.696842 0.892223 0.187029 0.50175 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 131
Initial state: 0 0.696899 0.826785 0.214129 0.364399 0.618462 0.878896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2229157 episodes
GETTING ACTION FROM:
action 2, numVisits=2229140, meanQ=4.914084, numObservations: 5
action 3, numVisits=12, meanQ=1.997517, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.696899 0.826785 0.214129 0.364399 0.618462 0.878896 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=283427, meanQ=8.384732, numObservations: 3
action 1, numVisits=53, meanQ=7.339628, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2881223 episodes
GETTING ACTION FROM:
action 3, numVisits=3163932, meanQ=6.136066, numObservations: 3
action 1, numVisits=769, meanQ=5.855600, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.696899 0.826785 0.214129 0.364399 0.618462 0.878896 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 132
Initial state: 0 0.643337 0.816829 0.631324 0.826841 0.706854 0.972007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2257691 episodes
GETTING ACTION FROM:
action 2, numVisits=2257685, meanQ=4.968666, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.643337 0.816829 0.631324 0.826841 0.706854 0.972007 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 133
Initial state: 0 0.428672 0.766338 0.561613 0.811508 0.688122 0.886286 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263044 episodes
GETTING ACTION FROM:
action 3, numVisits=2256607, meanQ=4.989197, numObservations: 4
action -1, numVisits=6425, meanQ=3.114178, numObservations: 1
action 1, numVisits=9, meanQ=0.997800, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.428672 0.766338 0.561613 0.811508 0.688122 0.886286 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 134
Initial state: 0 0.623958 0.862259 0.845555 0.0227101 0.509944 0.858271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1658640 episodes
GETTING ACTION FROM:
action 0, numVisits=1468898, meanQ=5.880558, numObservations: 3
action 2, numVisits=189735, meanQ=4.954430, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.623958 0.862259 0.845555 0.0227101 0.509944 0.858271 w: 1
Observation: 0 0 0.954239 0 0 0 0.846854 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=472711, meanQ=7.976116, numObservations: 4
action 1, numVisits=5, meanQ=3.402020, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2329089 episodes
GETTING ACTION FROM:
action 1, numVisits=354272, meanQ=5.222315, numObservations: 4
action 3, numVisits=2447531, meanQ=5.201314, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.623958 0.862259 0.845555 0.0227101 0.509944 0.858271 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 135
Initial state: 0 0.592262 0.819759 0.867059 0.142757 0.670825 0.854226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2212838 episodes
GETTING ACTION FROM:
action 2, numVisits=2200720, meanQ=4.887763, numObservations: 5
action -1, numVisits=12114, meanQ=3.066959, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.592262 0.819759 0.867059 0.142757 0.670825 0.854226 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=115176, meanQ=4.708073, numObservations: 5
action -1, numVisits=46304, meanQ=3.609073, numObservations: 1
action 0, numVisits=922, meanQ=3.422661, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2811721 episodes
GETTING ACTION FROM:
action 1, numVisits=2926897, meanQ=5.908266, numObservations: 5
action -1, numVisits=46304, meanQ=3.609073, numObservations: 1
action 0, numVisits=922, meanQ=3.422661, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.592262 0.819759 0.867059 0.142757 0.670825 0.854226 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=24033, meanQ=7.301417, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2915463 episodes
GETTING ACTION FROM:
action 2, numVisits=2939494, meanQ=6.160833, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.592262 0.819759 0.867059 0.142757 0.670825 0.854226 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 136
Initial state: 0 0.580917 0.808626 0.430829 0.594936 0.595812 0.814504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2240923 episodes
GETTING ACTION FROM:
action 2, numVisits=2103891, meanQ=4.984107, numObservations: 5
action 3, numVisits=136958, meanQ=4.945972, numObservations: 4
action 0, numVisits=48, meanQ=3.877539, numObservations: 1
action -1, numVisits=22, meanQ=3.314923, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action: 2
Next state: 0 0.580917 0.808626 0.430829 0.594936 0.595812 0.814504 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=266589, meanQ=8.371356, numObservations: 5
action 1, numVisits=36, meanQ=6.938897, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2787885 episodes
GETTING ACTION FROM:
action 3, numVisits=3054429, meanQ=6.082717, numObservations: 5
action 1, numVisits=79, meanQ=5.123928, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.580917 0.808626 0.430829 0.594936 0.595812 0.814504 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 137
Initial state: 0 0.51205 0.813107 0.360101 0.749511 0.577469 0.861824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262672 episodes
GETTING ACTION FROM:
action 2, numVisits=2262642, meanQ=4.903994, numObservations: 4
action 0, numVisits=26, meanQ=3.232159, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.51205 0.813107 0.360101 0.749511 0.577469 0.861824 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=287195, meanQ=8.389534, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2835520 episodes
GETTING ACTION FROM:
action 3, numVisits=3122713, meanQ=6.052043, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.51205 0.813107 0.360101 0.749511 0.577469 0.861824 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=78784, meanQ=7.241835, numObservations: 3
action 3, numVisits=8, meanQ=3.248762, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2943746 episodes
GETTING ACTION FROM:
action 1, numVisits=3022528, meanQ=6.398299, numObservations: 3
action 3, numVisits=8, meanQ=3.248762, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.51205 0.813107 0.360101 0.749511 0.577469 0.861824 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 138
Initial state: 0 0.546074 0.899435 0.39486 0.824524 0.508891 0.876281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1585850 episodes
GETTING ACTION FROM:
action 0, numVisits=1577464, meanQ=5.787779, numObservations: 3
action 3, numVisits=8373, meanQ=4.934908, numObservations: 3
action 1, numVisits=9, meanQ=2.774444, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 0
Next state: 0 0.546074 0.899435 0.39486 0.824524 0.508891 0.876281 w: 1
Observation: 0 0 0.870575 0 0.905749 0 0.811202 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=719659, meanQ=7.382813, numObservations: 5
action 2, numVisits=5, meanQ=2.598000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2428365 episodes
GETTING ACTION FROM:
action 1, numVisits=3148021, meanQ=5.484941, numObservations: 5
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.546074 0.899435 0.39486 0.824524 0.508891 0.876281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 139
Initial state: 0 0.678934 0.84869 0.598573 0.884204 0.0451144 0.0244199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2250868 episodes
GETTING ACTION FROM:
action 1, numVisits=2236492, meanQ=4.958388, numObservations: 4
action -1, numVisits=14372, meanQ=3.126545, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.678934 0.84869 0.598573 0.884204 0.0451144 0.0244199 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 140
Initial state: 0 0.508179 0.400433 0.525447 0.816986 0.526665 0.891682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271746 episodes
GETTING ACTION FROM:
action 2, numVisits=2271628, meanQ=4.913296, numObservations: 4
action 0, numVisits=54, meanQ=3.871237, numObservations: 1
action -1, numVisits=51, meanQ=3.841696, numObservations: 1
action 3, numVisits=12, meanQ=2.675000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.508179 0.400433 0.525447 0.816986 0.526665 0.891682 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 141
Initial state: 0 0.313919 0.440649 0.574472 0.842187 0.585601 0.891542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2286005 episodes
GETTING ACTION FROM:
action 3, numVisits=2285948, meanQ=4.922530, numObservations: 3
action -1, numVisits=36, meanQ=3.639504, numObservations: 1
action 2, numVisits=11, meanQ=2.453636, numObservations: 3
action 1, numVisits=8, meanQ=1.747513, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.313919 0.440649 0.574472 0.842187 0.585601 0.891542 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 142
Initial state: 0 0.544461 0.808388 0.5667 0.853304 0.0836379 0.930822 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2176900 episodes
GETTING ACTION FROM:
action 1, numVisits=2176791, meanQ=4.833771, numObservations: 4
action 0, numVisits=92, meanQ=4.032882, numObservations: 1
action 3, numVisits=8, meanQ=1.987500, numObservations: 2
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.544461 0.808388 0.5667 0.853304 0.0836379 0.930822 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 143
Initial state: 0 0.672028 0.851035 0.252106 0.824813 0.525256 0.835926 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2184889 episodes
GETTING ACTION FROM:
action 1, numVisits=2184880, meanQ=4.852931, numObservations: 5
action 2, numVisits=4, meanQ=-0.999975, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.672028 0.851035 0.252106 0.824813 0.525256 0.835926 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 144
Initial state: 0 0.560808 0.679274 0.653103 0.893932 0.617089 0.815957 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247233 episodes
GETTING ACTION FROM:
action 3, numVisits=2247144, meanQ=4.980528, numObservations: 5
action -1, numVisits=73, meanQ=4.085177, numObservations: 1
action 1, numVisits=12, meanQ=1.998333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.560808 0.679274 0.653103 0.893932 0.617089 0.815957 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 145
Initial state: 0 0.590827 0.837054 0.613596 0.899443 0.743889 0.134436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1589380 episodes
GETTING ACTION FROM:
action 0, numVisits=1589369, meanQ=5.721394, numObservations: 3
action 1, numVisits=7, meanQ=0.428571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.590827 0.837054 0.613596 0.899443 0.743889 0.134436 w: 1
Observation: 0 0 0.757728 0 0.976482 0 0.198576 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=806347, meanQ=7.183290, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2453438 episodes
GETTING ACTION FROM:
action 1, numVisits=3259783, meanQ=5.323524, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.590827 0.837054 0.613596 0.899443 0.743889 0.134436 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 146
Initial state: 0 0.645526 0.892417 0.726978 0.638297 0.693437 0.86461 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2168662 episodes
GETTING ACTION FROM:
action 3, numVisits=2168655, meanQ=4.842485, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.645526 0.892417 0.726978 0.638297 0.693437 0.86461 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 147
Initial state: 0 0.670665 0.837355 0.287689 0.596996 0.607598 0.855062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2161148 episodes
GETTING ACTION FROM:
action 3, numVisits=2161142, meanQ=4.843146, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.670665 0.837355 0.287689 0.596996 0.607598 0.855062 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 148
Initial state: 0 0.530824 0.875391 0.968362 0.498065 0.564966 0.817217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2284252 episodes
GETTING ACTION FROM:
action 2, numVisits=2276730, meanQ=4.990434, numObservations: 4
action -1, numVisits=7513, meanQ=2.923618, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.530824 0.875391 0.968362 0.498065 0.564966 0.817217 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 149
Initial state: 0 0.57411 0.89615 0.673135 0.867999 0.800469 0.961838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264135 episodes
GETTING ACTION FROM:
action 1, numVisits=2264104, meanQ=4.984121, numObservations: 4
action 0, numVisits=25, meanQ=3.391934, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.57411 0.89615 0.673135 0.867999 0.800469 0.961838 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 150
Initial state: 0 0.616828 0.859501 0.501698 0.852143 0.86064 0.465091 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2252504 episodes
GETTING ACTION FROM:
action 3, numVisits=2252494, meanQ=4.901294, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.616828 0.859501 0.501698 0.852143 0.86064 0.465091 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 151
Initial state: 0 0.855149 0.136107 0.661841 0.830131 0.68745 0.868772 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237869 episodes
GETTING ACTION FROM:
action 1, numVisits=2237863, meanQ=4.899942, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.855149 0.136107 0.661841 0.830131 0.68745 0.868772 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 152
Initial state: 0 0.765949 0.659718 0.556967 0.891605 0.605782 0.810754 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1534565 episodes
GETTING ACTION FROM:
action -1, numVisits=1534557, meanQ=2.832254, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action: -1
Next state: 0 0.765949 0.659718 0.556967 0.891605 0.605782 0.810754 w: 1
Observation: 0 0.810034 0 0.549649 0 0.518518 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1534540, meanQ=4.880353, numObservations: 4
action 3, numVisits=9, meanQ=1.432222, numObservations: 3
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 2429584 episodes
GETTING ACTION FROM:
action 2, numVisits=3964124, meanQ=5.063698, numObservations: 4
action 3, numVisits=9, meanQ=1.432222, numObservations: 3
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.765949 0.659718 0.556967 0.891605 0.605782 0.810754 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=613015, meanQ=8.317388, numObservations: 4
action 1, numVisits=27, meanQ=6.915185, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2837626 episodes
GETTING ACTION FROM:
action 3, numVisits=3450563, meanQ=6.171370, numObservations: 4
action 1, numVisits=103, meanQ=5.385050, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.765949 0.659718 0.556967 0.891605 0.605782 0.810754 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 153
Initial state: 0 0.55966 0.845119 0.589264 0.870345 0.166322 0.165877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2284001 episodes
GETTING ACTION FROM:
action 2, numVisits=2283994, meanQ=4.970634, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.55966 0.845119 0.589264 0.870345 0.166322 0.165877 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=166657, meanQ=5.550912, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2617381 episodes
GETTING ACTION FROM:
action 2, numVisits=2784038, meanQ=4.866057, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.55966 0.845119 0.589264 0.870345 0.166322 0.165877 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=100767, meanQ=8.384444, numObservations: 4
action 1, numVisits=173, meanQ=7.030749, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2876599 episodes
GETTING ACTION FROM:
action 3, numVisits=2974038, meanQ=6.080838, numObservations: 4
action 1, numVisits=3499, meanQ=5.951235, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.55966 0.845119 0.589264 0.870345 0.166322 0.165877 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=7042, meanQ=8.294057, numObservations: 4
action 2, numVisits=4, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2912149 episodes
GETTING ACTION FROM:
action 1, numVisits=2919182, meanQ=6.390132, numObservations: 4
action 2, numVisits=11, meanQ=3.180000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.55966 0.845119 0.589264 0.870345 0.166322 0.165877 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 154
Initial state: 0 0.730982 0.651957 0.589156 0.838212 0.661154 0.804368 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253485 episodes
GETTING ACTION FROM:
action 3, numVisits=2253479, meanQ=5.000675, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.730982 0.651957 0.589156 0.838212 0.661154 0.804368 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 155
Initial state: 0 0.584186 0.793994 0.628229 0.882995 0.62366 0.852523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2260396 episodes
GETTING ACTION FROM:
action 3, numVisits=2260312, meanQ=4.955065, numObservations: 4
action -1, numVisits=49, meanQ=3.859955, numObservations: 1
action 0, numVisits=33, meanQ=3.623134, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.584186 0.793994 0.628229 0.882995 0.62366 0.852523 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 156
Initial state: 0 0.534739 0.89911 0.594475 0.856321 0.139975 0.763481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2276614 episodes
GETTING ACTION FROM:
action 1, numVisits=2276599, meanQ=4.918816, numObservations: 3
action 3, numVisits=10, meanQ=0.597020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.534739 0.89911 0.594475 0.856321 0.139975 0.763481 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 157
Initial state: 0 0.521609 0.863225 0.536638 0.475362 0.527472 0.82907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2236597 episodes
GETTING ACTION FROM:
action 3, numVisits=2236588, meanQ=4.902913, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.521609 0.863225 0.536638 0.475362 0.527472 0.82907 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=163847, meanQ=4.705605, numObservations: 5
action 0, numVisits=347, meanQ=4.345600, numObservations: 1
action 1, numVisits=38, meanQ=3.521582, numObservations: 4
action 3, numVisits=9, meanQ=1.886667, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 2743846 episodes
GETTING ACTION FROM:
action 2, numVisits=2907693, meanQ=5.787989, numObservations: 5
action 0, numVisits=347, meanQ=4.345600, numObservations: 1
action 1, numVisits=38, meanQ=3.521582, numObservations: 4
action 3, numVisits=9, meanQ=1.886667, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.521609 0.863225 0.536638 0.475362 0.527472 0.82907 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=27350, meanQ=8.321502, numObservations: 5
action 3, numVisits=25652, meanQ=8.318889, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2923232 episodes
GETTING ACTION FROM:
action 3, numVisits=2360377, meanQ=5.981601, numObservations: 3
action 1, numVisits=615855, meanQ=5.976663, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.521609 0.863225 0.536638 0.475362 0.527472 0.82907 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=6002, meanQ=7.415012, numObservations: 4
action 3, numVisits=39, meanQ=6.535646, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2929722 episodes
GETTING ACTION FROM:
action 1, numVisits=2935679, meanQ=5.920791, numObservations: 4
action 3, numVisits=82, meanQ=5.071711, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.521609 0.863225 0.536638 0.475362 0.527472 0.82907 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 158
Initial state: 0 0.686072 0.82037 0.648957 0.847165 0.00509643 0.716946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2277223 episodes
GETTING ACTION FROM:
action 1, numVisits=2277164, meanQ=4.981365, numObservations: 4
action 3, numVisits=33, meanQ=3.175461, numObservations: 4
action 2, numVisits=22, meanQ=3.168182, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.686072 0.82037 0.648957 0.847165 0.00509643 0.716946 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 159
Initial state: 0 0.577744 0.852645 0.624722 0.858112 0.789501 0.57706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1566545 episodes
GETTING ACTION FROM:
action 0, numVisits=1566540, meanQ=5.320690, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.577744 0.852645 0.624722 0.858112 0.789501 0.57706 w: 1
Observation: 0 0 0.759233 0 0.863377 0 0.598142 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1218714, meanQ=7.109991, numObservations: 4
action 2, numVisits=14, meanQ=2.856436, numObservations: 5
action 3, numVisits=7, meanQ=2.144300, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2393259 episodes
GETTING ACTION FROM:
action 1, numVisits=3611971, meanQ=5.766218, numObservations: 4
action 2, numVisits=14, meanQ=2.856436, numObservations: 5
action 3, numVisits=7, meanQ=2.144300, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.577744 0.852645 0.624722 0.858112 0.789501 0.57706 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 160
Initial state: 0 0.844147 0.585763 0.689997 0.834112 0.580997 0.820319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264259 episodes
GETTING ACTION FROM:
action 3, numVisits=2264249, meanQ=4.921675, numObservations: 3
action 1, numVisits=5, meanQ=-0.201980, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.844147 0.585763 0.689997 0.834112 0.580997 0.820319 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 161
Initial state: 0 0.611582 0.826487 0.79305 0.775871 0.588326 0.848303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2298161 episodes
GETTING ACTION FROM:
action 1, numVisits=2298155, meanQ=4.921607, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.611582 0.826487 0.79305 0.775871 0.588326 0.848303 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 162
Initial state: 0 0.601579 0.808434 0.686026 0.83096 0.728982 0.0935924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2266375 episodes
GETTING ACTION FROM:
action 3, numVisits=2266364, meanQ=4.991547, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=6, meanQ=-2.318333, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.601579 0.808434 0.686026 0.83096 0.728982 0.0935924 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 163
Initial state: 0 0.681792 0.789811 0.670382 0.850679 0.62527 0.867493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2227962 episodes
GETTING ACTION FROM:
action 3, numVisits=2227901, meanQ=4.920404, numObservations: 5
action 0, numVisits=56, meanQ=3.780882, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.681792 0.789811 0.670382 0.850679 0.62527 0.867493 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 164
Initial state: 0 0.060082 0.137413 0.677078 0.823801 0.665658 0.898344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271432 episodes
GETTING ACTION FROM:
action 2, numVisits=2271424, meanQ=4.983803, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.060082 0.137413 0.677078 0.823801 0.665658 0.898344 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 165
Initial state: 0 0.66104 0.887652 0.545485 0.841343 0.857159 0.524434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2251334 episodes
GETTING ACTION FROM:
action 3, numVisits=2251283, meanQ=4.903196, numObservations: 4
action 0, numVisits=46, meanQ=3.763704, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.66104 0.887652 0.545485 0.841343 0.857159 0.524434 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=20145, meanQ=4.405995, numObservations: 4
action 3, numVisits=8, meanQ=-0.025000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2823834 episodes
GETTING ACTION FROM:
action 1, numVisits=2843979, meanQ=6.045037, numObservations: 4
action 3, numVisits=8, meanQ=-0.025000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.66104 0.887652 0.545485 0.841343 0.857159 0.524434 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 166
Initial state: 0 0.66758 0.233826 0.629602 0.849561 0.559386 0.886628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264777 episodes
GETTING ACTION FROM:
action 1, numVisits=2264631, meanQ=4.984853, numObservations: 4
action 0, numVisits=109, meanQ=4.252734, numObservations: 1
action -1, numVisits=16, meanQ=2.974399, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 4
action 3, numVisits=14, meanQ=1.570000, numObservations: 4
action: 1
Next state: 2 0.66758 0.233826 0.629602 0.849561 0.559386 0.886628 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 167
Initial state: 0 0.530108 0.856606 0.974504 0.519331 0.577872 0.827375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2267385 episodes
GETTING ACTION FROM:
action 1, numVisits=2267141, meanQ=4.978070, numObservations: 4
action -1, numVisits=139, meanQ=4.329248, numObservations: 1
action 0, numVisits=74, meanQ=4.088934, numObservations: 1
action 3, numVisits=27, meanQ=3.218156, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.530108 0.856606 0.974504 0.519331 0.577872 0.827375 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 168
Initial state: 0 0.549344 0.834545 0.900553 0.114452 0.536431 0.885761 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262535 episodes
GETTING ACTION FROM:
action 3, numVisits=2262527, meanQ=4.928718, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.549344 0.834545 0.900553 0.114452 0.536431 0.885761 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 169
Initial state: 0 0.530148 0.845247 0.556475 0.812119 0.47863 0.641302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271423 episodes
GETTING ACTION FROM:
action 2, numVisits=2267237, meanQ=4.898747, numObservations: 3
action 0, numVisits=4176, meanQ=2.675771, numObservations: 1
action 1, numVisits=7, meanQ=-0.145714, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.530148 0.845247 0.556475 0.812119 0.47863 0.641302 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 170
Initial state: 0 0.177986 0.0810287 0.63252 0.803915 0.575964 0.880391 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271383 episodes
GETTING ACTION FROM:
action 2, numVisits=2271322, meanQ=4.989502, numObservations: 4
action -1, numVisits=50, meanQ=3.876296, numObservations: 1
action 1, numVisits=8, meanQ=0.486250, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.177986 0.0810287 0.63252 0.803915 0.575964 0.880391 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 171
Initial state: 0 0.746562 0.66757 0.591661 0.841958 0.638098 0.843653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259620 episodes
GETTING ACTION FROM:
action 3, numVisits=2259550, meanQ=4.922708, numObservations: 4
action 0, numVisits=38, meanQ=3.678403, numObservations: 1
action 2, numVisits=29, meanQ=3.187248, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.746562 0.66757 0.591661 0.841958 0.638098 0.843653 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 172
Initial state: 0 0.550486 0.888643 0.50366 0.874717 0.0662722 0.779525 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2244901 episodes
GETTING ACTION FROM:
action 3, numVisits=2244770, meanQ=4.991289, numObservations: 5
action -1, numVisits=126, meanQ=4.311442, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.550486 0.888643 0.50366 0.874717 0.0662722 0.779525 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=165870, meanQ=8.397243, numObservations: 4
action 1, numVisits=119077, meanQ=8.387795, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2818707 episodes
GETTING ACTION FROM:
action 1, numVisits=1674912, meanQ=6.138997, numObservations: 4
action 2, numVisits=1428740, meanQ=6.138435, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.550486 0.888643 0.50366 0.874717 0.0662722 0.779525 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 173
Initial state: 0 0.676883 0.859494 0.264539 0.153465 0.695907 0.884759 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2282536 episodes
GETTING ACTION FROM:
action 1, numVisits=2282451, meanQ=4.980896, numObservations: 4
action -1, numVisits=46, meanQ=3.799530, numObservations: 1
action 2, numVisits=36, meanQ=3.222508, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.676883 0.859494 0.264539 0.153465 0.695907 0.884759 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 174
Initial state: 0 0.672969 0.566517 0.507855 0.89314 0.655568 0.880643 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2217131 episodes
GETTING ACTION FROM:
action 2, numVisits=2211127, meanQ=4.988087, numObservations: 5
action -1, numVisits=5538, meanQ=2.871413, numObservations: 1
action 0, numVisits=464, meanQ=2.676041, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.672969 0.566517 0.507855 0.89314 0.655568 0.880643 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 175
Initial state: 0 0.571987 0.888008 0.220369 0.348453 0.589529 0.880906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237278 episodes
GETTING ACTION FROM:
action 2, numVisits=2237137, meanQ=4.974594, numObservations: 4
action -1, numVisits=93, meanQ=3.976702, numObservations: 1
action 0, numVisits=24, meanQ=3.330897, numObservations: 1
action 1, numVisits=18, meanQ=3.115006, numObservations: 4
action 3, numVisits=6, meanQ=1.663333, numObservations: 2
action: 2
Next state: 0 0.571987 0.888008 0.220369 0.348453 0.589529 0.880906 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=339609, meanQ=8.314846, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2810540 episodes
GETTING ACTION FROM:
action 3, numVisits=3150139, meanQ=6.418169, numObservations: 5
action 1, numVisits=9, meanQ=3.221111, numObservations: 3
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.571987 0.888008 0.220369 0.348453 0.589529 0.880906 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=76218, meanQ=7.960985, numObservations: 3
action 1, numVisits=9, meanQ=4.555567, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2879249 episodes
GETTING ACTION FROM:
action 1, numVisits=2558601, meanQ=6.268628, numObservations: 5
action 3, numVisits=396849, meanQ=6.238683, numObservations: 4
action 2, numVisits=26, meanQ=4.691923, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.571987 0.888008 0.220369 0.348453 0.589529 0.880906 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 176
Initial state: 0 0.672845 0.833804 0.256238 0.911269 0.568545 0.871388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247904 episodes
GETTING ACTION FROM:
action 3, numVisits=2247857, meanQ=5.000740, numObservations: 5
action -1, numVisits=25, meanQ=3.441904, numObservations: 1
action 0, numVisits=20, meanQ=3.214348, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.672845 0.833804 0.256238 0.911269 0.568545 0.871388 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 177
Initial state: 0 0.322215 0.595317 0.504237 0.87124 0.668953 0.820004 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2228294 episodes
GETTING ACTION FROM:
action 3, numVisits=2218417, meanQ=4.921657, numObservations: 5
action 0, numVisits=9860, meanQ=2.994538, numObservations: 1
action 2, numVisits=14, meanQ=0.693571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.322215 0.595317 0.504237 0.87124 0.668953 0.820004 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 178
Initial state: 0 0.639249 0.840779 0.00909303 0.672824 0.637697 0.810135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237514 episodes
GETTING ACTION FROM:
action 1, numVisits=2237411, meanQ=4.909561, numObservations: 5
action 0, numVisits=46, meanQ=3.732690, numObservations: 1
action 3, numVisits=46, meanQ=3.730876, numObservations: 3
action 2, numVisits=9, meanQ=0.998889, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.639249 0.840779 0.00909303 0.672824 0.637697 0.810135 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 179
Initial state: 0 0.680758 0.855092 0.673438 0.388854 0.575527 0.843031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1590428 episodes
GETTING ACTION FROM:
action 0, numVisits=1590423, meanQ=5.698454, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.680758 0.855092 0.673438 0.388854 0.575527 0.843031 w: 1
Observation: 0 0 0.934669 0 0.471722 0 0.861739 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=746177, meanQ=7.217315, numObservations: 4
action 1, numVisits=31, meanQ=3.888068, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2462539 episodes
GETTING ACTION FROM:
action 3, numVisits=3208714, meanQ=5.670622, numObservations: 4
action 1, numVisits=31, meanQ=3.888068, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.680758 0.855092 0.673438 0.388854 0.575527 0.843031 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 180
Initial state: 0 0.566998 0.850237 0.29207 0.0520719 0.681758 0.890646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239696 episodes
GETTING ACTION FROM:
action 2, numVisits=2239690, meanQ=4.985114, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.566998 0.850237 0.29207 0.0520719 0.681758 0.890646 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=284465, meanQ=8.387386, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2780618 episodes
GETTING ACTION FROM:
action 3, numVisits=3065081, meanQ=6.114073, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.566998 0.850237 0.29207 0.0520719 0.681758 0.890646 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=23128, meanQ=8.031942, numObservations: 4
action 3, numVisits=3, meanQ=2.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2906396 episodes
GETTING ACTION FROM:
action 1, numVisits=2929517, meanQ=6.176383, numObservations: 4
action 3, numVisits=8, meanQ=1.500000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.566998 0.850237 0.29207 0.0520719 0.681758 0.890646 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 181
Initial state: 0 0.591441 0.899529 0.453929 0.781672 0.550727 0.881944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2257863 episodes
GETTING ACTION FROM:
action 1, numVisits=2254134, meanQ=4.978570, numObservations: 4
action -1, numVisits=3725, meanQ=2.631504, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.591441 0.899529 0.453929 0.781672 0.550727 0.881944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 182
Initial state: 0 0.300421 0.159577 0.603643 0.875766 0.575204 0.852161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258810 episodes
GETTING ACTION FROM:
action 3, numVisits=2258788, meanQ=5.112325, numObservations: 4
action 1, numVisits=17, meanQ=2.993535, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.300421 0.159577 0.603643 0.875766 0.575204 0.852161 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.542615 0.896285 0.482911 0.145601 0.607918 0.841221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2287173 episodes
GETTING ACTION FROM:
action 2, numVisits=2287161, meanQ=5.009461, numObservations: 4
action 3, numVisits=7, meanQ=0.428586, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.542615 0.896285 0.482911 0.145601 0.607918 0.841221 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=346797, meanQ=8.292711, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2798636 episodes
GETTING ACTION FROM:
action 1, numVisits=3145431, meanQ=5.972106, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.542615 0.896285 0.482911 0.145601 0.607918 0.841221 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 184
Initial state: 0 0.0556003 0.00611488 0.57259 0.899261 0.511492 0.89994 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2252591 episodes
GETTING ACTION FROM:
action 2, numVisits=2252573, meanQ=4.905020, numObservations: 4
action 3, numVisits=9, meanQ=2.333333, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.0556003 0.00611488 0.57259 0.899261 0.511492 0.89994 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 185
Initial state: 0 0.88565 0.761487 0.664238 0.875524 0.533394 0.85882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268430 episodes
GETTING ACTION FROM:
action 1, numVisits=2268344, meanQ=4.976316, numObservations: 4
action 0, numVisits=61, meanQ=3.984553, numObservations: 1
action -1, numVisits=22, meanQ=3.283235, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.88565 0.761487 0.664238 0.875524 0.533394 0.85882 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 186
Initial state: 0 0.674908 0.843022 0.596806 0.824671 0.619394 0.8205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2279904 episodes
GETTING ACTION FROM:
action 1, numVisits=2279895, meanQ=4.990896, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.674908 0.843022 0.596806 0.824671 0.619394 0.8205 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 187
Initial state: 0 0.695504 0.812502 0.523561 0.892696 0.449159 0.49991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2285832 episodes
GETTING ACTION FROM:
action 3, numVisits=2285816, meanQ=5.014878, numObservations: 4
action -1, numVisits=12, meanQ=2.664983, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.695504 0.812502 0.523561 0.892696 0.449159 0.49991 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=347918, meanQ=8.317016, numObservations: 3
action 2, numVisits=3, meanQ=2.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2867013 episodes
GETTING ACTION FROM:
action 1, numVisits=3214834, meanQ=6.256728, numObservations: 3
action 2, numVisits=98, meanQ=5.428266, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.695504 0.812502 0.523561 0.892696 0.449159 0.49991 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 188
Initial state: 0 0.692548 0.825951 0.511617 0.823859 0.5357 0.898632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2248164 episodes
GETTING ACTION FROM:
action 1, numVisits=2248154, meanQ=4.998695, numObservations: 5
action 2, numVisits=5, meanQ=-1.402000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.692548 0.825951 0.511617 0.823859 0.5357 0.898632 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 189
Initial state: 0 0.669894 0.392248 0.619368 0.820052 0.548289 0.801462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2248303 episodes
GETTING ACTION FROM:
action 1, numVisits=2248275, meanQ=4.910690, numObservations: 4
action 0, numVisits=22, meanQ=3.212822, numObservations: 1
action 2, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.669894 0.392248 0.619368 0.820052 0.548289 0.801462 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=285337, meanQ=8.368504, numObservations: 5
action 2, numVisits=25, meanQ=6.520408, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2794039 episodes
GETTING ACTION FROM:
action 2, numVisits=844015, meanQ=6.124155, numObservations: 3
action 3, numVisits=2235384, meanQ=6.076784, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.669894 0.392248 0.619368 0.820052 0.548289 0.801462 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 190
Initial state: 0 0.626483 0.821121 0.690002 0.820375 0.987081 0.175514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2219026 episodes
GETTING ACTION FROM:
action 3, numVisits=2218993, meanQ=4.855723, numObservations: 3
action -1, numVisits=29, meanQ=3.412157, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.626483 0.821121 0.690002 0.820375 0.987081 0.175514 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=313505, meanQ=8.331244, numObservations: 3
action 2, numVisits=24494, meanQ=8.296359, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2859659 episodes
GETTING ACTION FROM:
action 1, numVisits=2058086, meanQ=6.000968, numObservations: 3
action 2, numVisits=1139570, meanQ=5.999181, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.626483 0.821121 0.690002 0.820375 0.987081 0.175514 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 191
Initial state: 0 0.333838 0.625427 0.555805 0.827551 0.597465 0.837529 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1554483 episodes
GETTING ACTION FROM:
action -1, numVisits=1554447, meanQ=2.870305, numObservations: 1
action 2, numVisits=30, meanQ=1.253340, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.333838 0.625427 0.555805 0.827551 0.597465 0.837529 w: 1
Observation: 0 0.391526 0 0.571894 0 0.580017 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1549455, meanQ=4.922682, numObservations: 4
action 3, numVisits=4761, meanQ=4.799485, numObservations: 4
action 0, numVisits=152, meanQ=4.309095, numObservations: 1
action 2, numVisits=46, meanQ=3.633915, numObservations: 5
action -1, numVisits=32, meanQ=3.526008, numObservations: 1
Sampled 2446870 episodes
GETTING ACTION FROM:
action 1, numVisits=3996325, meanQ=5.064205, numObservations: 4
action 3, numVisits=4761, meanQ=4.799485, numObservations: 4
action 0, numVisits=152, meanQ=4.309095, numObservations: 1
action 2, numVisits=46, meanQ=3.633915, numObservations: 5
action -1, numVisits=32, meanQ=3.526008, numObservations: 1
action: 1
Next state: 0 0.333838 0.625427 0.555805 0.827551 0.597465 0.837529 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=629927, meanQ=8.301881, numObservations: 3
action 2, numVisits=7, meanQ=5.284300, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2858542 episodes
GETTING ACTION FROM:
action 3, numVisits=3488457, meanQ=5.867142, numObservations: 3
action 2, numVisits=16, meanQ=3.624381, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.333838 0.625427 0.555805 0.827551 0.597465 0.837529 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 192
Initial state: 0 0.989981 0.734502 0.69268 0.889171 0.683364 0.880354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2241966 episodes
GETTING ACTION FROM:
action 3, numVisits=220337, meanQ=5.014791, numObservations: 4
action 1, numVisits=2018222, meanQ=4.983752, numObservations: 5
action 2, numVisits=3377, meanQ=4.857791, numObservations: 4
action 0, numVisits=28, meanQ=3.500249, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.989981 0.734502 0.69268 0.889171 0.683364 0.880354 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 193
Initial state: 0 0.580781 0.879101 0.0547212 0.971222 0.579588 0.844862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2278002 episodes
GETTING ACTION FROM:
action 2, numVisits=2277956, meanQ=4.911987, numObservations: 3
action 0, numVisits=42, meanQ=3.665478, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.580781 0.879101 0.0547212 0.971222 0.579588 0.844862 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 194
Initial state: 0 0.177915 0.158958 0.692353 0.8647 0.593968 0.896032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258297 episodes
GETTING ACTION FROM:
action 1, numVisits=2258260, meanQ=4.997912, numObservations: 4
action 0, numVisits=33, meanQ=3.640208, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.177915 0.158958 0.692353 0.8647 0.593968 0.896032 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=343796, meanQ=8.311322, numObservations: 4
action 2, numVisits=9, meanQ=4.775567, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2813640 episodes
GETTING ACTION FROM:
action 3, numVisits=3157428, meanQ=6.147365, numObservations: 4
action 2, numVisits=15, meanQ=3.798673, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.177915 0.158958 0.692353 0.8647 0.593968 0.896032 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 195
Initial state: 0 0.792658 0.273977 0.660448 0.892669 0.608392 0.864546 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239192 episodes
GETTING ACTION FROM:
action 1, numVisits=2239164, meanQ=4.968830, numObservations: 5
action 2, numVisits=13, meanQ=2.231546, numObservations: 2
action 3, numVisits=11, meanQ=2.081827, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.792658 0.273977 0.660448 0.892669 0.608392 0.864546 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 196
Initial state: 0 0.588894 0.833733 0.448154 0.82156 0.575988 0.872283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264032 episodes
GETTING ACTION FROM:
action 1, numVisits=2250212, meanQ=4.994476, numObservations: 4
action -1, numVisits=13570, meanQ=3.112396, numObservations: 1
action 0, numVisits=234, meanQ=2.760840, numObservations: 1
action 2, numVisits=15, meanQ=1.260000, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.588894 0.833733 0.448154 0.82156 0.575988 0.872283 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 197
Initial state: 0 0.319215 0.20198 0.623981 0.894926 0.605993 0.883363 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2194289 episodes
GETTING ACTION FROM:
action 3, numVisits=2194240, meanQ=4.892611, numObservations: 5
action -1, numVisits=30, meanQ=3.488190, numObservations: 1
action 1, numVisits=13, meanQ=2.536923, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.319215 0.20198 0.623981 0.894926 0.605993 0.883363 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 198
Initial state: 0 0.585375 0.89128 0.70291 0.65656 0.599883 0.80062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1612981 episodes
GETTING ACTION FROM:
action 0, numVisits=1612967, meanQ=5.450643, numObservations: 2
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 1, numVisits=5, meanQ=0.196000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.585375 0.89128 0.70291 0.65656 0.599883 0.80062 w: 1
Observation: 0 0 0.920411 0 0.592327 0 0.885362 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1247613, meanQ=7.282727, numObservations: 3
action 2, numVisits=22, meanQ=3.429095, numObservations: 2
action 3, numVisits=6, meanQ=1.331683, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2498749 episodes
GETTING ACTION FROM:
action 1, numVisits=3746347, meanQ=5.740994, numObservations: 3
action 0, numVisits=15, meanQ=3.676972, numObservations: 1
action 2, numVisits=22, meanQ=3.429095, numObservations: 2
action 3, numVisits=6, meanQ=1.331683, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.585375 0.89128 0.70291 0.65656 0.599883 0.80062 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 199
Initial state: 0 0.359804 0.669862 0.643272 0.840941 0.642194 0.809927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246241 episodes
GETTING ACTION FROM:
action 2, numVisits=2246201, meanQ=4.971058, numObservations: 5
action -1, numVisits=32, meanQ=3.599190, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.359804 0.669862 0.643272 0.840941 0.642194 0.809927 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 200
Initial state: 0 0.033544 0.144218 0.508103 0.852116 0.514111 0.802419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259656 episodes
GETTING ACTION FROM:
action 1, numVisits=2259649, meanQ=5.004353, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.033544 0.144218 0.508103 0.852116 0.514111 0.802419 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=220752, meanQ=8.542338, numObservations: 3
action 2, numVisits=9, meanQ=5.011111, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2859896 episodes
GETTING ACTION FROM:
action 3, numVisits=3080548, meanQ=6.007133, numObservations: 3
action 2, numVisits=107, meanQ=5.130936, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.033544 0.144218 0.508103 0.852116 0.514111 0.802419 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 201
Initial state: 0 0.677357 0.865543 0.53893 0.883996 0.334597 0.636954 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2232320 episodes
GETTING ACTION FROM:
action 2, numVisits=2232272, meanQ=4.859748, numObservations: 4
action 1, numVisits=42, meanQ=3.368098, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.677357 0.865543 0.53893 0.883996 0.334597 0.636954 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 202
Initial state: 0 0.664149 0.833333 0.575952 0.870777 0.380028 0.226118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1556534 episodes
GETTING ACTION FROM:
action -1, numVisits=1555316, meanQ=2.918319, numObservations: 1
action 0, numVisits=1209, meanQ=2.582851, numObservations: 1
action 1, numVisits=5, meanQ=-0.582000, numObservations: 3
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.664149 0.833333 0.575952 0.870777 0.380028 0.226118 w: 1
Observation: 0 0.712213 0 0.49687 0 0.443102 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1555247, meanQ=4.971797, numObservations: 4
action 0, numVisits=44, meanQ=3.823368, numObservations: 1
action 2, numVisits=20, meanQ=2.000005, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 2450510 episodes
GETTING ACTION FROM:
action 3, numVisits=4005755, meanQ=4.969463, numObservations: 4
action 0, numVisits=46, meanQ=3.820310, numObservations: 1
action 2, numVisits=20, meanQ=2.000005, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.664149 0.833333 0.575952 0.870777 0.380028 0.226118 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=589030, meanQ=8.306884, numObservations: 5
action 1, numVisits=23585, meanQ=8.267189, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2804423 episodes
GETTING ACTION FROM:
action 2, numVisits=3160559, meanQ=6.292784, numObservations: 5
action 1, numVisits=256477, meanQ=6.282566, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.664149 0.833333 0.575952 0.870777 0.380028 0.226118 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 203
Initial state: 0 0.544767 0.841923 0.567805 0.81221 0.521092 0.383104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2260999 episodes
GETTING ACTION FROM:
action 2, numVisits=2260849, meanQ=4.961359, numObservations: 4
action -1, numVisits=82, meanQ=4.115005, numObservations: 1
action 1, numVisits=65, meanQ=3.941702, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.544767 0.841923 0.567805 0.81221 0.521092 0.383104 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 204
Initial state: 0 0.880456 0.779576 0.657389 0.852259 0.626355 0.870281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1564526 episodes
GETTING ACTION FROM:
action -1, numVisits=1551027, meanQ=2.930366, numObservations: 1
action 0, numVisits=13480, meanQ=2.871369, numObservations: 1
action 1, numVisits=15, meanQ=0.735347, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.880456 0.779576 0.657389 0.852259 0.626355 0.870281 w: 1
Observation: 0 0.854105 0 0.734216 0 0.664407 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1550912, meanQ=4.973115, numObservations: 4
action -1, numVisits=65, meanQ=4.032700, numObservations: 1
action 1, numVisits=26, meanQ=3.226931, numObservations: 4
action 2, numVisits=21, meanQ=3.194767, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
Sampled 2470083 episodes
GETTING ACTION FROM:
action 3, numVisits=4020995, meanQ=5.137943, numObservations: 4
action -1, numVisits=65, meanQ=4.032700, numObservations: 1
action 1, numVisits=26, meanQ=3.226931, numObservations: 4
action 2, numVisits=21, meanQ=3.194767, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action: 3
Next state: 1 0.880456 0.779576 0.657389 0.852259 0.626355 0.870281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 205
Initial state: 0 0.678236 0.864136 0.553539 0.800141 0.522122 0.556406 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2234863 episodes
GETTING ACTION FROM:
action 2, numVisits=2234791, meanQ=4.973573, numObservations: 5
action 3, numVisits=43, meanQ=3.784191, numObservations: 4
action 0, numVisits=26, meanQ=3.343940, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.678236 0.864136 0.553539 0.800141 0.522122 0.556406 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 206
Initial state: 0 0.93927 0.908577 0.547013 0.883054 0.519072 0.882274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2249424 episodes
GETTING ACTION FROM:
action 2, numVisits=2249397, meanQ=4.993943, numObservations: 5
action -1, numVisits=23, meanQ=3.381798, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.93927 0.908577 0.547013 0.883054 0.519072 0.882274 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 207
Initial state: 0 0.516845 0.802743 0.157953 0.18073 0.536692 0.893096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1557244 episodes
GETTING ACTION FROM:
action -1, numVisits=1557236, meanQ=2.856257, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.516845 0.802743 0.157953 0.18073 0.536692 0.893096 w: 1
Observation: 0 0.592569 0 0.127695 0 0.5598 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1557226, meanQ=4.912677, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2456483 episodes
GETTING ACTION FROM:
action 1, numVisits=4013709, meanQ=4.999090, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.516845 0.802743 0.157953 0.18073 0.536692 0.893096 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 208
Initial state: 0 0.524593 0.814349 0.183709 0.888105 0.588529 0.882555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2243717 episodes
GETTING ACTION FROM:
action 3, numVisits=2243630, meanQ=4.983636, numObservations: 5
action 0, numVisits=56, meanQ=3.937356, numObservations: 1
action 2, numVisits=21, meanQ=3.276667, numObservations: 4
action 1, numVisits=8, meanQ=1.747513, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.524593 0.814349 0.183709 0.888105 0.588529 0.882555 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 209
Initial state: 0 0.657118 0.819801 0.916799 0.744687 0.694778 0.860683 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2274394 episodes
GETTING ACTION FROM:
action 2, numVisits=2266368, meanQ=4.981386, numObservations: 4
action 3, numVisits=8021, meanQ=4.876675, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.657118 0.819801 0.916799 0.744687 0.694778 0.860683 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 210
Initial state: 0 0.680339 0.863753 0.732483 0.111342 0.665183 0.840446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2178149 episodes
GETTING ACTION FROM:
action 2, numVisits=2178080, meanQ=4.836712, numObservations: 5
action -1, numVisits=58, meanQ=3.826092, numObservations: 1
action 1, numVisits=8, meanQ=0.997500, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.680339 0.863753 0.732483 0.111342 0.665183 0.840446 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 211
Initial state: 0 0.659713 0.846724 0.537745 0.824103 0.667522 0.130897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2126585 episodes
GETTING ACTION FROM:
action 1, numVisits=2126182, meanQ=4.707162, numObservations: 5
action 0, numVisits=326, meanQ=4.254651, numObservations: 1
action -1, numVisits=71, meanQ=3.792797, numObservations: 1
action 3, numVisits=5, meanQ=-1.402000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.659713 0.846724 0.537745 0.824103 0.667522 0.130897 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 212
Initial state: 0 0.60428 0.850743 0.682762 0.891508 0.647955 0.956868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1555117 episodes
GETTING ACTION FROM:
action -1, numVisits=1555105, meanQ=2.877101, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=7, meanQ=-3.002857, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.60428 0.850743 0.682762 0.891508 0.647955 0.956868 w: 1
Observation: 0 0.584514 0 0.723611 0 0.687229 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1555092, meanQ=4.922040, numObservations: 4
action 3, numVisits=7, meanQ=1.014286, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2448845 episodes
GETTING ACTION FROM:
action 1, numVisits=4003937, meanQ=4.951951, numObservations: 4
action 3, numVisits=7, meanQ=1.014286, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.60428 0.850743 0.682762 0.891508 0.647955 0.956868 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 213
Initial state: 0 0.560625 0.868961 0.6977 0.895763 0.579045 0.146176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2270593 episodes
GETTING ACTION FROM:
action 1, numVisits=2270541, meanQ=4.979169, numObservations: 4
action 0, numVisits=33, meanQ=3.652093, numObservations: 1
action 2, numVisits=16, meanQ=2.873756, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.560625 0.868961 0.6977 0.895763 0.579045 0.146176 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 214
Initial state: 0 0.68941 0.820869 0.582352 0.892442 0.656582 0.898013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246929 episodes
GETTING ACTION FROM:
action 1, numVisits=2246884, meanQ=4.979017, numObservations: 5
action 0, numVisits=32, meanQ=3.595367, numObservations: 1
action -1, numVisits=10, meanQ=2.488000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.68941 0.820869 0.582352 0.892442 0.656582 0.898013 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 215
Initial state: 0 0.512314 0.890188 0.555174 0.850768 0.82012 0.172124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2255239 episodes
GETTING ACTION FROM:
action 3, numVisits=2255225, meanQ=4.911578, numObservations: 4
action 2, numVisits=9, meanQ=1.886667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.512314 0.890188 0.555174 0.850768 0.82012 0.172124 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 216
Initial state: 0 0.67537 0.822483 0.609054 0.804946 0.706576 0.874948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2248576 episodes
GETTING ACTION FROM:
action 3, numVisits=2248515, meanQ=4.982704, numObservations: 5
action -1, numVisits=49, meanQ=3.873416, numObservations: 1
action 1, numVisits=6, meanQ=1.663333, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.67537 0.822483 0.609054 0.804946 0.706576 0.874948 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 217
Initial state: 0 0.6916 0.821807 0.54249 0.851602 0.0419096 0.0265412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259764 episodes
GETTING ACTION FROM:
action 3, numVisits=2250690, meanQ=4.987891, numObservations: 4
action 0, numVisits=9057, meanQ=2.963763, numObservations: 1
action 1, numVisits=12, meanQ=0.490842, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 3
Next state: 0 0.6916 0.821807 0.54249 0.851602 0.0419096 0.0265412 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=344094, meanQ=8.325793, numObservations: 4
action 1, numVisits=11, meanQ=5.724545, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2810295 episodes
GETTING ACTION FROM:
action 2, numVisits=3154097, meanQ=6.213966, numObservations: 4
action 1, numVisits=300, meanQ=5.738434, numObservations: 5
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.6916 0.821807 0.54249 0.851602 0.0419096 0.0265412 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 218
Initial state: 0 0.609547 0.830584 0.532832 0.858355 0.433867 0.429556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2229209 episodes
GETTING ACTION FROM:
action 2, numVisits=2229088, meanQ=4.900560, numObservations: 5
action -1, numVisits=57, meanQ=3.889602, numObservations: 1
action 1, numVisits=61, meanQ=3.740331, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.609547 0.830584 0.532832 0.858355 0.433867 0.429556 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 219
Initial state: 0 0.512291 0.0951063 0.627835 0.870098 0.504716 0.807812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258655 episodes
GETTING ACTION FROM:
action 3, numVisits=2258644, meanQ=4.899602, numObservations: 4
action 1, numVisits=6, meanQ=-0.669983, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.512291 0.0951063 0.627835 0.870098 0.504716 0.807812 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 220
Initial state: 0 0.540632 0.855463 0.390295 0.994214 0.585075 0.823273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2279228 episodes
GETTING ACTION FROM:
action 2, numVisits=2279152, meanQ=4.983536, numObservations: 4
action 3, numVisits=50, meanQ=3.792400, numObservations: 4
action -1, numVisits=23, meanQ=3.350218, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.540632 0.855463 0.390295 0.994214 0.585075 0.823273 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=166602, meanQ=5.594949, numObservations: 3
action -1, numVisits=68, meanQ=4.759830, numObservations: 1
action 1, numVisits=20, meanQ=3.881505, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2862630 episodes
GETTING ACTION FROM:
action 1, numVisits=2546438, meanQ=5.868935, numObservations: 3
action 2, numVisits=482809, meanQ=5.333076, numObservations: 4
action -1, numVisits=73, meanQ=4.435685, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.540632 0.855463 0.390295 0.994214 0.585075 0.823273 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 221
Initial state: 0 0.601826 0.142134 0.628745 0.883727 0.605114 0.88041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2232975 episodes
GETTING ACTION FROM:
action 2, numVisits=2232969, meanQ=4.892064, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.601826 0.142134 0.628745 0.883727 0.605114 0.88041 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 222
Initial state: 0 0.589762 0.823647 0.525363 0.833224 0.692724 0.419807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247700 episodes
GETTING ACTION FROM:
action 1, numVisits=2245438, meanQ=4.985474, numObservations: 5
action 3, numVisits=2254, meanQ=4.657471, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.589762 0.823647 0.525363 0.833224 0.692724 0.419807 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 223
Initial state: 0 0.517314 0.893009 0.652399 0.870253 0.877697 0.0638822 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2145065 episodes
GETTING ACTION FROM:
action 3, numVisits=2144464, meanQ=4.745204, numObservations: 5
action 1, numVisits=542, meanQ=4.406865, numObservations: 4
action -1, numVisits=56, meanQ=3.714560, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.517314 0.893009 0.652399 0.870253 0.877697 0.0638822 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 224
Initial state: 0 0.808028 0.0327974 0.676751 0.858753 0.648003 0.845296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237280 episodes
GETTING ACTION FROM:
action 3, numVisits=2237059, meanQ=4.936496, numObservations: 4
action 0, numVisits=157, meanQ=4.259320, numObservations: 2
action -1, numVisits=58, meanQ=3.879439, numObservations: 1
action 1, numVisits=5, meanQ=0.196000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.808028 0.0327974 0.676751 0.858753 0.648003 0.845296 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 225
Initial state: 0 0.693375 0.898188 0.851298 0.57048 0.569826 0.882613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2295786 episodes
GETTING ACTION FROM:
action 3, numVisits=2295679, meanQ=4.992612, numObservations: 3
action -1, numVisits=90, meanQ=4.186284, numObservations: 1
action 2, numVisits=14, meanQ=2.122143, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.693375 0.898188 0.851298 0.57048 0.569826 0.882613 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 226
Initial state: 0 0.635738 0.832983 0.575882 0.842941 0.71935 0.205267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2273827 episodes
GETTING ACTION FROM:
action 2, numVisits=2273753, meanQ=5.012421, numObservations: 4
action 0, numVisits=70, meanQ=4.095784, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.635738 0.832983 0.575882 0.842941 0.71935 0.205267 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 227
Initial state: 0 0.622631 0.845799 0.282201 0.153305 0.545714 0.816274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239437 episodes
GETTING ACTION FROM:
action 2, numVisits=2237664, meanQ=5.099899, numObservations: 5
action 0, numVisits=1756, meanQ=2.737578, numObservations: 1
action 1, numVisits=10, meanQ=0.209000, numObservations: 3
action 3, numVisits=5, meanQ=0.196000, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.622631 0.845799 0.282201 0.153305 0.545714 0.816274 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=125200, meanQ=8.541025, numObservations: 3
action 1, numVisits=94472, meanQ=8.537095, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2830263 episodes
GETTING ACTION FROM:
action 1, numVisits=1993964, meanQ=6.007999, numObservations: 4
action 3, numVisits=1055968, meanQ=6.005811, numObservations: 3
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.622631 0.845799 0.282201 0.153305 0.545714 0.816274 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 228
Initial state: 0 0.646428 0.184306 0.653178 0.8896 0.536923 0.800316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2238854 episodes
GETTING ACTION FROM:
action 1, numVisits=2238772, meanQ=4.975672, numObservations: 5
action 3, numVisits=43, meanQ=3.640002, numObservations: 3
action 2, numVisits=21, meanQ=3.081910, numObservations: 4
action 0, numVisits=16, meanQ=2.822831, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.646428 0.184306 0.653178 0.8896 0.536923 0.800316 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 229
Initial state: 0 0.581205 0.343458 0.528024 0.867657 0.554087 0.888863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2232631 episodes
GETTING ACTION FROM:
action 3, numVisits=2230632, meanQ=4.992552, numObservations: 5
action 2, numVisits=1994, meanQ=4.821359, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.581205 0.343458 0.528024 0.867657 0.554087 0.888863 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 230
Initial state: 0 0.463373 0.554052 0.611671 0.888989 0.61073 0.817197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246557 episodes
GETTING ACTION FROM:
action 2, numVisits=2246528, meanQ=4.993658, numObservations: 5
action 1, numVisits=24, meanQ=3.413762, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.463373 0.554052 0.611671 0.888989 0.61073 0.817197 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 231
Initial state: 0 0.319105 0.840191 0.540085 0.839195 0.533374 0.89234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2252459 episodes
GETTING ACTION FROM:
action 1, numVisits=2252421, meanQ=5.123553, numObservations: 5
action -1, numVisits=34, meanQ=3.805003, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.319105 0.840191 0.540085 0.839195 0.533374 0.89234 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=147619, meanQ=7.329361, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2625973 episodes
GETTING ACTION FROM:
action 1, numVisits=2773590, meanQ=5.108970, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.319105 0.840191 0.540085 0.839195 0.533374 0.89234 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 232
Initial state: 0 0.597798 0.842248 0.686482 0.803625 0.135516 0.917079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2249872 episodes
GETTING ACTION FROM:
action 2, numVisits=2240770, meanQ=4.972160, numObservations: 4
action 0, numVisits=9096, meanQ=2.965313, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.597798 0.842248 0.686482 0.803625 0.135516 0.917079 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 233
Initial state: 0 0.628009 0.879884 0.0116646 0.689426 0.573669 0.867557 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247214 episodes
GETTING ACTION FROM:
action 3, numVisits=2247186, meanQ=5.004022, numObservations: 5
action 0, numVisits=20, meanQ=3.261697, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.628009 0.879884 0.0116646 0.689426 0.573669 0.867557 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 234
Initial state: 0 0.622268 0.817755 0.573221 0.850331 0.225054 0.0612059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2251549 episodes
GETTING ACTION FROM:
action 2, numVisits=2251535, meanQ=4.979201, numObservations: 5
action 3, numVisits=9, meanQ=1.445567, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.622268 0.817755 0.573221 0.850331 0.225054 0.0612059 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 235
Initial state: 0 0.536678 0.819792 0.961566 0.860996 0.564976 0.89614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2290753 episodes
GETTING ACTION FROM:
action 1, numVisits=2290618, meanQ=4.913408, numObservations: 3
action 2, numVisits=67, meanQ=3.941494, numObservations: 3
action 3, numVisits=29, meanQ=3.334834, numObservations: 3
action 0, numVisits=20, meanQ=3.118093, numObservations: 1
action -1, numVisits=19, meanQ=3.001411, numObservations: 1
action: 1
Next state: 1 0.536678 0.819792 0.961566 0.860996 0.564976 0.89614 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 236
Initial state: 0 0.302154 0.196623 0.545943 0.821382 0.555007 0.838298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2256968 episodes
GETTING ACTION FROM:
action 3, numVisits=2256507, meanQ=5.155347, numObservations: 5
action -1, numVisits=457, meanQ=2.271072, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.302154 0.196623 0.545943 0.821382 0.555007 0.838298 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 237
Initial state: 0 0.408745 0.176775 0.6952 0.858554 0.542389 0.874443 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2244681 episodes
GETTING ACTION FROM:
action 2, numVisits=2243317, meanQ=5.004564, numObservations: 5
action 1, numVisits=1359, meanQ=4.793085, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.408745 0.176775 0.6952 0.858554 0.542389 0.874443 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 238
Initial state: 0 0.522041 0.805695 0.648677 0.821692 0.103365 0.586674 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2224576 episodes
GETTING ACTION FROM:
action 3, numVisits=2224521, meanQ=4.901576, numObservations: 5
action -1, numVisits=49, meanQ=3.799475, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.522041 0.805695 0.648677 0.821692 0.103365 0.586674 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=282120, meanQ=8.390382, numObservations: 4
action 1, numVisits=25, meanQ=6.359212, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2819248 episodes
GETTING ACTION FROM:
action 2, numVisits=3100909, meanQ=5.937852, numObservations: 4
action 1, numVisits=482, meanQ=5.587357, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.522041 0.805695 0.648677 0.821692 0.103365 0.586674 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=70342, meanQ=7.308660, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2919146 episodes
GETTING ACTION FROM:
action 1, numVisits=2989486, meanQ=5.807343, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.522041 0.805695 0.648677 0.821692 0.103365 0.586674 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 239
Initial state: 0 0.582727 0.820128 0.195023 0.455548 0.619957 0.886064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258954 episodes
GETTING ACTION FROM:
action 1, numVisits=2258627, meanQ=4.921149, numObservations: 4
action -1, numVisits=319, meanQ=1.112936, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 1
Next state: 1 0.582727 0.820128 0.195023 0.455548 0.619957 0.886064 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 240
Initial state: 0 0.140626 0.372712 0.623344 0.847401 0.564392 0.812374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2250641 episodes
GETTING ACTION FROM:
action 1, numVisits=2250593, meanQ=5.003964, numObservations: 5
action -1, numVisits=36, meanQ=3.719905, numObservations: 1
action 2, numVisits=9, meanQ=2.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.140626 0.372712 0.623344 0.847401 0.564392 0.812374 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 241
Initial state: 0 0.0152149 0.940009 0.692894 0.803435 0.646125 0.890344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2257950 episodes
GETTING ACTION FROM:
action 3, numVisits=2257912, meanQ=4.996201, numObservations: 4
action -1, numVisits=34, meanQ=3.683853, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0152149 0.940009 0.692894 0.803435 0.646125 0.890344 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 242
Initial state: 0 0.589709 0.898721 0.9799 0.993044 0.618118 0.805045 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259179 episodes
GETTING ACTION FROM:
action 3, numVisits=2259071, meanQ=4.904343, numObservations: 4
action 0, numVisits=98, meanQ=4.132658, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.589709 0.898721 0.9799 0.993044 0.618118 0.805045 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 243
Initial state: 0 0.518809 0.854659 0.525694 0.84504 0.798818 0.49383 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1541665 episodes
GETTING ACTION FROM:
action -1, numVisits=1541660, meanQ=2.807753, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.518809 0.854659 0.525694 0.84504 0.798818 0.49383 w: 1
Observation: 0 0.617414 0 0.605498 0 0.802205 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1541652, meanQ=4.908247, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2474505 episodes
GETTING ACTION FROM:
action 3, numVisits=4016157, meanQ=5.167291, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.518809 0.854659 0.525694 0.84504 0.798818 0.49383 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 244
Initial state: 0 0.584257 0.861546 0.216427 0.300587 0.681678 0.87855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2236434 episodes
GETTING ACTION FROM:
action 1, numVisits=2236428, meanQ=4.923242, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.584257 0.861546 0.216427 0.300587 0.681678 0.87855 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 245
Initial state: 0 0.54737 0.887361 0.585887 0.47275 0.690461 0.828086 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263004 episodes
GETTING ACTION FROM:
action 3, numVisits=2262998, meanQ=4.918461, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.54737 0.887361 0.585887 0.47275 0.690461 0.828086 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 246
Initial state: 0 0.633787 0.891861 0.261106 0.15147 0.605095 0.88557 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259485 episodes
GETTING ACTION FROM:
action 3, numVisits=2259260, meanQ=4.984862, numObservations: 4
action -1, numVisits=148, meanQ=4.357373, numObservations: 1
action 0, numVisits=59, meanQ=3.975159, numObservations: 1
action 2, numVisits=16, meanQ=2.873756, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 1 0.633787 0.891861 0.261106 0.15147 0.605095 0.88557 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 247
Initial state: 0 0.522441 0.88956 0.699155 0.872116 0.279667 0.754193 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2234584 episodes
GETTING ACTION FROM:
action 3, numVisits=2234494, meanQ=4.929421, numObservations: 5
action -1, numVisits=36, meanQ=3.628744, numObservations: 1
action 2, numVisits=51, meanQ=3.512578, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.522441 0.88956 0.699155 0.872116 0.279667 0.754193 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=277146, meanQ=8.399742, numObservations: 5
action 1, numVisits=4823, meanQ=8.300775, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2811645 episodes
GETTING ACTION FROM:
action 2, numVisits=2327010, meanQ=5.976744, numObservations: 5
action 1, numVisits=766600, meanQ=5.972917, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.522441 0.88956 0.699155 0.872116 0.279667 0.754193 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 248
Initial state: 0 0.515189 0.88841 0.800248 0.95069 0.621195 0.880997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261679 episodes
GETTING ACTION FROM:
action 1, numVisits=2261663, meanQ=4.976243, numObservations: 4
action 2, numVisits=11, meanQ=1.361818, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.515189 0.88841 0.800248 0.95069 0.621195 0.880997 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 249
Initial state: 0 0.636499 0.888 0.0210712 0.330333 0.663309 0.852772 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2277384 episodes
GETTING ACTION FROM:
action 3, numVisits=2270702, meanQ=4.996146, numObservations: 3
action -1, numVisits=6678, meanQ=2.777852, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.636499 0.888 0.0210712 0.330333 0.663309 0.852772 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 250
Initial state: 0 0.689421 0.835428 0.526134 0.868165 0.712461 0.827606 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247586 episodes
GETTING ACTION FROM:
action 1, numVisits=2247533, meanQ=5.119614, numObservations: 5
action -1, numVisits=41, meanQ=3.918503, numObservations: 1
action 3, numVisits=9, meanQ=1.886667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.689421 0.835428 0.526134 0.868165 0.712461 0.827606 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 251
Initial state: 0 0.558147 0.838933 0.680684 0.800497 0.697464 0.535786 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262792 episodes
GETTING ACTION FROM:
action 3, numVisits=2262786, meanQ=4.917094, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.558147 0.838933 0.680684 0.800497 0.697464 0.535786 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 252
Initial state: 0 0.651495 0.821713 0.68849 0.815919 0.494518 0.180392 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2243450 episodes
GETTING ACTION FROM:
action 1, numVisits=2243427, meanQ=4.922168, numObservations: 5
action -1, numVisits=17, meanQ=2.953482, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.651495 0.821713 0.68849 0.815919 0.494518 0.180392 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 253
Initial state: 0 0.585464 0.873002 0.270355 0.894703 0.682534 0.810787 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2281337 episodes
GETTING ACTION FROM:
action 1, numVisits=2281057, meanQ=4.928835, numObservations: 3
action 0, numVisits=270, meanQ=4.343933, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.585464 0.873002 0.270355 0.894703 0.682534 0.810787 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 254
Initial state: 0 0.570395 0.616739 0.551482 0.811083 0.544888 0.881524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1548593 episodes
GETTING ACTION FROM:
action -1, numVisits=1548586, meanQ=2.872064, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.570395 0.616739 0.551482 0.811083 0.544888 0.881524 w: 1
Observation: 0 0.473717 0 0.52318 0 0.629649 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1548524, meanQ=4.921677, numObservations: 5
action 0, numVisits=50, meanQ=3.857916, numObservations: 1
action 1, numVisits=8, meanQ=0.511250, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2388693 episodes
GETTING ACTION FROM:
action 2, numVisits=3937215, meanQ=4.890730, numObservations: 5
action 0, numVisits=52, meanQ=3.793192, numObservations: 1
action 1, numVisits=8, meanQ=0.511250, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.570395 0.616739 0.551482 0.811083 0.544888 0.881524 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 255
Initial state: 0 0.54132 0.639407 0.593838 0.880771 0.656379 0.815437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2281431 episodes
GETTING ACTION FROM:
action 3, numVisits=2281422, meanQ=4.965871, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.54132 0.639407 0.593838 0.880771 0.656379 0.815437 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 256
Initial state: 0 0.942505 0.171806 0.56227 0.816739 0.639006 0.877833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237823 episodes
GETTING ACTION FROM:
action 3, numVisits=2237817, meanQ=4.921568, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.942505 0.171806 0.56227 0.816739 0.639006 0.877833 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=164057, meanQ=4.645002, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2764398 episodes
GETTING ACTION FROM:
action 2, numVisits=2928455, meanQ=5.754811, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.942505 0.171806 0.56227 0.816739 0.639006 0.877833 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 257
Initial state: 0 0.844041 0.541043 0.609233 0.856725 0.529199 0.856055 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2269312 episodes
GETTING ACTION FROM:
action 3, numVisits=2269305, meanQ=4.918670, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.844041 0.541043 0.609233 0.856725 0.529199 0.856055 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 258
Initial state: 0 0.506281 0.814966 0.58164 0.734368 0.64165 0.857208 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261431 episodes
GETTING ACTION FROM:
action 1, numVisits=2261371, meanQ=5.105755, numObservations: 4
action 0, numVisits=41, meanQ=3.896133, numObservations: 1
action 3, numVisits=16, meanQ=3.101256, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.506281 0.814966 0.58164 0.734368 0.64165 0.857208 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 259
Initial state: 0 0.544333 0.810754 0.542291 0.806656 0.891195 0.602993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239016 episodes
GETTING ACTION FROM:
action 2, numVisits=1472343, meanQ=4.992934, numObservations: 5
action 3, numVisits=766407, meanQ=4.925068, numObservations: 4
action 1, numVisits=262, meanQ=4.464868, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.544333 0.810754 0.542291 0.806656 0.891195 0.602993 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 260
Initial state: 0 0.741284 0.705334 0.589803 0.864585 0.518467 0.858467 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2240952 episodes
GETTING ACTION FROM:
action 3, numVisits=2240946, meanQ=4.965370, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.741284 0.705334 0.589803 0.864585 0.518467 0.858467 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 261
Initial state: 0 0.104684 0.190189 0.557041 0.849863 0.530424 0.806417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2269214 episodes
GETTING ACTION FROM:
action 1, numVisits=2269102, meanQ=4.905096, numObservations: 4
action -1, numVisits=95, meanQ=4.120439, numObservations: 1
action 2, numVisits=14, meanQ=2.856443, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.104684 0.190189 0.557041 0.849863 0.530424 0.806417 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=288937, meanQ=8.394157, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2872063 episodes
GETTING ACTION FROM:
action 2, numVisits=3160946, meanQ=6.248142, numObservations: 3
action 3, numVisits=54, meanQ=5.185002, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.104684 0.190189 0.557041 0.849863 0.530424 0.806417 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 262
Initial state: 0 0.671761 0.81419 0.225666 0.582757 0.662594 0.892587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2169366 episodes
GETTING ACTION FROM:
action 1, numVisits=2169295, meanQ=4.842991, numObservations: 5
action 0, numVisits=44, meanQ=3.666737, numObservations: 1
action -1, numVisits=24, meanQ=3.260123, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.671761 0.81419 0.225666 0.582757 0.662594 0.892587 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 263
Initial state: 0 0.631752 0.887896 0.699237 0.824994 0.865805 0.172079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2297349 episodes
GETTING ACTION FROM:
action 2, numVisits=2296869, meanQ=4.992532, numObservations: 3
action 0, numVisits=476, meanQ=1.731081, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.631752 0.887896 0.699237 0.824994 0.865805 0.172079 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.616957 0.827815 0.721026 0.736764 0.696885 0.826183 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2245697 episodes
GETTING ACTION FROM:
action 1, numVisits=2245648, meanQ=4.984229, numObservations: 5
action -1, numVisits=33, meanQ=3.596402, numObservations: 1
action 0, numVisits=10, meanQ=2.488000, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.616957 0.827815 0.721026 0.736764 0.696885 0.826183 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 265
Initial state: 0 0.521099 0.831324 0.534103 0.848192 0.0853453 0.909415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2302455 episodes
GETTING ACTION FROM:
action 2, numVisits=2292265, meanQ=4.990386, numObservations: 3
action 3, numVisits=9894, meanQ=4.910494, numObservations: 4
action 1, numVisits=292, meanQ=4.532852, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.521099 0.831324 0.534103 0.848192 0.0853453 0.909415 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 266
Initial state: 0 0.606846 0.856055 0.500839 0.88604 0.476212 0.549867 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2265375 episodes
GETTING ACTION FROM:
action 3, numVisits=2265320, meanQ=4.919895, numObservations: 4
action 0, numVisits=27, meanQ=3.430773, numObservations: 1
action -1, numVisits=26, meanQ=3.391543, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.606846 0.856055 0.500839 0.88604 0.476212 0.549867 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=142792, meanQ=8.541418, numObservations: 3
action 2, numVisits=80132, meanQ=8.534897, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2841411 episodes
GETTING ACTION FROM:
action 1, numVisits=2509607, meanQ=6.153557, numObservations: 4
action 2, numVisits=554726, meanQ=6.148038, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.606846 0.856055 0.500839 0.88604 0.476212 0.549867 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 267
Initial state: 0 0.0765498 0.276263 0.533974 0.804374 0.670279 0.824013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2209781 episodes
GETTING ACTION FROM:
action 2, numVisits=2209773, meanQ=4.907099, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.0765498 0.276263 0.533974 0.804374 0.670279 0.824013 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 268
Initial state: 0 0.373478 0.162217 0.5791 0.813345 0.674066 0.814879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261435 episodes
GETTING ACTION FROM:
action 2, numVisits=2261425, meanQ=4.966656, numObservations: 4
action 3, numVisits=5, meanQ=-0.201980, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.373478 0.162217 0.5791 0.813345 0.674066 0.814879 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 269
Initial state: 0 0.538126 0.829426 0.647748 0.881006 0.482475 0.660002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2284725 episodes
GETTING ACTION FROM:
action 3, numVisits=2284631, meanQ=4.916379, numObservations: 3
action -1, numVisits=90, meanQ=4.100687, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.538126 0.829426 0.647748 0.881006 0.482475 0.660002 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=347467, meanQ=8.322721, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2842664 episodes
GETTING ACTION FROM:
action 2, numVisits=3190128, meanQ=6.335487, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.538126 0.829426 0.647748 0.881006 0.482475 0.660002 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 270
Initial state: 0 0.686518 0.845875 0.547249 0.885503 0.373896 0.279465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2228713 episodes
GETTING ACTION FROM:
action 3, numVisits=2044770, meanQ=4.921234, numObservations: 5
action 2, numVisits=183600, meanQ=4.882348, numObservations: 4
action 0, numVisits=320, meanQ=4.494470, numObservations: 2
action 1, numVisits=21, meanQ=2.804771, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.686518 0.845875 0.547249 0.885503 0.373896 0.279465 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=260184, meanQ=8.377058, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2816599 episodes
GETTING ACTION FROM:
action 2, numVisits=3076776, meanQ=5.996242, numObservations: 4
action 1, numVisits=7, meanQ=1.570000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.686518 0.845875 0.547249 0.885503 0.373896 0.279465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 271
Initial state: 0 0.593065 0.826588 0.706411 0.926092 0.668316 0.823586 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2188273 episodes
GETTING ACTION FROM:
action 3, numVisits=2188239, meanQ=5.007587, numObservations: 4
action 1, numVisits=19, meanQ=2.788426, numObservations: 4
action -1, numVisits=12, meanQ=2.729587, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.593065 0.826588 0.706411 0.926092 0.668316 0.823586 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 272
Initial state: 0 0.519021 0.847364 0.628676 0.85343 0.830176 0.415159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2240029 episodes
GETTING ACTION FROM:
action 2, numVisits=2239968, meanQ=4.983898, numObservations: 5
action 1, numVisits=56, meanQ=3.782864, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.519021 0.847364 0.628676 0.85343 0.830176 0.415159 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 273
Initial state: 0 0.558444 0.566578 0.65205 0.808627 0.651343 0.882841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1610305 episodes
GETTING ACTION FROM:
action 0, numVisits=1610300, meanQ=5.525755, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.558444 0.566578 0.65205 0.808627 0.651343 0.882841 w: 1
Observation: 0 0 0.653436 0 0.839689 0 0.84251 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1235645, meanQ=7.369925, numObservations: 4
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2484268 episodes
GETTING ACTION FROM:
action 2, numVisits=3719911, meanQ=5.735531, numObservations: 4
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.558444 0.566578 0.65205 0.808627 0.651343 0.882841 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 274
Initial state: 0 0.520914 0.828107 0.534923 0.152106 0.568167 0.822261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246915 episodes
GETTING ACTION FROM:
action 2, numVisits=2243161, meanQ=4.897773, numObservations: 4
action -1, numVisits=3746, meanQ=2.963532, numObservations: 1
action 1, numVisits=5, meanQ=0.196000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.520914 0.828107 0.534923 0.152106 0.568167 0.822261 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 275
Initial state: 0 0.60235 0.16978 0.563195 0.8229 0.563531 0.810604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2235070 episodes
GETTING ACTION FROM:
action 1, numVisits=2234938, meanQ=4.966503, numObservations: 5
action 3, numVisits=76, meanQ=4.075271, numObservations: 5
action 0, numVisits=27, meanQ=3.449082, numObservations: 1
action 2, numVisits=27, meanQ=3.282226, numObservations: 5
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.60235 0.16978 0.563195 0.8229 0.563531 0.810604 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 276
Initial state: 0 0.587688 0.867629 0.569266 0.809977 0.639044 0.967554 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2225639 episodes
GETTING ACTION FROM:
action 3, numVisits=2225558, meanQ=4.934643, numObservations: 5
action 0, numVisits=31, meanQ=3.557798, numObservations: 1
action -1, numVisits=32, meanQ=3.554627, numObservations: 1
action 1, numVisits=17, meanQ=2.881176, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.587688 0.867629 0.569266 0.809977 0.639044 0.967554 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 277
Initial state: 0 0.500684 0.848468 0.665746 0.883651 0.500581 0.600434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2265013 episodes
GETTING ACTION FROM:
action 1, numVisits=2264985, meanQ=4.997829, numObservations: 4
action 3, numVisits=23, meanQ=2.904357, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.500684 0.848468 0.665746 0.883651 0.500581 0.600434 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.611216 0.843546 0.634953 0.891983 0.500998 0.895798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2279932 episodes
GETTING ACTION FROM:
action 2, numVisits=2279860, meanQ=4.921920, numObservations: 4
action -1, numVisits=68, meanQ=3.992940, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.611216 0.843546 0.634953 0.891983 0.500998 0.895798 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 279
Initial state: 0 0.550962 0.821201 0.824842 0.189773 0.638979 0.861384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2260670 episodes
GETTING ACTION FROM:
action 3, numVisits=2260633, meanQ=4.970325, numObservations: 4
action 0, numVisits=33, meanQ=3.568841, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.550962 0.821201 0.824842 0.189773 0.638979 0.861384 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 280
Initial state: 0 0.529283 0.890294 0.216149 0.900663 0.689051 0.890964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2202440 episodes
GETTING ACTION FROM:
action 1, numVisits=2202391, meanQ=4.852283, numObservations: 4
action -1, numVisits=30, meanQ=3.418720, numObservations: 1
action 2, numVisits=10, meanQ=2.202010, numObservations: 4
action 3, numVisits=7, meanQ=1.842871, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.529283 0.890294 0.216149 0.900663 0.689051 0.890964 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 281
Initial state: 0 0.672032 0.887451 0.537215 0.864476 0.619026 0.565953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2296444 episodes
GETTING ACTION FROM:
action 2, numVisits=2296391, meanQ=4.985364, numObservations: 3
action -1, numVisits=40, meanQ=3.766948, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.672032 0.887451 0.537215 0.864476 0.619026 0.565953 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 282
Initial state: 0 0.530172 0.80044 0.0791195 0.563259 0.625002 0.88046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2293196 episodes
GETTING ACTION FROM:
action 2, numVisits=2293154, meanQ=4.999162, numObservations: 3
action 0, numVisits=38, meanQ=3.716347, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.530172 0.80044 0.0791195 0.563259 0.625002 0.88046 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=348101, meanQ=8.318599, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2882555 episodes
GETTING ACTION FROM:
action 1, numVisits=3230654, meanQ=6.139094, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.530172 0.80044 0.0791195 0.563259 0.625002 0.88046 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 283
Initial state: 0 0.52233 0.935883 0.69576 0.856559 0.623204 0.8066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264130 episodes
GETTING ACTION FROM:
action 3, numVisits=2264124, meanQ=4.907264, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.52233 0.935883 0.69576 0.856559 0.623204 0.8066 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 284
Initial state: 0 0.529267 0.828782 0.346629 0.880841 0.581385 0.897803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2240750 episodes
GETTING ACTION FROM:
action 1, numVisits=2240744, meanQ=4.920764, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.529267 0.828782 0.346629 0.880841 0.581385 0.897803 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 285
Initial state: 0 0.559322 0.872436 0.118533 0.530495 0.568314 0.846951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253865 episodes
GETTING ACTION FROM:
action 2, numVisits=2253821, meanQ=5.009481, numObservations: 5
action -1, numVisits=35, meanQ=3.665725, numObservations: 1
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.559322 0.872436 0.118533 0.530495 0.568314 0.846951 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 286
Initial state: 0 0.587877 0.854469 0.699311 0.85615 0.604989 0.819004 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1552149 episodes
GETTING ACTION FROM:
action 0, numVisits=1552130, meanQ=2.937691, numObservations: 1
action 1, numVisits=12, meanQ=-2.000833, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 0
Next state: 0 0.587877 0.854469 0.699311 0.85615 0.604989 0.819004 w: 1
Observation: 0 0 0.890172 0 0.890232 0 0.889462 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1552025, meanQ=4.984021, numObservations: 4
action -1, numVisits=99, meanQ=4.221084, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2483308 episodes
GETTING ACTION FROM:
action 2, numVisits=4035323, meanQ=4.883039, numObservations: 4
action -1, numVisits=109, meanQ=4.139193, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.587877 0.854469 0.699311 0.85615 0.604989 0.819004 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 287
Initial state: 0 0.50829 0.847342 0.549481 0.889261 0.278469 0.219745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2267616 episodes
GETTING ACTION FROM:
action 2, numVisits=2267575, meanQ=4.977379, numObservations: 4
action -1, numVisits=27, meanQ=3.475392, numObservations: 1
action 1, numVisits=11, meanQ=2.452745, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.50829 0.847342 0.549481 0.889261 0.278469 0.219745 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 288
Initial state: 0 0.592885 0.30448 0.512846 0.868381 0.568937 0.854496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1606829 episodes
GETTING ACTION FROM:
action 0, numVisits=1592742, meanQ=5.852093, numObservations: 3
action 3, numVisits=14079, meanQ=5.119399, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.592885 0.30448 0.512846 0.868381 0.568937 0.854496 w: 1
Observation: 0 0 0.364445 0 0.884174 0 0.776474 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=471928, meanQ=8.087897, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2436281 episodes
GETTING ACTION FROM:
action 2, numVisits=2908191, meanQ=5.402412, numObservations: 4
action -1, numVisits=18, meanQ=3.587294, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.592885 0.30448 0.512846 0.868381 0.568937 0.854496 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 289
Initial state: 0 0.557429 0.820312 0.508446 0.547471 0.532636 0.887416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237907 episodes
GETTING ACTION FROM:
action 1, numVisits=2237899, meanQ=4.964817, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.557429 0.820312 0.508446 0.547471 0.532636 0.887416 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10377, meanQ=7.042229, numObservations: 3
action 3, numVisits=41, meanQ=6.063902, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2789587 episodes
GETTING ACTION FROM:
action 3, numVisits=2765898, meanQ=5.619131, numObservations: 5
action 1, numVisits=34105, meanQ=5.524019, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.557429 0.820312 0.508446 0.547471 0.532636 0.887416 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 290
Initial state: 0 0.727578 0.840269 0.67581 0.89996 0.612777 0.898352 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2267041 episodes
GETTING ACTION FROM:
action 3, numVisits=2267005, meanQ=5.126906, numObservations: 4
action -1, numVisits=19, meanQ=3.300518, numObservations: 1
action 2, numVisits=14, meanQ=0.993593, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.727578 0.840269 0.67581 0.89996 0.612777 0.898352 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 291
Initial state: 0 0.525398 0.827644 0.655678 0.964013 0.557584 0.807299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2275810 episodes
GETTING ACTION FROM:
action 1, numVisits=2143469, meanQ=4.999692, numObservations: 4
action 3, numVisits=132207, meanQ=4.908111, numObservations: 5
action 2, numVisits=101, meanQ=4.143501, numObservations: 4
action -1, numVisits=31, meanQ=3.578806, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.525398 0.827644 0.655678 0.964013 0.557584 0.807299 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 292
Initial state: 0 0.534251 0.399059 0.567284 0.87585 0.632841 0.84698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2224877 episodes
GETTING ACTION FROM:
action 3, numVisits=2224865, meanQ=4.917092, numObservations: 5
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.534251 0.399059 0.567284 0.87585 0.632841 0.84698 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 293
Initial state: 0 0.602156 0.826344 0.593665 0.883939 0.0228837 0.340099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2230467 episodes
GETTING ACTION FROM:
action 2, numVisits=2208211, meanQ=4.980370, numObservations: 4
action 1, numVisits=22251, meanQ=4.866191, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.602156 0.826344 0.593665 0.883939 0.0228837 0.340099 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 294
Initial state: 0 0.685507 0.839683 0.395888 0.297406 0.684945 0.856943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1512926 episodes
GETTING ACTION FROM:
action -1, numVisits=1512910, meanQ=2.714609, numObservations: 1
action 0, numVisits=13, meanQ=0.509460, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.685507 0.839683 0.395888 0.297406 0.684945 0.856943 w: 1
Observation: 0 0.609702 0 0.406733 0 0.771096 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1512895, meanQ=4.773921, numObservations: 4
action 3, numVisits=5, meanQ=0.196000, numObservations: 2
action 1, numVisits=5, meanQ=-0.201980, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 2317833 episodes
GETTING ACTION FROM:
action 2, numVisits=3830728, meanQ=4.949220, numObservations: 4
action 3, numVisits=5, meanQ=0.196000, numObservations: 2
action 1, numVisits=5, meanQ=-0.201980, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.685507 0.839683 0.395888 0.297406 0.684945 0.856943 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=492426, meanQ=8.390496, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2776362 episodes
GETTING ACTION FROM:
action 3, numVisits=3268785, meanQ=6.106271, numObservations: 5
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.685507 0.839683 0.395888 0.297406 0.684945 0.856943 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 295
Initial state: 0 0.216066 0.410171 0.681875 0.884669 0.574623 0.848676 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253100 episodes
GETTING ACTION FROM:
action 1, numVisits=2252931, meanQ=4.957835, numObservations: 4
action -1, numVisits=76, meanQ=4.053618, numObservations: 1
action 0, numVisits=46, meanQ=3.827675, numObservations: 1
action 2, numVisits=46, meanQ=3.772615, numObservations: 5
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.216066 0.410171 0.681875 0.884669 0.574623 0.848676 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 296
Initial state: 0 0.675089 0.830447 0.592735 0.886265 0.829511 0.396352 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258634 episodes
GETTING ACTION FROM:
action 3, numVisits=2253316, meanQ=4.982310, numObservations: 4
action -1, numVisits=5271, meanQ=3.061528, numObservations: 1
action 2, numVisits=44, meanQ=2.222502, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.675089 0.830447 0.592735 0.886265 0.829511 0.396352 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 297
Initial state: 0 0.539936 0.806502 0.0193376 0.587299 0.618076 0.888174 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2244899 episodes
GETTING ACTION FROM:
action 2, numVisits=2244847, meanQ=4.917236, numObservations: 4
action 0, numVisits=35, meanQ=3.613479, numObservations: 1
action 3, numVisits=14, meanQ=2.715007, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.539936 0.806502 0.0193376 0.587299 0.618076 0.888174 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=342199, meanQ=8.316782, numObservations: 5
action 3, numVisits=26, meanQ=6.768465, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2779300 episodes
GETTING ACTION FROM:
action 1, numVisits=3118970, meanQ=6.206491, numObservations: 5
action 3, numVisits=2553, meanQ=6.056956, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.539936 0.806502 0.0193376 0.587299 0.618076 0.888174 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 298
Initial state: 0 0.595404 0.890925 0.524455 0.824691 0.848231 0.283699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237040 episodes
GETTING ACTION FROM:
action 2, numVisits=2237005, meanQ=4.924169, numObservations: 4
action 1, numVisits=23, meanQ=2.912622, numObservations: 4
action 3, numVisits=8, meanQ=1.996250, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.595404 0.890925 0.524455 0.824691 0.848231 0.283699 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 299
Initial state: 0 0.641715 0.800535 0.631243 0.899933 0.0939451 0.126282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1560960 episodes
GETTING ACTION FROM:
action 0, numVisits=1560945, meanQ=2.927410, numObservations: 1
action 2, numVisits=8, meanQ=-0.001250, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.641715 0.800535 0.631243 0.899933 0.0939451 0.126282 w: 1
Observation: 0 0 0.849473 0 0.901286 0 0.217539 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1560890, meanQ=4.978168, numObservations: 4
action -1, numVisits=50, meanQ=3.896561, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2470290 episodes
GETTING ACTION FROM:
action 1, numVisits=4031180, meanQ=5.144080, numObservations: 4
action -1, numVisits=50, meanQ=3.896561, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.641715 0.800535 0.631243 0.899933 0.0939451 0.126282 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=286670, meanQ=5.813217, numObservations: 3
action 2, numVisits=15, meanQ=3.126000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2627683 episodes
GETTING ACTION FROM:
action 1, numVisits=2914353, meanQ=5.346340, numObservations: 4
action 2, numVisits=15, meanQ=3.126000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.641715 0.800535 0.631243 0.899933 0.0939451 0.126282 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 300
Initial state: 0 0.841911 0.419892 0.54749 0.810824 0.501306 0.803651 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268479 episodes
GETTING ACTION FROM:
action 1, numVisits=2268463, meanQ=4.973232, numObservations: 4
action 2, numVisits=11, meanQ=1.710000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.841911 0.419892 0.54749 0.810824 0.501306 0.803651 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 301
Initial state: 0 0.0881641 0.835396 0.654928 0.828584 0.624116 0.82237 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2287159 episodes
GETTING ACTION FROM:
action 1, numVisits=2287151, meanQ=4.919787, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0881641 0.835396 0.654928 0.828584 0.624116 0.82237 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=348599, meanQ=8.317596, numObservations: 5
action 2, numVisits=57, meanQ=7.350881, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2766371 episodes
GETTING ACTION FROM:
action 3, numVisits=3114642, meanQ=6.268287, numObservations: 5
action 2, numVisits=383, meanQ=5.875144, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.0881641 0.835396 0.654928 0.828584 0.624116 0.82237 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 302
Initial state: 0 0.296556 0.877849 0.633731 0.843128 0.689796 0.817728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247569 episodes
GETTING ACTION FROM:
action 2, numVisits=2247559, meanQ=4.918222, numObservations: 5
action 3, numVisits=5, meanQ=1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.296556 0.877849 0.633731 0.843128 0.689796 0.817728 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 303
Initial state: 0 0.342736 0.583262 0.502916 0.827014 0.664893 0.878189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2155860 episodes
GETTING ACTION FROM:
action 3, numVisits=2155696, meanQ=4.691159, numObservations: 4
action 0, numVisits=154, meanQ=4.076164, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.342736 0.583262 0.502916 0.827014 0.664893 0.878189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 304
Initial state: 0 0.0618711 0.237096 0.628267 0.890158 0.69866 0.830839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2228635 episodes
GETTING ACTION FROM:
action 3, numVisits=2228588, meanQ=4.919260, numObservations: 5
action -1, numVisits=43, meanQ=3.709252, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0618711 0.237096 0.628267 0.890158 0.69866 0.830839 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 305
Initial state: 0 0.519332 0.85184 0.731363 0.491588 0.562129 0.836968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2266784 episodes
GETTING ACTION FROM:
action 1, numVisits=2266772, meanQ=5.164761, numObservations: 5
action 3, numVisits=7, meanQ=-0.145714, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.519332 0.85184 0.731363 0.491588 0.562129 0.836968 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 306
Initial state: 0 0.738833 0.977956 0.580506 0.857769 0.605954 0.842104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2231057 episodes
GETTING ACTION FROM:
action 1, numVisits=2231021, meanQ=4.938264, numObservations: 5
action 0, numVisits=17, meanQ=3.081481, numObservations: 1
action 3, numVisits=16, meanQ=2.498750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.738833 0.977956 0.580506 0.857769 0.605954 0.842104 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 307
Initial state: 0 0.653882 0.833093 0.652559 0.858136 0.226485 0.309014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2276571 episodes
GETTING ACTION FROM:
action 2, numVisits=2276484, meanQ=4.978710, numObservations: 4
action 0, numVisits=43, meanQ=3.810204, numObservations: 1
action 3, numVisits=38, meanQ=3.523163, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.653882 0.833093 0.652559 0.858136 0.226485 0.309014 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 308
Initial state: 0 0.600735 0.795737 0.604026 0.859743 0.614419 0.856345 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2215301 episodes
GETTING ACTION FROM:
action 3, numVisits=2215284, meanQ=4.967627, numObservations: 5
action 1, numVisits=12, meanQ=2.498342, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.600735 0.795737 0.604026 0.859743 0.614419 0.856345 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 309
Initial state: 0 0.552813 0.874754 0.751375 0.249634 0.521564 0.875652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2157140 episodes
GETTING ACTION FROM:
action 1, numVisits=2157134, meanQ=4.975172, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.552813 0.874754 0.751375 0.249634 0.521564 0.875652 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 310
Initial state: 0 0.678926 0.821644 0.64929 0.835461 0.0984535 0.391954 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2236025 episodes
GETTING ACTION FROM:
action 3, numVisits=2235981, meanQ=4.898542, numObservations: 5
action 0, numVisits=35, meanQ=3.595136, numObservations: 1
action 1, numVisits=6, meanQ=0.981667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.678926 0.821644 0.64929 0.835461 0.0984535 0.391954 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=219152, meanQ=8.544577, numObservations: 3
action 2, numVisits=8, meanQ=5.501263, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2876868 episodes
GETTING ACTION FROM:
action 1, numVisits=3095946, meanQ=6.268146, numObservations: 3
action 2, numVisits=80, meanQ=5.397751, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.678926 0.821644 0.64929 0.835461 0.0984535 0.391954 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 311
Initial state: 0 0.386316 0.208082 0.695425 0.802868 0.506085 0.869085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2282323 episodes
GETTING ACTION FROM:
action 3, numVisits=2282227, meanQ=4.911664, numObservations: 3
action -1, numVisits=71, meanQ=3.997860, numObservations: 1
action 2, numVisits=19, meanQ=2.367905, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.386316 0.208082 0.695425 0.802868 0.506085 0.869085 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 312
Initial state: 0 0.51992 0.843402 0.162419 0.867885 0.681206 0.899426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239425 episodes
GETTING ACTION FROM:
action 2, numVisits=2239408, meanQ=4.910573, numObservations: 5
action 1, numVisits=12, meanQ=1.332500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.51992 0.843402 0.162419 0.867885 0.681206 0.899426 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=122119, meanQ=7.924800, numObservations: 3
action 1, numVisits=9, meanQ=3.221111, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2884709 episodes
GETTING ACTION FROM:
action 3, numVisits=3006826, meanQ=5.797684, numObservations: 3
action 1, numVisits=9, meanQ=3.221111, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.51992 0.843402 0.162419 0.867885 0.681206 0.899426 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 313
Initial state: 0 0.51295 0.844947 0.54153 0.808652 0.132119 0.223639 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2193386 episodes
GETTING ACTION FROM:
action 3, numVisits=2193294, meanQ=4.835818, numObservations: 4
action -1, numVisits=50, meanQ=3.726911, numObservations: 1
action 0, numVisits=36, meanQ=3.556709, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.51295 0.844947 0.54153 0.808652 0.132119 0.223639 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=333269, meanQ=8.328589, numObservations: 4
action 2, numVisits=380, meanQ=7.970145, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2842175 episodes
GETTING ACTION FROM:
action 1, numVisits=3172257, meanQ=6.101544, numObservations: 4
action 2, numVisits=3565, meanQ=5.975736, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.51295 0.844947 0.54153 0.808652 0.132119 0.223639 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 314
Initial state: 0 0.69422 0.105664 0.517591 0.890162 0.627942 0.861396 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2225169 episodes
GETTING ACTION FROM:
action 3, numVisits=2225132, meanQ=4.906366, numObservations: 5
action 2, numVisits=16, meanQ=2.873756, numObservations: 3
action 1, numVisits=17, meanQ=2.411176, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.69422 0.105664 0.517591 0.890162 0.627942 0.861396 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 315
Initial state: 0 0.607503 0.849411 0.540385 0.814253 0.886488 0.848431 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2281794 episodes
GETTING ACTION FROM:
action 1, numVisits=2274338, meanQ=4.999062, numObservations: 4
action 2, numVisits=7393, meanQ=4.914373, numObservations: 4
action -1, numVisits=57, meanQ=3.951172, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.607503 0.849411 0.540385 0.814253 0.886488 0.848431 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 316
Initial state: 0 0.613768 0.876574 0.616283 0.854726 0.902151 0.151238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2289629 episodes
GETTING ACTION FROM:
action 3, numVisits=2289623, meanQ=4.989611, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.613768 0.876574 0.616283 0.854726 0.902151 0.151238 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 317
Initial state: 0 0.580154 0.885559 0.579924 0.872865 0.193654 0.256056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263394 episodes
GETTING ACTION FROM:
action 2, numVisits=2263326, meanQ=4.985403, numObservations: 4
action 0, numVisits=61, meanQ=3.972787, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.580154 0.885559 0.579924 0.872865 0.193654 0.256056 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 318
Initial state: 0 0.675301 0.810814 0.0315264 0.127132 0.521533 0.828537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247654 episodes
GETTING ACTION FROM:
action 2, numVisits=2247575, meanQ=4.977002, numObservations: 5
action -1, numVisits=75, meanQ=4.095633, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.675301 0.810814 0.0315264 0.127132 0.521533 0.828537 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 319
Initial state: 0 0.630717 0.889998 0.671739 0.817354 0.106863 0.734958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262981 episodes
GETTING ACTION FROM:
action 2, numVisits=2262849, meanQ=5.007291, numObservations: 5
action -1, numVisits=80, meanQ=4.143458, numObservations: 1
action 0, numVisits=38, meanQ=3.750390, numObservations: 1
action 1, numVisits=13, meanQ=2.536923, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.630717 0.889998 0.671739 0.817354 0.106863 0.734958 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 320
Initial state: 0 0.502515 0.845551 0.0131931 0.821317 0.635769 0.85563 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2250256 episodes
GETTING ACTION FROM:
action 2, numVisits=2245508, meanQ=4.971563, numObservations: 4
action -1, numVisits=4744, meanQ=2.724626, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.502515 0.845551 0.0131931 0.821317 0.635769 0.85563 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=121608, meanQ=7.930711, numObservations: 3
action 3, numVisits=5, meanQ=4.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2894337 episodes
GETTING ACTION FROM:
action 1, numVisits=3015941, meanQ=5.758842, numObservations: 3
action 3, numVisits=7, meanQ=2.711429, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.502515 0.845551 0.0131931 0.821317 0.635769 0.85563 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 321
Initial state: 0 0.693446 0.859001 0.134047 0.259082 0.596324 0.854871 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271595 episodes
GETTING ACTION FROM:
action 1, numVisits=2271580, meanQ=4.917177, numObservations: 3
action -1, numVisits=10, meanQ=2.488000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.693446 0.859001 0.134047 0.259082 0.596324 0.854871 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 322
Initial state: 0 0.502816 0.888168 0.674551 0.885957 0.433889 0.857814 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237978 episodes
GETTING ACTION FROM:
action 1, numVisits=2237942, meanQ=4.911277, numObservations: 5
action 0, numVisits=24, meanQ=3.272254, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.502816 0.888168 0.674551 0.885957 0.433889 0.857814 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=163225, meanQ=4.681732, numObservations: 5
action 0, numVisits=65, meanQ=2.516202, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2746687 episodes
GETTING ACTION FROM:
action 3, numVisits=2909912, meanQ=5.628982, numObservations: 5
action 0, numVisits=65, meanQ=2.516202, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.502816 0.888168 0.674551 0.885957 0.433889 0.857814 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=8393, meanQ=8.130994, numObservations: 5
action 1, numVisits=6659, meanQ=7.737080, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2860506 episodes
GETTING ACTION FROM:
action 2, numVisits=2818611, meanQ=6.033308, numObservations: 5
action 1, numVisits=56945, meanQ=6.005416, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.502816 0.888168 0.674551 0.885957 0.433889 0.857814 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 323
Initial state: 0 0.678662 0.844385 0.632038 0.886725 0.675955 0.886918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258667 episodes
GETTING ACTION FROM:
action 3, numVisits=2199728, meanQ=4.989684, numObservations: 4
action 2, numVisits=46661, meanQ=4.918843, numObservations: 4
action 1, numVisits=12274, meanQ=4.888064, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.678662 0.844385 0.632038 0.886725 0.675955 0.886918 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 324
Initial state: 0 0.606459 0.839609 0.507927 0.880843 0.972865 0.553021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2265075 episodes
GETTING ACTION FROM:
action 3, numVisits=2264937, meanQ=4.995222, numObservations: 4
action -1, numVisits=67, meanQ=4.062505, numObservations: 1
action 0, numVisits=68, meanQ=4.034304, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.606459 0.839609 0.507927 0.880843 0.972865 0.553021 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 325
Initial state: 0 0.657324 0.855078 0.576533 0.893478 0.18467 0.472234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247154 episodes
GETTING ACTION FROM:
action 3, numVisits=2247145, meanQ=4.914433, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.657324 0.855078 0.576533 0.893478 0.18467 0.472234 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=285958, meanQ=8.397529, numObservations: 3
action 2, numVisits=45, meanQ=7.213778, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2870186 episodes
GETTING ACTION FROM:
action 1, numVisits=3154254, meanQ=6.191095, numObservations: 3
action 2, numVisits=1933, meanQ=6.014671, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.657324 0.855078 0.576533 0.893478 0.18467 0.472234 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 326
Initial state: 0 0.569684 0.807084 0.646366 0.809639 0.0029245 0.190858 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2300205 episodes
GETTING ACTION FROM:
action 2, numVisits=2300108, meanQ=4.923622, numObservations: 3
action 0, numVisits=51, meanQ=3.832231, numObservations: 1
action -1, numVisits=44, meanQ=3.767013, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.569684 0.807084 0.646366 0.809639 0.0029245 0.190858 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 327
Initial state: 0 0.518547 0.865329 0.841896 0.561147 0.529632 0.880242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2228347 episodes
GETTING ACTION FROM:
action 2, numVisits=2228338, meanQ=4.969529, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.518547 0.865329 0.841896 0.561147 0.529632 0.880242 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 328
Initial state: 0 0.591932 0.827726 0.863712 0.889608 0.514585 0.864909 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2301649 episodes
GETTING ACTION FROM:
action 1, numVisits=2301643, meanQ=5.002204, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.591932 0.827726 0.863712 0.889608 0.514585 0.864909 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 329
Initial state: 0 0.581582 0.865402 0.608322 0.838065 0.557284 0.126409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2256684 episodes
GETTING ACTION FROM:
action 2, numVisits=2256676, meanQ=5.130527, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.581582 0.865402 0.608322 0.838065 0.557284 0.126409 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 330
Initial state: 0 0.35725 0.501371 0.563336 0.855249 0.512067 0.834941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261077 episodes
GETTING ACTION FROM:
action 2, numVisits=2260642, meanQ=4.986305, numObservations: 4
action -1, numVisits=429, meanQ=1.510550, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.35725 0.501371 0.563336 0.855249 0.512067 0.834941 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 331
Initial state: 0 0.667217 0.818056 0.651658 0.843519 0.400657 0.893513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2233820 episodes
GETTING ACTION FROM:
action 2, numVisits=2229521, meanQ=5.106850, numObservations: 5
action -1, numVisits=4290, meanQ=2.686591, numObservations: 1
action 1, numVisits=6, meanQ=-0.350000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.667217 0.818056 0.651658 0.843519 0.400657 0.893513 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 332
Initial state: 0 0.608278 0.817697 0.51799 0.819593 0.491888 0.602309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1545966 episodes
GETTING ACTION FROM:
action 0, numVisits=1545958, meanQ=3.044154, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.608278 0.817697 0.51799 0.819593 0.491888 0.602309 w: 1
Observation: 0 0 0.731734 0 0.82313 0 0.522729 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1545948, meanQ=5.092870, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 2456554 episodes
GETTING ACTION FROM:
action 1, numVisits=4002502, meanQ=5.005082, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.608278 0.817697 0.51799 0.819593 0.491888 0.602309 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 333
Initial state: 0 0.567584 0.86952 0.443013 0.33603 0.60781 0.81764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258050 episodes
GETTING ACTION FROM:
action 2, numVisits=2258043, meanQ=4.905839, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.567584 0.86952 0.443013 0.33603 0.60781 0.81764 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=285572, meanQ=8.356624, numObservations: 3
action 1, numVisits=654, meanQ=8.091203, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2842679 episodes
GETTING ACTION FROM:
action 3, numVisits=3123848, meanQ=6.116710, numObservations: 3
action 1, numVisits=5054, meanQ=6.010485, numObservations: 3
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.567584 0.86952 0.443013 0.33603 0.60781 0.81764 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 334
Initial state: 0 0.583407 0.877182 0.660704 0.800793 0.55955 0.28101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2241389 episodes
GETTING ACTION FROM:
action 1, numVisits=2240936, meanQ=4.989631, numObservations: 5
action -1, numVisits=449, meanQ=1.703149, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.583407 0.877182 0.660704 0.800793 0.55955 0.28101 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 335
Initial state: 0 0.692896 0.808081 0.117369 0.679944 0.631949 0.880668 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258601 episodes
GETTING ACTION FROM:
action 2, numVisits=2258439, meanQ=5.003960, numObservations: 4
action 0, numVisits=98, meanQ=4.225072, numObservations: 1
action -1, numVisits=46, meanQ=3.837530, numObservations: 1
action 3, numVisits=17, meanQ=2.411176, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.692896 0.808081 0.117369 0.679944 0.631949 0.880668 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 336
Initial state: 0 0.618281 0.989371 0.61551 0.858523 0.68235 0.824305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2235735 episodes
GETTING ACTION FROM:
action 1, numVisits=2235662, meanQ=4.901343, numObservations: 5
action -1, numVisits=47, meanQ=3.784912, numObservations: 1
action 0, numVisits=19, meanQ=2.886032, numObservations: 1
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.618281 0.989371 0.61551 0.858523 0.68235 0.824305 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 337
Initial state: 0 0.783572 0.233916 0.525308 0.899869 0.59743 0.802534 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2276155 episodes
GETTING ACTION FROM:
action 3, numVisits=2276112, meanQ=5.015440, numObservations: 4
action -1, numVisits=32, meanQ=3.627471, numObservations: 1
action 2, numVisits=8, meanQ=2.012500, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.783572 0.233916 0.525308 0.899869 0.59743 0.802534 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=143135, meanQ=5.674148, numObservations: 3
action 2, numVisits=31, meanQ=4.216129, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 2638236 episodes
GETTING ACTION FROM:
action 3, numVisits=2781366, meanQ=5.081993, numObservations: 3
action 2, numVisits=36, meanQ=3.769444, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.783572 0.233916 0.525308 0.899869 0.59743 0.802534 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 338
Initial state: 0 0.60895 0.810067 0.800818 0.729873 0.519704 0.844459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2282543 episodes
GETTING ACTION FROM:
action 1, numVisits=2280965, meanQ=4.916978, numObservations: 3
action 3, numVisits=1547, meanQ=4.620585, numObservations: 4
action 2, numVisits=27, meanQ=3.367781, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.60895 0.810067 0.800818 0.729873 0.519704 0.844459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=168055, meanQ=4.827820, numObservations: 5
action 1, numVisits=19, meanQ=2.472632, numObservations: 3
action 3, numVisits=5, meanQ=-0.201980, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2794713 episodes
GETTING ACTION FROM:
action 2, numVisits=2962768, meanQ=5.703304, numObservations: 5
action 1, numVisits=19, meanQ=2.472632, numObservations: 3
action 3, numVisits=5, meanQ=-0.201980, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.60895 0.810067 0.800818 0.729873 0.519704 0.844459 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 339
Initial state: 0 0.973779 0.749133 0.55589 0.813904 0.546725 0.842244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2257784 episodes
GETTING ACTION FROM:
action 2, numVisits=2257090, meanQ=4.970048, numObservations: 4
action 3, numVisits=679, meanQ=4.662777, numObservations: 4
action 1, numVisits=11, meanQ=2.627282, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.973779 0.749133 0.55589 0.813904 0.546725 0.842244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 340
Initial state: 0 0.82258 0.640687 0.631539 0.891106 0.676747 0.850421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2251930 episodes
GETTING ACTION FROM:
action 1, numVisits=2247730, meanQ=5.127077, numObservations: 5
action 2, numVisits=4059, meanQ=4.784799, numObservations: 5
action -1, numVisits=138, meanQ=4.470938, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.82258 0.640687 0.631539 0.891106 0.676747 0.850421 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 341
Initial state: 0 0.62507 0.871261 0.524453 0.850284 0.0329917 0.750591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261221 episodes
GETTING ACTION FROM:
action 2, numVisits=2261142, meanQ=4.903841, numObservations: 4
action 0, numVisits=72, meanQ=3.987354, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.62507 0.871261 0.524453 0.850284 0.0329917 0.750591 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 342
Initial state: 0 0.0854166 0.688655 0.600296 0.815536 0.630939 0.840061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2234685 episodes
GETTING ACTION FROM:
action 3, numVisits=2234632, meanQ=4.983932, numObservations: 5
action -1, numVisits=49, meanQ=3.865331, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0854166 0.688655 0.600296 0.815536 0.630939 0.840061 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 343
Initial state: 0 0.527581 0.874088 0.914789 0.155847 0.667921 0.817136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253055 episodes
GETTING ACTION FROM:
action 1, numVisits=2246608, meanQ=4.916478, numObservations: 4
action 3, numVisits=6223, meanQ=4.822481, numObservations: 4
action 0, numVisits=130, meanQ=4.250177, numObservations: 2
action 2, numVisits=92, meanQ=4.093590, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.527581 0.874088 0.914789 0.155847 0.667921 0.817136 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 344
Initial state: 0 0.623656 0.822292 0.341434 0.738206 0.66856 0.860582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2288981 episodes
GETTING ACTION FROM:
action 3, numVisits=2288969, meanQ=4.989129, numObservations: 3
action 1, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.623656 0.822292 0.341434 0.738206 0.66856 0.860582 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 345
Initial state: 0 0.552472 0.850322 0.624105 0.842067 0.652221 0.382265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2266674 episodes
GETTING ACTION FROM:
action 2, numVisits=2266617, meanQ=4.997861, numObservations: 4
action 0, numVisits=53, meanQ=3.945281, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.552472 0.850322 0.624105 0.842067 0.652221 0.382265 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 346
Initial state: 0 0.560367 0.878553 0.499953 0.0142438 0.5773 0.851765 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2238104 episodes
GETTING ACTION FROM:
action 3, numVisits=2238036, meanQ=4.985397, numObservations: 5
action -1, numVisits=52, meanQ=3.913496, numObservations: 1
action 1, numVisits=13, meanQ=2.836923, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.560367 0.878553 0.499953 0.0142438 0.5773 0.851765 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 347
Initial state: 0 0.68126 0.806982 0.981544 0.259376 0.684112 0.879385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254821 episodes
GETTING ACTION FROM:
action 1, numVisits=2254719, meanQ=4.923489, numObservations: 4
action 0, numVisits=73, meanQ=4.017745, numObservations: 1
action 3, numVisits=13, meanQ=2.536923, numObservations: 4
action 2, numVisits=14, meanQ=2.422164, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.68126 0.806982 0.981544 0.259376 0.684112 0.879385 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 348
Initial state: 0 0.622761 0.809103 0.641403 0.896174 0.829648 0.619179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2276964 episodes
GETTING ACTION FROM:
action 1, numVisits=2276882, meanQ=4.894602, numObservations: 3
action -1, numVisits=78, meanQ=4.028871, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.622761 0.809103 0.641403 0.896174 0.829648 0.619179 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 349
Initial state: 0 0.19357 0.212667 0.596083 0.890993 0.633537 0.870303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2289787 episodes
GETTING ACTION FROM:
action 2, numVisits=2289672, meanQ=4.991921, numObservations: 4
action -1, numVisits=54, meanQ=3.950085, numObservations: 1
action 3, numVisits=58, meanQ=3.852762, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.19357 0.212667 0.596083 0.890993 0.633537 0.870303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 350
Initial state: 0 0.86355 0.169921 0.510024 0.824105 0.652757 0.844232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2272492 episodes
GETTING ACTION FROM:
action 1, numVisits=2272372, meanQ=5.006196, numObservations: 4
action 0, numVisits=113, meanQ=4.290696, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.86355 0.169921 0.510024 0.824105 0.652757 0.844232 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 351
Initial state: 0 0.529002 0.88561 0.634126 0.94597 0.685568 0.896914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2242498 episodes
GETTING ACTION FROM:
action 2, numVisits=2242391, meanQ=4.988305, numObservations: 5
action 3, numVisits=96, meanQ=4.054831, numObservations: 4
action 1, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.529002 0.88561 0.634126 0.94597 0.685568 0.896914 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 352
Initial state: 0 0.379595 0.190533 0.568947 0.855885 0.535025 0.833657 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259471 episodes
GETTING ACTION FROM:
action 2, numVisits=2259451, meanQ=5.105227, numObservations: 4
action 1, numVisits=15, meanQ=2.465340, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.379595 0.190533 0.568947 0.855885 0.535025 0.833657 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 353
Initial state: 0 0.610243 0.88211 0.122337 0.904988 0.671255 0.872155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2288899 episodes
GETTING ACTION FROM:
action 1, numVisits=2288878, meanQ=4.921730, numObservations: 3
action -1, numVisits=14, meanQ=2.643571, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.610243 0.88211 0.122337 0.904988 0.671255 0.872155 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 354
Initial state: 0 0.6025 0.893589 0.188755 0.596911 0.583793 0.872696 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1291549 episodes
GETTING ACTION FROM:
action 0, numVisits=1291464, meanQ=4.231722, numObservations: 2
action -1, numVisits=78, meanQ=2.701228, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 0
Next state: 0 0.6025 0.893589 0.188755 0.596911 0.583793 0.872696 w: 1
Observation: 0 0 0.833202 0 0.661351 0 0.860198 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=868092, meanQ=5.385567, numObservations: 1
action 3, numVisits=1876, meanQ=4.394866, numObservations: 5
action 2, numVisits=271, meanQ=4.191707, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1617861 episodes
GETTING ACTION FROM:
action 1, numVisits=41820, meanQ=4.874231, numObservations: 3
action 0, numVisits=2444134, meanQ=4.655838, numObservations: 1
action 3, numVisits=1876, meanQ=4.394866, numObservations: 5
action 2, numVisits=271, meanQ=4.191707, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.6025 0.893589 0.188755 0.596911 0.583793 0.872696 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 355
Initial state: 0 0.504412 0.882139 0.996142 0.962678 0.564365 0.825881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2255680 episodes
GETTING ACTION FROM:
action 1, numVisits=2255595, meanQ=4.891479, numObservations: 4
action 0, numVisits=52, meanQ=3.801653, numObservations: 1
action -1, numVisits=31, meanQ=3.512040, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.504412 0.882139 0.996142 0.962678 0.564365 0.825881 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=164821, meanQ=4.614393, numObservations: 3
action -1, numVisits=172, meanQ=4.095556, numObservations: 1
action 0, numVisits=73, meanQ=3.813119, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2849708 episodes
GETTING ACTION FROM:
action 3, numVisits=3014529, meanQ=5.940745, numObservations: 3
action -1, numVisits=172, meanQ=4.095556, numObservations: 1
action 0, numVisits=73, meanQ=3.813119, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.504412 0.882139 0.996142 0.962678 0.564365 0.825881 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 356
Initial state: 0 0.583849 0.816996 0.515957 0.844358 0.678579 0.491594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2238937 episodes
GETTING ACTION FROM:
action 2, numVisits=2238710, meanQ=4.900027, numObservations: 4
action 0, numVisits=126, meanQ=4.219897, numObservations: 1
action -1, numVisits=95, meanQ=4.116773, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action: 2
Next state: 1 0.583849 0.816996 0.515957 0.844358 0.678579 0.491594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 357
Initial state: 0 0.520313 0.862978 0.475933 0.602957 0.684879 0.858191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2260624 episodes
GETTING ACTION FROM:
action 1, numVisits=2260618, meanQ=4.897249, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.520313 0.862978 0.475933 0.602957 0.684879 0.858191 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 358
Initial state: 0 0.731984 0.296115 0.56111 0.848553 0.520446 0.805881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2294311 episodes
GETTING ACTION FROM:
action 2, numVisits=2294305, meanQ=4.917272, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.731984 0.296115 0.56111 0.848553 0.520446 0.805881 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 359
Initial state: 0 0.54389 0.865196 0.546422 0.872096 0.0746707 0.503714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2195170 episodes
GETTING ACTION FROM:
action 2, numVisits=2195125, meanQ=4.843366, numObservations: 4
action -1, numVisits=28, meanQ=3.320413, numObservations: 1
action 1, numVisits=12, meanQ=2.333333, numObservations: 3
action 3, numVisits=3, meanQ=0.330033, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.54389 0.865196 0.546422 0.872096 0.0746707 0.503714 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 360
Initial state: 0 0.608935 0.892876 0.518018 0.728544 0.60436 0.882821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2231516 episodes
GETTING ACTION FROM:
action 2, numVisits=2231510, meanQ=4.984056, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.608935 0.892876 0.518018 0.728544 0.60436 0.882821 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 361
Initial state: 0 0.618872 0.817632 0.409643 0.0795813 0.635229 0.863563 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2288950 episodes
GETTING ACTION FROM:
action 3, numVisits=2288883, meanQ=4.994777, numObservations: 3
action -1, numVisits=53, meanQ=3.922172, numObservations: 1
action 2, numVisits=8, meanQ=1.747513, numObservations: 2
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.618872 0.817632 0.409643 0.0795813 0.635229 0.863563 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=168039, meanQ=5.632091, numObservations: 3
action 0, numVisits=33, meanQ=4.377650, numObservations: 1
action -1, numVisits=14, meanQ=3.687680, numObservations: 1
action 2, numVisits=10, meanQ=3.397000, numObservations: 4
action 1, numVisits=13, meanQ=3.307708, numObservations: 2
Sampled 2824854 episodes
GETTING ACTION FROM:
action 2, numVisits=2815844, meanQ=5.830342, numObservations: 5
action 3, numVisits=177059, meanQ=5.579075, numObservations: 4
action 0, numVisits=33, meanQ=4.377650, numObservations: 1
action -1, numVisits=14, meanQ=3.687680, numObservations: 1
action 1, numVisits=13, meanQ=3.307708, numObservations: 2
action: 2
Next state: 0 0.618872 0.817632 0.409643 0.0795813 0.635229 0.863563 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=22208, meanQ=8.516257, numObservations: 3
action 1, numVisits=164, meanQ=7.943296, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2914656 episodes
GETTING ACTION FROM:
action 1, numVisits=1796023, meanQ=6.016101, numObservations: 3
action 3, numVisits=1141003, meanQ=5.973357, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.618872 0.817632 0.409643 0.0795813 0.635229 0.863563 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action -1, numVisits=4248, meanQ=5.920067, numObservations: 1
action 3, numVisits=322, meanQ=3.530521, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2951944 episodes
GETTING ACTION FROM:
action 3, numVisits=2950658, meanQ=6.133157, numObservations: 3
action -1, numVisits=5855, meanQ=3.753090, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.618872 0.817632 0.409643 0.0795813 0.635229 0.863563 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 362
Initial state: 0 0.679173 0.831763 0.528137 0.823581 0.506978 0.869445 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259143 episodes
GETTING ACTION FROM:
action 3, numVisits=2259054, meanQ=4.984123, numObservations: 4
action 0, numVisits=42, meanQ=3.763361, numObservations: 1
action -1, numVisits=35, meanQ=3.602616, numObservations: 1
action 2, numVisits=11, meanQ=1.907282, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.679173 0.831763 0.528137 0.823581 0.506978 0.869445 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 363
Initial state: 0 0.526667 0.853513 0.605421 0.834668 0.378447 0.181681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2275354 episodes
GETTING ACTION FROM:
action 2, numVisits=2275347, meanQ=4.967807, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.526667 0.853513 0.605421 0.834668 0.378447 0.181681 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=345816, meanQ=8.317629, numObservations: 4
action 3, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2815339 episodes
GETTING ACTION FROM:
action 1, numVisits=3161146, meanQ=6.137989, numObservations: 4
action 3, numVisits=10, meanQ=3.000000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.526667 0.853513 0.605421 0.834668 0.378447 0.181681 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 364
Initial state: 0 0.665544 0.863172 0.652112 0.822677 0.428775 0.30092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2248421 episodes
GETTING ACTION FROM:
action 2, numVisits=2248414, meanQ=4.867207, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.665544 0.863172 0.652112 0.822677 0.428775 0.30092 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 365
Initial state: 0 0.513201 0.804812 0.630703 0.832767 0.553345 0.508569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2243663 episodes
GETTING ACTION FROM:
action 1, numVisits=2243628, meanQ=4.971289, numObservations: 5
action 0, numVisits=31, meanQ=3.565569, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.513201 0.804812 0.630703 0.832767 0.553345 0.508569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 366
Initial state: 0 0.626819 0.854611 0.456449 0.874593 0.544152 0.822481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2279757 episodes
GETTING ACTION FROM:
action 1, numVisits=2279631, meanQ=4.883939, numObservations: 3
action -1, numVisits=119, meanQ=4.117146, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.626819 0.854611 0.456449 0.874593 0.544152 0.822481 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 367
Initial state: 0 0.519626 0.830008 0.265831 0.169778 0.646604 0.843964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258013 episodes
GETTING ACTION FROM:
action 1, numVisits=2257992, meanQ=4.979605, numObservations: 4
action 3, numVisits=16, meanQ=2.750000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.519626 0.830008 0.265831 0.169778 0.646604 0.843964 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 368
Initial state: 0 0.839959 0.0349252 0.689791 0.878887 0.6001 0.880182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253646 episodes
GETTING ACTION FROM:
action 2, numVisits=850403, meanQ=4.989604, numObservations: 5
action 1, numVisits=1375978, meanQ=4.986338, numObservations: 3
action 3, numVisits=27261, meanQ=4.919668, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.839959 0.0349252 0.689791 0.878887 0.6001 0.880182 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=61883, meanQ=5.611316, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2686690 episodes
GETTING ACTION FROM:
action 2, numVisits=2748571, meanQ=5.051158, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.839959 0.0349252 0.689791 0.878887 0.6001 0.880182 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 369
Initial state: 0 0.628979 0.859336 0.639616 0.86083 0.467012 0.327912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2243856 episodes
GETTING ACTION FROM:
action 2, numVisits=2243848, meanQ=5.000611, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.628979 0.859336 0.639616 0.86083 0.467012 0.327912 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 370
Initial state: 0 0.649942 0.851995 0.668256 0.851644 0.762387 0.783375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2251415 episodes
GETTING ACTION FROM:
action 3, numVisits=2251405, meanQ=4.973199, numObservations: 4
action 1, numVisits=5, meanQ=0.196000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.649942 0.851995 0.668256 0.851644 0.762387 0.783375 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 371
Initial state: 0 0.681875 0.833412 0.843416 0.626402 0.660413 0.842696 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2289045 episodes
GETTING ACTION FROM:
action 1, numVisits=2289027, meanQ=4.949994, numObservations: 3
action -1, numVisits=14, meanQ=2.779025, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.681875 0.833412 0.843416 0.626402 0.660413 0.842696 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 372
Initial state: 0 0.653257 0.895299 0.762237 0.846168 0.513645 0.807637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2229647 episodes
GETTING ACTION FROM:
action 2, numVisits=2229638, meanQ=4.964775, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.653257 0.895299 0.762237 0.846168 0.513645 0.807637 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 373
Initial state: 0 0.507156 0.807482 0.62801 0.467078 0.646737 0.854967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2250516 episodes
GETTING ACTION FROM:
action 1, numVisits=2250463, meanQ=4.918613, numObservations: 4
action 0, numVisits=24, meanQ=3.361680, numObservations: 1
action 2, numVisits=23, meanQ=2.038261, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.507156 0.807482 0.62801 0.467078 0.646737 0.854967 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 374
Initial state: 0 0.529567 0.303674 0.570307 0.863947 0.574344 0.875948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246988 episodes
GETTING ACTION FROM:
action 3, numVisits=2246857, meanQ=4.984993, numObservations: 5
action 0, numVisits=100, meanQ=4.219325, numObservations: 1
action 2, numVisits=21, meanQ=2.714286, numObservations: 4
action 1, numVisits=8, meanQ=1.747513, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.529567 0.303674 0.570307 0.863947 0.574344 0.875948 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=164864, meanQ=5.596604, numObservations: 4
action 2, numVisits=50, meanQ=3.674608, numObservations: 5
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2618432 episodes
GETTING ACTION FROM:
action 3, numVisits=2783296, meanQ=4.827017, numObservations: 4
action 2, numVisits=50, meanQ=3.674608, numObservations: 5
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.529567 0.303674 0.570307 0.863947 0.574344 0.875948 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 375
Initial state: 0 0.595663 0.858272 0.69639 0.857018 0.856277 0.00286524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2235308 episodes
GETTING ACTION FROM:
action 2, numVisits=2232743, meanQ=5.109738, numObservations: 5
action 3, numVisits=2533, meanQ=4.955592, numObservations: 5
action 1, numVisits=28, meanQ=3.571429, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.595663 0.858272 0.69639 0.857018 0.856277 0.00286524 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 376
Initial state: 0 0.640435 0.812156 0.544937 0.882528 0.616898 0.797687 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2266212 episodes
GETTING ACTION FROM:
action 3, numVisits=2266146, meanQ=4.954033, numObservations: 4
action 1, numVisits=55, meanQ=3.905458, numObservations: 3
action 2, numVisits=7, meanQ=1.570000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.640435 0.812156 0.544937 0.882528 0.616898 0.797687 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 377
Initial state: 0 0.0784239 0.133143 0.604768 0.898615 0.602343 0.886663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2186626 episodes
GETTING ACTION FROM:
action 2, numVisits=2186620, meanQ=4.822063, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.0784239 0.133143 0.604768 0.898615 0.602343 0.886663 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 378
Initial state: 0 0.924699 0.411939 0.5495 0.848618 0.697587 0.888816 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262383 episodes
GETTING ACTION FROM:
action 1, numVisits=2261856, meanQ=4.981759, numObservations: 4
action 3, numVisits=444, meanQ=4.610410, numObservations: 4
action 0, numVisits=50, meanQ=3.846702, numObservations: 1
action -1, numVisits=29, meanQ=3.521906, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action: 1
Next state: 2 0.924699 0.411939 0.5495 0.848618 0.697587 0.888816 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 379
Initial state: 0 0.501736 0.952386 0.620538 0.886317 0.592915 0.862228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2291235 episodes
GETTING ACTION FROM:
action 3, numVisits=2291105, meanQ=4.994910, numObservations: 3
action -1, numVisits=104, meanQ=4.240335, numObservations: 1
action 0, numVisits=23, meanQ=3.392524, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.501736 0.952386 0.620538 0.886317 0.592915 0.862228 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 380
Initial state: 0 0.363573 0.569322 0.682136 0.860103 0.620686 0.832013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2281035 episodes
GETTING ACTION FROM:
action 1, numVisits=2280926, meanQ=4.918542, numObservations: 3
action -1, numVisits=60, meanQ=3.934588, numObservations: 1
action 0, numVisits=47, meanQ=3.754966, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.363573 0.569322 0.682136 0.860103 0.620686 0.832013 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=347962, meanQ=8.316621, numObservations: 4
action 2, numVisits=15, meanQ=5.806000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2823289 episodes
GETTING ACTION FROM:
action 3, numVisits=3171241, meanQ=6.292142, numObservations: 4
action 2, numVisits=23, meanQ=4.308261, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.363573 0.569322 0.682136 0.860103 0.620686 0.832013 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 381
Initial state: 0 0.572043 0.887338 0.547083 0.871235 0.22526 0.732973 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262144 episodes
GETTING ACTION FROM:
action 3, numVisits=2262137, meanQ=4.926816, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.572043 0.887338 0.547083 0.871235 0.22526 0.732973 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 382
Initial state: 0 0.69572 0.861846 0.692628 0.85116 0.622569 0.801497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1552440 episodes
GETTING ACTION FROM:
action 0, numVisits=1552186, meanQ=2.952938, numObservations: 1
action -1, numVisits=248, meanQ=2.478921, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.69572 0.861846 0.692628 0.85116 0.622569 0.801497 w: 1
Observation: 0 0 0.903017 0 0.799025 0 0.851628 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1552131, meanQ=5.008453, numObservations: 4
action -1, numVisits=49, meanQ=3.900032, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2475948 episodes
GETTING ACTION FROM:
action 2, numVisits=4028078, meanQ=4.954161, numObservations: 4
action -1, numVisits=50, meanQ=3.844330, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.69572 0.861846 0.692628 0.85116 0.622569 0.801497 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 383
Initial state: 0 0.503309 0.819797 0.564563 0.842576 0.266797 0.0488945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2244100 episodes
GETTING ACTION FROM:
action 1, numVisits=2244069, meanQ=4.905152, numObservations: 5
action 3, numVisits=26, meanQ=3.076173, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.503309 0.819797 0.564563 0.842576 0.266797 0.0488945 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=164555, meanQ=4.603787, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
Sampled 2871945 episodes
GETTING ACTION FROM:
action 3, numVisits=3036500, meanQ=5.759992, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 0 0.503309 0.819797 0.564563 0.842576 0.266797 0.0488945 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=72385, meanQ=8.043218, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2881345 episodes
GETTING ACTION FROM:
action 1, numVisits=2953676, meanQ=6.184747, numObservations: 4
action 2, numVisits=54, meanQ=5.073889, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.503309 0.819797 0.564563 0.842576 0.266797 0.0488945 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 384
Initial state: 0 0.373389 0.531393 0.608328 0.842112 0.658336 0.823463 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2235865 episodes
GETTING ACTION FROM:
action 3, numVisits=2234556, meanQ=4.986760, numObservations: 5
action 1, numVisits=1177, meanQ=4.766759, numObservations: 4
action 2, numVisits=59, meanQ=3.977969, numObservations: 4
action -1, numVisits=51, meanQ=3.914846, numObservations: 1
action 0, numVisits=22, meanQ=3.348592, numObservations: 1
action: 3
Next state: 1 0.373389 0.531393 0.608328 0.842112 0.658336 0.823463 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 385
Initial state: 0 0.557172 0.866961 0.516826 0.892823 0.169634 0.672064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2250905 episodes
GETTING ACTION FROM:
action 1, numVisits=2250856, meanQ=4.984417, numObservations: 5
action 0, numVisits=45, meanQ=3.843503, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.557172 0.866961 0.516826 0.892823 0.169634 0.672064 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 386
Initial state: 0 0.562581 0.877925 0.389609 0.0844064 0.582191 0.841661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2279090 episodes
GETTING ACTION FROM:
action 3, numVisits=2278935, meanQ=4.970921, numObservations: 3
action -1, numVisits=147, meanQ=1.803311, numObservations: 1
action 2, numVisits=5, meanQ=-0.201980, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.562581 0.877925 0.389609 0.0844064 0.582191 0.841661 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 387
Initial state: 0 0.586309 0.836716 0.658874 0.833941 0.368369 0.121343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2241555 episodes
GETTING ACTION FROM:
action 1, numVisits=2241511, meanQ=4.932259, numObservations: 4
action -1, numVisits=40, meanQ=3.641001, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.586309 0.836716 0.658874 0.833941 0.368369 0.121343 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 388
Initial state: 0 0.65034 0.824663 0.633243 0.94708 0.568287 0.80096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2288614 episodes
GETTING ACTION FROM:
action 2, numVisits=2288606, meanQ=4.985445, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.65034 0.824663 0.633243 0.94708 0.568287 0.80096 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 389
Initial state: 0 0.629092 0.877156 0.564194 0.80035 0.912309 0.501583 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2256424 episodes
GETTING ACTION FROM:
action 2, numVisits=2256312, meanQ=4.991411, numObservations: 4
action 0, numVisits=79, meanQ=4.124673, numObservations: 2
action -1, numVisits=28, meanQ=3.493191, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.629092 0.877156 0.564194 0.80035 0.912309 0.501583 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 390
Initial state: 0 0.675541 0.896007 0.562263 0.828419 0.458906 0.268642 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246655 episodes
GETTING ACTION FROM:
action 3, numVisits=2246631, meanQ=4.971336, numObservations: 4
action 2, numVisits=19, meanQ=2.468953, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.675541 0.896007 0.562263 0.828419 0.458906 0.268642 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=343131, meanQ=8.299744, numObservations: 5
action 2, numVisits=7, meanQ=5.284300, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2804628 episodes
GETTING ACTION FROM:
action 1, numVisits=3147756, meanQ=6.454721, numObservations: 5
action 2, numVisits=8, meanQ=3.248762, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.675541 0.896007 0.562263 0.828419 0.458906 0.268642 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 391
Initial state: 0 0.662916 0.804962 0.191024 0.630018 0.605497 0.856169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259375 episodes
GETTING ACTION FROM:
action 1, numVisits=2258575, meanQ=4.926858, numObservations: 4
action 3, numVisits=612, meanQ=4.616509, numObservations: 5
action -1, numVisits=104, meanQ=4.180594, numObservations: 1
action 0, numVisits=83, meanQ=4.082784, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.662916 0.804962 0.191024 0.630018 0.605497 0.856169 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=164539, meanQ=4.673821, numObservations: 5
action 0, numVisits=61, meanQ=1.684604, numObservations: 1
action 2, numVisits=5, meanQ=-1.402000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2784645 episodes
GETTING ACTION FROM:
action 3, numVisits=2949184, meanQ=5.983625, numObservations: 5
action 0, numVisits=61, meanQ=1.684604, numObservations: 1
action 2, numVisits=5, meanQ=-1.402000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.662916 0.804962 0.191024 0.630018 0.605497 0.856169 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 392
Initial state: 0 0.552945 0.849856 0.650326 0.806909 0.549609 0.881733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2217616 episodes
GETTING ACTION FROM:
action 2, numVisits=2217582, meanQ=4.852211, numObservations: 5
action -1, numVisits=30, meanQ=3.352002, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.552945 0.849856 0.650326 0.806909 0.549609 0.881733 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 393
Initial state: 0 0.838691 0.206192 0.675166 0.861216 0.693781 0.876027 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1547898 episodes
GETTING ACTION FROM:
action 0, numVisits=1547884, meanQ=2.932786, numObservations: 1
action 3, numVisits=9, meanQ=0.331122, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.838691 0.206192 0.675166 0.861216 0.693781 0.876027 w: 1
Observation: 0 0 0.172323 0 0.856342 0 0.778461 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1547720, meanQ=4.979289, numObservations: 4
action 0, numVisits=157, meanQ=4.377972, numObservations: 1
action 1, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2468037 episodes
GETTING ACTION FROM:
action 2, numVisits=4015757, meanQ=5.030711, numObservations: 4
action 0, numVisits=157, meanQ=4.377972, numObservations: 1
action 1, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.838691 0.206192 0.675166 0.861216 0.693781 0.876027 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 394
Initial state: 0 0.16482 0.602419 0.637167 0.84305 0.657057 0.819578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2265194 episodes
GETTING ACTION FROM:
action 2, numVisits=2265047, meanQ=5.136532, numObservations: 4
action 3, numVisits=71, meanQ=4.117748, numObservations: 3
action -1, numVisits=37, meanQ=3.856859, numObservations: 1
action 1, numVisits=37, meanQ=3.751895, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.16482 0.602419 0.637167 0.84305 0.657057 0.819578 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 395
Initial state: 0 0.683631 0.851133 0.0450514 0.250129 0.513658 0.826054 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2217034 episodes
GETTING ACTION FROM:
action 3, numVisits=2216929, meanQ=4.905340, numObservations: 5
action 0, numVisits=62, meanQ=3.937818, numObservations: 1
action 1, numVisits=26, meanQ=3.376550, numObservations: 4
action 2, numVisits=15, meanQ=2.853333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.683631 0.851133 0.0450514 0.250129 0.513658 0.826054 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 396
Initial state: 0 0.515276 0.840464 0.670195 0.888211 0.393557 0.419095 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2256477 episodes
GETTING ACTION FROM:
action 1, numVisits=2256414, meanQ=4.894468, numObservations: 4
action -1, numVisits=59, meanQ=3.883449, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.515276 0.840464 0.670195 0.888211 0.393557 0.419095 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 397
Initial state: 0 0.518495 0.897986 0.200219 0.586172 0.603492 0.864513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2244499 episodes
GETTING ACTION FROM:
action 3, numVisits=2244493, meanQ=4.923804, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.518495 0.897986 0.200219 0.586172 0.603492 0.864513 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 398
Initial state: 0 0.668732 0.89669 0.886566 0.158269 0.54456 0.87077 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2231740 episodes
GETTING ACTION FROM:
action 3, numVisits=2231720, meanQ=4.995579, numObservations: 4
action 1, numVisits=12, meanQ=2.498342, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=4, meanQ=-2.005000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.668732 0.89669 0.886566 0.158269 0.54456 0.87077 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 399
Initial state: 0 0.658475 0.668163 0.506249 0.892484 0.563687 0.85335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2240787 episodes
GETTING ACTION FROM:
action 2, numVisits=2240772, meanQ=4.930719, numObservations: 5
action 1, numVisits=9, meanQ=1.886667, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.658475 0.668163 0.506249 0.892484 0.563687 0.85335 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=163541, meanQ=4.707899, numObservations: 5
action 0, numVisits=91, meanQ=3.913912, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 2796423 episodes
GETTING ACTION FROM:
action 3, numVisits=2959964, meanQ=5.736286, numObservations: 5
action 0, numVisits=91, meanQ=3.913912, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.658475 0.668163 0.506249 0.892484 0.563687 0.85335 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 400
Initial state: 0 0.583633 0.85051 0.425185 0.747036 0.640754 0.876673 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2241778 episodes
GETTING ACTION FROM:
action 3, numVisits=2241720, meanQ=4.992786, numObservations: 5
action 1, numVisits=45, meanQ=3.839782, numObservations: 4
action 2, numVisits=9, meanQ=1.886667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.583633 0.85051 0.425185 0.747036 0.640754 0.876673 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 401
Initial state: 0 0.59315 0.811959 0.180821 0.420905 0.598912 0.842182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2241299 episodes
GETTING ACTION FROM:
action 3, numVisits=2241191, meanQ=4.976380, numObservations: 5
action 1, numVisits=83, meanQ=3.546388, numObservations: 4
action -1, numVisits=22, meanQ=3.338046, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.59315 0.811959 0.180821 0.420905 0.598912 0.842182 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 402
Initial state: 0 0.582877 0.83505 0.50296 0.830769 0.798854 0.138096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2210465 episodes
GETTING ACTION FROM:
action 3, numVisits=2210348, meanQ=4.907525, numObservations: 4
action -1, numVisits=76, meanQ=3.985297, numObservations: 1
action 2, numVisits=36, meanQ=3.098064, numObservations: 4
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.582877 0.83505 0.50296 0.830769 0.798854 0.138096 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 403
Initial state: 0 0.571135 0.945069 0.604856 0.844945 0.688082 0.865685 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262450 episodes
GETTING ACTION FROM:
action 3, numVisits=2262444, meanQ=4.995827, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.571135 0.945069 0.604856 0.844945 0.688082 0.865685 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 404
Initial state: 0 0.176205 0.673357 0.631087 0.804384 0.629534 0.848077 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2302064 episodes
GETTING ACTION FROM:
action 2, numVisits=2301237, meanQ=4.987950, numObservations: 3
action 3, numVisits=775, meanQ=4.715987, numObservations: 4
action -1, numVisits=32, meanQ=3.608783, numObservations: 1
action 1, numVisits=18, meanQ=2.549456, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.176205 0.673357 0.631087 0.804384 0.629534 0.848077 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=20624, meanQ=4.351136, numObservations: 3
action -1, numVisits=33, meanQ=3.261389, numObservations: 1
action 3, numVisits=25, meanQ=2.603200, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2848558 episodes
GETTING ACTION FROM:
action 1, numVisits=2869182, meanQ=5.617044, numObservations: 3
action -1, numVisits=33, meanQ=3.261389, numObservations: 1
action 3, numVisits=25, meanQ=2.603200, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.176205 0.673357 0.631087 0.804384 0.629534 0.848077 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=58603, meanQ=8.016109, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2881685 episodes
GETTING ACTION FROM:
action 2, numVisits=2940286, meanQ=5.954963, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.176205 0.673357 0.631087 0.804384 0.629534 0.848077 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1279, meanQ=7.626713, numObservations: 3
action 3, numVisits=9, meanQ=5.443333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2888715 episodes
GETTING ACTION FROM:
action 3, numVisits=2882054, meanQ=6.295205, numObservations: 4
action 2, numVisits=7947, meanQ=5.679461, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.176205 0.673357 0.631087 0.804384 0.629534 0.848077 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 405
Initial state: 0 0.642206 0.895827 0.437672 0.636351 0.640529 0.807268 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268256 episodes
GETTING ACTION FROM:
action 1, numVisits=2268233, meanQ=5.115550, numObservations: 4
action 2, numVisits=15, meanQ=1.532667, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.642206 0.895827 0.437672 0.636351 0.640529 0.807268 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 406
Initial state: 0 0.580155 0.833689 0.485263 0.41898 0.696452 0.829762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253487 episodes
GETTING ACTION FROM:
action 3, numVisits=2253480, meanQ=4.992215, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.580155 0.833689 0.485263 0.41898 0.696452 0.829762 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 407
Initial state: 0 0.547831 0.860278 0.571109 0.804546 0.135575 0.970991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2265520 episodes
GETTING ACTION FROM:
action 3, numVisits=2265109, meanQ=4.899273, numObservations: 3
action 1, numVisits=327, meanQ=4.436828, numObservations: 3
action 0, numVisits=42, meanQ=3.716686, numObservations: 1
action -1, numVisits=33, meanQ=3.540289, numObservations: 1
action 2, numVisits=9, meanQ=1.886667, numObservations: 3
action: 3
Next state: 1 0.547831 0.860278 0.571109 0.804546 0.135575 0.970991 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 408
Initial state: 0 0.626123 0.86962 0.260254 0.376233 0.606403 0.857062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2213788 episodes
GETTING ACTION FROM:
action 3, numVisits=2213707, meanQ=4.914434, numObservations: 5
action 0, numVisits=40, meanQ=3.700961, numObservations: 1
action -1, numVisits=38, meanQ=3.660963, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.626123 0.86962 0.260254 0.376233 0.606403 0.857062 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 409
Initial state: 0 0.220404 0.673524 0.600762 0.809814 0.670842 0.84148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2229843 episodes
GETTING ACTION FROM:
action 3, numVisits=2229761, meanQ=4.906558, numObservations: 5
action 0, numVisits=78, meanQ=4.039838, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.220404 0.673524 0.600762 0.809814 0.670842 0.84148 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 410
Initial state: 0 0.682997 0.870348 0.539485 0.554298 0.594355 0.800313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2256465 episodes
GETTING ACTION FROM:
action 1, numVisits=2256439, meanQ=4.991631, numObservations: 4
action 0, numVisits=18, meanQ=3.162150, numObservations: 1
action 3, numVisits=5, meanQ=0.602040, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.682997 0.870348 0.539485 0.554298 0.594355 0.800313 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 411
Initial state: 0 0.627727 0.860278 0.938351 0.309745 0.584879 0.813567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263134 episodes
GETTING ACTION FROM:
action 1, numVisits=2263084, meanQ=4.914912, numObservations: 4
action 0, numVisits=46, meanQ=3.790755, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.627727 0.860278 0.938351 0.309745 0.584879 0.813567 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 412
Initial state: 0 0.502196 0.836117 0.636548 0.800763 0.999523 0.68479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2255114 episodes
GETTING ACTION FROM:
action 1, numVisits=2255050, meanQ=5.010847, numObservations: 5
action 2, numVisits=59, meanQ=3.734408, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.502196 0.836117 0.636548 0.800763 0.999523 0.68479 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 413
Initial state: 0 0.632803 0.896134 0.902149 0.212423 0.5505 0.864919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2224255 episodes
GETTING ACTION FROM:
action 3, numVisits=2224105, meanQ=4.924078, numObservations: 5
action 1, numVisits=110, meanQ=4.186818, numObservations: 4
action 0, numVisits=37, meanQ=3.558466, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.632803 0.896134 0.902149 0.212423 0.5505 0.864919 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 414
Initial state: 0 0.527778 0.868824 0.596038 0.891204 0.0878762 0.965557 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1535286 episodes
GETTING ACTION FROM:
action 0, numVisits=1535271, meanQ=2.941053, numObservations: 1
action 1, numVisits=7, meanQ=-0.145714, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=3, meanQ=-4.333333, numObservations: 3
action: 0
Next state: 0 0.527778 0.868824 0.596038 0.891204 0.0878762 0.965557 w: 1
Observation: 0 0 0.815337 0 0.872441 0 0.957203 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1535262, meanQ=4.997997, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 2418477 episodes
GETTING ACTION FROM:
action 2, numVisits=3953739, meanQ=4.862301, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.527778 0.868824 0.596038 0.891204 0.0878762 0.965557 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 415
Initial state: 0 0.682428 0.426839 0.561267 0.802936 0.502112 0.842989 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2211538 episodes
GETTING ACTION FROM:
action 2, numVisits=2211530, meanQ=4.888857, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.682428 0.426839 0.561267 0.802936 0.502112 0.842989 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=233985, meanQ=8.393203, numObservations: 3
action 1, numVisits=46984, meanQ=8.381607, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2838785 episodes
GETTING ACTION FROM:
action 3, numVisits=2847331, meanQ=6.248560, numObservations: 3
action 1, numVisits=272420, meanQ=6.238286, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.682428 0.426839 0.561267 0.802936 0.502112 0.842989 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 416
Initial state: 0 0.634135 0.838114 0.186396 0.70275 0.572121 0.875359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1667179 episodes
GETTING ACTION FROM:
action 0, numVisits=1433054, meanQ=5.908528, numObservations: 3
action 3, numVisits=234120, meanQ=4.890440, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.634135 0.838114 0.186396 0.70275 0.572121 0.875359 w: 1
Observation: 0 0 0.871579 0 0.791762 0 0.969707 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=458529, meanQ=8.074041, numObservations: 4
action 3, numVisits=7, meanQ=5.284300, numObservations: 1
action 2, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2473984 episodes
GETTING ACTION FROM:
action 1, numVisits=2932431, meanQ=5.604729, numObservations: 4
action 3, numVisits=63, meanQ=4.507624, numObservations: 4
action 2, numVisits=29, meanQ=3.551383, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.634135 0.838114 0.186396 0.70275 0.572121 0.875359 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 417
Initial state: 0 0.583114 0.881283 0.989586 0.733074 0.656832 0.803463 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2221650 episodes
GETTING ACTION FROM:
action 3, numVisits=2221549, meanQ=4.900154, numObservations: 5
action 0, numVisits=62, meanQ=3.913751, numObservations: 1
action -1, numVisits=29, meanQ=3.465885, numObservations: 1
action 2, numVisits=7, meanQ=0.711443, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 3
Next state: 1 0.583114 0.881283 0.989586 0.733074 0.656832 0.803463 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 418
Initial state: 0 0.135707 0.891355 0.691905 0.886482 0.566395 0.82791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2226267 episodes
GETTING ACTION FROM:
action 3, numVisits=2226261, meanQ=4.913668, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.135707 0.891355 0.691905 0.886482 0.566395 0.82791 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 419
Initial state: 0 0.736787 0.889933 0.525113 0.897959 0.622247 0.852341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247199 episodes
GETTING ACTION FROM:
action 1, numVisits=2247180, meanQ=4.912884, numObservations: 5
action 2, numVisits=9, meanQ=2.332244, numObservations: 3
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.736787 0.889933 0.525113 0.897959 0.622247 0.852341 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 420
Initial state: 0 0.675463 0.881143 0.967189 0.118509 0.608955 0.897807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263305 episodes
GETTING ACTION FROM:
action 3, numVisits=2263222, meanQ=4.935334, numObservations: 4
action -1, numVisits=54, meanQ=3.898466, numObservations: 1
action 2, numVisits=23, meanQ=3.252174, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.675463 0.881143 0.967189 0.118509 0.608955 0.897807 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=57168, meanQ=7.909719, numObservations: 4
action 1, numVisits=6, meanQ=4.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2812991 episodes
GETTING ACTION FROM:
action 2, numVisits=2870152, meanQ=5.961177, numObservations: 4
action 1, numVisits=11, meanQ=3.180000, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.675463 0.881143 0.967189 0.118509 0.608955 0.897807 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 421
Initial state: 0 0.969794 0.123625 0.570713 0.839908 0.678275 0.863804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264675 episodes
GETTING ACTION FROM:
action 3, numVisits=2264602, meanQ=4.925850, numObservations: 4
action -1, numVisits=62, meanQ=3.946941, numObservations: 1
action 1, numVisits=8, meanQ=1.500000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.969794 0.123625 0.570713 0.839908 0.678275 0.863804 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 422
Initial state: 0 0.52856 0.812118 0.541797 0.835168 0.130515 0.896746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2236055 episodes
GETTING ACTION FROM:
action 2, numVisits=2235967, meanQ=4.991159, numObservations: 5
action 0, numVisits=38, meanQ=3.717991, numObservations: 1
action -1, numVisits=27, meanQ=3.482680, numObservations: 1
action 1, numVisits=22, meanQ=3.089550, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.52856 0.812118 0.541797 0.835168 0.130515 0.896746 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 423
Initial state: 0 0.614131 0.875342 0.626626 0.853477 0.395013 0.799397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2234503 episodes
GETTING ACTION FROM:
action 1, numVisits=2234490, meanQ=4.981357, numObservations: 5
action 2, numVisits=8, meanQ=1.500000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.614131 0.875342 0.626626 0.853477 0.395013 0.799397 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 424
Initial state: 0 0.873526 0.284547 0.513336 0.852414 0.616808 0.843036 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268006 episodes
GETTING ACTION FROM:
action 1, numVisits=2268000, meanQ=4.974930, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.873526 0.284547 0.513336 0.852414 0.616808 0.843036 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=165285, meanQ=5.581941, numObservations: 3
action 0, numVisits=62, meanQ=4.703151, numObservations: 1
action -1, numVisits=15, meanQ=3.772957, numObservations: 1
action 3, numVisits=13, meanQ=3.151538, numObservations: 3
action 2, numVisits=12, meanQ=2.333342, numObservations: 3
Sampled 2800003 episodes
GETTING ACTION FROM:
action 3, numVisits=2601872, meanQ=5.800264, numObservations: 4
action 1, numVisits=363420, meanQ=5.124493, numObservations: 3
action 0, numVisits=69, meanQ=4.189534, numObservations: 1
action -1, numVisits=17, meanQ=3.093785, numObservations: 1
action 2, numVisits=12, meanQ=2.333342, numObservations: 3
action: 3
Next state: 1 0.873526 0.284547 0.513336 0.852414 0.616808 0.843036 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 425
Initial state: 0 0.507459 0.854376 0.749736 0.242846 0.522551 0.837096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2215479 episodes
GETTING ACTION FROM:
action 1, numVisits=2175357, meanQ=4.914109, numObservations: 5
action -1, numVisits=30378, meanQ=2.862274, numObservations: 1
action 0, numVisits=9714, meanQ=2.831605, numObservations: 1
action 3, numVisits=28, meanQ=1.500375, numObservations: 3
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 1
Next state: 1 0.507459 0.854376 0.749736 0.242846 0.522551 0.837096 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 426
Initial state: 0 0.061265 0.495141 0.60177 0.816446 0.665091 0.801278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1535660 episodes
GETTING ACTION FROM:
action -1, numVisits=1535647, meanQ=2.826670, numObservations: 1
action 3, numVisits=8, meanQ=-0.002475, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.061265 0.495141 0.60177 0.816446 0.665091 0.801278 w: 1
Observation: 0 0.073068 0 0.541311 0 0.675367 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1535334, meanQ=4.909722, numObservations: 5
action 1, numVisits=257, meanQ=4.364899, numObservations: 4
action 0, numVisits=34, meanQ=3.542615, numObservations: 1
action 3, numVisits=19, meanQ=2.889479, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2412594 episodes
GETTING ACTION FROM:
action 2, numVisits=3947928, meanQ=4.882819, numObservations: 5
action 1, numVisits=257, meanQ=4.364899, numObservations: 4
action 0, numVisits=34, meanQ=3.542615, numObservations: 1
action 3, numVisits=19, meanQ=2.889479, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.061265 0.495141 0.60177 0.816446 0.665091 0.801278 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 427
Initial state: 0 0.00934438 0.114739 0.638167 0.870209 0.563797 0.894645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2233517 episodes
GETTING ACTION FROM:
action 3, numVisits=2233472, meanQ=4.876310, numObservations: 4
action -1, numVisits=41, meanQ=1.320947, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.00934438 0.114739 0.638167 0.870209 0.563797 0.894645 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 428
Initial state: 0 0.049674 0.479977 0.663893 0.845522 0.68952 0.843508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239797 episodes
GETTING ACTION FROM:
action 3, numVisits=2239790, meanQ=4.995671, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.049674 0.479977 0.663893 0.845522 0.68952 0.843508 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 429
Initial state: 0 0.534055 0.348547 0.672255 0.871586 0.529598 0.811601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2192431 episodes
GETTING ACTION FROM:
action 1, numVisits=2192404, meanQ=4.855438, numObservations: 4
action 2, numVisits=22, meanQ=1.991373, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.534055 0.348547 0.672255 0.871586 0.529598 0.811601 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 430
Initial state: 0 0.0315073 0.183987 0.532209 0.883402 0.575618 0.889103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2270766 episodes
GETTING ACTION FROM:
action 1, numVisits=2270734, meanQ=4.987749, numObservations: 4
action 0, numVisits=25, meanQ=3.445836, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0315073 0.183987 0.532209 0.883402 0.575618 0.889103 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=288008, meanQ=8.391699, numObservations: 3
action 3, numVisits=364, meanQ=8.020718, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2875099 episodes
GETTING ACTION FROM:
action 2, numVisits=3161312, meanQ=6.140505, numObservations: 3
action 3, numVisits=2157, meanQ=5.976823, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0315073 0.183987 0.532209 0.883402 0.575618 0.889103 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 431
Initial state: 0 0.522893 0.538602 0.698064 0.827399 0.608393 0.845793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2285668 episodes
GETTING ACTION FROM:
action 2, numVisits=2285578, meanQ=4.963844, numObservations: 3
action -1, numVisits=72, meanQ=3.952843, numObservations: 1
action 1, numVisits=15, meanQ=2.320673, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.522893 0.538602 0.698064 0.827399 0.608393 0.845793 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 432
Initial state: 0 0.513952 0.812809 0.2163 0.368871 0.518582 0.824236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2221053 episodes
GETTING ACTION FROM:
action 2, numVisits=2221046, meanQ=4.960637, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.513952 0.812809 0.2163 0.368871 0.518582 0.824236 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=282162, meanQ=8.376462, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2799012 episodes
GETTING ACTION FROM:
action 1, numVisits=3081171, meanQ=6.252360, numObservations: 5
action 3, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.513952 0.812809 0.2163 0.368871 0.518582 0.824236 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 433
Initial state: 0 0.652554 0.826834 0.0432409 0.968404 0.628421 0.838333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253108 episodes
GETTING ACTION FROM:
action 3, numVisits=2252996, meanQ=4.983703, numObservations: 4
action 0, numVisits=56, meanQ=3.950152, numObservations: 1
action -1, numVisits=27, meanQ=3.450982, numObservations: 1
action 2, numVisits=22, meanQ=2.999100, numObservations: 4
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action: 3
Next state: 1 0.652554 0.826834 0.0432409 0.968404 0.628421 0.838333 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 434
Initial state: 0 0.643364 0.80113 0.863096 0.10623 0.625624 0.851815 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2234107 episodes
GETTING ACTION FROM:
action 1, numVisits=2231939, meanQ=4.867099, numObservations: 4
action -1, numVisits=1530, meanQ=3.288911, numObservations: 1
action 0, numVisits=619, meanQ=3.207455, numObservations: 1
action 2, numVisits=15, meanQ=1.264667, numObservations: 4
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action: 1
Next state: 1 0.643364 0.80113 0.863096 0.10623 0.625624 0.851815 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 435
Initial state: 0 0.604515 0.807674 0.487854 0.372472 0.601935 0.80404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263224 episodes
GETTING ACTION FROM:
action 1, numVisits=2260627, meanQ=4.914755, numObservations: 4
action -1, numVisits=2593, meanQ=2.487834, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.604515 0.807674 0.487854 0.372472 0.601935 0.80404 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 436
Initial state: 0 0.671222 0.892425 0.87929 0.978042 0.608871 0.86492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271593 episodes
GETTING ACTION FROM:
action 2, numVisits=2271423, meanQ=4.970059, numObservations: 4
action 0, numVisits=121, meanQ=4.271210, numObservations: 1
action -1, numVisits=47, meanQ=3.847899, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.671222 0.892425 0.87929 0.978042 0.608871 0.86492 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 437
Initial state: 0 0.601843 0.861797 0.557146 0.844319 0.960379 0.231024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1552644 episodes
GETTING ACTION FROM:
action -1, numVisits=1552623, meanQ=2.965958, numObservations: 1
action 1, numVisits=14, meanQ=0.715729, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.601843 0.861797 0.557146 0.844319 0.960379 0.231024 w: 1
Observation: 0 0.544911 0 0.538406 0 0.932417 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1552563, meanQ=5.008461, numObservations: 4
action 0, numVisits=30, meanQ=3.585208, numObservations: 1
action 1, numVisits=21, meanQ=2.808100, numObservations: 5
action 3, numVisits=6, meanQ=1.001683, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 2464142 episodes
GETTING ACTION FROM:
action 2, numVisits=4016705, meanQ=5.009454, numObservations: 4
action 0, numVisits=30, meanQ=3.585208, numObservations: 1
action 1, numVisits=21, meanQ=2.808100, numObservations: 5
action 3, numVisits=6, meanQ=1.001683, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.601843 0.861797 0.557146 0.844319 0.960379 0.231024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 438
Initial state: 0 0.633631 0.871046 0.629965 0.836617 0.273284 0.568047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2233319 episodes
GETTING ACTION FROM:
action 3, numVisits=2229885, meanQ=4.897255, numObservations: 5
action -1, numVisits=3430, meanQ=2.599246, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.633631 0.871046 0.629965 0.836617 0.273284 0.568047 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=55735, meanQ=7.952558, numObservations: 4
action 1, numVisits=110, meanQ=7.336275, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2829354 episodes
GETTING ACTION FROM:
action 1, numVisits=2539321, meanQ=6.093427, numObservations: 4
action 2, numVisits=345876, meanQ=6.081745, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.633631 0.871046 0.629965 0.836617 0.273284 0.568047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 439
Initial state: 0 0.533212 0.843754 0.54286 0.887826 0.0955892 0.354044 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262492 episodes
GETTING ACTION FROM:
action 3, numVisits=2262385, meanQ=4.980632, numObservations: 4
action 0, numVisits=94, meanQ=4.194095, numObservations: 1
action 1, numVisits=10, meanQ=1.198010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.533212 0.843754 0.54286 0.887826 0.0955892 0.354044 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=221115, meanQ=8.542795, numObservations: 3
action 2, numVisits=7, meanQ=5.284300, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2841856 episodes
GETTING ACTION FROM:
action 1, numVisits=3062902, meanQ=6.009029, numObservations: 3
action 2, numVisits=74, meanQ=5.080677, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.533212 0.843754 0.54286 0.887826 0.0955892 0.354044 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 440
Initial state: 0 0.59861 0.837071 0.604615 0.0255189 0.644127 0.862948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246867 episodes
GETTING ACTION FROM:
action 3, numVisits=2246778, meanQ=5.016927, numObservations: 5
action 0, numVisits=56, meanQ=3.991919, numObservations: 1
action 1, numVisits=21, meanQ=2.904776, numObservations: 4
action -1, numVisits=10, meanQ=2.488000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 0 0.59861 0.837071 0.604615 0.0255189 0.644127 0.862948 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=142112, meanQ=5.664346, numObservations: 3
action 2, numVisits=31, meanQ=4.090645, numObservations: 4
action -1, numVisits=17, meanQ=3.883784, numObservations: 1
action 0, numVisits=10, meanQ=3.465295, numObservations: 1
action 1, numVisits=16, meanQ=3.237500, numObservations: 3
Sampled 2653617 episodes
GETTING ACTION FROM:
action 1, numVisits=416070, meanQ=5.863975, numObservations: 5
action 3, numVisits=2379615, meanQ=4.910404, numObservations: 4
action 2, numVisits=86, meanQ=3.926977, numObservations: 5
action -1, numVisits=20, meanQ=3.001216, numObservations: 1
action 0, numVisits=12, meanQ=2.554412, numObservations: 1
action: 1
Next state: 1 0.59861 0.837071 0.604615 0.0255189 0.644127 0.862948 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 441
Initial state: 0 0.300513 0.00392917 0.590617 0.806353 0.503877 0.896906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2277115 episodes
GETTING ACTION FROM:
action 2, numVisits=2277050, meanQ=4.988671, numObservations: 4
action -1, numVisits=61, meanQ=4.011093, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.300513 0.00392917 0.590617 0.806353 0.503877 0.896906 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 442
Initial state: 0 0.658803 0.436962 0.633538 0.801995 0.64634 0.84316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2190311 episodes
GETTING ACTION FROM:
action 2, numVisits=2190305, meanQ=4.876712, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.658803 0.436962 0.633538 0.801995 0.64634 0.84316 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 443
Initial state: 0 0.507807 0.845287 0.69823 0.882792 0.764082 0.879045 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253676 episodes
GETTING ACTION FROM:
action 3, numVisits=2253669, meanQ=4.939637, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.507807 0.845287 0.69823 0.882792 0.764082 0.879045 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 444
Initial state: 0 0.643857 0.864957 0.669079 0.87176 0.576025 0.655227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268947 episodes
GETTING ACTION FROM:
action 2, numVisits=2268865, meanQ=4.994589, numObservations: 4
action 0, numVisits=73, meanQ=4.092574, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.643857 0.864957 0.669079 0.87176 0.576025 0.655227 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 445
Initial state: 0 0.561553 0.844468 0.538172 0.226313 0.562731 0.825326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2265147 episodes
GETTING ACTION FROM:
action 2, numVisits=2265140, meanQ=4.917731, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.561553 0.844468 0.538172 0.226313 0.562731 0.825326 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 446
Initial state: 0 0.684989 0.893712 0.132927 0.687626 0.624925 0.851045 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2191936 episodes
GETTING ACTION FROM:
action 1, numVisits=2191744, meanQ=4.841648, numObservations: 4
action -1, numVisits=117, meanQ=4.134275, numObservations: 1
action 0, numVisits=73, meanQ=3.926201, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.684989 0.893712 0.132927 0.687626 0.624925 0.851045 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 447
Initial state: 0 0.574933 0.837499 0.553282 0.831796 0.275653 0.699984 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261866 episodes
GETTING ACTION FROM:
action 3, numVisits=2261753, meanQ=4.994710, numObservations: 4
action -1, numVisits=72, meanQ=4.076741, numObservations: 1
action 0, numVisits=25, meanQ=3.389225, numObservations: 1
action 1, numVisits=15, meanQ=2.580667, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.574933 0.837499 0.553282 0.831796 0.275653 0.699984 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=215952, meanQ=8.318774, numObservations: 4
action 1, numVisits=128791, meanQ=8.315032, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2783590 episodes
GETTING ACTION FROM:
action 1, numVisits=2214188, meanQ=6.264865, numObservations: 5
action 2, numVisits=914143, meanQ=6.261826, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.574933 0.837499 0.553282 0.831796 0.275653 0.699984 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 448
Initial state: 0 0.56216 0.84302 0.573552 0.892399 0.20468 0.930386 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2224235 episodes
GETTING ACTION FROM:
action 1, numVisits=2224082, meanQ=4.887230, numObservations: 5
action -1, numVisits=134, meanQ=4.202112, numObservations: 1
action 0, numVisits=17, meanQ=2.925312, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.56216 0.84302 0.573552 0.892399 0.20468 0.930386 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=108548, meanQ=4.536178, numObservations: 4
action 0, numVisits=54291, meanQ=3.641182, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2768595 episodes
GETTING ACTION FROM:
action 3, numVisits=2877143, meanQ=5.909245, numObservations: 4
action 0, numVisits=54291, meanQ=3.641182, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.56216 0.84302 0.573552 0.892399 0.20468 0.930386 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 449
Initial state: 0 0.688978 0.87086 0.796742 0.489899 0.529066 0.820569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2161534 episodes
GETTING ACTION FROM:
action 1, numVisits=2161070, meanQ=4.760282, numObservations: 5
action 0, numVisits=372, meanQ=4.367542, numObservations: 1
action -1, numVisits=77, meanQ=3.880154, numObservations: 1
action 2, numVisits=14, meanQ=2.414286, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.688978 0.87086 0.796742 0.489899 0.529066 0.820569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 450
Initial state: 0 0.641471 0.897955 0.883302 0.3282 0.546892 0.809726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2219095 episodes
GETTING ACTION FROM:
action 2, numVisits=2218953, meanQ=4.953640, numObservations: 5
action 0, numVisits=97, meanQ=4.177627, numObservations: 1
action -1, numVisits=40, meanQ=3.728893, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.641471 0.897955 0.883302 0.3282 0.546892 0.809726 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 451
Initial state: 0 0.461586 0.171118 0.579131 0.818734 0.657987 0.865206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2273046 episodes
GETTING ACTION FROM:
action 1, numVisits=2272998, meanQ=4.931044, numObservations: 4
action -1, numVisits=30, meanQ=3.487256, numObservations: 1
action 2, numVisits=14, meanQ=2.414286, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.461586 0.171118 0.579131 0.818734 0.657987 0.865206 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=280718, meanQ=8.375606, numObservations: 3
action 2, numVisits=7528, meanQ=8.285230, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2859236 episodes
GETTING ACTION FROM:
action 3, numVisits=3108003, meanQ=6.280788, numObservations: 3
action 2, numVisits=39477, meanQ=6.246180, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.461586 0.171118 0.579131 0.818734 0.657987 0.865206 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 452
Initial state: 0 0.585466 0.877889 0.609135 0.817276 0.00837468 0.561634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2257798 episodes
GETTING ACTION FROM:
action 1, numVisits=2239460, meanQ=5.125666, numObservations: 4
action 0, numVisits=18298, meanQ=3.210003, numObservations: 1
action 2, numVisits=37, meanQ=2.183519, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.585466 0.877889 0.609135 0.817276 0.00837468 0.561634 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 453
Initial state: 0 0.53657 0.892023 0.889116 0.332357 0.60401 0.86273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2207845 episodes
GETTING ACTION FROM:
action 1, numVisits=2207790, meanQ=4.985627, numObservations: 4
action 2, numVisits=49, meanQ=2.784700, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.53657 0.892023 0.889116 0.332357 0.60401 0.86273 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 454
Initial state: 0 0.608177 0.847125 0.580933 0.068757 0.526027 0.801523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2227815 episodes
GETTING ACTION FROM:
action 3, numVisits=2227796, meanQ=4.954897, numObservations: 5
action 1, numVisits=14, meanQ=2.711429, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.608177 0.847125 0.580933 0.068757 0.526027 0.801523 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 455
Initial state: 0 0.349213 0.355347 0.665724 0.897844 0.53192 0.823957 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2238220 episodes
GETTING ACTION FROM:
action 3, numVisits=2237919, meanQ=4.975851, numObservations: 4
action 2, numVisits=296, meanQ=4.531633, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.349213 0.355347 0.665724 0.897844 0.53192 0.823957 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 456
Initial state: 0 0.57328 0.847629 0.126136 0.309414 0.609529 0.822876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268159 episodes
GETTING ACTION FROM:
action 2, numVisits=2268114, meanQ=4.919152, numObservations: 4
action 3, numVisits=40, meanQ=3.624502, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.57328 0.847629 0.126136 0.309414 0.609529 0.822876 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=346036, meanQ=8.320988, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2866168 episodes
GETTING ACTION FROM:
action 1, numVisits=3212202, meanQ=6.525824, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.57328 0.847629 0.126136 0.309414 0.609529 0.822876 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 457
Initial state: 0 0.611899 0.830978 0.303769 0.28291 0.60773 0.869127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2243008 episodes
GETTING ACTION FROM:
action 1, numVisits=2242987, meanQ=4.964015, numObservations: 5
action 3, numVisits=15, meanQ=2.593340, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.611899 0.830978 0.303769 0.28291 0.60773 0.869127 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 458
Initial state: 0 0.619315 0.882566 0.666808 0.875407 0.113588 0.18028 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2224484 episodes
GETTING ACTION FROM:
action 2, numVisits=2224441, meanQ=4.901818, numObservations: 5
action 0, numVisits=39, meanQ=3.642777, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.619315 0.882566 0.666808 0.875407 0.113588 0.18028 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 459
Initial state: 0 0.554304 0.948835 0.564422 0.856033 0.635856 0.829906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2249879 episodes
GETTING ACTION FROM:
action 3, numVisits=2249849, meanQ=4.987750, numObservations: 4
action 2, numVisits=16, meanQ=3.006250, numObservations: 3
action -1, numVisits=11, meanQ=2.136705, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.554304 0.948835 0.564422 0.856033 0.635856 0.829906 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 460
Initial state: 0 0.584752 0.857772 0.594647 0.848591 0.739685 0.961527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2195281 episodes
GETTING ACTION FROM:
action 3, numVisits=2195267, meanQ=4.864689, numObservations: 5
action 1, numVisits=6, meanQ=1.001683, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.584752 0.857772 0.594647 0.848591 0.739685 0.961527 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 461
Initial state: 0 0.304986 0.264944 0.553313 0.860571 0.584932 0.883563 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2286993 episodes
GETTING ACTION FROM:
action 1, numVisits=2286987, meanQ=4.908565, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.304986 0.264944 0.553313 0.860571 0.584932 0.883563 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=282343, meanQ=8.317885, numObservations: 3
action 2, numVisits=66013, meanQ=8.302092, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2849597 episodes
GETTING ACTION FROM:
action 3, numVisits=2584539, meanQ=6.122674, numObservations: 3
action 2, numVisits=613411, meanQ=6.117785, numObservations: 5
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.304986 0.264944 0.553313 0.860571 0.584932 0.883563 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=61570, meanQ=7.619660, numObservations: 3
action 3, numVisits=87, meanQ=6.808347, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2945597 episodes
GETTING ACTION FROM:
action 2, numVisits=3006977, meanQ=5.920052, numObservations: 3
action 3, numVisits=275, meanQ=5.440786, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.304986 0.264944 0.553313 0.860571 0.584932 0.883563 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 462
Initial state: 0 0.176891 0.211481 0.527067 0.844625 0.581132 0.830008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2228501 episodes
GETTING ACTION FROM:
action 2, numVisits=2228494, meanQ=4.990349, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.176891 0.211481 0.527067 0.844625 0.581132 0.830008 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 463
Initial state: 0 0.62775 0.817078 0.513542 0.894282 0.935677 0.143604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2223921 episodes
GETTING ACTION FROM:
action 3, numVisits=2223695, meanQ=5.083505, numObservations: 4
action 1, numVisits=198, meanQ=4.108629, numObservations: 5
action 2, numVisits=24, meanQ=3.332083, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.62775 0.817078 0.513542 0.894282 0.935677 0.143604 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 464
Initial state: 0 0.0894012 0.145618 0.649715 0.804945 0.615368 0.891517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2243526 episodes
GETTING ACTION FROM:
action 3, numVisits=2243518, meanQ=4.928885, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0894012 0.145618 0.649715 0.804945 0.615368 0.891517 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 465
Initial state: 0 0.685182 0.808979 0.580904 0.809532 0.579972 0.943711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258822 episodes
GETTING ACTION FROM:
action 3, numVisits=2258804, meanQ=4.903259, numObservations: 4
action 0, numVisits=14, meanQ=2.684150, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.685182 0.808979 0.580904 0.809532 0.579972 0.943711 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 466
Initial state: 0 0.632847 0.823137 0.846629 0.616029 0.593892 0.862492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2308968 episodes
GETTING ACTION FROM:
action 2, numVisits=2308937, meanQ=4.986114, numObservations: 3
action -1, numVisits=26, meanQ=3.448762, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.632847 0.823137 0.846629 0.616029 0.593892 0.862492 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 467
Initial state: 0 0.601588 0.88965 0.659597 0.895714 0.650312 0.802086 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2242636 episodes
GETTING ACTION FROM:
action 1, numVisits=2242591, meanQ=4.916316, numObservations: 5
action 3, numVisits=40, meanQ=3.686507, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.601588 0.88965 0.659597 0.895714 0.650312 0.802086 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 468
Initial state: 0 0.125214 0.325727 0.587 0.812268 0.535898 0.899756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2223791 episodes
GETTING ACTION FROM:
action 2, numVisits=2223776, meanQ=4.993775, numObservations: 5
action 1, numVisits=10, meanQ=1.799000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.125214 0.325727 0.587 0.812268 0.535898 0.899756 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 469
Initial state: 0 0.18627 0.389966 0.568712 0.894819 0.567898 0.804181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2251942 episodes
GETTING ACTION FROM:
action 1, numVisits=2251880, meanQ=4.985532, numObservations: 5
action -1, numVisits=55, meanQ=3.931062, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.18627 0.389966 0.568712 0.894819 0.567898 0.804181 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=220988, meanQ=8.548155, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2892440 episodes
GETTING ACTION FROM:
action 2, numVisits=3113388, meanQ=5.964859, numObservations: 3
action 3, numVisits=40, meanQ=4.399500, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.18627 0.389966 0.568712 0.894819 0.567898 0.804181 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 470
Initial state: 0 0.687 0.835101 0.391158 0.511827 0.577992 0.894503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264581 episodes
GETTING ACTION FROM:
action 1, numVisits=2264542, meanQ=4.934832, numObservations: 4
action -1, numVisits=31, meanQ=3.560352, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.687 0.835101 0.391158 0.511827 0.577992 0.894503 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 471
Initial state: 0 0.58037 0.835295 0.780587 0.963964 0.584333 0.876406 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2241863 episodes
GETTING ACTION FROM:
action 2, numVisits=2241781, meanQ=4.916144, numObservations: 5
action -1, numVisits=72, meanQ=4.012038, numObservations: 1
action 3, numVisits=7, meanQ=0.428571, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.58037 0.835295 0.780587 0.963964 0.584333 0.876406 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 472
Initial state: 0 0.608585 0.849955 0.555349 0.827955 0.423929 0.662212 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2218601 episodes
GETTING ACTION FROM:
action 3, numVisits=2218536, meanQ=4.967246, numObservations: 5
action 0, numVisits=30, meanQ=3.489764, numObservations: 1
action 2, numVisits=21, meanQ=2.904776, numObservations: 3
action 1, numVisits=12, meanQ=1.998333, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.608585 0.849955 0.555349 0.827955 0.423929 0.662212 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=281031, meanQ=8.333908, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2766046 episodes
GETTING ACTION FROM:
action 2, numVisits=3047060, meanQ=6.014055, numObservations: 5
action 1, numVisits=16, meanQ=3.988125, numObservations: 2
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.608585 0.849955 0.555349 0.827955 0.423929 0.662212 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 473
Initial state: 0 0.529414 0.81693 0.540655 0.878323 0.0859627 0.471228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2213657 episodes
GETTING ACTION FROM:
action 2, numVisits=2213643, meanQ=4.900269, numObservations: 5
action 3, numVisits=6, meanQ=1.331683, numObservations: 2
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.529414 0.81693 0.540655 0.878323 0.0859627 0.471228 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 474
Initial state: 0 0.209389 0.66615 0.689735 0.891438 0.539705 0.895009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263852 episodes
GETTING ACTION FROM:
action 1, numVisits=2263833, meanQ=4.973678, numObservations: 4
action 2, numVisits=10, meanQ=1.798020, numObservations: 4
action 3, numVisits=5, meanQ=0.196000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.209389 0.66615 0.689735 0.891438 0.539705 0.895009 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=287041, meanQ=8.401897, numObservations: 4
action 2, numVisits=88, meanQ=7.586710, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2815544 episodes
GETTING ACTION FROM:
action 3, numVisits=3101870, meanQ=6.310756, numObservations: 4
action 2, numVisits=801, meanQ=6.040813, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.209389 0.66615 0.689735 0.891438 0.539705 0.895009 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 475
Initial state: 0 0.681692 0.863115 0.723752 0.23631 0.676336 0.827588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2250600 episodes
GETTING ACTION FROM:
action 2, numVisits=2250518, meanQ=4.968022, numObservations: 5
action -1, numVisits=78, meanQ=4.072795, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.681692 0.863115 0.723752 0.23631 0.676336 0.827588 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 476
Initial state: 0 0.578038 0.543431 0.559389 0.889723 0.68594 0.810698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2236379 episodes
GETTING ACTION FROM:
action 1, numVisits=2236369, meanQ=4.919981, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=4, meanQ=-2.005000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.578038 0.543431 0.559389 0.889723 0.68594 0.810698 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=284823, meanQ=8.393114, numObservations: 3
action 2, numVisits=23, meanQ=6.652183, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2850278 episodes
GETTING ACTION FROM:
action 3, numVisits=3134981, meanQ=5.954787, numObservations: 3
action 2, numVisits=141, meanQ=5.296668, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.578038 0.543431 0.559389 0.889723 0.68594 0.810698 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 477
Initial state: 0 0.584026 0.874987 0.0297706 0.768528 0.590113 0.830335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2256862 episodes
GETTING ACTION FROM:
action 3, numVisits=2256769, meanQ=4.987342, numObservations: 4
action 0, numVisits=78, meanQ=4.103171, numObservations: 1
action 1, numVisits=12, meanQ=1.998333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.584026 0.874987 0.0297706 0.768528 0.590113 0.830335 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.506961 0.863195 0.758821 0.176925 0.69857 0.859596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2238188 episodes
GETTING ACTION FROM:
action 3, numVisits=2238127, meanQ=4.992102, numObservations: 5
action -1, numVisits=48, meanQ=3.864999, numObservations: 1
action 1, numVisits=10, meanQ=1.397000, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.506961 0.863195 0.758821 0.176925 0.69857 0.859596 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 479
Initial state: 0 0.556141 0.821031 0.0872142 0.875994 0.543325 0.878028 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2257123 episodes
GETTING ACTION FROM:
action 1, numVisits=2256464, meanQ=5.112896, numObservations: 5
action 3, numVisits=447, meanQ=4.562659, numObservations: 3
action 2, numVisits=171, meanQ=4.495015, numObservations: 4
action -1, numVisits=39, meanQ=3.873249, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.556141 0.821031 0.0872142 0.875994 0.543325 0.878028 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 480
Initial state: 0 0.632447 0.828468 0.684823 0.808379 0.711234 0.84134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2184626 episodes
GETTING ACTION FROM:
action 1, numVisits=2184590, meanQ=4.841671, numObservations: 4
action -1, numVisits=32, meanQ=3.486508, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.632447 0.828468 0.684823 0.808379 0.711234 0.84134 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 481
Initial state: 0 0.626804 0.88385 0.53404 0.876928 0.537869 0.462287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2188218 episodes
GETTING ACTION FROM:
action 1, numVisits=2188211, meanQ=4.870131, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.626804 0.88385 0.53404 0.876928 0.537869 0.462287 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 482
Initial state: 0 0.286093 0.105631 0.514578 0.870227 0.644791 0.853505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2240629 episodes
GETTING ACTION FROM:
action 3, numVisits=2240622, meanQ=4.995390, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.286093 0.105631 0.514578 0.870227 0.644791 0.853505 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 483
Initial state: 0 0.524539 0.831795 0.600133 0.858373 0.535163 0.781293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239537 episodes
GETTING ACTION FROM:
action 1, numVisits=2239527, meanQ=4.975740, numObservations: 5
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.524539 0.831795 0.600133 0.858373 0.535163 0.781293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 484
Initial state: 0 0.698767 0.881893 0.613923 0.87347 0.927667 0.0374215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2281844 episodes
GETTING ACTION FROM:
action 1, numVisits=2281838, meanQ=4.996597, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.698767 0.881893 0.613923 0.87347 0.927667 0.0374215 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 485
Initial state: 0 0.00147666 0.0853674 0.638797 0.86952 0.639843 0.851598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2181902 episodes
GETTING ACTION FROM:
action 1, numVisits=2181891, meanQ=4.842951, numObservations: 5
action 2, numVisits=6, meanQ=1.663333, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.00147666 0.0853674 0.638797 0.86952 0.639843 0.851598 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=213483, meanQ=8.539295, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2874073 episodes
GETTING ACTION FROM:
action 2, numVisits=3087554, meanQ=6.141322, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.00147666 0.0853674 0.638797 0.86952 0.639843 0.851598 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 486
Initial state: 0 0.627598 0.876827 0.529165 0.849827 0.550873 0.12111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247669 episodes
GETTING ACTION FROM:
action 2, numVisits=2247644, meanQ=4.982195, numObservations: 4
action 3, numVisits=20, meanQ=0.898005, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.627598 0.876827 0.529165 0.849827 0.550873 0.12111 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 487
Initial state: 0 0.512201 0.858713 0.905963 0.189057 0.606003 0.860898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2289388 episodes
GETTING ACTION FROM:
action 2, numVisits=2289334, meanQ=4.969057, numObservations: 3
action -1, numVisits=50, meanQ=3.879589, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.512201 0.858713 0.905963 0.189057 0.606003 0.860898 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 488
Initial state: 0 0.604659 0.879554 0.537609 0.879685 0.186261 0.865122 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2300531 episodes
GETTING ACTION FROM:
action 2, numVisits=2300475, meanQ=4.992489, numObservations: 3
action 0, numVisits=36, meanQ=3.669796, numObservations: 1
action -1, numVisits=18, meanQ=3.171934, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.604659 0.879554 0.537609 0.879685 0.186261 0.865122 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 489
Initial state: 0 0.55197 0.506019 0.621445 0.873919 0.539697 0.821829 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2277204 episodes
GETTING ACTION FROM:
action 1, numVisits=2277198, meanQ=4.994896, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.55197 0.506019 0.621445 0.873919 0.539697 0.821829 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 490
Initial state: 0 0.656687 0.874526 0.289431 0.926559 0.592238 0.807725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2150910 episodes
GETTING ACTION FROM:
action 2, numVisits=2150897, meanQ=4.990936, numObservations: 5
action 3, numVisits=8, meanQ=1.747513, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.656687 0.874526 0.289431 0.926559 0.592238 0.807725 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 491
Initial state: 0 0.511768 0.884358 0.509854 0.531591 0.659471 0.894335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2245520 episodes
GETTING ACTION FROM:
action 2, numVisits=2245420, meanQ=5.113849, numObservations: 5
action 0, numVisits=75, meanQ=4.211284, numObservations: 1
action -1, numVisits=23, meanQ=3.460101, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.511768 0.884358 0.509854 0.531591 0.659471 0.894335 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 492
Initial state: 0 0.506377 0.236082 0.638722 0.86098 0.671067 0.86726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2223696 episodes
GETTING ACTION FROM:
action 2, numVisits=2223633, meanQ=4.893213, numObservations: 5
action 0, numVisits=58, meanQ=3.888135, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.506377 0.236082 0.638722 0.86098 0.671067 0.86726 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 493
Initial state: 0 0.665385 0.880979 0.601092 0.817901 0.486276 0.374396 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2277236 episodes
GETTING ACTION FROM:
action 3, numVisits=2277153, meanQ=4.987765, numObservations: 4
action -1, numVisits=79, meanQ=4.113894, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.665385 0.880979 0.601092 0.817901 0.486276 0.374396 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=155575, meanQ=8.387426, numObservations: 3
action 2, numVisits=133988, meanQ=8.383162, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2747919 episodes
GETTING ACTION FROM:
action 1, numVisits=2236644, meanQ=6.245998, numObservations: 3
action 2, numVisits=800836, meanQ=6.242495, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.665385 0.880979 0.601092 0.817901 0.486276 0.374396 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 494
Initial state: 0 0.225734 0.400095 0.606097 0.808878 0.5457 0.839442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2140720 episodes
GETTING ACTION FROM:
action 3, numVisits=2140660, meanQ=4.993633, numObservations: 4
action -1, numVisits=56, meanQ=3.943145, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.225734 0.400095 0.606097 0.808878 0.5457 0.839442 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 495
Initial state: 0 0.507708 0.871685 0.438865 0.681024 0.599962 0.823439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2135322 episodes
GETTING ACTION FROM:
action 3, numVisits=2135271, meanQ=4.968748, numObservations: 4
action 0, numVisits=47, meanQ=3.850478, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.507708 0.871685 0.438865 0.681024 0.599962 0.823439 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 496
Initial state: 0 0.603039 0.80377 0.663852 0.834364 0.356284 0.148751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2178848 episodes
GETTING ACTION FROM:
action 2, numVisits=2178758, meanQ=4.974758, numObservations: 3
action -1, numVisits=75, meanQ=4.097047, numObservations: 1
action 1, numVisits=12, meanQ=1.998333, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.603039 0.80377 0.663852 0.834364 0.356284 0.148751 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 497
Initial state: 0 0.554145 0.845173 0.51823 0.85222 0.324747 0.904274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2145542 episodes
GETTING ACTION FROM:
action 1, numVisits=2145511, meanQ=4.992776, numObservations: 4
action 2, numVisits=26, meanQ=1.921931, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.554145 0.845173 0.51823 0.85222 0.324747 0.904274 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 498
Initial state: 0 0.773667 0.329647 0.639034 0.850035 0.518247 0.857598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2093625 episodes
GETTING ACTION FROM:
action 2, numVisits=2092873, meanQ=4.903537, numObservations: 5
action 1, numVisits=694, meanQ=4.611858, numObservations: 4
action 0, numVisits=54, meanQ=3.868159, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.773667 0.329647 0.639034 0.850035 0.518247 0.857598 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 499
Initial state: 0 0.508736 0.825434 0.524861 0.828628 0.0683031 0.0357355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2123011 episodes
GETTING ACTION FROM:
action 3, numVisits=2122970, meanQ=4.956005, numObservations: 4
action 2, numVisits=36, meanQ=3.547500, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.508736 0.825434 0.524861 0.828628 0.0683031 0.0357355 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 500
Initial state: 0 0.533169 0.998521 0.652325 0.872755 0.593913 0.838154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2123200 episodes
GETTING ACTION FROM:
action 3, numVisits=2118157, meanQ=4.901781, numObservations: 4
action -1, numVisits=3836, meanQ=2.968023, numObservations: 1
action 0, numVisits=1192, meanQ=2.799228, numObservations: 1
action 2, numVisits=14, meanQ=0.998586, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.533169 0.998521 0.652325 0.872755 0.593913 0.838154 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
