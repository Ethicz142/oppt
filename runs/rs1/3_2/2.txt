Run # 1
Initial state: 0 0.513467 0.858946 0.591451 0.696497 0.585992 0.885826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187932 episodes
GETTING ACTION FROM:
action 3, numVisits=1187759, meanQ=6.277599, numObservations: 4
action -1, numVisits=126, meanQ=5.613363, numObservations: 1
action 0, numVisits=27, meanQ=4.752006, numObservations: 1
action 2, numVisits=14, meanQ=4.062864, numObservations: 3
action 1, numVisits=6, meanQ=2.331683, numObservations: 2
action: 3
Next state: 0 0.513467 0.858946 0.591451 0.696497 0.585992 0.885826 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=44769, meanQ=6.969412, numObservations: 5
action 2, numVisits=104, meanQ=6.286444, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1571273 episodes
GETTING ACTION FROM:
action 2, numVisits=1011181, meanQ=6.364890, numObservations: 4
action 1, numVisits=604963, meanQ=6.347058, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.513467 0.858946 0.591451 0.696497 0.585992 0.885826 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=4891, meanQ=8.903779, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1617768 episodes
GETTING ACTION FROM:
action 3, numVisits=1622549, meanQ=6.445334, numObservations: 3
action 1, numVisits=97, meanQ=5.608144, numObservations: 3
action 2, numVisits=13, meanQ=3.691538, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.513467 0.858946 0.591451 0.696497 0.585992 0.885826 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 2
Initial state: 0 0.962762 0.847082 0.55131 0.849049 0.530168 0.81784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1251596 episodes
GETTING ACTION FROM:
action 2, numVisits=1251516, meanQ=6.243462, numObservations: 3
action 0, numVisits=42, meanQ=5.065127, numObservations: 1
action -1, numVisits=25, meanQ=4.725607, numObservations: 1
action 3, numVisits=11, meanQ=2.726364, numObservations: 2
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.962762 0.847082 0.55131 0.849049 0.530168 0.81784 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 3
Initial state: 0 0.600973 0.886509 0.760408 0.63328 0.592916 0.884914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1237639 episodes
GETTING ACTION FROM:
action 2, numVisits=1236935, meanQ=6.265758, numObservations: 4
action 1, numVisits=671, meanQ=5.981900, numObservations: 5
action -1, numVisits=29, meanQ=4.844977, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.600973 0.886509 0.760408 0.63328 0.592916 0.884914 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 4
Initial state: 0 0.677219 0.889215 0.600396 0.886026 0.488416 0.606478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 814412 episodes
GETTING ACTION FROM:
action -1, numVisits=778375, meanQ=4.219249, numObservations: 1
action 0, numVisits=36015, meanQ=4.188732, numObservations: 1
action 2, numVisits=19, meanQ=1.630537, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.677219 0.889215 0.600396 0.886026 0.488416 0.606478 w: 1
Observation: 0 0.597957 0 0.628247 0 0.398632 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=778358, meanQ=6.282294, numObservations: 4
action 2, numVisits=10, meanQ=2.998020, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1356421 episodes
GETTING ACTION FROM:
action 1, numVisits=2134779, meanQ=6.174365, numObservations: 4
action 2, numVisits=10, meanQ=2.998020, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.677219 0.889215 0.600396 0.886026 0.488416 0.606478 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 5
Initial state: 0 0.669139 0.835064 0.51685 0.866574 0.714676 0.206392 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1212326 episodes
GETTING ACTION FROM:
action 2, numVisits=1212293, meanQ=6.239241, numObservations: 5
action -1, numVisits=21, meanQ=4.529280, numObservations: 1
action 3, numVisits=6, meanQ=2.663333, numObservations: 2
action 1, numVisits=4, meanQ=1.747500, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.669139 0.835064 0.51685 0.866574 0.714676 0.206392 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10793, meanQ=6.113677, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1557993 episodes
GETTING ACTION FROM:
action 1, numVisits=1568784, meanQ=6.027158, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.669139 0.835064 0.51685 0.866574 0.714676 0.206392 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 6
Initial state: 0 0.0121182 0.935737 0.615921 0.854647 0.509981 0.858103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1221789 episodes
GETTING ACTION FROM:
action 3, numVisits=539148, meanQ=6.255167, numObservations: 4
action 1, numVisits=682570, meanQ=6.251403, numObservations: 5
action -1, numVisits=57, meanQ=5.252661, numObservations: 1
action 2, numVisits=12, meanQ=3.982508, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.0121182 0.935737 0.615921 0.854647 0.509981 0.858103 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 7
Initial state: 0 0.686458 0.831519 0.879184 0.113346 0.53424 0.840962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1206201 episodes
GETTING ACTION FROM:
action 3, numVisits=1206076, meanQ=6.229837, numObservations: 5
action -1, numVisits=110, meanQ=5.517515, numObservations: 1
action 2, numVisits=4, meanQ=1.475000, numObservations: 2
action 1, numVisits=9, meanQ=1.332222, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.686458 0.831519 0.879184 0.113346 0.53424 0.840962 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 8
Initial state: 0 0.506418 0.801342 0.60848 0.83668 0.466219 0.843073 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1218230 episodes
GETTING ACTION FROM:
action 2, numVisits=1218073, meanQ=6.243475, numObservations: 4
action 0, numVisits=99, meanQ=5.487099, numObservations: 1
action -1, numVisits=39, meanQ=5.049122, numObservations: 1
action 3, numVisits=12, meanQ=2.331683, numObservations: 3
action 1, numVisits=7, meanQ=1.998571, numObservations: 3
action: 2
Next state: 1 0.506418 0.801342 0.60848 0.83668 0.466219 0.843073 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 9
Initial state: 0 0.608433 0.826352 0.312911 0.886045 0.557865 0.841356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1221890 episodes
GETTING ACTION FROM:
action 3, numVisits=1221829, meanQ=6.255635, numObservations: 4
action 0, numVisits=29, meanQ=4.847180, numObservations: 1
action 2, numVisits=23, meanQ=4.646535, numObservations: 4
action 1, numVisits=7, meanQ=1.998571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.608433 0.826352 0.312911 0.886045 0.557865 0.841356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 10
Initial state: 0 0.505004 0.854181 0.618734 0.738903 0.68816 0.854178 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1202690 episodes
GETTING ACTION FROM:
action 3, numVisits=1202593, meanQ=6.242140, numObservations: 5
action 0, numVisits=92, meanQ=5.455906, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.505004 0.854181 0.618734 0.738903 0.68816 0.854178 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 11
Initial state: 0 0.511253 0.820982 0.0494868 0.99757 0.557022 0.844131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1208495 episodes
GETTING ACTION FROM:
action 2, numVisits=1208455, meanQ=6.239185, numObservations: 5
action 0, numVisits=34, meanQ=4.945417, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 0 0.511253 0.820982 0.0494868 0.99757 0.557022 0.844131 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=36459, meanQ=6.322372, numObservations: 5
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1541528 episodes
GETTING ACTION FROM:
action 3, numVisits=1577987, meanQ=6.563386, numObservations: 5
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.511253 0.820982 0.0494868 0.99757 0.557022 0.844131 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 12
Initial state: 0 0.649848 0.88024 0.374128 0.53984 0.571939 0.89626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1223288 episodes
GETTING ACTION FROM:
action 2, numVisits=1132221, meanQ=6.254783, numObservations: 5
action 3, numVisits=91048, meanQ=6.197936, numObservations: 4
action -1, numVisits=13, meanQ=4.172509, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.649848 0.88024 0.374128 0.53984 0.571939 0.89626 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=144217, meanQ=8.831472, numObservations: 4
action 1, numVisits=12690, meanQ=8.788144, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1569017 episodes
GETTING ACTION FROM:
action 3, numVisits=1358717, meanQ=6.666310, numObservations: 4
action 1, numVisits=367206, meanQ=6.660279, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 1 0.649848 0.88024 0.374128 0.53984 0.571939 0.89626 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 13
Initial state: 0 0.544457 0.876123 0.281696 0.959508 0.688841 0.861877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1235603 episodes
GETTING ACTION FROM:
action 2, numVisits=1221215, meanQ=6.271143, numObservations: 4
action 1, numVisits=14168, meanQ=6.121321, numObservations: 5
action 3, numVisits=188, meanQ=5.712396, numObservations: 5
action 0, numVisits=30, meanQ=4.899916, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 0 0.544457 0.876123 0.281696 0.959508 0.688841 0.861877 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31419, meanQ=7.498575, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1572135 episodes
GETTING ACTION FROM:
action 1, numVisits=1586539, meanQ=6.646367, numObservations: 4
action 3, numVisits=17016, meanQ=6.593587, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.544457 0.876123 0.281696 0.959508 0.688841 0.861877 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 14
Initial state: 0 0.664374 0.894016 0.698325 0.0132647 0.561622 0.836433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1239414 episodes
GETTING ACTION FROM:
action 1, numVisits=1239183, meanQ=6.184864, numObservations: 4
action 3, numVisits=222, meanQ=5.664551, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.664374 0.894016 0.698325 0.0132647 0.561622 0.836433 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 15
Initial state: 0 0.645681 0.819669 0.680593 0.812795 0.621213 0.862985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1259782 episodes
GETTING ACTION FROM:
action 2, numVisits=1204930, meanQ=6.238754, numObservations: 3
action 1, numVisits=54841, meanQ=6.119483, numObservations: 3
action 3, numVisits=7, meanQ=1.842857, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.645681 0.819669 0.680593 0.812795 0.621213 0.862985 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 16
Initial state: 0 0.0565481 0.495514 0.616713 0.856429 0.626234 0.861435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1213300 episodes
GETTING ACTION FROM:
action 1, numVisits=1213288, meanQ=6.247048, numObservations: 5
action 3, numVisits=7, meanQ=3.285714, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0565481 0.495514 0.616713 0.856429 0.626234 0.861435 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=137403, meanQ=8.805029, numObservations: 4
action 3, numVisits=32241, meanQ=8.788691, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1592826 episodes
GETTING ACTION FROM:
action 2, numVisits=1365649, meanQ=6.542190, numObservations: 4
action 3, numVisits=396813, meanQ=6.537007, numObservations: 3
action 1, numVisits=7, meanQ=1.998571, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.0565481 0.495514 0.616713 0.856429 0.626234 0.861435 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 17
Initial state: 0 0.603898 0.898495 0.363148 0.955885 0.652414 0.875154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1223505 episodes
GETTING ACTION FROM:
action 2, numVisits=1223494, meanQ=6.239471, numObservations: 4
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.603898 0.898495 0.363148 0.955885 0.652414 0.875154 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=21196, meanQ=7.356024, numObservations: 4
action 1, numVisits=4, meanQ=4.000000, numObservations: 2
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1545125 episodes
GETTING ACTION FROM:
action 3, numVisits=1566313, meanQ=6.554558, numObservations: 4
action 1, numVisits=11, meanQ=3.545455, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.603898 0.898495 0.363148 0.955885 0.652414 0.875154 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 18
Initial state: 0 0.718177 0.546996 0.621241 0.858836 0.660612 0.897026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1227290 episodes
GETTING ACTION FROM:
action 2, numVisits=1227228, meanQ=6.283268, numObservations: 4
action 0, numVisits=51, meanQ=5.225683, numObservations: 1
action 1, numVisits=6, meanQ=0.831667, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.718177 0.546996 0.621241 0.858836 0.660612 0.897026 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 19
Initial state: 0 0.678826 0.874888 0.348923 0.760594 0.58827 0.883238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1212939 episodes
GETTING ACTION FROM:
action 2, numVisits=1212922, meanQ=6.258564, numObservations: 5
action 3, numVisits=11, meanQ=3.724555, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.678826 0.874888 0.348923 0.760594 0.58827 0.883238 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=158562, meanQ=8.829536, numObservations: 4
action 3, numVisits=10962, meanQ=8.767420, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1563937 episodes
GETTING ACTION FROM:
action 1, numVisits=1276973, meanQ=6.592702, numObservations: 4
action 3, numVisits=456488, meanQ=6.588179, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.678826 0.874888 0.348923 0.760594 0.58827 0.883238 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 20
Initial state: 0 0.617914 0.886507 0.403642 0.543313 0.551921 0.860853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1257211 episodes
GETTING ACTION FROM:
action 3, numVisits=1257178, meanQ=6.252814, numObservations: 3
action 0, numVisits=27, meanQ=4.758624, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.617914 0.886507 0.403642 0.543313 0.551921 0.860853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 21
Initial state: 0 0.619846 0.83706 0.49084 0.898368 0.663893 0.860587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1256288 episodes
GETTING ACTION FROM:
action 2, numVisits=1256137, meanQ=6.254947, numObservations: 3
action -1, numVisits=79, meanQ=5.417451, numObservations: 1
action 0, numVisits=63, meanQ=5.299032, numObservations: 1
action 3, numVisits=7, meanQ=3.284300, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.619846 0.83706 0.49084 0.898368 0.663893 0.860587 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 22
Initial state: 0 0.390543 0.439817 0.694969 0.805463 0.567646 0.842267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1239626 episodes
GETTING ACTION FROM:
action 3, numVisits=1239606, meanQ=6.235180, numObservations: 3
action 2, numVisits=15, meanQ=3.739333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.390543 0.439817 0.694969 0.805463 0.567646 0.842267 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 23
Initial state: 0 0.486663 0.436033 0.6356 0.834845 0.663403 0.893005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1194183 episodes
GETTING ACTION FROM:
action 3, numVisits=1194126, meanQ=6.205034, numObservations: 5
action 2, numVisits=31, meanQ=4.547742, numObservations: 5
action 1, numVisits=14, meanQ=4.212143, numObservations: 3
action 0, numVisits=10, meanQ=3.764687, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.486663 0.436033 0.6356 0.834845 0.663403 0.893005 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 24
Initial state: 0 0.685775 0.874396 0.964965 0.412451 0.60059 0.856886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1230161 episodes
GETTING ACTION FROM:
action 1, numVisits=1228705, meanQ=6.226058, numObservations: 5
action 3, numVisits=1437, meanQ=5.984066, numObservations: 5
action 0, numVisits=13, meanQ=4.057073, numObservations: 1
action 2, numVisits=4, meanQ=-0.754975, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 0 0.685775 0.874396 0.964965 0.412451 0.60059 0.856886 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=40934, meanQ=6.719395, numObservations: 5
action 2, numVisits=45, meanQ=5.215556, numObservations: 4
action 1, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1578089 episodes
GETTING ACTION FROM:
action 3, numVisits=1619022, meanQ=6.691132, numObservations: 5
action 2, numVisits=45, meanQ=5.215556, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.685775 0.874396 0.964965 0.412451 0.60059 0.856886 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 25
Initial state: 0 0.304377 0.0429146 0.529766 0.858956 0.547685 0.814767 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1261268 episodes
GETTING ACTION FROM:
action 1, numVisits=1261252, meanQ=6.283285, numObservations: 4
action 3, numVisits=11, meanQ=3.634555, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.304377 0.0429146 0.529766 0.858956 0.547685 0.814767 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=84838, meanQ=8.372036, numObservations: 4
action 3, numVisits=73, meanQ=6.794889, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1621664 episodes
GETTING ACTION FROM:
action 2, numVisits=1592751, meanQ=6.610873, numObservations: 4
action 3, numVisits=113823, meanQ=6.594331, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.304377 0.0429146 0.529766 0.858956 0.547685 0.814767 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 26
Initial state: 0 0.937203 0.807931 0.682447 0.837624 0.666981 0.883446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1018047 episodes
GETTING ACTION FROM:
action 0, numVisits=484009, meanQ=6.365645, numObservations: 3
action 3, numVisits=533984, meanQ=6.243156, numObservations: 5
action -1, numVisits=39, meanQ=5.084281, numObservations: 1
action 1, numVisits=14, meanQ=1.842857, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.937203 0.807931 0.682447 0.837624 0.666981 0.883446 w: 1
Observation: 0 0 0.73701 0 0.842456 0 0.939082 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=215747, meanQ=8.140162, numObservations: 4
action 1, numVisits=20, meanQ=6.549500, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1359296 episodes
GETTING ACTION FROM:
action 3, numVisits=1574943, meanQ=6.459986, numObservations: 4
action 1, numVisits=69, meanQ=5.485367, numObservations: 4
action -1, numVisits=49, meanQ=5.371568, numObservations: 1
action 2, numVisits=3, meanQ=-0.966667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.937203 0.807931 0.682447 0.837624 0.666981 0.883446 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 27
Initial state: 0 0.0535284 0.0853645 0.588568 0.805918 0.517811 0.85035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1218383 episodes
GETTING ACTION FROM:
action 1, numVisits=1218272, meanQ=6.295898, numObservations: 5
action -1, numVisits=41, meanQ=5.129540, numObservations: 1
action 2, numVisits=67, meanQ=3.489255, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0535284 0.0853645 0.588568 0.805918 0.517811 0.85035 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=130246, meanQ=8.932946, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1594033 episodes
GETTING ACTION FROM:
action 2, numVisits=1724276, meanQ=6.902336, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.0535284 0.0853645 0.588568 0.805918 0.517811 0.85035 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 28
Initial state: 0 0.540682 0.84252 0.992891 0.647321 0.694938 0.875311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1220650 episodes
GETTING ACTION FROM:
action 3, numVisits=1220643, meanQ=6.247464, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.540682 0.84252 0.992891 0.647321 0.694938 0.875311 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 29
Initial state: 0 0.630467 0.829639 0.629983 0.817198 0.133338 0.0402291 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1219557 episodes
GETTING ACTION FROM:
action 3, numVisits=1219518, meanQ=6.240265, numObservations: 4
action 2, numVisits=23, meanQ=4.556961, numObservations: 2
action 1, numVisits=12, meanQ=4.080850, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.630467 0.829639 0.629983 0.817198 0.133338 0.0402291 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=210070, meanQ=8.630466, numObservations: 4
action 1, numVisits=26, meanQ=7.151935, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1565956 episodes
GETTING ACTION FROM:
action 2, numVisits=1775831, meanQ=6.953249, numObservations: 4
action 1, numVisits=217, meanQ=6.428251, numObservations: 4
action 3, numVisits=5, meanQ=1.396000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.630467 0.829639 0.629983 0.817198 0.133338 0.0402291 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 30
Initial state: 0 0.698651 0.834796 0.603179 0.819273 0.39525 0.85676 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1206740 episodes
GETTING ACTION FROM:
action 3, numVisits=936242, meanQ=6.298875, numObservations: 5
action 2, numVisits=270389, meanQ=6.240282, numObservations: 4
action -1, numVisits=104, meanQ=5.568113, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 0 0.698651 0.834796 0.603179 0.819273 0.39525 0.85676 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=35344, meanQ=8.470782, numObservations: 3
action 2, numVisits=6, meanQ=5.666667, numObservations: 3
action 3, numVisits=5, meanQ=5.396000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1589764 episodes
GETTING ACTION FROM:
action 1, numVisits=1622982, meanQ=6.578010, numObservations: 3
action 3, numVisits=1486, meanQ=6.387070, numObservations: 5
action 2, numVisits=651, meanQ=6.284424, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.698651 0.834796 0.603179 0.819273 0.39525 0.85676 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 31
Initial state: 0 0.528185 0.893472 0.538062 0.899299 0.971792 0.0710655 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1217957 episodes
GETTING ACTION FROM:
action 2, numVisits=1217941, meanQ=6.237620, numObservations: 4
action 1, numVisits=11, meanQ=3.545455, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.528185 0.893472 0.538062 0.899299 0.971792 0.0710655 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 32
Initial state: 0 0.611192 0.804635 0.543336 0.80464 0.680326 0.46124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1232083 episodes
GETTING ACTION FROM:
action 2, numVisits=1232076, meanQ=6.248002, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.611192 0.804635 0.543336 0.80464 0.680326 0.46124 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 33
Initial state: 0 0.564358 0.00493088 0.667274 0.863932 0.606453 0.832791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1287013 episodes
GETTING ACTION FROM:
action 2, numVisits=1286968, meanQ=6.255560, numObservations: 3
action 0, numVisits=39, meanQ=5.019384, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 1 0.564358 0.00493088 0.667274 0.863932 0.606453 0.832791 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 34
Initial state: 0 0.968122 0.87479 0.60192 0.830361 0.64823 0.810488 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1231947 episodes
GETTING ACTION FROM:
action 1, numVisits=1229864, meanQ=6.331498, numObservations: 5
action 3, numVisits=2028, meanQ=5.959310, numObservations: 5
action 0, numVisits=52, meanQ=5.288432, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.968122 0.87479 0.60192 0.830361 0.64823 0.810488 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 35
Initial state: 0 0.748404 0.173105 0.549597 0.855143 0.57385 0.853587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1213092 episodes
GETTING ACTION FROM:
action 3, numVisits=1211835, meanQ=6.260090, numObservations: 5
action 2, numVisits=1201, meanQ=6.037277, numObservations: 4
action -1, numVisits=52, meanQ=5.225641, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.748404 0.173105 0.549597 0.855143 0.57385 0.853587 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 36
Initial state: 0 0.536121 0.840469 0.552173 0.878918 0.59964 0.882051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1224795 episodes
GETTING ACTION FROM:
action 3, numVisits=1224669, meanQ=6.282953, numObservations: 5
action 1, numVisits=121, meanQ=5.556448, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.536121 0.840469 0.552173 0.878918 0.59964 0.882051 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 37
Initial state: 0 0.507497 0.876935 0.675718 0.878985 0.598081 0.241722 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1189594 episodes
GETTING ACTION FROM:
action 3, numVisits=1189518, meanQ=6.237998, numObservations: 5
action 0, numVisits=69, meanQ=5.341658, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.507497 0.876935 0.675718 0.878985 0.598081 0.241722 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=48961, meanQ=7.201671, numObservations: 5
action 3, numVisits=54, meanQ=5.253889, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1532586 episodes
GETTING ACTION FROM:
action 1, numVisits=1581544, meanQ=6.355380, numObservations: 5
action 3, numVisits=54, meanQ=5.253889, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 1
Next state: 1 0.507497 0.876935 0.675718 0.878985 0.598081 0.241722 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 38
Initial state: 0 0.972889 0.819837 0.574621 0.863788 0.558473 0.811386 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1219386 episodes
GETTING ACTION FROM:
action 3, numVisits=1219333, meanQ=6.256277, numObservations: 4
action -1, numVisits=38, meanQ=5.010213, numObservations: 1
action 0, numVisits=12, meanQ=4.068044, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.972889 0.819837 0.574621 0.863788 0.558473 0.811386 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 39
Initial state: 0 0.579385 0.868555 0.594838 0.870992 0.64578 0.445417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1244563 episodes
GETTING ACTION FROM:
action 2, numVisits=1244553, meanQ=6.242859, numObservations: 3
action 3, numVisits=4, meanQ=2.242500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.579385 0.868555 0.594838 0.870992 0.64578 0.445417 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 40
Initial state: 0 0.65648 0.886862 0.590646 0.884214 0.0174684 0.598135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1213803 episodes
GETTING ACTION FROM:
action 1, numVisits=1213685, meanQ=6.257112, numObservations: 5
action 0, numVisits=63, meanQ=5.262389, numObservations: 1
action -1, numVisits=41, meanQ=5.015186, numObservations: 1
action 3, numVisits=13, meanQ=3.690777, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.65648 0.886862 0.590646 0.884214 0.0174684 0.598135 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 41
Initial state: 0 0.758351 0.814892 0.666575 0.813741 0.595715 0.881409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1248773 episodes
GETTING ACTION FROM:
action 2, numVisits=1248723, meanQ=6.263846, numObservations: 5
action 0, numVisits=29, meanQ=4.842371, numObservations: 1
action 1, numVisits=16, meanQ=4.060638, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.758351 0.814892 0.666575 0.813741 0.595715 0.881409 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 42
Initial state: 0 0.117521 0.939976 0.6492 0.875223 0.640128 0.892597 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1243045 episodes
GETTING ACTION FROM:
action 3, numVisits=1242983, meanQ=6.271447, numObservations: 5
action 2, numVisits=40, meanQ=5.046010, numObservations: 4
action 0, numVisits=14, meanQ=4.124718, numObservations: 1
action 1, numVisits=6, meanQ=0.831667, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.117521 0.939976 0.6492 0.875223 0.640128 0.892597 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 43
Initial state: 0 0.63284 0.604304 0.676517 0.859755 0.540924 0.802572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1248891 episodes
GETTING ACTION FROM:
action 3, numVisits=1248885, meanQ=6.249305, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.63284 0.604304 0.676517 0.859755 0.540924 0.802572 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 44
Initial state: 0 0.857183 0.142946 0.558612 0.843831 0.57481 0.824477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1276982 episodes
GETTING ACTION FROM:
action 2, numVisits=1276241, meanQ=6.240381, numObservations: 4
action 3, numVisits=715, meanQ=5.940178, numObservations: 5
action -1, numVisits=20, meanQ=4.557291, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.857183 0.142946 0.558612 0.843831 0.57481 0.824477 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 45
Initial state: 0 0.597303 0.888143 0.895058 0.819749 0.599613 0.83375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1252483 episodes
GETTING ACTION FROM:
action 1, numVisits=1252391, meanQ=6.323782, numObservations: 4
action 3, numVisits=57, meanQ=5.117025, numObservations: 4
action -1, numVisits=29, meanQ=4.901030, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.597303 0.888143 0.895058 0.819749 0.599613 0.83375 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 46
Initial state: 0 0.502978 0.881373 0.528757 0.829479 0.876897 0.840987 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1228882 episodes
GETTING ACTION FROM:
action 1, numVisits=1225100, meanQ=6.322225, numObservations: 5
action 3, numVisits=3708, meanQ=6.203902, numObservations: 4
action 0, numVisits=38, meanQ=5.095611, numObservations: 1
action -1, numVisits=24, meanQ=4.775236, numObservations: 1
action 2, numVisits=12, meanQ=3.249167, numObservations: 4
action: 1
Next state: 1 0.502978 0.881373 0.528757 0.829479 0.876897 0.840987 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 47
Initial state: 0 0.58818 0.841712 0.851725 0.904139 0.6675 0.835105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1274178 episodes
GETTING ACTION FROM:
action 2, numVisits=1274163, meanQ=6.241619, numObservations: 4
action 3, numVisits=10, meanQ=2.999010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.58818 0.841712 0.851725 0.904139 0.6675 0.835105 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 48
Initial state: 0 0.98786 0.162156 0.549822 0.893167 0.512237 0.857266 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1285904 episodes
GETTING ACTION FROM:
action 1, numVisits=1285851, meanQ=6.223944, numObservations: 3
action -1, numVisits=33, meanQ=4.863580, numObservations: 1
action 3, numVisits=9, meanQ=3.553344, numObservations: 2
action 2, numVisits=9, meanQ=3.553344, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.98786 0.162156 0.549822 0.893167 0.512237 0.857266 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 49
Initial state: 0 0.532254 0.37445 0.519204 0.806368 0.50143 0.888831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1246471 episodes
GETTING ACTION FROM:
action 1, numVisits=1246446, meanQ=6.359966, numObservations: 5
action 3, numVisits=20, meanQ=3.331005, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.532254 0.37445 0.519204 0.806368 0.50143 0.888831 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 50
Initial state: 0 0.00203561 0.732441 0.576091 0.822841 0.536052 0.821799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1241411 episodes
GETTING ACTION FROM:
action 3, numVisits=1241334, meanQ=6.262693, numObservations: 5
action -1, numVisits=66, meanQ=5.342991, numObservations: 1
action 2, numVisits=7, meanQ=1.842857, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.00203561 0.732441 0.576091 0.822841 0.536052 0.821799 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 51
Initial state: 0 0.599442 0.883081 0.0598878 0.272807 0.609612 0.881816 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1262513 episodes
GETTING ACTION FROM:
action 3, numVisits=1262469, meanQ=6.173311, numObservations: 4
action -1, numVisits=39, meanQ=4.956609, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.599442 0.883081 0.0598878 0.272807 0.609612 0.881816 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 52
Initial state: 0 0.69235 0.893909 0.559572 0.829595 0.975443 0.300047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1241612 episodes
GETTING ACTION FROM:
action 3, numVisits=1241604, meanQ=6.257714, numObservations: 5
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.69235 0.893909 0.559572 0.829595 0.975443 0.300047 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 53
Initial state: 0 0.66671 0.891007 0.127329 0.897443 0.523361 0.843955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1271336 episodes
GETTING ACTION FROM:
action 2, numVisits=1269642, meanQ=6.249767, numObservations: 4
action 1, numVisits=1619, meanQ=6.025918, numObservations: 4
action -1, numVisits=65, meanQ=5.313239, numObservations: 1
action 3, numVisits=8, meanQ=2.873750, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.66671 0.891007 0.127329 0.897443 0.523361 0.843955 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=194977, meanQ=8.812928, numObservations: 4
action 3, numVisits=16647, meanQ=8.712215, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1599822 episodes
GETTING ACTION FROM:
action 1, numVisits=1582752, meanQ=6.773192, numObservations: 4
action 3, numVisits=228693, meanQ=6.763254, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.66671 0.891007 0.127329 0.897443 0.523361 0.843955 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 54
Initial state: 0 0.240832 0.26544 0.619081 0.883756 0.500428 0.89513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1208032 episodes
GETTING ACTION FROM:
action 1, numVisits=1207902, meanQ=6.155337, numObservations: 5
action 0, numVisits=77, meanQ=5.293318, numObservations: 1
action -1, numVisits=41, meanQ=4.975987, numObservations: 1
action 3, numVisits=10, meanQ=3.000000, numObservations: 3
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action: 1
Next state: 0 0.240832 0.26544 0.619081 0.883756 0.500428 0.89513 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=74819, meanQ=8.310005, numObservations: 3
action 2, numVisits=3, meanQ=2.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1578858 episodes
GETTING ACTION FROM:
action 3, numVisits=1653673, meanQ=6.367166, numObservations: 3
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.240832 0.26544 0.619081 0.883756 0.500428 0.89513 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 55
Initial state: 0 0.678144 0.829126 0.192119 0.00729289 0.591046 0.863752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1206611 episodes
GETTING ACTION FROM:
action 2, numVisits=1206592, meanQ=6.178441, numObservations: 4
action 0, numVisits=12, meanQ=3.838516, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 0 0.678144 0.829126 0.192119 0.00729289 0.591046 0.863752 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=202999, meanQ=8.717193, numObservations: 4
action 3, numVisits=3892, meanQ=8.604943, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1619582 episodes
GETTING ACTION FROM:
action 1, numVisits=1800533, meanQ=6.845165, numObservations: 4
action 3, numVisits=25936, meanQ=6.803372, numObservations: 5
action 2, numVisits=5, meanQ=3.198000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.678144 0.829126 0.192119 0.00729289 0.591046 0.863752 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 56
Initial state: 0 0.629464 0.829241 0.614479 0.690798 0.538745 0.876474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1260005 episodes
GETTING ACTION FROM:
action 2, numVisits=1259856, meanQ=6.234754, numObservations: 4
action 1, numVisits=93, meanQ=5.327663, numObservations: 3
action 0, numVisits=29, meanQ=4.849224, numObservations: 1
action 3, numVisits=25, meanQ=4.678804, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.629464 0.829241 0.614479 0.690798 0.538745 0.876474 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=35862, meanQ=8.416109, numObservations: 4
action 3, numVisits=36404, meanQ=8.268946, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1591559 episodes
GETTING ACTION FROM:
action 3, numVisits=1514900, meanQ=6.862465, numObservations: 5
action 1, numVisits=148915, meanQ=6.848838, numObservations: 4
action 2, numVisits=11, meanQ=3.626364, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.629464 0.829241 0.614479 0.690798 0.538745 0.876474 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 57
Initial state: 0 0.578995 0.826499 0.658176 0.825882 0.501055 0.252604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 824395 episodes
GETTING ACTION FROM:
action -1, numVisits=824389, meanQ=4.236017, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.578995 0.826499 0.658176 0.825882 0.501055 0.252604 w: 1
Observation: 0 0.634931 0 0.677256 0 0.498403 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=820661, meanQ=6.293755, numObservations: 5
action 3, numVisits=3656, meanQ=6.176836, numObservations: 4
action 2, numVisits=56, meanQ=5.205714, numObservations: 4
action 0, numVisits=13, meanQ=4.243092, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
Sampled 1342809 episodes
GETTING ACTION FROM:
action 1, numVisits=2163463, meanQ=6.288090, numObservations: 5
action 3, numVisits=3662, meanQ=6.164690, numObservations: 4
action 2, numVisits=56, meanQ=5.205714, numObservations: 4
action 0, numVisits=14, meanQ=3.796450, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.578995 0.826499 0.658176 0.825882 0.501055 0.252604 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 58
Initial state: 0 0.611934 0.881764 0.533117 0.876782 0.959899 0.739823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1201470 episodes
GETTING ACTION FROM:
action 3, numVisits=1201408, meanQ=6.240319, numObservations: 5
action -1, numVisits=39, meanQ=5.038118, numObservations: 1
action 1, numVisits=15, meanQ=3.930667, numObservations: 4
action 2, numVisits=6, meanQ=2.663333, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 2 0.611934 0.881764 0.533117 0.876782 0.959899 0.739823 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 59
Initial state: 0 0.611619 0.818831 0.579387 0.857098 0.665833 0.145844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1210399 episodes
GETTING ACTION FROM:
action 3, numVisits=1210389, meanQ=6.262676, numObservations: 4
action 1, numVisits=4, meanQ=-0.505000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.611619 0.818831 0.579387 0.857098 0.665833 0.145844 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 60
Initial state: 0 0.694345 0.803601 0.654198 0.860926 0.401843 0.0430359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1242593 episodes
GETTING ACTION FROM:
action 1, numVisits=1242579, meanQ=6.162928, numObservations: 3
action 3, numVisits=8, meanQ=2.873750, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.694345 0.803601 0.654198 0.860926 0.401843 0.0430359 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 61
Initial state: 0 0.550142 0.852257 0.637243 0.803036 0.35369 0.920232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1222166 episodes
GETTING ACTION FROM:
action 2, numVisits=1222159, meanQ=6.240787, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.550142 0.852257 0.637243 0.803036 0.35369 0.920232 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=48859, meanQ=6.706395, numObservations: 3
action 1, numVisits=18, meanQ=5.105556, numObservations: 4
action 2, numVisits=8, meanQ=4.247500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1606955 episodes
GETTING ACTION FROM:
action 3, numVisits=1655697, meanQ=6.684228, numObservations: 3
action 1, numVisits=133, meanQ=6.005865, numObservations: 5
action 2, numVisits=10, meanQ=4.098010, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.550142 0.852257 0.637243 0.803036 0.35369 0.920232 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 62
Initial state: 0 0.290074 0.676111 0.604648 0.881095 0.60851 0.896655 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1211411 episodes
GETTING ACTION FROM:
action 2, numVisits=1211311, meanQ=6.245600, numObservations: 5
action 0, numVisits=54, meanQ=5.206323, numObservations: 1
action -1, numVisits=35, meanQ=4.973061, numObservations: 1
action 3, numVisits=10, meanQ=2.099000, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.290074 0.676111 0.604648 0.881095 0.60851 0.896655 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 63
Initial state: 0 0.792564 0.538607 0.677769 0.81885 0.581063 0.854972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1200520 episodes
GETTING ACTION FROM:
action 1, numVisits=1200453, meanQ=6.259511, numObservations: 5
action -1, numVisits=62, meanQ=5.302446, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.792564 0.538607 0.677769 0.81885 0.581063 0.854972 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 64
Initial state: 0 0.652239 0.806725 0.624992 0.846003 0.641946 0.00417804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1235617 episodes
GETTING ACTION FROM:
action 1, numVisits=1235380, meanQ=6.170514, numObservations: 3
action 2, numVisits=219, meanQ=5.595443, numObservations: 5
action 3, numVisits=14, meanQ=4.134286, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.652239 0.806725 0.624992 0.846003 0.641946 0.00417804 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 65
Initial state: 0 0.67275 0.86407 0.724682 0.244403 0.650276 0.861116 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1269945 episodes
GETTING ACTION FROM:
action 3, numVisits=1269858, meanQ=6.254122, numObservations: 3
action 1, numVisits=47, meanQ=4.889368, numObservations: 3
action 0, numVisits=30, meanQ=4.819258, numObservations: 1
action 2, numVisits=8, meanQ=2.872513, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.67275 0.86407 0.724682 0.244403 0.650276 0.861116 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 66
Initial state: 0 0.553867 0.820399 0.658087 0.807008 0.677226 0.7974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1204690 episodes
GETTING ACTION FROM:
action 3, numVisits=1204663, meanQ=6.303579, numObservations: 5
action -1, numVisits=14, meanQ=4.287207, numObservations: 1
action 2, numVisits=9, meanQ=3.554444, numObservations: 3
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 2 0.553867 0.820399 0.658087 0.807008 0.677226 0.7974 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 67
Initial state: 0 0.695637 0.881262 0.51194 0.858695 0.426246 0.794017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1209427 episodes
GETTING ACTION FROM:
action 3, numVisits=1209413, meanQ=6.233714, numObservations: 5
action 1, numVisits=9, meanQ=3.554444, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.695637 0.881262 0.51194 0.858695 0.426246 0.794017 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=68990, meanQ=8.942872, numObservations: 3
action 2, numVisits=59903, meanQ=8.940923, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1553845 episodes
GETTING ACTION FROM:
action 2, numVisits=884540, meanQ=6.898395, numObservations: 4
action 1, numVisits=798197, meanQ=6.897986, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.695637 0.881262 0.51194 0.858695 0.426246 0.794017 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 68
Initial state: 0 0.688185 0.876801 0.673538 0.841929 0.989341 0.781624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1233929 episodes
GETTING ACTION FROM:
action 2, numVisits=1233896, meanQ=6.260037, numObservations: 4
action 3, numVisits=18, meanQ=3.994444, numObservations: 3
action 1, numVisits=11, meanQ=2.726364, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.688185 0.876801 0.673538 0.841929 0.989341 0.781624 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 69
Initial state: 0 0.852682 0.311245 0.508164 0.818459 0.667019 0.8223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1242476 episodes
GETTING ACTION FROM:
action 3, numVisits=1242445, meanQ=6.242888, numObservations: 3
action 1, numVisits=20, meanQ=4.048510, numObservations: 4
action 2, numVisits=7, meanQ=3.285714, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.852682 0.311245 0.508164 0.818459 0.667019 0.8223 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 70
Initial state: 0 0.486378 0.572765 0.507229 0.886755 0.543816 0.807388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1255102 episodes
GETTING ACTION FROM:
action 2, numVisits=1255053, meanQ=6.248019, numObservations: 3
action -1, numVisits=26, meanQ=4.738298, numObservations: 1
action 1, numVisits=13, meanQ=3.690777, numObservations: 3
action 3, numVisits=8, meanQ=2.873750, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.486378 0.572765 0.507229 0.886755 0.543816 0.807388 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 71
Initial state: 0 0.675952 0.858335 0.666917 0.841833 0.813641 0.15523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1186424 episodes
GETTING ACTION FROM:
action 2, numVisits=1116716, meanQ=6.258139, numObservations: 5
action 3, numVisits=69660, meanQ=6.160522, numObservations: 5
action 1, numVisits=32, meanQ=4.828444, numObservations: 4
action 0, numVisits=14, meanQ=4.119510, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.675952 0.858335 0.666917 0.841833 0.813641 0.15523 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 72
Initial state: 0 0.579071 0.884295 0.642219 0.758453 0.557102 0.89292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1223405 episodes
GETTING ACTION FROM:
action 2, numVisits=1223206, meanQ=6.247994, numObservations: 5
action 1, numVisits=129, meanQ=5.419150, numObservations: 4
action 3, numVisits=52, meanQ=4.982117, numObservations: 4
action 0, numVisits=16, meanQ=4.273289, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.579071 0.884295 0.642219 0.758453 0.557102 0.89292 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=80818, meanQ=8.096281, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1544095 episodes
GETTING ACTION FROM:
action 3, numVisits=1624910, meanQ=6.764514, numObservations: 5
action 1, numVisits=4, meanQ=1.747500, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.579071 0.884295 0.642219 0.758453 0.557102 0.89292 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 73
Initial state: 0 0.56659 0.805233 0.186707 0.96087 0.523785 0.878602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1211618 episodes
GETTING ACTION FROM:
action 3, numVisits=1211579, meanQ=6.246488, numObservations: 5
action 0, numVisits=31, meanQ=4.849105, numObservations: 1
action 2, numVisits=4, meanQ=2.242500, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.56659 0.805233 0.186707 0.96087 0.523785 0.878602 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 74
Initial state: 0 0.664284 0.818331 0.680122 0.876715 0.700696 0.288879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1221666 episodes
GETTING ACTION FROM:
action 2, numVisits=1221601, meanQ=6.262230, numObservations: 5
action -1, numVisits=56, meanQ=5.240113, numObservations: 1
action 3, numVisits=5, meanQ=1.396000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.664284 0.818331 0.680122 0.876715 0.700696 0.288879 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 75
Initial state: 0 0.775078 0.959603 0.69395 0.892045 0.510299 0.886982 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1219138 episodes
GETTING ACTION FROM:
action 2, numVisits=1219082, meanQ=6.272897, numObservations: 5
action -1, numVisits=50, meanQ=5.193410, numObservations: 1
action 1, numVisits=2, meanQ=-0.509950, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.775078 0.959603 0.69395 0.892045 0.510299 0.886982 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 76
Initial state: 0 0.542016 0.847686 0.685185 0.865972 0.538945 0.30667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1249525 episodes
GETTING ACTION FROM:
action 3, numVisits=1249512, meanQ=6.244509, numObservations: 3
action 1, numVisits=6, meanQ=2.660033, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.542016 0.847686 0.685185 0.865972 0.538945 0.30667 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 77
Initial state: 0 0.515379 0.843146 0.525558 0.862759 0.96836 0.300866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1221517 episodes
GETTING ACTION FROM:
action 3, numVisits=1221495, meanQ=6.234514, numObservations: 4
action 2, numVisits=13, meanQ=3.842323, numObservations: 4
action 1, numVisits=5, meanQ=1.396000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.515379 0.843146 0.525558 0.862759 0.96836 0.300866 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=27421, meanQ=6.304943, numObservations: 5
action 3, numVisits=1583, meanQ=3.680498, numObservations: 3
action -1, numVisits=29, meanQ=2.784728, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1557306 episodes
GETTING ACTION FROM:
action 1, numVisits=1584727, meanQ=6.400641, numObservations: 5
action 3, numVisits=1583, meanQ=3.680498, numObservations: 3
action -1, numVisits=29, meanQ=2.784728, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.515379 0.843146 0.525558 0.862759 0.96836 0.300866 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 78
Initial state: 0 0.485744 0.472119 0.640123 0.829047 0.605633 0.821905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1230518 episodes
GETTING ACTION FROM:
action 3, numVisits=1230408, meanQ=6.254657, numObservations: 4
action 0, numVisits=93, meanQ=5.478036, numObservations: 1
action -1, numVisits=9, meanQ=3.387067, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action: 3
Next state: 1 0.485744 0.472119 0.640123 0.829047 0.605633 0.821905 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 79
Initial state: 0 0.656979 0.817293 0.689019 0.885496 0.624565 0.175379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1237282 episodes
GETTING ACTION FROM:
action 1, numVisits=1237184, meanQ=6.182557, numObservations: 4
action 0, numVisits=86, meanQ=5.367818, numObservations: 1
action 2, numVisits=9, meanQ=3.554444, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.656979 0.817293 0.689019 0.885496 0.624565 0.175379 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 80
Initial state: 0 0.652769 0.801075 0.663871 0.821383 0.323725 0.93731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1254797 episodes
GETTING ACTION FROM:
action 1, numVisits=1206517, meanQ=6.288891, numObservations: 3
action 3, numVisits=48274, meanQ=6.173636, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.652769 0.801075 0.663871 0.821383 0.323725 0.93731 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 81
Initial state: 0 0.504506 0.857072 0.635678 0.894891 0.011363 0.190197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1235469 episodes
GETTING ACTION FROM:
action 3, numVisits=1235439, meanQ=6.271253, numObservations: 5
action 0, numVisits=22, meanQ=4.601880, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.504506 0.857072 0.635678 0.894891 0.011363 0.190197 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=72444, meanQ=8.945480, numObservations: 3
action 1, numVisits=62544, meanQ=8.943563, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1588501 episodes
GETTING ACTION FROM:
action 2, numVisits=1130931, meanQ=6.582419, numObservations: 4
action 1, numVisits=592557, meanQ=6.578957, numObservations: 3
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.504506 0.857072 0.635678 0.894891 0.011363 0.190197 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=8023, meanQ=8.660503, numObservations: 4
action 2, numVisits=3610, meanQ=8.624260, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1601704 episodes
GETTING ACTION FROM:
action 1, numVisits=1591417, meanQ=6.532611, numObservations: 4
action 2, numVisits=21915, meanQ=6.485531, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.504506 0.857072 0.635678 0.894891 0.011363 0.190197 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 82
Initial state: 0 0.512982 0.880392 0.672031 0.834197 0.0374339 0.789705 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1206844 episodes
GETTING ACTION FROM:
action 1, numVisits=1206829, meanQ=6.226741, numObservations: 5
action 2, numVisits=6, meanQ=2.333333, numObservations: 2
action 3, numVisits=5, meanQ=1.396000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.512982 0.880392 0.672031 0.834197 0.0374339 0.789705 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 83
Initial state: 0 0.759247 0.393123 0.614195 0.82775 0.569803 0.820896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1217905 episodes
GETTING ACTION FROM:
action 1, numVisits=1216691, meanQ=6.176443, numObservations: 4
action 3, numVisits=1117, meanQ=5.933467, numObservations: 4
action -1, numVisits=62, meanQ=5.220912, numObservations: 1
action 0, numVisits=33, meanQ=4.869247, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 2 0.759247 0.393123 0.614195 0.82775 0.569803 0.820896 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 84
Initial state: 0 0.513748 0.882576 0.845238 0.657447 0.696185 0.894087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1187791 episodes
GETTING ACTION FROM:
action 3, numVisits=1187649, meanQ=6.222403, numObservations: 5
action 2, numVisits=90, meanQ=5.274662, numObservations: 3
action 0, numVisits=42, meanQ=5.057713, numObservations: 1
action 1, numVisits=8, meanQ=2.872512, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.513748 0.882576 0.845238 0.657447 0.696185 0.894087 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 85
Initial state: 0 0.237034 0.300267 0.578237 0.853431 0.538579 0.871178 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1206056 episodes
GETTING ACTION FROM:
action 3, numVisits=1206038, meanQ=6.255620, numObservations: 4
action 2, numVisits=12, meanQ=3.249167, numObservations: 2
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.237034 0.300267 0.578237 0.853431 0.538579 0.871178 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 86
Initial state: 0 0.548451 0.838755 0.163308 0.793206 0.517689 0.895726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1214740 episodes
GETTING ACTION FROM:
action 3, numVisits=1214622, meanQ=6.236790, numObservations: 4
action -1, numVisits=107, meanQ=5.510306, numObservations: 1
action 2, numVisits=7, meanQ=3.284300, numObservations: 3
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.548451 0.838755 0.163308 0.793206 0.517689 0.895726 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 87
Initial state: 0 0.501307 0.857005 0.848936 0.151417 0.671687 0.827438 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1228936 episodes
GETTING ACTION FROM:
action 1, numVisits=1228924, meanQ=6.226195, numObservations: 4
action 2, numVisits=6, meanQ=2.333333, numObservations: 3
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.501307 0.857005 0.848936 0.151417 0.671687 0.827438 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 88
Initial state: 0 0.552664 0.877165 0.513147 0.88271 0.223844 0.298208 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1217006 episodes
GETTING ACTION FROM:
action 2, numVisits=1215189, meanQ=6.312887, numObservations: 4
action 1, numVisits=1773, meanQ=6.134724, numObservations: 5
action 3, numVisits=40, meanQ=5.133500, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.552664 0.877165 0.513147 0.88271 0.223844 0.298208 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 89
Initial state: 0 0.512978 0.114024 0.618717 0.834014 0.625997 0.841162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1192892 episodes
GETTING ACTION FROM:
action 3, numVisits=1192812, meanQ=6.236550, numObservations: 5
action -1, numVisits=73, meanQ=5.365406, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.512978 0.114024 0.618717 0.834014 0.625997 0.841162 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 90
Initial state: 0 0.588856 0.812863 0.617896 0.859461 0.294522 0.654857 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1211198 episodes
GETTING ACTION FROM:
action 3, numVisits=1211093, meanQ=6.260319, numObservations: 4
action 0, numVisits=77, meanQ=5.404196, numObservations: 1
action -1, numVisits=21, meanQ=4.610943, numObservations: 1
action 2, numVisits=5, meanQ=1.178000, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 0 0.588856 0.812863 0.617896 0.859461 0.294522 0.654857 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=74034, meanQ=8.938800, numObservations: 3
action 2, numVisits=55121, meanQ=8.934788, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1586104 episodes
GETTING ACTION FROM:
action 2, numVisits=1380697, meanQ=6.891085, numObservations: 4
action 1, numVisits=334549, meanQ=6.884326, numObservations: 3
action 3, numVisits=14, meanQ=4.699293, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.588856 0.812863 0.617896 0.859461 0.294522 0.654857 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 91
Initial state: 0 0.606886 0.842141 0.520171 0.886604 0.878766 0.00861034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1237745 episodes
GETTING ACTION FROM:
action 1, numVisits=1237731, meanQ=6.215944, numObservations: 4
action 3, numVisits=8, meanQ=2.871275, numObservations: 3
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.606886 0.842141 0.520171 0.886604 0.878766 0.00861034 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=41913, meanQ=6.908433, numObservations: 4
action 3, numVisits=62, meanQ=6.059840, numObservations: 4
action 1, numVisits=11, meanQ=4.544545, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1585813 episodes
GETTING ACTION FROM:
action 2, numVisits=1627159, meanQ=6.292580, numObservations: 4
action 1, numVisits=395, meanQ=5.912888, numObservations: 5
action 3, numVisits=243, meanQ=5.776133, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.606886 0.842141 0.520171 0.886604 0.878766 0.00861034 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 92
Initial state: 0 0.807923 0.228382 0.66127 0.879757 0.546878 0.835014 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1233167 episodes
GETTING ACTION FROM:
action 3, numVisits=1233131, meanQ=6.256983, numObservations: 4
action 0, numVisits=21, meanQ=4.443509, numObservations: 1
action 1, numVisits=11, meanQ=3.725455, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.807923 0.228382 0.66127 0.879757 0.546878 0.835014 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 93
Initial state: 0 0.52982 0.803127 0.662011 0.871859 0.919327 0.532746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1217470 episodes
GETTING ACTION FROM:
action 2, numVisits=1217441, meanQ=6.227172, numObservations: 5
action -1, numVisits=24, meanQ=4.588660, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.52982 0.803127 0.662011 0.871859 0.919327 0.532746 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 94
Initial state: 0 0.633391 0.82219 0.583615 0.81961 0.88987 0.280692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1263814 episodes
GETTING ACTION FROM:
action 1, numVisits=1263756, meanQ=6.206495, numObservations: 3
action -1, numVisits=38, meanQ=4.994374, numObservations: 1
action 2, numVisits=13, meanQ=3.766931, numObservations: 3
action 3, numVisits=5, meanQ=1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.633391 0.82219 0.583615 0.81961 0.88987 0.280692 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 95
Initial state: 0 0.552605 0.808571 0.609654 0.944655 0.636923 0.80831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1231780 episodes
GETTING ACTION FROM:
action 1, numVisits=1231717, meanQ=6.215457, numObservations: 4
action 2, numVisits=45, meanQ=4.999340, numObservations: 3
action 3, numVisits=14, meanQ=4.070714, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.552605 0.808571 0.609654 0.944655 0.636923 0.80831 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 96
Initial state: 0 0.053071 0.463769 0.546289 0.804275 0.641065 0.806928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1219950 episodes
GETTING ACTION FROM:
action 1, numVisits=1219781, meanQ=6.194134, numObservations: 5
action -1, numVisits=104, meanQ=5.445660, numObservations: 1
action 0, numVisits=53, meanQ=5.143668, numObservations: 1
action 2, numVisits=11, meanQ=1.726373, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.053071 0.463769 0.546289 0.804275 0.641065 0.806928 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=166974, meanQ=8.790158, numObservations: 3
action 3, numVisits=8, meanQ=5.373750, numObservations: 1
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1605103 episodes
GETTING ACTION FROM:
action 3, numVisits=144767, meanQ=6.916259, numObservations: 4
action 2, numVisits=1627302, meanQ=6.819161, numObservations: 3
action 1, numVisits=17, meanQ=4.881188, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.053071 0.463769 0.546289 0.804275 0.641065 0.806928 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 97
Initial state: 0 0.589248 0.815156 0.814607 0.943474 0.632413 0.813274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1229678 episodes
GETTING ACTION FROM:
action 1, numVisits=1229651, meanQ=6.239866, numObservations: 4
action -1, numVisits=11, meanQ=3.979945, numObservations: 1
action 3, numVisits=10, meanQ=3.098010, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.589248 0.815156 0.814607 0.943474 0.632413 0.813274 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 98
Initial state: 0 0.84113 0.537007 0.556582 0.844776 0.580976 0.893208 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1213613 episodes
GETTING ACTION FROM:
action 2, numVisits=1213558, meanQ=6.231238, numObservations: 5
action -1, numVisits=41, meanQ=5.061687, numObservations: 1
action 3, numVisits=6, meanQ=0.831667, numObservations: 1
action 1, numVisits=6, meanQ=0.831667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.84113 0.537007 0.556582 0.844776 0.580976 0.893208 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 99
Initial state: 0 0.41907 0.639985 0.654212 0.80943 0.570611 0.852544 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1226040 episodes
GETTING ACTION FROM:
action 2, numVisits=1226017, meanQ=6.256108, numObservations: 4
action 1, numVisits=17, meanQ=4.410588, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.41907 0.639985 0.654212 0.80943 0.570611 0.852544 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 100
Initial state: 0 0.650144 0.865679 0.129849 0.0169522 0.550814 0.850383 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1197926 episodes
GETTING ACTION FROM:
action 3, numVisits=1197901, meanQ=6.169910, numObservations: 4
action 0, numVisits=20, meanQ=4.258931, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.650144 0.865679 0.129849 0.0169522 0.550814 0.850383 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
