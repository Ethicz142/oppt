Run # 1
Initial state: 0 0.660416 0.834792 0.267748 0.0838731 0.639641 0.843143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657524 episodes
GETTING ACTION FROM:
action 3, numVisits=657040, meanQ=6.225641, numObservations: 4
action 1, numVisits=405, meanQ=5.863038, numObservations: 5
action -1, numVisits=63, meanQ=5.289478, numObservations: 1
action 2, numVisits=14, meanQ=3.129293, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.660416 0.834792 0.267748 0.0838731 0.639641 0.843143 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.681922 0.861042 0.0823735 0.135406 0.635 0.848739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691142 episodes
GETTING ACTION FROM:
action 2, numVisits=691071, meanQ=6.226827, numObservations: 5
action 0, numVisits=29, meanQ=4.868608, numObservations: 1
action -1, numVisits=27, meanQ=4.776064, numObservations: 1
action 1, numVisits=9, meanQ=2.332233, numObservations: 3
action 3, numVisits=6, meanQ=0.650000, numObservations: 2
action: 2
Next state: 0 0.681922 0.861042 0.0823735 0.135406 0.635 0.848739 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=86238, meanQ=8.871845, numObservations: 3
action 3, numVisits=8615, meanQ=8.819267, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 867847 episodes
GETTING ACTION FROM:
action 1, numVisits=807877, meanQ=6.597505, numObservations: 3
action 3, numVisits=154822, meanQ=6.586616, numObservations: 3
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.681922 0.861042 0.0823735 0.135406 0.635 0.848739 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 3
Initial state: 0 0.628071 0.871295 0.517999 0.837599 0.00719106 0.811732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703951 episodes
GETTING ACTION FROM:
action 3, numVisits=703917, meanQ=6.234678, numObservations: 3
action 0, numVisits=18, meanQ=4.367697, numObservations: 1
action 1, numVisits=7, meanQ=3.412857, numObservations: 4
action 2, numVisits=7, meanQ=3.285714, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.628071 0.871295 0.517999 0.837599 0.00719106 0.811732 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=75115, meanQ=8.857350, numObservations: 4
action 2, numVisits=39252, meanQ=8.847692, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 853504 episodes
GETTING ACTION FROM:
action 1, numVisits=652765, meanQ=6.777113, numObservations: 4
action 2, numVisits=315104, meanQ=6.773722, numObservations: 4
action 3, numVisits=3, meanQ=2.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.628071 0.871295 0.517999 0.837599 0.00719106 0.811732 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 4
Initial state: 0 0.578118 0.355772 0.51322 0.899185 0.617947 0.851469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690381 episodes
GETTING ACTION FROM:
action 2, numVisits=690314, meanQ=6.226034, numObservations: 5
action -1, numVisits=55, meanQ=5.223881, numObservations: 1
action 1, numVisits=6, meanQ=2.328383, numObservations: 2
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.578118 0.355772 0.51322 0.899185 0.617947 0.851469 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 5
Initial state: 0 0.580998 0.850668 0.24023 0.287816 0.669122 0.864103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697575 episodes
GETTING ACTION FROM:
action 2, numVisits=697528, meanQ=6.166159, numObservations: 4
action -1, numVisits=28, meanQ=4.741420, numObservations: 1
action 0, numVisits=11, meanQ=3.953500, numObservations: 1
action 1, numVisits=6, meanQ=2.663333, numObservations: 2
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 0 0.580998 0.850668 0.24023 0.287816 0.669122 0.864103 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=17213, meanQ=8.678219, numObservations: 4
action 1, numVisits=3, meanQ=2.993333, numObservations: 2
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 855302 episodes
GETTING ACTION FROM:
action 3, numVisits=872279, meanQ=6.590642, numObservations: 4
action 2, numVisits=227, meanQ=6.104538, numObservations: 4
action 1, numVisits=13, meanQ=3.690777, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.580998 0.850668 0.24023 0.287816 0.669122 0.864103 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 6
Initial state: 0 0.611134 0.877792 0.590362 0.382916 0.544688 0.899156 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700468 episodes
GETTING ACTION FROM:
action 2, numVisits=700450, meanQ=6.228065, numObservations: 4
action 1, numVisits=12, meanQ=2.579183, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 2 0.611134 0.877792 0.590362 0.382916 0.544688 0.899156 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 7
Initial state: 0 0.645206 0.866513 0.691981 0.870917 0.363294 0.707373 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700918 episodes
GETTING ACTION FROM:
action 2, numVisits=700780, meanQ=6.236122, numObservations: 4
action -1, numVisits=86, meanQ=5.446258, numObservations: 1
action 0, numVisits=45, meanQ=5.147962, numObservations: 1
action 1, numVisits=6, meanQ=2.333333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.645206 0.866513 0.691981 0.870917 0.363294 0.707373 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 8
Initial state: 0 0.65079 0.842293 0.384129 0.852277 0.657643 0.896972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 710848 episodes
GETTING ACTION FROM:
action 2, numVisits=710814, meanQ=6.228863, numObservations: 3
action 0, numVisits=27, meanQ=4.790909, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.65079 0.842293 0.384129 0.852277 0.657643 0.896972 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=29802, meanQ=8.856055, numObservations: 4
action 1, numVisits=85408, meanQ=8.842688, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 851551 episodes
GETTING ACTION FROM:
action 1, numVisits=636727, meanQ=7.042533, numObservations: 4
action 3, numVisits=330033, meanQ=7.039634, numObservations: 4
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.65079 0.842293 0.384129 0.852277 0.657643 0.896972 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 9
Initial state: 0 0.677867 0.861787 0.571085 0.84311 0.521441 0.158271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 710998 episodes
GETTING ACTION FROM:
action 2, numVisits=710907, meanQ=6.223611, numObservations: 3
action 0, numVisits=81, meanQ=5.410558, numObservations: 1
action 3, numVisits=6, meanQ=2.331683, numObservations: 2
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.677867 0.861787 0.571085 0.84311 0.521441 0.158271 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 10
Initial state: 0 0.0343072 0.888107 0.629965 0.831403 0.593765 0.809547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686596 episodes
GETTING ACTION FROM:
action 3, numVisits=686513, meanQ=6.221873, numObservations: 5
action 0, numVisits=43, meanQ=5.109432, numObservations: 1
action -1, numVisits=32, meanQ=4.912570, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action: 3
Next state: 1 0.0343072 0.888107 0.629965 0.831403 0.593765 0.809547 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 11
Initial state: 0 0.489141 0.68927 0.673893 0.885693 0.517883 0.847803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 705705 episodes
GETTING ACTION FROM:
action 2, numVisits=705685, meanQ=6.308297, numObservations: 4
action 1, numVisits=12, meanQ=3.330842, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.489141 0.68927 0.673893 0.885693 0.517883 0.847803 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 12
Initial state: 0 0.556105 0.0756783 0.584758 0.858503 0.583539 0.83636 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702066 episodes
GETTING ACTION FROM:
action 2, numVisits=701435, meanQ=6.229412, numObservations: 4
action 3, numVisits=625, meanQ=5.708588, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.556105 0.0756783 0.584758 0.858503 0.583539 0.83636 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 13
Initial state: 0 0.850382 0.662312 0.634675 0.836782 0.570132 0.869748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690554 episodes
GETTING ACTION FROM:
action 1, numVisits=690543, meanQ=6.230820, numObservations: 5
action 2, numVisits=5, meanQ=1.396000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.850382 0.662312 0.634675 0.836782 0.570132 0.869748 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 14
Initial state: 0 0.577671 0.839263 0.681748 0.85617 0.492353 0.473691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700539 episodes
GETTING ACTION FROM:
action 2, numVisits=700408, meanQ=6.236792, numObservations: 4
action 3, numVisits=99, meanQ=5.388185, numObservations: 3
action 0, numVisits=19, meanQ=4.531129, numObservations: 1
action 1, numVisits=11, meanQ=3.725455, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.577671 0.839263 0.681748 0.85617 0.492353 0.473691 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 15
Initial state: 0 0.0575676 0.273445 0.531298 0.814405 0.541293 0.849666 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701864 episodes
GETTING ACTION FROM:
action 3, numVisits=701776, meanQ=6.241656, numObservations: 4
action 0, numVisits=39, meanQ=5.057717, numObservations: 1
action -1, numVisits=23, meanQ=4.711273, numObservations: 1
action 1, numVisits=17, meanQ=4.410588, numObservations: 3
action 2, numVisits=9, meanQ=3.663344, numObservations: 2
action: 3
Next state: 1 0.0575676 0.273445 0.531298 0.814405 0.541293 0.849666 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 16
Initial state: 0 0.552435 0.844248 0.972599 0.930728 0.531245 0.861397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 477113 episodes
GETTING ACTION FROM:
action -1, numVisits=477032, meanQ=4.166631, numObservations: 1
action 0, numVisits=76, meanQ=3.346718, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.552435 0.844248 0.972599 0.930728 0.531245 0.861397 w: 1
Observation: 0 0.604047 0 0.940751 0 0.464707 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=477002, meanQ=6.234969, numObservations: 4
action 3, numVisits=18, meanQ=4.483889, numObservations: 3
action 2, numVisits=9, meanQ=3.554444, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 748387 episodes
GETTING ACTION FROM:
action 1, numVisits=1225375, meanQ=6.312838, numObservations: 4
action 3, numVisits=18, meanQ=4.483889, numObservations: 3
action -1, numVisits=14, meanQ=4.297052, numObservations: 1
action 2, numVisits=9, meanQ=3.554444, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.552435 0.844248 0.972599 0.930728 0.531245 0.861397 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 17
Initial state: 0 0.503876 0.877955 0.398054 0.369348 0.564726 0.834427 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692996 episodes
GETTING ACTION FROM:
action 3, numVisits=692968, meanQ=6.214530, numObservations: 4
action 2, numVisits=23, meanQ=4.651743, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.503876 0.877955 0.398054 0.369348 0.564726 0.834427 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 18
Initial state: 0 0.602188 0.817897 0.531703 0.840517 0.623905 0.544526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692266 episodes
GETTING ACTION FROM:
action 2, numVisits=692202, meanQ=6.171077, numObservations: 5
action 0, numVisits=26, meanQ=4.736490, numObservations: 1
action 1, numVisits=34, meanQ=3.050006, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.950000, numObservations: 1
action: 2
Next state: 1 0.602188 0.817897 0.531703 0.840517 0.623905 0.544526 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 19
Initial state: 0 0.568537 0.808007 0.689134 0.887683 0.940801 0.837485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688730 episodes
GETTING ACTION FROM:
action 1, numVisits=688231, meanQ=6.232007, numObservations: 5
action 3, numVisits=324, meanQ=5.824787, numObservations: 3
action 2, numVisits=109, meanQ=5.496794, numObservations: 4
action 0, numVisits=64, meanQ=5.322765, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.568537 0.808007 0.689134 0.887683 0.940801 0.837485 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 20
Initial state: 0 0.196628 0.403283 0.577104 0.882372 0.547605 0.803194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706116 episodes
GETTING ACTION FROM:
action 1, numVisits=706103, meanQ=6.157297, numObservations: 3
action 2, numVisits=7, meanQ=1.854314, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.196628 0.403283 0.577104 0.882372 0.547605 0.803194 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=114594, meanQ=8.847793, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 846639 episodes
GETTING ACTION FROM:
action 2, numVisits=568721, meanQ=6.856534, numObservations: 5
action 3, numVisits=392507, meanQ=6.850567, numObservations: 5
action 1, numVisits=7, meanQ=3.422900, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.196628 0.403283 0.577104 0.882372 0.547605 0.803194 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 21
Initial state: 0 0.589906 0.852109 0.907358 0.453072 0.580975 0.822059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688374 episodes
GETTING ACTION FROM:
action 3, numVisits=688323, meanQ=6.313569, numObservations: 5
action -1, numVisits=41, meanQ=5.158135, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.589906 0.852109 0.907358 0.453072 0.580975 0.822059 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 22
Initial state: 0 0.565226 0.801118 0.590511 0.861092 0.522198 0.103793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 680976 episodes
GETTING ACTION FROM:
action 1, numVisits=680903, meanQ=6.231066, numObservations: 5
action -1, numVisits=68, meanQ=5.345194, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.565226 0.801118 0.590511 0.861092 0.522198 0.103793 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 23
Initial state: 0 0.617262 0.873974 0.541707 0.977322 0.570543 0.880803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685389 episodes
GETTING ACTION FROM:
action 1, numVisits=685381, meanQ=6.148442, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.617262 0.873974 0.541707 0.977322 0.570543 0.880803 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 24
Initial state: 0 0.540384 0.898362 0.669343 0.896069 0.44738 0.576662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696600 episodes
GETTING ACTION FROM:
action 3, numVisits=696524, meanQ=6.237047, numObservations: 4
action -1, numVisits=68, meanQ=5.354148, numObservations: 1
action 2, numVisits=4, meanQ=1.525000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 0 0.540384 0.898362 0.669343 0.896069 0.44738 0.576662 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=95909, meanQ=8.873460, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 852227 episodes
GETTING ACTION FROM:
action 2, numVisits=948072, meanQ=6.661842, numObservations: 4
action 1, numVisits=63, meanQ=5.539365, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.540384 0.898362 0.669343 0.896069 0.44738 0.576662 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 25
Initial state: 0 0.646351 0.84093 0.661076 0.842783 0.873162 0.963574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691024 episodes
GETTING ACTION FROM:
action 1, numVisits=690757, meanQ=6.239918, numObservations: 5
action 3, numVisits=259, meanQ=5.272840, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.646351 0.84093 0.661076 0.842783 0.873162 0.963574 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 26
Initial state: 0 0.733807 0.617139 0.65398 0.808578 0.670995 0.84018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 678610 episodes
GETTING ACTION FROM:
action 1, numVisits=678536, meanQ=6.244476, numObservations: 5
action 0, numVisits=35, meanQ=5.008542, numObservations: 1
action -1, numVisits=21, meanQ=4.527336, numObservations: 1
action 2, numVisits=17, meanQ=4.293535, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.733807 0.617139 0.65398 0.808578 0.670995 0.84018 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.613063 0.825666 0.532131 0.854325 0.845253 0.777517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696568 episodes
GETTING ACTION FROM:
action 1, numVisits=695969, meanQ=6.229615, numObservations: 4
action 2, numVisits=557, meanQ=5.905152, numObservations: 4
action 0, numVisits=38, meanQ=5.036119, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.613063 0.825666 0.532131 0.854325 0.845253 0.777517 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 28
Initial state: 0 0.824487 0.98461 0.681572 0.828497 0.597524 0.888431 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696543 episodes
GETTING ACTION FROM:
action 1, numVisits=696535, meanQ=6.222668, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.824487 0.98461 0.681572 0.828497 0.597524 0.888431 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 29
Initial state: 0 0.655442 0.895826 0.577371 0.842099 0.204718 0.153951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691873 episodes
GETTING ACTION FROM:
action 3, numVisits=691865, meanQ=6.250254, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.655442 0.895826 0.577371 0.842099 0.204718 0.153951 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=95608, meanQ=8.874466, numObservations: 3
action 2, numVisits=13, meanQ=6.768462, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 876783 episodes
GETTING ACTION FROM:
action 1, numVisits=971801, meanQ=6.544262, numObservations: 3
action 2, numVisits=602, meanQ=6.233140, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.655442 0.895826 0.577371 0.842099 0.204718 0.153951 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 30
Initial state: 0 0.645318 0.808041 0.975834 0.735749 0.514332 0.89595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 709441 episodes
GETTING ACTION FROM:
action 3, numVisits=709373, meanQ=6.183042, numObservations: 3
action -1, numVisits=40, meanQ=5.023695, numObservations: 1
action 1, numVisits=24, meanQ=4.411262, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.645318 0.808041 0.975834 0.735749 0.514332 0.89595 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 31
Initial state: 0 0.693967 0.827246 0.529476 0.804134 0.0115658 0.740027 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693410 episodes
GETTING ACTION FROM:
action 1, numVisits=693355, meanQ=6.223557, numObservations: 4
action -1, numVisits=23, meanQ=4.594024, numObservations: 1
action 0, numVisits=11, meanQ=3.882670, numObservations: 1
action 2, numVisits=19, meanQ=3.787905, numObservations: 3
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.693967 0.827246 0.529476 0.804134 0.0115658 0.740027 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 32
Initial state: 0 0.5645 0.892029 0.595585 0.94471 0.63231 0.833905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700182 episodes
GETTING ACTION FROM:
action 1, numVisits=700155, meanQ=6.232381, numObservations: 4
action 0, numVisits=16, meanQ=4.272064, numObservations: 1
action 3, numVisits=7, meanQ=3.282886, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.5645 0.892029 0.595585 0.94471 0.63231 0.833905 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 33
Initial state: 0 0.593001 0.844434 0.527502 0.886786 0.618899 0.896624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698286 episodes
GETTING ACTION FROM:
action 1, numVisits=698279, meanQ=6.308333, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.593001 0.844434 0.527502 0.886786 0.618899 0.896624 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 34
Initial state: 0 0.666691 0.856862 0.703773 0.580422 0.674414 0.815481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686549 episodes
GETTING ACTION FROM:
action 1, numVisits=686541, meanQ=6.226066, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.666691 0.856862 0.703773 0.580422 0.674414 0.815481 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 35
Initial state: 0 0.619909 0.822698 0.56989 0.524763 0.580916 0.840971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698325 episodes
GETTING ACTION FROM:
action 3, numVisits=698273, meanQ=6.236825, numObservations: 4
action 0, numVisits=34, meanQ=4.961846, numObservations: 1
action -1, numVisits=14, meanQ=3.953766, numObservations: 1
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 1 0.619909 0.822698 0.56989 0.524763 0.580916 0.840971 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 36
Initial state: 0 0.084052 0.403454 0.579149 0.894673 0.640593 0.828238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701272 episodes
GETTING ACTION FROM:
action 2, numVisits=701264, meanQ=6.230506, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.084052 0.403454 0.579149 0.894673 0.640593 0.828238 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 37
Initial state: 0 0.635942 0.269679 0.577843 0.823989 0.620104 0.839614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 707211 episodes
GETTING ACTION FROM:
action 1, numVisits=707192, meanQ=6.230339, numObservations: 3
action 0, numVisits=13, meanQ=4.112780, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.635942 0.269679 0.577843 0.823989 0.620104 0.839614 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 38
Initial state: 0 0.534737 0.81999 0.63531 0.893962 0.55809 0.789906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691998 episodes
GETTING ACTION FROM:
action 1, numVisits=691952, meanQ=6.237219, numObservations: 4
action 2, numVisits=31, meanQ=4.902258, numObservations: 5
action 3, numVisits=11, meanQ=2.726364, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.534737 0.81999 0.63531 0.893962 0.55809 0.789906 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 39
Initial state: 0 0.520012 0.807955 0.63655 0.845652 0.423784 0.0940332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698290 episodes
GETTING ACTION FROM:
action 1, numVisits=698277, meanQ=6.248088, numObservations: 4
action 3, numVisits=7, meanQ=1.998571, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.520012 0.807955 0.63655 0.845652 0.423784 0.0940332 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 40
Initial state: 0 0.651913 0.870036 0.585363 0.878922 0.428905 0.171265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700909 episodes
GETTING ACTION FROM:
action 2, numVisits=700866, meanQ=6.257079, numObservations: 4
action 0, numVisits=20, meanQ=4.542883, numObservations: 1
action 3, numVisits=12, meanQ=3.999175, numObservations: 3
action 1, numVisits=9, meanQ=3.554444, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.651913 0.870036 0.585363 0.878922 0.428905 0.171265 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 41
Initial state: 0 0.526385 0.804328 0.306536 0.821276 0.609326 0.818791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690791 episodes
GETTING ACTION FROM:
action 2, numVisits=690310, meanQ=6.231981, numObservations: 5
action 3, numVisits=443, meanQ=5.886149, numObservations: 4
action -1, numVisits=32, meanQ=4.929451, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 0 0.526385 0.804328 0.306536 0.821276 0.609326 0.818791 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=17417, meanQ=8.707083, numObservations: 5
action 3, numVisits=41, meanQ=7.557810, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 839986 episodes
GETTING ACTION FROM:
action 1, numVisits=857284, meanQ=6.674555, numObservations: 5
action 3, numVisits=159, meanQ=6.035725, numObservations: 3
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.526385 0.804328 0.306536 0.821276 0.609326 0.818791 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 42
Initial state: 0 0.607041 0.852682 0.689353 0.899694 0.822229 0.453545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685660 episodes
GETTING ACTION FROM:
action 1, numVisits=685614, meanQ=6.239349, numObservations: 5
action 3, numVisits=36, meanQ=4.984169, numObservations: 4
action 2, numVisits=6, meanQ=2.300000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.607041 0.852682 0.689353 0.899694 0.822229 0.453545 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 43
Initial state: 0 0.688657 0.838452 0.614393 0.209721 0.660717 0.826023 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698800 episodes
GETTING ACTION FROM:
action 1, numVisits=698773, meanQ=6.299935, numObservations: 4
action 3, numVisits=22, meanQ=3.895914, numObservations: 5
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.688657 0.838452 0.614393 0.209721 0.660717 0.826023 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 44
Initial state: 0 0.643767 0.848941 0.692177 0.216749 0.504305 0.849375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699529 episodes
GETTING ACTION FROM:
action 2, numVisits=699484, meanQ=6.232359, numObservations: 4
action 1, numVisits=40, meanQ=4.824250, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.643767 0.848941 0.692177 0.216749 0.504305 0.849375 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=113672, meanQ=8.859212, numObservations: 4
action 2, numVisits=3, meanQ=2.993333, numObservations: 2
action 3, numVisits=3, meanQ=2.330033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 854285 episodes
GETTING ACTION FROM:
action 1, numVisits=967938, meanQ=6.563010, numObservations: 4
action 2, numVisits=16, meanQ=4.123750, numObservations: 3
action 3, numVisits=9, meanQ=3.332244, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.643767 0.848941 0.692177 0.216749 0.504305 0.849375 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 45
Initial state: 0 0.551244 0.815997 0.506429 0.831429 0.280243 0.340437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 677771 episodes
GETTING ACTION FROM:
action 3, numVisits=677735, meanQ=6.063162, numObservations: 4
action 1, numVisits=28, meanQ=3.921436, numObservations: 4
action 2, numVisits=4, meanQ=2.242500, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.551244 0.815997 0.506429 0.831429 0.280243 0.340437 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=92647, meanQ=8.888565, numObservations: 5
action 2, numVisits=12, meanQ=6.747500, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 839450 episodes
GETTING ACTION FROM:
action 1, numVisits=917325, meanQ=6.622249, numObservations: 5
action 2, numVisits=14773, meanQ=6.568860, numObservations: 4
action 3, numVisits=12, meanQ=4.165000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.551244 0.815997 0.506429 0.831429 0.280243 0.340437 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 46
Initial state: 0 0.689296 0.812635 0.621564 0.817962 0.627637 0.617976 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697831 episodes
GETTING ACTION FROM:
action 2, numVisits=697823, meanQ=6.224936, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.689296 0.812635 0.621564 0.817962 0.627637 0.617976 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 47
Initial state: 0 0.662433 0.843754 0.535243 0.839174 0.578897 0.0944489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 707609 episodes
GETTING ACTION FROM:
action 3, numVisits=707563, meanQ=6.223251, numObservations: 3
action -1, numVisits=40, meanQ=5.001799, numObservations: 1
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 2 0.662433 0.843754 0.535243 0.839174 0.578897 0.0944489 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 48
Initial state: 0 0.573598 0.834809 0.564411 0.849891 0.237403 0.043072 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 684870 episodes
GETTING ACTION FROM:
action 3, numVisits=684788, meanQ=6.240999, numObservations: 5
action 0, numVisits=68, meanQ=5.358443, numObservations: 1
action 1, numVisits=11, meanQ=2.726364, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.573598 0.834809 0.564411 0.849891 0.237403 0.043072 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16762, meanQ=8.696033, numObservations: 3
action 2, numVisits=37, meanQ=7.699459, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 872602 episodes
GETTING ACTION FROM:
action 1, numVisits=888386, meanQ=6.775815, numObservations: 3
action 2, numVisits=1014, meanQ=6.545424, numObservations: 5
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.573598 0.834809 0.564411 0.849891 0.237403 0.043072 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 49
Initial state: 0 0.313767 0.620932 0.600795 0.857071 0.545856 0.845298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 711117 episodes
GETTING ACTION FROM:
action 2, numVisits=711096, meanQ=6.237307, numObservations: 3
action 3, numVisits=16, meanQ=3.998763, numObservations: 5
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.313767 0.620932 0.600795 0.857071 0.545856 0.845298 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 50
Initial state: 0 0.569262 0.878873 0.255891 0.985954 0.506034 0.867483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687864 episodes
GETTING ACTION FROM:
action 3, numVisits=686238, meanQ=6.230538, numObservations: 5
action 2, numVisits=1585, meanQ=6.046521, numObservations: 4
action -1, numVisits=37, meanQ=4.979090, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.569262 0.878873 0.255891 0.985954 0.506034 0.867483 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 51
Initial state: 0 0.842478 0.554271 0.597237 0.842281 0.654513 0.875226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697250 episodes
GETTING ACTION FROM:
action 2, numVisits=696690, meanQ=6.241900, numObservations: 4
action 3, numVisits=429, meanQ=5.891720, numObservations: 5
action 1, numVisits=127, meanQ=5.570869, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.842478 0.554271 0.597237 0.842281 0.654513 0.875226 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 52
Initial state: 0 0.516425 0.162076 0.658447 0.85052 0.642677 0.800189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694703 episodes
GETTING ACTION FROM:
action 1, numVisits=692633, meanQ=6.238159, numObservations: 4
action 2, numVisits=1953, meanQ=6.051962, numObservations: 4
action 3, numVisits=79, meanQ=5.416333, numObservations: 4
action 0, numVisits=36, meanQ=5.004327, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.516425 0.162076 0.658447 0.85052 0.642677 0.800189 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 53
Initial state: 0 0.563199 0.893075 0.649772 0.866454 0.22676 0.604363 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687562 episodes
GETTING ACTION FROM:
action 2, numVisits=687506, meanQ=6.172305, numObservations: 4
action 0, numVisits=50, meanQ=5.142621, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.563199 0.893075 0.649772 0.866454 0.22676 0.604363 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 54
Initial state: 0 0.634427 0.835392 0.284816 0.844333 0.625166 0.884742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693605 episodes
GETTING ACTION FROM:
action 3, numVisits=693592, meanQ=6.226036, numObservations: 4
action 1, numVisits=7, meanQ=1.998571, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.634427 0.835392 0.284816 0.844333 0.625166 0.884742 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 55
Initial state: 0 0.61845 0.815835 0.548037 0.816616 0.984718 0.00147509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694898 episodes
GETTING ACTION FROM:
action 1, numVisits=694855, meanQ=6.221114, numObservations: 4
action 0, numVisits=17, meanQ=4.379404, numObservations: 1
action 2, numVisits=17, meanQ=3.699418, numObservations: 4
action 3, numVisits=7, meanQ=1.998571, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.61845 0.815835 0.548037 0.816616 0.984718 0.00147509 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 56
Initial state: 0 0.163288 0.83564 0.626501 0.817909 0.513059 0.84934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686588 episodes
GETTING ACTION FROM:
action 3, numVisits=686568, meanQ=6.218168, numObservations: 5
action 1, numVisits=14, meanQ=3.427143, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.163288 0.83564 0.626501 0.817909 0.513059 0.84934 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 57
Initial state: 0 0.582609 0.895452 0.339145 0.104452 0.652612 0.863339 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686546 episodes
GETTING ACTION FROM:
action 2, numVisits=686495, meanQ=6.230169, numObservations: 5
action 1, numVisits=23, meanQ=4.690439, numObservations: 3
action 0, numVisits=15, meanQ=4.303295, numObservations: 1
action 3, numVisits=11, meanQ=3.725455, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.582609 0.895452 0.339145 0.104452 0.652612 0.863339 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=58587, meanQ=8.886320, numObservations: 5
action 3, numVisits=35411, meanQ=8.878566, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 841443 episodes
GETTING ACTION FROM:
action 1, numVisits=759409, meanQ=6.944665, numObservations: 5
action 3, numVisits=176031, meanQ=6.935396, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.582609 0.895452 0.339145 0.104452 0.652612 0.863339 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 58
Initial state: 0 0.605673 0.820053 0.506878 0.842727 0.0757686 0.614412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688260 episodes
GETTING ACTION FROM:
action 2, numVisits=688228, meanQ=6.236201, numObservations: 5
action -1, numVisits=17, meanQ=4.439054, numObservations: 1
action 3, numVisits=9, meanQ=2.553333, numObservations: 3
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.605673 0.820053 0.506878 0.842727 0.0757686 0.614412 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 59
Initial state: 0 0.0458352 0.653567 0.558688 0.860151 0.542393 0.875589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688116 episodes
GETTING ACTION FROM:
action 3, numVisits=687996, meanQ=6.237295, numObservations: 5
action -1, numVisits=95, meanQ=5.490828, numObservations: 1
action 1, numVisits=21, meanQ=4.501905, numObservations: 4
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.0458352 0.653567 0.558688 0.860151 0.542393 0.875589 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 60
Initial state: 0 0.614905 0.805145 0.801932 0.902082 0.652379 0.853316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706936 episodes
GETTING ACTION FROM:
action 2, numVisits=706687, meanQ=6.243256, numObservations: 3
action 1, numVisits=184, meanQ=5.665492, numObservations: 5
action 3, numVisits=41, meanQ=4.959515, numObservations: 4
action -1, numVisits=22, meanQ=4.538615, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.614905 0.805145 0.801932 0.902082 0.652379 0.853316 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 61
Initial state: 0 0.532493 0.827173 0.624316 0.829797 0.711011 0.888249 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686744 episodes
GETTING ACTION FROM:
action 3, numVisits=686729, meanQ=6.224365, numObservations: 5
action 0, numVisits=10, meanQ=3.690685, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.532493 0.827173 0.624316 0.829797 0.711011 0.888249 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 62
Initial state: 0 0.61764 0.848938 0.366486 0.953177 0.6705 0.838897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690584 episodes
GETTING ACTION FROM:
action 2, numVisits=690506, meanQ=6.167974, numObservations: 5
action -1, numVisits=66, meanQ=5.264001, numObservations: 1
action 3, numVisits=9, meanQ=3.432233, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.61764 0.848938 0.366486 0.953177 0.6705 0.838897 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 63
Initial state: 0 0.569169 0.804732 0.159812 0.56131 0.519747 0.884847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701652 episodes
GETTING ACTION FROM:
action 2, numVisits=701547, meanQ=6.306774, numObservations: 4
action 3, numVisits=69, meanQ=5.363625, numObservations: 4
action -1, numVisits=32, meanQ=4.995937, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.569169 0.804732 0.159812 0.56131 0.519747 0.884847 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=114332, meanQ=8.857909, numObservations: 4
action 1, numVisits=9, meanQ=5.776667, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 845359 episodes
GETTING ACTION FROM:
action 3, numVisits=959667, meanQ=6.775044, numObservations: 4
action 1, numVisits=15, meanQ=4.399333, numObservations: 3
action 2, numVisits=19, meanQ=4.366847, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.569169 0.804732 0.159812 0.56131 0.519747 0.884847 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 64
Initial state: 0 0.63705 0.81347 0.685013 0.818343 0.248223 0.465775 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700796 episodes
GETTING ACTION FROM:
action 3, numVisits=620099, meanQ=6.228083, numObservations: 4
action 1, numVisits=80676, meanQ=6.190817, numObservations: 5
action 2, numVisits=17, meanQ=3.752353, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.63705 0.81347 0.685013 0.818343 0.248223 0.465775 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=67467, meanQ=8.937611, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 850905 episodes
GETTING ACTION FROM:
action 1, numVisits=918366, meanQ=6.817426, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=4, meanQ=1.475000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.63705 0.81347 0.685013 0.818343 0.248223 0.465775 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 65
Initial state: 0 0.216159 0.943119 0.648135 0.810364 0.642064 0.866206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694991 episodes
GETTING ACTION FROM:
action 3, numVisits=694576, meanQ=6.178193, numObservations: 4
action 1, numVisits=333, meanQ=5.753531, numObservations: 4
action -1, numVisits=40, meanQ=5.023847, numObservations: 1
action 2, numVisits=40, meanQ=4.640753, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.216159 0.943119 0.648135 0.810364 0.642064 0.866206 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 66
Initial state: 0 0.983187 0.963614 0.674607 0.820443 0.534188 0.825017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694927 episodes
GETTING ACTION FROM:
action 1, numVisits=694918, meanQ=6.223989, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.983187 0.963614 0.674607 0.820443 0.534188 0.825017 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 67
Initial state: 0 0.121981 0.586711 0.604798 0.837756 0.530144 0.88186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696474 episodes
GETTING ACTION FROM:
action 1, numVisits=679924, meanQ=6.241178, numObservations: 4
action 3, numVisits=10526, meanQ=6.160423, numObservations: 3
action 2, numVisits=5983, meanQ=6.139693, numObservations: 4
action -1, numVisits=39, meanQ=5.040415, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.121981 0.586711 0.604798 0.837756 0.530144 0.88186 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=21443, meanQ=8.653439, numObservations: 4
action 3, numVisits=15649, meanQ=8.645330, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 853655 episodes
GETTING ACTION FROM:
action 2, numVisits=769486, meanQ=6.592946, numObservations: 4
action 3, numVisits=121261, meanQ=6.579303, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.121981 0.586711 0.604798 0.837756 0.530144 0.88186 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 68
Initial state: 0 0.384744 0.878929 0.649512 0.844974 0.549094 0.876269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689754 episodes
GETTING ACTION FROM:
action 1, numVisits=689717, meanQ=6.233678, numObservations: 5
action 0, numVisits=29, meanQ=4.861528, numObservations: 1
action 2, numVisits=4, meanQ=1.745025, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 0 0.384744 0.878929 0.649512 0.844974 0.549094 0.876269 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=17291, meanQ=8.677530, numObservations: 3
action 3, numVisits=43, meanQ=7.650698, numObservations: 4
action 1, numVisits=4, meanQ=4.245025, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 870286 episodes
GETTING ACTION FROM:
action 2, numVisits=885562, meanQ=6.350206, numObservations: 3
action 3, numVisits=2051, meanQ=6.189572, numObservations: 4
action 1, numVisits=9, meanQ=3.552244, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.384744 0.878929 0.649512 0.844974 0.549094 0.876269 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 69
Initial state: 0 0.60039 0.832658 0.515627 0.887094 0.502047 0.0369254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687200 episodes
GETTING ACTION FROM:
action 3, numVisits=687127, meanQ=6.233907, numObservations: 5
action 0, numVisits=42, meanQ=5.077674, numObservations: 1
action 1, numVisits=21, meanQ=2.856667, numObservations: 5
action 2, numVisits=8, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.60039 0.832658 0.515627 0.887094 0.502047 0.0369254 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 70
Initial state: 0 0.552278 0.800188 0.894174 0.422616 0.698223 0.8935 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703433 episodes
GETTING ACTION FROM:
action 1, numVisits=703397, meanQ=6.239285, numObservations: 3
action 3, numVisits=30, meanQ=3.996337, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.552278 0.800188 0.894174 0.422616 0.698223 0.8935 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 71
Initial state: 0 0.634736 0.836483 0.0790089 0.975587 0.534093 0.806215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696761 episodes
GETTING ACTION FROM:
action 3, numVisits=696703, meanQ=6.228621, numObservations: 4
action 0, numVisits=32, meanQ=4.922526, numObservations: 1
action 1, numVisits=22, meanQ=4.453645, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.634736 0.836483 0.0790089 0.975587 0.534093 0.806215 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 72
Initial state: 0 0.502374 0.818117 0.591692 0.897066 0.662745 0.486393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687786 episodes
GETTING ACTION FROM:
action 1, numVisits=687745, meanQ=6.227975, numObservations: 5
action -1, numVisits=25, meanQ=4.731628, numObservations: 1
action 3, numVisits=13, meanQ=3.606169, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.502374 0.818117 0.591692 0.897066 0.662745 0.486393 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 73
Initial state: 0 0.524219 0.854093 0.624981 0.890753 0.520427 0.922418 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690663 episodes
GETTING ACTION FROM:
action 2, numVisits=690625, meanQ=6.214154, numObservations: 5
action 0, numVisits=33, meanQ=4.920617, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.524219 0.854093 0.624981 0.890753 0.520427 0.922418 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 74
Initial state: 0 0.624624 0.873155 0.209997 0.0355447 0.60022 0.899372 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700236 episodes
GETTING ACTION FROM:
action 2, numVisits=700223, meanQ=6.216676, numObservations: 4
action 1, numVisits=7, meanQ=1.998571, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.624624 0.873155 0.209997 0.0355447 0.60022 0.899372 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=90259, meanQ=8.855069, numObservations: 4
action 1, numVisits=23469, meanQ=8.824098, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 854220 episodes
GETTING ACTION FROM:
action 3, numVisits=787919, meanQ=6.638970, numObservations: 4
action 1, numVisits=180026, meanQ=6.630302, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.624624 0.873155 0.209997 0.0355447 0.60022 0.899372 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 75
Initial state: 0 0.50912 0.855641 0.673973 0.807739 0.893277 0.274283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702588 episodes
GETTING ACTION FROM:
action 2, numVisits=702556, meanQ=6.226539, numObservations: 4
action 0, numVisits=28, meanQ=4.779327, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.50912 0.855641 0.673973 0.807739 0.893277 0.274283 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 76
Initial state: 0 0.259675 0.929376 0.652906 0.867171 0.547934 0.822895 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690931 episodes
GETTING ACTION FROM:
action 1, numVisits=690923, meanQ=6.232444, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.259675 0.929376 0.652906 0.867171 0.547934 0.822895 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=37532, meanQ=8.671859, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 856647 episodes
GETTING ACTION FROM:
action 3, numVisits=894171, meanQ=6.913261, numObservations: 4
action 1, numVisits=5, meanQ=3.198000, numObservations: 2
action 2, numVisits=5, meanQ=3.198000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.259675 0.929376 0.652906 0.867171 0.547934 0.822895 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 77
Initial state: 0 0.527898 0.84223 0.709647 0.877417 0.532828 0.875596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697645 episodes
GETTING ACTION FROM:
action 3, numVisits=697635, meanQ=6.227601, numObservations: 4
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.527898 0.84223 0.709647 0.877417 0.532828 0.875596 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 78
Initial state: 0 0.520102 0.652463 0.670588 0.860142 0.656282 0.892859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687848 episodes
GETTING ACTION FROM:
action 2, numVisits=687841, meanQ=6.235833, numObservations: 5
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.520102 0.652463 0.670588 0.860142 0.656282 0.892859 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 79
Initial state: 0 0.680147 0.864281 0.690725 0.864388 0.9976 0.64982 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696565 episodes
GETTING ACTION FROM:
action 1, numVisits=696546, meanQ=6.230634, numObservations: 4
action -1, numVisits=15, meanQ=4.257142, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.680147 0.864281 0.690725 0.864388 0.9976 0.64982 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 80
Initial state: 0 0.631133 0.890232 0.974335 0.264009 0.590114 0.849739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699439 episodes
GETTING ACTION FROM:
action 1, numVisits=699330, meanQ=6.232954, numObservations: 4
action 0, numVisits=75, meanQ=5.387326, numObservations: 1
action 3, numVisits=27, meanQ=4.514819, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.631133 0.890232 0.974335 0.264009 0.590114 0.849739 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 81
Initial state: 0 0.640469 0.875917 0.598814 0.889267 0.16236 0.3283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685611 episodes
GETTING ACTION FROM:
action 3, numVisits=684505, meanQ=6.234717, numObservations: 5
action 1, numVisits=1065, meanQ=5.994345, numObservations: 5
action -1, numVisits=37, meanQ=4.945423, numObservations: 1
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 0 0.640469 0.875917 0.598814 0.889267 0.16236 0.3283 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=40292, meanQ=8.939528, numObservations: 3
action 1, numVisits=33887, meanQ=8.936465, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 838036 episodes
GETTING ACTION FROM:
action 1, numVisits=654965, meanQ=6.715610, numObservations: 5
action 2, numVisits=257246, meanQ=6.709823, numObservations: 4
action 3, numVisits=5, meanQ=2.980000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.640469 0.875917 0.598814 0.889267 0.16236 0.3283 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 82
Initial state: 0 0.562018 0.851333 0.525017 0.527773 0.675944 0.863471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699731 episodes
GETTING ACTION FROM:
action 1, numVisits=697990, meanQ=6.226451, numObservations: 4
action 3, numVisits=1658, meanQ=5.989100, numObservations: 5
action 0, numVisits=45, meanQ=5.119733, numObservations: 1
action -1, numVisits=37, meanQ=5.010355, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.562018 0.851333 0.525017 0.527773 0.675944 0.863471 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 83
Initial state: 0 0.925471 0.733318 0.504943 0.802212 0.631347 0.847167 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694522 episodes
GETTING ACTION FROM:
action 1, numVisits=694190, meanQ=6.223573, numObservations: 4
action 2, numVisits=217, meanQ=5.667978, numObservations: 4
action 0, numVisits=84, meanQ=5.428497, numObservations: 1
action 3, numVisits=29, meanQ=4.744838, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.925471 0.733318 0.504943 0.802212 0.631347 0.847167 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 84
Initial state: 0 0.552799 0.841187 0.183709 0.0648134 0.698057 0.865334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690516 episodes
GETTING ACTION FROM:
action 2, numVisits=690503, meanQ=6.245936, numObservations: 5
action 3, numVisits=7, meanQ=3.257143, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.552799 0.841187 0.183709 0.0648134 0.698057 0.865334 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=18056, meanQ=8.682384, numObservations: 5
action 3, numVisits=19579, meanQ=8.674790, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 840537 episodes
GETTING ACTION FROM:
action 3, numVisits=619210, meanQ=6.414514, numObservations: 5
action 1, numVisits=258776, meanQ=6.409298, numObservations: 5
action 2, numVisits=187, meanQ=5.871178, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.552799 0.841187 0.183709 0.0648134 0.698057 0.865334 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 85
Initial state: 0 0.0207587 0.349207 0.692036 0.835203 0.680796 0.80505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691388 episodes
GETTING ACTION FROM:
action 1, numVisits=691325, meanQ=6.230251, numObservations: 5
action 0, numVisits=51, meanQ=5.174305, numObservations: 1
action 2, numVisits=8, meanQ=2.872512, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0207587 0.349207 0.692036 0.835203 0.680796 0.80505 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=70532, meanQ=8.881054, numObservations: 4
action 2, numVisits=24387, meanQ=8.862962, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 851247 episodes
GETTING ACTION FROM:
action 3, numVisits=790973, meanQ=6.607885, numObservations: 4
action 2, numVisits=155190, meanQ=6.597411, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0207587 0.349207 0.692036 0.835203 0.680796 0.80505 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 86
Initial state: 0 0.543912 0.839657 0.956183 0.888795 0.659009 0.870492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703434 episodes
GETTING ACTION FROM:
action 2, numVisits=703390, meanQ=6.224380, numObservations: 4
action -1, numVisits=22, meanQ=4.578680, numObservations: 1
action 3, numVisits=19, meanQ=3.261589, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.543912 0.839657 0.956183 0.888795 0.659009 0.870492 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 87
Initial state: 0 0.666685 0.874324 0.963531 0.993689 0.607621 0.899106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699673 episodes
GETTING ACTION FROM:
action 1, numVisits=699635, meanQ=6.229877, numObservations: 4
action 3, numVisits=32, meanQ=3.498750, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.666685 0.874324 0.963531 0.993689 0.607621 0.899106 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 88
Initial state: 0 0.86614 0.823674 0.651937 0.894454 0.56264 0.869905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697059 episodes
GETTING ACTION FROM:
action 1, numVisits=697014, meanQ=6.232564, numObservations: 4
action 3, numVisits=39, meanQ=4.579492, numObservations: 4
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.86614 0.823674 0.651937 0.894454 0.56264 0.869905 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 89
Initial state: 0 0.0521043 0.11706 0.625867 0.852193 0.667276 0.834294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688160 episodes
GETTING ACTION FROM:
action 1, numVisits=688097, meanQ=6.226064, numObservations: 5
action 2, numVisits=57, meanQ=5.002461, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0521043 0.11706 0.625867 0.852193 0.667276 0.834294 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=57355, meanQ=8.878429, numObservations: 3
action 3, numVisits=37337, meanQ=8.869847, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 851941 episodes
GETTING ACTION FROM:
action 2, numVisits=700627, meanQ=6.873351, numObservations: 3
action 3, numVisits=246005, meanQ=6.866858, numObservations: 5
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.0521043 0.11706 0.625867 0.852193 0.667276 0.834294 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 90
Initial state: 0 0.477343 0.171413 0.601387 0.800637 0.560782 0.85917 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 471461 episodes
GETTING ACTION FROM:
action -1, numVisits=471433, meanQ=4.155368, numObservations: 1
action 2, numVisits=22, meanQ=1.861823, numObservations: 5
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.477343 0.171413 0.601387 0.800637 0.560782 0.85917 w: 1
Observation: 0 0.379066 0 0.654266 0 0.480633 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=470774, meanQ=6.224322, numObservations: 5
action 1, numVisits=652, meanQ=5.944250, numObservations: 5
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 737473 episodes
GETTING ACTION FROM:
action 1, numVisits=578180, meanQ=6.423972, numObservations: 5
action 3, numVisits=630644, meanQ=6.168797, numObservations: 5
action 0, numVisits=75, meanQ=5.331892, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.477343 0.171413 0.601387 0.800637 0.560782 0.85917 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=35399, meanQ=8.937356, numObservations: 3
action 3, numVisits=28893, meanQ=8.933601, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 853635 episodes
GETTING ACTION FROM:
action 2, numVisits=625132, meanQ=6.582757, numObservations: 4
action 3, numVisits=292794, meanQ=6.579124, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 1 0.477343 0.171413 0.601387 0.800637 0.560782 0.85917 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 5.8309
Run # 91
Initial state: 0 0.894962 0.497948 0.512156 0.872563 0.52562 0.85627 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697402 episodes
GETTING ACTION FROM:
action 1, numVisits=697328, meanQ=6.234033, numObservations: 4
action 0, numVisits=67, meanQ=5.339723, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.894962 0.497948 0.512156 0.872563 0.52562 0.85627 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=30662, meanQ=6.506347, numObservations: 4
action 3, numVisits=363, meanQ=5.650010, numObservations: 5
action 1, numVisits=9, meanQ=3.663344, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 861270 episodes
GETTING ACTION FROM:
action 2, numVisits=891932, meanQ=6.474498, numObservations: 4
action 3, numVisits=363, meanQ=5.650010, numObservations: 5
action 1, numVisits=9, meanQ=3.663344, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.894962 0.497948 0.512156 0.872563 0.52562 0.85627 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 92
Initial state: 0 0.65149 0.844646 0.632646 0.858311 0.359556 0.940162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692485 episodes
GETTING ACTION FROM:
action 1, numVisits=692415, meanQ=6.227121, numObservations: 5
action 2, numVisits=63, meanQ=5.167941, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.65149 0.844646 0.632646 0.858311 0.359556 0.940162 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 93
Initial state: 0 0.605335 0.899325 0.577986 0.452425 0.601498 0.878798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 681715 episodes
GETTING ACTION FROM:
action 1, numVisits=681625, meanQ=6.183000, numObservations: 5
action 0, numVisits=61, meanQ=5.248065, numObservations: 1
action -1, numVisits=22, meanQ=4.607385, numObservations: 1
action 3, numVisits=6, meanQ=2.331683, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.605335 0.899325 0.577986 0.452425 0.601498 0.878798 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 94
Initial state: 0 0.303139 0.540875 0.660011 0.832501 0.643583 0.863901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686576 episodes
GETTING ACTION FROM:
action 1, numVisits=686524, meanQ=6.239853, numObservations: 5
action -1, numVisits=35, meanQ=4.998275, numObservations: 1
action 3, numVisits=11, meanQ=3.725455, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.303139 0.540875 0.660011 0.832501 0.643583 0.863901 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=74342, meanQ=8.888947, numObservations: 4
action 3, numVisits=20234, meanQ=8.863835, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 852532 episodes
GETTING ACTION FROM:
action 3, numVisits=515651, meanQ=6.820297, numObservations: 4
action 2, numVisits=431391, meanQ=6.819021, numObservations: 4
action 1, numVisits=67, meanQ=5.896419, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.303139 0.540875 0.660011 0.832501 0.643583 0.863901 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 95
Initial state: 0 0.671614 0.873171 0.251379 0.993991 0.697995 0.874742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702048 episodes
GETTING ACTION FROM:
action 2, numVisits=702017, meanQ=6.220727, numObservations: 4
action -1, numVisits=23, meanQ=4.635671, numObservations: 1
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.671614 0.873171 0.251379 0.993991 0.697995 0.874742 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 96
Initial state: 0 0.647272 0.854063 0.465499 0.537468 0.628509 0.89914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688039 episodes
GETTING ACTION FROM:
action 1, numVisits=682463, meanQ=6.182206, numObservations: 5
action 2, numVisits=5570, meanQ=6.065664, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.647272 0.854063 0.465499 0.537468 0.628509 0.89914 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=30406, meanQ=5.459228, numObservations: 4
action 2, numVisits=105, meanQ=4.817622, numObservations: 5
action 3, numVisits=6, meanQ=0.831667, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 772051 episodes
GETTING ACTION FROM:
action 1, numVisits=802454, meanQ=6.170364, numObservations: 5
action 2, numVisits=105, meanQ=4.817622, numObservations: 5
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 3, numVisits=6, meanQ=0.831667, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.647272 0.854063 0.465499 0.537468 0.628509 0.89914 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 97
Initial state: 0 0.566577 0.809648 0.16671 0.980237 0.600427 0.82742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703996 episodes
GETTING ACTION FROM:
action 1, numVisits=703972, meanQ=6.239010, numObservations: 3
action -1, numVisits=20, meanQ=4.594633, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.566577 0.809648 0.16671 0.980237 0.600427 0.82742 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31816, meanQ=6.539391, numObservations: 5
action 1, numVisits=22, meanQ=4.445455, numObservations: 3
action 3, numVisits=8, meanQ=4.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 843891 episodes
GETTING ACTION FROM:
action 2, numVisits=875702, meanQ=6.469216, numObservations: 5
action 1, numVisits=22, meanQ=4.445455, numObservations: 3
action 3, numVisits=13, meanQ=4.384615, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.566577 0.809648 0.16671 0.980237 0.600427 0.82742 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=822, meanQ=7.300174, numObservations: 3
action 3, numVisits=6, meanQ=4.165000, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 863129 episodes
GETTING ACTION FROM:
action 3, numVisits=861627, meanQ=6.617959, numObservations: 4
action 2, numVisits=2326, meanQ=6.322843, numObservations: 4
action 1, numVisits=5, meanQ=3.198000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.566577 0.809648 0.16671 0.980237 0.600427 0.82742 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 98
Initial state: 0 0.397385 0.434153 0.541678 0.825935 0.636984 0.847995 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687777 episodes
GETTING ACTION FROM:
action 3, numVisits=687651, meanQ=6.241773, numObservations: 5
action -1, numVisits=113, meanQ=5.557641, numObservations: 1
action 2, numVisits=6, meanQ=2.331683, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.397385 0.434153 0.541678 0.825935 0.636984 0.847995 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 99
Initial state: 0 0.608933 0.830788 0.605451 0.8139 0.271102 0.682904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698431 episodes
GETTING ACTION FROM:
action 1, numVisits=698374, meanQ=6.226136, numObservations: 4
action -1, numVisits=25, meanQ=4.717569, numObservations: 1
action 2, numVisits=26, meanQ=4.341169, numObservations: 3
action 3, numVisits=4, meanQ=-1.002475, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.608933 0.830788 0.605451 0.8139 0.271102 0.682904 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 100
Initial state: 0 0.549347 0.832131 0.247697 0.600446 0.587856 0.801758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690074 episodes
GETTING ACTION FROM:
action 1, numVisits=688703, meanQ=6.239840, numObservations: 5
action 2, numVisits=1335, meanQ=5.907058, numObservations: 4
action 0, numVisits=33, meanQ=4.961716, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.549347 0.832131 0.247697 0.600446 0.587856 0.801758 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 101
Initial state: 0 0.696815 0.87925 0.618615 0.868397 0.835907 0.717362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695435 episodes
GETTING ACTION FROM:
action 3, numVisits=695428, meanQ=6.216976, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.696815 0.87925 0.618615 0.868397 0.835907 0.717362 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 102
Initial state: 0 0.508128 0.88173 0.26497 0.403324 0.699381 0.884974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698105 episodes
GETTING ACTION FROM:
action 1, numVisits=698071, meanQ=6.219914, numObservations: 4
action -1, numVisits=21, meanQ=4.625948, numObservations: 1
action 0, numVisits=10, meanQ=3.542020, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.508128 0.88173 0.26497 0.403324 0.699381 0.884974 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30938, meanQ=6.473268, numObservations: 4
action 1, numVisits=21, meanQ=3.280481, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 855672 episodes
GETTING ACTION FROM:
action 3, numVisits=886608, meanQ=6.201984, numObservations: 4
action 1, numVisits=21, meanQ=3.280481, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.508128 0.88173 0.26497 0.403324 0.699381 0.884974 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 103
Initial state: 0 0.564008 0.861468 0.209506 0.826649 0.548966 0.800357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693295 episodes
GETTING ACTION FROM:
action 2, numVisits=693210, meanQ=6.241349, numObservations: 5
action -1, numVisits=77, meanQ=5.413725, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 0 0.564008 0.861468 0.209506 0.826649 0.548966 0.800357 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=17352, meanQ=8.614662, numObservations: 4
action 1, numVisits=473, meanQ=8.355540, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 856440 episodes
GETTING ACTION FROM:
action 3, numVisits=851323, meanQ=6.264893, numObservations: 4
action 1, numVisits=22939, meanQ=6.223872, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 1 0.564008 0.861468 0.209506 0.826649 0.548966 0.800357 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 104
Initial state: 0 0.982397 0.811328 0.512974 0.825493 0.69274 0.800958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696150 episodes
GETTING ACTION FROM:
action 3, numVisits=696022, meanQ=6.238042, numObservations: 4
action 0, numVisits=40, meanQ=5.071467, numObservations: 1
action 2, numVisits=50, meanQ=4.950202, numObservations: 5
action -1, numVisits=27, meanQ=4.815466, numObservations: 1
action 1, numVisits=11, meanQ=3.725455, numObservations: 3
action: 3
Next state: 1 0.982397 0.811328 0.512974 0.825493 0.69274 0.800958 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 105
Initial state: 0 0.378928 0.759406 0.591696 0.8042 0.576283 0.857834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689072 episodes
GETTING ACTION FROM:
action 2, numVisits=689063, meanQ=6.299454, numObservations: 5
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.378928 0.759406 0.591696 0.8042 0.576283 0.857834 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 106
Initial state: 0 0.891086 0.610605 0.510571 0.883798 0.570177 0.817166 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695441 episodes
GETTING ACTION FROM:
action 3, numVisits=695394, meanQ=6.309726, numObservations: 4
action 1, numVisits=41, meanQ=4.877322, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.891086 0.610605 0.510571 0.883798 0.570177 0.817166 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 107
Initial state: 0 0.606535 0.803449 0.662585 0.871337 0.75429 0.456063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 709755 episodes
GETTING ACTION FROM:
action 2, numVisits=680549, meanQ=6.234055, numObservations: 3
action 1, numVisits=29062, meanQ=6.197854, numObservations: 3
action 0, numVisits=49, meanQ=5.171461, numObservations: 1
action -1, numVisits=46, meanQ=5.146426, numObservations: 1
action 3, numVisits=49, meanQ=5.027347, numObservations: 4
action: 2
Next state: 1 0.606535 0.803449 0.662585 0.871337 0.75429 0.456063 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 108
Initial state: 0 0.569738 0.84914 0.754845 0.706486 0.665394 0.821329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689814 episodes
GETTING ACTION FROM:
action 3, numVisits=689680, meanQ=6.310932, numObservations: 5
action 0, numVisits=87, meanQ=5.520511, numObservations: 1
action 1, numVisits=35, meanQ=4.905723, numObservations: 5
action 2, numVisits=10, meanQ=3.296010, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.569738 0.84914 0.754845 0.706486 0.665394 0.821329 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 109
Initial state: 0 0.625688 0.906654 0.559836 0.842315 0.585776 0.834042 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 711393 episodes
GETTING ACTION FROM:
action 2, numVisits=711386, meanQ=6.226677, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.625688 0.906654 0.559836 0.842315 0.585776 0.834042 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32031, meanQ=6.499869, numObservations: 4
action 2, numVisits=5, meanQ=3.198000, numObservations: 1
action 3, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 850816 episodes
GETTING ACTION FROM:
action 1, numVisits=882813, meanQ=6.393433, numObservations: 4
action 3, numVisits=33, meanQ=5.090606, numObservations: 4
action 2, numVisits=9, meanQ=3.554444, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.625688 0.906654 0.559836 0.842315 0.585776 0.834042 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 110
Initial state: 0 0.597592 0.830405 0.287674 0.119319 0.677051 0.848516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696414 episodes
GETTING ACTION FROM:
action 3, numVisits=696380, meanQ=6.321060, numObservations: 4
action 2, numVisits=22, meanQ=3.498655, numObservations: 3
action 1, numVisits=10, meanQ=2.999010, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.597592 0.830405 0.287674 0.119319 0.677051 0.848516 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 111
Initial state: 0 0.619858 0.721774 0.665688 0.866796 0.694143 0.834261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687718 episodes
GETTING ACTION FROM:
action 3, numVisits=687708, meanQ=6.239488, numObservations: 5
action 1, numVisits=5, meanQ=1.396000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.619858 0.721774 0.665688 0.866796 0.694143 0.834261 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 112
Initial state: 0 0.875542 0.320933 0.58277 0.891656 0.641563 0.894693 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692154 episodes
GETTING ACTION FROM:
action 2, numVisits=692073, meanQ=6.221372, numObservations: 5
action 0, numVisits=61, meanQ=5.280807, numObservations: 1
action 1, numVisits=17, meanQ=4.293535, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.875542 0.320933 0.58277 0.891656 0.641563 0.894693 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 113
Initial state: 0 0.512294 0.845257 0.502811 0.850244 0.200514 0.447602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699885 episodes
GETTING ACTION FROM:
action 2, numVisits=699855, meanQ=6.215753, numObservations: 4
action -1, numVisits=17, meanQ=4.397788, numObservations: 1
action 1, numVisits=9, meanQ=3.433333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.512294 0.845257 0.502811 0.850244 0.200514 0.447602 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 114
Initial state: 0 0.663186 0.819958 0.621631 0.815804 0.842541 0.911364 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698560 episodes
GETTING ACTION FROM:
action 1, numVisits=698547, meanQ=6.220847, numObservations: 4
action 2, numVisits=6, meanQ=2.663333, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.663186 0.819958 0.621631 0.815804 0.842541 0.911364 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 115
Initial state: 0 0.529426 0.874637 0.543187 0.828232 0.699731 0.885949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696996 episodes
GETTING ACTION FROM:
action 1, numVisits=696959, meanQ=6.214391, numObservations: 4
action 0, numVisits=24, meanQ=4.722789, numObservations: 1
action 3, numVisits=10, meanQ=3.198000, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.529426 0.874637 0.543187 0.828232 0.699731 0.885949 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 116
Initial state: 0 0.54574 0.888691 0.575906 0.820147 0.818835 0.770336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697094 episodes
GETTING ACTION FROM:
action 2, numVisits=697049, meanQ=6.237763, numObservations: 5
action -1, numVisits=16, meanQ=4.332653, numObservations: 1
action 1, numVisits=19, meanQ=3.314216, numObservations: 4
action 3, numVisits=8, meanQ=2.872513, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.54574 0.888691 0.575906 0.820147 0.818835 0.770336 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 117
Initial state: 0 0.57044 0.849736 0.601984 0.890445 0.158023 0.382392 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700776 episodes
GETTING ACTION FROM:
action 2, numVisits=698985, meanQ=6.245574, numObservations: 4
action 3, numVisits=1769, meanQ=6.060474, numObservations: 5
action 0, numVisits=15, meanQ=4.347968, numObservations: 1
action 1, numVisits=5, meanQ=1.396000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.57044 0.849736 0.601984 0.890445 0.158023 0.382392 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 118
Initial state: 0 0.64147 0.824341 0.639323 0.893063 0.463089 0.27149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698011 episodes
GETTING ACTION FROM:
action 1, numVisits=697996, meanQ=6.160565, numObservations: 4
action -1, numVisits=11, meanQ=3.944050, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.64147 0.824341 0.639323 0.893063 0.463089 0.27149 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 119
Initial state: 0 0.569581 0.850622 0.721561 0.358732 0.658702 0.88487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692083 episodes
GETTING ACTION FROM:
action 2, numVisits=692072, meanQ=6.232922, numObservations: 5
action 3, numVisits=6, meanQ=2.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.569581 0.850622 0.721561 0.358732 0.658702 0.88487 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 120
Initial state: 0 0.707981 0.425914 0.691417 0.870555 0.574295 0.881988 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695679 episodes
GETTING ACTION FROM:
action 1, numVisits=695630, meanQ=6.231891, numObservations: 4
action -1, numVisits=38, meanQ=5.045388, numObservations: 1
action 3, numVisits=7, meanQ=3.284300, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.707981 0.425914 0.691417 0.870555 0.574295 0.881988 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 121
Initial state: 0 0.590051 0.839758 0.691091 0.80875 0.15401 0.080217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685225 episodes
GETTING ACTION FROM:
action 3, numVisits=685213, meanQ=6.223973, numObservations: 5
action 2, numVisits=7, meanQ=1.998571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.590051 0.839758 0.691091 0.80875 0.15401 0.080217 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=60472, meanQ=8.889021, numObservations: 5
action 1, numVisits=33216, meanQ=8.879842, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 837938 episodes
GETTING ACTION FROM:
action 2, numVisits=673387, meanQ=6.679004, numObservations: 5
action 1, numVisits=258238, meanQ=6.673086, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.590051 0.839758 0.691091 0.80875 0.15401 0.080217 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 122
Initial state: 0 0.690567 0.823112 0.0565629 0.9202 0.625022 0.877324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 709906 episodes
GETTING ACTION FROM:
action 2, numVisits=709815, meanQ=6.237440, numObservations: 3
action -1, numVisits=74, meanQ=5.376149, numObservations: 1
action 1, numVisits=12, meanQ=3.414167, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.690567 0.823112 0.0565629 0.9202 0.625022 0.877324 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31946, meanQ=6.522319, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 859047 episodes
GETTING ACTION FROM:
action 1, numVisits=890992, meanQ=6.822993, numObservations: 4
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.690567 0.823112 0.0565629 0.9202 0.625022 0.877324 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=8802, meanQ=7.975399, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 866453 episodes
GETTING ACTION FROM:
action 3, numVisits=875255, meanQ=6.522577, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.690567 0.823112 0.0565629 0.9202 0.625022 0.877324 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 123
Initial state: 0 0.667952 0.885394 0.692418 0.894805 0.682864 0.117644 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697596 episodes
GETTING ACTION FROM:
action 1, numVisits=697586, meanQ=6.228319, numObservations: 4
action 3, numVisits=4, meanQ=-1.002475, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.667952 0.885394 0.692418 0.894805 0.682864 0.117644 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 124
Initial state: 0 0.644388 0.840723 0.665823 0.835898 0.600859 0.904378 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685067 episodes
GETTING ACTION FROM:
action 3, numVisits=685032, meanQ=6.171326, numObservations: 5
action 0, numVisits=29, meanQ=4.806180, numObservations: 1
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.644388 0.840723 0.665823 0.835898 0.600859 0.904378 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 125
Initial state: 0 0.6941 0.837604 0.900393 0.174233 0.565334 0.869685 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686972 episodes
GETTING ACTION FROM:
action 3, numVisits=686883, meanQ=6.174125, numObservations: 5
action -1, numVisits=48, meanQ=5.120974, numObservations: 1
action 1, numVisits=29, meanQ=4.779659, numObservations: 4
action 2, numVisits=10, meanQ=3.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.6941 0.837604 0.900393 0.174233 0.565334 0.869685 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 126
Initial state: 0 0.822694 0.694171 0.628164 0.829727 0.541287 0.831749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 710064 episodes
GETTING ACTION FROM:
action 1, numVisits=710012, meanQ=6.228895, numObservations: 3
action -1, numVisits=33, meanQ=4.904352, numObservations: 1
action 2, numVisits=15, meanQ=3.066000, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 2 0.822694 0.694171 0.628164 0.829727 0.541287 0.831749 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 127
Initial state: 0 0.541749 0.848676 0.102743 0.172442 0.697324 0.89743 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694819 episodes
GETTING ACTION FROM:
action 3, numVisits=693915, meanQ=6.253738, numObservations: 4
action 2, numVisits=868, meanQ=5.999370, numObservations: 5
action 1, numVisits=20, meanQ=4.553510, numObservations: 3
action 0, numVisits=14, meanQ=4.182924, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.541749 0.848676 0.102743 0.172442 0.697324 0.89743 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 128
Initial state: 0 0.650648 0.842667 0.812772 0.664108 0.577806 0.817362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692856 episodes
GETTING ACTION FROM:
action 2, numVisits=692721, meanQ=6.235308, numObservations: 5
action 3, numVisits=106, meanQ=5.447455, numObservations: 4
action 0, numVisits=26, meanQ=4.751909, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.650648 0.842667 0.812772 0.664108 0.577806 0.817362 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 129
Initial state: 0 0.759274 0.192661 0.670846 0.844903 0.692248 0.803017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698121 episodes
GETTING ACTION FROM:
action 3, numVisits=698109, meanQ=6.221532, numObservations: 4
action 1, numVisits=7, meanQ=1.998571, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.759274 0.192661 0.670846 0.844903 0.692248 0.803017 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 130
Initial state: 0 0.616229 0.849754 0.691093 0.88443 0.446569 0.263355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703202 episodes
GETTING ACTION FROM:
action 3, numVisits=703118, meanQ=6.221754, numObservations: 3
action 0, numVisits=44, meanQ=5.085269, numObservations: 1
action -1, numVisits=37, meanQ=4.984668, numObservations: 1
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.616229 0.849754 0.691093 0.88443 0.446569 0.263355 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=89026, meanQ=8.866146, numObservations: 4
action 1, numVisits=25074, meanQ=8.844379, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 849717 episodes
GETTING ACTION FROM:
action 2, numVisits=695963, meanQ=6.932007, numObservations: 4
action 1, numVisits=267842, meanQ=6.926544, numObservations: 5
action 3, numVisits=13, meanQ=4.453077, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.616229 0.849754 0.691093 0.88443 0.446569 0.263355 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 131
Initial state: 0 0.578077 0.83512 0.934223 0.0242818 0.56979 0.839175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701626 episodes
GETTING ACTION FROM:
action 2, numVisits=701609, meanQ=6.226932, numObservations: 4
action 0, numVisits=13, meanQ=4.068256, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.578077 0.83512 0.934223 0.0242818 0.56979 0.839175 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 132
Initial state: 0 0.619201 0.865374 0.692964 0.896696 0.485397 0.108053 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688984 episodes
GETTING ACTION FROM:
action 3, numVisits=688964, meanQ=6.233149, numObservations: 5
action 1, numVisits=15, meanQ=2.398673, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.619201 0.865374 0.692964 0.896696 0.485397 0.108053 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=58044, meanQ=8.897009, numObservations: 4
action 2, numVisits=35618, meanQ=8.887842, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 856427 episodes
GETTING ACTION FROM:
action 1, numVisits=487352, meanQ=6.632344, numObservations: 4
action 2, numVisits=462718, meanQ=6.632121, numObservations: 4
action 3, numVisits=20, meanQ=4.435005, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.619201 0.865374 0.692964 0.896696 0.485397 0.108053 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 133
Initial state: 0 0.592005 0.887713 0.250476 0.747368 0.636876 0.846358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692036 episodes
GETTING ACTION FROM:
action 2, numVisits=692029, meanQ=6.231360, numObservations: 5
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.592005 0.887713 0.250476 0.747368 0.636876 0.846358 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=62271, meanQ=8.886922, numObservations: 5
action 3, numVisits=33078, meanQ=8.877193, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 844857 episodes
GETTING ACTION FROM:
action 1, numVisits=555922, meanQ=6.599522, numObservations: 5
action 3, numVisits=384259, meanQ=6.597481, numObservations: 4
action 2, numVisits=26, meanQ=5.104231, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.592005 0.887713 0.250476 0.747368 0.636876 0.846358 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 134
Initial state: 0 0.546062 0.809753 0.548051 0.88641 0.112438 0.964156 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697214 episodes
GETTING ACTION FROM:
action 1, numVisits=697198, meanQ=6.227483, numObservations: 4
action 2, numVisits=8, meanQ=2.873750, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.546062 0.809753 0.548051 0.88641 0.112438 0.964156 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 135
Initial state: 0 0.643223 0.825704 0.552148 0.820465 0.312078 0.969681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 684439 episodes
GETTING ACTION FROM:
action 3, numVisits=684331, meanQ=6.320515, numObservations: 5
action 1, numVisits=104, meanQ=4.974616, numObservations: 4
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.643223 0.825704 0.552148 0.820465 0.312078 0.969681 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 136
Initial state: 0 0.523006 0.865682 0.228722 0.847601 0.532248 0.81843 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695410 episodes
GETTING ACTION FROM:
action 1, numVisits=695326, meanQ=6.238163, numObservations: 4
action 2, numVisits=46, meanQ=5.058698, numObservations: 3
action -1, numVisits=29, meanQ=4.881102, numObservations: 1
action 3, numVisits=7, meanQ=1.687143, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.523006 0.865682 0.228722 0.847601 0.532248 0.81843 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 137
Initial state: 0 0.542155 0.852504 0.25965 0.928606 0.567669 0.856424 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689064 episodes
GETTING ACTION FROM:
action 1, numVisits=689029, meanQ=6.233739, numObservations: 5
action -1, numVisits=29, meanQ=4.818806, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.542155 0.852504 0.25965 0.928606 0.567669 0.856424 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31019, meanQ=6.514373, numObservations: 5
action 1, numVisits=16, meanQ=2.873750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 838262 episodes
GETTING ACTION FROM:
action 3, numVisits=869279, meanQ=6.258440, numObservations: 5
action 1, numVisits=16, meanQ=2.873750, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.542155 0.852504 0.25965 0.928606 0.567669 0.856424 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 138
Initial state: 0 0.935823 0.395185 0.506045 0.802022 0.673515 0.836059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699802 episodes
GETTING ACTION FROM:
action 2, numVisits=699773, meanQ=6.169186, numObservations: 4
action 1, numVisits=22, meanQ=4.040005, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.935823 0.395185 0.506045 0.802022 0.673515 0.836059 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 139
Initial state: 0 0.559328 0.899077 0.882057 0.542997 0.618931 0.866763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695705 episodes
GETTING ACTION FROM:
action 1, numVisits=695695, meanQ=6.236942, numObservations: 4
action 3, numVisits=5, meanQ=-1.020000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.559328 0.899077 0.882057 0.542997 0.618931 0.866763 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 140
Initial state: 0 0.667302 0.846038 0.0644104 0.211131 0.546333 0.833765 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 707445 episodes
GETTING ACTION FROM:
action 3, numVisits=707412, meanQ=6.189984, numObservations: 3
action 2, numVisits=22, meanQ=4.341368, numObservations: 4
action 1, numVisits=7, meanQ=3.284300, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.667302 0.846038 0.0644104 0.211131 0.546333 0.833765 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 141
Initial state: 0 0.63217 0.836786 0.180309 0.68384 0.57792 0.884819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687894 episodes
GETTING ACTION FROM:
action 1, numVisits=687881, meanQ=6.231257, numObservations: 5
action 0, numVisits=7, meanQ=3.231443, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.63217 0.836786 0.180309 0.68384 0.57792 0.884819 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 142
Initial state: 0 0.816513 0.206784 0.521331 0.823402 0.681031 0.81068 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 677568 episodes
GETTING ACTION FROM:
action 2, numVisits=677556, meanQ=6.133860, numObservations: 5
action 3, numVisits=6, meanQ=2.333333, numObservations: 3
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.816513 0.206784 0.521331 0.823402 0.681031 0.81068 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 143
Initial state: 0 0.600853 0.928241 0.594177 0.826411 0.517164 0.836242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703398 episodes
GETTING ACTION FROM:
action 2, numVisits=703355, meanQ=6.272692, numObservations: 4
action 0, numVisits=31, meanQ=4.958157, numObservations: 1
action 1, numVisits=8, meanQ=2.737500, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 1 0.600853 0.928241 0.594177 0.826411 0.517164 0.836242 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 144
Initial state: 0 0.623104 0.861552 0.604378 0.865104 0.926119 0.841452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674616 episodes
GETTING ACTION FROM:
action 1, numVisits=674519, meanQ=6.142216, numObservations: 5
action -1, numVisits=79, meanQ=5.302390, numObservations: 1
action 2, numVisits=7, meanQ=3.285714, numObservations: 3
action 3, numVisits=9, meanQ=2.553333, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.623104 0.861552 0.604378 0.865104 0.926119 0.841452 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 145
Initial state: 0 0.678794 0.829574 0.535435 0.855714 0.89475 0.434065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695897 episodes
GETTING ACTION FROM:
action 1, numVisits=695875, meanQ=6.241786, numObservations: 4
action 0, numVisits=11, meanQ=3.963595, numObservations: 1
action 2, numVisits=8, meanQ=1.498762, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.678794 0.829574 0.535435 0.855714 0.89475 0.434065 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 146
Initial state: 0 0.59066 0.330497 0.639138 0.898851 0.573605 0.892457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700752 episodes
GETTING ACTION FROM:
action 1, numVisits=700686, meanQ=6.228576, numObservations: 4
action 0, numVisits=38, meanQ=5.029688, numObservations: 1
action 2, numVisits=14, meanQ=4.070007, numObservations: 4
action 3, numVisits=12, meanQ=3.983333, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.59066 0.330497 0.639138 0.898851 0.573605 0.892457 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 147
Initial state: 0 0.623047 0.821412 0.633862 0.869799 0.846931 0.615509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 709536 episodes
GETTING ACTION FROM:
action 2, numVisits=709175, meanQ=6.242870, numObservations: 3
action 3, numVisits=317, meanQ=4.959292, numObservations: 4
action 0, numVisits=32, meanQ=4.934440, numObservations: 1
action 1, numVisits=10, meanQ=3.198000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.623047 0.821412 0.633862 0.869799 0.846931 0.615509 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 148
Initial state: 0 0.522364 0.849237 0.614479 0.849761 0.35624 0.135329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 707581 episodes
GETTING ACTION FROM:
action 1, numVisits=707556, meanQ=6.231290, numObservations: 3
action 3, numVisits=19, meanQ=4.314742, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.522364 0.849237 0.614479 0.849761 0.35624 0.135329 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 149
Initial state: 0 0.637661 0.877576 0.5673 0.856718 0.215336 0.631336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686715 episodes
GETTING ACTION FROM:
action 3, numVisits=686707, meanQ=6.244831, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 0 0.637661 0.877576 0.5673 0.856718 0.215336 0.631336 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=49057, meanQ=8.872196, numObservations: 4
action 1, numVisits=45324, meanQ=8.872195, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 840852 episodes
GETTING ACTION FROM:
action 1, numVisits=615398, meanQ=6.751747, numObservations: 5
action 2, numVisits=319814, meanQ=6.747972, numObservations: 4
action 3, numVisits=22, meanQ=4.855000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.637661 0.877576 0.5673 0.856718 0.215336 0.631336 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=667, meanQ=8.520106, numObservations: 4
action 1, numVisits=2, meanQ=4.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 872062 episodes
GETTING ACTION FROM:
action 2, numVisits=872725, meanQ=6.316358, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.637661 0.877576 0.5673 0.856718 0.215336 0.631336 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 150
Initial state: 0 0.862424 0.19906 0.511461 0.887976 0.616617 0.892782 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694520 episodes
GETTING ACTION FROM:
action 1, numVisits=694439, meanQ=6.235721, numObservations: 4
action -1, numVisits=68, meanQ=5.345918, numObservations: 1
action 2, numVisits=10, meanQ=2.890010, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.862424 0.19906 0.511461 0.887976 0.616617 0.892782 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 151
Initial state: 0 0.167564 0.651028 0.579817 0.87619 0.611404 0.815449 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694209 episodes
GETTING ACTION FROM:
action 3, numVisits=694198, meanQ=6.216628, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 1 0.167564 0.651028 0.579817 0.87619 0.611404 0.815449 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 152
Initial state: 0 0.616052 0.845945 0.213373 0.261783 0.620146 0.854576 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700291 episodes
GETTING ACTION FROM:
action 1, numVisits=700255, meanQ=6.240943, numObservations: 4
action -1, numVisits=14, meanQ=4.229728, numObservations: 1
action 2, numVisits=11, meanQ=3.725455, numObservations: 3
action 3, numVisits=9, meanQ=3.442244, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.616052 0.845945 0.213373 0.261783 0.620146 0.854576 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 153
Initial state: 0 0.529476 0.833448 0.529994 0.878509 0.0172747 0.58513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690472 episodes
GETTING ACTION FROM:
action 2, numVisits=690455, meanQ=6.221493, numObservations: 5
action 1, numVisits=6, meanQ=2.663333, numObservations: 4
action 3, numVisits=7, meanQ=1.998571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.529476 0.833448 0.529994 0.878509 0.0172747 0.58513 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 154
Initial state: 0 0.579298 0.527251 0.630008 0.852787 0.5473 0.884613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699271 episodes
GETTING ACTION FROM:
action 1, numVisits=699236, meanQ=6.240480, numObservations: 4
action 3, numVisits=29, meanQ=4.748628, numObservations: 4
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 2 0.579298 0.527251 0.630008 0.852787 0.5473 0.884613 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 155
Initial state: 0 0.503629 0.83367 0.0524687 0.962434 0.568997 0.801275 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686919 episodes
GETTING ACTION FROM:
action 2, numVisits=686775, meanQ=6.235907, numObservations: 5
action 1, numVisits=101, meanQ=5.510990, numObservations: 4
action -1, numVisits=40, meanQ=5.081285, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.503629 0.83367 0.0524687 0.962434 0.568997 0.801275 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 156
Initial state: 0 0.538351 0.803179 0.883839 0.8054 0.555673 0.845493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686677 episodes
GETTING ACTION FROM:
action 3, numVisits=686660, meanQ=6.234097, numObservations: 5
action 2, numVisits=8, meanQ=1.745025, numObservations: 2
action 1, numVisits=5, meanQ=0.998020, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.538351 0.803179 0.883839 0.8054 0.555673 0.845493 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 157
Initial state: 0 0.0404409 0.796692 0.622762 0.861887 0.623482 0.872867 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692873 episodes
GETTING ACTION FROM:
action 2, numVisits=692866, meanQ=6.222188, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0404409 0.796692 0.622762 0.861887 0.623482 0.872867 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 158
Initial state: 0 0.534414 0.246625 0.502112 0.889038 0.692283 0.809737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 490494 episodes
GETTING ACTION FROM:
action 0, numVisits=490465, meanQ=6.417435, numObservations: 3
action 3, numVisits=24, meanQ=1.499587, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.534414 0.246625 0.502112 0.889038 0.692283 0.809737 w: 1
Observation: 0 0 0.246193 0 0.905584 0 0.737633 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=157627, meanQ=8.553179, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 758179 episodes
GETTING ACTION FROM:
action 2, numVisits=915806, meanQ=6.574613, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.534414 0.246625 0.502112 0.889038 0.692283 0.809737 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 159
Initial state: 0 0.847132 0.259712 0.620357 0.868574 0.674193 0.877937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690357 episodes
GETTING ACTION FROM:
action 1, numVisits=690297, meanQ=6.250235, numObservations: 5
action 0, numVisits=51, meanQ=5.231040, numObservations: 1
action 3, numVisits=6, meanQ=0.831667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.847132 0.259712 0.620357 0.868574 0.674193 0.877937 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30807, meanQ=6.549545, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 851731 episodes
GETTING ACTION FROM:
action 3, numVisits=882538, meanQ=6.516632, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.847132 0.259712 0.620357 0.868574 0.674193 0.877937 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 160
Initial state: 0 0.575562 0.877438 0.629564 0.816266 0.378678 0.879774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686792 episodes
GETTING ACTION FROM:
action 3, numVisits=686785, meanQ=6.215938, numObservations: 5
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.575562 0.877438 0.629564 0.816266 0.378678 0.879774 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=56133, meanQ=8.891812, numObservations: 4
action 1, numVisits=37688, meanQ=8.883928, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 856141 episodes
GETTING ACTION FROM:
action 2, numVisits=638102, meanQ=6.741488, numObservations: 4
action 1, numVisits=311858, meanQ=6.737461, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.575562 0.877438 0.629564 0.816266 0.378678 0.879774 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 161
Initial state: 0 0.657752 0.875023 0.145776 0.515656 0.597999 0.880748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661716 episodes
GETTING ACTION FROM:
action 1, numVisits=598909, meanQ=6.229914, numObservations: 5
action 0, numVisits=62802, meanQ=4.164127, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.657752 0.875023 0.145776 0.515656 0.597999 0.880748 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 162
Initial state: 0 0.694495 0.847211 0.624545 0.0172994 0.560881 0.881918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697126 episodes
GETTING ACTION FROM:
action 1, numVisits=697117, meanQ=6.232562, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.694495 0.847211 0.624545 0.0172994 0.560881 0.881918 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 163
Initial state: 0 0.797573 0.890215 0.528958 0.899244 0.632074 0.830121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698727 episodes
GETTING ACTION FROM:
action 1, numVisits=698686, meanQ=6.247317, numObservations: 4
action 0, numVisits=21, meanQ=4.640509, numObservations: 1
action 3, numVisits=17, meanQ=3.764118, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.797573 0.890215 0.528958 0.899244 0.632074 0.830121 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 164
Initial state: 0 0.357203 0.938209 0.628286 0.808733 0.569684 0.841596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696494 episodes
GETTING ACTION FROM:
action 2, numVisits=696485, meanQ=6.232372, numObservations: 5
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.357203 0.938209 0.628286 0.808733 0.569684 0.841596 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 165
Initial state: 0 0.850138 0.305987 0.549147 0.818034 0.523928 0.89756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685408 episodes
GETTING ACTION FROM:
action 3, numVisits=685399, meanQ=6.242682, numObservations: 5
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.850138 0.305987 0.549147 0.818034 0.523928 0.89756 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 166
Initial state: 0 0.602702 0.873461 0.0680637 0.148165 0.588028 0.886365 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687644 episodes
GETTING ACTION FROM:
action 1, numVisits=687608, meanQ=6.192464, numObservations: 5
action 2, numVisits=31, meanQ=4.866777, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.602702 0.873461 0.0680637 0.148165 0.588028 0.886365 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 167
Initial state: 0 0.556552 0.865842 0.406365 0.939661 0.693728 0.897876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700349 episodes
GETTING ACTION FROM:
action 1, numVisits=700233, meanQ=6.243337, numObservations: 4
action 3, numVisits=93, meanQ=5.069141, numObservations: 4
action 2, numVisits=19, meanQ=4.314742, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.556552 0.865842 0.406365 0.939661 0.693728 0.897876 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 168
Initial state: 0 0.855703 0.755962 0.595835 0.887273 0.669464 0.878191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697204 episodes
GETTING ACTION FROM:
action 1, numVisits=697122, meanQ=6.242554, numObservations: 4
action 0, numVisits=43, meanQ=5.119079, numObservations: 1
action -1, numVisits=34, meanQ=4.967922, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 2 0.855703 0.755962 0.595835 0.887273 0.669464 0.878191 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 169
Initial state: 0 0.542775 0.87032 0.694382 0.800534 0.410896 0.352091 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698037 episodes
GETTING ACTION FROM:
action 3, numVisits=694661, meanQ=6.232091, numObservations: 4
action 2, numVisits=3347, meanQ=6.108951, numObservations: 4
action 1, numVisits=25, meanQ=4.639204, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.542775 0.87032 0.694382 0.800534 0.410896 0.352091 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=112738, meanQ=8.850353, numObservations: 4
action 2, numVisits=3, meanQ=2.993333, numObservations: 2
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 857302 episodes
GETTING ACTION FROM:
action 1, numVisits=969491, meanQ=6.699608, numObservations: 4
action 2, numVisits=551, meanQ=6.380436, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.542775 0.87032 0.694382 0.800534 0.410896 0.352091 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 170
Initial state: 0 0.565768 0.805476 0.811736 0.617021 0.662073 0.849942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701046 episodes
GETTING ACTION FROM:
action 2, numVisits=700985, meanQ=6.225335, numObservations: 4
action 0, numVisits=41, meanQ=5.085088, numObservations: 1
action 3, numVisits=11, meanQ=3.625464, numObservations: 3
action 1, numVisits=7, meanQ=3.282886, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.565768 0.805476 0.811736 0.617021 0.662073 0.849942 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 171
Initial state: 0 0.631407 0.800449 0.956085 0.750676 0.692108 0.870709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697370 episodes
GETTING ACTION FROM:
action 1, numVisits=697316, meanQ=6.231814, numObservations: 4
action -1, numVisits=27, meanQ=4.822769, numObservations: 1
action 3, numVisits=16, meanQ=4.055006, numObservations: 3
action 0, numVisits=10, meanQ=3.739360, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.631407 0.800449 0.956085 0.750676 0.692108 0.870709 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 172
Initial state: 0 0.678097 0.839944 0.66339 0.267196 0.655406 0.80504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706368 episodes
GETTING ACTION FROM:
action 3, numVisits=706106, meanQ=6.232381, numObservations: 3
action 2, numVisits=255, meanQ=5.764275, numObservations: 5
action 1, numVisits=3, meanQ=-0.670000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.678097 0.839944 0.66339 0.267196 0.655406 0.80504 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31295, meanQ=6.478635, numObservations: 3
action 1, numVisits=31, meanQ=4.834523, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 875508 episodes
GETTING ACTION FROM:
action 2, numVisits=906735, meanQ=6.526213, numObservations: 3
action 3, numVisits=69, meanQ=5.506959, numObservations: 3
action 1, numVisits=31, meanQ=4.834523, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.678097 0.839944 0.66339 0.267196 0.655406 0.80504 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11.89
Run # 173
Initial state: 0 0.524987 0.892111 0.220636 0.0291185 0.524082 0.826795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686933 episodes
GETTING ACTION FROM:
action 3, numVisits=686884, meanQ=6.230425, numObservations: 5
action -1, numVisits=29, meanQ=4.857075, numObservations: 1
action 0, numVisits=12, meanQ=3.829882, numObservations: 1
action 2, numVisits=6, meanQ=0.831667, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 1 0.524987 0.892111 0.220636 0.0291185 0.524082 0.826795 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 174
Initial state: 0 0.546375 0.854646 0.625724 0.850124 0.481854 0.218993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 678645 episodes
GETTING ACTION FROM:
action 2, numVisits=678634, meanQ=6.184104, numObservations: 5
action 3, numVisits=6, meanQ=2.515000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.546375 0.854646 0.625724 0.850124 0.481854 0.218993 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 175
Initial state: 0 0.509288 0.81667 0.407003 0.2102 0.605893 0.811331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697824 episodes
GETTING ACTION FROM:
action 1, numVisits=692540, meanQ=6.234444, numObservations: 4
action 3, numVisits=4675, meanQ=6.106138, numObservations: 3
action 2, numVisits=550, meanQ=5.921751, numObservations: 4
action 0, numVisits=57, meanQ=5.263796, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.509288 0.81667 0.407003 0.2102 0.605893 0.811331 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 176
Initial state: 0 0.539402 0.82822 0.276421 0.138696 0.55213 0.820924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697643 episodes
GETTING ACTION FROM:
action 1, numVisits=697541, meanQ=6.224191, numObservations: 4
action -1, numVisits=81, meanQ=5.404321, numObservations: 1
action 0, numVisits=14, meanQ=4.223534, numObservations: 1
action 3, numVisits=5, meanQ=0.998020, numObservations: 2
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action: 1
Next state: 1 0.539402 0.82822 0.276421 0.138696 0.55213 0.820924 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 177
Initial state: 0 0.850976 0.248193 0.66072 0.852679 0.69958 0.857407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689612 episodes
GETTING ACTION FROM:
action 1, numVisits=689556, meanQ=6.235263, numObservations: 5
action 0, numVisits=51, meanQ=5.210391, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.850976 0.248193 0.66072 0.852679 0.69958 0.857407 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 178
Initial state: 0 0.659159 0.828613 0.829128 0.935537 0.609001 0.861379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703294 episodes
GETTING ACTION FROM:
action 2, numVisits=703259, meanQ=6.234855, numObservations: 4
action -1, numVisits=20, meanQ=4.391803, numObservations: 1
action 1, numVisits=11, meanQ=1.726373, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.659159 0.828613 0.829128 0.935537 0.609001 0.861379 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 179
Initial state: 0 0.813081 0.602 0.567036 0.8771 0.634035 0.84128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695928 episodes
GETTING ACTION FROM:
action 1, numVisits=695861, meanQ=6.233860, numObservations: 4
action -1, numVisits=31, meanQ=4.875443, numObservations: 1
action 0, numVisits=23, meanQ=4.688646, numObservations: 1
action 3, numVisits=11, meanQ=3.624564, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 2 0.813081 0.602 0.567036 0.8771 0.634035 0.84128 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 180
Initial state: 0 0.545092 0.443431 0.682376 0.809998 0.688803 0.852268 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698554 episodes
GETTING ACTION FROM:
action 2, numVisits=698427, meanQ=6.235362, numObservations: 4
action 0, numVisits=85, meanQ=5.446282, numObservations: 1
action 1, numVisits=28, meanQ=4.671079, numObservations: 2
action 3, numVisits=12, meanQ=3.816683, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.545092 0.443431 0.682376 0.809998 0.688803 0.852268 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 181
Initial state: 0 0.292925 0.0646423 0.668495 0.861114 0.691011 0.814626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696793 episodes
GETTING ACTION FROM:
action 3, numVisits=696686, meanQ=6.236682, numObservations: 4
action -1, numVisits=37, meanQ=5.004353, numObservations: 1
action 2, numVisits=50, meanQ=4.134006, numObservations: 4
action 1, numVisits=18, meanQ=3.491689, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.292925 0.0646423 0.668495 0.861114 0.691011 0.814626 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 182
Initial state: 0 0.550971 0.897412 0.563168 0.817954 0.467895 0.222355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696807 episodes
GETTING ACTION FROM:
action 1, numVisits=696727, meanQ=6.232471, numObservations: 4
action 0, numVisits=50, meanQ=5.189143, numObservations: 1
action 3, numVisits=26, meanQ=4.030385, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.550971 0.897412 0.563168 0.817954 0.467895 0.222355 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.68498 0.832441 0.0828559 0.366286 0.582103 0.88711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 707195 episodes
GETTING ACTION FROM:
action 1, numVisits=707131, meanQ=6.245818, numObservations: 3
action 2, numVisits=34, meanQ=4.876179, numObservations: 4
action -1, numVisits=20, meanQ=4.557166, numObservations: 1
action 3, numVisits=8, meanQ=2.873750, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.68498 0.832441 0.0828559 0.366286 0.582103 0.88711 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 184
Initial state: 0 0.579778 0.802123 0.0959178 0.967314 0.556946 0.894068 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701255 episodes
GETTING ACTION FROM:
action 2, numVisits=701149, meanQ=6.316782, numObservations: 4
action -1, numVisits=35, meanQ=5.075845, numObservations: 1
action 3, numVisits=32, meanQ=4.995941, numObservations: 4
action 1, numVisits=37, meanQ=4.942976, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 0 0.579778 0.802123 0.0959178 0.967314 0.556946 0.894068 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25730, meanQ=8.184879, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 784531 episodes
GETTING ACTION FROM:
action 2, numVisits=810253, meanQ=5.882891, numObservations: 4
action 1, numVisits=7, meanQ=1.998571, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.579778 0.802123 0.0959178 0.967314 0.556946 0.894068 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 185
Initial state: 0 0.449078 0.654753 0.591013 0.8995 0.620446 0.81598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 683148 episodes
GETTING ACTION FROM:
action 1, numVisits=683023, meanQ=6.137789, numObservations: 4
action 0, numVisits=93, meanQ=5.374020, numObservations: 1
action -1, numVisits=28, meanQ=4.724611, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 0 0.449078 0.654753 0.591013 0.8995 0.620446 0.81598 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=110554, meanQ=8.854463, numObservations: 5
action 3, numVisits=6, meanQ=5.996667, numObservations: 2
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 840559 episodes
GETTING ACTION FROM:
action 2, numVisits=950948, meanQ=6.589133, numObservations: 5
action 3, numVisits=159, meanQ=5.938742, numObservations: 3
action 1, numVisits=13, meanQ=3.766931, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.449078 0.654753 0.591013 0.8995 0.620446 0.81598 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 186
Initial state: 0 0.534868 0.80753 0.697937 0.893754 0.506269 0.635868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700376 episodes
GETTING ACTION FROM:
action 1, numVisits=700342, meanQ=6.233007, numObservations: 4
action 0, numVisits=25, meanQ=4.671076, numObservations: 1
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 2, numVisits=5, meanQ=-0.802000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.534868 0.80753 0.697937 0.893754 0.506269 0.635868 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 187
Initial state: 0 0.567991 0.837521 0.614772 0.832822 0.336588 0.97822 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689870 episodes
GETTING ACTION FROM:
action 2, numVisits=689857, meanQ=6.222145, numObservations: 5
action 3, numVisits=7, meanQ=1.998571, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.567991 0.837521 0.614772 0.832822 0.336588 0.97822 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 188
Initial state: 0 0.0159265 0.956224 0.52625 0.839559 0.667027 0.846255 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 712441 episodes
GETTING ACTION FROM:
action 2, numVisits=712373, meanQ=6.235063, numObservations: 3
action -1, numVisits=36, meanQ=4.984538, numObservations: 1
action 0, numVisits=15, meanQ=4.284434, numObservations: 1
action 3, numVisits=7, meanQ=3.284300, numObservations: 2
action 1, numVisits=10, meanQ=3.198000, numObservations: 2
action: 2
Next state: 1 0.0159265 0.956224 0.52625 0.839559 0.667027 0.846255 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 189
Initial state: 0 0.235103 0.777115 0.690662 0.839902 0.650065 0.883123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693794 episodes
GETTING ACTION FROM:
action 2, numVisits=693682, meanQ=6.310280, numObservations: 5
action 0, numVisits=52, meanQ=5.277530, numObservations: 1
action -1, numVisits=49, meanQ=5.256411, numObservations: 1
action 3, numVisits=8, meanQ=2.872513, numObservations: 3
action 1, numVisits=3, meanQ=-1.033333, numObservations: 2
action: 2
Next state: 1 0.235103 0.777115 0.690662 0.839902 0.650065 0.883123 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 190
Initial state: 0 0.571556 0.751416 0.568776 0.815755 0.631612 0.870363 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694916 episodes
GETTING ACTION FROM:
action 3, numVisits=694907, meanQ=6.229745, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.571556 0.751416 0.568776 0.815755 0.631612 0.870363 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 191
Initial state: 0 0.561647 0.844132 0.667485 0.822991 0.979471 0.0262186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686626 episodes
GETTING ACTION FROM:
action 1, numVisits=686592, meanQ=6.138823, numObservations: 4
action -1, numVisits=22, meanQ=4.462785, numObservations: 1
action 2, numVisits=6, meanQ=2.330033, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.561647 0.844132 0.667485 0.822991 0.979471 0.0262186 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 192
Initial state: 0 0.528573 0.82569 0.565974 0.817088 0.10597 0.546964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695668 episodes
GETTING ACTION FROM:
action 3, numVisits=695607, meanQ=6.230023, numObservations: 4
action 2, numVisits=38, meanQ=4.200526, numObservations: 3
action 1, numVisits=19, meanQ=3.204742, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.528573 0.82569 0.565974 0.817088 0.10597 0.546964 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=67188, meanQ=8.851189, numObservations: 5
action 1, numVisits=45655, meanQ=8.839090, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 842191 episodes
GETTING ACTION FROM:
action 2, numVisits=738224, meanQ=6.776596, numObservations: 5
action 1, numVisits=216809, meanQ=6.769074, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.528573 0.82569 0.565974 0.817088 0.10597 0.546964 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 193
Initial state: 0 0.503672 0.853109 0.501542 0.717846 0.570257 0.87746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700333 episodes
GETTING ACTION FROM:
action 1, numVisits=699168, meanQ=6.223494, numObservations: 4
action 3, numVisits=1098, meanQ=6.003716, numObservations: 4
action 2, numVisits=54, meanQ=5.065002, numObservations: 5
action 0, numVisits=11, meanQ=3.953500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.503672 0.853109 0.501542 0.717846 0.570257 0.87746 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 194
Initial state: 0 0.595719 0.857305 0.576425 0.515674 0.62446 0.812832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691447 episodes
GETTING ACTION FROM:
action 2, numVisits=691433, meanQ=6.232191, numObservations: 5
action 1, numVisits=9, meanQ=2.442233, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.595719 0.857305 0.576425 0.515674 0.62446 0.812832 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=42584, meanQ=8.717755, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 867405 episodes
GETTING ACTION FROM:
action 1, numVisits=907202, meanQ=6.603508, numObservations: 3
action 3, numVisits=2786, meanQ=6.466814, numObservations: 4
action 2, numVisits=3, meanQ=2.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.595719 0.857305 0.576425 0.515674 0.62446 0.812832 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 195
Initial state: 0 0.288574 0.654071 0.581533 0.844225 0.587397 0.812482 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 469836 episodes
GETTING ACTION FROM:
action -1, numVisits=469827, meanQ=4.142154, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.288574 0.654071 0.581533 0.844225 0.587397 0.812482 w: 1
Observation: 0 0.334468 0 0.668426 0 0.553658 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=469776, meanQ=6.224743, numObservations: 5
action 1, numVisits=39, meanQ=4.835903, numObservations: 3
action 3, numVisits=9, meanQ=3.554444, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 741205 episodes
GETTING ACTION FROM:
action 2, numVisits=1210960, meanQ=6.313784, numObservations: 5
action 1, numVisits=39, meanQ=4.835903, numObservations: 3
action 0, numVisits=21, meanQ=4.601429, numObservations: 1
action 3, numVisits=9, meanQ=3.554444, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.288574 0.654071 0.581533 0.844225 0.587397 0.812482 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 196
Initial state: 0 0.0946776 0.382409 0.664774 0.88643 0.559624 0.894261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687262 episodes
GETTING ACTION FROM:
action 1, numVisits=687236, meanQ=6.226587, numObservations: 5
action 3, numVisits=20, meanQ=4.539500, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.0946776 0.382409 0.664774 0.88643 0.559624 0.894261 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=45101, meanQ=8.870335, numObservations: 4
action 2, numVisits=49119, meanQ=8.865408, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 854616 episodes
GETTING ACTION FROM:
action 3, numVisits=518603, meanQ=6.765635, numObservations: 4
action 2, numVisits=430232, meanQ=6.764383, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.0946776 0.382409 0.664774 0.88643 0.559624 0.894261 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 197
Initial state: 0 0.515272 0.867918 0.65519 0.887171 0.658734 0.473853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690812 episodes
GETTING ACTION FROM:
action 1, numVisits=250066, meanQ=6.246007, numObservations: 5
action 2, numVisits=440645, meanQ=6.243512, numObservations: 5
action -1, numVisits=58, meanQ=5.291307, numObservations: 1
action 0, numVisits=41, meanQ=5.099030, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.515272 0.867918 0.65519 0.887171 0.658734 0.473853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 198
Initial state: 0 0.692994 0.897696 0.302897 0.0342149 0.52894 0.829593 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695080 episodes
GETTING ACTION FROM:
action 3, numVisits=695055, meanQ=6.229055, numObservations: 4
action 0, numVisits=17, meanQ=4.334182, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.692994 0.897696 0.302897 0.0342149 0.52894 0.829593 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 199
Initial state: 0 0.634561 0.843501 0.0430208 0.368199 0.5627 0.800489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 709828 episodes
GETTING ACTION FROM:
action 1, numVisits=709800, meanQ=6.241477, numObservations: 3
action 2, numVisits=13, meanQ=3.766931, numObservations: 2
action 3, numVisits=11, meanQ=2.725464, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.634561 0.843501 0.0430208 0.368199 0.5627 0.800489 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 200
Initial state: 0 0.626637 0.811589 0.669722 0.818918 0.621847 0.379667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698770 episodes
GETTING ACTION FROM:
action 2, numVisits=487368, meanQ=6.233137, numObservations: 4
action 3, numVisits=211244, meanQ=6.228093, numObservations: 4
action 1, numVisits=74, meanQ=5.322841, numObservations: 4
action 0, numVisits=48, meanQ=5.180729, numObservations: 1
action -1, numVisits=36, meanQ=5.001372, numObservations: 1
action: 2
Next state: 1 0.626637 0.811589 0.669722 0.818918 0.621847 0.379667 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 201
Initial state: 0 0.606807 0.848779 0.643774 0.859626 0.0735519 0.966136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695168 episodes
GETTING ACTION FROM:
action 2, numVisits=695048, meanQ=6.174039, numObservations: 5
action 0, numVisits=109, meanQ=5.477601, numObservations: 1
action 1, numVisits=8, meanQ=2.873750, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.606807 0.848779 0.643774 0.859626 0.0735519 0.966136 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 202
Initial state: 0 0.00320848 0.959437 0.539318 0.899278 0.551482 0.865002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 704419 episodes
GETTING ACTION FROM:
action 2, numVisits=704410, meanQ=6.197531, numObservations: 4
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.00320848 0.959437 0.539318 0.899278 0.551482 0.865002 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 203
Initial state: 0 0.556393 0.856892 0.22838 0.10954 0.541941 0.858953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 684506 episodes
GETTING ACTION FROM:
action 3, numVisits=684394, meanQ=6.184091, numObservations: 5
action 0, numVisits=95, meanQ=5.429335, numObservations: 1
action 2, numVisits=14, meanQ=3.427143, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.556393 0.856892 0.22838 0.10954 0.541941 0.858953 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 204
Initial state: 0 0.896771 0.506022 0.537176 0.800619 0.670519 0.894816 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702657 episodes
GETTING ACTION FROM:
action 2, numVisits=702573, meanQ=6.226489, numObservations: 4
action -1, numVisits=56, meanQ=5.244065, numObservations: 1
action 0, numVisits=25, meanQ=4.750355, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.896771 0.506022 0.537176 0.800619 0.670519 0.894816 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 205
Initial state: 0 0.205087 0.252268 0.63685 0.832579 0.544098 0.801349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698409 episodes
GETTING ACTION FROM:
action 1, numVisits=698331, meanQ=6.215532, numObservations: 4
action -1, numVisits=70, meanQ=5.326917, numObservations: 1
action 3, numVisits=4, meanQ=1.247550, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 0 0.205087 0.252268 0.63685 0.832579 0.544098 0.801349 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=96208, meanQ=8.880027, numObservations: 4
action 2, numVisits=5, meanQ=5.396000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 851577 episodes
GETTING ACTION FROM:
action 3, numVisits=947751, meanQ=6.701578, numObservations: 4
action 2, numVisits=39, meanQ=5.461026, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.205087 0.252268 0.63685 0.832579 0.544098 0.801349 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 206
Initial state: 0 0.680571 0.818037 0.656378 0.881944 0.903232 0.730235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697225 episodes
GETTING ACTION FROM:
action 1, numVisits=697217, meanQ=6.235130, numObservations: 4
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.680571 0.818037 0.656378 0.881944 0.903232 0.730235 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 207
Initial state: 0 0.617313 0.87446 0.677112 0.883737 0.982104 0.471515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695728 episodes
GETTING ACTION FROM:
action 2, numVisits=695649, meanQ=6.222508, numObservations: 4
action -1, numVisits=72, meanQ=5.362182, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.617313 0.87446 0.677112 0.883737 0.982104 0.471515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 208
Initial state: 0 0.863299 0.392295 0.607714 0.863656 0.507552 0.881707 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693078 episodes
GETTING ACTION FROM:
action 3, numVisits=693003, meanQ=6.313116, numObservations: 4
action 0, numVisits=40, meanQ=5.146873, numObservations: 1
action 1, numVisits=26, meanQ=4.376923, numObservations: 3
action 2, numVisits=7, meanQ=1.998571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.863299 0.392295 0.607714 0.863656 0.507552 0.881707 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 209
Initial state: 0 0.528702 0.83381 0.549278 0.808684 0.499614 0.0391356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695435 episodes
GETTING ACTION FROM:
action 1, numVisits=695335, meanQ=6.221491, numObservations: 4
action 0, numVisits=89, meanQ=5.435109, numObservations: 1
action 2, numVisits=7, meanQ=1.998571, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.528702 0.83381 0.549278 0.808684 0.499614 0.0391356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 210
Initial state: 0 0.70738 0.943849 0.510573 0.888253 0.527625 0.843837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696270 episodes
GETTING ACTION FROM:
action 1, numVisits=696189, meanQ=6.213103, numObservations: 4
action 0, numVisits=74, meanQ=5.365476, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.70738 0.943849 0.510573 0.888253 0.527625 0.843837 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 211
Initial state: 0 0.654125 0.854667 0.754293 0.923626 0.530269 0.820553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689108 episodes
GETTING ACTION FROM:
action 2, numVisits=689061, meanQ=6.177014, numObservations: 5
action 0, numVisits=16, meanQ=4.309761, numObservations: 1
action 3, numVisits=28, meanQ=4.070714, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.654125 0.854667 0.754293 0.923626 0.530269 0.820553 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 212
Initial state: 0 0.643123 0.862171 0.601219 0.829145 0.650629 0.568706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 705099 episodes
GETTING ACTION FROM:
action 2, numVisits=705088, meanQ=6.242890, numObservations: 4
action 3, numVisits=6, meanQ=0.831667, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.643123 0.862171 0.601219 0.829145 0.650629 0.568706 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 213
Initial state: 0 0.540943 0.887664 0.220908 0.28089 0.673147 0.819336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688667 episodes
GETTING ACTION FROM:
action 2, numVisits=688473, meanQ=6.224636, numObservations: 5
action 1, numVisits=153, meanQ=5.620804, numObservations: 5
action 0, numVisits=23, meanQ=4.687882, numObservations: 1
action 3, numVisits=16, meanQ=4.055625, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.540943 0.887664 0.220908 0.28089 0.673147 0.819336 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=41250, meanQ=8.937964, numObservations: 3
action 1, numVisits=33286, meanQ=8.934145, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 872898 episodes
GETTING ACTION FROM:
action 3, numVisits=637678, meanQ=6.765690, numObservations: 3
action 1, numVisits=309750, meanQ=6.761534, numObservations: 3
action 2, numVisits=7, meanQ=3.284300, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.540943 0.887664 0.220908 0.28089 0.673147 0.819336 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 214
Initial state: 0 0.361738 0.131298 0.674008 0.868085 0.681842 0.840869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690812 episodes
GETTING ACTION FROM:
action 1, numVisits=690719, meanQ=6.301117, numObservations: 5
action 0, numVisits=46, meanQ=5.194221, numObservations: 1
action -1, numVisits=24, meanQ=4.764041, numObservations: 1
action 3, numVisits=21, meanQ=4.661438, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 0 0.361738 0.131298 0.674008 0.868085 0.681842 0.840869 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=42623, meanQ=8.938717, numObservations: 3
action 3, numVisits=32458, meanQ=8.933824, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 861865 episodes
GETTING ACTION FROM:
action 2, numVisits=631104, meanQ=6.743139, numObservations: 3
action 3, numVisits=305839, meanQ=6.738784, numObservations: 5
action 1, numVisits=4, meanQ=1.525000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.361738 0.131298 0.674008 0.868085 0.681842 0.840869 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 215
Initial state: 0 0.600913 0.877311 0.613735 0.876792 0.00601131 0.11548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697123 episodes
GETTING ACTION FROM:
action 3, numVisits=696424, meanQ=6.231334, numObservations: 4
action 1, numVisits=517, meanQ=5.902471, numObservations: 5
action 2, numVisits=118, meanQ=5.526781, numObservations: 4
action 0, numVisits=62, meanQ=5.294706, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.600913 0.877311 0.613735 0.876792 0.00601131 0.11548 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=112824, meanQ=8.854852, numObservations: 4
action 1, numVisits=11, meanQ=6.362727, numObservations: 2
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 858073 episodes
GETTING ACTION FROM:
action 2, numVisits=970888, meanQ=6.954399, numObservations: 4
action 1, numVisits=17, meanQ=4.940588, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.600913 0.877311 0.613735 0.876792 0.00601131 0.11548 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 216
Initial state: 0 0.65879 0.838517 0.643274 0.804699 0.941369 0.516785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696891 episodes
GETTING ACTION FROM:
action 1, numVisits=696868, meanQ=6.227263, numObservations: 4
action 2, numVisits=15, meanQ=3.798667, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.65879 0.838517 0.643274 0.804699 0.941369 0.516785 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 217
Initial state: 0 0.632022 0.838015 0.699465 0.808442 0.0269438 0.343417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700136 episodes
GETTING ACTION FROM:
action 2, numVisits=700124, meanQ=6.225835, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.632022 0.838015 0.699465 0.808442 0.0269438 0.343417 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31332, meanQ=6.521567, numObservations: 5
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 838363 episodes
GETTING ACTION FROM:
action 3, numVisits=869695, meanQ=6.480241, numObservations: 5
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.632022 0.838015 0.699465 0.808442 0.0269438 0.343417 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=9883, meanQ=8.860517, numObservations: 3
action 1, numVisits=127, meanQ=8.369923, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 856052 episodes
GETTING ACTION FROM:
action 1, numVisits=564074, meanQ=6.549668, numObservations: 5
action 2, numVisits=301950, meanQ=6.465925, numObservations: 4
action 3, numVisits=39, meanQ=5.151282, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.632022 0.838015 0.699465 0.808442 0.0269438 0.343417 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 218
Initial state: 0 0.69714 0.895671 0.0495269 0.908168 0.590273 0.866717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699125 episodes
GETTING ACTION FROM:
action 1, numVisits=699103, meanQ=6.233913, numObservations: 4
action 3, numVisits=16, meanQ=3.999381, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.69714 0.895671 0.0495269 0.908168 0.590273 0.866717 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 219
Initial state: 0 0.133446 0.686489 0.561589 0.863735 0.642321 0.890472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693336 episodes
GETTING ACTION FROM:
action 3, numVisits=693290, meanQ=6.226067, numObservations: 4
action 0, numVisits=22, meanQ=4.667416, numObservations: 1
action 1, numVisits=20, meanQ=4.440005, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.133446 0.686489 0.561589 0.863735 0.642321 0.890472 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 220
Initial state: 0 0.647889 0.897386 0.558741 0.821567 0.569737 0.700541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696814 episodes
GETTING ACTION FROM:
action 2, numVisits=696772, meanQ=6.268442, numObservations: 4
action 1, numVisits=20, meanQ=4.499010, numObservations: 4
action 3, numVisits=18, meanQ=4.493900, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.647889 0.897386 0.558741 0.821567 0.569737 0.700541 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 221
Initial state: 0 0.678569 0.832591 0.0107797 0.74756 0.502074 0.871728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696321 episodes
GETTING ACTION FROM:
action 3, numVisits=696300, meanQ=6.240203, numObservations: 4
action 2, numVisits=9, meanQ=3.433333, numObservations: 3
action 0, numVisits=9, meanQ=2.947800, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.678569 0.832591 0.0107797 0.74756 0.502074 0.871728 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 222
Initial state: 0 0.694789 0.805938 0.129331 0.316263 0.644669 0.800427 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696261 episodes
GETTING ACTION FROM:
action 1, numVisits=696116, meanQ=6.232946, numObservations: 4
action 0, numVisits=83, meanQ=5.416126, numObservations: 1
action -1, numVisits=33, meanQ=4.951965, numObservations: 1
action 2, numVisits=27, meanQ=4.581111, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action: 1
Next state: 1 0.694789 0.805938 0.129331 0.316263 0.644669 0.800427 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 223
Initial state: 0 0.651976 0.874001 0.797602 0.88104 0.546428 0.87036 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 711150 episodes
GETTING ACTION FROM:
action 1, numVisits=711029, meanQ=6.222046, numObservations: 3
action -1, numVisits=94, meanQ=5.453616, numObservations: 1
action 0, numVisits=24, meanQ=4.693890, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.651976 0.874001 0.797602 0.88104 0.546428 0.87036 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 224
Initial state: 0 0.782057 0.334893 0.555119 0.897218 0.570949 0.827308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692694 episodes
GETTING ACTION FROM:
action 3, numVisits=692595, meanQ=6.224098, numObservations: 4
action -1, numVisits=44, meanQ=5.105083, numObservations: 1
action 2, numVisits=31, meanQ=4.482594, numObservations: 4
action 0, numVisits=17, meanQ=4.427022, numObservations: 1
action 1, numVisits=7, meanQ=3.284300, numObservations: 4
action: 3
Next state: 0 0.782057 0.334893 0.555119 0.897218 0.570949 0.827308 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31079, meanQ=6.485805, numObservations: 3
action 2, numVisits=16, meanQ=4.685638, numObservations: 4
action 3, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 870833 episodes
GETTING ACTION FROM:
action 1, numVisits=901786, meanQ=6.335187, numObservations: 3
action 2, numVisits=138, meanQ=5.650654, numObservations: 4
action 3, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 2 0.782057 0.334893 0.555119 0.897218 0.570949 0.827308 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11.89
Run # 225
Initial state: 0 0.576707 0.807927 0.618133 0.892281 0.589892 0.231313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690495 episodes
GETTING ACTION FROM:
action 2, numVisits=690485, meanQ=6.229312, numObservations: 5
action 1, numVisits=3, meanQ=-0.670000, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.576707 0.807927 0.618133 0.892281 0.589892 0.231313 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 226
Initial state: 0 0.284372 0.245521 0.680001 0.82518 0.640303 0.815969 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688222 episodes
GETTING ACTION FROM:
action 3, numVisits=688060, meanQ=6.232336, numObservations: 5
action -1, numVisits=91, meanQ=5.464422, numObservations: 1
action 0, numVisits=47, meanQ=5.155062, numObservations: 1
action 1, numVisits=22, meanQ=4.044550, numObservations: 4
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.284372 0.245521 0.680001 0.82518 0.640303 0.815969 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 227
Initial state: 0 0.184513 0.982719 0.626357 0.883248 0.557911 0.857421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697027 episodes
GETTING ACTION FROM:
action 3, numVisits=696963, meanQ=6.175440, numObservations: 4
action -1, numVisits=29, meanQ=4.814500, numObservations: 1
action 0, numVisits=17, meanQ=4.366539, numObservations: 1
action 1, numVisits=17, meanQ=2.470012, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.184513 0.982719 0.626357 0.883248 0.557911 0.857421 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 228
Initial state: 0 0.514275 0.815116 0.885198 0.60777 0.60948 0.832773 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 704119 episodes
GETTING ACTION FROM:
action 2, numVisits=704061, meanQ=6.189451, numObservations: 4
action -1, numVisits=42, meanQ=5.048382, numObservations: 1
action 1, numVisits=10, meanQ=3.198000, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 2 0.514275 0.815116 0.885198 0.60777 0.60948 0.832773 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 229
Initial state: 0 0.58524 0.895474 0.506217 0.858131 0.779503 0.111847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685047 episodes
GETTING ACTION FROM:
action 3, numVisits=684960, meanQ=6.228775, numObservations: 5
action 1, numVisits=45, meanQ=5.118667, numObservations: 5
action 0, numVisits=38, meanQ=5.022387, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.58524 0.895474 0.506217 0.858131 0.779503 0.111847 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 230
Initial state: 0 0.501144 0.845438 0.63253 0.428017 0.584836 0.87625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699824 episodes
GETTING ACTION FROM:
action 3, numVisits=699790, meanQ=6.228083, numObservations: 4
action 0, numVisits=23, meanQ=4.576050, numObservations: 1
action 1, numVisits=8, meanQ=2.873750, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.501144 0.845438 0.63253 0.428017 0.584836 0.87625 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 231
Initial state: 0 0.321917 0.623587 0.666293 0.839206 0.552811 0.834313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698445 episodes
GETTING ACTION FROM:
action 1, numVisits=698296, meanQ=6.184172, numObservations: 4
action 2, numVisits=141, meanQ=5.517589, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.321917 0.623587 0.666293 0.839206 0.552811 0.834313 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=41732, meanQ=8.939579, numObservations: 3
action 2, numVisits=34084, meanQ=8.936161, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 838778 episodes
GETTING ACTION FROM:
action 3, numVisits=634338, meanQ=6.801821, numObservations: 5
action 2, numVisits=280254, meanQ=6.796781, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.321917 0.623587 0.666293 0.839206 0.552811 0.834313 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 232
Initial state: 0 0.618671 0.891223 0.705314 0.700186 0.64604 0.895501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692410 episodes
GETTING ACTION FROM:
action 1, numVisits=692344, meanQ=6.211660, numObservations: 5
action -1, numVisits=44, meanQ=5.072818, numObservations: 1
action 2, numVisits=18, meanQ=2.382228, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.618671 0.891223 0.705314 0.700186 0.64604 0.895501 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 233
Initial state: 0 0.677866 0.881813 0.953142 0.500776 0.583633 0.819338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697979 episodes
GETTING ACTION FROM:
action 3, numVisits=697954, meanQ=6.233577, numObservations: 4
action 2, numVisits=17, meanQ=4.346471, numObservations: 3
action 1, numVisits=4, meanQ=1.747500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.677866 0.881813 0.953142 0.500776 0.583633 0.819338 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 234
Initial state: 0 0.513423 0.826587 0.735425 0.192541 0.622469 0.896272 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692223 episodes
GETTING ACTION FROM:
action 3, numVisits=692089, meanQ=6.232977, numObservations: 5
action 1, numVisits=106, meanQ=5.486665, numObservations: 4
action 2, numVisits=14, meanQ=4.140721, numObservations: 3
action -1, numVisits=12, meanQ=3.727199, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.513423 0.826587 0.735425 0.192541 0.622469 0.896272 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 235
Initial state: 0 0.667349 0.853066 0.643057 0.847309 0.717096 0.872779 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694908 episodes
GETTING ACTION FROM:
action 3, numVisits=689721, meanQ=6.236737, numObservations: 4
action 2, numVisits=5162, meanQ=6.141567, numObservations: 4
action 0, numVisits=22, meanQ=4.569324, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.667349 0.853066 0.643057 0.847309 0.717096 0.872779 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 236
Initial state: 0 0.504036 0.868132 0.682245 0.675918 0.554568 0.83717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706864 episodes
GETTING ACTION FROM:
action 1, numVisits=706855, meanQ=6.249328, numObservations: 3
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.504036 0.868132 0.682245 0.675918 0.554568 0.83717 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 237
Initial state: 0 0.569641 0.564143 0.666416 0.834088 0.600911 0.831155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687682 episodes
GETTING ACTION FROM:
action 2, numVisits=687660, meanQ=6.228347, numObservations: 5
action 1, numVisits=10, meanQ=3.880010, numObservations: 2
action 3, numVisits=8, meanQ=2.873750, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.569641 0.564143 0.666416 0.834088 0.600911 0.831155 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31136, meanQ=6.462388, numObservations: 4
action 2, numVisits=7, meanQ=-0.858571, numObservations: 2
action -1, numVisits=3, meanQ=-1.676600, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 854703 episodes
GETTING ACTION FROM:
action 1, numVisits=885839, meanQ=6.531553, numObservations: 4
action 2, numVisits=7, meanQ=-0.858571, numObservations: 2
action -1, numVisits=3, meanQ=-1.676600, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.569641 0.564143 0.666416 0.834088 0.600911 0.831155 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11.89
Run # 238
Initial state: 0 0.566745 0.870677 0.527076 0.760388 0.622066 0.80433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685888 episodes
GETTING ACTION FROM:
action 3, numVisits=685866, meanQ=6.231548, numObservations: 5
action 0, numVisits=13, meanQ=4.193705, numObservations: 1
action 2, numVisits=5, meanQ=-0.803980, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.566745 0.870677 0.527076 0.760388 0.622066 0.80433 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 239
Initial state: 0 0.586705 0.879766 0.557729 0.92364 0.561146 0.804414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690536 episodes
GETTING ACTION FROM:
action 1, numVisits=688518, meanQ=6.237461, numObservations: 5
action 3, numVisits=1978, meanQ=6.078563, numObservations: 4
action 0, numVisits=34, meanQ=4.988048, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.586705 0.879766 0.557729 0.92364 0.561146 0.804414 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 240
Initial state: 0 0.503882 0.83601 0.624833 0.22823 0.626058 0.816664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685708 episodes
GETTING ACTION FROM:
action 3, numVisits=685659, meanQ=6.237953, numObservations: 5
action 0, numVisits=23, meanQ=4.612171, numObservations: 1
action 1, numVisits=16, meanQ=3.435638, numObservations: 3
action 2, numVisits=8, meanQ=2.873750, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.503882 0.83601 0.624833 0.22823 0.626058 0.816664 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 241
Initial state: 0 0.514625 0.828704 0.60336 0.842143 0.674759 0.177399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695323 episodes
GETTING ACTION FROM:
action 3, numVisits=695292, meanQ=6.218798, numObservations: 4
action 2, numVisits=23, meanQ=4.651743, numObservations: 3
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.514625 0.828704 0.60336 0.842143 0.674759 0.177399 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=113219, meanQ=8.858232, numObservations: 4
action 2, numVisits=95, meanQ=8.109686, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 850632 episodes
GETTING ACTION FROM:
action 1, numVisits=963344, meanQ=6.920868, numObservations: 4
action 2, numVisits=592, meanQ=6.610490, numObservations: 4
action 3, numVisits=11, meanQ=4.544545, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.514625 0.828704 0.60336 0.842143 0.674759 0.177399 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 242
Initial state: 0 0.596076 0.844882 0.642643 0.864003 0.909218 0.0338212 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694809 episodes
GETTING ACTION FROM:
action 2, numVisits=694740, meanQ=6.233403, numObservations: 5
action -1, numVisits=27, meanQ=4.775856, numObservations: 1
action 3, numVisits=38, meanQ=3.175537, numObservations: 4
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.596076 0.844882 0.642643 0.864003 0.909218 0.0338212 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 243
Initial state: 0 0.863466 0.238081 0.571403 0.82673 0.611915 0.811411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690032 episodes
GETTING ACTION FROM:
action 2, numVisits=690015, meanQ=6.230483, numObservations: 5
action 3, numVisits=11, meanQ=3.814555, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.863466 0.238081 0.571403 0.82673 0.611915 0.811411 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 244
Initial state: 0 0.614488 0.832128 0.844095 0.069738 0.644234 0.80384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699817 episodes
GETTING ACTION FROM:
action 3, numVisits=699731, meanQ=6.237505, numObservations: 4
action 1, numVisits=78, meanQ=5.027569, numObservations: 4
action 2, numVisits=4, meanQ=1.745025, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.614488 0.832128 0.844095 0.069738 0.644234 0.80384 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 245
Initial state: 0 0.688651 0.288915 0.516006 0.827911 0.55701 0.875996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675644 episodes
GETTING ACTION FROM:
action 1, numVisits=675550, meanQ=6.150863, numObservations: 5
action -1, numVisits=55, meanQ=5.170001, numObservations: 1
action 0, numVisits=34, meanQ=4.889331, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 2 0.688651 0.288915 0.516006 0.827911 0.55701 0.875996 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 246
Initial state: 0 0.853252 0.160279 0.559021 0.839257 0.560129 0.80416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691146 episodes
GETTING ACTION FROM:
action 2, numVisits=691112, meanQ=6.237655, numObservations: 5
action 3, numVisits=26, meanQ=2.880004, numObservations: 5
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.853252 0.160279 0.559021 0.839257 0.560129 0.80416 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 247
Initial state: 0 0.558879 0.870265 0.962682 0.197215 0.673859 0.85057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699762 episodes
GETTING ACTION FROM:
action 1, numVisits=699739, meanQ=6.178460, numObservations: 4
action 3, numVisits=17, meanQ=4.294118, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.558879 0.870265 0.962682 0.197215 0.673859 0.85057 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 248
Initial state: 0 0.729401 0.641929 0.60495 0.887457 0.6258 0.883367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699607 episodes
GETTING ACTION FROM:
action 1, numVisits=699536, meanQ=6.228883, numObservations: 4
action 0, numVisits=32, meanQ=4.927144, numObservations: 1
action 3, numVisits=28, meanQ=4.667507, numObservations: 4
action 2, numVisits=9, meanQ=3.554444, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.729401 0.641929 0.60495 0.887457 0.6258 0.883367 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 249
Initial state: 0 0.678768 0.496306 0.686764 0.821182 0.545691 0.827292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688318 episodes
GETTING ACTION FROM:
action 1, numVisits=683368, meanQ=6.229020, numObservations: 5
action 2, numVisits=4922, meanQ=6.128772, numObservations: 4
action 0, numVisits=15, meanQ=4.234462, numObservations: 1
action 3, numVisits=11, meanQ=3.723655, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.678768 0.496306 0.686764 0.821182 0.545691 0.827292 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 250
Initial state: 0 0.630259 0.802767 0.655437 0.868378 0.556976 0.883901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 684149 episodes
GETTING ACTION FROM:
action 3, numVisits=683813, meanQ=6.229981, numObservations: 5
action 0, numVisits=328, meanQ=5.833657, numObservations: 2
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.630259 0.802767 0.655437 0.868378 0.556976 0.883901 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 251
Initial state: 0 0.597967 0.865461 0.175599 0.660507 0.512482 0.894975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702500 episodes
GETTING ACTION FROM:
action 2, numVisits=702424, meanQ=6.225127, numObservations: 4
action 0, numVisits=36, meanQ=4.988317, numObservations: 1
action -1, numVisits=23, meanQ=4.688017, numObservations: 1
action 1, numVisits=13, meanQ=3.766931, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action: 2
Next state: 0 0.597967 0.865461 0.175599 0.660507 0.512482 0.894975 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=40469, meanQ=8.935818, numObservations: 3
action 1, numVisits=36164, meanQ=8.933863, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 850241 episodes
GETTING ACTION FROM:
action 1, numVisits=607469, meanQ=6.566881, numObservations: 4
action 3, numVisits=319404, meanQ=6.563116, numObservations: 5
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.597967 0.865461 0.175599 0.660507 0.512482 0.894975 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 252
Initial state: 0 0.691109 0.810843 0.697638 0.854517 0.489202 0.515017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700214 episodes
GETTING ACTION FROM:
action 3, numVisits=700208, meanQ=6.226941, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.691109 0.810843 0.697638 0.854517 0.489202 0.515017 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=113600, meanQ=8.862654, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 872479 episodes
GETTING ACTION FROM:
action 2, numVisits=986046, meanQ=6.943195, numObservations: 3
action 1, numVisits=33, meanQ=5.630606, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.691109 0.810843 0.697638 0.854517 0.489202 0.515017 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 253
Initial state: 0 0.461888 0.066525 0.603377 0.865974 0.610514 0.800232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698524 episodes
GETTING ACTION FROM:
action 3, numVisits=698518, meanQ=6.214236, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.461888 0.066525 0.603377 0.865974 0.610514 0.800232 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 254
Initial state: 0 0.700295 0.500034 0.661948 0.833421 0.522647 0.853671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695577 episodes
GETTING ACTION FROM:
action 1, numVisits=695552, meanQ=6.224673, numObservations: 4
action -1, numVisits=20, meanQ=4.569942, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.700295 0.500034 0.661948 0.833421 0.522647 0.853671 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 255
Initial state: 0 0.521218 0.864278 0.222366 0.743526 0.527589 0.8395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 468845 episodes
GETTING ACTION FROM:
action 0, numVisits=468838, meanQ=4.184541, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.521218 0.864278 0.222366 0.743526 0.527589 0.8395 w: 1
Observation: 0 0 0.90139 0 0.701589 0 0.798933 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=468666, meanQ=6.248147, numObservations: 5
action 3, numVisits=167, meanQ=5.674188, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 743366 episodes
GETTING ACTION FROM:
action 2, numVisits=1211995, meanQ=6.253943, numObservations: 5
action 3, numVisits=167, meanQ=5.674188, numObservations: 3
action -1, numVisits=37, meanQ=5.026818, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.521218 0.864278 0.222366 0.743526 0.527589 0.8395 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=66130, meanQ=8.938393, numObservations: 3
action 1, numVisits=66040, meanQ=8.938342, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 841177 episodes
GETTING ACTION FROM:
action 3, numVisits=560791, meanQ=6.830662, numObservations: 5
action 1, numVisits=412554, meanQ=6.829248, numObservations: 5
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.521218 0.864278 0.222366 0.743526 0.527589 0.8395 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 5.8309
Run # 256
Initial state: 0 0.651318 0.868727 0.583254 0.911556 0.668051 0.824092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698476 episodes
GETTING ACTION FROM:
action 1, numVisits=272487, meanQ=6.229397, numObservations: 5
action 2, numVisits=425951, meanQ=6.228597, numObservations: 3
action -1, numVisits=32, meanQ=4.933813, numObservations: 1
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.651318 0.868727 0.583254 0.911556 0.668051 0.824092 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 257
Initial state: 0 0.646066 0.99312 0.650807 0.821072 0.687859 0.802906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697787 episodes
GETTING ACTION FROM:
action 3, numVisits=697749, meanQ=6.229871, numObservations: 4
action 0, numVisits=15, meanQ=4.325703, numObservations: 1
action 2, numVisits=19, meanQ=3.841053, numObservations: 4
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.646066 0.99312 0.650807 0.821072 0.687859 0.802906 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 258
Initial state: 0 0.659273 0.821944 0.664512 0.87561 0.132204 0.109246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693682 episodes
GETTING ACTION FROM:
action 2, numVisits=688045, meanQ=6.324159, numObservations: 5
action 3, numVisits=5553, meanQ=6.195999, numObservations: 4
action 1, numVisits=82, meanQ=5.516101, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.659273 0.821944 0.664512 0.87561 0.132204 0.109246 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 259
Initial state: 0 0.88179 0.247905 0.63176 0.800991 0.691521 0.898397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691801 episodes
GETTING ACTION FROM:
action 1, numVisits=691777, meanQ=6.222284, numObservations: 5
action 0, numVisits=18, meanQ=4.401209, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.88179 0.247905 0.63176 0.800991 0.691521 0.898397 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 260
Initial state: 0 0.498812 0.152669 0.562356 0.849476 0.620082 0.841386 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697406 episodes
GETTING ACTION FROM:
action 1, numVisits=697077, meanQ=6.232966, numObservations: 4
action 3, numVisits=226, meanQ=5.752436, numObservations: 5
action 0, numVisits=97, meanQ=5.486512, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.498812 0.152669 0.562356 0.849476 0.620082 0.841386 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=38402, meanQ=8.937802, numObservations: 3
action 3, numVisits=37578, meanQ=8.937366, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 855630 episodes
GETTING ACTION FROM:
action 3, numVisits=618440, meanQ=6.543185, numObservations: 3
action 2, numVisits=313166, meanQ=6.539508, numObservations: 3
action 1, numVisits=5, meanQ=3.198000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.498812 0.152669 0.562356 0.849476 0.620082 0.841386 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=5108, meanQ=8.363128, numObservations: 5
action 3, numVisits=1051, meanQ=8.246806, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 853996 episodes
GETTING ACTION FROM:
action 1, numVisits=770735, meanQ=6.400106, numObservations: 5
action 2, numVisits=70257, meanQ=6.126673, numObservations: 5
action 3, numVisits=19164, meanQ=6.103450, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.498812 0.152669 0.562356 0.849476 0.620082 0.841386 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=2471, meanQ=8.917112, numObservations: 3
action 3, numVisits=2428, meanQ=8.916652, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 869628 episodes
GETTING ACTION FROM:
action 2, numVisits=852819, meanQ=6.327827, numObservations: 4
action 3, numVisits=21701, meanQ=6.284874, numObservations: 5
action 1, numVisits=6, meanQ=0.831667, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.498812 0.152669 0.562356 0.849476 0.620082 0.841386 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 5.76259
Run # 261
Initial state: 0 0.391107 0.102817 0.593058 0.812621 0.635046 0.872728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691621 episodes
GETTING ACTION FROM:
action 2, numVisits=691580, meanQ=6.224489, numObservations: 5
action 3, numVisits=21, meanQ=3.808576, numObservations: 4
action 1, numVisits=16, meanQ=3.300006, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.391107 0.102817 0.593058 0.812621 0.635046 0.872728 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 262
Initial state: 0 0.353054 0.537426 0.68082 0.885559 0.696612 0.814798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696298 episodes
GETTING ACTION FROM:
action 3, numVisits=696288, meanQ=6.275714, numObservations: 4
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action 1, numVisits=4, meanQ=-0.505000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.353054 0.537426 0.68082 0.885559 0.696612 0.814798 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 263
Initial state: 0 0.792265 0.393296 0.596328 0.855548 0.609985 0.803605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698382 episodes
GETTING ACTION FROM:
action 3, numVisits=698286, meanQ=6.232749, numObservations: 4
action 0, numVisits=65, meanQ=5.308535, numObservations: 1
action 2, numVisits=28, meanQ=4.713579, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.792265 0.393296 0.596328 0.855548 0.609985 0.803605 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.628964 0.449194 0.650766 0.849688 0.509858 0.858197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687265 episodes
GETTING ACTION FROM:
action 1, numVisits=583454, meanQ=6.234833, numObservations: 5
action 2, numVisits=103735, meanQ=6.215203, numObservations: 5
action 3, numVisits=49, meanQ=5.004900, numObservations: 4
action -1, numVisits=25, meanQ=4.707977, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.628964 0.449194 0.650766 0.849688 0.509858 0.858197 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 265
Initial state: 0 0.554498 0.888757 0.621194 0.837841 0.155894 0.565138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696584 episodes
GETTING ACTION FROM:
action 1, numVisits=695493, meanQ=6.239219, numObservations: 4
action 2, numVisits=996, meanQ=6.007790, numObservations: 5
action -1, numVisits=74, meanQ=5.384024, numObservations: 1
action 0, numVisits=19, meanQ=4.527187, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 1 0.554498 0.888757 0.621194 0.837841 0.155894 0.565138 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 266
Initial state: 0 0.955915 0.516562 0.537756 0.890837 0.684643 0.805017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699472 episodes
GETTING ACTION FROM:
action 1, numVisits=660870, meanQ=6.229876, numObservations: 4
action 3, numVisits=38550, meanQ=6.184185, numObservations: 4
action 2, numVisits=48, meanQ=5.133756, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.955915 0.516562 0.537756 0.890837 0.684643 0.805017 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 267
Initial state: 0 0.432571 0.820584 0.547541 0.86556 0.68346 0.841652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696941 episodes
GETTING ACTION FROM:
action 3, numVisits=696935, meanQ=6.234925, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.432571 0.820584 0.547541 0.86556 0.68346 0.841652 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 268
Initial state: 0 0.696687 0.862309 0.60853 0.887144 0.988091 0.253987 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697376 episodes
GETTING ACTION FROM:
action 3, numVisits=697352, meanQ=6.215257, numObservations: 4
action 1, numVisits=14, meanQ=3.427143, numObservations: 3
action 2, numVisits=6, meanQ=2.496683, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.696687 0.862309 0.60853 0.887144 0.988091 0.253987 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 269
Initial state: 0 0.501425 0.463691 0.531728 0.838399 0.584285 0.811716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692328 episodes
GETTING ACTION FROM:
action 1, numVisits=679903, meanQ=6.240367, numObservations: 5
action 2, numVisits=12382, meanQ=6.073808, numObservations: 4
action -1, numVisits=35, meanQ=5.001696, numObservations: 1
action 3, numVisits=6, meanQ=2.331683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.501425 0.463691 0.531728 0.838399 0.584285 0.811716 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=93017, meanQ=8.885448, numObservations: 5
action 3, numVisits=8, meanQ=5.621250, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 846517 episodes
GETTING ACTION FROM:
action 2, numVisits=939522, meanQ=6.800333, numObservations: 5
action 3, numVisits=13, meanQ=3.843846, numObservations: 3
action 1, numVisits=8, meanQ=2.873750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.501425 0.463691 0.531728 0.838399 0.584285 0.811716 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 270
Initial state: 0 0.651401 0.863706 0.716739 0.619503 0.638136 0.883379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 473576 episodes
GETTING ACTION FROM:
action 0, numVisits=473566, meanQ=4.161666, numObservations: 1
action 3, numVisits=4, meanQ=-0.505000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.651401 0.863706 0.716739 0.619503 0.638136 0.883379 w: 1
Observation: 0 0 0.770019 0 0.620086 0 0.878433 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=473388, meanQ=6.230295, numObservations: 4
action 2, numVisits=155, meanQ=5.609251, numObservations: 4
action 1, numVisits=20, meanQ=4.593505, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 745383 episodes
GETTING ACTION FROM:
action 3, numVisits=1218744, meanQ=6.399025, numObservations: 4
action 2, numVisits=155, meanQ=5.609251, numObservations: 4
action -1, numVisits=27, meanQ=4.849289, numObservations: 1
action 1, numVisits=20, meanQ=4.593505, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.651401 0.863706 0.716739 0.619503 0.638136 0.883379 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 271
Initial state: 0 0.676245 0.896091 0.361376 0.676692 0.550577 0.892976 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706387 episodes
GETTING ACTION FROM:
action 3, numVisits=674268, meanQ=6.239769, numObservations: 3
action 1, numVisits=30245, meanQ=6.204730, numObservations: 5
action 2, numVisits=1870, meanQ=6.076437, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.676245 0.896091 0.361376 0.676692 0.550577 0.892976 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 272
Initial state: 0 0.853764 0.611339 0.6384 0.846439 0.582456 0.81912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702151 episodes
GETTING ACTION FROM:
action 2, numVisits=701984, meanQ=6.172771, numObservations: 4
action 0, numVisits=95, meanQ=5.414920, numObservations: 2
action -1, numVisits=52, meanQ=5.129550, numObservations: 1
action 3, numVisits=9, meanQ=3.554444, numObservations: 2
action 1, numVisits=11, meanQ=2.815464, numObservations: 5
action: 2
Next state: 1 0.853764 0.611339 0.6384 0.846439 0.582456 0.81912 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 273
Initial state: 0 0.608024 0.813344 0.58908 0.848966 0.665116 0.836849 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689728 episodes
GETTING ACTION FROM:
action 2, numVisits=689652, meanQ=6.225512, numObservations: 5
action -1, numVisits=48, meanQ=5.166344, numObservations: 1
action 1, numVisits=18, meanQ=2.443333, numObservations: 4
action 3, numVisits=8, meanQ=1.747500, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.608024 0.813344 0.58908 0.848966 0.665116 0.836849 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 274
Initial state: 0 0.467131 0.776138 0.684936 0.879772 0.656935 0.866062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706810 episodes
GETTING ACTION FROM:
action 3, numVisits=706785, meanQ=6.235864, numObservations: 3
action -1, numVisits=20, meanQ=4.596676, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.467131 0.776138 0.684936 0.879772 0.656935 0.866062 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 275
Initial state: 0 0.151978 0.0844848 0.580957 0.81614 0.530434 0.802833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685027 episodes
GETTING ACTION FROM:
action 1, numVisits=684953, meanQ=6.232274, numObservations: 5
action 0, numVisits=61, meanQ=5.284678, numObservations: 1
action 2, numVisits=7, meanQ=3.284300, numObservations: 3
action 3, numVisits=4, meanQ=-1.002475, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.151978 0.0844848 0.580957 0.81614 0.530434 0.802833 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=48975, meanQ=8.893726, numObservations: 4
action 3, numVisits=44770, meanQ=8.891429, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 855559 episodes
GETTING ACTION FROM:
action 2, numVisits=808163, meanQ=7.014716, numObservations: 4
action 3, numVisits=141140, meanQ=7.003169, numObservations: 4
action 1, numVisits=2, meanQ=-0.509950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.151978 0.0844848 0.580957 0.81614 0.530434 0.802833 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 276
Initial state: 0 0.592249 0.899306 0.670005 0.871503 0.261744 0.686648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690476 episodes
GETTING ACTION FROM:
action 1, numVisits=690433, meanQ=6.225327, numObservations: 5
action 3, numVisits=33, meanQ=4.724245, numObservations: 4
action 2, numVisits=6, meanQ=2.333333, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.592249 0.899306 0.670005 0.871503 0.261744 0.686648 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 277
Initial state: 0 0.305928 0.101406 0.548359 0.818838 0.513444 0.887831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703876 episodes
GETTING ACTION FROM:
action 2, numVisits=671621, meanQ=6.312276, numObservations: 4
action 3, numVisits=31910, meanQ=6.265917, numObservations: 4
action 1, numVisits=315, meanQ=5.886213, numObservations: 4
action 0, numVisits=28, meanQ=4.917227, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.305928 0.101406 0.548359 0.818838 0.513444 0.887831 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.265132 0.208503 0.54216 0.867423 0.652515 0.852711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694497 episodes
GETTING ACTION FROM:
action 3, numVisits=666941, meanQ=6.237305, numObservations: 4
action 2, numVisits=27505, meanQ=6.200815, numObservations: 5
action 0, numVisits=34, meanQ=4.952947, numObservations: 1
action 1, numVisits=15, meanQ=3.520013, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.265132 0.208503 0.54216 0.867423 0.652515 0.852711 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 279
Initial state: 0 0.530586 0.0223572 0.537907 0.863755 0.653924 0.896526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 712326 episodes
GETTING ACTION FROM:
action 1, numVisits=712311, meanQ=6.184496, numObservations: 3
action 2, numVisits=7, meanQ=3.285714, numObservations: 3
action 3, numVisits=4, meanQ=-0.754975, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.530586 0.0223572 0.537907 0.863755 0.653924 0.896526 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 280
Initial state: 0 0.36131 0.847531 0.645737 0.872637 0.557846 0.881717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688063 episodes
GETTING ACTION FROM:
action 3, numVisits=687969, meanQ=6.229722, numObservations: 5
action -1, numVisits=55, meanQ=5.227144, numObservations: 1
action 0, numVisits=30, meanQ=4.873466, numObservations: 1
action 2, numVisits=8, meanQ=2.872513, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.36131 0.847531 0.645737 0.872637 0.557846 0.881717 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 281
Initial state: 0 0.520603 0.839065 0.516509 0.182191 0.62417 0.879125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688554 episodes
GETTING ACTION FROM:
action 1, numVisits=688447, meanQ=6.228311, numObservations: 5
action 0, numVisits=96, meanQ=5.474939, numObservations: 1
action 2, numVisits=6, meanQ=0.830017, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.520603 0.839065 0.516509 0.182191 0.62417 0.879125 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 282
Initial state: 0 0.695052 0.812551 0.106708 0.703465 0.633929 0.857831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691459 episodes
GETTING ACTION FROM:
action 3, numVisits=691434, meanQ=6.226281, numObservations: 4
action -1, numVisits=19, meanQ=4.455221, numObservations: 1
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.695052 0.812551 0.106708 0.703465 0.633929 0.857831 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 283
Initial state: 0 0.592494 0.885632 0.275633 0.622704 0.502667 0.8613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690402 episodes
GETTING ACTION FROM:
action 2, numVisits=690288, meanQ=6.239977, numObservations: 5
action 3, numVisits=91, meanQ=5.192640, numObservations: 3
action 1, numVisits=19, meanQ=4.419474, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.592494 0.885632 0.275633 0.622704 0.502667 0.8613 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=94741, meanQ=8.875827, numObservations: 4
action 3, numVisits=16, meanQ=7.186256, numObservations: 2
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 855279 episodes
GETTING ACTION FROM:
action 1, numVisits=947723, meanQ=6.810513, numObservations: 4
action 3, numVisits=2312, meanQ=6.659191, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.592494 0.885632 0.275633 0.622704 0.502667 0.8613 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 284
Initial state: 0 0.475901 0.739194 0.562628 0.888719 0.652226 0.835818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689068 episodes
GETTING ACTION FROM:
action 3, numVisits=689049, meanQ=6.232802, numObservations: 5
action 2, numVisits=13, meanQ=3.691538, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.475901 0.739194 0.562628 0.888719 0.652226 0.835818 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 285
Initial state: 0 0.326614 0.532733 0.564451 0.823852 0.663815 0.853453 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 704444 episodes
GETTING ACTION FROM:
action 2, numVisits=704430, meanQ=6.235370, numObservations: 4
action 1, numVisits=7, meanQ=3.257143, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.326614 0.532733 0.564451 0.823852 0.663815 0.853453 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 286
Initial state: 0 0.645733 0.833212 0.563181 0.865844 0.702395 0.593886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 707877 episodes
GETTING ACTION FROM:
action 3, numVisits=707870, meanQ=6.235277, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.645733 0.833212 0.563181 0.865844 0.702395 0.593886 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 287
Initial state: 0 0.476856 0.890542 0.526988 0.866461 0.576979 0.828404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 707289 episodes
GETTING ACTION FROM:
action 1, numVisits=707223, meanQ=6.239600, numObservations: 3
action -1, numVisits=47, meanQ=5.163273, numObservations: 1
action 2, numVisits=11, meanQ=3.544555, numObservations: 3
action 3, numVisits=6, meanQ=2.663333, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.476856 0.890542 0.526988 0.866461 0.576979 0.828404 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=79240, meanQ=8.860790, numObservations: 4
action 3, numVisits=35709, meanQ=8.848348, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 843762 episodes
GETTING ACTION FROM:
action 3, numVisits=654592, meanQ=6.946248, numObservations: 5
action 2, numVisits=304119, meanQ=6.942109, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.476856 0.890542 0.526988 0.866461 0.576979 0.828404 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=6888, meanQ=8.337875, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 866626 episodes
GETTING ACTION FROM:
action 2, numVisits=873409, meanQ=6.427431, numObservations: 4
action 1, numVisits=104, meanQ=5.644135, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.476856 0.890542 0.526988 0.866461 0.576979 0.828404 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 288
Initial state: 0 0.621257 0.582451 0.68559 0.834729 0.512537 0.853823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697135 episodes
GETTING ACTION FROM:
action 1, numVisits=697077, meanQ=6.227421, numObservations: 4
action -1, numVisits=29, meanQ=4.855293, numObservations: 1
action 0, numVisits=19, meanQ=4.548234, numObservations: 1
action 3, numVisits=8, meanQ=2.873750, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 2 0.621257 0.582451 0.68559 0.834729 0.512537 0.853823 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 289
Initial state: 0 0.632372 0.826215 0.540908 0.812619 0.880465 0.832823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689157 episodes
GETTING ACTION FROM:
action 1, numVisits=689049, meanQ=6.230524, numObservations: 5
action -1, numVisits=87, meanQ=5.441405, numObservations: 1
action 0, numVisits=17, meanQ=4.315930, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.632372 0.826215 0.540908 0.812619 0.880465 0.832823 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 290
Initial state: 0 0.214331 0.489741 0.578445 0.813961 0.562487 0.806086 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694856 episodes
GETTING ACTION FROM:
action 3, numVisits=694821, meanQ=6.207668, numObservations: 4
action -1, numVisits=29, meanQ=4.777636, numObservations: 1
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.214331 0.489741 0.578445 0.813961 0.562487 0.806086 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 291
Initial state: 0 0.670602 0.800097 0.572226 0.802795 0.520172 0.665248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696438 episodes
GETTING ACTION FROM:
action 1, numVisits=696420, meanQ=6.234064, numObservations: 4
action -1, numVisits=11, meanQ=4.027600, numObservations: 1
action 3, numVisits=4, meanQ=1.992525, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.670602 0.800097 0.572226 0.802795 0.520172 0.665248 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 292
Initial state: 0 0.240349 0.0611487 0.69478 0.818257 0.541852 0.87807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697571 episodes
GETTING ACTION FROM:
action 1, numVisits=697447, meanQ=6.222016, numObservations: 4
action 2, numVisits=72, meanQ=5.185278, numObservations: 3
action -1, numVisits=47, meanQ=5.142767, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.240349 0.0611487 0.69478 0.818257 0.541852 0.87807 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=58864, meanQ=8.881779, numObservations: 3
action 2, numVisits=36636, meanQ=8.874831, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 854382 episodes
GETTING ACTION FROM:
action 3, numVisits=761104, meanQ=6.777151, numObservations: 3
action 2, numVisits=188722, meanQ=6.768394, numObservations: 5
action 1, numVisits=57, meanQ=5.727368, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.240349 0.0611487 0.69478 0.818257 0.541852 0.87807 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 293
Initial state: 0 0.505221 0.802484 0.660503 0.218071 0.622146 0.842411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 469695 episodes
GETTING ACTION FROM:
action -1, numVisits=469676, meanQ=4.179468, numObservations: 1
action 2, numVisits=13, meanQ=0.613854, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: -1
Next state: 0 0.505221 0.802484 0.660503 0.218071 0.622146 0.842411 w: 1
Observation: 0 0.501574 0 0.7352 0 0.525102 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=469622, meanQ=6.243486, numObservations: 5
action 3, numVisits=38, meanQ=4.730542, numObservations: 4
action 2, numVisits=13, meanQ=3.683085, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 734830 episodes
GETTING ACTION FROM:
action 1, numVisits=1204436, meanQ=6.361613, numObservations: 5
action 3, numVisits=38, meanQ=4.730542, numObservations: 4
action 0, numVisits=16, meanQ=4.410679, numObservations: 1
action 2, numVisits=13, meanQ=3.683085, numObservations: 5
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.505221 0.802484 0.660503 0.218071 0.622146 0.842411 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 294
Initial state: 0 0.541991 0.855259 0.537977 0.891716 0.0637353 0.803552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 707494 episodes
GETTING ACTION FROM:
action 2, numVisits=707471, meanQ=6.232705, numObservations: 3
action 1, numVisits=12, meanQ=4.000000, numObservations: 3
action 3, numVisits=7, meanQ=3.285714, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.541991 0.855259 0.537977 0.891716 0.0637353 0.803552 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 295
Initial state: 0 0.526667 0.841942 0.964652 0.892318 0.643954 0.89498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699290 episodes
GETTING ACTION FROM:
action 1, numVisits=699252, meanQ=6.233769, numObservations: 4
action 0, numVisits=30, meanQ=4.840772, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.526667 0.841942 0.964652 0.892318 0.643954 0.89498 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 296
Initial state: 0 0.251012 0.0744478 0.685019 0.850752 0.606825 0.808593 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688471 episodes
GETTING ACTION FROM:
action 2, numVisits=688366, meanQ=6.223062, numObservations: 5
action 0, numVisits=64, meanQ=5.309704, numObservations: 1
action -1, numVisits=27, meanQ=4.801646, numObservations: 1
action 1, numVisits=12, meanQ=2.414183, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.251012 0.0744478 0.685019 0.850752 0.606825 0.808593 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 297
Initial state: 0 0.535822 0.857738 0.709883 0.803429 0.562753 0.879526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693581 episodes
GETTING ACTION FROM:
action 3, numVisits=693555, meanQ=6.223044, numObservations: 4
action -1, numVisits=21, meanQ=4.554545, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.535822 0.857738 0.709883 0.803429 0.562753 0.879526 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 298
Initial state: 0 0.583823 0.806279 0.660002 0.883233 0.646175 0.735633 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688337 episodes
GETTING ACTION FROM:
action 3, numVisits=688331, meanQ=6.233423, numObservations: 5
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.583823 0.806279 0.660002 0.883233 0.646175 0.735633 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=94911, meanQ=8.888761, numObservations: 4
action 2, numVisits=4, meanQ=3.997525, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 850372 episodes
GETTING ACTION FROM:
action 1, numVisits=945252, meanQ=6.660128, numObservations: 4
action 2, numVisits=31, meanQ=5.128713, numObservations: 3
action 3, numVisits=5, meanQ=1.396000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.583823 0.806279 0.660002 0.883233 0.646175 0.735633 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 299
Initial state: 0 0.644382 0.897314 0.341489 0.386959 0.58762 0.891524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701023 episodes
GETTING ACTION FROM:
action 3, numVisits=701013, meanQ=6.226241, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.644382 0.897314 0.341489 0.386959 0.58762 0.891524 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 300
Initial state: 0 0.685592 0.878574 0.371299 0.0434995 0.590649 0.856515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697392 episodes
GETTING ACTION FROM:
action 1, numVisits=696465, meanQ=6.237904, numObservations: 4
action 2, numVisits=921, meanQ=5.988068, numObservations: 4
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.685592 0.878574 0.371299 0.0434995 0.590649 0.856515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 301
Initial state: 0 0.641902 0.873101 0.226346 0.391678 0.605792 0.886493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 707641 episodes
GETTING ACTION FROM:
action 1, numVisits=707589, meanQ=6.214407, numObservations: 3
action 0, numVisits=28, meanQ=4.766677, numObservations: 1
action -1, numVisits=21, meanQ=4.521551, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.641902 0.873101 0.226346 0.391678 0.605792 0.886493 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 302
Initial state: 0 0.643664 0.813569 0.551229 0.889524 0.598997 0.0603956 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698381 episodes
GETTING ACTION FROM:
action 2, numVisits=698232, meanQ=6.190777, numObservations: 4
action 3, numVisits=139, meanQ=5.556334, numObservations: 4
action 1, numVisits=6, meanQ=2.663333, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.643664 0.813569 0.551229 0.889524 0.598997 0.0603956 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 303
Initial state: 0 0.504701 0.863168 0.57749 0.884246 0.0919653 0.323032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695899 episodes
GETTING ACTION FROM:
action 1, numVisits=695806, meanQ=6.241875, numObservations: 4
action 3, numVisits=85, meanQ=5.431768, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.504701 0.863168 0.57749 0.884246 0.0919653 0.323032 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 304
Initial state: 0 0.585322 0.851914 0.654182 0.895905 0.0190893 0.117202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691628 episodes
GETTING ACTION FROM:
action 1, numVisits=655072, meanQ=6.227350, numObservations: 5
action 3, numVisits=36536, meanQ=6.197039, numObservations: 5
action 0, numVisits=16, meanQ=4.339277, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.585322 0.851914 0.654182 0.895905 0.0190893 0.117202 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 305
Initial state: 0 0.611189 0.877801 0.628598 0.880287 0.635202 0.440567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699758 episodes
GETTING ACTION FROM:
action 2, numVisits=699738, meanQ=6.228869, numObservations: 4
action 3, numVisits=9, meanQ=2.662233, numObservations: 3
action 1, numVisits=7, meanQ=0.554300, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.611189 0.877801 0.628598 0.880287 0.635202 0.440567 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31283, meanQ=6.514788, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 855433 episodes
GETTING ACTION FROM:
action 3, numVisits=886707, meanQ=6.334314, numObservations: 4
action 0, numVisits=7, meanQ=3.232857, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.611189 0.877801 0.628598 0.880287 0.635202 0.440567 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11.89
Run # 306
Initial state: 0 0.68421 0.892614 0.968346 0.72969 0.677345 0.825298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 681700 episodes
GETTING ACTION FROM:
action 1, numVisits=681683, meanQ=6.226673, numObservations: 5
action 3, numVisits=6, meanQ=2.331683, numObservations: 2
action 2, numVisits=7, meanQ=1.997157, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.68421 0.892614 0.968346 0.72969 0.677345 0.825298 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 307
Initial state: 0 0.649901 0.90871 0.621261 0.893271 0.559275 0.801694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698020 episodes
GETTING ACTION FROM:
action 3, numVisits=697977, meanQ=6.220932, numObservations: 4
action 0, numVisits=31, meanQ=4.892123, numObservations: 1
action 2, numVisits=6, meanQ=2.663333, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.649901 0.90871 0.621261 0.893271 0.559275 0.801694 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 308
Initial state: 0 0.518695 0.850274 0.312281 0.214205 0.533006 0.870612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687586 episodes
GETTING ACTION FROM:
action 2, numVisits=687515, meanQ=6.224606, numObservations: 5
action 0, numVisits=43, meanQ=5.066258, numObservations: 1
action 3, numVisits=14, meanQ=4.212143, numObservations: 3
action 1, numVisits=12, meanQ=4.090833, numObservations: 4
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 0 0.518695 0.850274 0.312281 0.214205 0.533006 0.870612 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=17743, meanQ=8.594355, numObservations: 3
action 3, numVisits=6, meanQ=3.983333, numObservations: 2
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 867667 episodes
GETTING ACTION FROM:
action 1, numVisits=885375, meanQ=6.603927, numObservations: 3
action 2, numVisits=29, meanQ=5.168628, numObservations: 3
action 3, numVisits=13, meanQ=3.607692, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.518695 0.850274 0.312281 0.214205 0.533006 0.870612 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 309
Initial state: 0 0.588347 0.854908 0.666156 0.811229 0.802364 0.641244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702972 episodes
GETTING ACTION FROM:
action 2, numVisits=702934, meanQ=6.176360, numObservations: 4
action -1, numVisits=32, meanQ=4.857492, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.588347 0.854908 0.666156 0.811229 0.802364 0.641244 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 310
Initial state: 0 0.61314 0.887007 0.760714 0.877382 0.584228 0.879619 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692883 episodes
GETTING ACTION FROM:
action 2, numVisits=692871, meanQ=6.232718, numObservations: 5
action 3, numVisits=6, meanQ=2.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.61314 0.887007 0.760714 0.877382 0.584228 0.879619 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 311
Initial state: 0 0.65827 0.87437 0.336311 0.521646 0.624457 0.848436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 682398 episodes
GETTING ACTION FROM:
action 2, numVisits=682383, meanQ=6.233343, numObservations: 5
action 1, numVisits=9, meanQ=3.653333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.65827 0.87437 0.336311 0.521646 0.624457 0.848436 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=75325, meanQ=8.884809, numObservations: 5
action 1, numVisits=18225, meanQ=8.858615, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 837363 episodes
GETTING ACTION FROM:
action 3, numVisits=618968, meanQ=6.650731, numObservations: 5
action 1, numVisits=311614, meanQ=6.646699, numObservations: 5
action 2, numVisits=332, meanQ=6.251115, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.65827 0.87437 0.336311 0.521646 0.624457 0.848436 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 312
Initial state: 0 0.637656 0.858924 0.574369 0.442189 0.544168 0.827295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697846 episodes
GETTING ACTION FROM:
action 3, numVisits=697719, meanQ=6.225885, numObservations: 4
action 2, numVisits=55, meanQ=5.224729, numObservations: 4
action -1, numVisits=37, meanQ=5.022744, numObservations: 1
action 0, numVisits=28, meanQ=4.754888, numObservations: 1
action 1, numVisits=7, meanQ=1.998571, numObservations: 3
action: 3
Next state: 1 0.637656 0.858924 0.574369 0.442189 0.544168 0.827295 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 313
Initial state: 0 0.260554 0.46627 0.574216 0.843009 0.691904 0.886106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 704822 episodes
GETTING ACTION FROM:
action 3, numVisits=704815, meanQ=6.240320, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.260554 0.46627 0.574216 0.843009 0.691904 0.886106 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 314
Initial state: 0 0.680638 0.893713 0.763871 0.683251 0.568231 0.822933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698416 episodes
GETTING ACTION FROM:
action 1, numVisits=698404, meanQ=6.193484, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.680638 0.893713 0.763871 0.683251 0.568231 0.822933 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 315
Initial state: 0 0.985579 0.82996 0.508029 0.862336 0.640769 0.821402 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701758 episodes
GETTING ACTION FROM:
action 2, numVisits=701699, meanQ=6.238463, numObservations: 4
action -1, numVisits=34, meanQ=4.955381, numObservations: 1
action 3, numVisits=21, meanQ=3.851429, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.985579 0.82996 0.508029 0.862336 0.640769 0.821402 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 316
Initial state: 0 0.945284 0.416732 0.661612 0.887085 0.668462 0.802005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692473 episodes
GETTING ACTION FROM:
action 1, numVisits=486491, meanQ=6.226334, numObservations: 5
action 2, numVisits=205908, meanQ=6.214225, numObservations: 5
action -1, numVisits=33, meanQ=4.920923, numObservations: 1
action 3, numVisits=39, meanQ=4.838213, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.945284 0.416732 0.661612 0.887085 0.668462 0.802005 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 317
Initial state: 0 0.581861 0.82148 0.403462 0.959343 0.627118 0.834667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692623 episodes
GETTING ACTION FROM:
action 3, numVisits=692574, meanQ=6.244228, numObservations: 4
action 1, numVisits=41, meanQ=5.012927, numObservations: 3
action 2, numVisits=4, meanQ=-0.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.581861 0.82148 0.403462 0.959343 0.627118 0.834667 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 318
Initial state: 0 0.514215 0.805136 0.632355 0.880191 0.889841 0.174845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701690 episodes
GETTING ACTION FROM:
action 2, numVisits=701639, meanQ=6.166861, numObservations: 4
action 0, numVisits=29, meanQ=4.792808, numObservations: 1
action 3, numVisits=12, meanQ=3.414167, numObservations: 3
action 1, numVisits=8, meanQ=3.121250, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.514215 0.805136 0.632355 0.880191 0.889841 0.174845 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 319
Initial state: 0 0.875108 0.98145 0.59137 0.832441 0.683836 0.86638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696498 episodes
GETTING ACTION FROM:
action 2, numVisits=696401, meanQ=6.236735, numObservations: 5
action -1, numVisits=36, meanQ=5.008434, numObservations: 1
action 0, numVisits=27, meanQ=4.786503, numObservations: 1
action 1, numVisits=26, meanQ=4.341169, numObservations: 3
action 3, numVisits=8, meanQ=3.121250, numObservations: 3
action: 2
Next state: 1 0.875108 0.98145 0.59137 0.832441 0.683836 0.86638 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 320
Initial state: 0 0.620147 0.0548586 0.626414 0.880054 0.592128 0.88075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697258 episodes
GETTING ACTION FROM:
action 3, numVisits=696355, meanQ=6.237209, numObservations: 4
action 2, numVisits=849, meanQ=5.971013, numObservations: 4
action 1, numVisits=50, meanQ=5.067002, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.620147 0.0548586 0.626414 0.880054 0.592128 0.88075 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 321
Initial state: 0 0.671293 0.824112 0.768823 0.820539 0.570387 0.884954 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693393 episodes
GETTING ACTION FROM:
action 2, numVisits=693087, meanQ=6.219987, numObservations: 5
action 1, numVisits=226, meanQ=5.697057, numObservations: 3
action -1, numVisits=67, meanQ=5.324963, numObservations: 1
action 3, numVisits=11, meanQ=2.815464, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.671293 0.824112 0.768823 0.820539 0.570387 0.884954 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 322
Initial state: 0 0.671299 0.881753 0.580604 0.805297 0.0860025 0.498943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697758 episodes
GETTING ACTION FROM:
action 1, numVisits=697699, meanQ=6.230067, numObservations: 4
action -1, numVisits=48, meanQ=5.137848, numObservations: 1
action 3, numVisits=6, meanQ=2.663333, numObservations: 2
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.671299 0.881753 0.580604 0.805297 0.0860025 0.498943 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 323
Initial state: 0 0.633407 0.854872 0.000245058 0.94485 0.60811 0.888431 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 475853 episodes
GETTING ACTION FROM:
action -1, numVisits=475847, meanQ=4.260602, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.633407 0.854872 0.000245058 0.94485 0.60811 0.888431 w: 1
Observation: 0 0.589728 0 0 0 0.590012 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=475832, meanQ=6.328471, numObservations: 4
action 3, numVisits=10, meanQ=3.198000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 744815 episodes
GETTING ACTION FROM:
action 2, numVisits=1220566, meanQ=6.318009, numObservations: 4
action 0, numVisits=81, meanQ=5.470885, numObservations: 1
action 3, numVisits=10, meanQ=3.198000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.633407 0.854872 0.000245058 0.94485 0.60811 0.888431 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=45629, meanQ=8.168367, numObservations: 4
action 1, numVisits=29, meanQ=4.776210, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 767607 episodes
GETTING ACTION FROM:
action 2, numVisits=813234, meanQ=6.194187, numObservations: 5
action 1, numVisits=29, meanQ=4.776210, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.633407 0.854872 0.000245058 0.94485 0.60811 0.888431 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 5.8309
Run # 324
Initial state: 0 0.62008 0.87179 0.709504 0.0129434 0.679015 0.81871 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703507 episodes
GETTING ACTION FROM:
action 2, numVisits=703498, meanQ=6.304742, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.62008 0.87179 0.709504 0.0129434 0.679015 0.81871 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 325
Initial state: 0 0.405001 0.0522024 0.548145 0.877121 0.689103 0.824636 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 469254 episodes
GETTING ACTION FROM:
action 0, numVisits=469249, meanQ=4.160418, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.405001 0.0522024 0.548145 0.877121 0.689103 0.824636 w: 1
Observation: 0 0 0.111288 0 0.92169 0 0.850708 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=469240, meanQ=6.228489, numObservations: 5
action 1, numVisits=4, meanQ=-0.505000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 733476 episodes
GETTING ACTION FROM:
action 3, numVisits=1202697, meanQ=6.220175, numObservations: 5
action -1, numVisits=19, meanQ=4.468189, numObservations: 1
action 1, numVisits=4, meanQ=-0.505000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.405001 0.0522024 0.548145 0.877121 0.689103 0.824636 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 326
Initial state: 0 0.813572 0.0849196 0.669466 0.840263 0.50077 0.842527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689861 episodes
GETTING ACTION FROM:
action 2, numVisits=689769, meanQ=6.165096, numObservations: 5
action -1, numVisits=50, meanQ=5.131299, numObservations: 1
action 0, numVisits=27, meanQ=4.726897, numObservations: 1
action 3, numVisits=9, meanQ=2.553333, numObservations: 4
action 1, numVisits=6, meanQ=0.831667, numObservations: 3
action: 2
Next state: 1 0.813572 0.0849196 0.669466 0.840263 0.50077 0.842527 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 327
Initial state: 0 0.674932 0.834187 0.593019 0.893368 0.538627 0.633161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696408 episodes
GETTING ACTION FROM:
action 3, numVisits=696304, meanQ=6.236882, numObservations: 4
action -1, numVisits=91, meanQ=5.469823, numObservations: 1
action 1, numVisits=7, meanQ=1.841443, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 0 0.674932 0.834187 0.593019 0.893368 0.538627 0.633161 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=95409, meanQ=8.892574, numObservations: 3
action 2, numVisits=258, meanQ=8.482095, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 868069 episodes
GETTING ACTION FROM:
action 1, numVisits=959461, meanQ=6.450647, numObservations: 3
action 2, numVisits=4275, meanQ=6.343694, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.674932 0.834187 0.593019 0.893368 0.538627 0.633161 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 328
Initial state: 0 0.472845 0.342123 0.587163 0.86512 0.60634 0.837928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697792 episodes
GETTING ACTION FROM:
action 1, numVisits=697760, meanQ=6.226469, numObservations: 4
action -1, numVisits=24, meanQ=4.662527, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 0 0.472845 0.342123 0.587163 0.86512 0.60634 0.837928 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=37694, meanQ=8.646382, numObservations: 5
action 2, numVisits=64, meanQ=7.794844, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 843220 episodes
GETTING ACTION FROM:
action 2, numVisits=708328, meanQ=6.779818, numObservations: 5
action 3, numVisits=172528, meanQ=6.760463, numObservations: 5
action 1, numVisits=123, meanQ=6.102405, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.472845 0.342123 0.587163 0.86512 0.60634 0.837928 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 329
Initial state: 0 0.642682 0.84263 0.20007 0.830552 0.542921 0.822784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 703914 episodes
GETTING ACTION FROM:
action 2, numVisits=703869, meanQ=6.181609, numObservations: 4
action -1, numVisits=22, meanQ=4.548602, numObservations: 1
action 3, numVisits=19, meanQ=3.262111, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.642682 0.84263 0.20007 0.830552 0.542921 0.822784 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=114239, meanQ=8.859001, numObservations: 4
action 1, numVisits=11, meanQ=6.362727, numObservations: 2
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 858782 episodes
GETTING ACTION FROM:
action 3, numVisits=972940, meanQ=6.856987, numObservations: 4
action 1, numVisits=83, meanQ=5.989157, numObservations: 5
action 2, numVisits=10, meanQ=4.098010, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.642682 0.84263 0.20007 0.830552 0.542921 0.822784 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 330
Initial state: 0 0.0833167 0.738322 0.567504 0.86136 0.680955 0.840756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696784 episodes
GETTING ACTION FROM:
action 3, numVisits=696734, meanQ=6.262063, numObservations: 4
action -1, numVisits=36, meanQ=5.023741, numObservations: 1
action 1, numVisits=9, meanQ=2.441133, numObservations: 2
action 2, numVisits=3, meanQ=-0.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.0833167 0.738322 0.567504 0.86136 0.680955 0.840756 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 331
Initial state: 0 0.735607 0.911149 0.561218 0.815386 0.557512 0.884843 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 684891 episodes
GETTING ACTION FROM:
action 2, numVisits=684884, meanQ=6.091378, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.735607 0.911149 0.561218 0.815386 0.557512 0.884843 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 332
Initial state: 0 0.673731 0.809336 0.651826 0.889081 0.327593 0.311101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690683 episodes
GETTING ACTION FROM:
action 3, numVisits=690611, meanQ=6.241930, numObservations: 5
action -1, numVisits=35, meanQ=5.003722, numObservations: 1
action 0, numVisits=32, meanQ=4.913650, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 0 0.673731 0.809336 0.651826 0.889081 0.327593 0.311101 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=41337, meanQ=8.939285, numObservations: 3
action 2, numVisits=34007, meanQ=8.935894, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 852886 episodes
GETTING ACTION FROM:
action 1, numVisits=666367, meanQ=6.784103, numObservations: 4
action 2, numVisits=261862, meanQ=6.778651, numObservations: 4
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.673731 0.809336 0.651826 0.889081 0.327593 0.311101 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 333
Initial state: 0 0.618469 0.89453 0.636339 0.829729 0.692671 0.892783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699115 episodes
GETTING ACTION FROM:
action 1, numVisits=699088, meanQ=6.240039, numObservations: 4
action -1, numVisits=18, meanQ=4.502529, numObservations: 1
action 2, numVisits=5, meanQ=0.998020, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.618469 0.89453 0.636339 0.829729 0.692671 0.892783 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 334
Initial state: 0 0.943463 0.964141 0.67929 0.8921 0.53071 0.824994 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697931 episodes
GETTING ACTION FROM:
action 1, numVisits=697863, meanQ=6.236782, numObservations: 4
action -1, numVisits=60, meanQ=5.289114, numObservations: 1
action 3, numVisits=4, meanQ=-0.505000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.943463 0.964141 0.67929 0.8921 0.53071 0.824994 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 335
Initial state: 0 0.68399 0.821005 0.605228 0.819908 0.523714 0.57761 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697897 episodes
GETTING ACTION FROM:
action 3, numVisits=697768, meanQ=6.229150, numObservations: 4
action 1, numVisits=124, meanQ=4.986615, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.68399 0.821005 0.605228 0.819908 0.523714 0.57761 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 336
Initial state: 0 0.632066 0.82566 0.51339 0.843573 0.578626 0.0770691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695774 episodes
GETTING ACTION FROM:
action 3, numVisits=695730, meanQ=6.226944, numObservations: 4
action -1, numVisits=19, meanQ=4.460964, numObservations: 1
action 2, numVisits=10, meanQ=3.881000, numObservations: 3
action 1, numVisits=13, meanQ=3.606931, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.632066 0.82566 0.51339 0.843573 0.578626 0.0770691 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 337
Initial state: 0 0.538329 0.827952 0.166903 0.838774 0.674102 0.893033 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695610 episodes
GETTING ACTION FROM:
action 3, numVisits=695603, meanQ=6.225039, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.538329 0.827952 0.166903 0.838774 0.674102 0.893033 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 338
Initial state: 0 0.603263 0.814191 0.232314 0.296164 0.58488 0.854085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706544 episodes
GETTING ACTION FROM:
action 1, numVisits=706538, meanQ=6.235446, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.603263 0.814191 0.232314 0.296164 0.58488 0.854085 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 339
Initial state: 0 0.740139 0.785072 0.621861 0.86597 0.572902 0.810801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685845 episodes
GETTING ACTION FROM:
action 1, numVisits=685718, meanQ=6.237913, numObservations: 5
action 2, numVisits=76, meanQ=5.376451, numObservations: 4
action -1, numVisits=45, meanQ=5.137319, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 2 0.740139 0.785072 0.621861 0.86597 0.572902 0.810801 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 340
Initial state: 0 0.581194 0.895838 0.663431 0.80778 0.7235 0.810912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695462 episodes
GETTING ACTION FROM:
action 3, numVisits=695388, meanQ=6.222803, numObservations: 4
action -1, numVisits=70, meanQ=5.348520, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.581194 0.895838 0.663431 0.80778 0.7235 0.810912 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 341
Initial state: 0 0.64925 0.809654 0.504025 0.800062 0.771085 0.516459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 474405 episodes
GETTING ACTION FROM:
action -1, numVisits=474382, meanQ=4.193881, numObservations: 1
action 3, numVisits=18, meanQ=1.271667, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.64925 0.809654 0.504025 0.800062 0.771085 0.516459 w: 1
Observation: 0 0.594931 0 0.573428 0 0.714727 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=474377, meanQ=6.261031, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 751794 episodes
GETTING ACTION FROM:
action 3, numVisits=1226084, meanQ=6.266145, numObservations: 5
action -1, numVisits=65, meanQ=5.336799, numObservations: 1
action 0, numVisits=24, meanQ=4.734559, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.64925 0.809654 0.504025 0.800062 0.771085 0.516459 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 342
Initial state: 0 0.303222 0.539093 0.603839 0.810613 0.598231 0.804157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695480 episodes
GETTING ACTION FROM:
action 2, numVisits=695321, meanQ=6.217649, numObservations: 5
action 3, numVisits=112, meanQ=5.462328, numObservations: 4
action -1, numVisits=44, meanQ=5.103276, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.303222 0.539093 0.603839 0.810613 0.598231 0.804157 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 343
Initial state: 0 0.588633 0.800578 0.474222 0.47393 0.662601 0.845636 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697451 episodes
GETTING ACTION FROM:
action 3, numVisits=697324, meanQ=6.235454, numObservations: 4
action 0, numVisits=94, meanQ=5.482392, numObservations: 1
action 2, numVisits=14, meanQ=3.992857, numObservations: 4
action 1, numVisits=17, meanQ=3.762953, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.588633 0.800578 0.474222 0.47393 0.662601 0.845636 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 344
Initial state: 0 0.825679 0.0746402 0.675912 0.806196 0.592859 0.856311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706823 episodes
GETTING ACTION FROM:
action 2, numVisits=706769, meanQ=6.221362, numObservations: 4
action 0, numVisits=32, meanQ=4.862156, numObservations: 1
action 3, numVisits=16, meanQ=2.873750, numObservations: 2
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.825679 0.0746402 0.675912 0.806196 0.592859 0.856311 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 345
Initial state: 0 0.599474 0.875261 0.787056 0.0518586 0.591587 0.87456 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695726 episodes
GETTING ACTION FROM:
action 3, numVisits=695645, meanQ=6.218206, numObservations: 4
action 2, numVisits=45, meanQ=5.083844, numObservations: 4
action 0, numVisits=28, meanQ=4.796110, numObservations: 1
action 1, numVisits=6, meanQ=2.331683, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.599474 0.875261 0.787056 0.0518586 0.591587 0.87456 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 346
Initial state: 0 0.0298675 0.655395 0.670241 0.813241 0.552942 0.878376 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693527 episodes
GETTING ACTION FROM:
action 3, numVisits=693502, meanQ=6.234719, numObservations: 4
action 0, numVisits=20, meanQ=4.585500, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0298675 0.655395 0.670241 0.813241 0.552942 0.878376 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 347
Initial state: 0 0.523371 0.896825 0.539333 0.852124 0.0105096 0.567361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699001 episodes
GETTING ACTION FROM:
action 3, numVisits=698932, meanQ=6.231573, numObservations: 4
action 0, numVisits=45, meanQ=5.122150, numObservations: 1
action 2, numVisits=20, meanQ=3.990000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.523371 0.896825 0.539333 0.852124 0.0105096 0.567361 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=39641, meanQ=8.940852, numObservations: 3
action 1, numVisits=35626, meanQ=8.938905, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 857823 episodes
GETTING ACTION FROM:
action 2, numVisits=640210, meanQ=6.881157, numObservations: 4
action 1, numVisits=292809, meanQ=6.876650, numObservations: 3
action 3, numVisits=72, meanQ=5.975972, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.523371 0.896825 0.539333 0.852124 0.0105096 0.567361 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 348
Initial state: 0 0.524521 0.875751 0.390582 0.0882144 0.69751 0.815667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698232 episodes
GETTING ACTION FROM:
action 3, numVisits=698113, meanQ=6.238452, numObservations: 4
action 0, numVisits=41, meanQ=5.089734, numObservations: 1
action 1, numVisits=47, meanQ=4.670430, numObservations: 5
action -1, numVisits=24, meanQ=4.642985, numObservations: 1
action 2, numVisits=7, meanQ=2.138586, numObservations: 4
action: 3
Next state: 1 0.524521 0.875751 0.390582 0.0882144 0.69751 0.815667 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 349
Initial state: 0 0.631202 0.865023 0.838335 0.418414 0.581439 0.883331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699885 episodes
GETTING ACTION FROM:
action 3, numVisits=699878, meanQ=6.222678, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.631202 0.865023 0.838335 0.418414 0.581439 0.883331 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 350
Initial state: 0 0.653288 0.839511 0.0603906 0.256549 0.553363 0.840251 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698471 episodes
GETTING ACTION FROM:
action 1, numVisits=698461, meanQ=6.223753, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 0 0.653288 0.839511 0.0603906 0.256549 0.553363 0.840251 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25895, meanQ=6.428694, numObservations: 3
action 1, numVisits=5099, meanQ=5.410562, numObservations: 4
action 3, numVisits=8, meanQ=2.872513, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 869167 episodes
GETTING ACTION FROM:
action 2, numVisits=895062, meanQ=6.811167, numObservations: 3
action 1, numVisits=5099, meanQ=5.410562, numObservations: 4
action 3, numVisits=8, meanQ=2.872513, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.653288 0.839511 0.0603906 0.256549 0.553363 0.840251 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=10473, meanQ=8.557191, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 847914 episodes
GETTING ACTION FROM:
action 1, numVisits=858288, meanQ=6.623641, numObservations: 5
action 2, numVisits=98, meanQ=5.846837, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.653288 0.839511 0.0603906 0.256549 0.553363 0.840251 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 351
Initial state: 0 0.516406 0.863802 0.692717 0.847496 0.27633 0.725964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697257 episodes
GETTING ACTION FROM:
action 3, numVisits=697192, meanQ=6.219251, numObservations: 4
action -1, numVisits=57, meanQ=5.247843, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.516406 0.863802 0.692717 0.847496 0.27633 0.725964 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=74358, meanQ=8.859507, numObservations: 4
action 1, numVisits=39131, meanQ=8.849665, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 854759 episodes
GETTING ACTION FROM:
action 2, numVisits=545447, meanQ=6.500189, numObservations: 4
action 1, numVisits=422801, meanQ=6.498974, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.516406 0.863802 0.692717 0.847496 0.27633 0.725964 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 352
Initial state: 0 0.657502 0.874336 0.696195 0.855802 0.898932 0.942732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697012 episodes
GETTING ACTION FROM:
action 2, numVisits=696985, meanQ=6.225299, numObservations: 4
action 3, numVisits=16, meanQ=3.436256, numObservations: 3
action 1, numVisits=7, meanQ=1.998571, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.657502 0.874336 0.696195 0.855802 0.898932 0.942732 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 353
Initial state: 0 0.93545 0.0991671 0.537034 0.80348 0.502741 0.827551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696651 episodes
GETTING ACTION FROM:
action 2, numVisits=696558, meanQ=6.240722, numObservations: 4
action 0, numVisits=32, meanQ=4.894500, numObservations: 1
action -1, numVisits=27, meanQ=4.827359, numObservations: 1
action 3, numVisits=33, meanQ=4.718485, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.93545 0.0991671 0.537034 0.80348 0.502741 0.827551 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 354
Initial state: 0 0.620434 0.837275 0.612276 0.314836 0.603041 0.832812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706731 episodes
GETTING ACTION FROM:
action 3, numVisits=706687, meanQ=6.177817, numObservations: 3
action 1, numVisits=38, meanQ=4.963426, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.620434 0.837275 0.612276 0.314836 0.603041 0.832812 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 355
Initial state: 0 0.811382 0.23027 0.542491 0.833034 0.683004 0.887167 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699216 episodes
GETTING ACTION FROM:
action 3, numVisits=699149, meanQ=6.239641, numObservations: 4
action 2, numVisits=59, meanQ=5.012207, numObservations: 5
action 1, numVisits=4, meanQ=-0.505000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.811382 0.23027 0.542491 0.833034 0.683004 0.887167 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 356
Initial state: 0 0.217258 0.366411 0.503252 0.867351 0.509363 0.833462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696085 episodes
GETTING ACTION FROM:
action 3, numVisits=696051, meanQ=6.232005, numObservations: 4
action 0, numVisits=29, meanQ=4.832141, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.217258 0.366411 0.503252 0.867351 0.509363 0.833462 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 357
Initial state: 0 0.652793 0.871751 0.593621 0.884057 0.610141 0.784866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 683793 episodes
GETTING ACTION FROM:
action 3, numVisits=680301, meanQ=6.241433, numObservations: 5
action 2, numVisits=3335, meanQ=6.108144, numObservations: 5
action 1, numVisits=141, meanQ=5.570292, numObservations: 4
action 0, numVisits=14, meanQ=4.229021, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 2 0.652793 0.871751 0.593621 0.884057 0.610141 0.784866 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 358
Initial state: 0 0.613086 0.81025 0.742883 0.715 0.63813 0.832269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688930 episodes
GETTING ACTION FROM:
action 1, numVisits=688862, meanQ=6.229360, numObservations: 5
action 0, numVisits=55, meanQ=5.247386, numObservations: 1
action 2, numVisits=6, meanQ=2.663333, numObservations: 3
action 3, numVisits=5, meanQ=1.396000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.613086 0.81025 0.742883 0.715 0.63813 0.832269 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 359
Initial state: 0 0.509422 0.880979 0.620212 0.702275 0.538028 0.852949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672102 episodes
GETTING ACTION FROM:
action 3, numVisits=672083, meanQ=6.142984, numObservations: 5
action 2, numVisits=9, meanQ=3.552244, numObservations: 2
action 1, numVisits=6, meanQ=2.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.509422 0.880979 0.620212 0.702275 0.538028 0.852949 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 360
Initial state: 0 0.588253 0.867153 0.229359 0.146292 0.607049 0.883516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 705211 episodes
GETTING ACTION FROM:
action 3, numVisits=705007, meanQ=6.237862, numObservations: 3
action 2, numVisits=108, meanQ=5.499631, numObservations: 5
action -1, numVisits=48, meanQ=5.184413, numObservations: 1
action 0, numVisits=47, meanQ=5.171741, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.588253 0.867153 0.229359 0.146292 0.607049 0.883516 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 361
Initial state: 0 0.642846 0.853566 0.123444 0.890474 0.591952 0.848992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691042 episodes
GETTING ACTION FROM:
action 2, numVisits=691035, meanQ=6.176865, numObservations: 5
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.642846 0.853566 0.123444 0.890474 0.591952 0.848992 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12168, meanQ=8.688061, numObservations: 4
action 3, numVisits=5280, meanQ=8.668362, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 867338 episodes
GETTING ACTION FROM:
action 3, numVisits=769028, meanQ=6.697447, numObservations: 3
action 1, numVisits=115522, meanQ=6.683902, numObservations: 4
action 2, numVisits=237, meanQ=6.221689, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.642846 0.853566 0.123444 0.890474 0.591952 0.848992 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 362
Initial state: 0 0.666421 0.878265 0.57183 0.878401 0.369364 0.727864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697526 episodes
GETTING ACTION FROM:
action 1, numVisits=697505, meanQ=6.228242, numObservations: 4
action 3, numVisits=16, meanQ=3.998763, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.666421 0.878265 0.57183 0.878401 0.369364 0.727864 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 363
Initial state: 0 0.659198 0.837108 0.612 0.821913 0.716814 0.869779 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690592 episodes
GETTING ACTION FROM:
action 2, numVisits=690574, meanQ=6.228365, numObservations: 5
action 3, numVisits=12, meanQ=0.665842, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.659198 0.837108 0.612 0.821913 0.716814 0.869779 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 364
Initial state: 0 0.515589 0.823272 0.660464 0.869192 0.208121 0.982155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689320 episodes
GETTING ACTION FROM:
action 2, numVisits=688833, meanQ=6.236604, numObservations: 5
action 1, numVisits=461, meanQ=5.896732, numObservations: 4
action 3, numVisits=22, meanQ=4.544095, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.515589 0.823272 0.660464 0.869192 0.208121 0.982155 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 365
Initial state: 0 0.546381 0.0238069 0.598769 0.831996 0.609162 0.815306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 709168 episodes
GETTING ACTION FROM:
action 1, numVisits=709132, meanQ=6.221362, numObservations: 3
action 3, numVisits=20, meanQ=4.440500, numObservations: 3
action 2, numVisits=12, meanQ=3.999175, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.546381 0.0238069 0.598769 0.831996 0.609162 0.815306 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 366
Initial state: 0 0.837372 0.523097 0.607997 0.810473 0.528904 0.821362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702424 episodes
GETTING ACTION FROM:
action 3, numVisits=702361, meanQ=6.217129, numObservations: 3
action -1, numVisits=19, meanQ=4.440910, numObservations: 1
action 0, numVisits=13, meanQ=4.189387, numObservations: 1
action 1, numVisits=25, meanQ=4.148400, numObservations: 4
action 2, numVisits=6, meanQ=2.331683, numObservations: 2
action: 3
Next state: 1 0.837372 0.523097 0.607997 0.810473 0.528904 0.821362 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 367
Initial state: 0 0.650854 0.859844 0.552395 0.62371 0.69094 0.852389 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700212 episodes
GETTING ACTION FROM:
action 2, numVisits=700126, meanQ=6.229582, numObservations: 4
action 0, numVisits=43, meanQ=5.110778, numObservations: 1
action -1, numVisits=35, meanQ=4.957901, numObservations: 1
action 1, numVisits=6, meanQ=2.663333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 0 0.650854 0.859844 0.552395 0.62371 0.69094 0.852389 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=96231, meanQ=8.891041, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 873050 episodes
GETTING ACTION FROM:
action 1, numVisits=969270, meanQ=6.539871, numObservations: 3
action 2, numVisits=10, meanQ=3.990000, numObservations: 2
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.650854 0.859844 0.552395 0.62371 0.69094 0.852389 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 368
Initial state: 0 0.594284 0.895768 0.587735 0.527308 0.545555 0.852862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695163 episodes
GETTING ACTION FROM:
action 3, numVisits=695102, meanQ=6.231497, numObservations: 4
action 2, numVisits=48, meanQ=4.990000, numObservations: 4
action 1, numVisits=9, meanQ=3.554444, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.594284 0.895768 0.587735 0.527308 0.545555 0.852862 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 369
Initial state: 0 0.698484 0.801424 0.626334 0.874111 0.267306 0.424752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695273 episodes
GETTING ACTION FROM:
action 3, numVisits=695245, meanQ=6.299615, numObservations: 4
action 1, numVisits=12, meanQ=3.983333, numObservations: 3
action 0, numVisits=10, meanQ=3.764687, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.698484 0.801424 0.626334 0.874111 0.267306 0.424752 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=41819, meanQ=8.938629, numObservations: 3
action 1, numVisits=34008, meanQ=8.935142, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 855306 episodes
GETTING ACTION FROM:
action 1, numVisits=529121, meanQ=6.547846, numObservations: 4
action 2, numVisits=402011, meanQ=6.546275, numObservations: 4
action 3, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.698484 0.801424 0.626334 0.874111 0.267306 0.424752 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 370
Initial state: 0 0.570411 0.829739 0.88653 0.902017 0.65666 0.829198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697572 episodes
GETTING ACTION FROM:
action 3, numVisits=697524, meanQ=6.237152, numObservations: 4
action -1, numVisits=37, meanQ=4.992594, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action 1, numVisits=4, meanQ=-0.505000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.570411 0.829739 0.88653 0.902017 0.65666 0.829198 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 371
Initial state: 0 0.510985 0.892349 0.480227 0.752287 0.691304 0.803176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693338 episodes
GETTING ACTION FROM:
action 1, numVisits=693324, meanQ=6.336509, numObservations: 5
action 3, numVisits=11, meanQ=3.626364, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.510985 0.892349 0.480227 0.752287 0.691304 0.803176 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 372
Initial state: 0 0.179623 0.921899 0.684358 0.892189 0.52041 0.809975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696481 episodes
GETTING ACTION FROM:
action 1, numVisits=696471, meanQ=6.249644, numObservations: 4
action 3, numVisits=4, meanQ=1.475000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.179623 0.921899 0.684358 0.892189 0.52041 0.809975 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31080, meanQ=6.563480, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 848324 episodes
GETTING ACTION FROM:
action 2, numVisits=879402, meanQ=6.425987, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.179623 0.921899 0.684358 0.892189 0.52041 0.809975 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 373
Initial state: 0 0.522663 0.803887 0.689078 0.877508 0.0623209 0.957471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689717 episodes
GETTING ACTION FROM:
action 3, numVisits=689544, meanQ=6.302813, numObservations: 5
action 0, numVisits=168, meanQ=5.732758, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.522663 0.803887 0.689078 0.877508 0.0623209 0.957471 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 374
Initial state: 0 0.796906 0.35952 0.581814 0.833255 0.564704 0.886342 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696295 episodes
GETTING ACTION FROM:
action 3, numVisits=696265, meanQ=6.298468, numObservations: 4
action -1, numVisits=18, meanQ=4.513313, numObservations: 1
action 2, numVisits=9, meanQ=3.554444, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.796906 0.35952 0.581814 0.833255 0.564704 0.886342 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 375
Initial state: 0 0.384604 0.927371 0.513878 0.898773 0.561479 0.822756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696928 episodes
GETTING ACTION FROM:
action 1, numVisits=696881, meanQ=6.224830, numObservations: 4
action 0, numVisits=32, meanQ=4.919080, numObservations: 1
action 2, numVisits=9, meanQ=3.554444, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.384604 0.927371 0.513878 0.898773 0.561479 0.822756 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 376
Initial state: 0 0.11767 0.304642 0.510053 0.860577 0.619393 0.80143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692101 episodes
GETTING ACTION FROM:
action 3, numVisits=691872, meanQ=6.233150, numObservations: 4
action 2, numVisits=213, meanQ=5.707745, numObservations: 5
action 1, numVisits=12, meanQ=4.074167, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.11767 0.304642 0.510053 0.860577 0.619393 0.80143 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 377
Initial state: 0 0.537976 0.862167 0.650764 0.898057 0.972224 0.931348 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 705583 episodes
GETTING ACTION FROM:
action 2, numVisits=552203, meanQ=6.235294, numObservations: 3
action 3, numVisits=153269, meanQ=6.223686, numObservations: 5
action -1, numVisits=75, meanQ=5.391417, numObservations: 1
action 1, numVisits=34, meanQ=4.875888, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.537976 0.862167 0.650764 0.898057 0.972224 0.931348 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 378
Initial state: 0 0.648142 0.878216 0.785045 0.453476 0.60584 0.89527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690455 episodes
GETTING ACTION FROM:
action 1, numVisits=690393, meanQ=6.224437, numObservations: 5
action 0, numVisits=43, meanQ=5.098446, numObservations: 1
action 2, numVisits=10, meanQ=3.196020, numObservations: 3
action 3, numVisits=7, meanQ=2.138586, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.648142 0.878216 0.785045 0.453476 0.60584 0.89527 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 379
Initial state: 0 0.600202 0.839315 0.784307 0.749272 0.677363 0.833004 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700101 episodes
GETTING ACTION FROM:
action 3, numVisits=700083, meanQ=6.185775, numObservations: 4
action 1, numVisits=12, meanQ=3.983333, numObservations: 2
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.600202 0.839315 0.784307 0.749272 0.677363 0.833004 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 380
Initial state: 0 0.0887152 0.731556 0.580828 0.855805 0.511439 0.893104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688291 episodes
GETTING ACTION FROM:
action 1, numVisits=688260, meanQ=6.251109, numObservations: 5
action 3, numVisits=24, meanQ=4.498342, numObservations: 5
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.0887152 0.731556 0.580828 0.855805 0.511439 0.893104 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=43363, meanQ=8.937318, numObservations: 3
action 3, numVisits=31234, meanQ=8.931502, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 853797 episodes
GETTING ACTION FROM:
action 3, numVisits=562958, meanQ=6.479057, numObservations: 4
action 2, numVisits=365435, meanQ=6.476282, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.0887152 0.731556 0.580828 0.855805 0.511439 0.893104 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 381
Initial state: 0 0.49967 0.268064 0.550986 0.846088 0.516605 0.851751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699872 episodes
GETTING ACTION FROM:
action 3, numVisits=699809, meanQ=6.223251, numObservations: 4
action -1, numVisits=55, meanQ=5.208472, numObservations: 1
action 2, numVisits=4, meanQ=1.742550, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.49967 0.268064 0.550986 0.846088 0.516605 0.851751 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 382
Initial state: 0 0.00739763 0.790712 0.604068 0.840089 0.547175 0.858013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 704387 episodes
GETTING ACTION FROM:
action 2, numVisits=704257, meanQ=6.180683, numObservations: 4
action 0, numVisits=65, meanQ=5.259325, numObservations: 1
action -1, numVisits=54, meanQ=5.177304, numObservations: 1
action 3, numVisits=7, meanQ=3.412857, numObservations: 2
action 1, numVisits=4, meanQ=-0.505000, numObservations: 3
action: 2
Next state: 0 0.00739763 0.790712 0.604068 0.840089 0.547175 0.858013 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31376, meanQ=5.308744, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 781883 episodes
GETTING ACTION FROM:
action 2, numVisits=813259, meanQ=6.177721, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.00739763 0.790712 0.604068 0.840089 0.547175 0.858013 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 383
Initial state: 0 0.564576 0.84767 0.482626 0.996141 0.60779 0.880167 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693831 episodes
GETTING ACTION FROM:
action 3, numVisits=693792, meanQ=6.231967, numObservations: 4
action 0, numVisits=23, meanQ=4.660995, numObservations: 1
action 2, numVisits=9, meanQ=3.554444, numObservations: 3
action 1, numVisits=5, meanQ=1.396000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.564576 0.84767 0.482626 0.996141 0.60779 0.880167 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 384
Initial state: 0 0.573328 0.834487 0.491714 0.107775 0.580743 0.841846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696647 episodes
GETTING ACTION FROM:
action 2, numVisits=696598, meanQ=6.218170, numObservations: 4
action 1, numVisits=44, meanQ=4.879548, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.573328 0.834487 0.491714 0.107775 0.580743 0.841846 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=57972, meanQ=8.894130, numObservations: 3
action 1, numVisits=37497, meanQ=8.887007, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 864007 episodes
GETTING ACTION FROM:
action 3, numVisits=630883, meanQ=6.822233, numObservations: 3
action 1, numVisits=328590, meanQ=6.819000, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.573328 0.834487 0.491714 0.107775 0.580743 0.841846 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 385
Initial state: 0 0.500286 0.898701 0.311185 0.65431 0.663722 0.87427 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688098 episodes
GETTING ACTION FROM:
action 1, numVisits=688033, meanQ=6.249747, numObservations: 5
action 0, numVisits=59, meanQ=5.275210, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.500286 0.898701 0.311185 0.65431 0.663722 0.87427 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 386
Initial state: 0 0.141383 0.532136 0.693435 0.844692 0.637419 0.81052 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688708 episodes
GETTING ACTION FROM:
action 3, numVisits=688653, meanQ=6.230846, numObservations: 5
action -1, numVisits=25, meanQ=4.741174, numObservations: 1
action 1, numVisits=15, meanQ=4.339340, numObservations: 3
action 2, numVisits=13, meanQ=3.690015, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.141383 0.532136 0.693435 0.844692 0.637419 0.81052 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 387
Initial state: 0 0.586769 0.892832 0.8242 0.762888 0.588832 0.822151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689823 episodes
GETTING ACTION FROM:
action 3, numVisits=689789, meanQ=6.316000, numObservations: 5
action 2, numVisits=28, meanQ=3.635007, numObservations: 4
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.586769 0.892832 0.8242 0.762888 0.588832 0.822151 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 388
Initial state: 0 0.629179 0.913228 0.642034 0.882708 0.59758 0.803123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699483 episodes
GETTING ACTION FROM:
action 1, numVisits=699429, meanQ=6.173778, numObservations: 4
action 2, numVisits=30, meanQ=4.672340, numObservations: 3
action 3, numVisits=20, meanQ=4.098505, numObservations: 3
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.629179 0.913228 0.642034 0.882708 0.59758 0.803123 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 389
Initial state: 0 0.641036 0.890391 0.0320207 0.760142 0.575611 0.807215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696667 episodes
GETTING ACTION FROM:
action 1, numVisits=696627, meanQ=6.241673, numObservations: 4
action 0, numVisits=36, meanQ=5.008176, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.641036 0.890391 0.0320207 0.760142 0.575611 0.807215 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 390
Initial state: 0 0.582587 0.369913 0.583303 0.865499 0.537125 0.822356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689286 episodes
GETTING ACTION FROM:
action 3, numVisits=689240, meanQ=6.229611, numObservations: 5
action 0, numVisits=39, meanQ=5.060900, numObservations: 1
action 1, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.582587 0.369913 0.583303 0.865499 0.537125 0.822356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 391
Initial state: 0 0.618556 0.831156 0.516885 0.846596 0.595556 0.0932426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706909 episodes
GETTING ACTION FROM:
action 1, numVisits=706837, meanQ=6.237705, numObservations: 3
action -1, numVisits=52, meanQ=5.219805, numObservations: 1
action 0, numVisits=17, meanQ=4.447072, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.618556 0.831156 0.516885 0.846596 0.595556 0.0932426 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 392
Initial state: 0 0.995448 0.395269 0.502024 0.805502 0.617769 0.830756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686571 episodes
GETTING ACTION FROM:
action 1, numVisits=681337, meanQ=6.240167, numObservations: 5
action 3, numVisits=5228, meanQ=6.112572, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.995448 0.395269 0.502024 0.805502 0.617769 0.830756 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30927, meanQ=6.528118, numObservations: 4
action 1, numVisits=6, meanQ=2.663333, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 850581 episodes
GETTING ACTION FROM:
action 3, numVisits=881508, meanQ=6.400864, numObservations: 4
action 1, numVisits=6, meanQ=2.663333, numObservations: 3
action 2, numVisits=3, meanQ=-0.670000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.995448 0.395269 0.502024 0.805502 0.617769 0.830756 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 393
Initial state: 0 0.881165 0.302858 0.666006 0.820737 0.659042 0.844459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691577 episodes
GETTING ACTION FROM:
action 1, numVisits=691547, meanQ=6.240460, numObservations: 4
action -1, numVisits=14, meanQ=4.024184, numObservations: 1
action 2, numVisits=13, meanQ=3.606931, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.881165 0.302858 0.666006 0.820737 0.659042 0.844459 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 394
Initial state: 0 0.278312 0.360985 0.576997 0.837846 0.51105 0.88612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 705118 episodes
GETTING ACTION FROM:
action 3, numVisits=705007, meanQ=6.232663, numObservations: 3
action 0, numVisits=71, meanQ=5.351557, numObservations: 1
action -1, numVisits=37, meanQ=5.011336, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.278312 0.360985 0.576997 0.837846 0.51105 0.88612 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 395
Initial state: 0 0.573915 0.854484 0.401957 0.530766 0.613231 0.86258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 683390 episodes
GETTING ACTION FROM:
action 3, numVisits=683248, meanQ=6.198382, numObservations: 5
action 2, numVisits=113, meanQ=5.419823, numObservations: 5
action -1, numVisits=21, meanQ=4.541931, numObservations: 1
action 1, numVisits=6, meanQ=0.830017, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.573915 0.854484 0.401957 0.530766 0.613231 0.86258 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 396
Initial state: 0 0.396949 0.147346 0.597553 0.847351 0.575912 0.813567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687510 episodes
GETTING ACTION FROM:
action 1, numVisits=687446, meanQ=6.227125, numObservations: 5
action 3, numVisits=52, meanQ=5.029238, numObservations: 4
action 2, numVisits=8, meanQ=2.873750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.396949 0.147346 0.597553 0.847351 0.575912 0.813567 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=64409, meanQ=8.876668, numObservations: 4
action 2, numVisits=29989, meanQ=8.863795, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 855025 episodes
GETTING ACTION FROM:
action 3, numVisits=580808, meanQ=6.833131, numObservations: 4
action 2, numVisits=368615, meanQ=6.830388, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.396949 0.147346 0.597553 0.847351 0.575912 0.813567 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 397
Initial state: 0 0.858008 0.316561 0.542097 0.800066 0.666899 0.813345 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699349 episodes
GETTING ACTION FROM:
action 3, numVisits=699303, meanQ=6.234248, numObservations: 4
action 1, numVisits=24, meanQ=4.733754, numObservations: 4
action -1, numVisits=19, meanQ=4.424459, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.858008 0.316561 0.542097 0.800066 0.666899 0.813345 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 398
Initial state: 0 0.614795 0.809502 0.511555 0.878396 0.658716 0.818381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692491 episodes
GETTING ACTION FROM:
action 1, numVisits=692454, meanQ=6.229659, numObservations: 4
action 3, numVisits=32, meanQ=4.686566, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.614795 0.809502 0.511555 0.878396 0.658716 0.818381 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 399
Initial state: 0 0.795054 0.833425 0.575477 0.849719 0.598893 0.861435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 704800 episodes
GETTING ACTION FROM:
action 3, numVisits=704793, meanQ=6.228070, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.795054 0.833425 0.575477 0.849719 0.598893 0.861435 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 400
Initial state: 0 0.519281 0.88395 0.661394 0.800822 0.231395 0.302532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 472793 episodes
GETTING ACTION FROM:
action -1, numVisits=472693, meanQ=4.159755, numObservations: 1
action 0, numVisits=84, meanQ=3.377503, numObservations: 1
action 1, numVisits=6, meanQ=0.831667, numObservations: 3
action 3, numVisits=9, meanQ=0.210000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.519281 0.88395 0.661394 0.800822 0.231395 0.302532 w: 1
Observation: 0 0.613883 0 0.753277 0 0.326152 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=465791, meanQ=6.218945, numObservations: 5
action 3, numVisits=6897, meanQ=6.137255, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 739432 episodes
GETTING ACTION FROM:
action 1, numVisits=1205221, meanQ=6.293118, numObservations: 5
action 3, numVisits=6897, meanQ=6.137255, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.519281 0.88395 0.661394 0.800822 0.231395 0.302532 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 401
Initial state: 0 0.651278 0.82224 0.596076 0.862205 0.351731 0.183127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 709282 episodes
GETTING ACTION FROM:
action 2, numVisits=709270, meanQ=6.233518, numObservations: 3
action 1, numVisits=7, meanQ=1.998571, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.651278 0.82224 0.596076 0.862205 0.351731 0.183127 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 402
Initial state: 0 0.545752 0.858947 0.529234 0.84269 0.663436 0.913095 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702653 episodes
GETTING ACTION FROM:
action 1, numVisits=682095, meanQ=6.230758, numObservations: 4
action 3, numVisits=20387, meanQ=6.184624, numObservations: 3
action -1, numVisits=99, meanQ=5.492570, numObservations: 1
action 0, numVisits=41, meanQ=5.089056, numObservations: 1
action 2, numVisits=31, meanQ=4.796774, numObservations: 4
action: 1
Next state: 1 0.545752 0.858947 0.529234 0.84269 0.663436 0.913095 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 403
Initial state: 0 0.267737 0.388606 0.569499 0.854961 0.58061 0.878138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697339 episodes
GETTING ACTION FROM:
action 3, numVisits=697251, meanQ=6.236626, numObservations: 4
action 0, numVisits=59, meanQ=5.283588, numObservations: 1
action -1, numVisits=24, meanQ=4.695898, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 1 0.267737 0.388606 0.569499 0.854961 0.58061 0.878138 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 404
Initial state: 0 0.427619 0.146197 0.590309 0.886553 0.698723 0.88542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699198 episodes
GETTING ACTION FROM:
action 2, numVisits=699184, meanQ=6.226609, numObservations: 4
action 1, numVisits=7, meanQ=3.441429, numObservations: 3
action 3, numVisits=3, meanQ=-0.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.427619 0.146197 0.590309 0.886553 0.698723 0.88542 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 405
Initial state: 0 0.669312 0.825834 0.587165 0.881812 0.139577 0.92681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 474965 episodes
GETTING ACTION FROM:
action 0, numVisits=474953, meanQ=4.180101, numObservations: 1
action 3, numVisits=7, meanQ=0.711429, numObservations: 3
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.669312 0.825834 0.587165 0.881812 0.139577 0.92681 w: 1
Observation: 0 0 0.844353 0 0.866094 0 0.97566 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=474676, meanQ=6.240525, numObservations: 4
action 1, numVisits=273, meanQ=5.677589, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 550942 episodes
GETTING ACTION FROM:
action 0, numVisits=451521, meanQ=6.304614, numObservations: 2
action 3, numVisits=574015, meanQ=6.263486, numObservations: 4
action 1, numVisits=273, meanQ=5.677589, numObservations: 5
action -1, numVisits=84, meanQ=5.477943, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.669312 0.825834 0.587165 0.881812 0.139577 0.92681 w: 1
Observation: 0 0 0.912158 0 0.788036 0 0.906022 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=253777, meanQ=8.518200, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 760962 episodes
GETTING ACTION FROM:
action 3, numVisits=1014730, meanQ=6.796463, numObservations: 4
action 1, numVisits=10, meanQ=4.099000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.669312 0.825834 0.587165 0.881812 0.139577 0.92681 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=8188, meanQ=6.788106, numObservations: 5
action 3, numVisits=39365, meanQ=6.462746, numObservations: 4
action 1, numVisits=17, meanQ=4.410006, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 844588 episodes
GETTING ACTION FROM:
action 2, numVisits=838823, meanQ=6.440857, numObservations: 5
action 3, numVisits=53318, meanQ=6.415221, numObservations: 4
action 1, numVisits=17, meanQ=4.410006, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.669312 0.825834 0.587165 0.881812 0.139577 0.92681 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=7585, meanQ=8.193578, numObservations: 5
action 3, numVisits=22, meanQ=4.944100, numObservations: 3
action 2, numVisits=6, meanQ=4.161700, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 858072 episodes
GETTING ACTION FROM:
action 3, numVisits=416618, meanQ=6.494671, numObservations: 4
action 1, numVisits=449058, meanQ=6.471625, numObservations: 5
action 2, numVisits=9, meanQ=3.552244, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.669312 0.825834 0.587165 0.881812 0.139577 0.92681 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.71497
Run # 406
Initial state: 0 0.33157 0.217852 0.513431 0.81409 0.544298 0.83027 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 702839 episodes
GETTING ACTION FROM:
action 2, numVisits=702822, meanQ=6.323860, numObservations: 4
action 3, numVisits=14, meanQ=1.997157, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.33157 0.217852 0.513431 0.81409 0.544298 0.83027 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 407
Initial state: 0 0.526344 0.837361 0.311935 0.0767105 0.526441 0.875771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694752 episodes
GETTING ACTION FROM:
action 3, numVisits=694741, meanQ=6.234784, numObservations: 4
action 1, numVisits=6, meanQ=0.831667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.526344 0.837361 0.311935 0.0767105 0.526441 0.875771 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 408
Initial state: 0 0.636573 0.831431 0.690594 0.805992 0.360984 0.979321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691377 episodes
GETTING ACTION FROM:
action 2, numVisits=689964, meanQ=6.221029, numObservations: 5
action 3, numVisits=1291, meanQ=6.018986, numObservations: 5
action 1, numVisits=118, meanQ=5.527545, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.636573 0.831431 0.690594 0.805992 0.360984 0.979321 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 409
Initial state: 0 0.655431 0.83095 0.651883 0.450075 0.633314 0.824257 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693767 episodes
GETTING ACTION FROM:
action 1, numVisits=693732, meanQ=6.216349, numObservations: 5
action -1, numVisits=15, meanQ=4.112087, numObservations: 1
action 2, numVisits=12, meanQ=3.248342, numObservations: 2
action 3, numVisits=6, meanQ=2.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.655431 0.83095 0.651883 0.450075 0.633314 0.824257 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 410
Initial state: 0 0.553932 0.433693 0.624807 0.874886 0.529873 0.894895 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697136 episodes
GETTING ACTION FROM:
action 3, numVisits=697025, meanQ=6.312172, numObservations: 4
action 2, numVisits=77, meanQ=4.946369, numObservations: 5
action -1, numVisits=22, meanQ=4.702757, numObservations: 1
action 1, numVisits=10, meanQ=3.772000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.553932 0.433693 0.624807 0.874886 0.529873 0.894895 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 411
Initial state: 0 0.660232 0.868462 0.567503 0.88675 0.418776 0.845623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 682867 episodes
GETTING ACTION FROM:
action 3, numVisits=682830, meanQ=6.239210, numObservations: 5
action -1, numVisits=25, meanQ=4.763200, numObservations: 1
action 2, numVisits=6, meanQ=2.333333, numObservations: 3
action 1, numVisits=4, meanQ=-1.002475, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.660232 0.868462 0.567503 0.88675 0.418776 0.845623 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=35233, meanQ=8.673459, numObservations: 5
action 1, numVisits=1426, meanQ=8.527029, numObservations: 4
action 3, numVisits=5, meanQ=3.198000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 839431 episodes
GETTING ACTION FROM:
action 2, numVisits=860661, meanQ=6.804728, numObservations: 5
action 1, numVisits=15429, meanQ=6.752373, numObservations: 4
action 3, numVisits=5, meanQ=3.198000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.660232 0.868462 0.567503 0.88675 0.418776 0.845623 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 412
Initial state: 0 0.59894 0.874281 0.303219 0.403768 0.646148 0.810654 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696100 episodes
GETTING ACTION FROM:
action 3, numVisits=696052, meanQ=6.239018, numObservations: 4
action 0, numVisits=35, meanQ=4.934991, numObservations: 1
action 1, numVisits=9, meanQ=3.554444, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.59894 0.874281 0.303219 0.403768 0.646148 0.810654 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 413
Initial state: 0 0.588174 0.877733 0.214458 0.6642 0.651687 0.875177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701781 episodes
GETTING ACTION FROM:
action 2, numVisits=701749, meanQ=6.177367, numObservations: 4
action 0, numVisits=22, meanQ=4.529950, numObservations: 1
action 3, numVisits=7, meanQ=3.285714, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.588174 0.877733 0.214458 0.6642 0.651687 0.875177 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=96643, meanQ=8.881340, numObservations: 4
action 3, numVisits=8, meanQ=5.262500, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 852303 episodes
GETTING ACTION FROM:
action 1, numVisits=948887, meanQ=6.645435, numObservations: 4
action 3, numVisits=66, meanQ=5.683182, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.588174 0.877733 0.214458 0.6642 0.651687 0.875177 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 414
Initial state: 0 0.589119 0.861265 0.594697 0.278116 0.565871 0.877112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695367 episodes
GETTING ACTION FROM:
action 3, numVisits=695213, meanQ=6.179600, numObservations: 4
action 1, numVisits=148, meanQ=5.567074, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.589119 0.861265 0.594697 0.278116 0.565871 0.877112 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 415
Initial state: 0 0.552042 0.841583 0.770165 0.578789 0.539008 0.877491 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706619 episodes
GETTING ACTION FROM:
action 1, numVisits=706605, meanQ=6.220031, numObservations: 3
action 3, numVisits=6, meanQ=0.831667, numObservations: 2
action 2, numVisits=4, meanQ=-0.505000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.552042 0.841583 0.770165 0.578789 0.539008 0.877491 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 416
Initial state: 0 0.518038 0.84774 0.665447 0.445099 0.687549 0.85768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697115 episodes
GETTING ACTION FROM:
action 3, numVisits=134506, meanQ=6.248636, numObservations: 3
action 2, numVisits=562584, meanQ=6.228055, numObservations: 5
action 1, numVisits=21, meanQ=4.227629, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.518038 0.84774 0.665447 0.445099 0.687549 0.85768 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 417
Initial state: 0 0.31759 0.552466 0.501026 0.831466 0.65464 0.899746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697146 episodes
GETTING ACTION FROM:
action 1, numVisits=674090, meanQ=6.238837, numObservations: 4
action 2, numVisits=22997, meanQ=6.197153, numObservations: 4
action -1, numVisits=56, meanQ=5.248580, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.31759 0.552466 0.501026 0.831466 0.65464 0.899746 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=48989, meanQ=8.886989, numObservations: 4
action 2, numVisits=43766, meanQ=8.884811, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 843964 episodes
GETTING ACTION FROM:
action 3, numVisits=618480, meanQ=6.815534, numObservations: 4
action 2, numVisits=318229, meanQ=6.811979, numObservations: 5
action 1, numVisits=11, meanQ=4.544545, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.31759 0.552466 0.501026 0.831466 0.65464 0.899746 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 418
Initial state: 0 0.613304 0.830576 0.550372 0.800471 0.480319 0.706624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697765 episodes
GETTING ACTION FROM:
action 2, numVisits=697725, meanQ=6.224421, numObservations: 4
action -1, numVisits=20, meanQ=4.480711, numObservations: 1
action 1, numVisits=12, meanQ=3.249167, numObservations: 2
action 3, numVisits=6, meanQ=2.333333, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.613304 0.830576 0.550372 0.800471 0.480319 0.706624 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 419
Initial state: 0 0.696862 0.813955 0.512392 0.806687 0.6071 0.0759017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694934 episodes
GETTING ACTION FROM:
action 3, numVisits=694680, meanQ=6.307893, numObservations: 4
action 0, numVisits=77, meanQ=5.476325, numObservations: 1
action -1, numVisits=56, meanQ=5.325595, numObservations: 1
action 1, numVisits=101, meanQ=5.283074, numObservations: 4
action 2, numVisits=20, meanQ=4.099000, numObservations: 4
action: 3
Next state: 0 0.696862 0.813955 0.512392 0.806687 0.6071 0.0759017 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=42344, meanQ=8.678508, numObservations: 4
action 1, numVisits=20, meanQ=7.099000, numObservations: 3
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 853834 episodes
GETTING ACTION FROM:
action 2, numVisits=891862, meanQ=6.483999, numObservations: 4
action 3, numVisits=4215, meanQ=6.376511, numObservations: 4
action 1, numVisits=122, meanQ=5.728525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.696862 0.813955 0.512392 0.806687 0.6071 0.0759017 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 420
Initial state: 0 0.810574 0.570276 0.505129 0.807904 0.635211 0.825359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699710 episodes
GETTING ACTION FROM:
action 1, numVisits=699550, meanQ=6.234911, numObservations: 4
action 3, numVisits=148, meanQ=5.420068, numObservations: 4
action 2, numVisits=8, meanQ=2.996262, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.810574 0.570276 0.505129 0.807904 0.635211 0.825359 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 421
Initial state: 0 0.511495 0.871109 0.53088 0.255126 0.596315 0.857529 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688271 episodes
GETTING ACTION FROM:
action 2, numVisits=688211, meanQ=6.243311, numObservations: 5
action 0, numVisits=47, meanQ=5.144051, numObservations: 1
action 3, numVisits=6, meanQ=2.333333, numObservations: 2
action 1, numVisits=5, meanQ=1.396000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 0 0.511495 0.871109 0.53088 0.255126 0.596315 0.857529 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=93501, meanQ=8.890412, numObservations: 4
action 1, numVisits=543, meanQ=8.612274, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 855088 episodes
GETTING ACTION FROM:
action 3, numVisits=942185, meanQ=6.873946, numObservations: 4
action 1, numVisits=6946, meanQ=6.791674, numObservations: 4
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.511495 0.871109 0.53088 0.255126 0.596315 0.857529 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 422
Initial state: 0 0.671296 0.867679 0.539777 0.830688 0.0755109 0.846416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689163 episodes
GETTING ACTION FROM:
action 2, numVisits=688727, meanQ=6.225922, numObservations: 5
action 1, numVisits=298, meanQ=5.730418, numObservations: 4
action -1, numVisits=84, meanQ=5.428757, numObservations: 1
action 0, numVisits=51, meanQ=5.197735, numObservations: 1
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action: 2
Next state: 1 0.671296 0.867679 0.539777 0.830688 0.0755109 0.846416 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 423
Initial state: 0 0.648603 0.816467 0.641127 0.891649 0.956544 0.652365 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697242 episodes
GETTING ACTION FROM:
action 3, numVisits=697180, meanQ=6.233395, numObservations: 4
action 1, numVisits=56, meanQ=5.208932, numObservations: 5
action 2, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.648603 0.816467 0.641127 0.891649 0.956544 0.652365 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 424
Initial state: 0 0.681142 0.870823 0.811237 0.260002 0.530715 0.891137 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695314 episodes
GETTING ACTION FROM:
action 3, numVisits=695239, meanQ=6.218659, numObservations: 4
action -1, numVisits=60, meanQ=5.267396, numObservations: 1
action 2, numVisits=7, meanQ=3.285714, numObservations: 2
action 1, numVisits=6, meanQ=2.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.681142 0.870823 0.811237 0.260002 0.530715 0.891137 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 425
Initial state: 0 0.532447 0.806153 0.907541 0.632829 0.5427 0.805395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698826 episodes
GETTING ACTION FROM:
action 2, numVisits=698792, meanQ=6.222593, numObservations: 4
action -1, numVisits=22, meanQ=4.570085, numObservations: 1
action 3, numVisits=9, meanQ=1.332222, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.532447 0.806153 0.907541 0.632829 0.5427 0.805395 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 426
Initial state: 0 0.580772 0.884187 0.636909 0.402486 0.616693 0.859562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706667 episodes
GETTING ACTION FROM:
action 2, numVisits=706447, meanQ=6.246723, numObservations: 3
action 1, numVisits=170, meanQ=5.672791, numObservations: 4
action -1, numVisits=46, meanQ=5.164347, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 2
Next state: 2 0.580772 0.884187 0.636909 0.402486 0.616693 0.859562 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 427
Initial state: 0 0.523456 0.887989 0.654339 0.835182 0.746025 0.997835 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671557 episodes
GETTING ACTION FROM:
action 3, numVisits=671483, meanQ=6.125157, numObservations: 5
action -1, numVisits=64, meanQ=5.203743, numObservations: 1
action 1, numVisits=6, meanQ=0.831667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 2 0.523456 0.887989 0.654339 0.835182 0.746025 0.997835 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 428
Initial state: 0 0.614652 0.86529 0.652432 0.81476 0.143777 0.10566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698876 episodes
GETTING ACTION FROM:
action 1, numVisits=585051, meanQ=6.220520, numObservations: 4
action 3, numVisits=113759, meanQ=6.114689, numObservations: 3
action -1, numVisits=56, meanQ=5.229713, numObservations: 1
action 2, numVisits=8, meanQ=3.121250, numObservations: 4
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.614652 0.86529 0.652432 0.81476 0.143777 0.10566 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 429
Initial state: 0 0.898089 0.501022 0.521304 0.861379 0.564732 0.835733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696640 episodes
GETTING ACTION FROM:
action 1, numVisits=696581, meanQ=6.229922, numObservations: 4
action 0, numVisits=53, meanQ=5.220236, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.898089 0.501022 0.521304 0.861379 0.564732 0.835733 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 430
Initial state: 0 0.575353 0.85203 0.653397 0.828263 0.871005 0.861828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691038 episodes
GETTING ACTION FROM:
action 1, numVisits=691027, meanQ=6.229407, numObservations: 5
action 3, numVisits=5, meanQ=0.998020, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.575353 0.85203 0.653397 0.828263 0.871005 0.861828 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 431
Initial state: 0 0.547987 0.838485 0.688214 0.816646 0.18035 0.0571509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 706981 episodes
GETTING ACTION FROM:
action 2, numVisits=687571, meanQ=6.239430, numObservations: 3
action 1, numVisits=19304, meanQ=6.154904, numObservations: 4
action 3, numVisits=77, meanQ=4.930914, numObservations: 5
action 0, numVisits=27, meanQ=4.783142, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.547987 0.838485 0.688214 0.816646 0.18035 0.0571509 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 432
Initial state: 0 0.203069 0.168114 0.620867 0.828973 0.50161 0.801453 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687332 episodes
GETTING ACTION FROM:
action 1, numVisits=687320, meanQ=6.212506, numObservations: 5
action 2, numVisits=7, meanQ=3.284300, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.203069 0.168114 0.620867 0.828973 0.50161 0.801453 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=38763, meanQ=8.936803, numObservations: 3
action 2, numVisits=35519, meanQ=8.935252, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 838789 episodes
GETTING ACTION FROM:
action 3, numVisits=749993, meanQ=6.608714, numObservations: 5
action 2, numVisits=163074, meanQ=6.598349, numObservations: 4
action 1, numVisits=5, meanQ=3.198000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.203069 0.168114 0.620867 0.828973 0.50161 0.801453 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 433
Initial state: 0 0.640646 0.8137 0.686727 0.800688 0.398895 0.993707 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687302 episodes
GETTING ACTION FROM:
action 2, numVisits=687250, meanQ=6.228538, numObservations: 5
action 0, numVisits=25, meanQ=4.724086, numObservations: 1
action -1, numVisits=11, meanQ=3.979945, numObservations: 1
action 3, numVisits=11, meanQ=3.725455, numObservations: 3
action 1, numVisits=5, meanQ=1.396000, numObservations: 2
action: 2
Next state: 1 0.640646 0.8137 0.686727 0.800688 0.398895 0.993707 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 434
Initial state: 0 0.657322 0.844353 0.81506 0.56078 0.685137 0.847294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697092 episodes
GETTING ACTION FROM:
action 3, numVisits=697085, meanQ=6.240247, numObservations: 4
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.657322 0.844353 0.81506 0.56078 0.685137 0.847294 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 435
Initial state: 0 0.638219 0.824799 0.764156 0.973633 0.586857 0.8992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694219 episodes
GETTING ACTION FROM:
action 2, numVisits=231609, meanQ=6.227138, numObservations: 3
action 3, numVisits=462531, meanQ=6.227015, numObservations: 5
action 0, numVisits=63, meanQ=5.290058, numObservations: 1
action 1, numVisits=14, meanQ=3.426436, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.638219 0.824799 0.764156 0.973633 0.586857 0.8992 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 436
Initial state: 0 0.894166 0.75685 0.62155 0.862835 0.673117 0.805148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696022 episodes
GETTING ACTION FROM:
action 2, numVisits=695979, meanQ=6.231901, numObservations: 5
action 0, numVisits=19, meanQ=4.494575, numObservations: 1
action -1, numVisits=14, meanQ=4.195918, numObservations: 1
action 3, numVisits=9, meanQ=3.554444, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.894166 0.75685 0.62155 0.862835 0.673117 0.805148 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 437
Initial state: 0 0.632715 0.812025 0.13116 0.603695 0.522972 0.896988 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687992 episodes
GETTING ACTION FROM:
action 2, numVisits=687962, meanQ=6.143931, numObservations: 4
action 3, numVisits=22, meanQ=2.726364, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.632715 0.812025 0.13116 0.603695 0.522972 0.896988 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=37904, meanQ=8.938972, numObservations: 3
action 3, numVisits=36464, meanQ=8.938518, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 852362 episodes
GETTING ACTION FROM:
action 3, numVisits=519941, meanQ=6.801076, numObservations: 4
action 1, numVisits=406755, meanQ=6.799801, numObservations: 3
action 2, numVisits=35, meanQ=5.506003, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.632715 0.812025 0.13116 0.603695 0.522972 0.896988 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 438
Initial state: 0 0.601189 0.979486 0.559248 0.898397 0.698773 0.858685 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 710260 episodes
GETTING ACTION FROM:
action 2, numVisits=710175, meanQ=6.230604, numObservations: 3
action 0, numVisits=76, meanQ=5.393969, numObservations: 1
action 1, numVisits=5, meanQ=-0.802000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.601189 0.979486 0.559248 0.898397 0.698773 0.858685 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 439
Initial state: 0 0.566226 0.413733 0.597223 0.877787 0.676768 0.804101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 705293 episodes
GETTING ACTION FROM:
action 2, numVisits=705247, meanQ=6.232592, numObservations: 4
action -1, numVisits=41, meanQ=5.048008, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.566226 0.413733 0.597223 0.877787 0.676768 0.804101 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 440
Initial state: 0 0.601541 0.877764 0.594473 0.689764 0.546565 0.840526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695422 episodes
GETTING ACTION FROM:
action 2, numVisits=673392, meanQ=6.315603, numObservations: 5
action 3, numVisits=21897, meanQ=6.237754, numObservations: 4
action 1, numVisits=129, meanQ=5.521864, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.601541 0.877764 0.594473 0.689764 0.546565 0.840526 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=40797, meanQ=8.695810, numObservations: 4
action 1, numVisits=79, meanQ=7.885572, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 865180 episodes
GETTING ACTION FROM:
action 1, numVisits=631058, meanQ=6.782309, numObservations: 3
action 3, numVisits=274997, meanQ=6.663496, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 1 0.601541 0.877764 0.594473 0.689764 0.546565 0.840526 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 441
Initial state: 0 0.629756 0.813414 0.343613 0.219911 0.69481 0.843359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686800 episodes
GETTING ACTION FROM:
action 1, numVisits=686700, meanQ=6.232217, numObservations: 5
action 0, numVisits=53, meanQ=5.215497, numObservations: 1
action 3, numVisits=41, meanQ=4.964151, numObservations: 4
action 2, numVisits=4, meanQ=1.745025, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.629756 0.813414 0.343613 0.219911 0.69481 0.843359 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 442
Initial state: 0 0.609691 0.888456 0.991756 0.157184 0.555416 0.887121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686833 episodes
GETTING ACTION FROM:
action 3, numVisits=686758, meanQ=6.232864, numObservations: 5
action 0, numVisits=30, meanQ=4.896167, numObservations: 1
action 2, numVisits=42, meanQ=4.344048, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.609691 0.888456 0.991756 0.157184 0.555416 0.887121 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 443
Initial state: 0 0.643467 0.817145 0.699192 0.845728 0.920694 0.412011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697394 episodes
GETTING ACTION FROM:
action 1, numVisits=697291, meanQ=6.233711, numObservations: 4
action -1, numVisits=95, meanQ=5.479654, numObservations: 1
action 2, numVisits=5, meanQ=1.396000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.643467 0.817145 0.699192 0.845728 0.920694 0.412011 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 444
Initial state: 0 0.523095 0.874319 0.580997 0.817766 0.626609 0.94821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685149 episodes
GETTING ACTION FROM:
action 1, numVisits=684900, meanQ=6.217158, numObservations: 5
action 2, numVisits=187, meanQ=5.459742, numObservations: 4
action -1, numVisits=54, meanQ=5.197780, numObservations: 1
action 3, numVisits=6, meanQ=0.831667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.523095 0.874319 0.580997 0.817766 0.626609 0.94821 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 445
Initial state: 0 0.510544 0.816402 0.354201 0.896066 0.670267 0.890613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690175 episodes
GETTING ACTION FROM:
action 3, numVisits=690107, meanQ=6.223699, numObservations: 5
action 2, numVisits=52, meanQ=5.067506, numObservations: 5
action 1, numVisits=12, meanQ=4.080025, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.510544 0.816402 0.354201 0.896066 0.670267 0.890613 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 446
Initial state: 0 0.952697 0.489644 0.551331 0.890918 0.500386 0.874143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696039 episodes
GETTING ACTION FROM:
action 3, numVisits=695986, meanQ=6.226892, numObservations: 4
action 0, numVisits=45, meanQ=5.128822, numObservations: 1
action 2, numVisits=4, meanQ=1.992525, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.952697 0.489644 0.551331 0.890918 0.500386 0.874143 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 447
Initial state: 0 0.570612 0.845585 0.522024 0.823444 0.91503 0.935497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693403 episodes
GETTING ACTION FROM:
action 3, numVisits=693383, meanQ=6.232949, numObservations: 4
action 1, numVisits=12, meanQ=3.248342, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.570612 0.845585 0.522024 0.823444 0.91503 0.935497 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 448
Initial state: 0 0.67203 0.861049 0.626912 0.808494 0.563735 0.479837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685289 episodes
GETTING ACTION FROM:
action 2, numVisits=684870, meanQ=6.221944, numObservations: 5
action 1, numVisits=352, meanQ=5.795575, numObservations: 4
action 0, numVisits=56, meanQ=5.221654, numObservations: 1
action 3, numVisits=9, meanQ=3.554444, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.67203 0.861049 0.626912 0.808494 0.563735 0.479837 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 449
Initial state: 0 0.571234 0.814913 0.541907 0.825554 0.49061 0.863345 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698666 episodes
GETTING ACTION FROM:
action 1, numVisits=698576, meanQ=6.230636, numObservations: 4
action 0, numVisits=42, meanQ=5.098836, numObservations: 1
action -1, numVisits=23, meanQ=4.628825, numObservations: 1
action 2, numVisits=21, meanQ=4.378110, numObservations: 4
action 3, numVisits=4, meanQ=1.747500, numObservations: 2
action: 1
Next state: 1 0.571234 0.814913 0.541907 0.825554 0.49061 0.863345 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 450
Initial state: 0 0.550409 0.827306 0.474714 0.0560438 0.674147 0.832227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 681555 episodes
GETTING ACTION FROM:
action 1, numVisits=681438, meanQ=6.223933, numObservations: 5
action 3, numVisits=77, meanQ=5.261819, numObservations: 3
action 0, numVisits=20, meanQ=4.567331, numObservations: 1
action -1, numVisits=14, meanQ=4.217610, numObservations: 1
action 2, numVisits=6, meanQ=2.331683, numObservations: 2
action: 1
Next state: 1 0.550409 0.827306 0.474714 0.0560438 0.674147 0.832227 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 451
Initial state: 0 0.594946 0.854851 0.568333 0.858176 0.65218 0.241968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697416 episodes
GETTING ACTION FROM:
action 3, numVisits=697378, meanQ=6.327216, numObservations: 4
action 1, numVisits=34, meanQ=3.117065, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.594946 0.854851 0.568333 0.858176 0.65218 0.241968 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 452
Initial state: 0 0.522093 0.843744 0.553686 0.863507 0.857983 0.905537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690577 episodes
GETTING ACTION FROM:
action 2, numVisits=690457, meanQ=6.234900, numObservations: 5
action -1, numVisits=61, meanQ=5.296954, numObservations: 1
action 0, numVisits=48, meanQ=5.160671, numObservations: 1
action 1, numVisits=7, meanQ=1.998571, numObservations: 3
action 3, numVisits=4, meanQ=1.992525, numObservations: 2
action: 2
Next state: 1 0.522093 0.843744 0.553686 0.863507 0.857983 0.905537 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 453
Initial state: 0 0.563319 0.860345 0.621015 0.113673 0.575972 0.871345 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695901 episodes
GETTING ACTION FROM:
action 2, numVisits=695864, meanQ=6.229101, numObservations: 4
action 0, numVisits=29, meanQ=4.831451, numObservations: 1
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.563319 0.860345 0.621015 0.113673 0.575972 0.871345 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 454
Initial state: 0 0.900174 0.352995 0.625633 0.896147 0.561189 0.814621 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690387 episodes
GETTING ACTION FROM:
action 1, numVisits=690375, meanQ=6.223943, numObservations: 5
action 2, numVisits=6, meanQ=2.663333, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 1
Next state: 2 0.900174 0.352995 0.625633 0.896147 0.561189 0.814621 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 455
Initial state: 0 0.540104 0.891877 0.505081 0.873779 0.0679557 0.931272 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 477022 episodes
GETTING ACTION FROM:
action 0, numVisits=477012, meanQ=4.124369, numObservations: 1
action 3, numVisits=5, meanQ=-0.802000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.540104 0.891877 0.505081 0.873779 0.0679557 0.931272 w: 1
Observation: 0 0 0.874048 0 0.958475 0 0.94854 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=476985, meanQ=6.184811, numObservations: 3
action 1, numVisits=21, meanQ=4.330967, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 757979 episodes
GETTING ACTION FROM:
action 2, numVisits=1234964, meanQ=6.353684, numObservations: 3
action 1, numVisits=21, meanQ=4.330967, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.540104 0.891877 0.505081 0.873779 0.0679557 0.931272 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 456
Initial state: 0 0.691869 0.890763 0.566907 0.840389 0.74244 0.52053 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696157 episodes
GETTING ACTION FROM:
action 2, numVisits=696027, meanQ=6.213268, numObservations: 4
action -1, numVisits=119, meanQ=5.547601, numObservations: 1
action 1, numVisits=7, meanQ=3.412857, numObservations: 3
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.691869 0.890763 0.566907 0.840389 0.74244 0.52053 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 457
Initial state: 0 0.284948 0.759662 0.655078 0.865366 0.659703 0.882296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691020 episodes
GETTING ACTION FROM:
action 3, numVisits=691008, meanQ=6.325625, numObservations: 4
action 1, numVisits=8, meanQ=3.121250, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 1 0.284948 0.759662 0.655078 0.865366 0.659703 0.882296 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 458
Initial state: 0 0.702546 0.404405 0.526825 0.831923 0.518708 0.855728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688715 episodes
GETTING ACTION FROM:
action 1, numVisits=688618, meanQ=6.180999, numObservations: 5
action 0, numVisits=40, meanQ=5.002568, numObservations: 1
action -1, numVisits=35, meanQ=4.919669, numObservations: 1
action 2, numVisits=16, meanQ=4.123750, numObservations: 3
action 3, numVisits=6, meanQ=2.663333, numObservations: 3
action: 1
Next state: 2 0.702546 0.404405 0.526825 0.831923 0.518708 0.855728 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 459
Initial state: 0 0.517495 0.86662 0.463172 0.107076 0.696567 0.82882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 685506 episodes
GETTING ACTION FROM:
action 3, numVisits=685472, meanQ=6.237492, numObservations: 5
action 2, numVisits=22, meanQ=4.045000, numObservations: 3
action 1, numVisits=8, meanQ=2.873750, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.517495 0.86662 0.463172 0.107076 0.696567 0.82882 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 460
Initial state: 0 0.570268 0.822199 0.215362 0.440259 0.577377 0.852161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693852 episodes
GETTING ACTION FROM:
action 1, numVisits=693740, meanQ=6.226096, numObservations: 4
action -1, numVisits=107, meanQ=5.523868, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-5.505000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.570268 0.822199 0.215362 0.440259 0.577377 0.852161 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 461
Initial state: 0 0.525184 0.88765 0.518443 0.804178 0.188827 0.781526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694981 episodes
GETTING ACTION FROM:
action 3, numVisits=694927, meanQ=6.227880, numObservations: 4
action -1, numVisits=49, meanQ=5.170537, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.525184 0.88765 0.518443 0.804178 0.188827 0.781526 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=17633, meanQ=8.675699, numObservations: 4
action 1, numVisits=110, meanQ=8.015912, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 856563 episodes
GETTING ACTION FROM:
action 2, numVisits=874025, meanQ=6.632478, numObservations: 4
action 1, numVisits=279, meanQ=6.195270, numObservations: 4
action 3, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.525184 0.88765 0.518443 0.804178 0.188827 0.781526 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 462
Initial state: 0 0.544871 0.844956 0.569069 0.518255 0.536877 0.849654 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695247 episodes
GETTING ACTION FROM:
action 1, numVisits=695180, meanQ=6.237923, numObservations: 4
action -1, numVisits=49, meanQ=5.192952, numObservations: 1
action 2, numVisits=15, meanQ=4.326667, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.544871 0.844956 0.569069 0.518255 0.536877 0.849654 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=54895, meanQ=8.884298, numObservations: 5
action 2, numVisits=40774, meanQ=8.879220, numObservations: 5
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 836493 episodes
GETTING ACTION FROM:
action 3, numVisits=625799, meanQ=6.585048, numObservations: 5
action 2, numVisits=306272, meanQ=6.581112, numObservations: 5
action 1, numVisits=92, meanQ=5.798153, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.544871 0.844956 0.569069 0.518255 0.536877 0.849654 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 463
Initial state: 0 0.644141 0.910383 0.65934 0.848164 0.538098 0.845997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689194 episodes
GETTING ACTION FROM:
action 1, numVisits=689124, meanQ=6.218446, numObservations: 5
action 0, numVisits=38, meanQ=4.990884, numObservations: 1
action -1, numVisits=28, meanQ=4.775035, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.644141 0.910383 0.65934 0.848164 0.538098 0.845997 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 464
Initial state: 0 0.542987 0.839645 0.178304 0.158192 0.522473 0.809686 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701483 episodes
GETTING ACTION FROM:
action 2, numVisits=701476, meanQ=6.225614, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.542987 0.839645 0.178304 0.158192 0.522473 0.809686 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=72321, meanQ=8.856948, numObservations: 4
action 3, numVisits=41337, meanQ=8.850449, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 855679 episodes
GETTING ACTION FROM:
action 3, numVisits=497399, meanQ=6.736253, numObservations: 4
action 1, numVisits=471935, meanQ=6.735330, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.542987 0.839645 0.178304 0.158192 0.522473 0.809686 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 465
Initial state: 0 0.585575 0.845845 0.600091 0.823832 0.144058 0.956818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696631 episodes
GETTING ACTION FROM:
action 3, numVisits=696547, meanQ=6.225990, numObservations: 4
action -1, numVisits=71, meanQ=5.347637, numObservations: 1
action 1, numVisits=7, meanQ=3.412857, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 1 0.585575 0.845845 0.600091 0.823832 0.144058 0.956818 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 466
Initial state: 0 0.518458 0.806925 0.558574 0.84385 0.55838 0.972841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 705483 episodes
GETTING ACTION FROM:
action 3, numVisits=705345, meanQ=6.231387, numObservations: 3
action 2, numVisits=132, meanQ=5.101442, numObservations: 4
action 1, numVisits=2, meanQ=-0.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.518458 0.806925 0.558574 0.84385 0.55838 0.972841 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 467
Initial state: 0 0.511641 0.879423 0.646308 0.82716 0.204689 0.812994 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689235 episodes
GETTING ACTION FROM:
action 2, numVisits=689196, meanQ=6.234201, numObservations: 5
action 1, numVisits=29, meanQ=4.748286, numObservations: 4
action 3, numVisits=6, meanQ=2.331683, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.511641 0.879423 0.646308 0.82716 0.204689 0.812994 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 468
Initial state: 0 0.596444 0.899555 0.645881 0.856317 0.429013 0.405362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688428 episodes
GETTING ACTION FROM:
action 3, numVisits=688331, meanQ=6.237303, numObservations: 5
action 0, numVisits=84, meanQ=5.438616, numObservations: 1
action 2, numVisits=6, meanQ=2.333333, numObservations: 2
action 1, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.596444 0.899555 0.645881 0.856317 0.429013 0.405362 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=62898, meanQ=8.892575, numObservations: 3
action 2, numVisits=31775, meanQ=8.884956, numObservations: 5
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 858111 episodes
GETTING ACTION FROM:
action 1, numVisits=485182, meanQ=6.643704, numObservations: 3
action 2, numVisits=467599, meanQ=6.643693, numObservations: 5
action 3, numVisits=4, meanQ=1.747500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.596444 0.899555 0.645881 0.856317 0.429013 0.405362 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 469
Initial state: 0 0.666553 0.882217 0.676731 0.802914 0.819239 0.998592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 698833 episodes
GETTING ACTION FROM:
action 3, numVisits=698763, meanQ=6.234188, numObservations: 4
action 2, numVisits=52, meanQ=5.153656, numObservations: 3
action 1, numVisits=14, meanQ=4.070007, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.666553 0.882217 0.676731 0.802914 0.819239 0.998592 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 470
Initial state: 0 0.608051 0.881368 0.508515 0.822174 0.062442 0.0692692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 692216 episodes
GETTING ACTION FROM:
action 2, numVisits=691893, meanQ=6.228661, numObservations: 5
action 1, numVisits=299, meanQ=5.349268, numObservations: 4
action -1, numVisits=21, meanQ=4.593654, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.608051 0.881368 0.508515 0.822174 0.062442 0.0692692 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 471
Initial state: 0 0.57311 0.842249 0.608468 0.803174 0.211605 0.0788142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686021 episodes
GETTING ACTION FROM:
action 3, numVisits=685995, meanQ=6.220047, numObservations: 5
action 0, numVisits=20, meanQ=4.554384, numObservations: 2
action 2, numVisits=3, meanQ=-0.670000, numObservations: 1
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.57311 0.842249 0.608468 0.803174 0.211605 0.0788142 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=93741, meanQ=8.883434, numObservations: 4
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 849349 episodes
GETTING ACTION FROM:
action 2, numVisits=940723, meanQ=6.503613, numObservations: 4
action 1, numVisits=2363, meanQ=6.355205, numObservations: 5
action 3, numVisits=6, meanQ=0.831667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.57311 0.842249 0.608468 0.803174 0.211605 0.0788142 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 472
Initial state: 0 0.532144 0.854361 0.56339 0.300457 0.641232 0.84482 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699024 episodes
GETTING ACTION FROM:
action 3, numVisits=698930, meanQ=6.242357, numObservations: 4
action -1, numVisits=86, meanQ=5.447663, numObservations: 1
action 1, numVisits=4, meanQ=-0.505000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.532144 0.854361 0.56339 0.300457 0.641232 0.84482 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 473
Initial state: 0 0.134388 0.628774 0.511255 0.865312 0.601588 0.891179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693913 episodes
GETTING ACTION FROM:
action 3, numVisits=693789, meanQ=6.243275, numObservations: 4
action 0, numVisits=56, meanQ=5.262224, numObservations: 1
action -1, numVisits=24, meanQ=4.712150, numObservations: 1
action 2, numVisits=37, meanQ=4.455146, numObservations: 4
action 1, numVisits=7, meanQ=3.285714, numObservations: 2
action: 3
Next state: 1 0.134388 0.628774 0.511255 0.865312 0.601588 0.891179 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 474
Initial state: 0 0.650691 0.835833 0.560135 0.806105 0.646522 0.604829 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 680234 episodes
GETTING ACTION FROM:
action 3, numVisits=680193, meanQ=6.099193, numObservations: 4
action 2, numVisits=27, meanQ=4.140744, numObservations: 4
action 1, numVisits=10, meanQ=2.297000, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.650691 0.835833 0.560135 0.806105 0.646522 0.604829 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 475
Initial state: 0 0.676382 0.881738 0.654856 0.282799 0.666311 0.889097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 690983 episodes
GETTING ACTION FROM:
action 2, numVisits=690954, meanQ=6.219276, numObservations: 5
action -1, numVisits=16, meanQ=4.173230, numObservations: 1
action 1, numVisits=10, meanQ=2.096030, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.676382 0.881738 0.654856 0.282799 0.666311 0.889097 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=70242, meanQ=8.890047, numObservations: 4
action 3, numVisits=24806, meanQ=8.872551, numObservations: 4
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 854136 episodes
GETTING ACTION FROM:
action 1, numVisits=531837, meanQ=6.685159, numObservations: 4
action 3, numVisits=417343, meanQ=6.683714, numObservations: 4
action 2, numVisits=5, meanQ=3.198000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.676382 0.881738 0.654856 0.282799 0.666311 0.889097 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 476
Initial state: 0 0.512535 0.841651 0.587773 0.894166 0.930973 0.212304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701669 episodes
GETTING ACTION FROM:
action 2, numVisits=701541, meanQ=6.182827, numObservations: 4
action 1, numVisits=78, meanQ=5.186287, numObservations: 4
action -1, numVisits=30, meanQ=4.834875, numObservations: 1
action 3, numVisits=18, meanQ=4.055000, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 0 0.512535 0.841651 0.587773 0.894166 0.930973 0.212304 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=30835, meanQ=5.344103, numObservations: 4
action -1, numVisits=24, meanQ=4.015661, numObservations: 1
action 3, numVisits=26, meanQ=3.728473, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 785808 episodes
GETTING ACTION FROM:
action 2, numVisits=816643, meanQ=5.778962, numObservations: 4
action -1, numVisits=24, meanQ=4.015661, numObservations: 1
action 3, numVisits=26, meanQ=3.728473, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.512535 0.841651 0.587773 0.894166 0.930973 0.212304 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 477
Initial state: 0 0.487711 0.970555 0.699905 0.893864 0.622704 0.808443 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688678 episodes
GETTING ACTION FROM:
action 3, numVisits=688668, meanQ=6.219210, numObservations: 5
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.487711 0.970555 0.699905 0.893864 0.622704 0.808443 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.946286 0.41049 0.545473 0.833831 0.669118 0.805236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 464735 episodes
GETTING ACTION FROM:
action -1, numVisits=464724, meanQ=4.038536, numObservations: 1
action 2, numVisits=3, meanQ=-0.670000, numObservations: 2
action 1, numVisits=5, meanQ=-0.802000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.946286 0.41049 0.545473 0.833831 0.669118 0.805236 w: 1
Observation: 0 1 0 0.568588 0 0.726264 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=464677, meanQ=6.117189, numObservations: 5
action -1, numVisits=36, meanQ=4.914212, numObservations: 1
action 3, numVisits=6, meanQ=2.663333, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 719941 episodes
GETTING ACTION FROM:
action 1, numVisits=1184617, meanQ=6.108715, numObservations: 5
action -1, numVisits=37, meanQ=4.854672, numObservations: 1
action 3, numVisits=6, meanQ=2.663333, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.946286 0.41049 0.545473 0.833831 0.669118 0.805236 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 479
Initial state: 0 0.564677 0.802636 0.0866838 0.257627 0.673386 0.807465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691446 episodes
GETTING ACTION FROM:
action 2, numVisits=691413, meanQ=6.188644, numObservations: 5
action -1, numVisits=22, meanQ=4.492466, numObservations: 1
action 0, numVisits=5, meanQ=1.958020, numObservations: 2
action 1, numVisits=4, meanQ=1.747500, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 0 0.564677 0.802636 0.0866838 0.257627 0.673386 0.807465 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=38187, meanQ=8.934487, numObservations: 3
action 1, numVisits=36735, meanQ=8.933922, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 846342 episodes
GETTING ACTION FROM:
action 3, numVisits=575731, meanQ=6.494873, numObservations: 5
action 1, numVisits=345532, meanQ=6.492145, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 3
Next state: 0 0.564677 0.802636 0.0866838 0.257627 0.673386 0.807465 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=438, meanQ=8.503722, numObservations: 3
action 3, numVisits=123, meanQ=8.240814, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 880149 episodes
GETTING ACTION FROM:
action 1, numVisits=875668, meanQ=6.441608, numObservations: 3
action 3, numVisits=5028, meanQ=6.338181, numObservations: 4
action 2, numVisits=15, meanQ=4.399333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.564677 0.802636 0.0866838 0.257627 0.673386 0.807465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.8309
Run # 480
Initial state: 0 0.675147 0.881839 0.599277 0.837113 0.842321 0.381009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 697147 episodes
GETTING ACTION FROM:
action 3, numVisits=697071, meanQ=6.224734, numObservations: 4
action -1, numVisits=45, meanQ=5.110926, numObservations: 1
action 2, numVisits=23, meanQ=4.690439, numObservations: 4
action 1, numVisits=6, meanQ=2.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.675147 0.881839 0.599277 0.837113 0.842321 0.381009 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 481
Initial state: 0 0.521883 0.818079 0.404602 0.427367 0.67548 0.882926 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 699356 episodes
GETTING ACTION FROM:
action 2, numVisits=699333, meanQ=6.159686, numObservations: 4
action 0, numVisits=17, meanQ=4.385647, numObservations: 1
action 1, numVisits=2, meanQ=-0.509950, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 0 0.521883 0.818079 0.404602 0.427367 0.67548 0.882926 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=40314, meanQ=8.937885, numObservations: 3
action 1, numVisits=35507, meanQ=8.935709, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 853876 episodes
GETTING ACTION FROM:
action 3, numVisits=749931, meanQ=6.590005, numObservations: 4
action 1, numVisits=179763, meanQ=6.580805, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.521883 0.818079 0.404602 0.427367 0.67548 0.882926 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 482
Initial state: 0 0.645238 0.877774 0.33855 0.467674 0.671942 0.841652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689843 episodes
GETTING ACTION FROM:
action 2, numVisits=689763, meanQ=6.229863, numObservations: 5
action 0, numVisits=37, meanQ=5.016823, numObservations: 1
action 3, numVisits=40, meanQ=4.860507, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.645238 0.877774 0.33855 0.467674 0.671942 0.841652 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=59199, meanQ=8.876312, numObservations: 4
action 1, numVisits=35097, meanQ=8.868052, numObservations: 5
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 841044 episodes
GETTING ACTION FROM:
action 1, numVisits=644235, meanQ=6.885500, numObservations: 5
action 3, numVisits=291096, meanQ=6.880910, numObservations: 4
action 2, numVisits=10, meanQ=3.990000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.645238 0.877774 0.33855 0.467674 0.671942 0.841652 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 483
Initial state: 0 0.621698 0.873543 0.543799 0.856988 0.728446 0.86555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 689948 episodes
GETTING ACTION FROM:
action 2, numVisits=689924, meanQ=6.222848, numObservations: 5
action 3, numVisits=19, meanQ=4.314221, numObservations: 3
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.621698 0.873543 0.543799 0.856988 0.728446 0.86555 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 484
Initial state: 0 0.430525 0.643253 0.514497 0.846951 0.588862 0.869528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 695264 episodes
GETTING ACTION FROM:
action 3, numVisits=695237, meanQ=6.222392, numObservations: 4
action -1, numVisits=16, meanQ=4.375412, numObservations: 1
action 2, numVisits=7, meanQ=3.425729, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 1 0.430525 0.643253 0.514497 0.846951 0.588862 0.869528 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 485
Initial state: 0 0.499143 0.207789 0.694229 0.821124 0.619005 0.824311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686867 episodes
GETTING ACTION FROM:
action 3, numVisits=686843, meanQ=6.176192, numObservations: 5
action 1, numVisits=16, meanQ=3.998762, numObservations: 4
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.499143 0.207789 0.694229 0.821124 0.619005 0.824311 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 486
Initial state: 0 0.558778 0.886124 0.587084 0.843678 0.77277 0.463847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 701167 episodes
GETTING ACTION FROM:
action 2, numVisits=700498, meanQ=6.320661, numObservations: 4
action 3, numVisits=665, meanQ=5.984420, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 2
action: 2
Next state: 1 0.558778 0.886124 0.587084 0.843678 0.77277 0.463847 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 487
Initial state: 0 0.661753 0.809845 0.103018 0.105147 0.55734 0.898588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 693776 episodes
GETTING ACTION FROM:
action 1, numVisits=291060, meanQ=6.180504, numObservations: 4
action 3, numVisits=402645, meanQ=6.167387, numObservations: 5
action -1, numVisits=39, meanQ=4.953007, numObservations: 1
action 2, numVisits=19, meanQ=4.419474, numObservations: 4
action 0, numVisits=13, meanQ=3.996849, numObservations: 1
action: 1
Next state: 0 0.661753 0.809845 0.103018 0.105147 0.55734 0.898588 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=12986, meanQ=5.325233, numObservations: 3
action 2, numVisits=10, meanQ=2.099000, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 797511 episodes
GETTING ACTION FROM:
action 1, numVisits=810495, meanQ=5.854106, numObservations: 3
action 2, numVisits=10, meanQ=2.099000, numObservations: 3
action 3, numVisits=4, meanQ=1.747500, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 0 0.661753 0.809845 0.103018 0.105147 0.55734 0.898588 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=9363, meanQ=8.229567, numObservations: 3
action 3, numVisits=84, meanQ=7.450955, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 882036 episodes
GETTING ACTION FROM:
action 2, numVisits=891040, meanQ=6.759609, numObservations: 3
action 3, numVisits=441, meanQ=6.389547, numObservations: 4
action 1, numVisits=3, meanQ=-0.670000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.661753 0.809845 0.103018 0.105147 0.55734 0.898588 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=1935, meanQ=8.915881, numObservations: 3
action 1, numVisits=25, meanQ=7.839600, numObservations: 3
action 2, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 867108 episodes
GETTING ACTION FROM:
action 3, numVisits=868822, meanQ=6.838977, numObservations: 4
action 1, numVisits=245, meanQ=6.354980, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 1 0.661753 0.809845 0.103018 0.105147 0.55734 0.898588 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 5.76259
Run # 488
Initial state: 0 0.594761 0.894937 0.570062 0.844418 0.457765 0.874315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 705810 episodes
GETTING ACTION FROM:
action 3, numVisits=705754, meanQ=6.178191, numObservations: 3
action -1, numVisits=38, meanQ=4.947716, numObservations: 1
action 2, numVisits=14, meanQ=2.641436, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.594761 0.894937 0.570062 0.844418 0.457765 0.874315 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 489
Initial state: 0 0.544766 0.83983 0.600239 0.863109 0.408154 0.301731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 694216 episodes
GETTING ACTION FROM:
action 1, numVisits=694181, meanQ=6.231369, numObservations: 4
action 3, numVisits=29, meanQ=2.724145, numObservations: 3
action 2, numVisits=2, meanQ=-1.004950, numObservations: 1
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.544766 0.83983 0.600239 0.863109 0.408154 0.301731 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 490
Initial state: 0 0.468311 0.058477 0.511172 0.860504 0.540871 0.897199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 696827 episodes
GETTING ACTION FROM:
action 3, numVisits=696769, meanQ=6.234244, numObservations: 4
action -1, numVisits=30, meanQ=4.885078, numObservations: 1
action 0, numVisits=23, meanQ=4.621346, numObservations: 1
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.468311 0.058477 0.511172 0.860504 0.540871 0.897199 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 491
Initial state: 0 0.6929 0.803419 0.672285 0.875051 0.99321 0.917866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688900 episodes
GETTING ACTION FROM:
action 3, numVisits=688811, meanQ=6.177952, numObservations: 5
action 2, numVisits=48, meanQ=5.113544, numObservations: 4
action -1, numVisits=37, meanQ=4.949507, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 2 0.6929 0.803419 0.672285 0.875051 0.99321 0.917866 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 492
Initial state: 0 0.668648 0.801997 0.589652 0.170506 0.660387 0.872778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 713463 episodes
GETTING ACTION FROM:
action 2, numVisits=713386, meanQ=6.231122, numObservations: 3
action -1, numVisits=69, meanQ=5.336467, numObservations: 1
action 1, numVisits=4, meanQ=1.495050, numObservations: 2
action 3, numVisits=2, meanQ=-0.010000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.668648 0.801997 0.589652 0.170506 0.660387 0.872778 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 493
Initial state: 0 0.639238 0.881866 0.546158 0.869212 0.105347 0.512924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 686832 episodes
GETTING ACTION FROM:
action 3, numVisits=686761, meanQ=6.174772, numObservations: 5
action 1, numVisits=41, meanQ=4.744395, numObservations: 4
action 0, numVisits=21, meanQ=4.561135, numObservations: 1
action 2, numVisits=7, meanQ=1.997157, numObservations: 2
action -1, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 3
Next state: 0 0.639238 0.881866 0.546158 0.869212 0.105347 0.512924 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=72792, meanQ=8.899173, numObservations: 3
action 1, numVisits=21179, meanQ=8.879046, numObservations: 4
action 3, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 861440 episodes
GETTING ACTION FROM:
action 2, numVisits=533582, meanQ=6.704605, numObservations: 3
action 1, numVisits=421826, meanQ=6.703355, numObservations: 4
action 3, numVisits=4, meanQ=1.202500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.639238 0.881866 0.546158 0.869212 0.105347 0.512924 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 494
Initial state: 0 0.838034 0.30163 0.543688 0.884354 0.692409 0.886117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 700910 episodes
GETTING ACTION FROM:
action 2, numVisits=700830, meanQ=6.230287, numObservations: 4
action -1, numVisits=43, meanQ=5.109965, numObservations: 1
action 1, numVisits=30, meanQ=2.929347, numObservations: 4
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 2
Next state: 1 0.838034 0.30163 0.543688 0.884354 0.692409 0.886117 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 495
Initial state: 0 0.12537 0.37233 0.559618 0.879525 0.682418 0.822943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687532 episodes
GETTING ACTION FROM:
action 3, numVisits=687366, meanQ=6.228461, numObservations: 5
action 0, numVisits=61, meanQ=5.281650, numObservations: 1
action -1, numVisits=47, meanQ=5.155756, numObservations: 1
action 2, numVisits=56, meanQ=5.031439, numObservations: 4
action 1, numVisits=2, meanQ=-1.004950, numObservations: 1
action: 3
Next state: 0 0.12537 0.37233 0.559618 0.879525 0.682418 0.822943 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=3753, meanQ=5.926882, numObservations: 4
action 3, numVisits=6, meanQ=2.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 853257 episodes
GETTING ACTION FROM:
action 2, numVisits=857010, meanQ=6.602953, numObservations: 4
action 3, numVisits=6, meanQ=2.333333, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.12537 0.37233 0.559618 0.879525 0.682418 0.822943 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
Run # 496
Initial state: 0 0.151091 0.557938 0.655317 0.87242 0.581272 0.868934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 687137 episodes
GETTING ACTION FROM:
action 3, numVisits=687097, meanQ=6.230521, numObservations: 5
action -1, numVisits=30, meanQ=4.876019, numObservations: 1
action 1, numVisits=7, meanQ=1.998571, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.151091 0.557938 0.655317 0.87242 0.581272 0.868934 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 497
Initial state: 0 0.656564 0.837661 0.34981 0.59523 0.656317 0.826115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 684454 episodes
GETTING ACTION FROM:
action 3, numVisits=684391, meanQ=6.235605, numObservations: 5
action 0, numVisits=50, meanQ=5.184926, numObservations: 1
action 1, numVisits=7, meanQ=1.997157, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.656564 0.837661 0.34981 0.59523 0.656317 0.826115 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 498
Initial state: 0 0.548054 0.879792 0.636438 0.845271 0.0564373 0.67952 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 705421 episodes
GETTING ACTION FROM:
action 1, numVisits=705386, meanQ=6.226539, numObservations: 3
action -1, numVisits=21, meanQ=4.545336, numObservations: 1
action 3, numVisits=8, meanQ=2.873750, numObservations: 3
action 2, numVisits=4, meanQ=1.747500, numObservations: 2
action 0, numVisits=2, meanQ=-1.509950, numObservations: 1
action: 1
Next state: 1 0.548054 0.879792 0.636438 0.845271 0.0564373 0.67952 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 499
Initial state: 0 0.559348 0.0319513 0.695507 0.831131 0.63984 0.861747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 675589 episodes
GETTING ACTION FROM:
action 3, numVisits=675420, meanQ=6.140193, numObservations: 5
action 0, numVisits=147, meanQ=5.542417, numObservations: 1
action 1, numVisits=11, meanQ=3.814555, numObservations: 4
action 2, numVisits=9, meanQ=2.553333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.559348 0.0319513 0.695507 0.831131 0.63984 0.861747 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 500
Initial state: 0 0.641404 0.345106 0.59488 0.831597 0.658725 0.8029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 708368 episodes
GETTING ACTION FROM:
action 1, numVisits=708265, meanQ=6.237952, numObservations: 3
action -1, numVisits=59, meanQ=5.289409, numObservations: 1
action 0, numVisits=42, meanQ=5.103749, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.641404 0.345106 0.59488 0.831597 0.658725 0.8029 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -1
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=75056, meanQ=8.862003, numObservations: 4
action 3, numVisits=40121, meanQ=8.853735, numObservations: 3
action 1, numVisits=1, meanQ=-0.010000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 858248 episodes
GETTING ACTION FROM:
action 3, numVisits=552180, meanQ=6.886069, numObservations: 3
action 2, numVisits=421244, meanQ=6.884702, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=2, meanQ=-5.505000, numObservations: 1
action: 3
Next state: 1 0.641404 0.345106 0.59488 0.831597 0.658725 0.8029 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.91
